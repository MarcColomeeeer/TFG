[
    {
        "title": "A Method for Solving Distributed Service Allocation Problems",
        "authors": [
            "Jose M Vidal"
        ],
        "category": "cs.MA",
        "published_year": "2003",
        "summary": "  We present a method for solving service allocation problems in which a set of\nservices must be allocated to a set of agents so as to maximize a global\nutility. The method is completely distributed so it can scale to any number of\nservices without degradation. We first formalize the service allocation problem\nand then present a simple hill-climbing, a global hill-climbing, and a\nbidding-protocol algorithm for solving it. We analyze the expected performance\nof these algorithms as a function of various problem parameters such as the\nbranching factor and the number of agents. Finally, we use the sensor\nallocation problem, an instance of a service allocation problem, to show the\nbidding protocol at work. The simulations also show that phase transition on\nthe expected quality of the solution exists as the amount of communication\nbetween agents increases.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0306119v1"
    },
    {
        "title": "Running C++ models undet the Swarm environment",
        "authors": [
            "Richard Leow",
            "Russell K. Standish"
        ],
        "category": "cs.MA",
        "published_year": "2004",
        "summary": "  Objective-C is still the language of choice if users want to run their\nsimulation efficiently under the Swarm environment since the Swarm environment\nitself was written in Objective-C. The language is a fast, object-oriented and\neasy to learn. However, the language is less well known than, less expressive\nthan, and lacks support for many important features of C++ (eg. OpenMP for high\nperformance computing application). In this paper, we present a methodology and\nsoftware tools that we have developed for auto generating an Objective-C object\ntemplate (and all the necessary interfacing functions) from a given C++ model,\nutilising the Classdesc's object description technology, so that the C++ model\ncan both be run and accessed under the Objective-C and C++ environments. We\nalso present a methodology for modifying an existing Swarm application to make\npart of the model (eg. the heatbug's step method) run under the C++\nenvironment.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0401025v1"
    },
    {
        "title": "EcoLab: Agent Based Modeling for C++ programmers",
        "authors": [
            "Russell K. Standish",
            "Richard Leow"
        ],
        "category": "cs.MA",
        "published_year": "2004",
        "summary": "  \\EcoLab{} is an agent based modeling system for C++ programmers, strongly\ninfluenced by the design of Swarm. This paper is just a brief outline of\n\\EcoLab's features, more details can be found in other published articles,\ndocumentation and source code from the \\EcoLab{} website.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0401026v1"
    },
    {
        "title": "An agent framework for dynamic agent retraining: Agent academy",
        "authors": [
            "P. Mitkas",
            "A. Symeonidis",
            "D. Kechagias",
            "I. N. Athanasiadis",
            "G. Laleci",
            "G. Kurt",
            "Y. Kabak",
            "A. Acar",
            "A. Dogac"
        ],
        "category": "cs.MA",
        "published_year": "2004",
        "summary": "  Agent Academy (AA) aims to develop a multi-agent society that can train new\nagents for specific or general tasks, while constantly retraining existing\nagents in a recursive mode. The system is based on collecting information both\nfrom the environment and the behaviors of the acting agents and their related\nsuccesses/failures to generate a body of data, stored in the Agent Use\nRepository, which is mined by the Data Miner module, in order to generate\nuseful knowledge about the application domain. Knowledge extracted by the Data\nMiner is used by the Agent Training Module as to train new agents or to enhance\nthe behavior of agents already running. In this paper the Agent Academy\nframework is introduced, and its overall architecture and functionality are\npresented. Training issues as well as agent ontologies are discussed. Finally,\na scenario, which aims to provide environmental alerts to both individuals and\npublic authorities, is described an AA-based use case.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0407025v1"
    },
    {
        "title": "Coalition Formation: Concessions, Task Relationships and Complexity\n  Reduction",
        "authors": [
            "Samir Aknine",
            "Onn Shehory"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  Solutions to the coalition formation problem commonly assume agent\nrationality and, correspondingly, utility maximization. This in turn may\nprevent agents from making compromises. As shown in recent studies, compromise\nmay facilitate coalition formation and increase agent utilities. In this study\nwe leverage on those new results. We devise a novel coalition formation\nmechanism that enhances compromise. Our mechanism can utilize information on\ntask dependencies to reduce formation complexity. Further, it works well with\nboth cardinal and ordinal task values. Via experiments we show that the use of\nthe suggested compromise-based coalition formation mechanism provides\nsignificant savings in the computation and communication complexity of\ncoalition formation. Our results also show that when information on task\ndependencies is used, the complexity of coalition formation is further reduced.\nWe demonstrate successful use of the mechanism for collaborative information\nfiltering, where agents combine linguistic rules to analyze documents'\ncontents.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0502094v1"
    },
    {
        "title": "Emergent Statistical Wealth Distributions in Simple Monetary Exchange\n  Models: A Critical Review",
        "authors": [
            "Thomas Lux"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  This paper reviews recent attempts at modelling inequality of wealth as an\nemergent phenomenon of interacting-agent processes. We point out that recent\nmodels of wealth condensation which draw their inspiration from molecular\ndynamics have, in fact, reinvented a process introduced quite some time ago by\nAngle (1986) in the sociological literature. We emphasize some problematic\naspects of simple wealth exchange models and contrast them with a monetary\nmodel based on economic principles of market mediated exchange. The paper also\nreports new results on the influence of market power on the wealth distribution\nin statistical equilibrium. As it turns out, inequality increases but market\npower alone is not sufficient for changing the exponential tails of simple\nexchange models into Pareto tails.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0506092v1"
    },
    {
        "title": "Friends for Free: Self-Organizing Artificial Social Networks for Trust\n  and Cooperation",
        "authors": [
            "David Hales",
            "Stefano Arteconi"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  By harvesting friendship networks from e-mail contacts or instant message\n\"buddy lists\" Peer-to-Peer (P2P) applications can improve performance in low\ntrust environments such as the Internet. However, natural social networks are\nnot always suitable, reliable or available. We propose an algorithm (SLACER)\nthat allows peer nodes to create and manage their own friendship networks.\n  We evaluate performance using a canonical test application, requiring\ncooperation between peers for socially optimal outcomes. The Artificial Social\nNetworks (ASN) produced are connected, cooperative and robust - possessing many\nof the disable properties of human friendship networks such as trust between\nfriends (directly linked peers) and short paths linking everyone via a chain of\nfriends.\n  In addition to new application possibilities, SLACER could supply ASN to P2P\napplications that currently depend on human social networks thus transforming\nthem into fully autonomous, self-managing systems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0509037v1"
    },
    {
        "title": "Effect of door delay on aircraft evacuation time",
        "authors": [
            "Martyn Amos",
            "Andrew Wood"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  The recent commercial launch of twin-deck Very Large Transport Aircraft\n(VLTA) such as the Airbus A380 has raised questions concerning the speed at\nwhich they may be evacuated. The abnormal height of emergency exits on the\nupper deck has led to speculation that emotional factors such as fear may lead\nto door delay, and thus play a significant role in increasing overall\nevacuation time. Full-scale evacuation tests are financially expensive and\npotentially hazardous, and systematic studies of the evacuation of VLTA are\nrare. Here we present a computationally cheap agent-based framework for the\ngeneral simulation of aircraft evacuation, and apply it to the particular case\nof the Airbus A380. In particular, we investigate the effect of door delay, and\nconclude that even a moderate average delay can lead to evacuation times that\nexceed the maximum for safety certification. The model suggests practical ways\nto minimise evacuation time, as well as providing a general framework for the\nsimulation of evacuation.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0509050v1"
    },
    {
        "title": "Building Scenarios for Environmental Management and Planning: An\n  IT-Based Approach",
        "authors": [
            "Dino Borri",
            "Domenico Camarda"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  Oftentimes, the need to build multidiscipline knowledge bases, oriented to\npolicy scenarios, entails the involvement of stakeholders in manifold domains,\nwith a juxtaposition of different languages whose semantics can hardly allow\ninter-domain transfers. A useful support for planning is the building up of\ndurable IT based interactive platforms, where it is possible to modify initial\npositions toward a semantic convergence. The present paper shows an area-based\napplication of these tools, for the integrated distance-management of different\nforms of knowledge expressed by selected stakeholders about environmental\nplanning issues, in order to build alternative development scenarios.\n  Keywords: Environmental planning, Scenario building, Multi-source knowledge,\nIT-based\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0602056v1"
    },
    {
        "title": "Open at the Top; Open at the Bottom; and Continually (but Slowly)\n  Evolving",
        "authors": [
            "Russ Abbott"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  Systems of systems differ from traditional systems in that they are open at\nthe top, open at the bottom, and continually (but slowly) evolving. \"Open at\nthe top\" means that there is no pre-defined top level application. New\napplications may be created at any time. \"Open at the bottom\" means that the\nsystem primitives are defined functionally rather than concretely. This allows\nthe implementation of these primitives to be modified as technology changes.\n\"Continually (but slowly) evolving\" means that the system's functionality is\nstable enough to be useful but is understood to be subject to modification.\nSystems with these properties tend to be environments within which other\nsystems operate--and hence are systems of systems. It is also important to\nunderstand the larger environment within which a system of systems exists.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603126v1"
    },
    {
        "title": "Complex Systems + Systems Engineering = Complex Systems Engineeri",
        "authors": [
            "Russ Abbott"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  One may define a complex system as a system in which phenomena emerge as a\nconsequence of multiscale interaction among the system's components and their\nenvironments. The field of Complex Systems is the study of such\nsystems--usually naturally occurring, either bio-logical or social. Systems\nEngineering may be understood to include the conceptualising and building of\nsystems that consist of a large number of concurrently operating and\ninteracting components--usually including both human and non-human elements. It\nhas become increasingly apparent that the kinds of systems that systems\nengineers build have many of the same multiscale characteristics as those of\nnaturally occurring complex systems. In other words, systems engineering is the\nengineering of complex systems. This paper and the associated panel will\nexplore some of the connections between the fields of complex systems and\nsystems engineering.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603127v1"
    },
    {
        "title": "Primitive operations for the construction and reorganization of\n  minimally persistent formations",
        "authors": [
            "Julien M. Hendrickx",
            "Baris Fidan",
            "Changbin Yu",
            "Brian D. O. Anderson",
            "Vincent D. Blondel"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  In this paper, we study the construction and transformation of\ntwo-dimensional persistent graphs. Persistence is a generalization to directed\ngraphs of the undirected notion of rigidity. In the context of moving\nautonomous agent formations, persistence characterizes the efficacy of a\ndirected structure of unilateral distances constraints seeking to preserve a\nformation shape. Analogously to the powerful results about Henneberg sequences\nin minimal rigidity theory, we propose different types of directed graph\noperations allowing one to sequentially build any minimally persistent graph\n(i.e. persistent graph with a minimal number of edges for a given number of\nvertices), each intermediate graph being also minimally persistent. We also\nconsider the more generic problem of obtaining one minimally persistent graph\nfrom another, which corresponds to the on-line reorganization of an autonomous\nagent formation. We prove that we can obtain any minimally persistent formation\nfrom any other one by a sequence of elementary local operations such that\nminimal persistence is preserved throughout the reorganization process.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0609041v1"
    },
    {
        "title": "Going Stupid with EcoLab",
        "authors": [
            "Russell K. Standish"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  In 2005, Railsback et al. proposed a very simple model ({\\em Stupid\n  Model}) that could be implemented within a couple of hours, and later\nextended to demonstrate the use of common ABM platform functionality. They\nprovided implementations of the model in several agent based modelling\nplatforms, and compared the platforms for ease of implementation of this simple\nmodel, and performance. In this paper, I implement Railsback et al's Stupid\nModel in the EcoLab simulation platform, a C++ based modelling platform,\ndemonstrating that it is a feasible platform for these sorts of models, and\ncompare the performance of the implementation with Repast, Mason and Swarm\nversions.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0612014v1"
    },
    {
        "title": "Artificiality in Social Sciences",
        "authors": [
            "Jean-Philippe Rennard"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  This text provides with an introduction to the modern approach of\nartificiality and simulation in social sciences. It presents the relationship\nbetween complexity and artificiality, before introducing the field of\nartificial societies which greatly benefited from the computer power fast\nincrease, gifting social sciences with formalization and experimentation tools\npreviously owned by \"hard\" sciences alone. It shows that as \"a new way of doing\nsocial sciences\", artificial societies should undoubtedly contribute to a\nrenewed approach in the study of sociality and should play a significant part\nin the elaboration of original theories of social phenomena.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0701087v2"
    },
    {
        "title": "Observable Graphs",
        "authors": [
            "Raphael M. Jungers",
            "Vincent D. Blondel"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  An edge-colored directed graph is \\emph{observable} if an agent that moves\nalong its edges is able to determine his position in the graph after a\nsufficiently long observation of the edge colors. When the agent is able to\ndetermine his position only from time to time, the graph is said to be\n\\emph{partly observable}. Observability in graphs is desirable in situations\nwhere autonomous agents are moving on a network and one wants to localize them\n(or the agent wants to localize himself) with limited information. In this\npaper, we completely characterize observable and partly observable graphs and\nshow how these concepts relate to observable discrete event systems and to\nlocal automata. Based on these characterizations, we provide polynomial time\nalgorithms to decide observability, to decide partial observability, and to\ncompute the minimal number of observations necessary for finding the position\nof an agent. In particular we prove that in the worst case this minimal number\nof observations increases quadratically with the number of nodes in the graph.\n  From this it follows that it may be necessary for an agent to pass through\nthe same node several times before he is finally able to determine his position\nin the graph. We then consider the more difficult question of assigning colors\nto a graph so as to make it observable and we prove that two different versions\nof this problem are NP-complete.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0702091v1"
    },
    {
        "title": "Scalability and Optimisation of a Committee of Agents Using Genetic\n  Algorithm",
        "authors": [
            "T. Marwala",
            "P. De Wilde",
            "L. Correia",
            "P. Mariano",
            "R. Ribeiro",
            "V. Abramov",
            "N. Szirbik",
            "J. Goossenaerts"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  A population of committees of agents that learn by using neural networks is\nimplemented to simulate the stock market. Each committee of agents, which is\nregarded as a player in a game, is optimised by continually adapting the\narchitecture of the agents using genetic algorithms. The committees of agents\nbuy and sell stocks by following this procedure: (1) obtain the current price\nof stocks; (2) predict the future price of stocks; (3) and for a given price\ntrade until all the players are mutually satisfied. The trading of stocks is\nconducted by following these rules: (1) if a player expects an increase in\nprice then it tries to buy the stock; (2) else if it expects a drop in the\nprice, it sells the stock; (3)and the order in which a player participates in\nthe game is random. The proposed procedure is implemented to simulate trading\nof three stocks, namely, the Dow Jones, the Nasdaq and the S&P 500. A linear\nrelationship between the number of players and agents versus the computational\ntime to run the complete simulation is observed. It is also found that no\nplayer has a monopolistic advantage.\n",
        "pdf_link": "http://arxiv.org/pdf/0705.1757v1"
    },
    {
        "title": "A competitive multi-agent model of interbank payment systems",
        "authors": [
            "Marco Galbiati",
            "Kimmo Soramaki"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  We develop a dynamic multi-agent model of an interbank payment system where\nbanks choose their level of available funds on the basis of private payoff\nmaximisation. The model consists of the repetition of a simultaneous move stage\ngame with incomplete information, incomplete monitoring, and stochastic\npayoffs. Adaptation takes place with bayesian updating, with banks maximizing\nimmediate payoffs. We carry out numerical simulations to solve the model and\ninvestigate two special scenarios: an operational incident and exogenous\nthroughput guidelines for payment submission. We find that the demand for\nintraday credit is an S-shaped function of the cost ratio between intraday\ncredit costs and the costs associated with delaying payments. We also find that\nthe demand for liquidity is increased both under operational incidents and in\nthe presence of effective throughput guidelines.\n",
        "pdf_link": "http://arxiv.org/pdf/0705.3050v1"
    },
    {
        "title": "A Study On Distributed Model Predictive Consensus",
        "authors": [
            "Tamas Keviczky",
            "Karl Henrik Johansson"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  We investigate convergence properties of a proposed distributed model\npredictive control (DMPC) scheme, where agents negotiate to compute an optimal\nconsensus point using an incremental subgradient method based on primal\ndecomposition as described in Johansson et al. [2006, 2007]. The objective of\nthe distributed control strategy is to agree upon and achieve an optimal common\noutput value for a group of agents in the presence of constraints on the agent\ndynamics using local predictive controllers. Stability analysis using a\nreceding horizon implementation of the distributed optimal consensus scheme is\nperformed. Conditions are given under which convergence can be obtained even if\nthe negotiations do not reach full consensus.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.4450v1"
    },
    {
        "title": "Multi Site Coordination using a Multi-Agent System",
        "authors": [
            "Thibaud Monteiro",
            "Daniel Roy",
            "Didier Anciaux"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  A new approach of coordination of decisions in a multi site system is\nproposed. It is based this approach on a multi-agent concept and on the\nprinciple of distributed network of enterprises. For this purpose, each\nenterprise is defined as autonomous and performs simultaneously at the local\nand global levels. The basic component of our approach is a so-called Virtual\nEnterprise Node (VEN), where the enterprise network is represented as a set of\ntiers (like in a product breakdown structure). Within the network, each partner\nconstitutes a VEN, which is in contact with several customers and suppliers.\nExchanges between the VENs ensure the autonomy of decision, and guarantiee the\nconsistency of information and material flows. Only two complementary VEN\nagents are necessary: one for external interactions, the Negotiator Agent (NA)\nand one for the planning of internal decisions, the Planner Agent (PA). If\nsupply problems occur in the network, two other agents are defined: the Tier\nNegotiator Agent (TNA) working at the tier level only and the Supply Chain\nMediator Agent (SCMA) working at the level of the enterprise network. These two\nagents are only active when the perturbation occurs. Otherwise, the VENs\nprocess the flow of information alone. With this new approach, managing\nenterprise network becomes much more transparent and looks like managing a\nsimple enterprise in the network. The use of a Multi-Agent System (MAS) allows\nphysical distribution of the decisional system, and procures a heterarchical\norganization structure with a decentralized control that guaranties the\nautonomy of each entity and the flexibility of the network.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.3031v1"
    },
    {
        "title": "Multi-agents architecture for supply chain management",
        "authors": [
            "Daniel Roy",
            "Didier Anciaux",
            "Thibaud Monteiro",
            "Latifa Ouzizi"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  The purpose of this paper is to propose a new approach for the supply chain\nmanagement. This approach is based on the virtual enterprise paradigm and the\nused of multi-agent concept. Each entity (like enterprise) is autonomous and\nmust perform local and global goals in relation with its environment. The base\ncomponent of our approach is a Virtual Enterprise Node (VEN). The supply chain\nis viewed as a set of tiers (corresponding to the levels of production), in\nwhich each partner of the supply chain (VEN) is in relation with several\ncustomers and suppliers. Each VEN belongs to one tier. The main customer gives\nglobal objectives (quantity, cost and delay) to the supply chain. The Mediator\nAgent (MA) is in charge to manage the supply chain in order to respect those\nobjectives as global level. Those objectives are taking over to Negotiator\nAgent at the tier level (NAT). These two agents are only active if a\nperturbation occurs; otherwise information flows are only exchange between\nVENs. This architecture allows supply chains management which is completely\ntransparent seen from simple enterprise of the supply chain. The used of\nMulti-Agent System (MAS) allows physical distribution of the decisional system.\nMoreover, the hierarchical organizational structure with a decentralized\ncontrol guaranties, in the same time, the autonomy of each entity and the whole\nflexibility.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.3032v1"
    },
    {
        "title": "On Krause's multi-agent consensus model with state-dependent\n  connectivity (Extended version)",
        "authors": [
            "Vincent D. Blondel",
            "Julien M. Hendrickx",
            "John N. Tsitsiklis"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  We study a model of opinion dynamics introduced by Krause: each agent has an\nopinion represented by a real number, and updates its opinion by averaging all\nagent opinions that differ from its own by less than 1. We give a new proof of\nconvergence into clusters of agents, with all agents in the same cluster\nholding the same opinion. We then introduce a particular notion of equilibrium\nstability and provide lower bounds on the inter-cluster distances at a stable\nequilibrium. To better understand the behavior of the system when the number of\nagents is large, we also introduce and study a variant involving a continuum of\nagents, obtaining partial convergence results and lower bounds on inter-cluster\ndistances, under some mild assumptions.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.2028v4"
    },
    {
        "title": "Multi-Agent Crisis Response systems - Design Requirements and Analysis\n  of Current Systems",
        "authors": [
            "Khaled M. Khalil",
            "M. Abdel-Aziz",
            "Taymour T. Nazmy",
            "Abdel-Badeeh M. Salem"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  Crisis response is a critical area of research, with encouraging progress in\nthe past view yeas. The aim of the research is to contribute to building future\ncrisis environment where software agents, robots, responders, crisis managers,\nand crisis organizations interact to provide advice, protection and aid. This\npaper discusses the crisis response domain requirements, and provides analysis\nof five crisis response systems namely: DrillSim [2], DEFACTO [15], ALADDIN\n[1], RoboCup Rescue [18], and FireGrid [3]. Analysis of systems includes\nsystems architecture and methodology. In addition, we identified features and\nlimitations of systems based on crisis response domain requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.2543v1"
    },
    {
        "title": "Collaborative systems and multiagent systems",
        "authors": [
            "Alin Munteanu",
            "Cristina Ofelia Sofran"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  This paper presents some basic elements regarding the domain of the\ncollaborative systems, a domain of maximum actuality and also the multiagent\nsystems, developed as a result of a sound study on the one-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3669v1"
    },
    {
        "title": "Self-stabilizing Determinsitic Gathering",
        "authors": [
            "Yoann Dieudonné",
            "Franck Petit"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  In this paper, we investigate the possibility to deterministically solve the\ngathering problem (GP) with weak robots (anonymous, autonomous, disoriented,\ndeaf and dumb, and oblivious). We introduce strong multiplicity detection as\nthe ability for the robots to detect the exact number of robots located at a\ngiven position. We show that with strong multiplicity detection, there exists a\ndeterministic self-stabilizing algorithm solving GP for n robots if, and only\nif, n is odd.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.0747v1"
    },
    {
        "title": "Multi-Agent Model Predictive Control: A Survey",
        "authors": [
            "R. R. Negenborn",
            "B. De Schutter",
            "J. Hellendoorn"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  In this report we define characteristic control design elements and show how\nconventional single-agent MPC implements these. We survey recent literature on\nmulti-agent MPC and discuss how this literature deals with decomposition,\nproblem assignment, and cooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/0908.1076v1"
    },
    {
        "title": "Towards Participatory Design of Multi-agent Approach to Transport\n  Demands",
        "authors": [
            "Yee Ming Chen",
            "Bo-Yuan Wang"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  The design of multi-agent based simulations (MABS) is up to now mainly done\nin laboratories and based on designers' understanding of the activities to be\nsimulated. Domain experts have little chance to directly validate agent\nbehaviors. To fill this gap, we are investigating participatory methods of\ndesign, which allow users to participate in the design the pickup and delivery\nproblem (PDP) in the taxi planning problem. In this paper, we present a\nparticipatory process for designing new socio-technical architectures to afford\nthe taxi dispatch for this transportation system. The proposed dispatch\narchitecture attempts to increase passenger satisfaction more globally, by\nconcurrently dispatching multiple taxis to the same number of passengers in the\nsame geographical region, and vis-avis human driver and dispatcher\nsatisfaction.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.1865v1"
    },
    {
        "title": "Set-Rationalizable Choice and Self-Stability",
        "authors": [
            "Felix Brandt",
            "Paul Harrenstein"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  A common assumption in modern microeconomic theory is that choice should be\nrationalizable via a binary preference relation, which \\citeauthor{Sen71a}\nshowed to be equivalent to two consistency conditions, namely $\\alpha$\n(contraction) and $\\gamma$ (expansion). Within the context of \\emph{social}\nchoice, however, rationalizability and similar notions of consistency have\nproved to be highly problematic, as witnessed by a range of impossibility\nresults, among which Arrow's is the most prominent. Since choice functions\nselect \\emph{sets} of alternatives rather than single alternatives, we propose\nto rationalize choice functions by preference relations over sets\n(set-rationalizability). We also introduce two consistency conditions,\n$\\hat\\alpha$ and $\\hat\\gamma$, which are defined in analogy to $\\alpha$ and\n$\\gamma$, and find that a choice function is set-rationalizable if and only if\nit satisfies $\\hat\\alpha$. Moreover, a choice function satisfies $\\hat\\alpha$\nand $\\hat\\gamma$ if and only if it is \\emph{self-stable}, a new concept based\non earlier work by \\citeauthor{Dutt88a}. The class of self-stable social choice\nfunctions contains a number of appealing Condorcet extensions such as the\nminimal covering set and the essential set.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.3580v3"
    },
    {
        "title": "An XML-based Multi-Agent System for Supporting Online Recruitment\n  Services",
        "authors": [
            "P. De Meo",
            "G. Quattrone",
            "G. Terracina",
            "D. Ursino"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  In this paper we propose an XML-based multi-agent recommender system for\nsupporting online recruitment services. Our system is characterized by the\nfollowing features: {\\em (i)} it handles user profiles for personalizing the\njob search over the Internet; {\\em (ii)} it is based on the Intelligent Agent\nTechnology; {\\em (iii)} it uses XML for guaranteeing a light, versatile and\nstandard mechanism for information representation, storing and exchange. The\npaper discusses the basic features of the proposed system, presents the results\nof an experimental study we have carried out for evaluating its performance,\nand makes a comparison between the proposed system and other e-recruitment\nsystems already presented in the past.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0753v1"
    },
    {
        "title": "Multi-Agent System Interaction in Integrated SCM",
        "authors": [
            "Ritu Sindhu",
            "Abdul Wahid",
            "G. N. Purohit"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  Coordination between organizations on strategic, tactical and operation\nlevels leads to more effective and efficient supply chains. Supply chain\nmanagement is increasing day by day in modern enterprises. The environment is\nbecoming competitive and many enterprises will find it difficult to survive if\nthey do not make their sourcing, production and distribution more efficient.\nMulti-agent supply chain management has recognized as an effective methodology\nfor supply chain management. Multi-agent systems (MAS) offer new methods\ncompared to conventional, centrally organized architectures in the scope of\nsupply chain management (SCM). Since necessary data are not available within\nthe whole supply chain, an integrated approach for production planning and\ncontrol taking into account all the partners involved is not feasible. In this\nstudy we show how MAS architecture interacts in the integrated SCM architecture\nwith the help of various intelligent agents to highlight the above problem.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0912v1"
    },
    {
        "title": "Simulation of Pedestrians Crossing a Street",
        "authors": [
            "Cornelia Boenisch",
            "Tobias Kretz"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  The simulation of vehicular traffic as well as pedestrian dynamics meanwhile\nboth have a decades long history. The success of this conference series, PED\nand others show that the interest in these topics is still strongly increasing.\nThis contribution deals with a combination of both systems: pedestrians\ncrossing a street. In a VISSIM simulation for varying demand jam sizes of\nvehicles as well as pedestrians and the travel times of the pedestrians are\nmeasured and compared. The study is considered as a study of VISSIM's con ict\narea functionality as such, as there is no empirical data available to use for\ncalibration issues. Above a vehicle demand threshold the results show a\nnon-monotonic dependence of pedestrians' travel time on pedestrian demand.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.2902v1"
    },
    {
        "title": "Applications of the Dynamic Distance Potential Field Method",
        "authors": [
            "Tobias Kretz"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  Recently the dynamic distance potential field (DDPF) was introduced as a\ncomputationally efficient method to make agents in a simulation of pedestrians\nmove rather on the quickest path than the shortest. It can be considered to be\nan estimated-remaining-journey-time-based one-shot dynamic assignment method\nfor pedestrian route choice on the operational level of dynamics. In this\ncontribution the method is shortly introduced and the effect of the method on\nRiMEA's test case 11 is investigated.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.3723v1"
    },
    {
        "title": "Enhancing Multi-Agent Based Simulation with Human-Agents Interactive\n  Spatial Behaviour",
        "authors": [
            "Yee Ming Chen",
            "Bo-Yuan Wang",
            "Hung-Ming Shiu"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  We are exploring the enhancement of models of agent behaviour with more\n\"human-like\" decision making strategies than are presently available. Our\nmotivation is to developed with a view to as the decision analysis and support\nfor electric taxi company under the mission of energy saving and reduction of\nCO2, in particular car-pool and car-sharing management policies. In order to\nachieve the object of decision analysis for user, we provide a human-agents\ninteractive spatial behaviour to support user making decision real time. We\nadopt passenger average waiting time and electric taxi average idle time as the\nperformance measures and decision support fro electric taxi company. Finally,\naccording to the analysis result, we demonstrate that our multi-agent\nsimulation and GUI can help users or companies quickly make a quality and\naccurate decision to reduce the decision-making cost and time.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3961v1"
    },
    {
        "title": "Multi-Agent Model using Secure Multi-Party Computing in e-Governance",
        "authors": [
            "Durgesh Kumar Mishra",
            "Samiksha Shukla"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  Information management and retrieval of all the citizen occurs in almost all\nthe public service functions. Electronic Government system is an emerging trend\nin India through which efforts are made to strive maximum safety and security.\nVarious solutions for this have been proposed like Shibboleth, Public Key\nInfrastructure, Smart Cards and Light Weight Directory Access Protocols. Still,\nnone of these guarantee 100 percent security. Efforts are being made to provide\ncommon national identity solution to various diverse Government identity cards.\nIn this paper, we discuss issues related to these solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3984v1"
    },
    {
        "title": "Local and Global Trust Based on the Concept of Promises",
        "authors": [
            "Jan Bergstra",
            "Mark Burgess"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  We use the notion of a promise to define local trust between agents\npossessing autonomous decision-making. An agent is trustworthy if it is\nexpected that it will keep a promise. This definition satisfies most\ncommonplace meanings of trust. Reputation is then an estimation of this\nexpectation value that is passed on from agent to agent.\n  Our definition distinguishes types of trust, for different behaviours, and\ndecouples the concept of agent reliability from the behaviour on which the\njudgement is based. We show, however, that trust is fundamentally heuristic, as\nit provides insufficient information for agents to make a rational judgement. A\nglobal trustworthiness, or community trust can be defined by a proportional,\nself-consistent voting process, as a weighted eigenvector-centrality function\nof the promise theoretical graph.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.4637v1"
    },
    {
        "title": "Developing Artificial Herders Using Jason",
        "authors": [
            "Niklas Skamriis Boss",
            "Andreas Schmidt Jensen",
            "Jørgen Villadsen"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  This paper gives an overview of a proposed strategy for the \"Cows and\nHerders\" scenario given in the Multi-Agent Programming Contest 2009. The\nstrategy is to be implemented using the Jason platform, based on the\nagent-oriented programming language Agent-Speak. The paper describes the\nagents, their goals and the strategies they should follow. The basis for the\npaper and for participating in the contest is a new course given in spring 2009\nand our main objective is to show that we are able to implement complex\nmulti-agent systems with the knowledge gained in an introductory course on\nmulti-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.0115v1"
    },
    {
        "title": "A Framework to Manage the Complex Organisation of Collaborating: Its\n  Application to Autonomous Systems",
        "authors": [
            "Peter Johnson",
            "Rachid Hourizi",
            "Neil Carrigan",
            "Nick Forbes"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  In this paper we present an analysis of the complexities of large group\ncollaboration and its application to develop detailed requirements for\ncollaboration schema for Autonomous Systems (AS). These requirements flow from\nour development of a framework for collaboration that provides a basis for\ndesigning, supporting and managing complex collaborative systems that can be\napplied and tested in various real world settings. We present the concepts of\n\"collaborative flow\" and \"working as one\" as descriptive expressions of what\ngood collaborative teamwork can be in such scenarios. The paper considers the\napplication of the framework within different scenarios and discuses the\nutility of the framework in modelling and supporting collaboration in complex\norganisational structures.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.4419v1"
    },
    {
        "title": "A Hybrid System based on Multi-Agent System in the Data Preprocessing\n  Stage",
        "authors": [
            "Kobkul Kularbphettong",
            "Gareth Clayton",
            "Phayung Meesad"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  We describe the usage of the Multi-agent system in the data preprocessing\nstage of an on-going project, called e-Wedding. The aim of this project is to\nutilize MAS and various approaches, like Web services, Ontology, and Data\nmining techniques, in e-Business that want to improve responsiveness and\nefficiency of systems so as to extract customer behavior model on Wedding\nBusinesses. However, in this paper, we propose and implement the\nmulti-agent-system, based on JADE, to only cope data preprocessing stage\nspecified on handle with missing value techniques. JADE is quite easy to learn\nand use. Moreover, it supports many agent approaches such as agent\ncommunication, protocol, behavior and ontology. This framework has been\nexperimented and evaluated in the realization of a simple, but realistic. The\nresults, though still preliminary, are quite.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1792v1"
    },
    {
        "title": "Reconfigurable Parallel Data Flow Architecture",
        "authors": [
            "Hamid Reza Naji"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  This paper presents a reconfigurable parallel data flow architecture. This\narchitecture uses the concepts of multi-agent paradigm in reconfigurable\nhardware systems. The utilization of this new paradigm has the potential to\ngreatly increase the flexibility, efficiency, expandability of data flow\nsystems and to provide an attractive alternative to the current set of disjoint\napproaches that are currently applied to this problem domain. The ability of\nmethodology to implement data flow type processing with different models is\npresented in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1810v1"
    },
    {
        "title": "Improving Supply Chain Coordination by Linking Dynamic Procurement\n  Decision to Multi-Agent System",
        "authors": [
            "Yee Ming Chen"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  The Internet has changed the way business is conducted in many ways. For\nexample, in the field of procurement, the possibility to directly interact with\na trading partner has given rise to new mechanisms in the supply chain\nmanagement. One such interactive dynamic procurement, which lets both buyer and\nseller software agents bid by potential buyer agents instead of static\nprocurement by vendors. Dynamic procurement decision could provide the buying\nand selling channel to buyer, to avoid occurring condition that seller could\nnot deliver on the contract promise. Using NYOP(Name Your Own Price) to be the\ncore of dynamic procurement negotiation algorithm sets up multi-agent dynamic\nsupply chain system, to present the DSINs(Dynamic Supply Chain Information\nNetworks) by JADE, and to present the dynamic supply chain logistic simulation\nby eM-Plant. Finally, evaluating supply chain performance with supply chain\nperformance metrics (such as bullwhip, fill rate), to be the reference of\nenterprise making deciding in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4450v1"
    },
    {
        "title": "Crowd simulation influenced by agent's socio-psychological state",
        "authors": [
            "F. Cherif",
            "R. Chighoub"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  The aim our work is to create virtual humans as intelligent entities, which\nincludes approximate the maximum as possible the virtual agent animation to the\nnatural human behavior. In order to accomplish this task, our agent must be\ncapable to interact with the environment, interacting with objects and other\nagents. The virtual agent needs to act as real person, so he should be capable\nto extract semantic information from the geometric model of the world where he\nis inserted, based on his own perception, and he realizes his own decision. The\nmovement of the individuals is representing by the combination of two\napproaches of movement which are, the social force model and the based-rule\nmodel. These movements are influenced by a set of socio-psychological rules to\ngive a more realistic result.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4454v1"
    },
    {
        "title": "Facial Recognition Technology: An analysis with scope in India",
        "authors": [
            "S. B. Thorat",
            "S. K. Nayak",
            "Jyoti P Dandale"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  A facial recognition system is a computer application for automatically\nidentifying or verifying a person from a digital image or a video frame from a\nvideo source. One of the way is to do this is by comparing selected facial\nfeatures from the image and a facial database.It is typically used in security\nsystems and can be compared to other biometrics such as fingerprint or eye iris\nrecognition systems. In this paper we focus on 3-D facial recognition system\nand biometric facial recognision system. We do critics on facial recognision\nsystem giving effectiveness and weaknesses. This paper also introduces scope of\nrecognision system in India.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4263v1"
    },
    {
        "title": "A Formal Specification of Dynamic Protocols for Open Agent Systems",
        "authors": [
            "Alexander Artikis"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Multi-agent systems where the agents are developed by parties with competing\ninterests, and where there is no access to an agent's internal state, are often\nclassified as `open'. The member agents of such systems may inadvertently fail\nto, or even deliberately choose not to, conform to the system specification.\nConsequently, it is necessary to specify the normative relations that may exist\nbetween the agents, such as permission, obligation, and institutional power.\nThe specification of open agent systems of this sort is largely seen as a\ndesign-time activity. Moreover, there is no support for run-time specification\nmodification. Due to environmental, social, or other conditions, however, it is\noften required to revise the specification during the system execution. To\naddress this requirement, we present an infrastructure for `dynamic'\nspecifications, that is, specifications that may be modified at run-time by the\nagents. The infrastructure consists of well-defined procedures for proposing a\nmodification of the `rules of the game', as well as decision-making over and\nenactment of proposed modifications. We evaluate proposals for rule\nmodification by modelling a dynamic specification as a metric space, and by\nconsidering the effects of accepting a proposal on system utility. Furthermore,\nwe constrain the enactment of proposals that do not meet the evaluation\ncriteria. We employ the action language C+ to formalise dynamic specifications,\nand the `Causal Calculator' implementation of C+ to execute the specifications.\nWe illustrate our infrastructure by presenting a dynamic specification of a\nresource-sharing protocol.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4815v1"
    },
    {
        "title": "Set-Monotonicity Implies Kelly-Strategyproofness",
        "authors": [
            "Felix Brandt"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  This paper studies the strategic manipulation of set-valued social choice\nfunctions according to Kelly's preference extension, which prescribes that one\nset of alternatives is preferred to another if and only if all elements of the\nformer are preferred to all elements of the latter. It is shown that\nset-monotonicity---a new variant of Maskin-monotonicity---implies\nKelly-strategyproofness in comprehensive subdomains of the linear domain.\nInterestingly, there are a handful of appealing Condorcet extensions---such as\nthe top cycle, the minimal covering set, and the bipartisan set---that satisfy\nset-monotonicity even in the unrestricted linear domain, thereby answering\nquestions raised independently by Barber\\`a (1977) and Kelly (1977).\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4877v5"
    },
    {
        "title": "Separating Agent-Functioning and Inter-Agent Coordination by Activated\n  Modules: The DECOMAS Architecture",
        "authors": [
            "Jan Sudeikat",
            "Wolfgang Renz"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  The embedding of self-organizing inter-agent processes in distributed\nsoftware applications enables the decentralized coordination system elements,\nsolely based on concerted, localized interactions. The separation and\nencapsulation of the activities that are conceptually related to the\ncoordination, is a crucial concern for systematic development practices in\norder to prepare the reuse and systematic integration of coordination processes\nin software systems. Here, we discuss a programming model that is based on the\nexternalization of processes prescriptions and their embedding in Multi-Agent\nSystems (MAS). One fundamental design concern for a corresponding execution\nmiddleware is the minimal-invasive augmentation of the activities that affect\ncoordination. This design challenge is approached by the activation of agent\nmodules. Modules are converted to software elements that reason about and\nmodify their host agent. We discuss and formalize this extension within the\ncontext of a generic coordination architecture and exemplify the proposed\nprogramming model with the decentralized management of (web) service\ninfrastructures.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.1450v1"
    },
    {
        "title": "Soft Control on Collective Behavior of a Group of Autonomous Agents by a\n  Shill Agent",
        "authors": [
            "Jing Han",
            "Ming Li",
            "Lei Guo"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  This paper asks a new question: how can we control the collective behavior of\nself-organized multi-agent systems? We try to answer the question by proposing\na new notion called 'Soft Control', which keeps the local rule of the existing\nagents in the system. We show the feasibility of soft control by a case study.\nConsider the simple but typical distributed multi-agent model proposed by\nVicsek et al. for flocking of birds: each agent moves with the same speed but\nwith different headings which are updated using a local rule based on the\naverage of its own heading and the headings of its neighbors. Most studies of\nthis model are about the self-organized collective behavior, such as\nsynchronization of headings. We want to intervene in the collective behavior\n(headings) of the group by soft control. A specified method is to add a special\nagent, called a 'Shill', which can be controlled by us but is treated as an\nordinary agent by other agents. We construct a control law for the shill so\nthat it can synchronize the whole group to an objective heading. This control\nlaw is proved to be effective analytically and numerically. Note that soft\ncontrol is different from the approach of distributed control. It is a natural\nway to intervene in the distributed systems. It may bring out many interesting\nissues and challenges on the control of complex systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.0803v1"
    },
    {
        "title": "An early warning method for crush",
        "authors": [
            "Peter J. Harding",
            "Steve M. V. Gwynne",
            "Martyn Amos"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Fatal crush conditions occur in crowds with tragic frequency. Event\norganisers and architects are often criticised for failing to consider the\ncauses and implications of crush, but the reality is that the prediction and\nmitigation of such conditions offers a significant technical challenge. Full\ntreatment of physical force within crowd simulations is precise but\ncomputationally expensive; the more common method of human interpretation of\nresults is computationally \"cheap\" but subjective and time-consuming. In this\npaper we propose an alternative method for the analysis of crowd behaviour,\nwhich uses information theory to measure crowd disorder. We show how this\ntechnique may be easily incorporated into an existing simulation framework, and\nvalidate it against an historical event. Our results show that this method\noffers an effective and efficient route towards automatic detection of crush.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.2160v1"
    },
    {
        "title": "Sensor Scheduling for Energy-Efficient Target Tracking in Sensor\n  Networks",
        "authors": [
            "George K. Atia",
            "Venugopal V. Veeravalli",
            "Jason A. Fuemmeler"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  In this paper we study the problem of tracking an object moving randomly\nthrough a network of wireless sensors. Our objective is to devise strategies\nfor scheduling the sensors to optimize the tradeoff between tracking\nperformance and energy consumption. We cast the scheduling problem as a\nPartially Observable Markov Decision Process (POMDP), where the control actions\ncorrespond to the set of sensors to activate at each time step. Using a\nbottom-up approach, we consider different sensing, motion and cost models with\nincreasing levels of difficulty. At the first level, the sensing regions of the\ndifferent sensors do not overlap and the target is only observed within the\nsensing range of an active sensor. Then, we consider sensors with overlapping\nsensing range such that the tracking error, and hence the actions of the\ndifferent sensors, are tightly coupled. Finally, we consider scenarios wherein\nthe target locations and sensors' observations assume values on continuous\nspaces. Exact solutions are generally intractable even for the simplest models\ndue to the dimensionality of the information and action spaces. Hence, we\ndevise approximate solution techniques, and in some cases derive lower bounds\non the optimal tradeoff curves. The generated scheduling policies, albeit\nsuboptimal, often provide close-to-optimal energy-tracking tradeoffs.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.2997v1"
    },
    {
        "title": "Multi-Agent Programming Contest 2010 - The Jason-DTU Team",
        "authors": [
            "Jørgen Villadsen",
            "Niklas Skamriis Boss",
            "Andreas Schmidt Jensen",
            "Steen Vester"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  We provide a brief description of the Jason-DTU system, including the\nmethodology, the tools and the team strategy that we plan to use in the agent\ncontest.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.0145v1"
    },
    {
        "title": "Implementing Lego Agents Using Jason",
        "authors": [
            "Andreas Schmidt Jensen"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Since many of the currently available multi-agent frameworks are generally\nmostly intended for research, it can be difficult to built multi-agent systems\nusing physical robots. In this report I describe a way to combine the\nmulti-agent framework Jason, an extended version of the agent-oriented\nprogramming language AgentSpeak, with Lego robots to address this problem. By\nextending parts of the Jason reasoning cycle I show how Lego robots are able to\ncomplete tasks such as following lines on a floor and communicating to be able\nto avoid obstacles with minimal amount of coding. The final implementation is a\nfunctional extension that is able to built multi-agent systems using Lego\nagents, however there are some issues that have not been addressed. If the\nagents are highly dependent on percepts from their sensors, they are required\nto move quite slowly, because there currently is a high delay in the reasoning\ncycle, when it is combined with a robot. Overall the system is quite robust and\ncan be used to make simple Lego robots perform tasks of an advanced agent in a\nmulti-agent environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.0150v1"
    },
    {
        "title": "An Investigation of the Advantages of Organization-Centered Multi-Agent\n  Systems",
        "authors": [
            "Andreas Schmidt Jensen"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Whereas classical multi-agent systems have the agent in center, there have\nrecently been a development towards focusing more on the organization of the\nsystem. This allows the designer to focus on what the system goals are, without\nconsidering how the goals should be fulfilled. This paper investigates whether\ntaking this approach has any clear advantages to the classical way of\nimplementing multi-agent systems. The investigation is done by implementing\neach type of system in the same environment in order to realize what advantages\nand disadvantages each approach has.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.0155v1"
    },
    {
        "title": "Static and Expanding Grid Coverage with Ant Robots : Complexity Results",
        "authors": [
            "Yaniv Altshuler",
            "Alfred Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  In this paper we study the strengths and limitations of collaborative teams\nof simple agents. In particular, we discuss the efficient use of \"ant robots\"\nfor covering a connected region on the Z^{2} grid, whose area is unknown in\nadvance, and which expands at a given rate, where $n$ is the initial size of\nthe connected region.\n  We show that regardless of the algorithm used, and the robots' hardware and\nsoftware specifications, the minimal number of robots required in order for\nsuch coverage to be possible is \\Omega({\\sqrt{n}}).\n  In addition, we show that when the region expands at a sufficiently slow\nrate, a team of \\Theta(\\sqrt{n}) robots could cover it in at most O(n^{2} \\ln\nn) time.\n  This completion time can even be achieved by myopic robots, with no ability\nto directly communicate with each other, and where each robot is equipped with\na memory of size O(1) bits w.r.t the size of the region (therefore, the robots\ncannot maintain maps of the terrain, nor plan complete paths).\n  Regarding the coverage of non-expanding regions in the grid, we improve the\ncurrent best known result of O(n^{2}) by demonstrating an algorithm that\nguarantees such a coverage with completion time of O(\\frac{1}{k} n^{1.5} + n)\nin the worst case, and faster for shapes of perimeter length which is shorter\nthan O(n).\n",
        "pdf_link": "http://arxiv.org/pdf/1011.5914v1"
    },
    {
        "title": "Visibility maintenance via controlled invariance for leader-follower\n  Dubins-like vehicles",
        "authors": [
            "Fabio Morbidi",
            "Francesco Bullo",
            "Domenico Prattichizzo"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  The paper studies the visibility maintenance problem (VMP) for a\nleader-follower pair of Dubins-like vehicles with input constraints, and\nproposes an original solution based on the notion of controlled invariance. The\nnonlinear model describing the relative dynamics of the vehicles is interpreted\nas linear uncertain system, with the leader robot acting as an external\ndisturbance. The VMP is then reformulated as a linear constrained regulation\nproblem with additive disturbances (DLCRP). Positive D-invariance conditions\nfor linear uncertain systems with parametric disturbance matrix are introduced\nand used to solve the VMP when box bounds on the state, control input and\ndisturbance are considered. The proposed design procedure is shown to be easily\nadaptable to more general working scenarios. Extensive simulation results are\nprovided to illustrate the theory and show the effectiveness of our approach\n",
        "pdf_link": "http://arxiv.org/pdf/1011.6127v1"
    },
    {
        "title": "The Rule Responder eScience Infrastructure",
        "authors": [
            "Adrian Paschke",
            "Zhili Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  To a large degree information and services for chemical e-Science have become\naccessible - anytime, anywhere - but not necessarily useful. The Rule Responder\neScience middleware is about providing information consumers with rule-based\nagents to transform existing information into relevant information of practical\nconsequences, hence providing control to the end-users to express in a\ndeclarative rule-based way how to turn existing information into personally\nrelevant information and how to react or make automated decisions on top of it.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.1651v1"
    },
    {
        "title": "Emotionally Colorful Reflexive Games",
        "authors": [
            "Sergey Tarasenko"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  This study addresses the matter of reflexive control of the emotional states\nby means of Reflexive Game Theory (RGT). It is shown how to build a bridge\nbetween RGT and emotions. For this purpose the Pleasure-Arousal-Dominance (PAD)\nmodel is adopted. The major advantages of RGT are its ability to predict human\nbehavior and unfold the entire spectra of reflexion in the human mind. On the\nother hand, PAD provides ultimate approach to model emotions. It is illustrated\nthat emotions are reflexive processes and, consequently, RGT fused with PAD\nmodel is natural solution to model emotional interactions between people. The\nfusion of RGT and PAD, called Emotional Reflexive Games (ERG), inherits the key\nfeatures of both components. Using ERG, we show how reflexive control can be\nsuccessfully applied to model human emotional states. Up to date, EGR is a\nunique methodology capable of modeling human reflexive processes and emotional\naspects simultaneously.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.0820v1"
    },
    {
        "title": "Symmetry in behavior of complex social systems - discussion of models of\n  crowd evacuation organized in agreement with symmetry conditions",
        "authors": [
            "W. Sikora",
            "J. Malinowski"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  The evacuation of football stadium scenarios are discussed as model realizing\nordered states, described as movements of individuals according to fields of\ndisplacements, calculated correspondingly to given scenario. The symmetry of\nthe evacuation space is taken into account in calculation of displacements\nfield - the displacements related to every point of this space are presented in\nthe coordinate frame in the best way adapted to given symmetry space group,\nwhich the set of basic vectors of irreducible representation of given group is.\nThe speeds of individuals at every point in the presented model have the same\nquantity. As the results the times of evacuation and average forces acting on\nindividuals during the evacuation are given. Both parameters are compared with\nthe same parameters got without symmetry considerations. They are calculated in\nthe simulation procedure. The new program (using modified Helbing model) has\nbeen elaborated and presented in this work for realization the simulation tasks\nthe.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.1261v2"
    },
    {
        "title": "Knowledge Management System Design using Extended Gaia",
        "authors": [
            "Pooja Jain",
            "Deepak Dahiya"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  An efficient Learning resource centre can be achieved with the help of a\nnetwork of collaborating, coordinating and communicating software agents.\nAgent-oriented techniques represent an exciting new means of analysing,\ndesigning and building complex software systems. The designing of the\ninteracting agents is done with the help of Gaia, extended for the multiagent\nsystems. Gaia is a methodology for agent-oriented analysis and design proposed\nby M. Wooldridge [9].\n",
        "pdf_link": "http://arxiv.org/pdf/1102.2114v2"
    },
    {
        "title": "Reasoning about Social Choice Functions",
        "authors": [
            "Nicolas Troquard",
            "Wiebe van der Hoek",
            "Michael Wooldridge"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  We introduce a logic specifically designed to support reasoning about social\nchoice functions. The logic includes operators to capture strategic ability,\nand operators to capture agent preferences. We establish a correspondence\nbetween formulae in the logic and properties of social choice functions, and\nshow that the logic is expressively complete with respect to social choice\nfunctions, i.e., that every social choice function can be characterised as a\nformula of the logic. We prove that the logic is decidable, and give a complete\naxiomatization. To demonstrate the value of the logic, we show in particular\nhow it can be applied to the problem of determining whether a social choice\nfunction is strategy-proof.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.3341v1"
    },
    {
        "title": "Context Aware Multisensor Image Fusion for Military Sensor Networks\n  using Multi Agent System",
        "authors": [
            "Ashok V Sutagundar",
            "Sunilkumar S Manvi"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  This paper proposes a Context Aware Agent based Military Sensor Network\n(CAMSN) to form an improved infrastructure for multi-sensor image fusion. It\nconsiders contexts driven by a node and sink. The contexts such as general and\ncritical object detection are node driven where as sensing time (such as day or\nnight) is sink driven. The agencies used in the scheme are categorized as node\nand sink agency. Each agency employs a set of static and mobile agents to\nperform dedicated tasks. Node agency performs context sensing and context\ninterpretation based on the sensed image and sensing time. Node agency\ncomprises of node manager agent, context agent and node blackboard (NBB).\nContext agent gathers the context from the target and updates the NBB, Node\nmanager agent interprets the context and passes the context information to sink\nnode by using flooding mechanism. Sink agency mainly comprises of sink manager\nagent, fusing agent, and sink black board. A context at the sensor node\ntriggers the fusion process at the sink. Based on the context, sink manager\nagent triggers the fusing agent. Fusing agent roams around the network, visits\nactive sensor node, fuses the relevant images and sends the fused image to\nsink. The fusing agent uses wavelet transform for fusion. The scheme is\nsimulated for testing its operation effectiveness in terms of fusion time, mean\nsquare error, throughput, dropping rate, bandwidth requirement, node battery\nusage and agent overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.1279v1"
    },
    {
        "title": "Tight Bounds for Black Hole Search with Scattered Agents in Synchronous\n  Rings",
        "authors": [
            "Jérémie Chalopin",
            "Shantanu Das",
            "Arnaud Labourel",
            "Euripides Markou"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  We study the problem of locating a particularly dangerous node, the so-called\nblack hole in a synchronous anonymous ring network with mobile agents. A black\nhole is a harmful stationary process residing in a node of the network and\ndestroying destroys all mobile agents visiting that node without leaving any\ntrace. We consider the more challenging scenario when the agents are identical\nand initially scattered within the network. Moreover, we solve the problem with\nagents that have constant-sized memory and carry a constant number of identical\ntokens, which can be placed at nodes of the network. In contrast, the only\nknown solutions for the case of scattered agents searching for a black hole,\nuse stronger models where the agents have non-constant memory, can write\nmessages in whiteboards located at nodes or are allowed to mark both the edges\nand nodes of the network with tokens. This paper solves the problem for ring\nnetworks containing a single black hole. We are interested in the minimum\nresources (number of agents and tokens) necessary for locating all links\nincident to the black hole. We present deterministic algorithms for ring\ntopologies and provide matching lower and upper bounds for the number of agents\nand the number of tokens required for deterministic solutions to the black hole\nsearch problem, in oriented or unoriented rings, using movable or unmovable\ntokens.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.5076v1"
    },
    {
        "title": "Complex Adaptive Digital EcoSystems",
        "authors": [
            "Gerard Briscoe"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  We investigate an abstract conceptualisation of DigitalEcosystems from a\ncomputer science perspective. We then provide a conceptual framework for the\ncross pollination of ideas, concepts and understanding between different\nclasses of ecosystems through the universally applicable principles of Complex\nAdaptive Systems (CAS) modelling. A framework to assist the cross-disciplinary\ncollaboration of research into Digital Ecosystems, including Digital\nBusinessEcosystems (DBEs) and Digital Knowledge Ecosystems (DKEs). So, we have\ndefined the key steps towards a theoretical framework for Digital Ecosystems,\nthat is compatible with the diverse theoretical views prevalent. Therefore, a\ntheoretical edifice that can unify the diverse efforts within Digital\nEcosystems research.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.1564v1"
    },
    {
        "title": "An Agent-based Strategy for Deploying Analysis Models into Specification\n  and Design for Distributed APS Systems",
        "authors": [
            "Luis Antonio de Santa-Eulalia",
            "Sophie D'Amours",
            "Jean-Marc Frayret"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Despite the extensive use of the agent technology in the Supply Chain\nManagement field, its integration with Advanced Planning and Scheduling (APS)\ntools still represents a promising field with several open research questions.\nSpecifically, the literature falls short in providing an integrated framework\nto analyze, specify, design and implement simulation experiments covering the\nwhole simulation cycle. Thus, this paper proposes an agent-based strategy to\nconvert the 'analysis' models into 'specification' and 'design' models\ncombining two existing methodologies proposed in the literature. The first one\nis a recent and unique approach dedicated to the 'analysis' of agent-based APS\nsystems. The second one is a well-established methodological framework to\n'specify' and 'design' agent-based supply chain systems. The proposed\nconversion strategy is original and is the first one allowing simulation\nanalysts to integrate the whole simulation development process in the domain of\ndistributed APS.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.3225v1"
    },
    {
        "title": "Autonomous Traffic Control System Using Agent Based Technology",
        "authors": [
            "Venkatesh. M",
            "K. Kumar",
            "Srinivas. V"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  The way of analyzing, designing and building of real-time projects has been\nchanged due to the rapid growth of internet, mobile technologies and\nintelligent applications. Most of these applications are intelligent, tiny and\ndistributed components called as agent. Agent works like it takes the input\nfrom numerous real-time sources and gives back the real-time response. In this\npaper how these agents can be implemented in vehicle traffic management\nespecially in large cities and identifying various challenges when there is a\nrapid growth of population and vehicles. In this paper our proposal gives a\nsolution for using autonomous or agent based technology. These autonomous or\nintelligent agents have the capability to observe, act and learn from their\npast experience. This system uses the knowledge flow of precedent signal or\ndata to identify the incoming flow of forthcoming signal. Our architecture\ninvolves the video analysis and exploration using some Intelligence learning\nalgorithm to estimate and identify the flow of traffic.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.3674v2"
    },
    {
        "title": "Model of skyscraper evacuation with the use of space symmetry and fluid\n  dynamic approximation",
        "authors": [
            "W. Sikora",
            "J. Malinowski",
            "A. Kupczak"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  The simulation of evacuation of pedestrians from skyscraper is a situation\nwhere the symmetry analysis method and equations of fluid dynamics finds to be\nvery useful. When applied, they strongly reduce the number of free parameters\nused in simulations and in such a way speed up the calculations and make them\neasier to manage by the programmer and what is even more important, they can\ngive a fresh insight into a problem of evacuation and help with incorporation\nof \"Ambient Intelligent Devices\" into future real buildings. We have analyzed\nvarious, simplified, cases of evacuation from skyscraper by employing improved\n\"Social Force Model\". For each of them we obtained the average force acting on\nthe pedestrian as a function of the evacuation time. The results clearly show\nthat both methods mentioned above, can be successfully implemented in the\nsimulation process and return with satisfactory conclusions.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.3702v1"
    },
    {
        "title": "Multi-Agent Programming Contest 2011 - The Python-DTU Team",
        "authors": [
            "Jørgen Villadsen",
            "Mikko Berggren Ettienne",
            "Steen Vester"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  We provide a brief description of the Python-DTU system, including the\noverall design, the tools and the algorithms that we plan to use in the agent\ncontest.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.0105v1"
    },
    {
        "title": "Agent Development Toolkits",
        "authors": [
            "Aarti Singh",
            "Dimple Juneja",
            "A. K. Sharma"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Development of agents as well as their wide usage requires good underlying\ninfrastructure. Literature indicates scarcity of agent development tools in\ninitial years of research which limited the exploitation of this beneficial\ntechnology. However, today a wide variety of tools are available, for\ndeveloping robust infrastructure. This technical note provides a deep overview\nof such tools and contrasts features provided by them.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.5930v1"
    },
    {
        "title": "Autonomic Management for Multi-agent Systems",
        "authors": [
            "Nadir K. Salih",
            "Tianyi Zang",
            "PG. K. Viju",
            "Abdelmotalib A. Mohamed"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Autonomic computing is a computing system that can manage itself by\nself-configuration, self-healing, self-optimizing and self-protection.\nResearchers have been emphasizing the strong role that multi agent systems can\nplay progressively towards the design and implementation of complex autonomic\nsystems. The important of autonomic computing is to create computing systems\ncapable of managing themselves to a far greater extent than they do today. With\nthe nature of autonomy, reactivity, sociality and pro-activity, software agents\nare promising to make autonomic computing system a reality. This paper mixed\nmulti-agent system with autonomic feature that completely hides its complexity\nfrom users/services. Mentioned Java Application Development Framework as\nplatform example of this environment, could applied to web services as front\nend to users. With multi agent support it also provides adaptability,\nintelligence, collaboration, goal oriented interactions, flexibility, mobility\nand persistence in software systems\n",
        "pdf_link": "http://arxiv.org/pdf/1111.6771v1"
    },
    {
        "title": "Reaching an Optimal Consensus: Dynamical Systems that Compute\n  Intersections of Convex Sets",
        "authors": [
            "Guodong Shi",
            "Karl Henrik Johansson",
            "Yiguang Hong"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  In this paper, multi-agent systems minimizing a sum of objective functions,\nwhere each component is only known to a particular node, is considered for\ncontinuous-time dynamics with time-varying interconnection topologies. Assuming\nthat each node can observe a convex solution set of its optimization component,\nand the intersection of all such sets is nonempty, the considered optimization\nproblem is converted to an intersection computation problem. By a simple\ndistributed control rule, the considered multi-agent system with\ncontinuous-time dynamics achieves not only a consensus, but also an optimal\nagreement within the optimal solution set of the overall optimization\nobjective. Directed and bidirectional communications are studied, respectively,\nand connectivity conditions are given to ensure a global optimal consensus. In\nthis way, the corresponding intersection computation problem is solved by the\nproposed decentralized continuous-time algorithm. We establish several\nimportant properties of the distance functions with respect to the global\noptimal solution set and a class of invariant sets with the help of convex and\nnon-smooth analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.1333v2"
    },
    {
        "title": "Connectivity and Set Tracking of Multi-agent Systems Guided by Multiple\n  Moving Leaders",
        "authors": [
            "Guodong Shi",
            "Yiguang Hong",
            "K. H. Johansson"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  In this paper, we investigate distributed multi-agent tracking of a convex\nset specified by multiple moving leaders with unmeasurable velocities. Various\njointly-connected interaction topologies of the follower agents with\nuncertainties are considered in the study of set tracking. Based on the\nconnectivity of the time-varying multi-agent system, necessary and sufficient\nconditions are obtained for set input-to-state stability and set integral\ninput-to-state stability for a nonlinear neighbor-based coordination rule with\nswitching directed topologies. Conditions for asymptotic set tracking are also\nproposed with respect to the polytope spanned by the leaders.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.1335v1"
    },
    {
        "title": "The Role of Persistent Graphs in the Agreement Seeking of Social\n  Networks",
        "authors": [
            "Guodong Shi",
            "Karl Henrik Johansson"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  This paper investigates the role persistent arcs play for a social network to\nreach a global belief agreement under discrete-time or continuous-time\nevolution. Each (directed) arc in the underlying communication graph is assumed\nto be associated with a time-dependent weight function which describes the\nstrength of the information flow from one node to another. An arc is said to be\npersistent if its weight function has infinite $\\mathscr{L}_1$ or $\\ell_1$ norm\nfor continuous-time or discrete-time belief evolutions, respectively. The graph\nthat consists of all persistent arcs is called the persistent graph of the\nunderlying network. Three necessary and sufficient conditions on agreement or\n$\\epsilon$-agreement are established, by which we prove that the persistent\ngraph fully determines the convergence to a common opinion in social networks.\nIt is shown how the convergence rates explicitly depend on the diameter of the\npersistent graph. The results adds to the understanding of the fundamentals\nbehind global agreements, as it is only persistent arcs that contribute to the\nconvergence.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.1338v2"
    },
    {
        "title": "Towards an intelligence based conceptual framework for e-maintenance",
        "authors": [
            "Abdessamad Mouzoune"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Since the time when concept of e-maintenance was introduced, most of the\nworks insisted on the relevance of the underlying Information and Communication\nTechnologies infrastructure. Through a review of current e-maintenance\nconceptual approaches and realizations, this paper aims to reconsider the\npredominance of ICT within e-maintenance projects and literature. The review\nbrings to light the importance of intelligence as a fundamental dimension of\ne-maintenance that is to be led in a holistic predefined manner rather than\nisolated efforts within ICT driven approaches. As a contribution towards an\nintelligence based e-maintenance conceptual framework, a proposal is outlined\nin this paper to model e-maintenance system as an intelligent system. The\nproposed frame is based on CogAff architecture for intelligent agents. Within\nthe proposed frame, more importance was reserved to the environment that the\nsystem is to be continuously aware of: Plant Environment, Internal and External\nEnterprise Environment and Human Environment. In addition to the abilities\nrequired for internal coherent behavior of the system, requirements for\nmaintenance activities support are also mapped within the same frame according\nto corresponding levels of management. A case study was detailed in this paper\nsustaining the applicability of the proposal in relation to the classification\nof existing e-maintenance platforms. However, more work is needed to enhance\nexhaustiveness of the frame to serve as a comparison tool of existing\ne-maintenance systems. At the conceptual level, our future work is to use the\nproposed frame in an e-maintenance project.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.0714v1"
    },
    {
        "title": "A Multi-Agent Prediction Market based on Partially Observable Stochastic\n  Game",
        "authors": [
            "Janyl Jumadinova",
            "Prithviraj Dasgupta"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  We present a novel, game theoretic representation of a multi-agent prediction\nmarket using a partially observable stochastic game with information (POSGI).\nWe then describe a correlated equilibrium (CE)-based solution strategy for this\ngame which enables each agent to dynamically calculate the prices at which it\nshould trade a security in the prediction market. We have extended our results\nto risk averse traders and shown that a Pareto optimal correlated equilibrium\nstrategy can be used to incentively truthful revelations from risk averse\nagents. Simulation results comparing our CE strategy with five other strategies\ncommonly used in similar markets, with both risk neutral and risk averse\nagents, show that the CE strategy improves price predictions and provides\nhigher utilities to the agents as compared to other existing strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6035v1"
    },
    {
        "title": "Multi-level agent-based modeling with the Influence Reaction principle",
        "authors": [
            "Gildas Morvan",
            "Daniel Jolly"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This paper deals with the specification and the implementation of multi-level\nagent-based models, using a formal model, IRM4MLS (an Influence Reaction Model\nfor Multi-Level Simulation), based on the Influence Reaction principle.\nProposed examples illustrate forms of top-down control in (multi-level)\nmulti-agent based-simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.0634v1"
    },
    {
        "title": "Coupling Clinical Decision Support System with Computerized Prescriber\n  Order Entry and their Dynamic Plugging in the Medical Workflow System",
        "authors": [
            "Lotfi Bouzguenda",
            "Manel Turki"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This work deals with coupling Clinical Decision Support System (CDSS) with\nComputerized Prescriber Order Entry (CPOE) and their dynamic plugging in the\nmedical Workflow Management System (WfMS). First, in this paper we argue some\nexisting CDSS representative of the state of the art in order to emphasize\ntheir inability to deal with coupling with CPOE and medical WfMS. The\nmulti-agent technology is at the basis of our proposition since (i) it provides\nnatural abstractions to deal with distribution, heterogeneity and autonomy\nwhich are inherent to the previous systems (CDSS, CPOE and medical WfMS), and\n(ii) it introduces powerful concepts such as organizations, goals and roles\nuseful to describe in details the coordination of the different components\ninvolved in these systems. In this paper, we also propose a Multi-Agent System\n(MAS) to support the coupling CDSS with CPOE. Finally, we show how we integrate\nthe proposed MAS in the medical workflow management system which is also based\non collaborating agents\n",
        "pdf_link": "http://arxiv.org/pdf/1204.4427v1"
    },
    {
        "title": "Proceedings Third Workshop on Formal Aspects of Virtual Organisations",
        "authors": [
            "Jeremy Bryans",
            "John Fitzgerald"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This volume contains the proceedings of the 3rd International Workshop on\nFormal Aspects of Virtual Organisations (FAVO 2011). The workshop was held in\nSao Paulo, Brazil on October 18th, 2011 as a satellite event to the 12th IFIP\nWorking Conference on Virtual Enterprises (PRO-VE'11). The FAVO workshop aims\nto provide a forum for researchers interested in the application of formal\ntechniques in the design and analysis of Virtual Organisations.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.5796v1"
    },
    {
        "title": "Modelling spatial patterns of economic activity in the Netherlands",
        "authors": [
            "Jung-Hun Yang",
            "Dick Ettema",
            "Koen Frenken",
            "Frank Van Oort",
            "Evert-Jan Visser"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Understanding how spatial configurations of economic activity emerge is\nimportant when formulating spatial planning and economic policy. Not only\nmicro-simulation and agent-based model such as UrbanSim, ILUMAS and SIMFIRMS,\nbut also Simon's model of hierarchical concentration have widely applied, for\nthis purpose. These models, however, have limitations with respect to\nsimulating structural changes in spatial economic systems and the impact of\nproximity. The present paper proposes a model of firm development that is based\non behavioural rules such as growth, closure, spin-off and relocation. An\nimportant aspect of the model is that locational preferences of firms are based\non agglomeration advantages, accessibility of markets and congestion, allowing\nfor a proper description of concentration and deconcentration tendencies. By\ncomparing the outcomes of the proposed model with real world data, we will\ncalibrate the parameters and assess how well the model predicts existing\nspatial configurations and decide. The model is implemented as an agent-based\nsimulation model describing firm development in the Netherlands in 21\nindustrial sectors from 1950 to 2004.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.0110v1"
    },
    {
        "title": "Multi-level agent-based modeling - A literature survey",
        "authors": [
            "Gildas Morvan"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  During last decade, multi-level agent-based modeling has received significant\nand dramatically increasing interest. In this article we present a\ncomprehensive and structured review of literature on the subject. We present\nthe main theoretical contributions and application domains of this concept,\nwith an emphasis on social, flow, biological and biomedical models.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.0561v7"
    },
    {
        "title": "Engineering hierarchical complex systems: an agent-based approach. The\n  case of flexible manufacturing systems",
        "authors": [
            "Gildas Morvan",
            "Daniel Dupont",
            "Jean-Baptiste Soyez",
            "Rochdi Merzouki"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This article introduces a formal model to specify, model and validate\nhierarchical complex systems described at different levels of analysis. It\nrelies on concepts that have been developed in the multi-agent-based simulation\n(MABS) literature: level, influence and reaction. One application of such model\nis the specification of hierarchical complex systems, in which decisional\ncapacities are dynamically adapted at each level with respect to the\nemergences/constraints paradigm. In the conclusion, we discuss the main\nperspective of this work: the definition of a generic meta-model for holonic\nmulti-agent systems (HMAS).\n",
        "pdf_link": "http://arxiv.org/pdf/1205.7025v1"
    },
    {
        "title": "MAINWAVE: Multi Agents and Issues Negotiation for Web using Alliance\n  Virtual Engine",
        "authors": [
            "Debajyoti Mukhopadhyay",
            "Saurabh Deochake",
            "Shashank Kanth",
            "Subhadip Chakraborty",
            "Suresh Sarode"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This paper showcases an improved architecture for a complete negotiation\nsystem that permits multi party multi issue negotiation. The concepts of\nmultithreading and concurrency has been utilized to perform parallel execution.\nThe negotiation history has been implemented that stores all the records of the\nmessages exchanged for every successful and rejected negotiation process and\nimplements the concepts of artificial intelligence in determination of proper\nweights for a valid negotiation mechanism. The issues are arranged in a\nhierarchical pattern so as to simplify the representation and priorities are\nassigned to each issue, which amounts to its relative importance. There is\nrefinement of utilities by consideration of the non-functional attributes. So\nas to avoid overloading of the system, a maximum number of parties are allowed\nto participate in the entire mechanism and if more parties arrive, they're put\ninto a waiting queue in accordance to certain criteria such as the first come\nfirst serve or the relative priorities. This helps in fault tolerance. It also\nsupports the formation of alliances among the various parties while carrying\nout a negotiation.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.5884v1"
    },
    {
        "title": "MITRA: A Meta-Model for Information Flow in Trust and Reputation\n  Architectures",
        "authors": [
            "Eugen Staab",
            "Guillaume Muller"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  We propose MITRA, a meta-model for the information flow in (computational)\ntrust and reputation architectures. On an abstract level, MITRA describes the\ninformation flow as it is inherent in prominent trust and reputation models\nfrom the literature. We use MITRA to provide a structured comparison of these\nmodels. This makes it possible to get a clear overview of the complex research\narea. Furthermore, by doing so, we identify interesting new approaches for\ntrust and reputation modeling that so far have not been investigated.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.0405v1"
    },
    {
        "title": "NAAS: Negotiation Automation Architecture with Buyer's Behavior Pattern\n  Prediction Component",
        "authors": [
            "Debajyoti Mukhopadhyay",
            "Sheetal Vij",
            "Suyog Tasare"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  In this era of \"Services\" everywhere, with the explosive growth of E-Commerce\nand B2B transactions, there is a pressing need for the development of\nintelligent negotiation systems which consists of feasible architecture, a\nreliable framework and flexible multi agent based protocols developed in\nspecialized negotiation languages with complete semantics and support for\nmessage passing between the buyers and sellers. This is possible using web\nservices on the internet. The key issue is negotiation and its automation. In\nthis paper we review the classical negotiation methods and some of the existing\narchitectures and frameworks. We are proposing here a new combinatory framework\nand architecture, NAAS. The key feature in this framework is a component for\nprediction or probabilistic behavior pattern recognition of a buyer, along with\nthe other classical approaches of negotiation frameworks and architectures.\nNegotiation is practically very complex activity to automate without human\nintervention so in the future we also intend to develop a new protocol which\nwill facilitate automation of all the types of negotiation strategies like\nbargaining, bidding, auctions, under our NAAS framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.2235v1"
    },
    {
        "title": "Multi-Agent Programming Contest 2012 - The Python-DTU Team",
        "authors": [
            "Jørgen Villadsen",
            "Andreas Schmidt Jensen",
            "Mikko Berggren Ettienne",
            "Steen Vester",
            "Kenneth Balsiger Andersen",
            "Andreas Frøsig"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  We provide a brief description of the Python-DTU system, including the\noverall design, the tools and the algorithms that we plan to use in the agent\ncontest.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.0437v1"
    },
    {
        "title": "Distributed Formation of Balanced and Bistochastic Weighted Diagraphs in\n  Multi-Agent Systems",
        "authors": [
            "Themistoklis Charalambous",
            "Christoforos N. Hadjicostis"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Consensus strategies find a variety of applications in distributed\ncoordination and decision making in multi-agent systems. In particular, average\nconsensus plays a key role in a number of applications and is closely\nassociated with two classes of digraphs, weight-balanced (for continuous-time\nsystems) and bistochastic (for discrete-time systems). A weighted digraph is\ncalled balanced if, for each node, the sum of the weights of the edges outgoing\nfrom that node is equal to the sum of the weights of the edges incoming to that\nnode. In addition, a weight-balanced digraph is bistochastic if all weights are\nnonnegative and, for each node, the sum of weights of edges incoming to that\nnode and the sum of the weights of edges out-going from that node is unity;\nthis implies that the corresponding weight matrix is column and row stochastic\n(i.e., doubly stochastic). We propose two distributed algorithms: one solves\nthe weight-balance problem and the other solves the bistochastic matrix\nformation problem for a distributed system whose components (nodes) can\nexchange information via interconnection links (edges) that form an arbitrary,\npossibly directed, strongly connected communication topology (digraph). Both\ndistributed algorithms achieve their goals asymptotically and operate\niteratively by having each node adapt the (nonnegative) weights on its outgoing\nedges based on the weights of its incoming links (i.e., based on purely local\ninformation). We also provide examples to illustrate the operation,\nperformance, and potential advantages of the proposed algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.4383v1"
    },
    {
        "title": "Modélisation multi-niveaux dans AA4MM",
        "authors": [
            "Benjamin Camus",
            "Julien Siebert",
            "Christine Bourjot",
            "Vincent Chevrier"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  In this article, we propose to represent a multi-level phenomenon as a set of\ninteracting models. This perspective makes the levels of representation and\ntheir relationships explicit. To deal with coherence, causality and\ncoordination issues between models, we rely on AA4MM, a metamodel dedicated to\nsuch a representation. We illustrate our proposal and we show the interest of\nour approach on a flocking phenomenon.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.5936v1"
    },
    {
        "title": "Sensor networks security based on sensitive robots agents. A conceptual\n  model",
        "authors": [
            "Camelia-M. Pintea",
            "Petrica C. Pop"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Multi-agent systems are currently applied to solve complex problems. The\nsecurity of networks is an eloquent example of a complex and difficult problem.\nA new model-concept Hybrid Sensitive Robot Metaheuristic for Intrusion\nDetection is introduced in the current paper. The proposed technique could be\nused with machine learning based intrusion detection techniques. The new model\nuses the reaction of virtual sensitive robots to different stigmergic variables\nin order to keep the tracks of the intruders when securing a sensor network.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.7422v1"
    },
    {
        "title": "Embedding agents in business applications using enterprise integration\n  patterns",
        "authors": [
            "Stephen Cranefield",
            "Surangika Ranathunga"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This paper addresses the issue of integrating agents with a variety of\nexternal resources and services, as found in enterprise computing environments.\nWe propose an approach for interfacing agents and existing message routing and\nmediation engines based on the endpoint concept from the enterprise integration\npatterns of Hohpe and Woolf. A design for agent endpoints is presented, and an\narchitecture for connecting the Jason agent platform to the Apache Camel\nenterprise integration framework using this type of endpoint is described. The\napproach is illustrated by means of a business process use case, and a number\nof Camel routes are presented. These demonstrate the benefits of interfacing\nagents to external services via a specialised message routing tool that\nsupports enterprise integration patterns.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.1937v1"
    },
    {
        "title": "Using Serious Games to Train Evacuation Behaviour",
        "authors": [
            "João Ribeiro",
            "João Emílio Almeida",
            "Rosaldo J. F. Rossetti",
            "António Coelho",
            "António Leça Coelho"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Emergency evacuation plans and evacuation drills are mandatory in public\nbuildings in many countries. Their importance is considerable when it comes to\nguarantee safety and protection during a crisis. However, sometimes\ndiscrepancies arise between the goals of the plan and its outcomes, because\npeople find it hard to take them very seriously, or due to the financial and\ntime resources required. Serious games are a possible solution to tackle this\nproblem. They have been successfully applied in different areas such as health\ncare and education, since they can simulate an environment/task quite\naccurately, making them a practical alternative to real-life simulations. This\npaper presents a serious game developed using Unity3D to recreate a virtual\nfire evacuation training tool. The prototype application was deployed which\nallowed the validation by user testing. A sample of 30 individuals tested the\nevacuating scenario, having to leave the building during a fire in the shortest\ntime possible. Results have shown that users effectively end up learning some\nevacuation procedures from the activity, even if only to look for emergency\nsigns indicating the best evacuation paths. It was also evidenced that users\nwith higher video game experience had a significantly better performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.3828v1"
    },
    {
        "title": "Crowd Simulation Modeling Applied to Emergency and Evacuation\n  Simulations using Multi-Agent Systems",
        "authors": [
            "João E. Almeida",
            "Rosaldo J. F. Rosseti",
            "António Leça Coelho"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  In recent years crowd modeling has become increasingly important both in the\ncomputer games industry and in emergency simulation. This paper discusses some\naspects of what has been accomplished in this field, from social sciences to\nthe computer implementation of modeling and simulation. Problem overview is\ndescribed including some of the most common techniques used. Multi-Agent\nSystems is stated as the preferred approach for emergency evacuation\nsimulations. A framework is proposed based on the work of Fangqin and Aizhu\nwith extensions to include some BDI aspects. Future work includes expansion of\nthe model's features and implementation of a prototype for validation of the\npropose methodology.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4692v1"
    },
    {
        "title": "NetLogo Implementation of an Evacuation Scenario",
        "authors": [
            "João Emílio Almeida",
            "Zafeiris Kokkinogenis",
            "Rosaldo J. F. Rossetti"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  The problem of evacuating crowded closed spaces, such as discotheques, public\nexhibition pavilions or concert houses, has become increasingly important and\ngained attention both from practitioners and from public authorities. A\nsimulation implementation using NetLogo, an agent-based simulation framework\nthat permits the quickly creation of prototypes, is presented. Our aim is to\nprove that this model developed using NetLogo, albeit simple can be expanded\nand adapted for fire safety experts test various scenarios and validate the\noutcome of their design. Some preliminary experiments are carried out, whose\nresults are presented, validated and discussed so as to illustrate their\nefficiency. Finally, we draw some conclusions and point out ways in which this\nwork can be further extended.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4695v1"
    },
    {
        "title": "Agent-based environment for knowledge integration",
        "authors": [
            "Anna Zygmunt",
            "Jarosław Koźlak",
            "Leszek Siwik"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Representing knowledge with the use of ontology description languages offers\nseveral advantages arising from knowledge reusability, possibilities of\ncarrying out reasoning processes and the use of existing concepts of knowledge\nintegration. In this work we are going to present an environment for the\nintegration of knowledge expressed in such a way. Guaranteeing knowledge\nintegration is an important element during the development of the Semantic Web.\nThanks to this, it is possible to obtain access to services which offer\nknowledge contained in various distributed databases associated with\nsemantically described web portals. We will present the advantages of the\nmulti-agent approach while solving this problem. Then, we will describe an\nexample of its application in systems supporting company management knowledge\nin the process of constructing supply-chains.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.6106v1"
    },
    {
        "title": "Evaluating Reputation Systems for Agent Mediated e-Commerce",
        "authors": [
            "Vibha Gaur",
            "Neeraj Kumar Sharma",
            "Punam Bedi"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Agent mediated e-commerce involves buying and selling on Internet through\nsoftware agents. The success of an agent mediated e-commerce system lies in the\nunderlying reputation management system which is used to improve the quality of\nservices in e-market environment. A reputation system encourages the honest\nbehaviour of seller agents and discourages the malicious behaviour of dishonest\nseller agents in the e-market where actual traders never meet each other. This\npaper evaluates various reputation systems for assigning reputation rating to\nsoftware agents acting on behalf of buyers and sellers in e-market. These\nmodels are analysed on the basis of a number of features viz. reputation\ncomputation and their defence mechanisms against different attacks. To address\nthe problems of traditional reputation systems which are relatively static in\nnature, this paper identifies characteristics of a dynamic reputation framework\nwhich ensures judicious use of information sharing for inter-agent cooperation\nand also associates the reputation of an agent with the value of a transaction\nso that the market approaches an equilibrium state and dishonest agents are\nweeded out of the market.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.7377v1"
    },
    {
        "title": "Designing Electronic Markets for Defeasible-based Contractual Agents",
        "authors": [
            "Adrian Groza"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  The design of punishment policies applied to specific domains linking agents\nactions to material penalties is an open research issue. The proposed framework\napplies principles of contract law to set penalties: expectation damages,\nopportunity cost, reliance damages, and party design remedies. In order to\ndecide which remedy provides maximum welfare within an electronic market, a\nsimulation environment called DEMCA (Designing Electronic Markets for\nContractual Agents) was developed. Knowledge representation and the reasoning\ncapabilities of the agents are based on an extended version of temporal\ndefeasible logic.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5545v1"
    },
    {
        "title": "Assessment of Path Reservation in Distributed Real-Time Vehicle Guidance",
        "authors": [
            "Sebastian Senge"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  In this paper we assess the impact of path reservation as an additional\nfeature in our distributed real-time vehicle guidance protocol BeeJamA. Through\nour microscopic simulations we show that na\\\"{\\i}ve reservation of links\nwithout any further measurements is only an improvement in case of complete\nmarket penetration, otherwise it even reduces the performance of our approach\nbased on real-time link loads. Moreover, we modified the reservation process to\nincorporate current travel times and show that this improves the results in our\nsimulations when at least 40% market penetration is possible.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.6360v1"
    },
    {
        "title": "Artificial Ant Species on Solving Optimization Problems",
        "authors": [
            "Camelia-M. Pintea"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  During the last years several ant-based techniques were involved to solve\nhard and complex optimization problems. The current paper is a short study\nabout the influence of artificial ant species in solving optimization problems.\nThere are studied the artificial Pharaoh Ants, Lasius Niger and also artificial\nants with no special specificity used commonly in Ant Colony Optimization.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.1881v1"
    },
    {
        "title": "Multi-agent Systems with Compasses",
        "authors": [
            "Ziyang Meng",
            "Guodong Shi",
            "Karl Henrik Johansson"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This paper investigates agreement protocols over cooperative and\ncooperative--antagonistic multi-agent networks with coupled continuous-time\nnonlinear dynamics. To guarantee convergence for such systems, it is common in\nthe literature to assume that the vector field of each agent is pointing inside\nthe convex hull formed by the states of the agent and its neighbors, given that\nthe relative states between each agent and its neighbors are available. This\nconvexity condition is relaxed in this paper, as we show that it is enough that\nthe vector field belongs to a strict tangent cone based on a local supporting\nhyperrectangle. The new condition has the natural physical interpretation of\nrequiring shared reference directions in addition to the available local\nrelative states. Such shared reference directions can be further interpreted as\nif each agent holds a magnetic compass indicating the orientations of a global\nframe. It is proven that the cooperative multi-agent system achieves\nexponential state agreement if and only if the time-varying interaction graph\nis uniformly jointly quasi-strongly connected. Cooperative--antagonistic\nmulti-agent systems are also considered. For these systems, the relation has a\nnegative sign for arcs corresponding to antagonistic interactions. State\nagreement may not be achieved, but instead it is shown that all the agents'\nstates asymptotically converge, and their limits agree componentwise in\nabsolute values if and in general only if the time-varying interaction graph is\nuniformly jointly strongly connected.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.0813v3"
    },
    {
        "title": "Alert-BDI: BDI Model with Adaptive Alertness through Situational\n  Awareness",
        "authors": [
            "Manu S Hegde",
            "Sanjay Singh"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  In this paper, we address the problems faced by a group of agents that\npossess situational awareness, but lack a security mechanism, by the\nintroduction of a adaptive risk management system. The Belief-Desire-Intention\n(BDI) architecture lacks a framework that would facilitate an adaptive risk\nmanagement system that uses the situational awareness of the agents. We extend\nthe BDI architecture with the concept of adaptive alertness. Agents can modify\ntheir level of alertness by monitoring the risks faced by them and by their\npeers. Alert-BDI enables the agents to detect and assess the risks faced by\nthem in an efficient manner, thereby increasing operational efficiency and\nresistance against attacks.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.3874v1"
    },
    {
        "title": "Effects of Crowding Perception on Self-organized Pedestrian Flows Using\n  Adaptive Agent-based Model",
        "authors": [
            "Qi Xu",
            "Baohua Mao",
            "Xujie Feng",
            "Jia Feng"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Pedestrian behavior has much more complicated characteristics in a dense\ncrowd and thus attracts the widespread interest of scientists and engineers.\nHowever, even successful modeling approaches such as pedestrian models based on\nparticle systems are still not fully considered the perceptive mechanism\nunderlying collective pedestrian behavior. This paper extends a behavioral\nheuristics-based pedestrian model to an adaptive agent-based model, which\nexplicitly considers the crowding effect of neighboring individuals and\nperception anisotropy on the representation of a pedestrians visual\ninformation. The adaptive agents with crowding perception are constructed to\ninvestigate complex, selforganized collective dynamics of pedestrian motion.\nThe proposed model simulates selforganized pedestrian flows in good\nquantitative agreement with empirical data. The selforganized phenomena include\nlane formation in bidirectional flow and fundamental diagrams of unidirectional\nflow. Simulation results show that the emergence of lane formation in\nbidirectional flow can be well reproduced. To investigate this further,\nincreasing view distance has a significant effect on reducing the number of\nlanes, increasing lane width, and stabilizing the self-organized lanes. The\npaper also discusses phase transitions of fundamental diagrams of pedestrian\ncrowds with unidirectional flow. It is found that the heterogeneity of how\npedestrians perceive crowding in the population has a remarkable impact on the\nflow quality, which results in the buildup of congestion and rapidly decreases\nthe efficiency of pedestrian flows. It also indicates that the concept of\nheterogeneity may be used to explain the instability of phase transitions.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.5380v3"
    },
    {
        "title": "Cucker-Smale flocking with alternating leaders",
        "authors": [
            "Zhuchun Li",
            "Seung-Yeal Ha"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  We study the emergent flocking behavior in a group of Cucker-Smale flocking\nagents under rooted leadership with alternating leaders. It is well known that\nthe network topology regulates the emergent behaviors of flocks. All existing\nresults on the Cucker-Smale model with leader-follower topologies assume a\nfixed leader during temporal evolution process. The rooted leadership is the\nmost general topology taking a leadership. Motivated by collective behaviors\nobserved in the flocks of birds, swarming fishes and potential engineering\napplications, we consider the rooted leadership with alternating leaders; that\nis, at each time slice there is a leader but it can be switched among the\nagents from time to time. We will provide several sufficient conditions leading\nto the asymptotic flocking among the Cucker-Smale agents under rooted\nleadership with alternating leaders.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3875v1"
    },
    {
        "title": "A Hierarchical Dynamic Programming Algorithm for Optimal Coalition\n  Structure Generation",
        "authors": [
            "Meritxell Vinyals",
            "Thomas Voice",
            "Sarvapali Ramchurn",
            "Nicholas R. Jennings"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  We present a new Dynamic Programming (DP) formulation of the Coalition\nStructure Generation (CSG) problem based on imposing a hierarchical\norganizational structure over the agents. We show the efficiency of this\nformulation by deriving DyPE, a new optimal DP algorithm which significantly\noutperforms current DP approaches in speed and memory usage. In the classic\ncase, in which all coalitions are feasible, DyPE has half the memory\nrequirements of other DP approaches. On graph-restricted CSG, in which\nfeasibility is restricted by a (synergy) graph, DyPE has either the same or\nlower computational complexity depending on the underlying graph structure of\nthe problem. Our empirical evaluation shows that DyPE outperforms the\nstate-of-the-art DP approaches by several orders of magnitude in a large range\nof graph structures (e.g. for certain scalefree graphs DyPE reduces the memory\nrequirements by $10^6$ and solves problems that previously needed hours in\nminutes).\n",
        "pdf_link": "http://arxiv.org/pdf/1310.6704v1"
    },
    {
        "title": "IRM4MLS: the influence reaction model for multi-level simulation",
        "authors": [
            "Gildas Morvan",
            "Alexandre Veremme",
            "Daniel Dupont"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  In this paper, a meta-model called IRM4MLS, that aims to be a generic ground\nto specify and execute multi-level agent-based models is presented. It relies\non the influence/reaction principle and more specifically on IRM4S. Simulation\nmodels for IRM4MLS are defined. The capabilities and possible extensions of the\nmeta-model are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.7951v1"
    },
    {
        "title": "Observation of large-scale multi-agent based simulations",
        "authors": [
            "Gildas Morvan",
            "Alexandre Veremme",
            "Daniel Dupont"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  The computational cost of large-scale multi-agent based simulations (MABS)\ncan be extremely important, especially if simulations have to be monitored for\nvalidation purposes. In this paper, two methods, based on self-observation and\nstatistical survey theory, are introduced in order to optimize the computation\nof observations in MABS. An empirical comparison of the computational cost of\nthese methods is performed on a toy problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.0758v1"
    },
    {
        "title": "A Methodology to Engineer and Validate Dynamic Multi-level Multi-agent\n  Based Simulations",
        "authors": [
            "Jean-Baptiste Soyez",
            "Gildas Morvan",
            "Daniel Dupont",
            "Rochdi Merzouki"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This article proposes a methodology to model and simulate complex systems,\nbased on IRM4MLS, a generic agent-based meta-model able to deal with\nmulti-level systems. This methodology permits the engineering of dynamic\nmulti-level agent-based models, to represent complex systems over several\nscales and domains of interest. Its goal is to simulate a phenomenon using\ndynamically the lightest representation to save computer resources without loss\nof information. This methodology is based on two mechanisms: (1) the activation\nor deactivation of agents representing different domain parts of the same\nphenomenon and (2) the aggregation or disaggregation of agents representing the\nsame phenomenon at different scales.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.5108v1"
    },
    {
        "title": "Agent Approach in Support of Enterprise Application Integration",
        "authors": [
            "Djamel Benmerzoug"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  The present approach highlights the synergies between application integration\nand interaction protocols. Since both fields have advanced in different\ndirections, a number of important technical problems can be addressed by their\nproper synthesis. In our previous work, we proposed a methodological approach\nbased on Interaction Protocols for Enterprise Applica tion Integration (EAI).\nThis approach permits to specify MAS (Multi-Agent System) interaction\nprotocols, verify their behavior and use them to integrate multiple business\napplications. The result of the proposed approach is a validated interaction\nprotocol. Based on this protocol, we define in this paper, an agent- based\narchitecture for the EAI. It includes all the concepts nec- essary to support\ncommunication and coordination mechanisms such as inter-agent and agent-Web\nservices communication.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6149v1"
    },
    {
        "title": "Intelligent Agent for Prediction in E- Negotiation: An Approach",
        "authors": [
            "Mohammad Irfan Bala",
            "Sheetal Vij",
            "Debajyoti Mukhopadhyay"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  With the proliferation of web technologies it becomes more and more important\nto make the traditional negotiation pricing mechanism automated and\nintelligent. The behaviour of software agents which negotiate on behalf of\nhumans is determined by their tactics in the form of decision functions.\nPrediction of partners behaviour in negotiation has been an active research\ndirection in recent years as it will improve the utility gain for the adaptive\nnegotiation agent and also achieve the agreement much quicker or look after\nmuch higher benefits. In this paper we review the various negotiation methods\nand the existing architecture. Although negotiation is practically very complex\nactivity to automate without human intervention we have proposed architecture\nfor predicting the opponents behaviour which will take into consideration\nvarious factors which affect the process of negotiation. The basic concept is\nthat the information about negotiators, their individual actions and dynamics\ncan be used by software agents equipped with adaptive capabilities to learn\nfrom past negotiations and assist in selecting appropriate negotiation tactics.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6229v1"
    },
    {
        "title": "Agent Based Negotiation using Cloud - an Approach in E-Commerce",
        "authors": [
            "Amruta More",
            "Sheetal Vij",
            "Debajyoti Mukhopadhyay"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Cloud computing allows subscription based access to computing. It also allows\nstorage services over Internet. Automated Negotiation is becoming an emerging,\nand important area in the field of Multi Agent Systems in ECommerce. Multi\nAgent based negotiation system is necessary to increase the efficiency of\nE-negotiation process. Cloud computing provides security and privacy to the\nuser data and low maintenance costs. We propose a Negotiation system using\ncloud. In this system, all product information and multiple agent details are\nstored on cloud. Both parties select their agents through cloud for\nnegotiation. Agent acts as a negotiator. Agents have users details and their\nrequirements for a particular product. Using users requirement, agents\nnegotiate on some issues such as price, volume, duration, quality and so on.\nAfter completing negotiation process, agents give feedback to the user about\nwhether negotiation is successful or not. This negotiation system is dynamic in\nnature and increases the agents with the increase in participating user.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6233v1"
    },
    {
        "title": "Multi-agent based protection system for distribution system with DG",
        "authors": [
            "Jin Shang",
            "Nengling Tai",
            "Qi Liu"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This paper introduces the basic structure of multi-agent based protection\nsystem for distribution system with DGs. The entire system consists of\nintelligent agents and communication system. Intelligent agents can be divided\ninto three layers, the bottom layer, the middle layer and the upper layer. The\ndesign of the agent in different layer is analyzed in detail. Communication\nsystem is the bridge of multi-agent system (MAS). The transmission mode,\nselective communication and other principles are discussed to improve the\ntransmission efficiency. Finally, some evaluations are proposed, which provides\nthe design of MAS with reference.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6870v1"
    },
    {
        "title": "Toward an agent based distillation approach for protesting crowd\n  simulation",
        "authors": [
            "Lam Thu Bui",
            "Van Vien Mac"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This paper investigates the problem of protesting crowd simulation. It\nconsiders CROCADILE, an agent based distillation system, for this purpose. A\nmodel of protesting crowd was determined and then a CROCADILE model of\nprotesting crowd was engineered and demonstrated. We validated the model by\nusing two scenarios where protesters are varied with different personalities.\nThe results indicated that CROCADILE served well as the platform for protesting\ncrowd modeling simulation\n",
        "pdf_link": "http://arxiv.org/pdf/1312.4048v1"
    },
    {
        "title": "Modification of Contract Net Protocol(CNP) : A Rule-Updation Approach",
        "authors": [
            "Sandeep Kaur",
            "Harjot Kaur",
            "Sumeet Kaur Sehra"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Coordination in multi-agent system is very essential, in order to perform\ncomplex tasks and lead MAS towards its goal. Also, the member agents of\nmulti-agent system should be autonomous as well as collaborative to accomplish\nthe complex task for which multi-agent system is designed specifically.\nContract-Net Protocol (CNP) is one of the coordination mechanisms which is used\nby multi-agent systems which prefer coordination through interaction protocols.\nIn order to overcome the limitations of conventional CNP, this paper proposes a\nmodification in conventional CNP called updated-CNP. Updated-CNP is an effort\ntowards updating of a CNP in terms of its limitations of modifiability and\ncommunication overhead. The limitation of the modification of tasks, if the\ntask requirements change at any instance, corresponding to tasks which are\nallocated to contractor agents by manager agents is possible in our updated-CNP\nversion, which was not possible in the case of conventional-CNP, as it has to\nbe restarted in the case of task modification. This in turn will be reducing\nthe communication overhead of CNP, which is time taken by various agents using\nCNP to pass messages to each other. For the illustration of the updated CNP, we\nhave used a sound predator-prey case study.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.4259v1"
    },
    {
        "title": "Developing a model of evacuation after an earthquake in Lebanon",
        "authors": [
            "Hong Van Truong",
            "Elise Beck",
            "Julie Dugdale",
            "Carole Adam"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This article describes the development of an agent-based model (AMEL,\nAgent-based Model for Earthquake evacuation in Lebanon) that aims at simulating\nthe movement of pedestrians shortly after an earthquake. The GAMA platform was\nchosen to implement the model. AMEL is applied to a real case study, a district\nof the city of Beirut, Lebanon, which potentially could be stricken by a M7\nearthquake. The objective of the model is to reproduce real life mobility\nbehaviours that have been gathered through a survey in Beirut and to test\ndifferent future scenarios, which may help the local authorities to target\ninformation campaigns.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.5941v1"
    },
    {
        "title": "Fuzzy Decision Analysis in Negotiation between the System of Systems\n  Agent and the System Agent in an Agent-Based Model",
        "authors": [
            "Paulette Acheson",
            "Cihan Dagli",
            "Nil Kilicay-Ergin"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Previous papers have described a computational approach to System of Systems\n(SoS) development using an Agent-Based Model (ABM). This paper describes the\nFuzzy Decision Analysis used in the negotiation between the SoS agent and a\nSystem agent in the ABM of an Acknowledged SoS development. An Acknowledged SoS\nhas by definition a limited influence on the development of the individual\nSystems. The individual Systems have their own priorities, pressures, and\nagenda which may or may not align with the goals of the SoS. The SoS has some\nfunding and deadlines which can be used to negotiate with the individual System\nin order to illicit the required capability from that System. The Fuzzy\nDecision Analysis determines how the SoS agent will adjust the funding and\ndeadlines for each of the Systems in order to achieve the desired SoS\narchitecture quality. The Fuzzy Decision Analysis has inputs of performance,\nfunding, and deadlines as well as weights for each capability. The performance,\nfunding, and deadlines are crisp values which are fuzzified. The fuzzified\nvalues are then used with a Fuzzy Inference Engine to get the fuzzy outputs of\nfunding adjustment and deadline adjustment which must then be defuzzified\nbefore being passed to the System agent. The first contribution of this paper\nis the fuzzy decision analysis that represents the negotiation between the SoS\nagent and the System agent. A second contribution of this paper is the method\nof implementing the fuzzy decision analysis which provides a generalized fuzzy\ndecision analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.0029v1"
    },
    {
        "title": "Computing Agents for Decision Support Systems",
        "authors": [
            "D. Krzywicki",
            "Ł. Faber",
            "A. Byrski",
            "M. Kisiel-Dorohinicki"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In decision support systems, it is essential to get a candidate solution\nfast, even if it means resorting to an approximation. This constraint\nintroduces a scalability requirement with regard to the kind of heuristics\nwhich can be used in such systems. As execution time is bounded, these\nalgorithms need to give better results and scale up with additional computing\nresources instead of additional time. In this paper, we show how multi-agent\nsystems can fulfil these requirements. We recall as an example the concept of\nEvolutionary Multi-Agent Systems, which combine evolutionary and agent\ncomputing paradigms. We describe several possible implementations and present\nexperimental results demonstrating how additional resources improve the\nefficiency of such systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.2793v2"
    },
    {
        "title": "Simulating urban expansion in the parcel level for all Chinese cities",
        "authors": [
            "Ying Long",
            "Kang Wu",
            "Qizhi Mao"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Large-scale models are generally associated with big modelling units in\nspace, like counties or super grids (several to dozens km2). Few applied urban\nmodels can pursue large-scale extent with fine-level units simultaneously due\nto data availability and computation load. The framework of automatic\nidentification and characterization parcels developed by Long and Liu (2013)\nmakes such an ideal model possible by establishing existing urban parcels using\nroad networks and points of interest for a super large area (like a country or\na continent). In this study, a mega-vector-parcels cellular automata model\n(MVP-CA) is developed for simulating urban expansion in the parcel level for\nall 654 Chinese cities. Existing urban parcels in 2012, for initiating MVP-CA,\nare generated using multi-levelled road networks and ubiquitous points of\ninterest, followed by simulating parcel-based urban expansion of all cities\nduring 2012-2017. Reflecting national spatial development strategies discussed\nextensively by academics and decision makers, the baseline scenario and other\ntwo simulated urban expansion scenarios have been tested and compared\nhorizontally. As the first fine-scale urban expansion model from the national\nscope, its academic contributions, practical applications, and potential biases\nare discussed in this paper as well.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3718v1"
    },
    {
        "title": "New Mechanism for Multiagent Extensible Negotiations",
        "authors": [
            "Samir Aknine"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Multiagent negotiation mechanisms advise original solutions to several\nproblems for which usual problem solving methods are inappropriate. Mainly\nnegotiation models are based on agents' interactions through messages. Agents\ninteract in order to reach an agreement for solving a specific problem. In this\nwork, we study a new variant of negotiations, which has not yet been addressed\nin existing works. This negotiation form is denoted extensible negotiation. In\ncontrast with current negotiation models, this form of negotiation allows the\nagents to dynamically extend the set of items under negotiation. This facility\ngives more acceptable solutions for the agents in their negotiation. The\nadvantage of enlarging the negotiation space is to certainly offer more\nfacilities for the agents for reaching new agreements which would not have been\nobtained using usual negotiation methods. This paper presents the protocol and\nthe strategies used by the agents to deal with such negotiations.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3986v1"
    },
    {
        "title": "Extending Agents by Transmitting Protocols in Open Systems",
        "authors": [
            "Lavindra de Silva",
            "Michael Winikoff",
            "Wei Liu"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Agents in an open system communicate using interaction protocols. Suppose\nthat we have a system of agents and that we want to add a new protocol that all\n(or some) agents should be able to understand. Clearly, modifying the source\ncode for each agent implementation is not practical. A solution to this problem\nof upgrading an open system is to have a mechanism that allows agents to\nreceive a description of an interaction protocol and use it. In this paper we\npropose a representation for protocols based on extending Petri nets. However,\nthis is not enough: in an open system the source of a protocol may not be\ntrusted and a protocol that is received may contain steps that are erroneous or\nthat make confidential information public. We therefore also describe an\nanalysis method that infers whether a protocol is safe. Finally, we give an\nexecution model for extended Petri nets.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.0429v1"
    },
    {
        "title": "A Metric for Modelling and Measuring Complex Behavioural Systems",
        "authors": [
            "Kieran Greer"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper describes a metric for measuring the success of a complex system\ncomposed of agents performing autonomous behaviours. Because of the difficulty\nin evaluating such systems, this metric will help to give an initial indication\nas to how suitable the agents would be for solving the problem. The system is\nmodelled as a script, or behavioural ontology, with a number of variables to\nrepresent each of the behaviour attributes. The set of equations can be used\nboth for modeling and as part of the simulation evaluation. Behaviours can be\nnested, allowing for compound behaviours of arbitrary complexity to be built.\nThere is also the capability for including rules or decision making into the\nscript. The paper also gives some test examples to show how the metric might be\nused.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.0770v1"
    },
    {
        "title": "Multiagent Conflict Resolution for a Specification Network of\n  Discrete-Event Coordinating Agents",
        "authors": [
            "Manh Tung Pham",
            "Kiam Tian Seow"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper presents a novel compositional approach to distributed\ncoordination module (CM) synthesis for multiple discrete-event agents in the\nformal languages and automata framework. The approach is supported by two\noriginal ideas. The first is a new formalism called the Distributed Constraint\nSpecification Network (DCSN) that can comprehensibly describe the networking\nconstraint relationships among distributed agents. The second is multiagent\nconflict resolution planning, which entails generating and using AND/OR graphs\nto compactly represent conflict resolution (synthesis-process) plans for a\nDCSN. Together with the framework of local CM design developed in the authors'\nearlier work, the systematic approach supports separately designing local and\ndeconflicting CM's for individual agents in accordance to a selected conflict\nresolution plan. Composing the agent models and the CM's designed furnishes an\noverall nonblocking coordination solution that meets the set of inter-agent\nconstraints specified in a given DCSN.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.4711v1"
    },
    {
        "title": "Management of dangerous goods in container terminal with MAS model",
        "authors": [
            "Mansoriya Hamidou",
            "Dominique Fournier",
            "Eric Sanlaville",
            "Frédéric Serin"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In a container terminal, many operations occur within the storage area:\ncontainers import, containers export and containers shifting. All these\noperations require the respect of many rules and even laws in order to\nguarantee the port safety and to prevent risks, especially when hazardous\nmaterial is concerned. In this paper, we propose a hybrid architecture, using a\nCellular Automaton and a Multi-Agent System to handle the dangerous container\nstorage problem. It is an optimization problem since the aim is to improve the\ncontainer terminal configuration, that is, the way hazardous containers are\ndispatched through the terminal to improve its security. In our model, we\nconsider containers as agents, in order to use a Multi-Agent System for the\ndecision aid software, and a Cellular Automaton for modelling the terminal\nitself. To validate our approach many tests have been performed and the results\nshow the relevance of our model.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.7152v1"
    },
    {
        "title": "Towards designing artificial universes for artificial agents under\n  interaction closure",
        "authors": [
            "Martin Biehl",
            "Christoph Salge",
            "Daniel Polani"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We are interested in designing artificial universes for artifi- cial agents.\nWe view artificial agents as networks of high- level processes on top of of a\nlow-level detailed-description system. We require that the high-level processes\nhave some intrinsic explanatory power and we introduce an extension of\ninformational closure namely interaction closure to capture this. Then we\nderive a method to design artificial universes in the form of finite Markov\nchains which exhibit high-level pro- cesses that satisfy the property of\ninteraction closure. We also investigate control or information transfer which\nwe see as an building block for networks representing artificial agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.1502v1"
    },
    {
        "title": "Using FLAME Toolkit for Agent-Based Simulation: Case Study Sugarscape\n  Model",
        "authors": [
            "Mariam Kiran"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Social scientists have used agent-based models to understand how individuals\ninteract and behave in various political, ecological and economic scenarios.\nAgent-based models are ideal for understanding such models involving\ninteracting individuals producing emergent phenomenon. Sugarscape is one of the\nmost famous examples of a social agent-based model which has been used to show\nhow societies grow in the real world.\n  This paper builds on the Sugarscape model, using the Flexible Large scale\nAgent-based modelling Environment (FLAME) to simulate three different scenarios\nof the experiment, which are based on the Sugar and Citizen locations. FLAME is\nan agent-based modelling framework which has previously been used to model\nbiological and economic models. The paper includes details on how the model was\nwritten and the various parameters set for the simulation. The results of the\nmodel simulated are processed for three scenarios and analysed to see what\naffect the initial starting states of the agents had on the overall result\nobtained through the model and the variance in simulation time of processing\nthe model on multicore architectures.\n  The experiments highlight that there are limitations of the FLAME framework\nand writing simulation models in general which are highly dependent on initial\nstarting states of a model, also raising further potential work which can be\nbuilt into the Sugarscape model to study other interesting phenomenon in social\nand economic laws.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.3441v1"
    },
    {
        "title": "Plurality Voting under Uncertainty",
        "authors": [
            "Reshef Meir"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Understanding the nature of strategic voting is the holy grail of social\nchoice theory, where game-theory, social science and recently computational\napproaches are all applied in order to model the incentives and behavior of\nvoters.\n  In a recent paper, Meir et al.[EC'14] made another step in this direction, by\nsuggesting a behavioral game-theoretic model for voters under uncertainty. For\na specific variation of best-response heuristics, they proved initial existence\nand convergence results in the Plurality voting system.\n  In this paper, we extend the model in multiple directions, considering voters\nwith different uncertainty levels, simultaneous strategic decisions, and a more\npermissive notion of best-response. We prove that a voting equilibrium exists\neven in the most general case. Further, any society voting in an iterative\nsetting is guaranteed to converge.\n  We also analyze an alternative behavior where voters try to minimize their\nworst-case regret. We show that the two behaviors coincide in the simple\nsetting of Meir et al., but not in the general case.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.4949v1"
    },
    {
        "title": "Agent-Based Model for Rural-Urban Migration: A Dynamic Consideration",
        "authors": [
            "Ning Cai",
            "Hai-Ying Ma",
            "M. Junaid Khan"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper develops a dynamic agent-based model for rural-urban migration,\nbased on the previous relevant works. The model conforms to the typical dynamic\nlinear multi-agent systems model concerned extensively in systems science, in\nwhich the communication network is formulated as a digraph. Simulations reveal\nthat consensus of certain variable could be harmful to the overall stability\nand should be avoided.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.5336v1"
    },
    {
        "title": "Spacetimes with Semantics",
        "authors": [
            "Mark Burgess"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Relationships between objects constitute our notion of space. When these\nrelationships change we interpret this as the passage of time. Observer\ninterpretations are essential to the way we understand these relationships.\nHence observer semantics are an integral part of what we mean by spacetime.\n  Semantics make up the essential difference in how one describes and uses the\nconcept of space in physics, chemistry, biology and technology. In these notes,\nI have tried to assemble what seems to be a set of natural, and pragmatic,\nconsiderations about discrete, finite spacetimes, to unify descriptions of\nthese areas.\n  It reviews familiar notions of spacetime, and brings them together into a\nless familiar framework of promise theory (autonomous agents), in order to\nilluminate the goal of encoding the semantics of observers into a description\nof spacetime itself. Autonomous agents provide an exacting atomic and local\nmodel for finite spacetime, which quickly reveals the issues of incomplete\ninformation and non-locality. From this we should be able to reconstruct all\nother notions of spacetime.\n  The aim of this exercise is to apply related tools and ideas to an initial\nunification of real and artificial spaces, e.g. databases and information webs\nwith natural spacetime. By reconstructing these spaces from autonomous agents,\nwe may better understand naming and coordinatization of semantic spaces, from\ncrowds and swarms to datacentres and libraries, as well as the fundamental\narena of natural science.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.5563v1"
    },
    {
        "title": "An Evolutionary Approach for Optimizing Hierarchical Multi-Agent System\n  Organization",
        "authors": [
            "Zhiqi Shen",
            "Ling Yu",
            "Han Yu"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  It has been widely recognized that the performance of a multi-agent system is\nhighly affected by its organization. A large scale system may have billions of\npossible ways of organization, which makes it impractical to find an optimal\nchoice of organization using exhaustive search methods. In this paper, we\npropose a genetic algorithm aided optimization scheme for designing\nhierarchical structures of multi-agent systems. We introduce a novel algorithm,\ncalled the hierarchical genetic algorithm, in which hierarchical crossover with\na repair strategy and mutation of small perturbation are used. The phenotypic\nhierarchical structure space is translated to the genome-like array\nrepresentation space, which makes the algorithm genetic-operator-literate. A\ncase study with 10 scenarios of a hierarchical information retrieval model is\nprovided. Our experiments have shown that competitive baseline structures which\nlead to the optimal organization in terms of utility can be found by the\nproposed algorithm during the evolutionary search. Compared with the\ntraditional genetic operators, the newly introduced operators produced better\norganizations of higher utility more consistently in a variety of test cases.\nThe proposed algorithm extends of the search processes of the state-of-the-art\nmulti-agent organization design methodologies, and is more computationally\nefficient in a large search space.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.6202v1"
    },
    {
        "title": "Analysis of the Effects of Failure and Noise in the Distributed\n  Connectivity Maintenance of a Multi-robot System",
        "authors": [
            "Vinícius A. Battagello",
            "Carlos H. C. Ribeiro"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  To perform cooperative tasks in a decentralized manner, multi-robot systems\nare often required to communicate with each other. Therefore, maintaining the\ncommunication graph connectivity is a fundamental issue when roaming a\nterritory with obstacles. However, when dealing with real-robot systems,\nseveral sources of data corruption can appear in the agent interaction. In this\npaper, the effects of failure and noise in the communication between agents are\nanalyzed upon a connectivity maintenance control strategy. The results show\nthat the connectivity strategy is resilient to the negative effects of such\ndisturbances under realistic settings that consider a bandwidth limit for the\ncontrol effort. This opens the perspective of applying the connectivity\nmaintenance strategy in adaptive schemes that consider, for instance,\nautonomous adaptation to constraints other than connectivity itself, e.g.\ncommunication efficiency and energy harvesting.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.0055v1"
    },
    {
        "title": "Information-Sharing over Adaptive Networks with Self-interested Agents",
        "authors": [
            "Chung-Kai Yu",
            "Mihaela van der Schaar",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We examine the behavior of multi-agent networks where information-sharing is\nsubject to a positive communications cost over the edges linking the agents. We\nconsider a general mean-square-error formulation where all agents are\ninterested in estimating the same target vector. We first show that, in the\nabsence of any incentives to cooperate, the optimal strategy for the agents is\nto behave in a selfish manner with each agent seeking the optimal solution\nindependently of the other agents. Pareto inefficiency arises as a result of\nthe fact that agents are not using historical data to predict the behavior of\ntheir neighbors and to know whether they will reciprocate and participate in\nsharing information. Motivated by this observation, we develop a reputation\nprotocol to summarize the opponent's past actions into a reputation score,\nwhich can then be used to form a belief about the opponent's subsequent\nactions. The reputation protocol entices agents to cooperate and turns their\noptimal strategy into an action-choosing strategy that enhances the overall\nsocial benefit of the network. In particular, we show that when the\ncommunications cost becomes large, the expected social benefit of the proposed\nprotocol outperforms the social benefit that is obtained by cooperative agents\nthat always share data. We perform a detailed mean-square-error analysis of the\nevolution of the network over three domains: far field, near-field, and\nmiddle-field, and show that the network behavior is stable for sufficiently\nsmall step-sizes. The various theoretical results are illustrated by numerical\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.1468v2"
    },
    {
        "title": "Resolving multi-proxy transitive vote delegation",
        "authors": [
            "Jonas Degrave"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Solving a delegation graph for transitive votes is already a non-trivial task\nfor many programmers. When extending the current main paradigm, where each\nvoter can only appoint a single transitive delegation, to a system where each\nvote can be separated over multiple delegations, solving the delegation graph\nbecomes even harder. This article presents a solution of an example graph, and\na non-formal proof of why this algorithm works.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.4039v1"
    },
    {
        "title": "Binary Log-Linear Learning with Stochastic Communication Links",
        "authors": [
            "Arjun Muralidharan",
            "Yuan Yan",
            "Yasamin Mostofi"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In this paper, we consider distributed decision-making over stochastic\ncommunication links in multi-agent systems. We show how to extend the current\nliterature on potential games with binary log-linear learning (which mainly\nfocuses on ideal communication links) to consider the impact of stochastic\ncommunication channels. More specifically, we derive conditions on the\nprobability of link connectivity to achieve a target probability for the set of\npotential maximizers (in the stationary distribution). Furthermore, our toy\nexample demonstrates a transition phenomenon for achieving any target\nprobability for the set of potential maximizers.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.4166v1"
    },
    {
        "title": "Prices Matter for the Parameterized Complexity of Shift Bribery",
        "authors": [
            "Robert Bredereck",
            "Jiehua Chen",
            "Piotr Faliszewski",
            "André Nichterlein",
            "Rolf Niedermeier"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  In the Shift Bribery problem, we are given an election (based on preference\norders), a preferred candidate $p$, and a budget. The goal is to ensure that\n$p$ wins by shifting $p$ higher in some voters' preference orders. However,\neach such shift request comes at a price (depending on the voter and on the\nextent of the shift) and we must not exceed the given budget. We study the\nparameterized computational complexity of Shift Bribery with respect to a\nnumber of parameters (pertaining to the nature of the solution sought and the\nsize of the election) and several classes of price functions. When we\nparameterize Shift Bribery by the number of affected voters, then for each of\nour voting rules (Borda, Maximin, Copeland) the problem is W[2]-hard. If,\ninstead, we parameterize by the number of positions by which $p$ is shifted in\ntotal,then the problem is fixed-parameter tractable for Borda and Maximin,and\nis W[1]-hard for Copeland. If we parameterize by the budget, then the results\ndepend on the price function class. We also show that Shift Bribery tends to be\ntractable when parameterized by the number of voters, but that the results for\nthe number of candidates are more enigmatic.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.01253v2"
    },
    {
        "title": "Can Other People Make You Less Creative?",
        "authors": [
            "Liane Gabora"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper explains in layperson's terms how an agent-based model was used to\ninvestigate the hypothesis that culture evolves more effectively when\nnovelty-generating creative processes are tempered by imitation processes that\npreserve proven successful ideas. Using EVOC, an agent-based model of cultural\nevolution we found that (1) the optimal ratio of inventing to imitating ranged\nfrom 1:1 to 2:1 depending on the fitness function, (2) there was a trade-off\nbetween the proportion of creators to conformers and how creative the creators\nwere, and (3) when agents in increased or decreased their creativity depending\non the success of their latest creative efforts, they segregated into creators\nand conformers, and the mean fitness of ideas across the society was higher. It\nis tentatively suggested that through the unconscious use of social cues,\nmembers of a society self-organizes to achieve a balanced mix of creators and\nconformers.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.02076v1"
    },
    {
        "title": "Mathematical Modeling of Insurance Mechanisms for E-commerce Systems",
        "authors": [
            "Hong Xie",
            "John C. S. Lui"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Electronic commerce (a.k.a. E-commerce) systems such as eBay and Taobao of\nAlibaba are becoming increasingly popular. Having an effective reputation\nsystem is critical to this type of internet service because it can assist\nbuyers to evaluate the trustworthiness of sellers, and it can also improve the\nrevenue for reputable sellers and E-commerce operators. We formulate a\nstochastic model to analyze an eBay-like reputation system and propose four\nmeasures to quantify its effectiveness: (1) new seller ramp up time, (2) new\nseller drop out probability, (3) long term profit gains for sellers, and (4)\naverage per seller transaction gains for the E-commerce operator. Through our\nanalysis, we identify key factors which influence these four measures. We\npropose a new insurance mechanism which consists of an insurance protocol and a\ntransaction mechanism to improve the above four measures. We show that our\ninsurance mechanism can reduce the ramp up time by around 87.2%, and guarantee\nnew sellers ramp up before the deadline $T_w$ with a high probability (close to\n1.0). It also increases the long term profit gains and average per seller\ntransaction gains by at least 95.3%.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.03212v2"
    },
    {
        "title": "Data Driven Validation Framework for Multi-agent Activity-based Models",
        "authors": [
            "Jan Drchal",
            "Michal Čertický",
            "Michal Jakob"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Activity-based models, as a specific instance of agent-based models, deal\nwith agents that structure their activity in terms of (daily) activity\nschedules. An activity schedule consists of a sequence of activity instances,\neach with its assigned start time, duration and location, together with\ntransport modes used for travel between subsequent activity locations. A\ncritical step in the development of simulation models is validation. Despite\nthe growing importance of activity-based models in modelling transport and\nmobility, there has been so far no work focusing specifically on statistical\nvalidation of such models. In this paper, we propose a six-step Validation\nFramework for Activity-based Models (VALFRAM) that allows exploiting historical\nreal-world data to assess the validity of activity-based models. The framework\ncompares temporal and spatial properties and the structure of activity\nschedules against real-world travel diaries and origin-destination matrices. We\nconfirm the usefulness of the framework on three real-world activity-based\ntransport models.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07601v2"
    },
    {
        "title": "Crowd Congestion and Stampede Management through Multi Robotic Agents",
        "authors": [
            "Garima Ahuja",
            "Kamalakar Karlapalem"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Crowd management is a complex, challenging and crucial task. Lack of\nappropriate management of crowd has, in past, led to many unfortunate stampedes\nwith significant loss of life. To increase the crowd management efficiency, we\ndeploy automated real time detection of stampede prone areas. Then, we use\nrobotic agents to aid the crowd management police in controlling the crowd in\nthese stampede prone areas. While doing so, we aim for minimum interference by\nrobotic agents in our environment. Thereby not disturbing the ambiance and\naesthetics of the place. We evaluate the effectiveness of our model in dealing\nwith difficult scenarios like emergency evacuation and presence of localized\ncongestion. Lastly, we simulate a multi agent system based on our model and use\nit to illustrate the utility of robotic agents for detecting and reducing\ncongestion.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.00071v1"
    },
    {
        "title": "Model Checking AORTA: Verification of Organization-Aware Agents",
        "authors": [
            "Andreas Schmidt Jensen"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  As agent systems grow larger and more complex, there is an increasing need to\nformally verify them. Furthermore, it is often suggested that complex systems\ncan be regulated using organizational models, imposing constraints on the\nagents in the systems. Agents that can understand the organizational model and\nconstraints in a system is said to be organization-aware. This paper is\nconcerned with verification of organization-aware agents. We show how agents\nusing AORTA, a framework for making agents organization-aware, can be formally\nverified using an extended version of the Agent Java PathFinder (AJPF), a model\nchecking system designed specifically for agent programming languages. We\nintegrate AORTA with the Agent Infrastructure Layer (AIL), which is an\nintermediate layer on top of which APLs can be implemented, and use our\nextension of AJPF to verify a system of agents aiming to write a paper together\nby using an organization for coordination.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05317v1"
    },
    {
        "title": "A Multi-Agent System of Project Bidding Management Simulation",
        "authors": [
            "Rui Liu"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper presents a simulation model based on the general framework of\nMulti-Agent System (MAS) that can be used to investigate construction project\nbidding process. Specifically, it can be used to investigate different\nstrategies in project bidding management from the general contractors'\nperspective. The effectiveness of the studied management strategies is\nevaluated by the quality, time and cost of bidding activities. As an\nimplementation of MAS theory, this work is expected to test the suitability of\nMAS in studying construction management related problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06124v1"
    },
    {
        "title": "The Emergence of Norms via Contextual Agreements in Open Societies",
        "authors": [
            "George Vouros"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper explores the emergence of norms in agents' societies when agents\nplay multiple -even incompatible- roles in their social contexts\nsimultaneously, and have limited interaction ranges. Specifically, this article\nproposes two reinforcement learning methods for agents to compute agreements on\nstrategies for using common resources to perform joint tasks. The computation\nof norms by considering agents' playing multiple roles in their social contexts\nhas not been studied before. To make the problem even more realistic for open\nsocieties, we do not assume that agents share knowledge on their common\nresources. So, they have to compute semantic agreements towards performing\ntheir joint actions. %The paper reports on an empirical study of whether and\nhow efficiently societies of agents converge to norms, exploring the proposed\nsocial learning processes w.r.t. different society sizes, and the ways agents\nare connected. The results reported are very encouraging, regarding the speed\nof the learning process as well as the convergence rate, even in quite complex\nsettings.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.07017v1"
    },
    {
        "title": "A composite constraints approach to declarative agent-based modeling",
        "authors": [
            "David Bruce Borenstein"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Agent-based models (ABMs) are ubiquitous in research and industry. Currently,\nsimulating ABMs involves at least some imperative (step-by-step) computer\ninstructions. An alternative approach is declarative programming, in which a\nset of requirements is described at a high level of abstraction. Here we\ndescribe a fully declarative approach to the automated construction of\nsimulations for ABMs. In this framework, logic for ABM simulations is\nencapsulated into predefined components. The user specifies a set of\nrequirements describing the desired functionality. Additionally, each component\nhas a set of consistency requirements. The framework iteratively seeks a\nsimulation design that satisfies both user and system requirements. This\napproach allows the user to omit most details from the simulation\nspecification, simplifying simulation design.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.08880v1"
    },
    {
        "title": "MORE: Merged Opinions Reputation Model",
        "authors": [
            "Nardine Osman",
            "Alessandro Provetti",
            "Valerio Riggi",
            "Carles Sierra"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Reputation is generally defined as the opinion of a group on an aspect of a\nthing. This paper presents a reputation model that follows a probabilistic\nmodelling of opinions based on three main concepts: (1) the value of an opinion\ndecays with time, (2) the reputation of the opinion source impacts the\nreliability of the opinion, and (3) the certainty of the opinion impacts its\nweight with respect to other opinions. Furthermore, the model is flexible with\nits opinion sources: it may use explicit opinions or implicit opinions that can\nbe extracted from agent behavior in domains where explicit opinions are sparse.\nWe illustrate the latter with an approach to extract opinions from behavioral\ninformation in the sports domain, focusing on football in particular. One of\nthe uses of a reputation model is predicting behavior. We take up the challenge\nof predicting the behavior of football teams in football matches, which we\nargue is a very interesting yet difficult approach for evaluating the model.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.09066v1"
    },
    {
        "title": "Unperturbed Schelling segregation in two or three dimensions",
        "authors": [
            "George Barmpalias",
            "Richard Elwes",
            "Andy Lewis-Pye"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Schelling's model of segregation, first described in 1969, has become one of\nthe best known models of self-organising behaviour. While Schelling's explicit\nconcern was to understand the mechanisms underlying racial segregation in large\ncities from a game theoretic perspective, the model should be seen as one of a\nfamily, arising in fields as diverse as statistical mechanics, neural networks\nand the social sciences, and which are concerned with interacting populations\nsituated on network structures. Despite extensive study, however, the\n(unperturbed) Schelling model has largely resisted rigorous analysis, prior\nresults in the literature generally pertaining to variants of the model in\nwhich noise is introduced into the dynamics of the system, the resulting model\nthen being amenable to standard techniques from statistical mechanics or\nstochastic evolutionary game theory. A series of recent papers (one by Brandt,\nImmorlica, Kamath, and Kleinberg, and two by the authors), has seen the first\nrigorous analysis of the one dimensional version of the unperturbed model. Here\nwe provide the first rigorous analysis of the two and three dimensional\nunperturbed models, establishing most of the phase diagram, and answering a\nchallenge from a recent paper by Brandt, Immorlica, Kamath, and Kleinberg.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.03809v4"
    },
    {
        "title": "Socializing Autonomous Units with the Reflexive Game Theory and\n  Resonate-and-Fire neurons",
        "authors": [
            "Sergey Tarasenko"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  In this study the concept of reflexia is applied to modeling behavior of\nautonomous units. The relationship between reflexia, on the one hand, and\nmirror neuron system and perception of emotions, on the other hand, is\nintroduced. The main method of using reflexia in a group of autonomous units is\nReflexive Game Theory (RGT). To embody RGT in a group of autonomous agents a\ncommunication system is employed. This communication system uses frequency\ndomain multiplexing by means of Izhikevich's resonate-and-fire neural models.\nThe result of socialization of autonomous units by means of RGT and\ncommunication system is illustrated in several examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.04811v1"
    },
    {
        "title": "Informational parasites in code evolution",
        "authors": [
            "Andres C. Burgos",
            "Daniel Polani"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  In a previous study, we considered an information-theoretic model of code\nevolution. In it, agents obtain information about their (common) environment by\nthe perception of messages of other agents, which is determined by an\ninteraction probability (the structure of the population). For an agent to\nunderstand another agent's messages, the former must either know the identity\nof the latter, or the code producing the messages must be universally\ninterpretable. A universal code, however, introduces a vulnerability: a\nparasitic entity can take advantage of it. Here, we investigate this problem.\nIn our specific setting, we consider a parasite to be an agent that tries to\ninflict as much damage as possible in the mutual understanding of the\npopulation (i.e. the parasite acts as a disinformation agent). We show that,\nafter introducing a parasite in the population, the former adopts a code such\nthat it captures the information about the environment that is missing in the\npopulation. Such agent would be of great value, but only if the rest of the\npopulation could understand its messages. However, it is of little use here,\nsince the parasite utilises the most common messages in the population to\nexpress different concepts. Now we let the population respond by updating their\ncodes such that, in this arms race, they again maximise their mutual\nunderstanding. As a result, there is a code drift in the population where the\nutilisation of the messages of the parasite is avoided. A consequence of this\nis that the information that the parasite possesses but the agents lack becomes\nunderstandable and readily available.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.00956v2"
    },
    {
        "title": "Spacetimes with Semantics (II), Scaling of agency, semantics, and\n  tenancy",
        "authors": [
            "Mark Burgess"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Using Promise Theory as a calculus, I review how to define agency in a\nscalable way, for the purpose of understanding semantic spacetimes. By\nfollowing simple scaling rules, replacing individual agents with `super-agents'\n(sub-spaces), it is shown how agency can be scaled both dynamically and\nsemantically.\n  The notion of occupancy and tenancy, or how space is used and filled in\ndifferent ways, is also defined, showing how spacetime can be shared between\nindependent parties, both by remote association and local encapsulation. I\ndescribe how to build up dynamic and semantic continuity, by joining discrete\nindividual atoms and molecules of space into quasi-continuous lattices.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.01716v1"
    },
    {
        "title": "An informational study of the evolution of codes and of emerging\n  concepts in populations of agents",
        "authors": [
            "Andres C. Burgos",
            "Daniel Polani"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  We consider the problem of the evolution of a code within a structured\npopulation of agents. The agents try to maximise their information about their\nenvironment by acquiring information from the outputs of other agents in the\npopulation. A naive use of information-theoretic methods would assume that\nevery agent knows how to \"interpret\" the information offered by other agents.\nHowever, this assumes that one \"knows\" which other agents one observes, and\nthus which code they use. In our model, however, we wish to preclude that: it\nis not clear which other agents an agent is observing, and the resulting usable\ninformation is therefore influenced by the universality of the code used and by\nwhich agents an agent is \"listening\" to. We further investigate whether an\nagent who does not directly perceive the environment can distinguish states by\nobserving other agents' outputs. For this purpose, we consider a population of\ndifferent types of agents \"talking\" about different concepts, and try to\nextract new ones by considering their outputs only.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.04142v1"
    },
    {
        "title": "The Specification of Sugarscape",
        "authors": [
            "Joseph Kehoe"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Sugarscape is a well known and influential Agent Based Social Simulation\n(ABSS). Various parts of Sugarscape are supplied as examples in almost all\nAgent Based Model (ABM) toolkits. It has been used for demonstrating the\napplicability of different approaches to ABM. However a lack of agreement on\nthe precise definition of the rules within Sugarscape has curtailed its\nusefulness. We provide a formal specification of Sugarscape using the Z\nspecification language. This demonstrates the ability of formal specification\nto capture the definition of an ABM in a precise manner. It shows that formal\nspecifications could be used as an approach to tackle the replication problem\nin the field of ABM. It also provides the first clear interpretation of\nSugarscape identifying areas where information is missing and/or ambiguous.\nThis enables researchers to make proper comparisons between different\nimplementations of this model.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.06012v3"
    },
    {
        "title": "A First Step Towards Dynamic Hybrid Traffic Modeling",
        "authors": [
            "Najia Bouha",
            "Gildas Morvan",
            "Hassane Abouaïssa",
            "Yoann Kubera"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Hybrid traffic modeling and simulation provide an important way to represent\nand evaluate large-scale traffic networks at different levels of details. The\nfirst level, called \"microscopic\" allows the description of individual vehicles\nand their interactions as well as the study of driver's individual behavior.\nThe second, based on the analogy with fluidic dynamic, is the \"macroscopic\" one\nand provides an efficient way to represent traffic flow behavior in large\ntraffic infrastructures, using three aggregated variables: traffic density,\nmean speed and traffic volume. An intermediate level called \"mesoscopic\"\nconsiders a group of vehicles sharing common properties such as a same origin\nand destination. The work conducted in this paper presents a first step\nallowing simulation of wide area traffic network on the basis of dynamic hybrid\nmodeling, where the representation associated to a network section can change\nat runtime. The proposed approach is implemented in a simulation platform,\ncalled Jam-free.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.07257v1"
    },
    {
        "title": "Augmenting Agent Platforms to Facilitate Conversation Reasoning",
        "authors": [
            "David Lillis",
            "Rem W. Collier`"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Within Multi Agent Systems, communication by means of Agent Communication\nLanguages (ACLs) has a key role to play in the co-operation, co-ordination and\nknowledge-sharing between agents. Despite this, complex reasoning about agent\nmessaging, and specifically about conversations between agents, tends not to\nhave widespread support amongst general-purpose agent programming languages.\n  ACRE (Agent Communication Reasoning Engine) aims to complement the existing\nlogical reasoning capabilities of agent programming languages with the\ncapability of reasoning about complex interaction protocols in order to\nfacilitate conversations between agents. This paper outlines the aims of the\nACRE project and gives details of the functioning of a prototype implementation\nwithin the Agent Factory multi agent framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.02685v1"
    },
    {
        "title": "Modeling emergence of norms in multi-agent systems by applying tipping\n  points ideas",
        "authors": [
            "Francisco Lopez"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Norms are known to be a major factor determining humans behavior. It's also\nshown that norms can be quite effective tool for building agent-based\nsocieties. Various normative architectures have been proposed for designing\nnormative multi-agent systems (NorMAS). Due to human nature of the concept\nnorms, many of these architectures are built based on theories in social\nsciences. Tipping point theory, as is briefly discussed in this paper, seems to\nhave a great potential to be used for designing normative architectures. This\ntheory deals with the factors that affect social epidemics that arise in human\nsocieties. In this paper, we try to apply the main concepts of this theory to\nagent-based normative architectures. We show several ways to implement these\nconcepts, and study their effects in an agent-based normative scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.04531v1"
    },
    {
        "title": "Models and Representations for Fractal Social Organizations",
        "authors": [
            "Arianit Pajaziti"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Our subject is oriented towards investigation of potential ways of societal\norganization, that allow for collective intelligent organization and management\nof resources. The main objective of such organizations is the exploration of\nthe social energy from the existing societies. We conjecture that an\norganizational model that fulfills the mentioned requirements is the Fractal\nSocial Organization (FSO). Our goal is to prove and verify the effectiveness of\nthis model by performing various simulations using the NetLogo environment, a\ntool that allows agent-based rapid prototyping. We begin by simulating trivial\nreal life activities that demonstrate the main properties of the core unit of\nthe FSO, namely the SoC. Further, more complex scenarios involving various\nnested SoCs are simulated. Two main simulation models are presented, allowing\nus to obtain preliminary results using the FSO concepts as a potential\nsolution. In the first simulation model we demonstrate that by the use of FSO\nproperties the individuals may benefit by receiving more qualitative healthcare\nservices, while in the second simulation model we show how it might be possible\nto improve the fall detection systems by the use of FSO mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.05112v1"
    },
    {
        "title": "Comparison between purely statistical and multi-agent based ap-proaches\n  for occupant behaviour modeling in buildings",
        "authors": [
            "Khadija Tijani",
            "Ayesha Kashif",
            "Stéphane Ploix",
            "Benjamin Haas",
            "Julie Dugdale"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper analyzes two modeling approaches for occupant behaviour in\nbuildings. It compares a purely statistical approach with a multi-agent social\nsimulation based approach. The study concerns the door openings in an office.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.02225v1"
    },
    {
        "title": "Dynamic Group Behaviors for Interactive Crowd Simulation",
        "authors": [
            "Liang He",
            "Jia Pan",
            "Sahil Narang",
            "Wenping Wang",
            "Dinesh Manocha"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We present a new algorithm to simulate dynamic group behaviors for\ninteractive multi-agent crowd simulation. Our approach is general and makes no\nassumption about the environment, shape, or size of the groups. We use the\nleast effort principle to perform coherent group navigation and present\nefficient inter-group and intra-group maintenance techniques. We extend the\nreciprocal collision avoidance scheme to perform agent-group and group-group\ncollision avoidance that can generate collision-free as well as coherent and\ntrajectories. The additional overhead of dynamic group simulation is relatively\nsmall. We highlight its interactive performance on complex scenarios with\nhundreds of agents and compare the trajectory behaviors with real-world videos.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.03623v1"
    },
    {
        "title": "Wheeled Robots playing Chain Catch: Strategies and Evaluation",
        "authors": [
            "Garima Agrawal",
            "Kamalakar Karlapalem"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Robots playing games that humans are adept in is a challenge. We studied\nrobotic agents playing Chain Catch game as a Multi-Agent System (MAS). Our game\nstarts with a traditional Catch game similar to Pursuit evasion, and further\nextends it to form a growing chain of predator agents to chase remaining preys.\nHence Chain Catch is a combination of two challenges - pursuit domain and\nrobotic chain formation. These are games that require team of robotic agents to\ncooperate among themselves and to compete with other group of agents through\nquick decision making. In this paper, we present a Chain Catch simulator that\nallows us to incorporate game rules, design strategies and simulate the game\nplay. We developed cost model driven strategies for each of Escapee, Catcher\nand Chain. Our results show that Sliding slope strategy is the best strategy\nfor Escapees whereas Tagging method is the best method for chain s movement in\nChain Catch. We also use production quality robots to implement the game play\nin a physical environment and analyze game strategies on real robots. Our real\nrobots implementation in different scenarios shows that game strategies work as\nexpected and a complete chain formation takes place successfully in each game.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.06460v1"
    },
    {
        "title": "Modeling and Simulation of Passenger Traffic in a National Airport",
        "authors": [
            "Javier Enciso",
            "Juan Vargas",
            "Pablo Martínez"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Optimal operation of a country's air transport infrastructure plays a major\nrole in the economic development of nations. Due to the increasing use of air\ntransportation in today's world, flights' boarding times have become a concern\nfor both airlines and airports, thus the importance of knowing beforehand how\nchanges in flights demand parameters and physical airport layout will affect\npassengers flow and boarding times. This paper presents a pedestrian modeling\nstudy in which a national airport passenger flow was analyzed. The study was\nconducted at Vanguardia National Airport in Villavicencio, Meta, Colombia.\nDifferent effects of structural changes are shown and provide judging elements\nfor decision makers regarding passenger traffic in airport design.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02704v1"
    },
    {
        "title": "Influence of Agents Heterogeneity in Cellular Model of Evacuation",
        "authors": [
            "Pavel Hrabák",
            "Marek Bukáček"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  The influence of agents heterogeneity on the microscopic characteristics of\npedestrian flow is studied via an evacuation simulation tool based on the\nFloor-Field model. The heterogeneity is introduced in agents velocity,\naggressiveness, and sensitivity to occupation. The simulation results are\ncompared to data gathered during an original experiment. The comparison shows\nthat the heterogeneity in aggressiveness and sensitivity occupation enables to\nreproduce some microscopic aspects. The heterogeneity in velocity seems to be\nredundant.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.08226v1"
    },
    {
        "title": "An Introductory Course to Judgment Aggregation",
        "authors": [
            "Marija Slavkovik"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Reaching some form of consensus is often necessary for autonomous agents that\nwant to coordinate their actions or otherwise engage in joint activities. One\nway to reach a consensus is by aggregating individual information, such as\ndecisions, beliefs, preferences and constraints. Judgment aggregation is a\nsocial choice method, which generalises voting, that studies the aggregation of\nindividual judgments regarding the truth-value of logically related\npropositions. As such, judgment aggregation is applicable for consensus\nreaching problems in multi agent systems. As other social choice theory,\njudgment aggregation research is abundant with impossibility results. However,\nthe aim of this tutorial is to give an introduction to the methods of judgment\naggregation, not the impossibility results. In particular, the tutorial will\nintroduce the basic frameworks that model judgment aggregation problems and\ngive an overview of the judgment aggregation functions so far developed as well\nas their social theoretic and computational complexity properties. The focus of\nthe tutorial are consensus reaching problems in multi agent systems that can be\nmodelled as judgment aggregation problems. The desirable properties of a\njudgment aggregation method applied to these problems are not necessarily the\nsame as properties desirable in legal or political contexts, which is\nconsidered to be the native domain of judgment aggregation. After this tutorial\nthe participants are expected to be able to read and understand judgment\naggregation literature and have a grasp on the state-of-the-art and open\nquestions in judgment aggregation research of interest to multi agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.03307v1"
    },
    {
        "title": "Real-time Rescheduling in Distributed Railway Network: An Agent-Based\n  Approach",
        "authors": [
            "Poulami Dalapati",
            "Piyush Agarwal",
            "Animesh Dutta",
            "Swapan Bhattacharya"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This paper addresses the issues concerning the rescheduling of a static\ntimetable in case of a disaster encountered in a large and complex railway\nnetwork system. The proposed approach tries to modify the schedule so as to\nminimise the overall delay of trains. This is achieved by representing the\nrescheduling problem in the form of a Petri-Net and the highly uncertain\ndisaster recovery times in such a model is handled as Markov Decision Processes\n(MDP ). For solving the rescheduling problem, a istributed Constraint\nOptimisation (DCOP ) based strategy involving the use of autonomous agents is\nused to generate the desired schedule. The proposed approach is evaluated on\nthe actual schedule of the Eastern Railways, India by constructing vari- ous\ndisaster scenarios using the Java Agent DEvelopment Framework (JADE). When\ncompared to the existing approaches, the proposed framework substantially\nreduces the delay of trains after rescheduling.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.03340v1"
    },
    {
        "title": "Demand Control Management in Micro-grids: The Impact of Different\n  Policies and Communication Network Topologies",
        "authors": [
            "Florian Kühnlenz",
            "Pedro H. J. Nardelli",
            "Hirley Alves"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This work studies how the communication network between proactive consumers\naffects the power utilization and fairness in a simplified direct-current\nmicro-grid model, composed by three coupled layers: physical (an electric\ncircuit that represents a micro-grid), communication (a peer-to-peer network\nwithin the micro-grid) and regulatory (individual decision strategies). Our\nresults show that, for optimal power utilization and fairness, a global\nknowledge about the system is needed, demonstrating the importance of a\nmicro-grid aggregator to inform about the power consumption for different time\nperiods.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.01430v2"
    },
    {
        "title": "AntPaP: Patrolling and Fair Partitioning of Graphs by A(ge)nts Leaving\n  Pheromone Traces",
        "authors": [
            "Gidi Elazar",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  A team of identical and oblivious ant-like agents - a(ge)nts - leaving\npheromone traces, are programmed to jointly patrol an area modeled as a graph.\nThey perform this task using simple local interactions, while also achieving\nthe important byproduct of partitioning the graph into roughly equal-sized\ndisjoint sub-graphs. Each a(ge)nt begins to operate at an arbitrary initial\nlocation, and throughout its work does not acquire any information on either\nthe shape or size of the graph, or the number or whereabouts of other a(ge)nts.\nGraph partitioning occurs spontaneously, as each of the a(ge)nts patrols and\nexpands its own pheromone-marked sub-graph, or region. This graph partitioning\nalgorithm is inspired by molecules hitting the borders of air filled elastic\nballoons: an a(ge)nt that hits a border edge from the interior of its region\nmore frequently than an external a(ge)nt hits the same edge from an adjacent\nvertex in the neighboring region, may conquer that adjacent vertex, expanding\nits region at the expense of the neighbor. Since the rule of patrolling a\nregion ensures that each vertex is visited with a frequency inversely\nproportional to the size of the region, in terms of vertex count, a smaller\nregion will effectively exert higher \"pressure\" at its borders, and conquer\nadjacent vertices from a larger region, thereby increasing the smaller region\nand shrinking the larger. The algorithm, therefore, tends to equalize the sizes\nof the regions patrolled, resembling a set of perfectly elastic physical\nballoons, confined to a closed volume and filled with an equal amount of air.\nThe pheromone based local interactions of agents eventually cause the system to\nevolve into a partition that is close to balanced rather quickly, and if the\ngraph and the number of a(ge)nts remain unchanged, it is guaranteed that the\nsystem settles into a stable and balanced partition.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.04511v1"
    },
    {
        "title": "Essentials of an Integrated Crowd Management Support System Based on\n  Collective Artificial Intelligence",
        "authors": [
            "Giuseppe Vizzari",
            "Stefania Bandini"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  The simulation of the dynamical behavior of pedestrians and crowds in spatial\nstructures is a consolidated research and application context that still\npresents challenges for researchers in different fields and disciplines.\nDespite currently available commercial systems for this kind of simulation are\ngrowingly employed by designers and planners for the evaluation of alternative\nsolutions, this class of systems is generally not integrated with existing\nmonitoring and control infrastructures, usually employed by crowd managers and\nfield operators for security reasons. This paper introduces the essentials and\nthe related computational frame- work of an Integrated Crowd Management Support\nSystem based on a Collective Artificial Intelligence approach encompassing (i)\ninterfaces from and to monitored and controlled environments (respectively,\nsen- sors and actuators), (ii) a set of software tools supporting the analysis\nof pedestrians and crowd phenomena taking place in the environment to feed a\n(iii) faster than real-time simulation of the plausible evolution of the\ncurrent situation in order to support forms of inference provid- ing decision\nsupport to crowd managers, potentially directly controlling elements of the\nenvironment (e.g. blocking turnstiles, escalators), com- municating orders to\noperators on the field or trying to influence the pedestrians by means of\ndynamic signage or audible messages.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.04851v1"
    },
    {
        "title": "Optimal Demand Side Management by Distributed and Secured Energy\n  Commitment Framework",
        "authors": [
            "Shantanu Chakraborty",
            "Toshiya Okabe"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This paper introduces a demand-side distributed and secured energy commitment\nframework and operations for a Power Producer and Supplier (PPS) in deregulated\nenvironment. Due to the diversity of geographical location as well as\ncustomers' energy profile coupled with high number of customers, managing\nenergy transactions and resulting energy exchanges are challenging for a PPS.\nThe envisioned PPS maintains several aggregators (e.g. Microgrids), named as\nSub Service Provider (SSP) that manage customers/subscribers under their\ndomains. The SSPs act as agents that perform local energy matching (inside\ntheir domains) and distributed energy matching within SSPs to determine the\nenergy commitment. The goal of the distributed energy matching is to reduce the\ninvolvement of External Energy Supplier (e.g. Utility) while providing a\nplatform to demand side players to be a part of energy transaction. A\ndistributed assignment problem is designed that requires minimum and aggregated\ninformation exchange (hence, secured) and solved by Linear Programming (LP)\nthat provides the distributed matching decision. The communicative burden among\nSSPs due to the exchange of energy information is reduced by applying an\nadaptive coalition formation method. The simulations are conducted by\nimplementing a synchronous distributed matching algorithm while showing the\neffectiveness of the proposed framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.06166v1"
    },
    {
        "title": "Review on Microscopic Pedestrian Simulation Model",
        "authors": [
            "Kardi Teknomo",
            "Yasushi Takeyama",
            "Hajime Inamura"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Microscopic Pedestrian Simulation Model is computer simulation model of\npedestrian movement where every pedestrian in the model is treated as\nindividual. Most of pedestrian researches have been done on macroscopic level,\nwhich does not consider the interaction between pedestrians and does not well\nsuited for prediction of pedestrian flow performance in pedestrian areas or\nbuilding with some objects that reduce the effective width of it. In the other\nhand, microscopic level has more general usage and considers detail of the\ndesign. Tough the analytical model for microscopic pedestrian model is existed\nexist, the numerical solution of the model is very difficult and simulation is\nfavorable. The model has practical application of Evacuation from building,\nDesign of pedestrian area, and Experimental & Optimization Design Tool. In\ngeneral, Microscopic Pedestrian Simulation Model consist of two terms, that\nmake the pedestrian moving toward the destination and make repulsive effect\ntoward other pedestrian or obstacles.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.01808v1"
    },
    {
        "title": "Decentralized Non-communicating Multiagent Collision Avoidance with Deep\n  Reinforcement Learning",
        "authors": [
            "Yu Fan Chen",
            "Miao Liu",
            "Michael Everett",
            "Jonathan P. How"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Finding feasible, collision-free paths for multiagent systems can be\nchallenging, particularly in non-communicating scenarios where each agent's\nintent (e.g. goal) is unobservable to the others. In particular, finding time\nefficient paths often requires anticipating interaction with neighboring\nagents, the process of which can be computationally prohibitive. This work\npresents a decentralized multiagent collision avoidance algorithm based on a\nnovel application of deep reinforcement learning, which effectively offloads\nthe online computation (for predicting interaction patterns) to an offline\nlearning procedure. Specifically, the proposed approach develops a value\nnetwork that encodes the estimated time to the goal given an agent's joint\nconfiguration (positions and velocities) with its neighbors. Use of the value\nnetwork not only admits efficient (i.e., real-time implementable) queries for\nfinding a collision-free velocity vector, but also considers the uncertainty in\nthe other agents' motion. Simulation results show more than 26 percent\nimprovement in paths quality (i.e., time to reach the goal) when compared with\noptimal reciprocal collision avoidance (ORCA), a state-of-the-art collision\navoidance strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.07845v2"
    },
    {
        "title": "Predictive Positioning and Quality Of Service Ridesharing for Campus\n  Mobility On Demand Systems",
        "authors": [
            "Justin Miller",
            "Jonathan P. How"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Autonomous Mobility On Demand (MOD) systems can utilize fleet management\nstrategies in order to provide a high customer quality of service (QoS).\nPrevious works on autonomous MOD systems have developed methods for rebalancing\nsingle capacity vehicles, where QoS is maintained through large fleet sizing.\nThis work focuses on MOD systems utilizing a small number of vehicles, such as\nthose found on a campus, where additional vehicles cannot be introduced as\ndemand for rides increases. A predictive positioning method is presented for\nimproving customer QoS by identifying key locations to position the fleet in\norder to minimize expected customer wait time. Ridesharing is introduced as a\nmeans for improving customer QoS as arrival rates increase. However, with\nridesharing perceived QoS is dependent on an often unknown customer preference.\nTo address this challenge, a customer ratings model, which learns customer\npreference from a 5-star rating, is developed and incorporated directly into a\nridesharing algorithm. The predictive positioning and ridesharing methods are\napplied to simulation of a real-world campus MOD system.A combined predictive\npositioning and ridesharing approach is shown to reduce customer service times\nby up to 29% and the customer ratings model is shown to provide the best\noverall MOD fleet management performance over a range of customer preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.08116v2"
    },
    {
        "title": "Diffusion LMS for Multitask Problems with Local Linear Equality\n  Constraints",
        "authors": [
            "Roula Nassif",
            "Cédric Richard",
            "André Ferrari",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We consider distributed multitask learning problems over a network of agents\nwhere each agent is interested in estimating its own parameter vector, also\ncalled task, and where the tasks at neighboring agents are related according to\na set of linear equality constraints. Each agent possesses its own convex cost\nfunction of its parameter vector and a set of linear equality constraints\ninvolving its own parameter vector and the parameter vectors of its neighboring\nagents. We propose an adaptive stochastic algorithm based on the projection\ngradient method and diffusion strategies in order to allow the network to\noptimize the individual costs subject to all constraints. Although the\nderivation is carried out for linear equality constraints, the technique can be\napplied to other forms of convex constraints. We conduct a detailed\nmean-square-error analysis of the proposed algorithm and derive closed-form\nexpressions to predict its learning behavior. We provide simulations to\nillustrate the theoretical findings. Finally, the algorithm is employed for\nsolving two problems in a distributed manner: a minimum-cost flow problem over\na network and a space-time varying field reconstruction problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.02943v2"
    },
    {
        "title": "Towards Modelling Pedestrian-Vehicle Interactions: Empirical Study on\n  Urban Unsignalized Intersection",
        "authors": [
            "Andrea Gorrini",
            "Giuseppe Vizzari",
            "Stefania Bandini"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  The modelling and simulation of the interaction among vehicles and\npedestrians during cross-walking is an open challenge for both research and\npractical computational solutions supporting urban/traffic decision makers and\nmanagers. The social cost of pedestrians' risky behaviour pushes the\ndevelopment of a new generation of computational models integrating analytical\nknowledge, data and experience about the complex dynamics occurring in\npedestrian/vehicle interactions, which are not completely understood despite\nrecent efforts. This paper presents the results of a significant data gathering\ncampaign realised at an unsignalized zebra crossing. The selected area of the\ncity of Milan (Italy) is characterised by a significant presence of elderly\ninhabitants and pedestrian-vehicle risky interactions, testified by a high\nnumber of accidents involving pedestrians in the past years. The results\nconcern the analysis of: (i) vehicular and pedestrian traffic volumes; (ii)\nlevel of service; (iii) pedestrian-vehicle interactions, considering the impact\nof ageing on crossing behaviour. Results showed that the phenomenon is\ncharacterised by three main phases: approaching, appraising (evaluation of the\ndistance and speed of oncoming vehicles) and crossing. The final objective of\nthe research is to support the development of a microscopic agent-based tool\nfor simulating pedestrian behaviour at unsignalized crosswalks, focusing on the\nspecific needs of the elderly pedestrians.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.07892v1"
    },
    {
        "title": "Avoid or Follow? Modelling Route Choice Based on Experimental Empirical\n  Evidences",
        "authors": [
            "Luca Crociani",
            "Daichi Yanagisawa",
            "Giuseppe Vizzari",
            "Katsuhiro Nishinari",
            "Stefania Bandini"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Computer-based simulation of pedestrian dynamics reached meaningful results\nin the last decade, thanks to empirical evidences and acquired knowledge\nfitting fundamental diagram constraints and space utilization. Moreover,\ncomputational models for pedestrian wayfinding often neglect extensive\nempirical evidences supporting the calibration and validation phase of\nsimulations. The paper presents the results of a set of controlled experiments\n(with human volunteers) designed and performed to understand pedestrian's route\nchoice. The setting offers alternative paths to final destinations, at\ndifferent crowding conditions. Results show that the length of paths and level\nof congestion influence decisions (negative feedback), as well as imitative\nbehaviour of \"emergent leaders\" choosing a new path (positive feedback). A\nnovel here illustrated model for the simulation of pedestrian route choice\ncaptures such evidences, encompassing both the tendency to avoid congestion and\nto follow emerging leaders. The found conflicting tendencies are modelled with\nthe introduction of a utility function allowing a consistent calibration over\nthe achieved results. A demonstration of the simulated dynamics on a larger\nscenario will be also illustrated in the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.07901v1"
    },
    {
        "title": "The Composition and Formation of Effective Teams. Computer Science meets\n  Psychology",
        "authors": [
            "Ewa Andrejczuk",
            "Rita Berger",
            "Juan A. Rodriguez-Aguilar",
            "Carles Sierra",
            "Víctor Marín-Puchades"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Nowadays the composition and formation of effective teams is highly important\nfor both companies to assure their competitiveness and for a wide range of\nemerging applications exploiting multiagent collaboration (e.g. crowdsourcing,\nhuman-agent collaborations). The aim of this article is to provide an\nintegrative perspective on team composition, team formation and their\nrelationship with team performance. Thus, we review the contributions in both\nthe computer science literature and the organisational psychology literature\ndealing with these topics. Our purpose is twofold. First, we aim at identifying\nthe strengths and weaknesses of the contributions made by these two diverse\nbodies of research. Second, we pursue to identify cross-fertilisation\nopportunities that help both disciplines benefit from one another. Given the\nvolume of existing literature, our review is not intended to be exhaustive.\nInstead, we have preferred to focus on the most significant contributions in\nboth fields together with recent contributions that break new ground to spur\ninnovative research.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.08804v1"
    },
    {
        "title": "Context-Based Concurrent Experience Sharing in Multiagent Systems",
        "authors": [
            "Dan Garant",
            "Bruno da Silva",
            "Victor Lesser",
            "Chongjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  One of the key challenges for multi-agent learning is scalability. In this\npaper, we introduce a technique for speeding up multi-agent learning by\nexploiting concurrent and incremental experience sharing. This solution\nadaptively identifies opportunities to transfer experiences between agents and\nallows for the rapid acquisition of appropriate policies in large-scale,\nstochastic, homogeneous multi-agent systems. We introduce an online,\ndistributed, supervisor-directed transfer technique for constructing high-level\ncharacterizations of an agent's dynamic learning environment---called\ncontexts---which are used to identify groups of agents operating under\napproximately similar dynamics within a short temporal window. A set of\nsupervisory agents computes contextual information for groups of subordinate\nagents, thereby identifying candidates for experience sharing. Our method uses\na tiered architecture to propagate, with low communication overhead, state,\naction, and reward data amongst the members of each dynamically-identified\ninformation-sharing group. We applied this method to a large-scale distributed\ntask allocation problem with hundreds of information-sharing agents operating\nin an unknown, non-stationary environment. We demonstrate that our approach\nresults in significant performance gains, that it is robust to noise-corrupted\nor suboptimal context features, and that communication costs scale linearly\nwith the supervisor-to-subordinate ratio.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.01931v1"
    },
    {
        "title": "Vocabulary Alignment in Openly Specified Interactions",
        "authors": [
            "Paula Chocron",
            "Marco Schorlemmer"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The problem of achieving common understanding between agents that use\ndifferent vocabularies has been mainly addressed by designing techniques that\nexplicitly negotiate mappings between their vocabularies, requiring agents to\nshare a meta-language. In this paper we consider the case of agents that use\ndifferent vocabularies and have no meta-language in common, but share the\nknowledge of how to perform a task, given by the specification of an\ninteraction protocol. For this situation, we present a framework that lets\nagents learn a vocabulary alignment from the experience of interacting. Unlike\nprevious work in this direction, we use open protocols that constrain possible\nactions instead of defining procedures, making our approach more general. We\npresent two techniques that can be used either to learn an alignment from\nscratch or to repair an existent one, and we evaluate experimentally their\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.02367v1"
    },
    {
        "title": "On time and consistency in multi-level agent-based simulations",
        "authors": [
            "Gildas Morvan",
            "Yoann Kubera"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The integration of multiple viewpoints became an increasingly popular\napproach to deal with agent-based simulations. Despite their disparities,\nrecent approaches successfully manage to run such multi-level simulations. Yet,\nare they doing it appropriately?\n  This paper tries to answer that question, with an analysis based on a generic\nmodel of the temporal dynamics of multi-level simulations. This generic model\nis then used to build an orthogonal approach to multi-level simulation called\nSIMILAR. In this approach, most time-related issues are explicitly modeled,\nowing to an implementation-oriented approach based on the influence/reaction\nprinciple.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.02399v1"
    },
    {
        "title": "Automating decision making to help establish norm-based regulations",
        "authors": [
            "Maite Lopez-Sanchez",
            "Marc Serramia",
            "Juan A. Rodriguez-Aguilar",
            "Javier Morales",
            "Michael Wooldridge"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Norms have been extensively proposed as coordination mechanisms for both\nagent and human societies. Nevertheless, choosing the norms to regulate a\nsociety is by no means straightforward. The reasons are twofold. First, the\nnorms to choose from may not be independent (i.e, they can be related to each\nother). Second, different preference criteria may be applied when choosing the\nnorms to enact. This paper advances the state of the art by modeling a series\nof decision-making problems that regulation authorities confront when choosing\nthe policies to establish. In order to do so, we first identify three different\nnorm relationships -namely, generalisation, exclusivity, and substitutability-\nand we then consider norm representation power, cost, and associated moral\nvalues as alternative preference criteria. Thereafter, we show that the\ndecision-making problems faced by policy makers can be encoded as linear\nprograms, and hence solved with the aid of state-of-the-art solvers.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.09087v2"
    },
    {
        "title": "A Cooperative Enterprise Agent Based Control Architecture",
        "authors": [
            "Simona Caramihai",
            "Ioan Dumitrache",
            "Aurelian Stanescu",
            "Janetta Culita"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The paper proposes a hierarchical, agent-based, DES supported, distributed\narchitecture for networked organization control. Taking into account enterprise\nintegration engineering frameworks and business process management techniques,\nthe paper intends to apply control engineering approaches for solving some\nproblems of coordinating networked organizations, such as performance\nevaluation and optimization of workflows.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.02935v1"
    },
    {
        "title": "Distributed Proportional-Fairness Control in MicroGrids via Blockchain\n  Smart Contracts",
        "authors": [
            "Pietro Danzi",
            "Marko Angjelichinoski",
            "Čedomir Stefanović",
            "Petar Popovski"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Residential microgrids (MGs) may host a large number of Distributed Energy\nResources (DERs). The strategy that maximizes the revenue for each individual\nDER is the one in which the DER operates at capacity, injecting all available\npower into the grid. However, when the DER penetration is high and the\nconsumption low, this strategy may lead to power surplus that causes voltage\nincrease over recommended limits. In order to create incentives for the DER to\noperate below capacity, we propose a proportional-fairness control strategy in\nwhich (i) a subset of DERs decrease their own power output, sacrificing the\nindividual revenue, and (ii) the DERs in the subset are dynamically selected\nbased on the record of their control history. The trustworthy implementation of\nthe scheme is carried out through a custom-designed blockchain mechanism that\nmaintains a distributed database trusted by all DERs. In particular, the\nblockchain is used to stipulate and store a smart contract that enforces\nproportional fairness. The simulation results verify the potential of the\nproposed framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.01453v2"
    },
    {
        "title": "Applying Artificial Intelligence and Internet Techniques in Rural\n  Tourism Domain",
        "authors": [
            "Cristina Turcu",
            "Cornel Turcu"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Society has become more dependent on automated intelligent systems, at the\nsame time, these systems have become more and more complicated. Society's\nexpectation regarding the capabilities and intelligence of such systems has\nalso grown. We have become a more complicated society with more complicated\nproblems. As the expectation of intelligent systems rises, we discover many\nmore applications for artificial intelligence. Additionally, as the difficulty\nlevel and computational requirements of such problems rise, there is a need to\ndistribute the problem solving. Although the field of multiagent systems (MAS)\nand distributed artificial intelligence (DAI) is relatively young, the\nimportance and applicability of this technology for solving today's problems\ncontinue to grow. In multiagent systems, the main goal is to provide fruitful\ncooperation among agents in order to enrich the support given to all user\nactivities. This paper deals with the development of a multiagent system aimed\nat solving the reservation problems encountered in rural tourism. Due to their\nbenefits over the last few years, online travel agencies have become a very\nuseful instrument in planning vacations. A MAS concept (which is based on the\nInternet exploitation) can improve this activity and provide clients with a\nnew, rapid and efficient way of making accommodation arrangements.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.09838v1"
    },
    {
        "title": "Distributed multi-agent Gaussian regression via finite-dimensional\n  approximations",
        "authors": [
            "Gianluigi Pillonetto",
            "Luca Schenato",
            "Damiano Varagnolo"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We consider the problem of distributedly estimating Gaussian processes in\nmulti-agent frameworks. Each agent collects few measurements and aims to\ncollaboratively reconstruct a common estimate based on all data. Agents are\nassumed with limited computational and communication capabilities and to gather\n$M$ noisy measurements in total on input locations independently drawn from a\nknown common probability density. The optimal solution would require agents to\nexchange all the $M$ input locations and measurements and then invert an $M\n\\times M$ matrix, a non-scalable task. Differently, we propose two suboptimal\napproaches using the first $E$ orthonormal eigenfunctions obtained from the\n\\ac{KL} expansion of the chosen kernel, where typically $E \\ll M$. The benefits\nare that the computation and communication complexities scale with $E$ and not\nwith $M$, and computing the required statistics can be performed via standard\naverage consensus algorithms. We obtain probabilistic non-asymptotic bounds\nthat determine a priori the desired level of estimation accuracy, and new\ndistributed strategies relying on Stein's unbiased risk estimate (SURE)\nparadigms for tuning the regularization parameters and applicable to generic\nbasis functions (thus not necessarily kernel eigenfunctions) and that can again\nbe implemented via average consensus. The proposed estimators and bounds are\nfinally tested on both synthetic and real field data.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.00194v2"
    },
    {
        "title": "Impact of Mobility-on-Demand on Traffic Congestion: Simulation-based\n  Study",
        "authors": [
            "David Fiedler",
            "Michal Čáp",
            "Michal Čertický"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The increasing use of private vehicles for transportation in cities results\nin a growing demand for parking space and road network capacity. In many\ndensely populated urban areas, however, the capacity of existing infrastructure\nis insufficient and extremely difficult to expand. Mobility-on-demand systems\nhave been proposed as a remedy to the problem of limited parking space because\nthey are able to satisfy the existing transportation demand with fewer shared\nvehicles and consequently require less parking space. Yet, the impact of\nlarge-scale vehicle sharing on traffic patterns is not well understood. In this\nwork, we perform a simulation-based analysis of consequences of a hypothetical\ndeployment of a large-scale station-based mobility-on-demand system in Prague\nand measure the traffic intensity generated by the system and its effects on\nthe formation of congestion. We find that such a mobility-on-demand system\nwould lead to significantly increased total driven distance and it would also\nincrease levels of congestion due to extra trips without passengers. In fact,\n38% kilometers traveled in such an MoD system would be driven empty.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.02484v1"
    },
    {
        "title": "Dynamic Switching Networks: A Dynamic, Non-local, and Time-independent\n  Approach to Emergence",
        "authors": [
            "A. M. Khalili"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The concept of emergence is a powerful concept to explain very complex\nbehaviour by simple underling rules. Existing approaches of producing emergent\ncollective behaviour have many limitations making them unable to account for\nthe complexity we see in the real world. In this paper we propose a new\ndynamic, non-local, and time independent approach that uses a network like\nstructure to implement the laws or the rules, where the mathematical equations\nrepresenting the rules are converted to a series of switching decisions carried\nout by the network on the particles moving in the network. The proposed\napproach is used to generate patterns with different types of symmetry.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.04513v3"
    },
    {
        "title": "Potentials and Implications of Dedicated Highway Lanes for Autonomous\n  Vehicles",
        "authors": [
            "Jordan Ivanchev",
            "Alois Knoll",
            "Daniel Zehe",
            "Suraj Nair",
            "David Eckhoff"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The introduction of autonomous vehicles (AVs) will have far-reaching effects\non road traffic in cities and on highways.The implementation of automated\nhighway system (AHS), possibly with a dedicated lane only for AVs, is believed\nto be a requirement to maximise the benefit from the advantages of AVs. We\nstudy the ramifications of an increasing percentage of AVs on the traffic\nsystem with and without the introduction of a dedicated AV lane on highways. We\nconduct an analytical evaluation of a simplified scenario and a macroscopic\nsimulation of the city of Singapore under user equilibrium conditions with a\nrealistic traffic demand. We present findings regarding average travel time,\nfuel consumption, throughput and road usage. Instead of only considering the\nhighways, we also focus on the effects on the remaining road network. Our\nresults show a reduction of average travel time and fuel consumption as a\nresult of increasing the portion of AVs in the system. We show that the\nintroduction of an AV lane is not beneficial in terms of average commute time.\nExamining the effects of the AV population only, however, the AV lane provides\na considerable reduction of travel time (approx. 25%) at the price of delaying\nconventional vehicles (approx. 7%). Furthermore a notable shift of travel\ndemand away from the highways towards major and small roads is noticed in early\nstages of AV penetration of the system. Finally, our findings show that after a\ncertain threshold percentage of AVs the differences between AV and no AV lane\nscenarios become negligible.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.07658v1"
    },
    {
        "title": "Dynamic Path Planning and Movement Control in Pedestrian Simulation",
        "authors": [
            "Fatema Tuj Johora",
            "Philipp Kraus",
            "Jörg P. Müller"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Modeling and simulation of pedestrian behavior is used in applications such\nas planning large buildings, disaster management, or urban planning.\nRealistically simulating pedestrian behavior is challenging, due to the\ncomplexity of individual behavior as well as the complexity of interactions of\npedestrians with each other and with the environment. This work-in-progress\npaper addresses the tactical (path planning) and the operational level\n(movement control) of pedestrian simulation from the perspective of\nmultiagent-based modeling. We propose (1) an novel extension of the JPS routing\nalgorithm for tactical planning, and (2) an architecture how path planning can\nbe integrated with a social-force based movement control. The architecture is\ninspired by layered architectures for robot planning and control. We validate\ncorrectness and efficiency of our approach through simulation runs.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.08235v1"
    },
    {
        "title": "A Coalition Formation Approach to Coordinated Task Allocation in\n  Heterogeneous UAV Networks",
        "authors": [
            "Fatemeh Afghah",
            "Mohammad Zaeri-Amirani",
            "Abolfazl Razi",
            "Jacob Chakareski",
            "Elizabeth Bentley"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The problem of adversary target detection and the subsequent task completion\nusing a heterogeneous network of resource-constrained UAVs is considered. No\nprior knowledge about locations and required resources to identify these\ntargets is available to the UAVs. In the proposed leader-follower coalition\nformation model, the UAV that first locates a target serves as the coalition\nleader and selects a group of follower UAVs to complete the task associated\nwith the identified target. The goal of the coalition formation is to complete\nthe designated tasks with minimal resource utilization. Another role of\ncoalition members is to make the ground station aware of the detected adversary\ntarget by forwarding its signal to the station via a distributed cooperative\nrelaying scheme. We also propose a reputation-based mechanism for coalition\nformation to monitor the cooperative behavior of the UAVs over the course of\ntime and exclude potentially untrustworthy UAVs. Simulation results show the\nefficiency of the proposed method in forming optimal coalitions compared to\nalternative methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.00214v1"
    },
    {
        "title": "Internalising Interaction Protocols as First-Class Programming Elements\n  in Multi Agent Systems",
        "authors": [
            "David J. Lillis"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Since their inception, Multi Agent Systems (MASs) have been championed as a\nsolution for the increasing problem of software complexity. Communities of\ndistributed autonomous computing entities that are capable of collaborating,\nnegotiating and acting to solve complex organisational and system management\nproblems are an attractive proposition. Central to this is the requirement for\nagents to possess the capability of interacting with one another in a\nstructured, consistent and organised manner.\n  This thesis presents the Agent Conversation Reasoning Engine (ACRE), which\nconstitutes a holistic view of communication management for MASs. ACRE is\nintended to facilitate the practical development, debugging and deployment of\ncommunication-heavy MASs.\n  ACRE has been formally defined in terms of its operational semantics, and a\ngeneric architecture has been proposed to facilitate its integration with a\nwide variety of diverse agent development frameworks and Agent Oriented\nProgramming (AOP) languages. A concrete implementation has also been developed\nthat uses the Agent Factory AOP framework as its base. This allows ACRE to be\nused with a number of different AOP languages, while providing a reference\nimplementation that other integrations can be modelled upon. A standard is also\nproposed for the modelling and sharing of agent-focused interaction protocols\nthat is independent of the platform within which a concrete ACRE implementation\nis run.\n  Finally, a user evaluation illustrates the benefits of incorporating\nconversation management into agent programming.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.02634v1"
    },
    {
        "title": "Multi-agent based IoT smart waste monitoring and collection architecture",
        "authors": [
            "Eunice David Likotiko",
            "Devotha Nyambo",
            "Joseph Mwangoka"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Solid waste management is one of the existing challenges in urban areas and\nit is becoming a critical issue due to rapid increase in population.\nAppropriate solid waste management systems are important for improving the\nenvironment and the well being of residents. In this paper, an Internet of\nThings (IoT) architecture for real time waste monitoring and collection has\nbeen proposed; able to improve and optimize solid waste collection in a city.\nNetlogo Multiagent platform has been used to simulate real time monitoring and\nsmart decisions on waste management. Waste filling level in bins and truck\ncollection process are abstracted to a multiagent model and citizen are\ninvolved by paying the price for waste collection services. Furthermore, waste\nlevel data are updated and recorded continuously and are provided to decision\nalgorithms to determine the vehicle optimal route for waste collection to the\ndistributed bins in the city. Several simulation cases executed and results\nvalidated. The presented solution gives substantial benefits to all waste\nstakeholders by enabling the waste collection process to be more efficient.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.03966v1"
    },
    {
        "title": "Robust Environmental Mapping by Mobile Sensor Networks",
        "authors": [
            "Hyongju Park",
            "Jinsun Liu",
            "Matthew Johnson-Roberson",
            "Ram Vasudevan"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Constructing a spatial map of environmental parameters is a crucial step to\npreventing hazardous chemical leakages, forest fires, or while estimating a\nspatially distributed physical quantities such as terrain elevation. Although\nprior methods can do such mapping tasks efficiently via dispatching a group of\nautonomous agents, they are unable to ensure satisfactory convergence to the\nunderlying ground truth distribution in a decentralized manner when any of the\nagents fail. Since the types of agents utilized to perform such mapping are\ntypically inexpensive and prone to failure, this results in poor overall\nmapping performance in real-world applications, which can in certain cases\nendanger human safety. This paper presents a Bayesian approach for robust\nspatial mapping of environmental parameters by deploying a group of mobile\nrobots capable of ad-hoc communication equipped with short-range sensors in the\npresence of hardware failures. Our approach first utilizes a variant of the\nVoronoi diagram to partition the region to be mapped into disjoint regions that\nare each associated with at least one robot. These robots are then deployed in\na decentralized manner to maximize the likelihood that at least one robot\ndetects every target in their associated region despite a non-zero probability\nof failure. A suite of simulation results is presented to demonstrate the\neffectiveness and robustness of the proposed method when compared to existing\ntechniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.07510v2"
    },
    {
        "title": "Cellular Automata Simulation on FPGA for Training Neural Networks with\n  Virtual World Imagery",
        "authors": [
            "Olivier Van Acker",
            "Oded Lachish",
            "Graeme Burnett"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We present ongoing work on a tool that consists of two parts: (i) A raw\nmicro-level abstract world simulator with an interface to (ii) a 3D game\nengine, translator of raw abstract simulator data to photorealistic graphics.\nPart (i) implements a dedicated cellular automata (CA) on reconfigurable\nhardware (FPGA) and part (ii) interfaces with a deep learning framework for\ntraining neural networks. The bottleneck of such an architecture usually lies\nin the fact that transferring the state of the whole CA significantly slows\ndown the simulation. We bypass this by sending only a small subset of the\ngeneral state, which we call a 'locus of visibility', akin to a torchlight in a\ndarkened 3D space, into the simulation. The torchlight concept exists in many\ngames but these games generally only simulate what is in or near the locus. Our\nchosen architecture will enable us to simulate on a micro level outside the\nlocus. This will give us the advantage of being able to create a larger and\nmore fine-grained simulation which can be used to train neural networks for use\nin games.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.07951v1"
    },
    {
        "title": "A-Evac: the evacuation simulator for stochastic environment",
        "authors": [
            "Adam Krasuski",
            "Karol Krenski"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We introduce an open-source software Aamks for fire risk assessment. This\narticle focuses on a component of Aamks - an evacuation simulator named a-evac.\nA-evac models evacuation of humans in the fire environment produced by CFAST\nfire simulator. In the article we discuss the probabilistic evacuation\napproach, automatic planning of exit routes, the interactions amongst the\nmoving evacuees and the impact of smoke on the humans. The results consist of\nrisk values based on FED, F-N curves and evacuation animations.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09229v1"
    },
    {
        "title": "Data Backup Network Formation with Heterogeneous Agents",
        "authors": [
            "Harshit Jain",
            "Guduru Sai Teja",
            "Pramod Mane",
            "Kapil Ahuja",
            "Nagarajan Krishnamurthy"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Social storage systems are becoming increasingly popular compared to the\nexisting data backup systems like local, centralized and P2P systems. An\nendogenously built symmetric social storage model and its aspects like the\nutility of each agent, bilateral stability, contentment, and efficiency have\nbeen extensively discussed in Mane et. al. (2017). We include heterogeneity in\nthis model by using the concept of Social Range Matrix from Kuznetsov et. al\n(2010).\n  Now, each agent is concerned about its perceived utility, which is a linear\ncombination of its utility as well as others utilities (depending upon whether\nthe pair are friends, enemies or do not care about each other). We derive\nconditions when two agents may want to add or delete a link, and provide an\nalgorithm that checks if a bilaterally stable network is possible or not.\nFinally, we take some special Social Range Matrices and prove that under\ncertain conditions on network parameters, a bilaterally stable network is\nunique.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.10283v1"
    },
    {
        "title": "The Role of Compliance in Heterogeneous Interacting Agents: Data from\n  Observations",
        "authors": [
            "Stefania Bandini",
            "Luca Crociani",
            "Giuseppe Vizzari",
            "Flavio Soares Correa da Silva",
            "Andrea Gorrini"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The dynamics of agent-based systems provide a framework to face the\ncomplexity of pedestrian-vehicle interactions in future cities, in which the\ncompliance to traffic norms plays a fundamental role. The data of an\nobservation performed at a non-signalized intersection are presented to provide\nuseful insights for supporting the future development of agent-based models.\nResults focus on drivers' compliance to crossing pedestrians, describing\npotentially conflictual interactions among heterogeneous agents. The discussion\ncloses with the potential applications of the collected data set for modelling\nthe phenomenon.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.01648v1"
    },
    {
        "title": "Machine Learning simulates Agent-Based Model",
        "authors": [
            "Bernardo Alves Furtado"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Running agent-based models (ABMs) is a burdensome computational task,\nspecially so when considering the flexibility ABMs intrinsically provide. This\npaper uses a bundle of model configuration parameters along with obtained\nresults from a validated ABM to train some Machine Learning methods for\nsocioeconomic optimal cases. A larger space of possible parameters and\ncombinations of parameters are then used as input to predict optimal cases and\nconfirm parameters calibration. Analysis of the parameters of the optimal cases\nare then compared to the baseline model. This exploratory initial exercise\nconfirms the adequacy of most of the parameters and rules and suggests changing\nof directions to two parameters. Additionally, it helps highlight metropolitan\nregions of higher quality of life. Better understanding of ABM mechanisms and\nparameters' influence may nudge policy-making slightly closer to optimal level.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04429v2"
    },
    {
        "title": "Priority Rules on ATN (PRT) Intersections",
        "authors": [
            "Waldemar Grabski",
            "Wiktor B. Daszczuk"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In Autonomous Transit Networks some basic elements influence the throughput:\nnetwork structure, maximum velocity, number of vehicles etc. Other parameters\nlike station structure, dynamic routing or vehicle behavior on intersections\nplay minor role. Yet in highly congested nets, when vehicles interfere in the\ntraffic, some subtle decisions may influence overall system ridership. We\ntested the impact of intersection priority rules on passenger waiting time,\nwhich measures the throughput. The dependence occurred its relevance in a\ncrowded network.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.05987v1"
    },
    {
        "title": "Using Machine Learning to Enhance Vehicles Traffic in ATN (PRT) Systems",
        "authors": [
            "Bogdan Czejdo",
            "Wiktor B. Daszczuk",
            "Mikołaj Baszun"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper discusses new techniques to enhance Automated Transit Networks\n(ATN, previously called Personal Rapid Transit - PRT) based on Artificial\nIntelligence tools. The main direction is improvement of the cooperation of\nautonomous modules that use negotiation protocols, following the IoT paradigm.\nOne of the goals is to increase ATN system throughput by tuning up autonomous\nvehicles cooperation. Machine learning (ML) was used to improve algorithms\ndesigned by human programmers. We used \"existing controls\" corresponding to\nnear-optimal solutions and built refinement models to more accurately relate a\nsystem's dynamics to its performance. A mechanism that mostly influences ATN\nperformance is Empty Vehicle Management (EVM). The algorithms designed by human\nprogrammers was used: calls to empty vehicles for waiting passengers and\nbalancing based on reallocation of empty vehicles to achieve better regularity\nof their settlement. In this paper we discuss how we can improve these\nalgorithms (and tune them to current conditions) by using ML to tailor\nindividual behavioral policies. Using ML techniques was possible because our\nalgorithm is based on a set of parameters. A number of weights and thresholds\ncould be tuned up to give better decisions on moving empty vehicles across the\ntrack.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.05990v1"
    },
    {
        "title": "Emotion-Based Crowd Simulation Model Based on Physical Strength\n  Consumption for Emergency Scenarios",
        "authors": [
            "Mingliang Xu",
            "Chaochao Li",
            "Pei Lv",
            "Wei Chen",
            "Zhigang Deng",
            "Bing Zhou",
            "Dinesh Manocha"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Increasing attention is being given to the modeling and simulation of traffic\nflow and crowd movement, two phenomena that both deal with interactions between\npedestrians and cars in many situations. In particular, crowd simulation is\nimportant for understanding mobility and transportation patterns. In this\npaper, we propose an emotion-based crowd simulation model integrating physical\nstrength consumption. Inspired by the theory of \"the devoted actor,\" the\nmovements of each individual in our model are determined by modeling the\ninfluence of physical strength consumption and the emotion of panic. In\nparticular, human physical strength consumption is computed using a\nphysics-based numerical method. Inspired by the James-Lange theory, panic\nlevels are estimated by means of an enhanced emotional contagion model that\nleverages the inherent relationship between physical strength consumption and\npanic. To the best of our knowledge, our model is the first method integrating\nphysical strength consumption into an emotion-based crowd simulation model by\nexploiting the relationship between physical strength consumption and emotion.\nWe highlight the performance on different scenarios and compare the resulting\nbehaviors with real-world video sequences. Our approach can reliably predict\nchanges in physical strength consumption and panic levels of individuals in an\nemergency situation.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.00216v4"
    },
    {
        "title": "PolicySpace: a modeling platform",
        "authors": [
            "Bernardo Alves Furtado"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Public Policy involves proposing changes to existing practices, alternatives,\nnew habits. Citizens and institutions react accordingly, accepting, refuting or\nadapting. Agent-based modeling is a tool that can enrich the policy analysis\npackage explicitly considering dynamics, space and individual-level\ninteractions. This paper presents a modeling platform called PolicySpace that\nmodels public policies within an empirical, spatial environment using data from\n46 metropolitan regions in Brazil. We describe the basics of the model, its\nagents and markets, the tax scheme, the parametrization, and how to run the\nmodel. Finally, we validate the model and demonstrate an application of the\nfiscal analysis. Besides providing the basics of the platform, our results\nindicate the relevance of the rules of taxes transfer for cities' quality of\nlife.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.00259v1"
    },
    {
        "title": "Comparative Analysis of Human Movement Prediction: Space Syntax and\n  Inverse Reinforcement Learning",
        "authors": [
            "Soma Suzuki"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Space syntax matrix has been the main approach for human movement prediction\nin the urban environment. An alternative, relatively new methodology is an\nagent-based pedestrian model constructed using machine learning techniques.\nEven though both approaches have been studied intensively, the quantitative\ncomparison between them has not been conducted. In this paper, comparative\nanalysis of space syntax metrics and maximum entropy inverse reinforcement\nlearning (MEIRL) is performed. The experimental result on trajectory data of\nartificially generated pedestrian agents shows that MEIRL outperforms space\nsyntax matrix. The possibilities for combining two methods are drawn out as\nconclusions, and the relative challenges with the data collection are\nhighlighted.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.00464v2"
    },
    {
        "title": "Active repositioning of storage units in Robotic Mobile Fulfillment\n  Systems",
        "authors": [
            "Marius Merschformann"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In our work we focus on Robotic Mobile Fulfillment Systems in e-commerce\ndistribution centers. These systems were designed to increase pick rates by\nemploying mobile robots bringing movable storage units (so-called pods) to pick\nand replenishment stations as needed, and back to the storage area afterwards.\nOne advantage of this approach is that repositioning of inventory can be done\ncontinuously, even during pick and replenishment operations. This is primarily\naccomplished by bringing a pod to a storage location different than the one it\nwas fetched from, a process we call passive pod repositioning. Additionally,\nthis can be done by explicitly bringing a pod from one storage location to\nanother, a process we call active pod repositioning. In this work we introduce\nfirst mechanisms for the latter technique and conduct a simulation-based\nexperiment to give first insights of their effect.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.04105v1"
    },
    {
        "title": "Preventing Social Disappointment in Elections",
        "authors": [
            "Mohammad Ali Javidian",
            "Pooyan Jamshidi",
            "Marco Valtorta",
            "Rasoul Ramezanian"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Mechanism design is concerned with settings where a policymaker (or social\nplanner) faces the problem of aggregating the announced preferences of multiple\nagents into a collective (or social), system-wide decision. One of the most\nimportant ways for aggregating preference that has been used in multi-agent\nsystems is election. In an election, the aim is to select the candidate who\nreflects the common will of society. Despite the importance of this subject, in\nsome situations, the result of the election does not respect the purpose of\nthose who execute it and the election leads to dissatisfaction of a large\namount of people and in some cases causes polarization in societies. To analyze\nthese situations, we introduce a new notion called social disappointment and we\nshow which voting rules can prevent it in elections. In addition, we propose\nnew protocols to prevent social disappointment in elections. A version of the\nimpossibility theorem is proved regarding social disappointment in elections,\nshowing that there is no voting rule for four or more candidates that\nsimultaneously satisfies avoiding social disappointment and Condorcet winner\ncriteria. We give conditions under which one of our new protocols always\nselects the Condorcet winner under the assumption of single peakedness. We\nempirically compare our protocols with seven well-known other voting protocols\nand observe that our protocols are capable of preventing social disappointment\nand are more robust against manipulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05911v4"
    },
    {
        "title": "Decision Rules for Robotic Mobile Fulfillment Systems",
        "authors": [
            "Marius Merschformann",
            "Tim Lamballais",
            "René de Koster",
            "Leena Suhl"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The Robotic Mobile Fulfillment Systems (RMFS) is a new type of robotized,\nparts-to-picker material handling system, designed especially for e-commerce\nwarehouses. Robots bring movable shelves, called pods, to workstations where\ninventory is put on or removed from the pods. This paper simulates both the\npick and replenishment process and studies the order assignment, pod selection\nand pod storage assignment problems by evaluating multiple decision rules per\nproblem. The discrete event simulation uses realistic robot movements and keeps\ntrack of every unit of inventory on every pod. We analyze seven performance\nmeasures, e.g. throughput capacity and order due time, and find that the unit\nthroughput is strongly correlated with the other performance measures. We vary\nthe number of robots, the number of pick stations, the number of SKUs (stock\nkeeping units), the order size and whether returns need processing or not. The\ndecision rules for pick order assignment have a strong impact on the unit\nthroughput rate. This is not the case for replenishment order assignment, pod\nselection and pod storage. Furthermore, for warehouses with a large number of\nSKUs, more robots are needed for a high unit throughput rate, even if the\nnumber of pods and the dimensions of the storage area remain the same. Lastly,\nprocessing return orders only affects the unit throughput rate for warehouse\nwith a large number of SKUs and large pick orders.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.06703v1"
    },
    {
        "title": "Courtesy as a Means to Coordinate",
        "authors": [
            "Panayiotis Danassis",
            "Boi Faltings"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We investigate the problem of multi-agent coordination under rationality\nconstraints. Specifically, role allocation, task assignment, resource\nallocation, etc. Inspired by human behavior, we propose a framework (CA^3NONY)\nthat enables fast convergence to efficient and fair allocations based on a\nsimple convention of courtesy. We prove that following such convention induces\na strategy which constitutes an $\\epsilon$-subgame-perfect equilibrium of the\nrepeated allocation game with discounting. Simulation results highlight the\neffectiveness of CA^3NONY as compared to state-of-the-art bandit algorithms,\nsince it achieves more than two orders of magnitude faster convergence, higher\nefficiency, fairness, and average payoff.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07140v5"
    },
    {
        "title": "An Agent-Based Simulation Model for Optimization of the Signalized\n  Intersection Connected to Freeway On-Ramp",
        "authors": [
            "Xuejin Wen"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Unlike most existing studies on off-ramp traffic signal control, this paper\nfocuses on the optimization problem of the signalized intersection connected to\nfreeway on-ramps. Conflicts are often observed between the traffic heading to\nan on-ramp and the traffic continuing straight which leads to issues such as\nintersection overflow, increased delay, and concerns about safety. For studying\nthis problem, a real-world signalized intersection in Buffalo, New York was\nchosen, which has two through lanes and one short shared (through and\nright-turn) lane. At the downstream of the intersection are two following\non-ramps, one to the highway I-290 West and the other to I-290 East. During\npeak hours, the shared lane often observes a long queue, which furthermore\nblocks the through traffic on the parallel lane. To solve this problem, a\nVISSIM agent-based simulation model was built and calibrated based on field\nobservations. Three potential optimization solutions were proposed and tested\nwith the help of VISSIM: (1) increasing the length of the short shared through\nand right-turn lane; (2) making the short shared through and right-turn lane\nright-turn only, and (3) adding a new diverge lane for the right-turn vehicles.\nAccording to the simulation results, solution (3) performs the best, resulting\nin the least vehicle delay time.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07583v1"
    },
    {
        "title": "Crowd Behavior Simulation with Emotional Contagion in Unexpected\n  Multi-hazard Situations",
        "authors": [
            "Mingliang Xu",
            "Xiaozheng Xie",
            "Pei Lv",
            "Jiangwei Niu",
            "Hua Wang",
            "Chaochao Li",
            "Ruijie Zhu",
            "Zhigang Deng",
            "Bing Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In this paper we present a novel crowd simulation method by modeling the\ngeneration and contagion of panic emotion under multi-hazard circumstances.\nSpecifically, we first classify hazards into different types (transient and\npersistent, concurrent and non-concurrent, static and dynamic ) based on their\ninherent characteristics. Then, we introduce the concept of perilous field for\neach hazard and further transform the critical level of the field to its\ninvoked-panic emotion. After that, we propose an emotional contagion model to\nsimulate the evolving process of panic emotion caused by multiple hazards in\nthese situations. Finally, we introduce an Emotional Reciprocal Velocity\nObstacles (ERVO) model to simulate the crowd behaviors by augmenting the\ntraditional RVO model with emotional contagion, which combines the emotional\nimpact and local avoidance together for the first time. Our experimental\nresults show that this method can soundly generate realistic group behaviors as\nwell as panic emotion dynamics in a crowd in multi-hazard environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.10000v3"
    },
    {
        "title": "Evolutionary model discovery of causal factors behind the\n  socio-agricultural behavior of the ancestral Pueblo",
        "authors": [
            "Chathika Gunaratne",
            "Ivan Garibay",
            "Nguyen Dang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Agent-based modeling of artificial societies offers a platform to test\nhuman-interpretable, causal explanations of human behavior that generate\nsociety-scale phenomena. However, parameter calibration is insufficient to\nconduct an adequate data-driven exploration of the importance of causal factors\nthat constitute agent rules, resulting in models with limited causal accuracy\nand robustness. We introduce evolutionary model discovery, a framework that\ncombines genetic programming and random forest regression to evaluate the\nimportance of a set of causal factors hypothesized to affect the individual's\ndecision-making process. We investigated the farm plot seeking behavior of the\nancestral Pueblo of the Long House Valley simulated in the Artificial Anasazi\nmodel our proposed framework. We evaluated the importance of causal factors not\nconsidered in the original model that we hypothesized to have affected the\ndecision-making process. Contrary to the original model, where closeness was\nthe sole factor driving farm plot selection, selection of higher quality land\nand desire for social presence are shown to be more important. In fact, model\nperformance is improved when agents select farm plots further away from their\nfailed farm plot. Farm selection strategies designed using these insights into\nthe socio-agricultural behavior of the ancestral Pueblo significantly improved\nthe model's accuracy and robustness.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.00435v2"
    },
    {
        "title": "Controlling Swarms: A Programming Paradigm with Minimalistic\n  Communication",
        "authors": [
            "Joshua Cherian Varughese",
            "Hannes Hornischer",
            "Ronald Thenius",
            "Payam Zahadat",
            "Franz Wotawa",
            "Thomas Schmickl"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Inspired by natural swarms, numerous control schemes enabling robotic swarms,\nmobile sensor networks and other multi-agent systems to exhibit various\nself-organized behaviors have been suggested. In this work, we present a Wave\nOriented Swarm Programming Paradigm (WOSPP) enabling the control of swarms with\nminimalistic communication bandwidth in a simple manner, yet allowing the\nemergence of diverse complex behaviors and autonomy of the swarm. Communi\ncation in the proposed paradigm is based on \"ping\"-signals inspired by\nstrategies for communication and self organization of slime mold (dictyostelium\ndiscoideum) and fireflies (lampyridae). Signals propagate as information-waves\nthroughout the swarm. We show that even with 1-bit bandwidth communication\nbetween agents suffices for the design of a substantial set of behaviors in the\ndomain of essential behaviors of a collective. Ultimately, the reader will be\nenabled to develop and design a control scheme for individual swarms.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.04202v2"
    },
    {
        "title": "Analytically Modeling Unmanaged Intersections with Microscopic Vehicle\n  Interactions",
        "authors": [
            "Changliu Liu",
            "Mykel J. Kochenderfer"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  With the emergence of autonomous vehicles, it is important to understand\ntheir impact on the transportation system. However, conventional traffic\nsimulations are time-consuming. In this paper, we introduce an analytical\ntraffic model for unmanaged intersections accounting for microscopic vehicle\ninteractions. The macroscopic property, i.e., delay at the intersection, is\nmodeled as an event-driven stochastic dynamic process, whose dynamics encode\nthe microscopic vehicle behaviors. The distribution of macroscopic properties\ncan be obtained through either direct analysis or event-driven simulation. They\nare more efficient than conventional (time-driven) traffic simulation, and\ncapture more microscopic details compared to conventional macroscopic flow\nmodels. We illustrate the efficiency of this method by delay analyses under two\ndifferent policies at a two-lane intersection. The proposed model allows for 1)\nefficient and effective comparison among different policies, 2) policy\noptimization, 3) traffic prediction, and 4) system optimization (e.g.,\ninfrastructure and protocol).\n",
        "pdf_link": "http://arxiv.org/pdf/1804.04746v3"
    },
    {
        "title": "God Save the Queen",
        "authors": [
            "Jurek Czyzowicz",
            "Konstantinos Georgiou",
            "Ryan Killick",
            "Evangelos Kranakis",
            "Danny Krizanc",
            "Lata Narayanan",
            "Jaroslav Opatrny",
            "Sunil Shende"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Queen Daniela of Sardinia is asleep at the center of a round room at the top\nof the tower in her castle. She is accompanied by her faithful servant, Eva.\nSuddenly, they are awakened by cries of \"Fire\". The room is pitch black and\nthey are disoriented. There is exactly one exit from the room somewhere along\nits boundary. They must find it as quickly as possible in order to save the\nlife of the queen. It is known that with two people searching while moving at\nmaximum speed 1 anywhere in the room, the room can be evacuated (i.e., with\nboth people exiting) in $1 + \\frac{2\\pi}{3} + \\sqrt{3} \\approx 4.8264$ time\nunits and this is optimal~[Czyzowicz et al., DISC'14], assuming that the first\nperson to find the exit can directly guide the other person to the exit using\nher voice. Somewhat surprisingly, in this paper we show that if the goal is to\nsave the queen (possibly leaving Eva behind to die in the fire) there is a\nslightly better strategy. We prove that this \"priority\" version of evacuation\ncan be solved in time at most $4.81854$. Furthermore, we show that any strategy\nfor saving the queen requires time at least $3 + \\pi/6 + \\sqrt{3}/2 \\approx\n4.3896$ in the worst case. If one or both of the queen's other servants (Biddy\nand/or Lili) are with her, we show that the time bounds can be improved to\n$3.8327$ for two servants, and $3.3738$ for three servants. Finally we show\nlower bounds for these cases of $3.6307$ (two servants) and $3.2017$ (three\nservants). The case of $n\\geq 4$ is the subject of an independent study by\nQueen Daniela's Royal Scientific Team.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.06011v1"
    },
    {
        "title": "Leveraging Statistical Multi-Agent Online Planning with Emergent Value\n  Function Approximation",
        "authors": [
            "Thomy Phan",
            "Lenz Belzner",
            "Thomas Gabor",
            "Kyrill Schmid"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Making decisions is a great challenge in distributed autonomous environments\ndue to enormous state spaces and uncertainty. Many online planning algorithms\nrely on statistical sampling to avoid searching the whole state space, while\nstill being able to make acceptable decisions. However, planning often has to\nbe performed under strict computational constraints making online planning in\nmulti-agent systems highly limited, which could lead to poor system\nperformance, especially in stochastic domains. In this paper, we propose\nEmergent Value function Approximation for Distributed Environments (EVADE), an\napproach to integrate global experience into multi-agent online planning in\nstochastic domains to consider global effects during local planning. For this\npurpose, a value function is approximated online based on the emergent system\nbehaviour by using methods of reinforcement learning. We empirically evaluated\nEVADE with two statistical multi-agent online planning algorithms in a highly\ncomplex and stochastic smart factory environment, where multiple agents need to\nprocess various items at a shared set of machines. Our experiments show that\nEVADE can effectively improve the performance of multi-agent online planning\nwhile offering efficiency w.r.t. the breadth and depth of the planning process.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.06311v2"
    },
    {
        "title": "The Sharer's Dilemma in Collective Adaptive Systems of Self-Interested\n  Agents",
        "authors": [
            "Lenz Belzner",
            "Kyrill Schmid",
            "Thomy Phan",
            "Thomas Gabor",
            "Martin Wirsing"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In collective adaptive systems (CAS), adaptation can be implemented by\noptimization wrt. utility. Agents in a CAS may be self-interested, while their\nutilities may depend on other agents' choices. Independent optimization of\nagent utilities may yield poor individual and global reward due to locally\ninterfering individual preferences. Joint optimization may scale poorly, and is\nimpossible if agents cannot expose their preferences due to privacy or security\nissues. In this paper, we study utility sharing for mitigating this issue.\nSharing utility with others may incentivize individuals to consider choices\nthat are locally suboptimal but increase global reward. We illustrate our\napproach with a utility sharing variant of distributed cross entropy\noptimization. Empirical results show that utility sharing increases expected\nindividual and global payoff in comparison to optimization without utility\nsharing. We also investigate the effect of greedy defectors in a CAS of\nsharing, self-interested agents. We observe that defection increases the mean\nexpected individual payoff at the expense of sharing individuals' payoff. We\nempirically show that the choice between defection and sharing yields a\nfundamental dilemma for self-interested agents in a CAS.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.10781v1"
    },
    {
        "title": "Learning over Multitask Graphs -- Part I: Stability Analysis",
        "authors": [
            "Roula Nassif",
            "Stefan Vlaski",
            "Cedric Richard",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper formulates a multitask optimization problem where agents in the\nnetwork have individual objectives to meet, or individual parameter vectors to\nestimate, subject to a smoothness condition over the graph. The smoothness\ncondition softens the transition in the tasks among adjacent nodes and allows\nincorporating information about the graph structure into the solution of the\ninference problem. A diffusion strategy is devised that responds to streaming\ndata and employs stochastic approximations in place of actual gradient vectors,\nwhich are generally unavailable. The approach relies on minimizing a global\ncost consisting of the aggregate sum of individual costs regularized by a term\nthat promotes smoothness. We show in this Part I of the work, under conditions\non the step-size parameter, that the adaptive strategy induces a contraction\nmapping and leads to small estimation errors on the order of the small\nstep-size. The results in the accompanying Part II will reveal explicitly the\ninfluence of the network topology and the regularization strength on the\nnetwork performance and will provide insights into the design of effective\nmultitask strategies for distributed inference over networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.08535v2"
    },
    {
        "title": "Learning over Multitask Graphs -- Part II: Performance Analysis",
        "authors": [
            "Roula Nassif",
            "Stefan Vlaski",
            "Cedric Richard",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Part I of this paper formulated a multitask optimization problem where agents\nin the network have individual objectives to meet, or individual parameter\nvectors to estimate, subject to a smoothness condition over the graph. A\ndiffusion strategy was devised that responds to streaming data and employs\nstochastic approximations in place of actual gradient vectors, which are\ngenerally unavailable. The approach relied on minimizing a global cost\nconsisting of the aggregate sum of individual costs regularized by a term that\npromotes smoothness. We examined the first-order, the second-order, and the\nfourth-order stability of the multitask learning algorithm. The results\nidentified conditions on the step-size parameter, regularization strength, and\ndata characteristics in order to ensure stability. This Part II examines\nsteady-state performance of the strategy. The results reveal explicitly the\ninfluence of the network topology and the regularization strength on the\nnetwork performance and provide insights into the design of effective multitask\nstrategies for distributed inference over networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.08547v2"
    },
    {
        "title": "Volunteers in the Smart City: Comparison of Contribution Strategies on\n  Human-Centered Measures",
        "authors": [
            "Stefano Bennati",
            "Ivana Dusparic",
            "Rhythima Shinde",
            "Catholijn M. Jonker"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Several smart city services rely on users contribution, e.g., data, which can\nbe costly for the users in terms of privacy. High costs lead to reduced user\nparticipation, which undermine the success of smart city technologies. This\nwork develops a scenario-independent design principle, based on public good\ntheory, for resource management in smart city applications, where provision of\na service depends on contributors and free-riders, which benefit from the\nservice without contributing own resources. Following this design principle,\ndifferent classes of algorithms for resource management are evaluated with\nrespect to human-centered measures, i.e., privacy, fairness and social welfare.\nTrade-offs that characterize algorithms are discussed across two smart city\napplication scenarios. These results might help Smart City application\ndesigners to choose a suitable algorithm given a scenario-specific set of\nrequirements, and users to choose a service based on an algorithm that matches\ntheir preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.09090v1"
    },
    {
        "title": "Resisting hostility generated by terror: An agent-based study",
        "authors": [
            "Sylvie Huet",
            "Guillaume Deffuant",
            "Armelle Nugier",
            "Michel Streith",
            "Serge Guimond"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We aim to study through an agent-based model the cultural conditions leading\nto a decrease or an increase of discrimination between groups after a major\ncultural threat such as a terrorist attack. We propose an agent-based model of\ncultural dynamics inspired from the social psychological theories. An agent has\na cultural identity comprised of the most acceptable positions about each of\nthe different cultural worldviews corresponding to the main cultural groups of\nthe considered society and a margin of acceptance around each of these most\nacceptable positions. An agent forms an attitude about another agent depending\non the similarity between their cultural identities. When a terrorist attack is\nperpetrated in the name of an extreme cultural identity, the negatively\nperceived agents from this extreme cultural identity modify their margins of\nacceptance in order to differentiate themselves more from the threatening\ncultural identity. We generated a set of populations with cultural identities\ncompatible with data given by a survey on groups' attitudes among a large\nsample representative of the population of France; we then simulated the\nreaction of these agents facing a threat. For most populations, the average\nattitude toward agents with the same preferred worldview as the terrorists\nbecomes more negative; however, when the population shows some cultural\nproperties, we noticed the opposite effect as the average attitude of the\npopulation becomes less negative. This particular context requires that the\nagents sharing the same preferred worldview with the terrorists strongly\ndifferentiate themselves from the terrorists' extreme cultural identity and\nthat the other agents be aware of these changes.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10109v1"
    },
    {
        "title": "Few self-involved agents among BC agents can lead to polarized local or\n  global consensus",
        "authors": [
            "Sylvie Huet",
            "Jean-Denis Mathias"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Social issues are generally discussed by highly-involved and less-involved\npeople to build social norms defining what has to be thought and done about\nthem. As self-involved agents share different attitude dynamics to other agents\nWood, Pool et al, 1996, we study the emergence and evolution of norms through\nan individual-based model involving these two types of agents. The dynamics of\nself-involved agents is drawn from Huet and Deffuant, 2010, and the dynamics of\nothers, from Deffuant et al, 2001. The attitude of an agent is represented as a\nsegment on a continuous attitudinal space. Two agents are close if their\nattitude segments share sufficient overlap. Our agents discuss two different\nissues, one of which, called main issue, is more important for the\nself-involved agents than the other, called secondary issue. Self-involved\nagents are attracted on both issues if they are close on main issue, but shift\naway from their peer's opinion if they are only close on secondary issue.\nDifferently, non-self-involved agents are attracted by other agents when they\nare close on both the main and secondary issues. We observe the emergence of\nvarious types of extreme minor clusters. In one or different groups of\nattitudes, they can lead to an already-built moderate norm or a norm polarized\non secondary and/or main issues. They can also push disagreeing agents gathered\nin different groups to a global moderate consensus.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10176v1"
    },
    {
        "title": "Tangramob: an agent-based simulation framework for validating urban\n  smart mobility solutions",
        "authors": [
            "Carlo Castagnari",
            "Flavio Corradini",
            "Francesco De Angelis",
            "Jacopo de Berardinis",
            "Giorgio Forcina",
            "Andrea Polini"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Estimating the effects of introducing a range of smart mobility solutions\nwithin an urban area is a crucial concern in urban planning. The lack of a\nDecision Support System (DSS) for the assessment of mobility initiatives,\nforces local public authorities and mobility service providers to base their\ndecisions on guidelines derived from common heuristics and best practices.\nThese approaches can help planners in shaping mobility solutions, but given the\nhigh number of variables to consider the effects are not guaranteed. Therefore,\na solution conceived respecting the available guidelines can result in a\nfailure in a different context. In particular, difficult aspects to consider\nare the interactions between different mobility services available in a given\nurban area, and the acceptance of a given mobility initiative by the\ninhabitants of the area. In order to fill this gap, we introduce Tangramob, an\nagent-based simulation framework capable of assessing the impacts of a Smart\nMobility Initiative (SMI) within an urban area of interest. Tangramob simulates\nhow urban traffic is expected to evolve as citizens start experiencing the\nnewly offered traveling solutions. This allows decision makers to evaluate the\nefficacy of their initiatives taking into account the current urban system. In\nthis paper we provide an overview of the simulation framework along with its\ndesign. To show the potential of Tangramob, 3 mobility initiatives are\nsimulated and compared on the same scenario. This shows how it is possible to\nperform comparative experiments so as to align mobility initiatives to the user\ngoals.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10906v1"
    },
    {
        "title": "A Puff of Steem: Security Analysis of Decentralized Content Curation",
        "authors": [
            "Aggelos Kiayias",
            "Benjamin Livshits",
            "Andrés Monteoliva Mosteiro",
            "Orfeas Stefanos Thyfronitis Litos"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Decentralized content curation is the process through which uploaded posts\nare ranked and filtered based exclusively on users' feedback. Platforms such as\nthe blockchain-based Steemit employ this type of curation while providing\nmonetary incentives to promote the visibility of high quality posts according\nto the perception of the participants. Despite the wide adoption of the\nplatform very little is known regarding its performance and resilience\ncharacteristics. In this work, we provide a formal model for decentralized\ncontent curation that identifies salient complexity and game-theoretic measures\nof performance and resilience to selfish participants. Armed with our model, we\nprovide a first analysis of Steemit identifying the conditions under which the\nsystem can be expected to correctly converge to curation while we demonstrate\nits susceptibility to selfish participant behaviour. We validate our\ntheoretical results with system simulations in various scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.01719v2"
    },
    {
        "title": "Simulating acculturation dynamics between migrants and locals in\n  relation to network formation",
        "authors": [
            "Rocco Paolillo",
            "Wander Jager"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  International migration implies the coexistence of different ethnic and\ncultural groups in the receiving country. The refugee crisis of 2015 has\nresulted in critical levels of opinion polarization on the question of whether\nto welcome migrants, causing clashes in receiving countries. This scenario\nemphasizes the need to better understand the dynamics of mutual adaptation\nbetween locals and migrants, and the conditions that favor successful\nintegration. Agent-based simulations can help achieve this goal. In this work,\nwe introduce our model MigrAgent and our preliminary results. The model\nsynthesizes the dynamics of migration intake and post-migration adaptation. It\nexplores the different acculturation outcomes that can emerge from the mutual\nadaptation of a migrant population and a local population depending on their\ndegree of tolerance. With parameter sweeping, we detect how different\nacculturation strategies can coexist in a society and in different degrees\namong various subgroups. The results show higher polarization effects between a\nlocal population and a migrant population for fast intake conditions. When\nmigrant intake is slow, transitory conditions between acculturation outcomes\nemerge for subgroups, e.g., from assimilation to integration for liberal\nmigrants and from marginalization to separation for conservative migrants.\nRelative group sizes due to speed of intake cause counterintuitive scenarios,\nsuch as the separation of liberal locals. We qualitatively compare the\nprocesses of our model with the German portion sample of the survey Causes and\nConsequences of Socio-Cultural Integration Processes among New Immigrants in\nEurope (SCIP), finding preliminary confirmation of our assumptions and results.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02650v2"
    },
    {
        "title": "MoCaNA, un agent de n{é}gociation automatique utilisant la recherche\n  arborescente de Monte-Carlo",
        "authors": [
            "Cédric Buron",
            "Zahia Guessoum",
            "Sylvain Ductor",
            "Olivier Roussel"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Automated negotiation is a rising topic in Artificial Intelligence research.\nMonte Carlo methods have got increasing interest, in particular since they have\nbeen used with success on games with high branching factor such as go.In this\npaper, we describe an Monte Carlo Negotiating Agent (MoCaNA) whose bidding\nstrategy relies on Monte Carlo Tree Search. We provide our agent with opponent\nmodeling tehcniques for bidding strtaegy and utility. MoCaNA can negotiate on\ncontinuous negotiating domains and in a context where no bound has been\nspecified. We confront MoCaNA and the finalists of ANAC 2014 and a RandomWalker\non different negotiation domains. Our agent ouperforms the RandomWalker in a\ndomain without bound and the majority of the ANAC finalists in a domain with a\nbound.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.06918v1"
    },
    {
        "title": "Catching Cheats: Detecting Strategic Manipulation in Distributed\n  Optimisation of Electric Vehicle Aggregators",
        "authors": [
            "Alvaro Perez-Diaz",
            "Enrico Gerding",
            "Frank McGroarty"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Given the rapid rise of electric vehicles (EVs) worldwide, and the ambitious\ntargets set for the near future, the management of large EV fleets must be seen\nas a priority. Specifically, we study a scenario where EV charging is managed\nthrough self-interested EV aggregators who compete in the day-ahead market in\norder to purchase the electricity needed to meet their clients' requirements.\nWith the aim of reducing electricity costs and lowering the impact on\nelectricity markets, a centralised bidding coordination framework has been\nproposed in the literature employing a coordinator. In order to improve privacy\nand limit the need for the coordinator, we propose a reformulation of the\ncoordination framework as a decentralised algorithm, employing the Alternating\nDirection Method of Multipliers (ADMM). However, given the self-interested\nnature of the aggregators, they can deviate from the algorithm in order to\nreduce their energy costs. Hence, we study the strategic manipulation of the\nADMM algorithm and, in doing so, describe and analyse different possible attack\nvectors and propose a mathematical framework to quantify and detect\nmanipulation. Importantly, this detection framework is not limited the\nconsidered EV scenario and can be applied to general ADMM algorithms. Finally,\nwe test the proposed decentralised coordination and manipulation detection\nalgorithms in realistic scenarios using real market and driver data from Spain.\nOur empirical results show that the decentralised algorithm's convergence to\nthe optimal solution can be effectively disrupted by manipulative attacks\nachieving convergence to a different non-optimal solution which benefits the\nattacker. With respect to the detection algorithm, results indicate that it\nachieves very high accuracies and significantly outperforms a naive benchmark.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.07063v2"
    },
    {
        "title": "Evolution of holonic control architectures towards Industry 4.0: A short\n  overview",
        "authors": [
            "Olivier Cardin",
            "William Derigent",
            "Damien Trentesaux"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The flexibility claimed by the next generation production systems induces a\ndeep modification of the behavior and the core itself of the control systems.\nOverconnectivity and data management abilities targeted by Industry 4.0\nparadigm enable the emergence of more flexible and reactive control systems,\nbased on the cooperation of autonomous and connected entities in the decision\nmaking process. For the last 20 years, holonic paradigm has become the core\nparadigm of those evolutions, and evolved in itself. This contribution aims at\nemphasizing the conceptual evolutions in the application of holonic paradigm in\nthe control architectures of manufacturing systems and highlighting the current\nresearch trends in this field.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.09109v1"
    },
    {
        "title": "Reasoning about Norms Revision",
        "authors": [
            "Davide Dell'Anna",
            "Mehdi Dastani",
            "Fabiano Dalpiaz"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Norms with sanctions have been widely employed as a mechanism for controlling\nand coordinating the behavior of agents without limiting their autonomy. The\nnorms enforced in a multi-agent system can be revised in order to increase the\nlikelihood that desirable system properties are fulfilled or that system\nperformance is sufficiently high. In this paper, we provide a preliminary\nanalysis of some types of norm revision: relaxation and strengthening.\nFurthermore, with the help of some illustrative scenarios, we show the\nusefulness of norm revision for better satisfying the overall system\nobjectives.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.10591v1"
    },
    {
        "title": "Multi-Layers Supply chain modelling based on Multi-Agent Approach",
        "authors": [
            "Samia Chehbi-Gamoura",
            "Yacine Ouzrout",
            "Abdelaziz Bouras"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper proposes a strategic multi layers model based on multi agents\napproach for supply chain system. It introduces a formulation and a solution\nmethodology for the problem of supply chain design and modeling. In this paper\nwe describe and analyze the relationships among main entities of a supply\nchain, such as suppliers, producers, and distribution centers, in the aim to\ndesign the agents and define their behavior. We also study, how these\nrelationships can be formulated in a multi layer model. Finally, a generic\nmulti agent model is illustrated.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.13189v1"
    },
    {
        "title": "A multi-agent system for managing the product lifecycle sustainability",
        "authors": [
            "Thtiya Manakitsirisuthi",
            "Yacine Ouzrout",
            "Abdelaziz Bouras"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The international competitive market causes the increasing of shorten product\nlife cycle and product development process with the improvement in term of\ntime, cost and quality while increasing the waste generation. Product life\ncycle sustainability can reduce waste, conserve resources, use recycling\nmaterials, design product for easy disassembly and avoid using hazardous\nmaterial. This paper proposes a knowledge management architecture, based on a\nmulti-agent system, which focuses on the \"sustainability\" in order to manage\nknowledge in each stage of the product lifecycle, and particularly in the\nrecovery process. The aim of this research work is to make the link between a\ndecision-making system based on the agent's knowledge about the sustainability\n(environmental norms, rules...) and a PLM (Product Lifecycle Management)\nsystem. The software Agents will help the decision makers in each stage of the\nlifecycle and make them take into account the environmental impact of their\ndecisions.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.13195v1"
    },
    {
        "title": "Towards Agent-based Models of Rumours in Organizations: A Social\n  Practice Theory Approach",
        "authors": [
            "Amir Ebrahimi Fard",
            "Rijk Mercuur",
            "Virginia Dignum",
            "Catholijn M. Jonker",
            "Bartel van de Walle"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Rumour is a collective emergent phenomenon with a potential for provoking a\ncrisis. Modelling approaches have been deployed since five decades ago;\nhowever, the focus was mostly on epidemic behaviour of the rumours which does\nnot take into account the differences of the agents. We use social practice\ntheory to model agent decision making in organizational rumourmongering. Such\nan approach provides us with an opportunity to model rumourmongering agents\nwith a layer of cognitive realism and study the impacts of various intervention\nstrategies for prevention and control of rumours in organizations.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.00651v2"
    },
    {
        "title": "An Exchange Mechanism to Coordinate Flexibility in Residential Energy\n  Cooperatives",
        "authors": [
            "Shantanu Chakraborty",
            "Pablo Hernandez-Leal",
            "Michael Kaisers"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Energy cooperatives (ECs) such as residential and industrial microgrids have\nthe potential to mitigate increasing fluctuations in renewable electricity\ngeneration, but only if their joint response is coordinated. However, the\ncoordination and control of independently operated flexible resources (e.g.,\nstorage, demand response) imposes critical challenges arising from the\nheterogeneity of the resources, conflict of interests, and impact on the grid.\nCorrespondingly, overcoming these challenges with a general and fair yet\nefficient exchange mechanism that coordinates these distributed resources will\naccommodate renewable fluctuations on a local level, thereby supporting the\nenergy transition. In this paper, we introduce such an exchange mechanism. It\nincorporates a payment structure that encourages prosumers to participate in\nthe exchange by increasing their utility above baseline alternatives. The\nallocation from the proposed mechanism increases the system efficiency\n(utilitarian social welfare) and distributes profits more fairly (measured by\nNash social welfare) than individual flexibility activation. A case study\nanalyzing the mechanism performance and resulting payments in numerical\nexperiments over real demand and generation profiles of the Pecan Street\ndataset elucidates the efficacy to promote cooperation between co-located\nflexibilities in residential cooperatives through local exchange.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.04750v2"
    },
    {
        "title": "Implementing Argumentation-enabled Empathic Agents",
        "authors": [
            "Timotheus Kampik",
            "Juan Carlos Nieves",
            "Helena Lindgren"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In a previous publication, we introduced the core concepts of empathic agents\nas agents that use a combination of utility-based and rule-based approaches to\nresolve conflicts when interacting with other agents in their environment. In\nthis work, we implement proof-of-concept prototypes of empathic agents with the\nmulti-agent systems development framework Jason and apply argumentation theory\nto extend the previously introduced concepts to account for inconsistencies\nbetween the beliefs of different agents. We then analyze the feasibility of\ndifferent admissible set-based argumentation semantics to resolve these\ninconsistencies. As a result of the analysis we identify the maximal ideal\nextension as the most feasible argumentation semantics for the problem in\nfocus.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.04985v1"
    },
    {
        "title": "Aerial Robot Model based design and verification of the single and\n  multi-agent inspection application development",
        "authors": [
            "Seiko P. Yamaguchi",
            "Masaru Sakuma",
            "Takaki Ueno",
            "Filip Karolonek",
            "Tadeusz Uhl",
            "Ankit A. Ravankar",
            "Takanori Emaru",
            "Yukinori Kobayashi"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In recent decade, potential application of Unmanned Aerial Vehicles (UAV) has\nenabled replacement of various operations in hard-to-access areas, such as,\ninspection, surveillance or search and rescue applications in challenging and\ncomplex environments. Furthermore, aerial robotics application with multi-agent\nsystems are anticipated to further extend its potential. However, one of the\nmajor difficulties in aerial robotics applications is the testing of the\nelaborated system within safety concerns, especially when multiple agents are\nsimultaneously applied. Thus, virtual prototyping and simulation-based\ndevelopment can serve in development, assessment and improvement of the aerial\nrobot applications. In this research, two examples of the specific applications\nare highlighted, harbor structure and facilities inspection with UAV, and\ndevelopment of autonomous positioning of multi-UAVs communication relaying\nsystem. In this research, virtual prototype was designed and further simulated\nin multi-body simulation (MBS) feigning the sensing and actuating equipment\nbehaviors. Simultaneous simulation of the control and application system\nrunning with software in the loop (SITL) method is utilized to assess the\ndesigned hardware behavior with modular application nodes running in Robot\nOperating System. Furthermore, prepared simulation environment is assessed with\nmulti-agent system, proposed in previous research with autonomous position\ncontrol of communication relaying system. Application of the virtual\nprototype's simulation environment enables further examination of the proposed\nsystem within comparison degree with postfield tests. The research aims to\ncontribute through case assessment of the design process to safer, time and\ncost-efficient development and application design in the field of aerial\nrobotics.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.05296v1"
    },
    {
        "title": "Gliders2d: Source Code Base for RoboCup 2D Soccer Simulation League",
        "authors": [
            "Mikhail Prokopenko",
            "Peter Wang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We describe Gliders2d, a base code release for Gliders, a soccer simulation\nteam which won the RoboCup Soccer 2D Simulation League in 2016. We trace six\nevolutionary steps, each of which is encapsulated in a sequential change of the\nreleased code, from v1.1 to v1.6, starting from agent2d-3.1.1 (set as the\nbaseline v1.0). These changes improve performance by adjusting the agents'\nstamina management, their pressing behaviour and the action-selection\nmechanism, as well as their positional choice in both attack and defense, and\nenabling riskier passes. The resultant behaviour, which is sufficiently generic\nto be applicable to physical robot teams, increases the players' mobility and\nachieves a better control of the field. The last presented version,\nGliders2d-v1.6, approaches the strength of Gliders2013, and outperforms\nagent2d-3.1.1 by four goals per game on average. The sequential improvements\ndemonstrate how the methodology of human-based evolutionary computation can\nmarkedly boost the overall performance with even a small number of controlled\nsteps.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.10202v1"
    },
    {
        "title": "An Analysis of Pedestrians' Behavior in Emergency Evacuation Using\n  Cellular Automata Simulation",
        "authors": [
            "Zhiguo Zhou",
            "Huiyu Cai",
            "Zhixuan Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  To minimize property loss and death count in terror attacks and other\nemergent scenarios, attention given to timely and effective evacuation cannot\nbe enough. Due to limited evacuation resource, i.e., number of available exits,\nthere exists interdependence among pedestrians such as cooperation, competition\nand herd effect. Thus human factors - more specifically, pedestrians' behavior\nin emergency evacuation - play a significant role in evacuation research.\nEffective evacuation can only be reached when route planning are considered in\nconjunction with psychological dynamics, which is often ignored. As another\ndrawback, previous research assumes the environment including available exits\nas stationary. However, we note that during emergency, some exits which are not\noften utilized in normal times are opened, which potentially helps if\npedestrians are aware of them. In this paper, we analyze the effect of\npedestrians' behavior, i.e., herd effect and knowledge of changing environment\nwith Cellular Automata (CA) simulation. Results of the simulation show the\nharmful effect of herd effect as well as highlight the importance of timely\ninforming pedestrians of environmental change. Accordingly, we propose policy\nand procedural recommendations for emergency management of large, crowded\nstructures. Our future work includes considering more human factors and\napplying our model to log data provided by videos in public venues, which can\nfurther show effectiveness of our model in real scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.01229v3"
    },
    {
        "title": "Demonstration of a Time-Efficient Mobility System Using a Scaled Smart\n  City",
        "authors": [
            "Logan E. Beaver",
            "Behdad Chalaki",
            "AM Ishtiaque Mahbub",
            "Liuhui Zhao",
            "Ray Zayas",
            "Andreas A. Malikopoulos"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The implementation of connected and automated vehicle (CAV) technologies\nenables a novel computational framework to deliver real-time control actions\nthat optimize travel time, energy, and safety. Hardware is an integral part of\nany practical implementation of CAVs, and as such, it should be incorporated in\nany validation method. However, high costs associated with full scale, field\ntesting of CAVs have proven to be a significant barrier. In this paper, we\npresent the implementation of a decentralized control framework, which was\ndeveloped previously, in a scaled-city using robotic CAVs, and discuss the\nimplications of CAVs on travel time. Supplemental information and videos can be\nfound at https://sites.google.com/view/ud-ids-lab/tfms.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.01632v2"
    },
    {
        "title": "Intelligent Knowledge Distribution: Constrained-Action POMDPs for\n  Resource-Aware Multi-Agent Communication",
        "authors": [
            "Michael C. Fowler",
            "T. Charles Clancy",
            "Ryan K. Williams"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper addresses a fundamental question of multi-agent knowledge\ndistribution: what information should be sent to whom and when, with the\nlimited resources available to each agent? Communication requirements for\nmulti-agent systems can be rather high when an accurate picture of the\nenvironment and the state of other agents must be maintained. To reduce the\nimpact of multi-agent coordination on networked systems, e.g., power and\nbandwidth, this paper introduces two concepts for partially observable Markov\ndecision processes (POMDPs): 1) action-based constraints which yield\nconstrained-action POMDPs (CA-POMDPs); and 2) soft probabilistic constraint\nsatisfaction for the resulting infinite-horizon controllers. To enable\nconstraint analysis over an infinite horizon, an unconstrained policy is first\nrepresented as a Finite State Controller (FSC) and optimized with policy\niteration. The FSC representation then allows for a combination of Markov chain\nMonte Carlo and discrete optimization to improve the probabilistic constraint\nsatisfaction of the controller while minimizing the impact to the value\nfunction. Within the CA-POMDP framework we then propose Intelligent Knowledge\nDistribution (IKD) which yields per-agent policies for distributing knowledge\nbetween agents subject to interaction constraints. Finally, the CA-POMDP and\nIKD concepts are validated using an asset tracking problem where multiple\nunmanned aerial vehicles (UAVs) with heterogeneous sensors collaborate to\nlocalize a ground asset to assist in avoiding unseen obstacles in a disaster\narea. The IKD model was able to maintain asset tracking through multi-agent\ncommunications while only violating soft power and bandwidth constraints 3% of\nthe time, while greedy and naive approaches violated constraints more than 60%\nof the time.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.03086v1"
    },
    {
        "title": "Minimizing Travel in the Uniform Dispersal Problem for Robotic Sensors",
        "authors": [
            "Michael Amir",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The limited energy capacity of individual robotic agents in a swarm often\nlimits the possible cooperative tasks they can perform. In this work, we\ninvestigate the problem of covering an unknown connected grid environment (e.g.\na maze or connected corridors) with a robotic swarm so as to minimize the\nmaximal number of steps that each member of the swarm makes and their activity\ntime before their work is finished, thereby minimizing the energy requirements.\nThe robots are autonomous, anonymous and identical, with local sensors and\nfinite memory, and possess no communication capabilities. They are assumed to\ndisperse over time from a fixed location, and to move synchronously. The robots\nare tasked with occupying every cell of the environment, while avoiding\ncollisions.\n  In the literature such topics are known as \\textit{uniform dispersal\nproblems}. The goal of minimizing the number of steps traveled by the robots\nhas previously been studied in this context. Our contribution is a local\nrobotic strategy for simply connected grid environments that, by exploiting\ntheir topology, achieves optimal makespan (the amount of time it takes to cover\nthe environment) and minimizes the maximal number of steps taken by the\nindividual robots before their deactivation. The robots succeed in discovering\noptimal paths to their eventual destinations, and finish the covering process\nin $2V-1$ time steps, where $V$ is the number of cells in the environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.03259v1"
    },
    {
        "title": "On self-organised aggregation dynamics in swarms of robots with informed\n  robots",
        "authors": [
            "Ziya Firat",
            "Eliseo Ferrante",
            "Yannick Gillet",
            "Elio Tuci"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we use simulated swarms of robots to further explore the\naggregation dynamics generated by these simple individual mechanisms. Our\nobjective is to study the introduction of \"informed robots\", and to study how\nmany of these are needed to direct the aggregation process toward a pre-defined\nsite among those available in the environment. Informed robots are members of a\ngroup that selectively avoid the site/s where no aggregate should emerge, and\nstop only on the experimenter predefined site/s for aggregation. We study the\naggregation process with informed robots in three different scenarios: two that\nare morphologically symmetric, whereby the different types of aggregation site\nare equally represented in the environment; and an asymmetric scenario, whereby\nthe target site has an area that is half the area of the sites that should be\navoided. We first show what happens when no robot in the swarm is informed: in\nsymmetric environments, the swarm is able to break the symmetry and aggregates\non one of the two types of site at random, not necessarily on the target site,\nwhile in the asymmetric environment, the swarm tends to aggregate on the sites\nthat are most represented in terms of area. As a further valuable contribution\nof this study, we provide analytical results by studying a system of Ordinary\nDifferential Equations' (ODEs) that is an extension of a well known model.\nUsing this model, we show how, for certain values of the parameters, the model\ncan predict the dynamics observed with simulated robots in one of the two\nsymmetric scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.03841v1"
    },
    {
        "title": "CIMAX: Collective Information Maximization in Robotic Swarms Using Local\n  Communication",
        "authors": [
            "Hannes Hornischer",
            "Joshua Cherian Varughese",
            "Ronald Thenius",
            "Franz Wotawa",
            "Manfred Füllsack",
            "Thomas Schmickl"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Robotic swarms and mobile sensor networks are used for environmental\nmonitoring in various domains and areas of operation. Especially in otherwise\ninaccessible environments decentralized robotic swarms can be advantageous due\nto their high spatial resolution of measurements and resilience to failure of\nindividuals in the swarm. However, such robotic swarms might need to be able to\ncompensate misplacement during deployment or adapt to dynamical changes in the\nenvironment. Reaching a collective decision in a swarm with limited\ncommunication abilities without a central entity serving as decision-maker can\nbe a challenging task. Here we present the CIMAX algorithm for collective\ndecision making for maximizing the information gathered by the swarm as a\nwhole. Agents negotiate based on their individual sensor readings and\nultimately make a decision for collectively moving in a particular direction so\nthat the swarm as a whole increases the amount of relevant measurements and\nthus accessible information. We use both simulation and real robotic\nexperiments for presenting, testing and validating our algorithm. CIMAX is\ndesigned to be used in underwater swarm robots for troubleshooting an oxygen\ndepletion phenomenon known as \"anoxia\".\n",
        "pdf_link": "http://arxiv.org/pdf/1903.05444v1"
    },
    {
        "title": "A Principal-Agent Model of Systems Engineering Processes with\n  Application to Satellite Design",
        "authors": [
            "Salar Safarkhani",
            "Vikranth Reddy Kattakuri",
            "Ilias Bilionis",
            "Jitesh Panchal"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We present a principal-agent model of a one-shot, shallow, systems\nengineering process. The process is one-shot in the sense that decisions are\nmade during one time step and that they are final. The term shallow refers to a\none-layer hierarchy of the process. Specifically, we assume that the systems\nengineer has already decomposed the problem in subsystems, and that each\nsubsystem is assigned to a different subsystem engineer. Each subsystem\nengineer works independently to maximize their own expected payoff. The goal of\nthe systems engineer is to maximize the system-level payoff by incentivizing\nthe subsystem engineers. We restrict our attention to requirement-based\nsystem-level payoffs, i.e., the systems engineer makes a profit only if all the\ndesign requirements are met. We illustrate the model using the design of an\nEarth-orbiting satellite system where the systems engineer determines the\noptimum incentive structures and requirements for two subsystems: the\npropulsion subsystem and the power subsystem. The model enables the analysis of\na systems engineer's decisions about optimal passed-down requirements and\nincentives for sub-system engineers under different levels of task difficulty\nand associated costs. Sample results, for the case of risk-neutral systems and\nsubsystems engineers, show that it is not always in the best interest of the\nsystems engineer to pass down the true requirements. As expected, the model\npredicts that for small to moderate task uncertainties the optimal requirements\nare higher than the true ones, effectively eliminating the probability of\nfailure for the systems engineer. In contrast, the model predicts that for\nlarge task uncertainties the optimal requirements should be smaller than the\ntrue ones in order to lure the subsystem engineers into participation.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.06979v1"
    },
    {
        "title": "Local Interactions for Cohesive Flexible Swarms",
        "authors": [
            "Rotem Manor",
            "Ariel Barel",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Distributed gathering algorithms aim to achieve complete visibility graphs\nvia a \"never lose a neighbour\" policy. We suggest a method to maintain\nconnected graph topologies, while reducing the number of effective edges in the\ngraph to order n. This allows to achieve different goals and swarming\nbehaviours: the system remains connected but flexible, hence can maneuver in\nenvironments that are replete with obstacles and narrow passages, etc.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09259v1"
    },
    {
        "title": "A Hybrid Approach to Persistent Coverage in Stochastic Environments",
        "authors": [
            "William Bentz",
            "Dimitra Panagou"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper considers the persistent coverage of a 2-D manifold that has been\nembedded in 3-D space. The manifold is subject to continual impact by intruders\nwhich travel at constant velocities along arbitrarily oriented straight-line\ntrajectories. The trajectories of intruders are estimated online with an\nextended Kalman filter and their predicted impact points contribute normally\ndistributed decay terms to the coverage level. A formal hybrid control strategy\nis presented that allows for power-constrained 3-D free-flyer agents to\npersistently monitor the domain, track and intercept intruders, and\nperiodically deploy from and return to a single charging station on the\nmanifold. Guarantees on intruder interception with respect to agent power\nlifespans are formally proven. The efficacy of the algorithm is demonstrated\nthrough simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09658v2"
    },
    {
        "title": "Towards a Theory of Systems Engineering Processes: A Principal-Agent\n  Model of a One-Shot, Shallow Process",
        "authors": [
            "Salar Safarkhani",
            "Ilias Bilionis",
            "Jitesh Panchal"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Systems engineering processes coordinate the effort of different individuals\nto generate a product satisfying certain requirements. As the involved\nengineers are self-interested agents, the goals at different levels of the\nsystems engineering hierarchy may deviate from the system-level goals which may\ncause budget and schedule overruns. Therefore, there is a need of a systems\nengineering theory that accounts for the human behavior in systems design. To\nthis end, the objective of this paper is to develop and analyze a\nprincipal-agent model of a one-shot (single iteration), shallow (one level of\nhierarchy) systems engineering process. We assume that the systems engineer\nmaximizes the expected utility of the system, while the subsystem engineers\nseek to maximize their expected utilities. Furthermore, the systems engineer is\nunable to monitor the effort of the subsystem engineer and may not have a\ncomplete information about their types or the complexity of the design task.\nHowever, the systems engineer can incentivize the subsystem engineers by\nproposing specific contracts. To obtain an optimal incentive, we pose and solve\nnumerically a bi-level optimization problem. Through extensive simulations, we\nstudy the optimal incentives arising from different system-level value\nfunctions under various combinations of effort costs, problem-solving skills,\nand task complexities.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.12086v2"
    },
    {
        "title": "Potential Games for Distributed Constrained Consensus",
        "authors": [
            "Dimitris Ampeliotis",
            "Kostas Berberidis"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The problem of computing a common point that lies in the intersection of a\nfinite number of closed convex sets, each known to one agent in a network, is\nstudied. This issue, known as the distributed convex feasibility problem or the\ndistributed constrained consensus problem, constitutes an important research\ngoal mainly due to the large number of possible applications. In this work,\nthis issue is treated from a game theoretic viewpoint. In particular, we\nformulate the problem as a non-cooperative game for which a potential function\nexists and prove that all Nash equilibria of this game correspond to consensus\nstates. Based upon this analysis, a best-response based distributed algorithm\nthat solves the constrained consensus problem is developed. Furthermore, one\nmore approach to solve the convex feasibility problem is studied based upon a\nprojected gradient type algorithm that seeks the maximum of the considered\npotential function. A condition for the convergence of this scheme is derived\nand an exact distributed algorithm is given. Finally, simulation results for a\nsource localization problem are given, that validate the theoretical results\nand demonstrate the applicability and performance of the derived algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.03577v1"
    },
    {
        "title": "Learning Complex Multi-Agent Policies in Presence of an Adversary",
        "authors": [
            "Siddharth Ghiya",
            "Katia Sycara"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In recent years, there has been some outstanding work on applying deep\nreinforcement learning to multi-agent settings. Often in such multi-agent\nscenarios, adversaries can be present. We address the requirements of such a\nsetting by implementing a graph-based multi-agent deep reinforcement learning\nalgorithm. In this work, we consider the scenario of multi-agent deception in\nwhich multiple agents need to learn to cooperate and communicate in order to\ndeceive an adversary. We have employed a two-stage learning process to get the\ncooperating agents to learn such deceptive behaviors. Our experiments show that\nour approach allows us to employ curriculum learning to increase the number of\ncooperating agents in the environment and enables a team of agents to learn\ncomplex behaviors to successfully deceive an adversary.\n  Keywords: Multi-agent system, Graph neural network, Reinforcement learning\n",
        "pdf_link": "http://arxiv.org/pdf/2008.07698v2"
    },
    {
        "title": "Decentralised Multi-Agent Reinforcement Learning for Dynamic and\n  Uncertain Environments",
        "authors": [
            "Andrei Marinescu",
            "Ivana Dusparic",
            "Adam Taylor",
            "Vinny Cahill",
            "Siobhán Clarke"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) is a widely used technique for\noptimization in decentralised control problems. However, most applications of\nMARL are in static environments, and are not suitable when agent behaviour and\nenvironment conditions are dynamic and uncertain. Addressing uncertainty in\nsuch environments remains a challenging problem for MARL-based systems. The\ndynamic nature of the environment causes previous knowledge of how agents\ninteract to become outdated. Advanced knowledge of potential changes through\nprediction significantly supports agents converging to near-optimal control\nsolutions. In this paper we propose P-MARL, a decentralised MARL algorithm\nenhanced by a prediction mechanism that provides accurate information regarding\nup-coming changes in the environment. This prediction is achieved by employing\nan Artificial Neural Network combined with a Self-Organising Map that detects\nand matches changes in the environment. The proposed algorithm is validated in\na realistic smart-grid scenario, and provides a 92% Pareto efficient solution\nto an electric vehicle charging problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.4561v1"
    },
    {
        "title": "Situating Agent-Based Modelling in Population Health Research",
        "authors": [
            "Eric Silverman",
            "Umberto Gostoli",
            "Stefano Picascia",
            "Jonatan Almagor",
            "Mark McCann",
            "Richard Shaw",
            "Claudio Angione"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Today's most troublesome population health challenges are often driven by\nsocial and environmental determinants, which are difficult to model using\ntraditional epidemiological methods. We agree with those who have argued for\nthe wider adoption of agent-based modelling (ABM) in taking on these\nchallenges. However, while ABM has been used occasionally in population health,\nwe argue that for ABM to be most effective in the field it should be used as a\nmeans for answering questions normally inaccessible to the traditional\nepidemiological toolkit. In an effort to clearly illustrate the utility of ABM\nfor population health research, and to clear up persistent misunderstandings\nregarding the method's conceptual underpinnings, we offer a detailed\npresentation of the core concepts of complex systems theory, and summarise why\nsimulations are essential to the study of complex systems. We then examine the\ncurrent state of the art in ABM for population health, and propose they are\nwell-suited for the study of the `wicked' problems in population health, and\ncould make significant contributions to theory and intervention development in\nthese areas.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.02345v1"
    },
    {
        "title": "Evolution of a Complex Predator-Prey Ecosystem on Large-scale\n  Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Jun Yamada",
            "John Shawe-Taylor",
            "Zafeirios Fountas"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Simulation of population dynamics is a central research theme in\ncomputational biology, which contributes to understanding the interactions\nbetween predators and preys. Conventional mathematical tools of this theme,\nhowever, are incapable of accounting for several important attributes of such\nsystems, such as the intelligent and adaptive behavior exhibited by individual\nagents. This unrealistic setting is often insufficient to simulate properties\nof population dynamics found in the real-world. In this work, we leverage\nmulti-agent deep reinforcement learning, and we propose a new model of\nlarge-scale predator-prey ecosystems. Using different variants of our proposed\nenvironment, we show that multi-agent simulations can exhibit key real-world\ndynamical properties. To obtain this behavior, we firstly define a mating\nmechanism such that existing agents reproduce new individuals bound by the\nconditions of the environment. Furthermore, we incorporate a real-time\nevolutionary algorithm and show that reinforcement learning enhances the\nevolution of the agents' physical properties such as speed, attack and\nresilience against attacks.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03267v1"
    },
    {
        "title": "Resilient Consensus via Weight Learning and Its Application in\n  Fault-Tolerant Clock Synchronization",
        "authors": [
            "Jian Hou",
            "Zhiyong Chen",
            " ZhiyunLin",
            "Mengfan Xiang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper addresses the distributed consensus problem in the presence of\nfaulty nodes. A novel weight learning algorithm is introduced such that neither\nnetwork connectivity nor a sequence of history records is required to achieve\nresilient consensus. The critical idea is to dynamically update the interaction\nweights among neighbors learnt from their credibility measurement. Basically,\nwe define a reward function that is inversely proportional to the distance to\nits neighbor, and then adjust the credibility based on the reward derived at\nthe present step and the previous credibility. In such a way, the interaction\nweights are updated at every step, which integrates the historic information\nand degrades the influences from faulty nodes. Both fixed and stochastic\ntopologies are considered in this paper. Furthermore, we apply this novel\napproach in clock synchronization problem. By updating the logical clock skew\nand offset via the corresponding weight learning algorithms, respectively, the\nlogical clock synchronization is eventually achieved regardless of faulty\nnodes. Simulations are provided to illustrate the effectiveness of the\nstrategy.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03541v1"
    },
    {
        "title": "Qatten: A General Framework for Cooperative Multiagent Reinforcement\n  Learning",
        "authors": [
            "Yaodong Yang",
            "Jianye Hao",
            "Ben Liao",
            "Kun Shao",
            "Guangyong Chen",
            "Wulong Liu",
            "Hongyao Tang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In many real-world tasks, multiple agents must learn to coordinate with each\nother given their private observations and limited communication ability. Deep\nmultiagent reinforcement learning (Deep-MARL) algorithms have shown superior\nperformance in such challenging settings. One representative class of work is\nmultiagent value decomposition, which decomposes the global shared multiagent\nQ-value $Q_{tot}$ into individual Q-values $Q^{i}$ to guide individuals'\nbehaviors, i.e. VDN imposing an additive formation and QMIX adopting a\nmonotonic assumption using an implicit mixing method. However, most of the\nprevious efforts impose certain assumptions between $Q_{tot}$ and $Q^{i}$ and\nlack theoretical groundings. Besides, they do not explicitly consider the\nagent-level impact of individuals to the whole system when transforming\nindividual $Q^{i}$s into $Q_{tot}$. In this paper, we theoretically derive a\ngeneral formula of $Q_{tot}$ in terms of $Q^{i}$, based on which we can\nnaturally implement a multi-head attention formation to approximate $Q_{tot}$,\nresulting in not only a refined representation of $Q_{tot}$ with an agent-level\nattention mechanism, but also a tractable maximization algorithm of\ndecentralized policies. Extensive experiments demonstrate that our method\noutperforms state-of-the-art MARL methods on the widely adopted StarCraft\nbenchmark across different scenarios, and attention analysis is further\nconducted with valuable insights.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03939v2"
    },
    {
        "title": "Q-value Path Decomposition for Deep Multiagent Reinforcement Learning",
        "authors": [
            "Yaodong Yang",
            "Jianye Hao",
            "Guangyong Chen",
            "Hongyao Tang",
            "Yingfeng Chen",
            "Yujing Hu",
            "Changjie Fan",
            "Zhongyu Wei"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Recently, deep multiagent reinforcement learning (MARL) has become a highly\nactive research area as many real-world problems can be inherently viewed as\nmultiagent systems. A particularly interesting and widely applicable class of\nproblems is the partially observable cooperative multiagent setting, in which a\nteam of agents learns to coordinate their behaviors conditioning on their\nprivate observations and commonly shared global reward signals. One natural\nsolution is to resort to the centralized training and decentralized execution\nparadigm. During centralized training, one key challenge is the multiagent\ncredit assignment: how to allocate the global rewards for individual agent\npolicies for better coordination towards maximizing system-level's benefits. In\nthis paper, we propose a new method called Q-value Path Decomposition (QPD) to\ndecompose the system's global Q-values into individual agents' Q-values. Unlike\nprevious works which restrict the representation relation of the individual\nQ-values and the global one, we leverage the integrated gradient attribution\ntechnique into deep MARL to directly decompose global Q-values along trajectory\npaths to assign credits for agents. We evaluate QPD on the challenging\nStarCraft II micromanagement tasks and show that QPD achieves the\nstate-of-the-art performance in both homogeneous and heterogeneous multiagent\nscenarios compared with existing cooperative MARL algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03950v1"
    },
    {
        "title": "Industry 4.0: contributions of holonic manufacturing control\n  architectures and future challenges",
        "authors": [
            "William Derigent",
            "Olivier Cardin",
            "Damien Trentesaux"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The flexibility claimed by the next generation production systems induces a\ndeep modification of the behaviour and the core itself of the control systems.\nOver-connectivity and data management abilities targeted by Industry 4.0\nparadigm enable the emergence of more flexible and reactive control systems,\nbased on the cooperation of autonomous and connected entities in the\ndecision-making process. From most relevant articles extracted from existing\nliterature, a list of 10 key enablers for Industry 4.0 is first presented.\nDuring the last 20 years, the holonic paradigm has become a major paradigm of\nIntelligent Manufacturing Systems. After the presentation of the holonic\nparadigm and holon properties, this article highlights how historical and\ncurrent holonic control architectures can partly fulfil I4.0 key enablers. The\nremaining unfulfilled key enablers are then the subject of an extensive\ndiscussion on the remaining research perspectives on holonic architectures\nneeded to achieve a complete support of Industry4.0.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.04525v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning and Human Social Factors in Climate\n  Change Mitigation",
        "authors": [
            "Kyle Tilbury",
            "Jesse Hoey"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Many complex real-world problems, such as climate change mitigation, are\nintertwined with human social factors. Climate change mitigation, a social\ndilemma made difficult by the inherent complexities of human behavior, has an\nimpact at a global scale. We propose applying multi-agent reinforcement\nlearning (MARL) in this setting to develop intelligent agents that can\ninfluence the social factors at play in climate change mitigation. There are\nethical, practical, and technical challenges that must be addressed when\ndeploying MARL in this way. In this paper, we present these challenges and\noutline an approach to address them. Understanding how intelligent agents can\nbe used to impact human social factors is important to prevent their abuse and\ncan be beneficial in furthering our knowledge of these complex problems as a\nwhole. The challenges we present are not limited to our specific application\nbut are applicable to broader MARL. Thus, developing MARL for social factors in\nclimate change mitigation helps address general problems hindering MARL's\napplicability to other real-world problems while also motivating discussion on\nthe social implications of MARL deployment.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.05147v1"
    },
    {
        "title": "Internet of Smart-Cameras for Traffic Lights Optimization in Smart\n  Cities",
        "authors": [
            "Willy Carlos Tchuitcheu",
            "Christophe Bobda",
            "Md Jubaer Hossain Pantho"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Smart and decentralized control systems have recently been proposed to handle\nthe growing traffic congestion in urban cities. Proposed smart traffic light\nsolutions based on Wireless Sensor Network and Vehicular Ad-hoc NETwork are\neither unreliable and inflexible or complex and costly. Furthermore, the\nhandling of special vehicles such as emergency is still not viable, especially\nduring busy hours. Inspired by the emergence of distributed smart cameras, we\npresent a novel approach to traffic control at intersections. Our approach uses\nsmart cameras at intersections along with image understanding for real-time\ntraffic monitoring and assessment. Besides understanding the traffic flow, the\ncameras can detect and track special vehicles and help prioritize emergency\ncases. Traffic violations can be identified as well and traffic statistics\ncollected. In this paper, we introduce a flexible, adaptive and distributed\ncontrol algorithm that uses the information provided by distributed smart\ncameras to efficiently control traffic signals. Experimental results show that\nour collision-free approach outperforms the state-of-the-art of the average\nuser's waiting time in the queue and improves the routing of emergency vehicles\nin a cross congestion area.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.05410v1"
    },
    {
        "title": "Vision-Based Real-Time Indoor Positioning System for Multiple Vehicles",
        "authors": [
            "Maximilian Kloock",
            "Patrick Scheffe",
            "Isabelle Tülleners",
            "Janis Maczijewski",
            "Stefan Kowalewski",
            "Bassam Alrifaee"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We propose a novel external indoor positioning system that computes the\nposition and orientation of multiple model-scale vehicles. For this purpose, we\nuse a camera mounted at a height of 3.3m and LEDs attached to each vehicle. We\nreach an accuracy of about 1.1 cm for the position and around 0.6 {\\deg} for\nthe orientation in the mean. Our system is real-time capable with a soft\ndeadline of 20 ms. Moreover, it is robust against changing lighting conditions\nand reflections.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.05755v2"
    },
    {
        "title": "An Efficient Transfer Learning Framework for Multiagent Reinforcement\n  Learning",
        "authors": [
            "Tianpei Yang",
            "Weixun Wang",
            "Hongyao Tang",
            "Jianye Hao",
            "Zhaopeng Meng",
            "Hangyu Mao",
            "Dong Li",
            "Wulong Liu",
            "Chengwei Zhang",
            "Yujing Hu",
            "Yingfeng Chen",
            "Changjie Fan"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Transfer Learning has shown great potential to enhance single-agent\nReinforcement Learning (RL) efficiency. Similarly, Multiagent RL (MARL) can\nalso be accelerated if agents can share knowledge with each other. However, it\nremains a problem of how an agent should learn from other agents. In this\npaper, we propose a novel Multiagent Policy Transfer Framework (MAPTF) to\nimprove MARL efficiency. MAPTF learns which agent's policy is the best to reuse\nfor each agent and when to terminate it by modeling multiagent policy transfer\nas the option learning problem. Furthermore, in practice, the option module can\nonly collect all agent's local experiences for update due to the partial\nobservability of the environment. While in this setting, each agent's\nexperience may be inconsistent with each other, which may cause the inaccuracy\nand oscillation of the option-value's estimation. Therefore, we propose a novel\noption learning algorithm, the successor representation option learning to\nsolve it by decoupling the environment dynamics from rewards and learning the\noption-value under each agent's preference. MAPTF can be easily combined with\nexisting deep RL and MARL approaches, and experimental results show it\nsignificantly boosts the performance of existing methods in both discrete and\ncontinuous state spaces.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08030v4"
    },
    {
        "title": "Adversarial Impacts on Autonomous Decentralized Lightweight Swarms",
        "authors": [
            "Shaya Wolf",
            "Rafer Cooley",
            "Mike Borowczak"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The decreased size and cost of Unmanned Aerial Vehicles (UAVs) and Unmanned\nGround Vehicles (UGVs) has enabled the use of swarms of unmanned autonomous\nvehicles to accomplish a variety of tasks. By utilizing swarming behaviors, it\nis possible to efficiently accomplish coordinated tasks while minimizing\nper-drone computational requirements. Some drones rely on decentralized\nprotocols that exhibit emergent behavior across the swarm. While fully\ndecentralized algorithms remove obvious attack vectors their susceptibility to\nexternal influence is less understood. This work investigates the influences\nthat can compromise the functionality of an autonomous swarm leading to\nhazardous situations and cascading vulnerabilities. When a swarm is tasked with\nmissions involving the safety or health of humans, external influences could\nhave serious consequences. The adversarial swarm in this work utilizes an\nattack vector embedded within the decentralized movement algorithm of a\npreviously defined autonomous swarm designed to create a perimeter sentry\nswarm. Various simulations confirm the adversarial swarm's ability to capture\nsignificant portions (6-23%) of the perimeter.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.09109v1"
    },
    {
        "title": "iLQGames.jl: Rapidly Designing and Solving Differential Games in Julia",
        "authors": [
            "Lasse Peters",
            "Zachary N. Sunberg"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In many problems that involve multiple decision making agents, optimal\nchoices for each agent depend on the choices of others. Differential game\ntheory provides a principled formalism for expressing these coupled\ninteractions and recent work offers efficient approximations to solve these\nproblems to non-cooperative equilibria. iLQGames.jl is a framework for\ndesigning and solving differential games, built around the iterative\nlinear-quadratic method. It is written in the Julia programming language to\nallow flexible prototyping and integration with other research software, while\nleveraging the high-performance nature of the language to allow real-time\nexecution. The open-source software package can be found at\nhttps://github.com/lassepe/iLQGames.jl.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.10185v2"
    },
    {
        "title": "Multi-agent maintenance scheduling based on the coordination between\n  central operator and decentralized producers in an electricity market",
        "authors": [
            "Pegah Rokhforoz",
            "Blazhe Gjorgiev",
            "Giovanni Sansavini",
            "Olga Fink"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Condition-based and predictive maintenance enable early detection of critical\nsystem conditions and thereby enable decision makers to forestall faults and\nmitigate them. However, decision makers also need to take the operational and\nproduction needs into consideration for optimal decision-making when scheduling\nmaintenance activities. Particularly in network systems, such as power grids,\ndecisions on the maintenance of single assets can affect the entire network and\nare, therefore, more complex. This paper proposes a two-level multi-agent\ndecision support systems for the generation maintenance decision (GMS) of power\ngrids in an electricity markets. The aim of the GMS is to minimize the\ngeneration cost while maximizing the system reliability. The proposed framework\nintegrates a central coordination system, i.e. the transmission system operator\n(TSO), and distributed agents representing power generation units that act to\nmaximize their profit and decide about the optimal maintenance time slots while\nensuring the fulfilment of the energy demand. The objective function of agents\n(power generation companies) is based on the reward and the penalty that they\nobtain from the interplay between power production and loss of production due\nto failure, respectively. The optimal strategy of agents is then derived using\na distributed algorithm, where agents choose their optimal maintenance decision\nand send their decisions to the central coordinating system. The TSO decides\nwhether to accept the agents' decisions by considering the market reliability\naspects and power supply constraints. To solve this coordination problem, we\npropose a negotiation algorithm using an incentive signal to coordinate the\nagents' and central system's decisions such that all the agents' decisions can\nbe accepted by the central system. We demonstrate the efficiency of our\nproposed algorithm using a IEEE 39 bus system.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.12217v3"
    },
    {
        "title": "A Checklist for the Evaluation of Pedestrian Simulation Software\n  Functionalities",
        "authors": [
            "Mizar Luca Federici",
            "Lorenza Manenti",
            "Sara Manzoni"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The employment of micro-simulation (agent-based) tools in the phase of design\nof public and private spaces and facilities and for the definition of transport\nschemes that impact on pedestrian flows, thanks to their achieved accuracy and\npredictive capacity, has become a consolidated practice. These instruments\nprovide support to the organization of spaces, services and facilities and to\nthe definition of management procedures for normal and emergency situations.\nThe employment of these tools is effective for various but not for all the\ncontexts, nevertheless new features and functions are under constant\ndevelopment and new products are often launched on the market. Therefore, there\nis a higher necessity of a standard criteria both for the evaluation of the\nkinds of function that these software provide, at use of practitioners and\nend-users, and for the definition of software requirements as a reference for\nthe developers that aim at being competitive on this market.\n  On the basis of our experience as pedestrian modellers and as researchers in\nthe crowd modelling area, we designed a comprehensive and detailed ready-to-use\nchecklist for the quantitative evaluation of Pedestrian Simulation Software\nfunctionalities that aims at capturing all the aspects that we claim that are\nuseful to undertake a professional study. These functions in our opinion are\nnecessary to provide accurate results in the planning of new facilities or\nschemes that involve pedestrian activities. With this work we propose a set of\ncriteria of evaluation for these products also to encourage a debate for the\ndefinition of objective standards for pedestrian simulation software\ncertification.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.7717v2"
    },
    {
        "title": "Real scenario and simulations on GLOSA traffic light system for reduced\n  CO2 emissions, waiting time and travel time",
        "authors": [
            "Marie-Ange Lebre",
            "Frédéric Le Mouël",
            "Eric Ménard",
            "Alexandre Garnault",
            "Benazouz Bradaï",
            "Vanessa Picron"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Cooperative ITS is enabling vehicles to communicate with the infrastructure\nto provide improvements in traffic control. A promising approach consists in\nanticipating the road profile and the upcoming dynamic events like traffic\nlights. This topic has been addressed in the French public project Co-Drive\nthrough functions developed by Valeo named Green Light Optimal Speed Advisor\n(GLOSA). The system advises the optimal speed to pass the next traffic light\nwithout stopping. This paper presents results of its performance in different\nscenarios through simulations and real driving measurements. A scaling is done\nin an urban area, with different penetration rates in vehicle and\ninfrastructure equipment for vehicular communication. Our simulation results\nindicate that GLOSA can reduce CO2 emissions, waiting time and travel time,\nboth in experimental conditions and in real traffic conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.01965v1"
    },
    {
        "title": "Organization of Multi-Agent Systems: An Overview",
        "authors": [
            "Hosny Ahmed Abbas",
            "Samir Ibrahim Shaheen",
            "Mohammed Hussein Amin"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  In complex, open, and heterogeneous environments, agents must be able to\nreorganize towards the most appropriate organizations to adapt unpredictable\nenvironment changes within Multi-Agent Systems (MAS). Types of reorganization\ncan be seen from two different levels. The individual agents level\n(micro-level) in which an agent changes its behaviors and interactions with\nother agents to adapt its local environment. And the organizational level\n(macro-level) in which the whole system changes it structure by adding or\nremoving agents. This chapter is dedicated to overview different aspects of\nwhat is called MAS Organization including its motivations, paradigms, models,\nand techniques adopted for statically or dynamically organizing agents in MAS.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.09032v1"
    },
    {
        "title": "Conflict Solution According to \"Aggressiveness\" of Agents in\n  Floor-Field-Based Model",
        "authors": [
            "Pavel Hrabák",
            "Marek Bukáček"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This contribution introduces an element of \"aggressiveness\" into the\nFloor-Field based model with adaptive time-span. The aggressiveness is\nunderstood as an ability to win conflicts and push through the crowd. From\nexperiments it is observed that this ability is not directly correlated with\nthe desired velocity in the free flow regime. The influence of the\naggressiveness is studied by means of the dependence of the travel time on the\noccupancy of a room. A simulation study shows that the conflict solution based\non the aggressiveness parameter can mimic the observations from the experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.07038v1"
    },
    {
        "title": "Applying DCOP to User Association Problem in Heterogeneous Networks with\n  Markov Chain Based Algorithm",
        "authors": [
            "Peibo Duan",
            "Guoqiang Mao",
            "Changsheng Zhang",
            "Bin Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Multi-agent systems (MAS) is able to characterize the behavior of individual\nagent and the interaction between agents. Thus, it motivates us to leverage the\ndistributed constraint optimization problem (DCOP), a framework of modeling\nMAS, to solve the user association problem in heterogeneous networks (HetNets).\nTwo issues we have to consider when we take DCOP into the application of HetNet\nincluding: (i) How to set up an effective model by DCOP taking account of the\nnegtive impact of the increment of users on the modeling process (ii) Which\nkind of algorithms is more suitable to balance the time consumption and the\nquality of soltuion. Aiming to overcome these issues, we firstly come up with\nan ECAV-$\\eta$ (Each Connection As Variable) model in which a parameter $\\eta$\nwith an adequate assignment ($\\eta=3$ in this paper) is able to control the\nscale of the model. After that, a Markov chain (MC) based algorithm is proposed\non the basis of log-sum-exp function. Experimental results show that the\nsolution obtained by DCOP framework is better than the one obtained by the\nMax-SINR algorithm. Comparing with the Lagrange dual decomposition based method\n(LDD), the solution performance has been improved since there is no need to\ntransform original problem into a satisfied one. In addition, it is also\napparent that the DCOP based method has better robustness than LDD when the\nnumber of users increases but the available resource at base stations are\nlimited.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.01289v1"
    },
    {
        "title": "On the Computational Complexity of Variants of Combinatorial Voter\n  Control in Elections",
        "authors": [
            "Leon Kellerhals",
            "Viatcheslav Korenwein",
            "Philipp Zschoche",
            "Robert Bredereck",
            "Jiehua Chen"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Voter control problems model situations in which an external agent tries\ntoaffect the result of an election by adding or deleting the fewest number of\nvoters. The goal of the agent is to make a specific candidate either win\n(\\emph{constructive} control) or lose (\\emph{destructive} control) the\nelection. We study the constructive and destructive voter control problems\nwhenadding and deleting voters have a \\emph{combinatorial flavor}: If we add\n(resp.\\ delete) a voter~$v$, we also add (resp.\\ delete) a bundle~$\\kappa(v) $\nof voters that are associated with~$v$. While the bundle~$\\kappa(v)$ may have\nmore than one voter, a voter may also be associated with more than one voter.\nWe analyze the computational complexity of the four voter control problems for\nthe Plurality rule. We obtain that, in general, making a candidate lose is\ncomputationally easier than making her win. In particular, if the bundling\nrelation is symmetric (i.e.\\ $\\forall w\\colon w \\in \\kappa(v) \\Leftrightarrow v\n\\in \\kappa(w) $), and if each voter has at most two voters associated with him,\nthen destructive control is polynomial-time solvable while the constructive\nvariant remains $\\NP$-hard. Even if the bundles are disjoint (i.e.\\ $\\forall\nw\\colon w \\in \\kappa(v) \\Leftrightarrow \\kappa(v) = \\kappa(w) $), the\nconstructive problem variants remain intractable. Finally, the minimization\nvariant of constructive control by adding voters does not admit an efficient\napproximation algorithm, unless P=NP.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.05108v1"
    },
    {
        "title": "Socio-Affective Agents as Models of Human Behaviour in the Networked\n  Prisoner's Dilemma",
        "authors": [
            "Joshua D. A. Jung",
            "Jesse Hoey"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Affect Control Theory (ACT) is a powerful and general sociological model of\nhuman affective interaction. ACT provides an empirically derived mathematical\nmodel of culturally shared sentiments as heuristic guides for human decision\nmaking. BayesACT, a variant on classical ACT, combines affective reasoning with\ncognitive (denotative or logical) reasoning as is traditionally found in AI.\nBayes\\-ACT allows for the creation of agents that are both emotionally guided\nand goal-directed. In this work, we simulate BayesACT agents in the Iterated\nNetworked Prisoner's Dilemma (INPD), and we show four out of five known\nproperties of human play in INPD are replicated by these socio-affective\nagents. In particular, we show how the observed human behaviours of network\nstructure invariance, anti-correlation of cooperation and reward, and player\ntype stratification are all clearly emergent properties of the networked\nBayesACT agents. We further show that decision hyteresis (Moody Conditional\nCooperation) is replicated by BayesACT agents in over $2/3$ of the cases we\nhave considered. In contrast, previously used imitation-based agents are only\nable to replicate one of the five properties. We discuss the implications of\nthese findings in the development of human-agent societies.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.09112v1"
    },
    {
        "title": "Structurally Observable Distributed Networks of Agents under Cost and\n  Robustness Constraints",
        "authors": [
            "Stephen Kruzick",
            "Sérgio Pequito",
            "Soummya Kar",
            "José M. F. Moura",
            "A. Pedro Aguiar"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In many problems, agents cooperate locally so that a leader or fusion center\ncan infer the state of every agent from probing the state of only a small\nnumber of agents. Versions of this problem arise when a fusion center\nreconstructs an extended physical field by accessing the state of just a few of\nthe sensors measuring the field, or a leader monitors the formation of a team\nof robots. Given a link cost, the paper presents a polynomial time algorithm to\ndesign a minimum cost coordinated network dynamics followed by the agents,\nunder an observability constraint. The problem is placed in the context of\nstructural observability and solved even when up to k agents in the coordinated\nnetwork dynamics fail.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.02597v1"
    },
    {
        "title": "Multi-agent systems and decentralized artificial superintelligence",
        "authors": [
            "S. Ponomarev",
            "A. E. Voronkov"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Multi-agents systems communication is a technology, which provides a way for\nmultiple interacting intelligent agents to communicate with each other and with\nenvironment. Multiple-agent systems are used to solve problems that are\ndifficult for solving by individual agent. Multiple-agent communication\ntechnologies can be used for management and organization of computing fog and\nact as a global, distributed operating system. In present publication we\nsuggest technology, which combines decentralized P2P BOINC general-purpose\ncomputing tasks distribution, multiple-agents communication protocol and\nsmart-contract based rewards, powered by Ethereum blockchain. Such system can\nbe used as distributed P2P computing power market, protected from any central\nauthority. Such decentralized market can further be updated to system, which\nlearns the most efficient way for software-hardware combinations usage and\noptimization. Once system learns to optimize software-hardware efficiency it\ncan be updated to general-purpose distributed intelligence, which acts as\ncombination of single-purpose AI.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.08529v1"
    },
    {
        "title": "The Role of Data-driven Priors in Multi-agent Crowd Trajectory\n  Estimation",
        "authors": [
            "Gang Qiao",
            "Sejong Yoon",
            "Mubbasir Kapadia",
            "Vladimir Pavlovic"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Trajectory interpolation, the process of filling-in the gaps and removing\nnoise from observed agent trajectories, is an essential task for the motion\ninference in multi-agent setting. A desired trajectory interpolation method\nshould be robust to noise, changes in environments or agent densities, while\nalso being yielding realistic group movement behaviors. Such realistic\nbehaviors are, however, challenging to model as they require avoidance of\nagent-agent or agent-environment collisions and, at the same time, seek\ncomputational efficiency. In this paper, we propose a novel framework composed\nof data-driven priors (local, global or combined) and an efficient optimization\nstrategy for multi-agent trajectory interpolation. The data-driven priors\nimplicitly encode the dependencies of movements of multiple agents and the\ncollision-avoiding desiderata, enabling elimination of costly pairwise\ncollision constraints and resulting in reduced computational complexity and\noften improved estimation. Various combinations of priors and optimization\nalgorithms are evaluated in comprehensive simulated experiments. Our\nexperimental results reveal important insights, including the significance of\nthe global flow prior and the lesser-than-expected influence of data-driven\ncollision priors.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.03354v1"
    },
    {
        "title": "JADE - A Platform for Research on Cooperation of Physical and Virtual\n  Agents",
        "authors": [
            "Wiktor B. Daszczuk",
            "Jerzy Mieścicki"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In the ICS, WUT a platform for simulation of cooperation of physical and\nvirtual mobile agents is under development. The paper describes the motivation\nof the research, an organization of the platform, a model of agent, and the\nprinciples of design of the platform. Several experimental simulations are\nbriefly described.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.08852v1"
    },
    {
        "title": "A Generic Approach for Accelerating Belief Propagation based DCOP\n  Algorithms via A Branch-and-Bound Technique",
        "authors": [
            "Ziyu Chen",
            "Xingqiong Jiang",
            "Yanchen Deng",
            "Dingding Chen",
            "Zhongshi He"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Belief propagation approaches, such as Max-Sum and its variants, are a kind\nof important methods to solve large-scale Distributed Constraint Optimization\nProblems (DCOPs). However, for problems with n-ary constraints, these\nalgorithms face a huge challenge since their computational complexity scales\nexponentially with the number of variables a function holds. In this paper, we\npresent a generic and easy-to-use method based on a branch-and-bound technique\nto solve the issue, called Function Decomposing and State Pruning (FDSP). We\ntheoretically prove that FDSP can provide monotonically non-increasing upper\nbounds and speed up belief propagation based DCOP algorithms without an effect\non solution quality. Also, our empirically evaluation indicates that FDSP can\nreduce 97\\% of the search space at least and effectively accelerate Max-Sum,\ncompared with the state-of-the-art.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.06863v2"
    },
    {
        "title": "Shared Autonomous Vehicle Simulation and Service Design",
        "authors": [
            "Reza Vosooghi",
            "Jakob Puchinger",
            "Marija Jankovic",
            "Anthony Vouillon"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Today, driverless cars, as a new technology that allows a more accessible,\ndynamic and intelligent form of Shared Mobility, are expected to revolutionize\nurban transportation. One of the conceivable mobility services based on\ndriverless cars is shared autonomous vehicles (SAVs). This service could merge\ncabs, carsharing, and ridesharing systems into a singular transportation mode.\nHowever, the success and competitiveness of future SAV services depend on their\noperational models, which are linked intrinsically to the service configuration\nand fleet specification. In addition, any change in operational models will\nresult in a different demand. Using a comprehensive framework of SAV simulation\nin a multi-modal dynamic demand system with integrated SAV user taste\nvariation, this study evaluates the performance of various SAV fleets and\nvehicle capacities serving travelers across the Rouen Normandie metropolitan\narea in France. Also, the impact of ridesharing and rebalancing strategies on\nservice performance is investigated.Research results suggest that the\nperformance of SAV is strongly correlated with the fleet size and the strategy\nof individual or shared rides. Further analysis indicates that for the pricing\nscheme proposed in this study (i.e., 20% lower for ridesharing scenario), the\nstandard 4-seats car with shared ride remains the best option among all\nscenarios. The results also underline that enabling vehicle-rebalancing\nstrategies may have an important effect on both user and service-related\nmetrics. The estimated SAV average and maximum driven distance prove the\nimportance of vehicle range and charging station deployment.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.07588v2"
    },
    {
        "title": "Reasoning about Hypothetical Agent Behaviours and their Parameters",
        "authors": [
            "Stefano V. Albrecht",
            "Peter Stone"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Agents can achieve effective interaction with previously unknown other agents\nby maintaining beliefs over a set of hypothetical behaviours, or types, that\nthese agents may have. A current limitation in this method is that it does not\nrecognise parameters within type specifications, because types are viewed as\nblackbox mappings from interaction histories to probability distributions over\nactions. In this work, we propose a general method which allows an agent to\nreason about both the relative likelihood of types and the values of any\nbounded continuous parameters within types. The method maintains individual\nparameter estimates for each type and selectively updates the estimates for\nsome types after each observation. We propose different methods for the\nselection of types and the estimation of parameter values. The proposed methods\nare evaluated in detailed experiments, showing that updating the parameter\nestimates of a single type after each observation can be sufficient to achieve\ngood performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.11064v1"
    },
    {
        "title": "Interactive Physics-Inspired Traffic Congestion Management",
        "authors": [
            "Hossein Rastgoftar"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper proposes a new physics-based approach to effectively control\ncongestion in a network of interconnected roads (NOIR). The paper integrates\nmass flow conservation and diffusion-based dynamics to model traffic\ncoordination in a NOIR. The mass conservation law is used to model the traffic\ndensity dynamics across the NOIR while the diffusion law is applied to include\ntraffic speed and motion direction into planning. This paper offers an analogy\nbetween traffic coordination in a transportation system and heat flux in a\nthermal system to define a potential filed over the NOIR. The paper also\ndevelops an interactive light-based and boundary control to manage traffic\ncongestion through optimizing the traffic signal operations and controlling\ntraffic flows at the NOIR boundary nodes. More specifically, a model predictive\nboundary control optimizes the NOIR inflow traffic while a receding horizon\noptimizer assigns the optimal movement phases at the NOIR intersections. For\nsimulation, the paper models traffic congestion in a heterogeneous NOIR with a\nlarge number of interior and boundary nodes where the proposed interactive\ncontrol can successfully manage the congestion.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.11362v2"
    },
    {
        "title": "Fixed-Time Cooperative Tracking Control for Double-Integrator\n  Multi-Agent Systems: A Time-Based Generator Approach",
        "authors": [
            "Qiang Chen",
            "Yu Zhao",
            "Guanghui Wen",
            "Guoqing Shi",
            "Xinghuo Yu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, both the fixed-time distributed consensus tracking and the\nfixed-time distributed average tracking problems for double-integrator-type\nmulti-agent systems with bounded input disturbances are studied, respectively.\nFirstly, a new practical robust fixed-time sliding mode control method based on\nthe time-based generator is proposed. Secondly, a fixed-time distributed\nconsensus tracking observer for double-integrator-type multi-agent systems is\ndesigned to estimate the state disagreements between the leader and the\nfollowers under undirected and directed communication, respectively. Thirdly, a\nfixed-time distributed average tracking observer for double-integrator-type\nmulti-agent systems is designed to measure the average value of reference\nsignals under undirected communication. Note that both the observers for the\ndistributed consensus tracking and the distributed average tracking are devised\nbased on time-based generators and can be extended to that of high-order\nmulti-agent systems trivially. Furthermore, by combing the fixed-time sliding\nmode control with the fixed-time observers, the fixed-time controllers are\ndesigned to solve the distributed consensus tracking and the distributed\naverage tracking problems. Finally, a few numerical simulations are shown to\nverify the results.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.01490v1"
    },
    {
        "title": "Modelling Gossip Interactions in Open Multi-Agent Systems",
        "authors": [
            "Charles Monnoyer de Galland",
            "Samuel Martin",
            "Julien M. Hendrickx"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We consider open multi-agent systems, which are systems subject to frequent\narrivals and departures of agents while the studied process takes place. We\nstudy the behavior of all-to-all pairwise gossip interactions in such open\nsystems. Arrivals and departures of agents imply that the composition and size\nof the system evolve with time, and in particular prevent convergence. We\ndescribe the expected behavior of the system by showing that the evolution of\nscale-independent quantities can be characterized exactly by a fixed-size\nlinear dynamical system. We apply this approach to characterize the evolution\nof the two first moments (and thus also of the variance) for open systems of\nfixed and variable size. Our approach is based on the continuous-time modelling\nof random asynchronous events impacting the systems (gossip steps, arrivals,\ndepartures, and replacements), and can be extended to other types of events.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.02970v2"
    },
    {
        "title": "Metis: Multi-Agent Based Crisis Simulation System",
        "authors": [
            "George Sidiropoulos",
            "Chairi Kiourt",
            "Lefteris Moussiades"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  With the advent of the computational technologies (Graphics Processing Units\n- GPUs) and Machine Learning, the research domain of crowd simulation for\ncrisis management has flourished. Along with the new techniques and\nmethodologies that have been proposed all those years, aiming to increase the\nrealism of crowd simulation, several crisis simulation systems/tools have been\ndeveloped, but most of them focus on special cases without providing users the\nability to adapt them based on their needs. Towards these directions, in this\npaper, we introduce a novel multi-agent-based crisis simulation system for\nindoor cases. The main advantage of the system is its ease of use feature,\nfocusing on non-expert users (users with little to no programming skills) that\ncan exploit its capabilities a, adapt the entire environment based on their\nneeds (Case studies) and set up building evacuation planning experiments with\nsome of the most popular Reinforcement Learning algorithms. Simply put, the\nsystem's features focus on dynamic environment design and crisis management,\ninterconnection with popular Reinforcement Learning libraries, agents with\ndifferent characteristics (behaviors), fire propagation parameterization,\nrealistic physics based on popular game engine, GPU-accelerated agents training\nand simulation end conditions. A case study exploiting a popular reinforcement\nlearning algorithm, for training of the agents, presents the dynamics and the\ncapabilities of the proposed systems and the paper is concluded with the\nhighlights of the system and some future directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.03934v1"
    },
    {
        "title": "Value Alignment Equilibrium in Multiagent Systems",
        "authors": [
            "Nieves Montes",
            "Carles Sierra"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Value alignment has emerged in recent years as a basic principle to produce\nbeneficial and mindful Artificial Intelligence systems. It mainly states that\nautonomous entities should behave in a way that is aligned with our human\nvalues. In this work, we summarize a previously developed model that considers\nvalues as preferences over states of the world and defines alignment between\nthe governing norms and the values. We provide a use-case for this framework\nwith the Iterated Prisoner's Dilemma model, which we use to exemplify the\ndefinitions we review. We take advantage of this use-case to introduce new\nconcepts to be integrated with the established framework: alignment equilibrium\nand Pareto optimal alignment. These are inspired on the classical Nash\nequilibrium and Pareto optimality, but are designed to account for any value we\nwish to model in the system.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.07619v3"
    },
    {
        "title": "Electing the Executive Branch",
        "authors": [
            "Rutvik Page",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The executive branch, or government, is typically not elected directly by the\npeople, but rather formed by another elected body or person such as the\nparliament or the president. As a result, its members are not directly\naccountable to the people, individually or as a group. We consider a scenario\nin which the members of the government are elected directly by the people, and\nwish to achieve proportionality while doing so. We propose a formal model\nconsisting of $k$ offices, each with its own disjoint set of candidates, and a\nset of voters who provide approval ballots for all offices. We wish to identify\ngood aggregation rules that assign one candidate to each office. As using a\nsimple majority vote for each office independently might result in disregarding\nminority preferences altogether, here we consider an adaptation of the greedy\nvariant of Proportional Approval Voting (GreedyPAV) to our setting, and\ndemonstrate -- through computer-based simulations -- how voting for all offices\ntogether using this rule overcomes this weakness. We note that the approach is\napplicable also to a party that employs direct democracy, where party members\nelect the party's representatives in a coalition government.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.09734v4"
    },
    {
        "title": "Learning to Play against Any Mixture of Opponents",
        "authors": [
            "Max Olan Smith",
            "Thomas Anthony",
            "Yongzhao Wang",
            "Michael P. Wellman"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Intuitively, experience playing against one mixture of opponents in a given\ndomain should be relevant for a different mixture in the same domain. We\npropose a transfer learning method, Q-Mixing, that starts by learning Q-values\nagainst each pure-strategy opponent. Then a Q-value for any distribution of\nopponent strategies is approximated by appropriately averaging the separately\nlearned Q-values. From these components, we construct policies against all\nopponent mixtures without any further training. We empirically validate\nQ-Mixing in two environments: a simple grid-world soccer environment, and a\ncomplicated cyber-security game. We find that Q-Mixing is able to successfully\ntransfer knowledge across any mixture of opponents. We next consider the use of\nobservations during play to update the believed distribution of opponents. We\nintroduce an opponent classifier -- trained in parallel to Q-learning, using\nthe same data -- and use the classifier results to refine the mixing of\nQ-values. We find that Q-Mixing augmented with the opponent classifier function\nperforms comparably, and with lower variance, than training directly against a\nmixed-strategy opponent.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.14180v2"
    },
    {
        "title": "Disappointment in Social Choice Protocols",
        "authors": [
            "Mohammad Ali Javidian",
            "Rasoul Ramezanian"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Social choice theory is a theoretical framework for analysis of combining\nindividual preferences, interests, or welfare to reach a collective decision or\nsocial welfare in some sense. We introduce a new criterion for social choice\nprotocols called social disappointment. Social disappointment happens when the\noutcome of a voting system occurs for those alternatives which are at the end\nof at least half of individual preference profiles. Here we introduce some\nprotocols that prevent social disappointment and prove an impossibility theorem\nbased on this key concept.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.2386v1"
    },
    {
        "title": "A Dynamic Multi Agent based scheduling for flexible flow line\n  manufacturing system accompanied by dynamic customer demand",
        "authors": [
            "Daniral Roudi",
            "Ali Vatankhah Barenji",
            "Reza Vatankhah Barenji",
            "Majid Hashemipour"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Dynamic rescheduling decision-making problem is an important issue in modern\nmanufacturing system with the feature of combinational computation complexity.\nThis paper introduces a multi-agent based approach using the detailed process,\nprovided by Prometheus methodology, which used for the design of a simultaneous\ndynamic rescheduling decision making for flexible flow line manufacturing\nsystem that working under dynamic customer demand. The application has been\ncompletely modeled with the Prometheus Design Tool (PDT), which offers full\nsupport to Prometheus Methodology. The proposed dynamic scheduling decision\nmaking system is developed for Automated UPVC door and Windows Company and can\nbe support both static and dynamic scheduling.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.00518v1"
    },
    {
        "title": "Fictitious play for cooperative action selection in robot teams",
        "authors": [
            "Michalis Smyrnakis",
            "Sandor M. Veres"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  A game theoretic distributed decision making approach is presented for the\nproblem of control effort allocation in a robotic team based on a novel variant\nof fictitious play. The proposed learning process allows the robots to\naccomplish their objectives by coordinating their actions in order to\nefficiently complete their tasks. In particular, each robot of the team\npredicts the other robots' planned actions while making decisions to maximise\ntheir own expected reward that depends on the reward for joint successful\ncompletion of the task. Action selection is interpreted as an $n$-player\ncooperative game. The approach presented can be seen as part of the\n\\emph{Belief Desire Intention} (BDI) framework, also can address the problem of\ncooperative, legal, safe, considerate and emphatic decisions by robots if their\nindividual and group rewards are suitably defined. After theoretical analysis\nthe performance of the proposed algorithm is tested on four simulation\nscenarios. The first one is a coordination game between two material handling\nrobots, the second one is a warehouse patrolling task by a team of robots, the\nthird one presents a coordination mechanism between two robots that carry a\nheavy object on a corridor and the fourth one is an example of coordination on\na sensors network.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.05638v1"
    },
    {
        "title": "SimAthens: A spatial microsimulation approach to the estimation and\n  analysis of small-area income distributions and poverty rates in Athens,\n  Greece",
        "authors": [
            "Anastasia Panori",
            "Dimitris Ballas",
            "Yannis Psycharis"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Published during a severe economic crisis, this study presents the first\nspatial microsimulation model for the analysis of income inequalities and\npoverty in Greece. First, we present a brief overview of the method and discuss\nits potential for the analysis of multidimensional poverty and income\ninequality in Greece. We then present the SimAthens model, based on a\ncombination of small-area demographic and socioeconomic information available\nfrom the Greek census of population with data from the European Union\nStatistics on Income and Living Conditions (EU-SILC). The model is based on an\niterative proportional fitting (IPF) algorithm, and is used to reweigh EU-SILC\nrecords to fit in small-area descriptions for Athens based on 2001 and 2011\ncensuses. This is achieved by using demographic and socioeconomic\ncharacteristics as constraint variables. Finally, synthesis of the labor market\nand occupations are chosen as the main variables for externally validating our\nresults, in order to verify the integrity of the model. Results of this\nexternal validation process are found to be extremely satisfactory, indicating\na high goodness of fit between simulated and real values. Finally, the study\npresents a number of model outputs, illustrating changes in social and economic\ngeography, during a severe economic crisis, offering a great opportunity for\ndiscussing further potential of this model in policy analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.07824v1"
    },
    {
        "title": "Robust Sequential Path Planning Under Disturbances and Adversarial\n  Intruder",
        "authors": [
            "Mo Chen",
            "Somil Bansal",
            "Jaime F. Fisac",
            "Claire J. Tomlin"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Provably safe and scalable multi-vehicle path planning is an important and\nurgent problem due to the expected increase of automation in civilian airspace\nin the near future. Although this problem has been studied in the past, there\nhas not been a method that guarantees both goal satisfaction and safety for\nvehicles with general nonlinear dynamics while taking into account disturbances\nand potential adversarial agents, to the best of our knowledge. Hamilton-Jacobi\n(HJ) reachability is the ideal tool for guaranteeing goal satisfaction and\nsafety under such scenarios, and has been successfully applied to many\nsmall-scale problems. However, a direct application of HJ reachability in most\ncases becomes intractable when there are more than two vehicles due to the\nexponentially scaling computational complexity with respect to system\ndimension. In this paper, we take advantage of the guarantees HJ reachability\nprovides, and eliminate the computation burden by assigning a strict priority\nordering to the vehicles under consideration. Under this sequential path\nplanning (SPP) scheme, vehicles reserve \"space-time\" portions in the airspace,\nand the space-time portions guarantee dynamic feasibility, collision avoidance,\nand optimality of the paths given the priority ordering. With a computation\ncomplexity that scales quadratically when accounting for both disturbances and\nan intruder, and linearly when accounting for only disturbances, SPP can\ntractably solve the multi-vehicle path planning problem for vehicles with\ngeneral nonlinear dynamics in a practical setting. We demonstrate our theory in\nrepresentative simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.08364v1"
    },
    {
        "title": "Distributed Estimation for Adaptive Networks Based on Serial-Inspired\n  Diffusion",
        "authors": [
            "C. T. Healy",
            "R. C. de Lamare"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Distributed estimation and processing in networks modeled by graphs have\nreceived a great deal of interest recently, due to the benefits of\ndecentralised processing in terms of performance and robustness to\ncommunications link failure between nodes of the network. Diffusion-based\nalgorithms have been demonstrated to be among the most effective for\ndistributed signal processing problems, through the combination of local node\nestimate updates and sharing of information with neighbour nodes through\ndiffusion. In this work, we develop a serial-inspired approach based on\nmessage-passing strategies that provides a significant improvement in\nperformance over prior art. The concept of serial processing in the graph has\nbeen successfully applied in sum-product based algorithms and here provides\ninspiration for an algorithm which makes use of the most up-to-date information\nin the graph in combination with the diffusion approach to offer improved\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.08951v1"
    },
    {
        "title": "Disruptive innovations in RoboCup 2D Soccer Simulation League: from\n  Cyberoos'98 to Gliders2016",
        "authors": [
            "Mikhail Prokopenko",
            "Peter Wang"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We review disruptive innovations introduced in the RoboCup 2D Soccer\nSimulation League over the twenty years since its inception, and trace the\nprogress of our champion team (Gliders). We conjecture that the League has been\ndeveloping as an ecosystem shaped by diverse approaches taken by participating\nteams, increasing in its overall complexity. A common feature is that different\nchampion teams succeeded in finding a way to decompose the enormous\nsearch-space of possible single- and multi-agent behaviours, by automating the\nexploration of the problem space with various techniques which accelerated the\nsoftware development efforts. These methods included interactive debugging,\nmachine learning, automated planning, and opponent modelling. The winning\napproach developed by Gliders is centred on human-based evolutionary\ncomputation which optimised several components such as an action-dependent\nevaluation function, dynamic tactics with Voronoi diagrams, information\ndynamics, and bio-inspired collective behaviour.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.00947v1"
    },
    {
        "title": "Real-time Collision Handling in Railway Network:An Agent-based Approach",
        "authors": [
            "Poulami Dalapati",
            "Abhijeet Padhy",
            "Bhawana Mishra",
            "Animesh Dutta",
            "Swapan Bhattacharya"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Advancement in intelligent transportation systems with complex operations\nrequires autonomous planning and management to avoid collisions in day-to-day\ntraffic. As failure and/or inadequacy in traffic safety system are\nlife-critical, such collisions must be detected and resolved in an efficient\nway to manage continuously rising traffic. In this paper, we address different\ntypes of collision scenarios along with their early detection and resolution\ntechniques in a complex railway system. In order to handle collisions\ndynamically in distributed manner, a novel agent based solution approach is\nproposed using the idea of max-sum algorithm, where each agent (train agent,\nstation agent, and junction agent) communicates and cooperates with others to\ngenerate a good feasible solution that keeps the system in a safe state, i.e.,\ncollision free. We implement the proposed mechanism in Java Agent DEvelopment\nFramework (JADE). The results are evaluated with exhaustive experiments and\ncompared with different existing collision handling methods to show the\nefficiency of our proposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.01260v1"
    },
    {
        "title": "Analyzing Traffic Delay at Unmanaged Intersections",
        "authors": [
            "Changliu Liu",
            "Mykel J. Kochenderfer"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  At an unmanaged intersection, it is important to understand how much traffic\ndelay may be caused as a result of microscopic vehicle interactions.\nConventional traffic simulations that explicitly track these interactions are\ntime-consuming. Prior work introduced an analytical traffic model for unmanaged\nintersections. The traffic delay at the intersection is modeled as an\nevent-driven stochastic process, whose dynamics encode microscopic vehicle\ninteractions. This paper studies the traffic delay in a two-lane intersection\nusing the model. We perform rigorous analyses concerning the distribution of\ntraffic delay under different scenarios. We then discuss the relationships\nbetween traffic delay and multiple factors such as traffic flow density,\nunevenness of traffic flows, temporal gaps between two consecutive vehicles,\nand the passing order.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.02660v1"
    },
    {
        "title": "Partial Replanning for Decentralized Dynamic Task Allocation",
        "authors": [
            "Noam Buckman",
            "Han-Lim Choi",
            "Jonathan P. How"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In time-sensitive and dynamic missions, multi-UAV teams must respond quickly\nto new information and objectives. This paper presents a dynamic decentralized\ntask allocation algorithm for allocating new tasks that appear online during\nthe solving of the task allocation problem. Our algorithm extends the\nConsensus-Based Bundle Algorithm (CBBA), a decentralized task allocation\nalgorithm, allowing for the fast allocation of new tasks without a full\nreallocation of existing tasks. CBBA with Partial Replanning (CBBA-PR) enables\nthe team to trade-off between convergence time and increased coordination by\nresetting a portion of their previous allocation at every round of bidding on\ntasks. By resetting the last tasks allocated by each agent, we are able to\nensure the convergence of the team to a conflict-free solution. CBBA-PR can be\nfurther improved by reducing the team size involved in the replanning, further\nreducing the communication burden of the team and runtime of CBBA-PR. Finally,\nwe validate the faster convergence and improved solution quality of CBBA-PR in\nmulti-UAV simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.04836v2"
    },
    {
        "title": "Aggregation over Metric Spaces: Proposing and Voting in Elections,\n  Budgeting, and Legislation",
        "authors": [
            "Laurent Bulteau",
            "Gal Shahaf",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We present a unifying framework encompassing many social choice settings.\nViewing each social choice setting as voting in a suitable metric space, we\nconsider a general model of social choice over metric spaces, in\nwhich---similarly to the spatial model of elections---each voter specifies an\nideal element of the metric space. The ideal element functions as a vote, where\neach voter prefers elements that are closer to her ideal element. But it also\nfunctions as a proposal, thus making all participants equal not only as voters\nbut also as proposers. We consider Condorcet aggregation and a continuum of\nsolution concepts, ranging from minimizing the sum of distances to minimizing\nthe maximum distance.\n  We study applications of the abstract model to various social choice\nsettings, including single-winner elections, committee elections, participatory\nbudgeting, and participatory legislation. For each setting, we compare each\nsolution concept to known voting rules and study various properties of the\nresulting voting rules. Our framework provides expressive aggregation for a\nbroad range of social choice settings while remaining simple for voters, and\nmay enable a unified and integrated implementation for all these settings, as\nwell as unified extensions such as sybil-resiliency, proxy voting, and\ndeliberative decision making.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.06277v4"
    },
    {
        "title": "Cooperative Queuing Policies for Effective Human-Multi-Robot Interaction",
        "authors": [
            "Masoume M. Raeissi",
            "Alessandro Farinelli"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We consider multi-robot applications, where a team of robots can ask for the\nintervention of a human operator to handle difficult situations. As the number\nof requests grows, team members will have to wait for the operator attention,\nhence the operator becomes a bottleneck for the system. Our aim in this context\nis to make the robots learn cooperative strategies to decrease the time spent\nwaiting for the operator. In particular, we consider a queuing model where\nrobots decide whether or not to join the queue and use multi-robot learning to\nestimate the best cooperative policy. In more detail, we formalize the problem\nas Decentralized Markov Decision Process and provide a suitable state\nrepresentation, so to apply an independent learners approach. We evaluate the\nproposed method in a robotic water monitoring simulation and empirically show\nthat our approach can significantly improve the team performance, while being\ncomputationally tractable.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.07123v1"
    },
    {
        "title": "Adaptive guaranteed-performance consensus design for high-order\n  multiagent systems",
        "authors": [
            "Jianxiang Xi",
            "Jie Yang",
            "Hao Liu",
            "Tang Zheng"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The current paper addresses the distributed guaranteed-performance consensus\ndesign problems for general high-order linear multiagent systems with\nleaderless and leader-follower structures, respectively. The information about\nthe Laplacian matrix of the interaction topology or its minimum nonzero\neigenvalue is usually required in existing works on the guaranteed-performance\nconsensus, which means that their conclusions are not completely distributed. A\nnew translation-adaptive strategy is proposed to realize the completely\ndistributed guaranteed-performance consensus control by using the structure\nfeature of a complete graph in the current paper. For the leaderless case, an\nadaptive guaranteed-performance consensualization criterion is given in terms\nof Riccati inequalities and a regulation approach of the consensus control gain\nis presented by linear matrix inequalities. Extensions to the leader-follower\ncases are further investigated. Especially, the guaranteed-performance costs\nfor leaderless and leader-follower cases are determined, respectively, which\nare associated with the intrinsic structure characteristic of the interaction\ntopologies. Finally, two numerical examples are provided to demonstrate\ntheoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.09757v1"
    },
    {
        "title": "Probabilistic Gathering Of Agents With Simple Sensors",
        "authors": [
            "Ariel Barel",
            "Thomas Dagès",
            "Rotem Manor",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Gathering is a fundamental task for multi-agent systems and the problem has\nbeen studied under various assumptions on the sensing capabilities of mobile\nagents. This paper addresses the problem for a group of agents that are\nidentical and indistinguishable, oblivious, and lack the capacity of direct\ncommunication. At the beginning of unit-time intervals, the agents select\nrandom headings in the plane and then detect the presence of other agents\nbehind them. Then they move forward only if no agents are detected in their\nsensing \"back half-plane\". Two types of motion are considered: when no peers\nare detected behind them, either the agents perform unit jumps forward, or they\nstart to move with unit speed while continuously sensing their back half-plane,\nand stop whenever another agent appears there. For the first type of motion\nextensive empirical evidence suggests that with high probability clustering\noccurs in finite expected time to a small region with diameter of about the\nsize of the unit jump, while for continuous sensing and motion we can prove\ngathering in finite expected time if a \"blind-zone\" is assumed in their sensing\nhalf-plane. Relationships between the number of agents or the size of the\nblind-zone and convergence time are empirically studied and compared to a\ntheoretical upper-bound dependent on these factors.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.00294v2"
    },
    {
        "title": "On Steering Swarms",
        "authors": [
            "Ariel Barel",
            "Rotem Manor",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The main contribution of this paper is a novel method allowing an external\nobserver/controller to steer and guide swarms of identical and\nindistinguishable agents, in spite of the agents' lack of information on\nabsolute location and orientation. Importantly, this is done via simple global\nbroadcast signals, based on the observed average swarm location, with no need\nto send control signals to any specific agent in the swarm.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.00385v1"
    },
    {
        "title": "Cooperative Driving at Unsignalized Intersections Using Tree Search",
        "authors": [
            "Huile Xu",
            "Yi Zhang",
            "Li Li",
            "Weixia Li"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we propose a new cooperative driving strategy for connected\nand automated vehicles (CAVs) at unsignalized intersections. Based on the tree\nrepresentation of the solution space for the passing order, we combine Monte\nCarlo tree search (MCTS) and some heuristic rules to find a nearly\nglobal-optimal passing order (leaf node) within a very short planning time.\nTesting results show that this new strategy can keep a good tradeoff between\nperformance and computation flexibility.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.01024v1"
    },
    {
        "title": "On the Enactability of Agent Interaction Protocols: Toward a Unified\n  Approach",
        "authors": [
            "Angelo Ferrando",
            "Michael Winikoff",
            "Stephen Cranefield",
            "Frank Dignum",
            "Viviana Mascardi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Interactions between agents are usually designed from a global viewpoint.\nHowever, the implementation of a multi-agent interaction is distributed. This\ndifference can introduce issues. For instance, it is possible to specify\nprotocols from a global viewpoint that cannot be implemented as a collection of\nindividual agents. This leads naturally to the question of whether a given\n(global) protocol is enactable. We consider this question in a powerful setting\n(trace expression), considering a range of message ordering interpretations\n(what does it mean to say that an interaction step occurs before another), and\na range of possible constraints on the semantics of message delivery,\ncorresponding to different properties of underlying communication middleware.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.01131v4"
    },
    {
        "title": "COME TOGETHER: Multi-Agent Geometric Consensus (Gathering, Rendezvous,\n  Clustering, Aggregation)",
        "authors": [
            "Ariel Barel",
            "Rotem Manor",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This report surveys results on distributed systems comprising mobile agents\nthat are identical and anonymous, oblivious and interact solely by adjusting\ntheir motion according to the relative location of their neighbours. The agents\nare assumed capable of sensing the presence of other agents within a given\nsensing range and able to implement rules of motion based on full or partial\ninformation on the geometric constellation of their neighbouring agents. Eight\ndifferent problems that cover assumptions of finite vs infinite sensing range,\ndirection and distance vs direction only sensing and discrete vs continuous\nmotion, are analyzed in the context of geometric consensus, clustering or\ngathering tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.01455v1"
    },
    {
        "title": "Exploration of High-Dimensional Grids by Finite State Machines",
        "authors": [
            "Stefan Dobrev",
            "Lata Narayanan",
            "Jaroslav Opatrny",
            "Denis Pankratov"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We consider the problem of finding a treasure at an unknown point of an\n$n$-dimensional infinite grid, $n\\geq 3$, by initially collocated finite state\nagents (scouts/robots). Recently, the problem has been well characterized for 2\ndimensions for deterministic as well as randomized agents, both in synchronous\nand semi-synchronous models. It has been conjectured that $n+1$ randomized\nagents are necessary to solve this problem in the $n$-dimensional grid. In this\npaper we disprove the conjecture in a strong sense: we show that three\nrandomized synchronous agents suffice to explore an $n$-dimensional grid for\nany $n$. Our algorithm is optimal in terms of the number of the agents. Our key\ninsight is that a constant number of finite state machine agents can, by their\npositions and movements, implement a stack, which can store the path being\nexplored. We also show how to implement our algorithm using: four randomized\nsemi-synchronous agents; four deterministic synchronous agents; or five\ndeterministic semi-synchronous agents.\n  We give a different algorithm that uses $4$ deterministic semi-synchronous\nagents for the $3$-dimensional grid. This is provably optimal, and\nsurprisingly, matches the result for $2$ dimensions. For $n\\geq 4$, the time\ncomplexity of the solutions mentioned above is exponential in distance $D$ of\nthe treasure from the starting point of the agents. We show that in the\ndeterministic case, one additional agent brings the time down to a polynomial.\nFinally, we focus on algorithms that never venture much beyond the distance\n$D$. We describe an algorithm that uses $O(\\sqrt{n})$ semi-synchronous\ndeterministic agents that never go beyond $2D$, as well as show that any\nalgorithm using $3$ synchronous deterministic agents in $3$ dimensions must\ntravel beyond $\\Omega(D^{3/2})$ from the origin.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.03693v1"
    },
    {
        "title": "Optimizing Online Matching for Ride-Sourcing Services with Multi-Agent\n  Deep Reinforcement Learning",
        "authors": [
            "Jintao Ke",
            "Feng Xiao",
            "Hai Yang",
            "Jieping Ye"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Ride-sourcing services are now reshaping the way people travel by effectively\nconnecting drivers and passengers through mobile internets. Online matching\nbetween idle drivers and waiting passengers is one of the most key components\nin a ride-sourcing system. The average pickup distance or time is an important\nmeasurement of system efficiency since it affects both passengers' waiting time\nand drivers' utilization rate. It is naturally expected that a more effective\nbipartite matching (with smaller average pickup time) can be implemented if the\nplatform accumulates more idle drivers and waiting passengers in the matching\npool. A specific passenger request can also benefit from a delayed matching\nsince he/she may be matched with closer idle drivers after waiting for a few\nseconds. Motivated by the potential benefits of delayed matching, this paper\nestablishes a two-stage framework which incorporates a combinatorial\noptimization and multi-agent deep reinforcement learning methods. The\nmulti-agent reinforcement learning methods are used to dynamically determine\nthe delayed time for each passenger request (or the time at which each request\nenters the matching pool), while the combinatorial optimization conducts an\noptimal bipartite matching between idle drivers and waiting passengers in the\nmatching pool. Two reinforcement learning methods, spatio-temporal multi-agent\ndeep Q learning (ST-M-DQN) and spatio-temporal multi-agent actor-critic\n(ST-M-A2C) are developed. Through extensive empirical experiments with a\nwell-designed simulator, we show that the proposed framework is able to\nremarkably improve system performances.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.06228v1"
    },
    {
        "title": "Agent Madoff: A Heuristic-Based Negotiation Agent For The Diplomacy\n  Strategy Game",
        "authors": [
            "Hao Hao Tan"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we present the strategy of Agent Madoff, which is a\nheuristic-based negotiation agent that won 2nd place at the Automated\nNegotiating Agents Competition (ANAC 2017). Agent Madoff is implemented to play\nthe game Diplomacy, which is a strategic board game that mimics the situation\nduring World War I. Each player represents a major European power which has to\nnegotiate with other forces and win possession of a majority supply centers on\nthe map. We propose a design architecture which consists of 3 components:\nheuristic module, acceptance strategy and bidding strategy. The heuristic\nmodule, responsible for evaluating which regions on the graph are more worthy,\nconsiders the type of region and the number of supply centers adjacent to the\nregion and return a utility value for each region on the map. The acceptance\nstrategy is done on a case-by-case basis according to the type of the order by\ncalculating the acceptance probability using a composite function. The bidding\nstrategy adopts a defensive approach aimed to neutralize attacks and resolve\nconflict moves with other players to minimize our loss on supply centers.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.06996v1"
    },
    {
        "title": "Analysing Factorizations of Action-Value Networks for Cooperative\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Jacopo Castellini",
            "Frans A. Oliehoek",
            "Rahul Savani",
            "Shimon Whiteson"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Recent years have seen the application of deep reinforcement learning\ntechniques to cooperative multi-agent systems, with great empirical success.\nHowever, given the lack of theoretical insight, it remains unclear what the\nemployed neural networks are learning, or how we should enhance their learning\npower to address the problems on which they fail. In this work, we empirically\ninvestigate the learning power of various network architectures on a series of\none-shot games. Despite their simplicity, these games capture many of the\ncrucial problems that arise in the multi-agent setting, such as an exponential\nnumber of joint actions or the lack of an explicit coordination mechanism. Our\nresults extend those in [4] and quantify how well various approaches can\nrepresent the requisite value functions, and help us identify the reasons that\ncan impede good performance, like sparsity of the values or too tight\ncoordination requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.07497v4"
    },
    {
        "title": "Empathic Autonomous Agents",
        "authors": [
            "Timotheus Kampik",
            "Juan Carlos Nieves",
            "Helena Lindgren"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Identifying and resolving conflicts of interests is a key challenge when\ndesigning autonomous agents. For example, such conflicts often occur when\ncomplex information systems interact persuasively with humans and are in the\nfuture likely to arise in non-human agent-to-agent interaction. We introduce a\ntheoretical framework for an empathic autonomous agent that proactively\nidentifies potential conflicts of interests in interactions with other agents\n(and humans) by considering their utility functions and comparing them with its\nown preferences using a system of shared values to find a solution all agents\nconsider acceptable. To illustrate how empathic autonomous agents work, we\nprovide running examples and a simple prototype implementation in a\ngeneral-purpose programing language. To give a high-level overview of our work,\nwe propose a reasoning-loop architecture for our empathic agent.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.07781v1"
    },
    {
        "title": "Survivable Networks via UAV Swarms Guided by Decentralized Real-Time\n  Evolutionary Computation",
        "authors": [
            "George Leu",
            "Jiangjun Tang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The survivable network concept refers to contexts where the wireless\ncommunication between ground agents needs to be maintained as much as possible\nat all times, regardless of any adverse conditions that may arise. In this\npaper we propose a nature-inspired approach to survivable networks, in which we\nbring together swarm intelligence and evolutionary computation. We use an\non-line real-time Genetic Algorithm to optimize the movements of an UAV swarm\ntowards maintaining communication between the ground agents. The proposed\napproach models the ground agents and the UAVs as boids-based swarms, and\noptimizes the movement of the UAVs using different instances of the GA running\nindependently on each UAV. The UAV coordination mechanism is an implicit one,\nembedded in the fitness function of the Genetic Algorithm instances. The\nbehaviors of the individual UAVs emerge into an aggregated optimization of the\noverall network survivability. The results show that the proposed approach is\nable to maintain satisfactory network survivability levels regardless of the\nground agents' movements, including for cases as complex as random walks.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.07860v1"
    },
    {
        "title": "Agent based decision making for Integrated Air Defense system",
        "authors": [
            "Sumanta Kumar Das",
            "Sumant Mukherjee"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper presents algorithms of decision making agents for an integrated\nair defense (IAD) system. The advantage of using agent based over conventional\ndecision making system is its ability to automatically detect and track targets\nand if required allocate weapons to neutralize threat in an integrated mode.\nSuch approach is particularly useful for futuristic network centric warfare.\nTwo agents are presented here that perform the basic decisions making tasks of\ncommand and control (C2) like detection and action against jamming, threat\nassessment and weapons allocation, etc. The belief-desire-intension (BDI)\narchitectures stay behind the building blocks of these agents. These agents\ndecide their actions by meta level plan reasoning process. The proposed agent\nbased IAD system runs without any manual inputs, and represents a state of art\nmodel for C2 autonomy.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.01358v1"
    },
    {
        "title": "Actor-Critic Algorithms for Constrained Multi-agent Reinforcement\n  Learning",
        "authors": [
            "Raghuram Bharadwaj Diddigi",
            "Sai Koti Reddy Danda",
            "Prabuchandran K. J.",
            "Shalabh Bhatnagar"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In cooperative stochastic games multiple agents work towards learning joint\noptimal actions in an unknown environment to achieve a common goal. In many\nreal-world applications, however, constraints are often imposed on the actions\nthat can be jointly taken by the agents. In such scenarios the agents aim to\nlearn joint actions to achieve a common goal (minimizing a specified cost\nfunction) while meeting the given constraints (specified via certain penalty\nfunctions). In this paper, we consider the relaxation of the constrained\noptimization problem by constructing the Lagrangian of the cost and penalty\nfunctions. We propose a nested actor-critic solution approach to solve this\nrelaxed problem. In this approach, an actor-critic scheme is employed to\nimprove the policy for a given Lagrange parameter update on a faster timescale\nas in the classical actor-critic architecture. A meta actor-critic scheme using\nthis faster timescale policy updates is then employed to improve the Lagrange\nparameters on the slower timescale. Utilizing the proposed nested actor-critic\nschemes, we develop three Nested Actor-Critic (N-AC) algorithms. Through\nexperiments on constrained cooperative tasks, we show the effectiveness of the\nproposed algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02907v2"
    },
    {
        "title": "Search for Smart Evaders with Sweeping Agents",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Suppose that in a given planar circular region, there are some smart mobile\nevaders and we would like to find them using sweeping agents. We assume that\nthe sweeping agents are in a line formation whose total length is 2r. We\npropose procedures for designing a sweeping process that ensures the successful\ncompletion of the task, thereby deriving conditions on the sweeping velocity of\nthe linear formation and its path. Successful completion of the task means that\nevaders with a given limit on their velocity cannot escape the sweeping agents.\nA simpler task for the sweeping formation is the confinement of the evaders to\ntheir initial domain. The feasibility of completing these tasks depends on\ngeometric and dynamic constraints that impose a lower bound on the velocity\nthat the sweeper line formation must have. This critical velocity is derived to\nensure the satisfaction of the confinement task. Increasing the velocity above\nthe lower bound enables the agents to complete the search task as well. We\npresent results on the total search time as a function of the sweeping velocity\nof the formation given the initial conditions on the size of the search region\nand the maximal velocity of the evaders.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04006v2"
    },
    {
        "title": "ES-CTC: A Deep Neuroevolution Model for Cooperative Intelligent Freeway\n  Traffic Control",
        "authors": [
            "Yuankai Wu",
            "Huachun Tan",
            "Zhuxi Jiang",
            "Bin Ran"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Cooperative intelligent freeway traffic control is an important application\nin intelligent transportation systems, which is expected to improve the\nmobility of freeway networks. In this paper, we propose a deep neuroevolution\nmodel, called ES-CTC, to achieve a cooperative control scheme of ramp metering,\ndifferential variable speed limits and lane change control agents for improving\nfreeway traffic. In this model, the graph convolutional networks are used to\nlearn more meaningful spatial pattern from traffic sensors, a knowledge sharing\nlayer is designed for communication between different agents. The proposed\nneural networks structure allows different agents share knowledge with each\nother and execute action asynchronously. In order to address the delayed reward\nand action asynchronism issues, the evolutionary strategy is utilized to train\nthe agents under stochastic traffic demands. The experimental results on a\nsimulated freeway section indicate that ES-CTC is a viable approach and\noutperforms several existing methods\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04083v1"
    },
    {
        "title": "Inventory Management - A Case Study with NetLogo",
        "authors": [
            "Rui Portocarrero Sarmento"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Multi-Agent Systems (MAS) have been applied to several areas or tasks ranging\nfrom energy networks controlling to robot soccer teams. MAS are the ideal\nsolution when they provide decision support in situations where human decision\nand actions are not feasible to operate the system in control and in real-time.\nThus, we present a case study that is related to dynamic simulation of an\nautomatic inventory management system. We provide two types of agents, the\nclients, and the seller agents. Through a system of communication, the agents\nexchange messages to fulfill their inventory needs. The client agents trade\nproducts in quantities according to their needs and rely on seller agents if\nother clients in the retailer chain cannot provide the needed items.\nAdditionally, it is expected that the trading between a client and the sellers\nis done through a reverted type of auction. This case study MAS uses BDI and\nFIPA-ACL in its implementation resulting in a clear simulation of the system.\nWe expect to provide a comparison between two distinct situations. One with\nonly external transactions with providers, and a situation where both internal\nand external transactions are allowed.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.08041v1"
    },
    {
        "title": "CoRide: Joint Order Dispatching and Fleet Management for Multi-Scale\n  Ride-Hailing Platforms",
        "authors": [
            "Jiarui Jin",
            "Ming Zhou",
            "Weinan Zhang",
            "Minne Li",
            "Zilong Guo",
            "Zhiwei Qin",
            "Yan Jiao",
            "Xiaocheng Tang",
            "Chenxi Wang",
            "Jun Wang",
            "Guobin Wu",
            "Jieping Ye"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  How to optimally dispatch orders to vehicles and how to tradeoff between\nimmediate and future returns are fundamental questions for a typical\nride-hailing platform. We model ride-hailing as a large-scale parallel ranking\nproblem and study the joint decision-making task of order dispatching and fleet\nmanagement in online ride-hailing platforms. This task brings unique challenges\nin the following four aspects. First, to facilitate a huge number of vehicles\nto act and learn efficiently and robustly, we treat each region cell as an\nagent and build a multi-agent reinforcement learning framework. Second, to\ncoordinate the agents from different regions to achieve long-term benefits, we\nleverage the geographical hierarchy of the region grids to perform hierarchical\nreinforcement learning. Third, to deal with the heterogeneous and variant\naction space for joint order dispatching and fleet management, we design the\naction as the ranking weight vector to rank and select the specific order or\nthe fleet management destination in a unified formulation. Fourth, to achieve\nthe multi-scale ride-hailing platform, we conduct the decision-making process\nin a hierarchical way where a multi-head attention mechanism is utilized to\nincorporate the impacts of neighbor agents and capture the key agent in each\nscale. The whole novel framework is named as CoRide. Extensive experiments\nbased on multiple cities real-world data as well as analytic synthetic data\ndemonstrate that CoRide provides superior performance in terms of platform\nrevenue and user experience in the task of city-wide hybrid order dispatching\nand fleet management over strong baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.11353v2"
    },
    {
        "title": "Justification Based Reasoning in Dynamic Conflict Resolution",
        "authors": [
            "Werner Damm",
            "Martin Fränzle",
            "Willem Hagemann",
            "Paul Kröger",
            "Astrid Rakow"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We study conflict situations that dynamically arise in traffic scenarios,\nwhere different agents try to achieve their set of goals and have to decide on\nwhat to do based on their local perception. We distinguish several types of\nconflicts for this setting. In order to enable modelling of conflict situations\nand the reasons for conflicts, we present a logical framework that adopts\nconcepts from epistemic and modal logic, justification and temporal logic.\nUsing this framework, we illustrate how conflicts can be identified and how we\nderive a chain of justifications leading to this conflict. We discuss how\nconflict resolution can be done when a vehicle has local, incomplete\ninformation, vehicle to vehicle communication (V2V) and partially ordered\ngoals.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.11764v1"
    },
    {
        "title": "AsymDPOP: Complete Inference for Asymmetric Distributed Constraint\n  Optimization Problems",
        "authors": [
            "Yanchen Deng",
            "Ziyu Chen",
            "Dingding Chen",
            "Wenxin Zhang",
            "Xingqiong Jiang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Asymmetric distributed constraint optimization problems (ADCOPs) are an\nemerging model for coordinating agents with personal preferences. However, the\nexisting inference-based complete algorithms which use local eliminations\ncannot be applied to ADCOPs, as the parent agents are required to transfer\ntheir private functions to their children. Rather than disclosing private\nfunctions explicitly to facilitate local eliminations, we solve the problem by\nenforcing delayed eliminations and propose AsymDPOP, the first inference-based\ncomplete algorithm for ADCOPs. To solve the severe scalability problems\nincurred by delayed eliminations, we propose to reduce the memory consumption\nby propagating a set of smaller utility tables instead of a joint utility\ntable, and to reduce the computation efforts by sequential optimizations\ninstead of joint optimizations. The empirical evaluation indicates that\nAsymDPOP significantly outperforms the state-of-the-arts, as well as the\nvanilla DPOP with PEAV formulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.11828v2"
    },
    {
        "title": "EasySched: a multi-agent architecture for the predictive and reactive\n  scheduling of Industry 4.0 production systems based on the available\n  renewable energy",
        "authors": [
            "Maroua Nouiri",
            "Damien Trentesaux",
            "Abdelghani Bekrar"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Industry 4.0 is concerned with sustainable development constraints. In this\ncontext, we propose a multi-agent architecture, named EasySched, aiming at\nelaborating predictive and reactive scheduling as the result of a coordination\nbetween systems producing goods and systems producing renewable energy. The\nvalidation of this architecture is original, and was conducted in a completely\nand physically distributed way, using networked embedded systems. This\nvalidation was done on a series of instances inspired by the literature. The\nresults showed that EasySched succeeds in adapting the production of goods\naccording to the available renewable energy\n",
        "pdf_link": "http://arxiv.org/pdf/1905.12083v1"
    },
    {
        "title": "An Introduction to Engineering Multiagent Industrial Symbiosis Systems:\n  Potentials and Challenges",
        "authors": [
            "Vahid Yazdanpanah",
            "Devrim Murat Yazan",
            "Jos van Hillegersberg",
            "Mehdi Dastani"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Multiagent Systems (MAS) research reached a maturity to be confidently\napplied to real-life complex problems. Successful application of MAS methods\nfor behavior modeling, strategic reasoning, and decentralized governance,\nencouraged us to focus on applicability of MAS techniques in a class of\nindustrial systems and to elaborate on potentials and challenges for method\nintegration/contextualization. We direct attention towards a form of industrial\npractices called Industrial Symbiosis Systems (ISS) as a highly dynamic domain\nof application for MAS techniques. In ISS, firms aim to reduce their material\nand energy footprint by circulating reusable resources among the members. To\nenable systematic reasoning about ISS behavior and support firms' (as well as\nISS designers') decisions, we see the opportunity for marrying industrial\nengineering with engineering multiagent systems. This enables introducing (1)\nrepresentation frameworks to reason about dynamics of ISS, (2) operational\nsemantics to develop computational models for ISS, and (3) coordination\nmechanisms to enforce desirable ISS behaviors. We argue for applicability and\nexpressiveness of resource-bounded formalisms and norm-aware mechanisms for the\ndesign and deployment of ISS practices. In this proposal, we elaborate on\ndifferent dimensions of ISS, present a methodological foundation for ISS\ndevelopment, and finally discuss open problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.12890v1"
    },
    {
        "title": "New Algorithms for Functional Distributed Constraint Optimization\n  Problems",
        "authors": [
            "Khoi D. Hoang",
            "William Yeoh",
            "Makoto Yokoo",
            "Zinovi Rabinovich"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The Distributed Constraint Optimization Problem (DCOP) formulation is a\npowerful tool to model multi-agent coordination problems that are distributed\nby nature. The formulation is suitable for problems where variables are\ndiscrete and constraint utilities are represented in tabular form. However,\nmany real-world applications have variables that are continuous and tabular\nforms thus cannot accurately represent constraint utilities. To overcome this\nlimitation, researchers have proposed the Functional DCOP (F-DCOP) model, which\nare DCOPs with continuous variables. But existing approaches usually come with\nsome restrictions on the form of constraint utilities and are without quality\nguarantees. Therefore, in this paper, we (i) propose exact algorithms to solve\na specific subclass of F-DCOPs; (ii) propose approximation methods with quality\nguarantees to solve general F-DCOPs; and (iii) empirically show that our\nalgorithms outperform existing state-of-the-art F-DCOP algorithms on randomly\ngenerated instances when given the same communication limitations.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.13275v1"
    },
    {
        "title": "ColosseumRL: A Framework for Multiagent Reinforcement Learning in\n  $N$-Player Games",
        "authors": [
            "Alexander Shmakov",
            "John Lanier",
            "Stephen McAleer",
            "Rohan Achar",
            "Cristina Lopes",
            "Pierre Baldi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Much of recent success in multiagent reinforcement learning has been in\ntwo-player zero-sum games. In these games, algorithms such as fictitious\nself-play and minimax tree search can converge to an approximate Nash\nequilibrium. While playing a Nash equilibrium strategy in a two-player zero-sum\ngame is optimal, in an $n$-player general sum game, it becomes a much less\ninformative solution concept. Despite the lack of a satisfying solution\nconcept, $n$-player games form the vast majority of real-world multiagent\nsituations. In this paper we present a new framework for research in\nreinforcement learning in $n$-player games. We hope that by analyzing behavior\nlearned by agents in these environments the community can better understand\nthis important research area and move toward meaningful solution concepts and\nresearch directions. The implementation and additional information about this\nframework can be found at https://colosseumrl.igb.uci.edu/.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.04451v1"
    },
    {
        "title": "Approximate Strategyproofness in Large, Two-Sided Matching Markets",
        "authors": [
            "Lars Lien Ankile",
            "Kjartan Krange",
            "Yuto Yagi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  An approximation of strategyproofness in large, two-sided matching markets is\nhighly evident. Through simulations, one can observe that the percentage of\nagents with useful deviations decreases as the market size grows. Furthermore,\nthere seems to be a strong connection between the length of preference order\nlists, the correlation of agent preferences, and the approximation of\nstrategyproofness. Interestingly, approximate strategyproofness is reached\neasier with a shorter length of preference orders and higher preference\ncorrelation. These findings justify the use of the deferred acceptance\nalgorithm in large two-sided matching markets despite it not being\nstrategy-proof.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.04800v2"
    },
    {
        "title": "An Agency-Directed Approach to Test Generation for Simulation-based\n  Autonomous Vehicle Verification",
        "authors": [
            "Greg Chance",
            "Abanoub Ghobrial",
            "Severin Lemaignan",
            "Tony Pipe",
            "Kerstin Eder"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Simulation-based verification is beneficial for assessing otherwise dangerous\nor costly on-road testing of autonomous vehicles (AV). This paper addresses the\nchallenge of efficiently generating effective tests for simulation-based AV\nverification using software testing agents. The multi-agent system (MAS)\nprogramming paradigm offers rational agency, causality and strategic planning\nbetween multiple agents. We exploit these aspects for test generation, focusing\nin particular on the generation of tests that trigger the precondition of an\nassertion. On the example of a key assertion we show that, by encoding a\nvariety of different behaviours respondent to the agent's perceptions of the\ntest environment, the agency-directed approach generates twice as many\neffective tests than pseudo-random test generation, while being both efficient\nand robust. Moreover, agents can be encoded to behave naturally without\ncompromising the effectiveness of test generation. Our results suggest that\ngenerating tests using agency-directed testing significantly improves upon\nrandom and simultaneously provides more realistic driving scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05434v3"
    },
    {
        "title": "Convergence of Opinion Diffusion is PSPACE-complete",
        "authors": [
            "Dmitry Chistikov",
            "Grzegorz Lisowski",
            "Mike Paterson",
            "Paolo Turrini"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We analyse opinion diffusion in social networks, where a finite set of\nindividuals is connected in a directed graph and each simultaneously changes\ntheir opinion to that of the majority of their influencers. We study the\nalgorithmic properties of the fixed-point behaviour of such networks, showing\nthat the problem of establishing whether individuals converge to stable\nopinions is PSPACE-complete.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.09864v2"
    },
    {
        "title": "Coordination of Autonomous Vehicles: Taxonomy and Survey",
        "authors": [
            "Stefano Mariani",
            "Giacomo Cabri",
            "Franco Zambonelli"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In the near future, our streets will be populated by myriads of autonomous\nself-driving vehicles to serve our diverse mobility needs. This will raise the\nneed to coordinate their movements in order to properly handle both access to\nshared resources (e.g., intersections and parking slots) and the execution of\nmobility tasks (e.g., platooning and ramp merging). In this paper, we firstly\nintroduce the general issues associated to coordination of autonomous vehicles,\nby identifying and framing the key classes of coordination problems. Following,\nwe overview the different approaches that can be adopted to manage such\ncoordination problems, by classifying them in terms of the degree of autonomy\nin decision making that is left to autonomous vehicles during coordination.\nFinally, we overview some further peculiar challenges that research will have\nto address before autonomously coordinated vehicles can safely hit our streets.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.02443v1"
    },
    {
        "title": "Open Challenges and Issues: Artificial Intelligence for Transactive\n  Management",
        "authors": [
            "Asma Khatun",
            "Sk. Golam Sarowar Hossain"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The advancement of Artificial Intelligence (AI) has improved the automation\nof energy managements. In smart energy management or in a smart grid framework,\nall the devices and the distributed resources and renewable resources are\nembedded which leads to reduce cost. A smart energy management system,\nTransactive management (TM) is a concept to improve the efficiency and\nreliability of the power system. The aim of this article is to look for the\ncurrent development of TM methods based on AI and Machine Learning (ML)\ntechnology. In AI paradigm, MultiAgent System (MAS) based method is an active\nresearch area and are still in evolution. Hence this article describes how MAS\nbased method applied in TM. This paper also finds that MAS based method faces\nmajor difficulty to design or set up goal to various agents and describes how\nML technique can contribute to that solution. A brief comparison analysis\nbetween MAS and ML techniques are also presented. At the end, this article\nsummarizes the most relevant open challenges and issues on the AI based methods\nfor transactive energy management.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03238v1"
    },
    {
        "title": "Distributed Possibilistic Learning in Multi-Agent Systems",
        "authors": [
            "Jonathan Lawry",
            "Michael Crosscombe",
            "David Harvey"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Possibility theory is proposed as an uncertainty representation framework for\ndistributed learning in multi-agent systems and robot swarms. In particular, we\ninvestigate its application to the best-of-n problem where the aim is for a\npopulation of agents to identify the highest quality out of n options through\nlocal interactions between individuals and limited direct feedback from the\nenvironment. In this context we claim that possibility theory provides\nefficient mechanisms by which an agent can learn about the state of the world,\nand which can allow them to handle inconsistencies between what they and others\nbelieve by varying the level of imprecision of their own beliefs. We introduce\na discrete time model of a population of agents applying possibility theory to\nthe best-of-n problem. Simulation experiments are then used to investigate the\naccuracy of possibility theory in this context as well as its robustness to\nnoise under varying amounts of direct evidence. Finally, we compare possibility\ntheory in this context with a similar probabilistic approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.07145v1"
    },
    {
        "title": "United for Change: Deliberative Coalition Formation to Change the Status\n  Quo",
        "authors": [
            "Edith Elkind",
            "Davide Grossi",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We study a setting in which a community wishes to identify a strongly\nsupported proposal from a space of alternatives, in order to change the status\nquo. We describe a deliberation process in which agents dynamically form\ncoalitions around proposals that they prefer over the status quo. We formulate\nconditions on the space of proposals and on the ways in which coalitions are\nformed that guarantee deliberation to succeed, that is, to terminate by\nidentifying a proposal with the largest possible support. Our results provide\ntheoretical foundations for the analysis of deliberative processes such as the\nones that take place in online systems for democratic deliberation support.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.08031v5"
    },
    {
        "title": "Mechanism Design for Multi-Party Machine Learning",
        "authors": [
            "Mengjing Chen",
            "Yang Liu",
            "Weiran Shen",
            "Yiheng Shen",
            "Pingzhong Tang",
            "Qiang Yang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In a multi-party machine learning system, different parties cooperate on\noptimizing towards better models by sharing data in a privacy-preserving way. A\nmajor challenge in learning is the incentive issue. For example, if there is\ncompetition among the parties, one may strategically hide his data to prevent\nother parties from getting better models.\n  In this paper, we study the problem through the lens of mechanism design and\nincorporate the features of multi-party learning in our setting. First, each\nagent's valuation has externalities that depend on others' types and actions.\nSecond, each agent can only misreport a type lower than his true type, but not\nthe other way round. We call this setting interdependent value with\ntype-dependent action spaces. We provide the optimal truthful mechanism in the\nquasi-monotone utility setting. We also provide necessary and sufficient\nconditions for truthful mechanisms in the most general case. Finally, we show\nthe existence of such mechanisms is highly affected by the market growth rate\nand provide empirical analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.08996v3"
    },
    {
        "title": "Context-Aware Deep Q-Network for Decentralized Cooperative\n  Reconnaissance by a Robotic Swarm",
        "authors": [
            "Nishant Mohanty",
            "Mohitvishnu S. Gadde",
            "Suresh Sundaram",
            "Narasimhan Sundararajan",
            "P. B. Sujit"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  One of the crucial problems in robotic swarm-based operation is to search and\nneutralize heterogeneous targets in an unknown and uncertain environment,\nwithout any communication within the swarm. Here, some targets can be\nneutralized by a single robot, while others need multiple robots in a\nparticular sequence to neutralize them. The complexity in the problem arises\ndue to the scalability and information uncertainty, which restricts the robot's\nawareness of the swarm and the target distribution. In this paper, this problem\nis addressed by proposing a novel Context-Aware Deep Q-Network (CA-DQN)\nframework to obtain communication free cooperation between the robots in the\nswarm. Each robot maintains an adaptive grid representation of the vicinity\nwith the context information embedded into it to keep the swarm intact while\nsearching and neutralizing the targets. The problem formulation uses a\nreinforcement learning framework where two Deep Q-Networks (DQNs) handle\n'conflict' and 'conflict-free' scenarios separately. The self-play-in-based\napproach is used to determine the optimal policy for the DQNs. Monte-Carlo\nsimulations and comparison studies with a state-of-the-art coalition formation\nalgorithm are performed to verify the performance of CA-DQN with varying\nenvironmental parameters. The results show that the approach is invariant to\nthe number of detected targets and the number of robots in the swarm. The paper\nalso presents the real-time implementation of CA-DQN for different scenarios\nusing ground robots in a laboratory environment to demonstrate the working of\nCA-DQN with low-power computing devices.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.11710v2"
    },
    {
        "title": "Search for Smart Evaders with Swarms of Sweeping Agents",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Suppose that in a given planar circular region, there are some smart mobile\nevaders and we would like to find them using sweeping agents. We assume that\neach agent has a line sensor of length 2r. We propose procedures for designing\ncooperative sweeping processes that ensure the successful completion of the\ntask, thereby deriving conditions on the sweeping velocity of the agents and\ntheir paths. Successful completion of the task means that evaders with a given\nlimit on their velocity cannot escape the sweeping agents. A simpler task for\nthe sweeping swarm is the confinement of the evaders to their initial domain.\nThe feasibility of completing these tasks depends on geometric and dynamic\nconstraints that impose a lower bound on the velocity that the sweeper swarm\nmust have. This critical velocity is derived to ensure the satisfaction of the\nconfinement task. Increasing the velocity above the lower bound enables the\nagents to complete the search task as well. We present results on the total\nsearch time as a function of the sweeping velocity of the swarm's agents given\nthe initial conditions on the size of the search region and the maximal\nvelocity of the evaders.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.01011v1"
    },
    {
        "title": "Finding the maximum-a-posteriori behaviour of agents in an agent-based\n  model",
        "authors": [
            "Daniel Tang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper we consider the problem of finding the most probable set of\nevents that could have led to a set of partial, noisy observations of some\ndynamical system. In particular, we consider the case of a dynamical system\nthat is a (possibly stochastic) time-stepping agent-based model with a discrete\nstate space, the (possibly noisy) observations are the number of agents that\nhave some given property and the events we're interested in are the decisions\nmade by the agents (their ``expressed behaviours'') as the model evolves.\n  We show that this problem can be reduced to an integer linear programming\nproblem which can subsequently be solved numerically using a standard\nbranch-and-cut algorithm. We describe two implementations, an ``offline''\nalgorithm that finds the maximum-a-posteriori expressed behaviours given a set\nof observations over a finite time window, and an ``online'' algorithm that\nincrementally builds a feasible set of behaviours from a stream of observations\nthat may have no natural beginning or end.\n  We demonstrate both algorithms on a spatial predator-prey model on a 32x32\ngrid with an initial population of 100 agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02096v1"
    },
    {
        "title": "Approximation Algorithms for Distributed Multi-Robot Coverage in\n  Non-Convex Environments",
        "authors": [
            "Armin Sadeghi",
            "Ahmad Bilal Asghar",
            "Stephen L. Smith"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, we revisit the distributed coverage control problem with\nmultiple robots on both metric graphs and in non-convex continuous\nenvironments. Traditionally, the solutions provided for this problem converge\nto a locally optimal solution with no guarantees on the quality of the\nsolution. We consider sub-additive sensing functions, which capture the\nscenarios where sensing an event requires the robot to visit the event\nlocation. For these sensing functions, we provide the first constant factor\napproximation algorithms for the distributed coverage problem. The\napproximation results require twice the conventional communication range in the\nexisting coverage algorithms. However, we show through extensive simulation\nresults that the proposed approximation algorithms outperform several existing\nalgorithms in convex, non-convex continuous, and discrete environments even\nwith the conventional communication ranges. Moreover, the proposed algorithms\nmatch the state-of-the-art centralized algorithms in the solution quality.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02471v1"
    },
    {
        "title": "Autonomy with regard to an Attribute",
        "authors": [
            "Eric Sanchis"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  This paper presents a model of autonomy called autonomy with regard to an\nattribute applicable to cognitive and not cognitive artificial agents. Three\ncriteria (global / partial, social / nonsocial, absolute / relative) are\ndefined and used to describe the main characteristics of this type of autonomy.\nA software agent autonomous with regard to the mobility illustrates a possible\nimplementation of this model.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.1558v1"
    },
    {
        "title": "Application of distributed constraint satisfaction problem to the\n  agent-based planning in manufacturing systems",
        "authors": [
            "S. Kornienko",
            "O. Kornienko",
            "P. Levi"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Nowadays, a globalization of national markets requires developing flexible\nand demand-driven production systems. Agent-based technology, being\ndistributed, flexible and autonomous is expected to provide a short-time\nreaction to disturbances and sudden changes of environment and allows\nsatisfying the mentioned requirements. The distributed constraint satisfaction\napproach underlying the suggested method is described by a modified Petri\nnetwork providing both the conceptual notions and main details of\nimplementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0601v1"
    },
    {
        "title": "Multi Agent Communication System for Online Auction with Decision\n  Support System by JADE and TRACE",
        "authors": [
            "A. Martin",
            "T. Miranda Lakshmi",
            "J. Madhusudanan"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  The success of online auctions has given buyers access to greater product\ndiversity with potentially lower prices. It has provided sellers with access to\nlarge numbers of potential buyers and reduced transaction costs by enabling\nauctions to take place without regard to time or place. However it is difficult\nto spend more time period with system and closely monitor the auction until\nauction participant wins the bid or closing of the auction. Determining which\nitems to bid on or what may be the recommended bid and when to bid it are\ndifficult questions to answer for online auction participants. The multi agent\nauction advisor system JADE and TRACE, which is connected with decision support\nsystem, gives the recommended bid to buyers for online auctions. The auction\nadvisor system relies on intelligent agents both for the retrieval of relevant\nauction data and for the processing of that data to enable meaningful\nrecommendations, statistical reports and market prediction report to be made to\nauction participants.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.1093v1"
    },
    {
        "title": "A georeferenced Agent-Based Model to analyze the climate change impacts\n  on the Andorra winter tourism",
        "authors": [
            "M. Pons-Pons",
            "P. A. Johnson",
            "M. Rosas-Casals",
            "B. Sureda",
            "E. Jover"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  This study presents a georeferenced agent-based model to analyze the climate\nchange impacts on the ski industry in Andorra and the effect of snowmaking as\nfuture adaptation strategy. The present study is the first attempt to analyze\nthe ski industry in the Pyrenees region and will contribute to a better\nunderstanding of the vulnerability of Andorran ski resorts and the suitability\nof snowmaking as potential adaptation strategy to climate change. The resulting\nmodel can be used as a planning support tool to help local stakeholders\nunderstand the vulnerability and potential impacts of climate change. This\nmodel can be used in the decision-making process of designing and developing\nappropriate sustainable adaptation strategies to future climate variability.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.1409v2"
    },
    {
        "title": "Extremal Behaviour in Multiagent Contract Negotiation",
        "authors": [
            "P. E. Dunne"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  We examine properties of a model of resource allocation in which several\nagents exchange resources in order to optimise their individual holdings. The\nschemes discussed relate to well-known negotiation protocols proposed in\nearlier work and we consider a number of alternative notions of rationality\ncovering both quantitative measures, e.g. cooperative and individual\nrationality and more qualitative forms, e.g. Pigou-Dalton transfers. While it\nis known that imposing particular rationality and structural restrictions may\nresult in some reallocations of the resource set becoming unrealisable, in this\npaper we address the issue of the number of restricted rational deals that may\nbe required to implement a particular reallocation when it is possible to do\nso. We construct examples showing that this number may be exponential (in the\nnumber of resources m), even when all of the agent utility functions are\nmonotonic. We further show that k agents may achieve in a single deal a\nreallocation requiring exponentially many rational deals if at most k-1 agents\ncan participate, this same reallocation being unrealisable by any sequences of\nrational deals in which at most k-2 agents are involved.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.2129v1"
    },
    {
        "title": "Hybrid BDI-POMDP Framework for Multiagent Teaming",
        "authors": [
            "R. Nair",
            "M. Tambe"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Many current large-scale multiagent team implementations can be characterized\nas following the belief-desire-intention (BDI) paradigm, with explicit\nrepresentation of team plans. Despite their promise, current BDI team\napproaches lack tools for quantitative performance analysis under uncertainty.\nDistributed partially observable Markov decision problems (POMDPs) are well\nsuited for such analysis, but the complexity of finding optimal policies in\nsuch models is highly intractable. The key contribution of this article is a\nhybrid BDI-POMDP approach, where BDI team plans are exploited to improve POMDP\ntractability and POMDP analysis improves BDI team plan performance. Concretely,\nwe focus on role allocation, a fundamental problem in BDI teams: which agents\nto allocate to the different roles in the team. The article provides three key\ncontributions. First, we describe a role allocation technique that takes into\naccount future uncertainties in the domain; prior work in multiagent role\nallocation has failed to address such uncertainties. To that end, we introduce\nRMTDP (Role-based Markov Team Decision Problem), a new distributed POMDP model\nfor analysis of role allocations. Our technique gains in tractability by\nsignificantly curtailing RMTDP policy search; in particular, BDI team plans\nprovide incomplete RMTDP policies, and the RMTDP policy search fills the gaps\nin such incomplete policies by searching for the best role allocation. Our\nsecond key contribution is a novel decomposition technique to further improve\nRMTDP policy search efficiency. Even though limited to searching role\nallocations, there are still combinatorially many role allocations, and\nevaluating each in RMTDP to identify the best is extremely difficult. Our\ndecomposition technique exploits the structure in the BDI team plans to\nsignificantly prune the search space of role allocations. Our third key\ncontribution is a significantly faster policy evaluation algorithm suited for\nour BDI-POMDP hybrid approach. Finally, we also present experimental results\nfrom two domains: mission rehearsal simulation and RoboCupRescue disaster\nrescue simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.2132v1"
    },
    {
        "title": "Cooperative Information Sharing to Improve Distributed Learning in\n  Multi-Agent Systems",
        "authors": [
            "P. S. Dutta",
            "N. R. Jennings",
            "L. Moreau"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Effective coordination of agents actions in partially-observable domains is a\nmajor challenge of multi-agent systems research. To address this, many\nresearchers have developed techniques that allow the agents to make decisions\nbased on estimates of the states and actions of other agents that are typically\nlearnt using some form of machine learning algorithm. Nevertheless, many of\nthese approaches fail to provide an actual means by which the necessary\ninformation is made available so that the estimates can be learnt. To this end,\nwe argue that cooperative communication of state information between agents is\none such mechanism. However, in a dynamically changing environment, the\naccuracy and timeliness of this communicated information determine the fidelity\nof the learned estimates and the usefulness of the actions taken based on\nthese. Given this, we propose a novel information-sharing protocol,\npost-task-completion sharing, for the distribution of state information. We\nthen show, through a formal analysis, the improvement in the quality of\nestimates produced using our strategy over the widely used protocol of sharing\ninformation between nearest neighbours. Moreover, communication heuristics\ndesigned around our information-sharing principle are subjected to empirical\nevaluation along with other benchmark strategies (including Littmans Q-routing\nand Stones TPOT-RL) in a simulated call-routing application. These studies,\nconducted across a range of environmental settings, show that, compared to the\ndifferent benchmarks used, our strategy generates an improvement of up to 60%\nin the call connection rate; of more than 1000% in the ability to connect\nlong-distance calls; and incurs as low as 0.25 of the message overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.5712v1"
    },
    {
        "title": "Negotiating Socially Optimal Allocations of Resources",
        "authors": [
            "U. Endriss",
            "N. Maudet",
            "F. Sadri",
            "F. Toni"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  A multiagent system may be thought of as an artificial society of autonomous\nsoftware agents and we can apply concepts borrowed from welfare economics and\nsocial choice theory to assess the social welfare of such an agent society. In\nthis paper, we study an abstract negotiation framework where agents can agree\non multilateral deals to exchange bundles of indivisible resources. We then\nanalyse how these deals affect social welfare for different instances of the\nbasic framework and different interpretations of the concept of social welfare\nitself. In particular, we show how certain classes of deals are both sufficient\nand necessary to guarantee that a socially optimal allocation of resources will\nbe reached eventually.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.6340v1"
    },
    {
        "title": "Blackboard Rules for Coordinating Context-aware Applications in Mobile\n  Ad Hoc Networks",
        "authors": [
            "Jean-Marie Jacquet",
            "Isabelle Linden",
            "Mihail-Octavian Staicu"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Thanks to improvements in wireless communication technologies and increasing\ncomputing power in hand-held devices, mobile ad hoc networks are becoming an\never-more present reality. Coordination languages are expected to become\nimportant means in supporting this type of interaction. To this extent we argue\nthe interest of the Bach coordination language as a middleware that can handle\nand react to context changes as well as cope with unpredictable physical\ninterruptions that occur in opportunistic network connections. More concretely,\nour proposal is based on blackboard rules that model declaratively the actions\nto be taken once the blackboard content reaches a predefined state, but also\nthat manage the engagement and disengagement of hosts and transient sharing of\nblackboards. The idea of reactiveness has already been introduced in previous\nwork, but as will be appreciated by the reader, this article presents a new\nperspective, more focused on a declarative setting.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.1421v1"
    },
    {
        "title": "Reliability of swarming algorithms for mobile sensor network\n  applications",
        "authors": [
            "Steven Senger"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  There are many well-studied swarming algorithms which are often suited to\nvery specific purposes. As mobile sensor networks become increasingly complex,\nand are comprised of more and more agents, it makes sense to consider swarming\nalgorithms for movement control. We introduce a natural way to measure the\nreliability of various swarming algorithms so a balance can be struck between\nalgorithmic complexity and sampling accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5331v1"
    },
    {
        "title": "CarPed -- A Hybrid and Macroscopic Traffic and Pedestrian Simulator",
        "authors": [
            "Daniel H. Biedermann",
            "Peter M. Kielar",
            "Quirin Aumann",
            "Carlos M. Osorio",
            "Celeste T. W. Lai"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Dense human flow has been a concern for the safety of public events for a\nlong time. Macroscopic pedestrian models, which are mainly based on fluid\ndynamics, are often used to simulate huge crowds due to their low computational\ncosts (Columbo & Rosini 2005). Similar approaches are used in the field of\ntraffic simulations (Lighthill & Whitham 1955). A combined macroscopic\nsimulation of vehicles and pedestrians is extremely helpful for\nall-encompassing traffic control. Therefore, we developed a hybrid model that\ncontains networks for vehicular traffic and human flow. This comprehensive\nmodel supports concurrent multi-modal simulations of traffic and pedestrians.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.00053v1"
    },
    {
        "title": "MOS-2: A Two-Dimension Space for Positioning MAS Organizational Models",
        "authors": [
            "Hosny Abbas",
            "Samir Shaheen"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  The increased complexity and dynamism of present and future Multi-Agent\nSystems (MAS) enforce the need for considering both of their static\n(design-time) and the dynamic (run-time) aspects. A type of balance between the\ntwo aspects can definitely give better results related to system stability and\nadaptivity. MAS organization is the research area that is concerned with these\nissues and it is currently a very active and interesting research area.\nDesigning a MAS with an initial organization and giving it the ability to\ndynamically reorganize to adapt the dynamic changes of its unpredictable and\nuncertain environment, is the feasible way to survive and to run effectively.\nNormally, MAS organization is tackled by what is called, MAS organizational\nmodels, which are concerned with the description (formally or informally) of\nthe structural and dynamical aspects of agent organizations. This paper\nproposes a two-dimension space, called MOS-2, for positioning and assessing MAS\norganizational models based on two dimensions: their adopted engineering\nviewpoint (agent-centered or organization-centered) as the vertical dimension\nand the agents awareness/unawareness of the existence of the organizational\nlevel as the horizontal dimension. The MOS-2 space is applied for positioning a\nnumber of familiar organizational models. Its future trends and possible\nimprovements are highlighted. They include the following, (1) adding Time as a\ndimension, (2) increasing the considered dimensions, (3) providing a\nquantitative approach for positioning MAS organizational models.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.07349v1"
    },
    {
        "title": "Model-Based Stochastic Search for Large Scale Optimization of\n  Multi-Agent UAV Swarms",
        "authors": [
            "David D. Fan",
            "Evangelos Theodorou",
            "John Reeder"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Recent work from the reinforcement learning community has shown that\nEvolution Strategies are a fast and scalable alternative to other reinforcement\nlearning methods. In this paper we show that Evolution Strategies are a special\ncase of model-based stochastic search methods. This class of algorithms has\nnice asymptotic convergence properties and known convergence rates. We show how\nthese methods can be used to solve both cooperative and competitive multi-agent\nproblems in an efficient manner. We demonstrate the effectiveness of this\napproach on two complex multi-agent UAV swarm combat scenarios: where a team of\nfixed wing aircraft must attack a well-defended base, and where two teams of\nagents go head to head to defeat each other.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.01106v2"
    },
    {
        "title": "Hierarchical Heuristic Learning towards Effcient Norm Emergence",
        "authors": [
            "Tianpei Yang",
            "Jianye Hao",
            "Zhaopeng Meng",
            "Sandip Sen",
            "Sheng Jin"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Social norms serve as an important mechanism to regulate the behaviors of\nagents and to facilitate coordination among them in multiagent systems. One\nimportant research question is how a norm can rapidly emerge through repeated\nlocal interaction within an agent society under different environments when\ntheir coordination space becomes large. To address this problem, we propose a\nHierarchically Heuristic Learning Strategy (HHLS) under the hierarchical social\nlearning framework, in which subordinate agents report their information to\ntheir supervisors, while supervisors can generate instructions (rules and\nsuggestions) based on the information collected from their subordinates.\nSubordinate agents heuristically update their strategies based on both their\nown experience and the instructions from their supervisors. Extensive\nexperiment evaluations show that HHLS can support the emergence of desirable\nsocial norms more efficiently and is applicable in a much wider range of\nmultiagent interaction scenarios compared with previous work. We also\ninvestigate the effectiveness of HHLS by separating out the different\ncomponents of the HHLS and evaluating the relative importance of those\ncomponents. The influence of key related factors (e.g., hierarchical factors,\nnon-hierarchical factors, fixed-strategy agents) are investigated as well.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.03059v1"
    },
    {
        "title": "Directing Chemotaxis-Based Spatial Self-Organization via Biased, Random\n  Initial Conditions",
        "authors": [
            "Sean Grimes",
            "Linge Bai",
            "Andrew W. E. McDonald",
            "David E. Breen"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Inspired by the chemotaxis interaction of living cells, we have developed an\nagent-based approach for self-organizing shape formation. Since all our\nsimulations begin with a different uniform random configuration and our agents\nmove stochastically, it has been observed that the self-organization process\nmay form two or more stable final configurations. These differing\nconfigurations may be characterized via statistical moments of the agents'\nlocations. In order to direct the agents to robustly form one specific\nconfiguration, we generate biased initial conditions whose statistical moments\nare related to moments of the desired configuration. With this approach, we are\nable to successfully direct the aggregating swarms to produced a desired\nmacroscopic shape, starting from randomized initial conditions with controlled\nstatistical properties.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.03654v1"
    },
    {
        "title": "Decentralised Learning in Systems with Many, Many Strategic Agents",
        "authors": [
            "David Mguni",
            "Joel Jennings",
            "Enrique Munoz de Cote"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Although multi-agent reinforcement learning can tackle systems of\nstrategically interacting entities, it currently fails in scalability and lacks\nrigorous convergence guarantees. Crucially, learning in multi-agent systems can\nbecome intractable due to the explosion in the size of the state-action space\nas the number of agents increases. In this paper, we propose a method for\ncomputing closed-loop optimal policies in multi-agent systems that scales\nindependently of the number of agents. This allows us to show, for the first\ntime, successful convergence to optimal behaviour in systems with an unbounded\nnumber of interacting adaptive learners. Studying the asymptotic regime of\nN-player stochastic games, we devise a learning protocol that is guaranteed to\nconverge to equilibrium policies even when the number of agents is extremely\nlarge. Our method is model-free and completely decentralised so that each agent\nneed only observe its local state information and its realised rewards. We\nvalidate these theoretical results by showing convergence to Nash-equilibrium\npolicies in applications from economics and control theory with thousands of\nstrategically interacting agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.05028v1"
    },
    {
        "title": "Detection under One-Bit Messaging over Adaptive Networks",
        "authors": [
            "Stefano Marano",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This work studies the operation of multi-agent networks engaged in binary\ndecision tasks, and derives performance expressions and performance operating\ncurves under challenging conditions with some revealing insights. One of the\nmain challenges in the analysis is that agents are only allowed to exchange\none-bit messages, and the information at each agent therefore consists of both\ncontinuous and discrete components. Due to this mixed nature, the steady-state\ndistribution of the state of each agent cannot be inferred from direct\napplication of central limit arguments. Instead, the behavior of the continuous\ncomponent is characterized in integral form by using a log-characteristic\nfunction, while the behavior of the discrete component is characterized by\nmeans of an asymmetric Bernoulli convolution. By exploiting these results, the\narticle derives reliable approximate performance expressions for the network\nnodes that match well with the simulated results for a wide range of system\nparameters. The results also reveal an important interplay between continuous\nadaptation under constant step-size learning and the binary nature of the\nmessages exchanged with neighbors.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.06725v3"
    },
    {
        "title": "Human Satisfaction as the Ultimate Goal in Ridesharing",
        "authors": [
            "Chaya Levinger",
            "Amos Azaria",
            "Noam Hazon"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Transportation services play a crucial part in the development of modern\nsmart cities. In particular, on-demand ridesharing services, which group\ntogether passengers with similar itineraries, are already operating in several\nmetropolitan areas. These services can be of significant social and\nenvironmental benefit, by reducing travel costs, road congestion and co2\nemissions. The deployment of autonomous cars in the near future will surely\nchange the way people are traveling. It is even more promising for a\nridesharing service, since it will be easier and cheaper for a company to\nhandle a fleet of autonomous cars that can serve the demands of different\npassengers.\n  We argue that user satisfaction should be the main objective when trying to\nfind the best assignment of passengers to vehicles and the determination of\ntheir routes. Moreover, the model of user satisfaction should be rich enough to\ncapture the traveling distance, cost, and other factors as well. We show that\nit is more important to capture a rich model of human satisfaction than peruse\nan optimal performance. That is, we developed a practical algorithm for\nassigning passengers to vehicles, which outperforms assignment algorithms that\nare optimal, but use a simpler satisfaction model.\n  To the best of our knowledge, this is the first paper to exclusively\nconcentrate on a rich and realistic function of user satisfaction as the\nobjective, which is (arguably) the most important aspect to consider for\nachieving a widespread adaption of ridesharing services.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.00376v1"
    },
    {
        "title": "Resilient Synchronization of Distributed Multi-agent Systems under\n  Attacks",
        "authors": [
            "Aquib Mustafa",
            "Rohollah Moghadam",
            "Hamidreza Modares"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In this paper, we first address adverse effects of cyber-physical attacks on\ndistributed synchronization of multi-agent systems, by providing conditions\nunder which an attacker can destabilize the underlying network, as well as\nanother set of conditions under which local neighborhood tracking errors of\nintact agents converge to zero. Based on this analysis, we propose a\nKullback-Liebler divergence based criterion in view of which each agent detects\nits neighbors' misbehavior and, consequently, forms a self-belief about the\ntrustworthiness of the information it receives. Agents continuously update\ntheir self-beliefs and communicate them with their neighbors to inform them of\nthe significance of their outgoing information. Moreover, if the self-belief of\nan agent is low, it forms trust on its neighbors. Agents incorporate their\nneighbors' self-beliefs and their own trust values on their control protocols\nto slow down and mitigate attacks. We show that using the proposed resilient\napproach, an agent discards the information it receives from a neighbor only if\nits neighbor is compromised, and not solely based on the discrepancy among\nneighbors' information, which might be caused by legitimate changes, and not\nattacks. The proposed approach is guaranteed to work under mild connectivity\nassumptions.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.02856v5"
    },
    {
        "title": "QDDS: A Novel Quantum Swarm Algorithm Inspired by a Double Dirac Delta\n  Potential",
        "authors": [
            "Saptarshi Sengupta",
            "Sanchita Basak",
            "Richard Alan Peters II"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In this paper a novel Quantum Double Delta Swarm (QDDS) algorithm modeled\nafter the mechanism of convergence to the center of attractive potential field\ngenerated within a single well in a double Dirac delta well setup has been put\nforward and the preliminaries discussed. Theoretical foundations and\nexperimental illustrations have been incorporated to provide a first basis for\nfurther development, specifically in refinement of solutions and applicability\nto problems in high dimensional spaces. Simulations are carried out over\nvarying dimensionality on four benchmark functions, viz. Rosenbrock,\nRastrigrin, Griewank and Sphere as well as the multidimensional Finite Impulse\nResponse (FIR) Filter design problem with different population sizes. Test\nresults illustrate the algorithm yields superior results to some related\nreports in the literature while reinforcing the need of substantial future work\nto deliver near-optimal results consistently, especially if dimensionality\nscales up.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.02870v2"
    },
    {
        "title": "When Are Two Gossips the Same? Types of Communication in Epistemic\n  Gossip Protocols",
        "authors": [
            "Krzysztof R. Apt",
            "Davide Grossi",
            "Wiebe van der Hoek"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We provide an in-depth study of the knowledge-theoretic aspects of\ncommunication in so-called gossip protocols. Pairs of agents communicate by\nmeans of calls in order to spread information---so-called secrets---within the\ngroup. Depending on the nature of such calls knowledge spreads in different\nways within the group. Systematizing existing literature, we identify 18\ndifferent types of communication, and model their epistemic effects through\ncorresponding indistinguishability relations. We then provide a classification\nof these relations and show its usefulness for an epistemic analysis in\npresence of different communication types. Finally, we explain how to formalise\nthe assumption that the agents have common knowledge of a distributed epistemic\ngossip protocol.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.05283v3"
    },
    {
        "title": "Mutual Influences in Interwoven Systems and their detection in the\n  context of Organic Computing",
        "authors": [
            "Neeraj Mumbuveetil Sasankan"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Technical systems have evolved over time into large and complex Interwoven\nSystems consisting of several to a huge number of (possibly heterogeneous)\nsubsystems that have interdependencies. The resultant mutual influences among\nsubsystems have made them so complex that they are no longer manageable by\nhumans and it is assumed to intensify rapidly. Identifying such mutual\ninfluences is the first step towards mastering the complexity of such systems.\nThis paper presents mutual influences in Interwoven Systems by describing\nreal-world examples and a methodology to detect them in the context of Organic\nComputing. The methodology is evaluated with the help of an example. Further, a\ntaxonomy of Organic Computing applications helpful for selecting suitable\nmethods for detecting hidden mutual influences is described briefly.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.08262v1"
    },
    {
        "title": "Multisensor Management Algorithm for Airborne Sensors Using Frank-Wolfe\n  Method",
        "authors": [
            "Youngjoo Kim",
            "Hyochoong Bang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This study proposes an airborne multisensor management algorithm for target\ntracking, taking each of multiple unmanned aircraft as a sensor. The purpose of\nthe algorithm is to determine the configuration of the sensor deployment and to\nguide the mobile sensors to track moving targets in an optimal way. The cost\nfunction as a performance metric is defined as a combination of the\nD-optimality criterion of the Fisher information matrix. The convexity of the\ncost function is proved and the optimal solution for deployment and guidance\nproblem is derived by the Frank-Wolfe method, also known as the conditional\ngradient descent method. An intuitive optimal approach to deal with the problem\nis to direct the sensor to the optimal position obtained by solving a nonlinear\noptimization problem. On the other hand, the proposed method takes the\nconditional gradient of the cost function as the command to the deployed\nsensors, so that the sensors are guaranteed to be in the feasible points and\nthey achieve the current best performance. Simulation results demonstrate that\nthe proposed algorithm provides better performance than directing each sensor\nto its optimal position.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.08531v1"
    },
    {
        "title": "Towards a Programmable Framework for Agent Game Playing",
        "authors": [
            "Francis Lawlor",
            "Rem Collier",
            "Vivek Nallur"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The field of Game Theory provides a useful mechanism for modeling many\ndecision-making scenarios. In participating in these scenarios individuals and\ngroups adopt particular strategies, which generally perform with varying levels\nof success. However, most results have focussed on players that play the same\ngame in an iterated fashion. This paper describes a framework which can be used\nto observe agents when they do not know in advance which game they are going to\nplay. That is, the same group of agents could first play a few rounds of the\nIterated Prisoner's Dilemma, and then a few rounds of the Linear Public Goods\nGame, and then a few rounds of Minority Game, or perhaps all games in a\nstrictly alternating fashion or a randomized instantiation of games. This\nframework will allow for investigation of agents in more complex settings, when\nthere is uncertainty about the future, and limited resources to store\nstrategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.08545v1"
    },
    {
        "title": "Measuring collaborative emergent behavior in multi-agent reinforcement\n  learning",
        "authors": [
            "Sean L. Barton",
            "Nicholas R. Waytowich",
            "Erin Zaroukian",
            "Derrik E. Asher"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Multi-agent reinforcement learning (RL) has important implications for the\nfuture of human-agent teaming. We show that improved performance with\nmulti-agent RL is not a guarantee of the collaborative behavior thought to be\nimportant for solving multi-agent tasks. To address this, we present a novel\napproach for quantitatively assessing collaboration in continuous spatial tasks\nwith multi-agent RL. Such a metric is useful for measuring collaboration\nbetween computational agents and may serve as a training signal for\ncollaboration in future RL paradigms involving humans.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.08663v1"
    },
    {
        "title": "Energy Contract Settlements through Automated Negotiation in Residential\n  Cooperatives",
        "authors": [
            "Shantanu Chakraborty",
            "Tim Baarslag",
            "Michael Kaisers"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper presents an automated peer-to-peer (P2P) negotiation strategy for\nsettling energy contracts among prosumers in a Residential Energy Cooperative\n(REC) considering heterogeneous prosumer preferences. The heterogeneity arises\nfrom prosumers' evaluation of energy contracts through multiple societal and\nenvironmental criteria and the prosumers' private preferences over those\ncriteria. The prosumers engage in bilateral negotiations with peers to mutually\nagree on periodical energy contracts/loans that consist of an energy volume to\nbe exchanged at that period and the return time of the exchanged energy. The\nprosumers keep an ordered preference profile of possible energy contracts by\nevaluating the contracts from their own valuations on the entailed criteria,\nand iteratively offer the peers contracts until an agreement is formed. A\nprosumer embeds the valuations into a utility function that further considers\nuncertainties imposed by demand and generation profiles. Empirical evaluation\non real demand, generation and storage profiles illustrates that the proposed\nnegotiation based strategy is able to increase the system efficiency (measured\nby utilitarian social welfare) and fairness (measured by Nash social welfare)\nover a baseline strategy and an individual flexibility control strategy. We\nthus elicit system benefits from P2P flexibility exchange already with few\nagents and without central coordination, providing a simple yet flexible and\neffective paradigm that may complement existing markets.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.10978v4"
    },
    {
        "title": "Sensory Regimes of Effective Distributed Searching without Leaders",
        "authors": [
            "Ravid Cohen",
            "Yossi Yovel",
            "Dan Halperin"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Collective animal movement fascinates children and scientists alike. One of\nthe most commonly given explanations for collective animal movement is improved\nforaging. Animals are hypothesized to gain from searching for food in groups.\nHere, we use a computer simulation to analyze how moving in a group assists\nsearching for food. We use a well-established collective movement model that\nonly assumes local interactions between individuals without any leadership, in\norder to examine the benefits of group searching. We focus on how the sensory\nabilities of the simulated individuals, and specifically their ability to\ndetect food and to follow neighbours, influence searching dynamics and\nsearching performance. We show that local interactions between neighbors are\nsufficient for the formation of groups, which search more efficiently than\nindependently moving individuals. Once a member of a group finds food, this\ninformation diffuses through the group and results in a convergence of up to\n85\\% of group members on the food. Interestingly, this convergence behavior can\nemerge from the local interactions between group members without a need to\nexplicitly define it. In order to understand the principles underlying the\ngroup's performance, we perturb many of the model's basic parameters, including\nits social, environmental and sensory parameters. We test a wide range of\nbiological-plausible sensory regimes, relevant to different species and\ndifferent sensory modalities and examine how they effect group-foraging\nperformance. This thorough analysis of model parameters allows for the\ngeneralization of our results to a wide range of organisms, which rely on\ndifferent sensory modalities, explaining why they move and forage in groups.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.02895v1"
    },
    {
        "title": "Coupling agent based simulation with dynamic networks analysis to study\n  the emergence of mutual knowledge as a percolation phenomenon",
        "authors": [
            "Julie Dugdale",
            "Narjes Bellamine",
            "Ben Saoud",
            "Fedia Zouai",
            "Bernard Pavard"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The emergence of mutual knowledge is a major cognitive mechanism for the\nrobustness of complex socio technical systems. It has been extensively studied\nfrom an ethnomethodological point of view and empirically reproduced by multi\nagent simulations. Whilst such simulations have been used to design real work\nsettings the underlying theoretical grounding for the process is vague. The aim\nof this paper is to investigate whether the emergence of mutual knowledge (MK)\nin a group of co-located individuals can be explained as a percolation\nphenomenon. The followed methodology consists in coupling agent-based\nsimulation with dynamic networks analysis to study information propagation\nphenomena: after using an agent-based simulation we generated and then analysed\nits traces as networks where agents met and exchanged knowledge. Deep analysis\nof the resulting networks clearly shows that the emergence of MK is comparable\nto a percolation process. We specifically focus on how changes at the\nmicroscopic level in our agent based simulator affect percolation and\nrobustness. These results therefore provides theoretical basis for the analysis\nof social organizations.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.04007v1"
    },
    {
        "title": "Modelling PM10 Crisis Peaks Using Multi-Agent based Simulation:\n  Application to Annaba City, North-East Algeria",
        "authors": [
            "Sabri Ghazi",
            "Julie Dugdale",
            "Tarek Khadir"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The paper describes a MAS (multi-agent system) simulation approach for\ncontrolling PM10 (Particulate Matter) crisis peaks. A dispersion model is used\nwith an Artificial Neural Network (ANN) to predict the PM10 concentration\nlevel. The dispersion and ANN models are integrated into a MAS system. PM10\nsource controllers are modelled as software agents. The MAS is composed of\nagents that cooperate with each other for reducing their emissions and control\nthe air pollution peaks. Different control strategies are simulated and\ncompared using data from Annaba (North-East Algeria). The simulator helps to\ncompare and assess the efficiency of policies to control peaks in PM10.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.04022v1"
    },
    {
        "title": "A Multi-Agent based Approach for Simulating the Impact of Human\n  Behaviours on Air Pollution",
        "authors": [
            "Sabri Ghazi",
            "Julie Dugdale",
            "Tarek Khadir"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper presents a Multi-Agent System (MAS) approach for designing an air\npollution simulator. The aim is to simulate the concentration of air pollutants\nemitted from sources (e.g. factories) and to investigate the emergence of\ncooperation between the emission source managers and the impact this has on air\nquality. The emission sources are controlled by agents. The agents try to\nachieve their goals (i.e. increase production, which has the side effect of\nraising air pollution) and also cooperate with others agents by altering their\nemission rate according to the air quality. The agents play an adapted version\nof the evolutionary N-Person Prisoners' Dilemma game in a non-deterministic\nenvironment; they have two decisions: decrease or increase the emission. The\nrewards/penalties are influenced by the pollutant concentration which is, in\nturn, determined using climatic parameters. In order to give predictions about\nthe Plume Dispersion) model and an ANN (Artificial Neural Network) prediction\nmodel. The prediction is calculated using the dispersal information and real\ndata about climatic parameters (wind speed, humidity, temperature and\nrainfall). Every agent cooperates with its neighbours that emit the same\npollutant, and it learns how to adapt its strategy to gain more reward. When\nthe pollution level exceeds the maximum allowed level, agents are penalised\naccording to their participation. The system has been tested using real data\nfrom the region of Annaba (North-East Algeria). It helped to investigate how\nthe regulations enhance the cooperation and may help controlling the air\nquality. The designed system helps the environmental agencies to assess their\nair pollution controlling policies.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.05429v1"
    },
    {
        "title": "Multi-Level Mesa",
        "authors": [
            "Thomas Pike"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Multi-level Mesa is an extension to support the Python based Agents Based\nModel (ABM) library Mesa. Multi-level Mesa provides ABM infrastructure to allow\nfor the inclusion of complex networks, which have modules (groups) and\nhierarchies (layers) of agents. This approach allows for users to define and\nsimulate multi-layered adaptions of complex networks. This study reviews other\nmulti-level libraries currently in the field, describes the main functions and\nclasses of the Multi-level Mesa, and describes its implementation and impact in\nnumerous varieties using the seminal ABM - Sugarscape. Multi-level Mesa and\nSugarscape examples are available on GitHub at\nhttps://github.com/tpike3/multilevel_mesa and\nhttps://github.com/tpike3/SugarScape.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.08315v1"
    },
    {
        "title": "ABIDES: Towards High-Fidelity Market Simulation for AI Research",
        "authors": [
            "David Byrd",
            "Maria Hybinette",
            "Tucker Hybinette Balch"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We introduce ABIDES, an Agent-Based Interactive Discrete Event Simulation\nenvironment. ABIDES is designed from the ground up to support AI agent research\nin market applications. While simulations are certainly available within\ntrading firms for their own internal use, there are no broadly available\nhigh-fidelity market simulation environments. We hope that the availability of\nsuch a platform will facilitate AI research in this important area. ABIDES\ncurrently enables the simulation of tens of thousands of trading agents\ninteracting with an exchange agent to facilitate transactions. It supports\nconfigurable pairwise network latencies between each individual agent as well\nas the exchange. Our simulator's message-based design is modeled after NASDAQ's\npublished equity trading protocols ITCH and OUCH. We introduce the design of\nthe simulator and illustrate its use and configuration with sample code,\nvalidating the environment with example trading scenarios. The utility of\nABIDES is illustrated through experiments to develop a market impact model. We\nclose with discussion of future experimental problems it can be used to\nexplore, such as the development of ML-based trading algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12066v1"
    },
    {
        "title": "Dealing with uncertainty in agent-based models for short-term\n  predictions",
        "authors": [
            "Le-Minh Kieu",
            "Nicolas Malleson",
            "Alison Heppenstall"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Agent-based models (ABM) are gaining traction as one of the most powerful\nmodelling tools within the social sciences. They are particularly suited to\nsimulating complex systems. Despite many methodological advances within ABM,\none of the major drawbacks is their inability to incorporate real-time data to\nmake accurate short-term predictions. This paper presents an approach that\nallows ABMs to be dynamically optimised. Through a combination of parameter\ncalibration and data assimilation (DA), the accuracy of model-based predictions\nusing ABM in real time is increased. We use the exemplar of a bus route system\nto explore these methods. The bus route ABMs developed in this research are\nexamples of ABMs that can be dynamically optimised by a combination of\nparameter calibration and DA. The proposed model and framework can also be used\nin an passenger information system, or in an Intelligent Transport Systems to\nprovide forecasts of bus locations and arrival times.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.08288v1"
    },
    {
        "title": "Neural Flocking: MPC-based Supervised Learning of Flocking Controllers",
        "authors": [
            "Shouvik Roy",
            "Usama Mehmood",
            "Radu Grosu",
            "Scott A. Smolka",
            "Scott D. Stoller",
            "Ashish Tiwari"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We show how a distributed flocking controller can be synthesized using deep\nlearning from a centralized controller which generates the trajectories of the\nflock. Our approach is based on supervised learning, with the centralized\ncontroller providing the training data to the learning agent, i.e., the\nsynthesized distributed controller. We use Model Predictive Control (MPC) for\nthe centralized controller, an approach that has been successfully demonstrated\non flocking problems. MPC-based flocking controllers are high-performing but\nalso computationally expensive. By learning a symmetric distributed neural\nflocking controller from a centralized MPC-based flocking controller, we\nachieve the best of both worlds: the neural controllers have high performance\n(on par with the MPC controllers) and high efficiency. Our experimental results\ndemonstrate the sophisticated nature of the distributed controllers we learn.\nIn particular, the neural controllers are capable of achieving myriad\nflocking-oriented control objectives, including flocking formation, collision\navoidance, obstacle avoidance, predator avoidance, and target seeking.\nMoreover, they generalize the behavior seen in the training data in order to\nachieve these objectives in a significantly broader range of scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.09813v2"
    },
    {
        "title": "A Predictive Deep Learning Approach to Output Regulation: The Case of\n  Collaborative Pursuit Evasion",
        "authors": [
            "Shashwat Shivam",
            "Aris Kanellopoulos",
            "Kyriakos G. Vamvoudakis",
            "Yorai Wardi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we consider the problem of controlling an underactuated system\nin unknown, and potentially adversarial environments. The emphasis will be on\nautonomous aerial vehicles, modelled by Dubins dynamics. The proposed control\nlaw is based on a variable integrator via online prediction for target\ntracking. To showcase the efficacy of our method, we analyze a pursuit evasion\ngame between multiple autonomous agents. To obviate the need for perfect\nknowledge of the evader's future strategy, we use a deep neural network that is\ntrained to approximate the behavior of the evader based on measurements\ngathered online during the pursuit.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.00893v1"
    },
    {
        "title": "Threshold Greedy Based Task Allocation for Multiple Robot Operations",
        "authors": [
            "Teng Li",
            "Hyo-Sang Shin",
            "Antonios Tsourdos"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper deals with large-scale decentralised task allocation problems for\nmultiple heterogeneous robots with monotone submodular objective functions. One\nof the significant challenges with the large-scale decentralised task\nallocation problem is the NP-hardness for computation and communication. This\npaper proposes a decentralised Decreasing Threshold Task Allocation (DTTA)\nalgorithm that enables parallel allocation by leveraging a decreasing threshold\nto handle the NP-hardness. Then DTTA is upgraded to a more practical version\nLazy Decreasing Threshold Task Allocation (LDTTA) by combining a variant of\nLazy strategy. DTTA and LDTTA can release both computational and communicating\nburden for multiple robots in a decentralised network while providing an\noptimality bound of solution quality. To examine the performance of the\nproposed algorithms, this paper models a multi-target surveillance scenario and\nconducts Monte-Carlo simulations. Simulation results reveal that the proposed\nalgorithms achieve similar function values but consume much less running time\nand consensus steps compared with benchmark decentralised task allocation\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.01239v1"
    },
    {
        "title": "Büchi automata for distributed temporal logic",
        "authors": [
            "Jaime Ramos"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The distributed temporal logic DTL is a logic for reasoning about temporal\nproperties of distributed systems from the local point of view of the system's\nagents, which are assumed to execute sequentially and to interact by means of\nsynchronous event sharing. Different versions of DTL have been provided over\nthe years for a number of different applications, reflecting different\nperspectives on how non-local information can be accessed by each agent. In\nthis paper, we propose a novel notion of distributed B\\\"uchi automaton\nenvisaged to encompass DTL with a model-checking mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.01741v1"
    },
    {
        "title": "Modelling transport provision in a polycentric mega city region",
        "authors": [
            "Florent Le Néchet"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The aim of this paper is to present a model of interaction between transport\nand land use which aims at endogenously integrates the provision of\ntransportation infrastructure and its effects on land use, with a long term\nperspective (Lowry, 1964, Wegener, 2004, Levinson, 2011, Bretagnolle, 2014,\nMimeur et al., 2015). LUTECIA (Land Use, Transport, Evaluation of Cooperation,\nInfrastructure provision and Agglomeration effects) model puts emphasis on\nmultiscale processes of urban growth, in the context of the emergence of\nMega-City Regions (MCR, Hall & Pain, 2006). It allows us, in this exploratory\nphase, to characterize via simulation the conditions of development of\npolycentric metropolises. Nevertheless, we argue that such approaches are all\nthe more necessary that we are in a period of multiple transitions that\nclassical modelling tools have difficulty to capture.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.02396v1"
    },
    {
        "title": "Bi-level Actor-Critic for Multi-agent Coordination",
        "authors": [
            "Haifeng Zhang",
            "Weizhe Chen",
            "Zeren Huang",
            "Minne Li",
            "Yaodong Yang",
            "Weinan Zhang",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Coordination is one of the essential problems in multi-agent systems.\nTypically multi-agent reinforcement learning (MARL) methods treat agents\nequally and the goal is to solve the Markov game to an arbitrary Nash\nequilibrium (NE) when multiple equilibra exist, thus lacking a solution for NE\nselection. In this paper, we treat agents \\emph{unequally} and consider\nStackelberg equilibrium as a potentially better convergence point than Nash\nequilibrium in terms of Pareto superiority, especially in cooperative\nenvironments. Under Markov games, we formally define the bi-level reinforcement\nlearning problem in finding Stackelberg equilibrium. We propose a novel\nbi-level actor-critic learning method that allows agents to have different\nknowledge base (thus intelligent), while their actions still can be executed\nsimultaneously and distributedly. The convergence proof is given, while the\nresulting learning algorithm is tested against the state of the arts. We found\nthat the proposed bi-level actor-critic algorithm successfully converged to the\nStackelberg equilibria in matrix games and find an asymmetric solution in a\nhighway merge environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.03510v3"
    },
    {
        "title": "A Particle Swarm Based Algorithm for Functional Distributed Constraint\n  Optimization Problems",
        "authors": [
            "Moumita Choudhury",
            "Saaduddin Mahmud",
            "Md. Mosaddek Khan"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Distributed Constraint Optimization Problems (DCOPs) are a widely studied\nconstraint handling framework. The objective of a DCOP algorithm is to optimize\na global objective function that can be described as the aggregation of a\nnumber of distributed constraint cost functions. In a DCOP, each of these\nfunctions is defined by a set of discrete variables. However, in many\napplications, such as target tracking or sleep scheduling in sensor networks,\ncontinuous valued variables are more suited than the discrete ones. Considering\nthis, Functional DCOPs (F-DCOPs) have been proposed that is able to explicitly\nmodel a problem containing continuous variables. Nevertheless, the\nstate-of-the-art F-DCOPs approaches experience onerous memory or computation\noverhead. To address this issue, we propose a new F-DCOP algorithm, namely\nParticle Swarm Based F-DCOP (PFD), which is inspired by a meta-heuristic,\nParticle Swarm Optimization (PSO). Although it has been successfully applied to\nmany continuous optimization problems, the potential of PSO has not been\nutilized in F-DCOPs. To be exact, PFD devises a distributed method of solution\nconstruction while significantly reducing the computation and memory\nrequirements. Moreover, we theoretically prove that PFD is an anytime\nalgorithm. Finally, our empirical results indicate that PFD outperforms the\nstate-of-the-art approaches in terms of solution quality and computation\noverhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.06168v1"
    },
    {
        "title": "Distributed Leader Following of an Active Leader for Linear\n  Heterogeneous Multi-Agent Systems",
        "authors": [
            "Yi-Fan Chung",
            "Solmaz S. Kia"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper considers a leader-following problem for a group of heterogeneous\nlinear time invariant (LTI) followers that are interacting over a directed\nacyclic graph. Only a subset of the followers has access to the state of the\nleader in specific sampling times. The dynamics of the leader that generates\nits sampled states is unknown to the followers. For interaction topologies in\nwhich the leader is a global sink in the graph, we propose a distributed\nalgorithm that allows the followers to arrive at the sampled state of the\nleader by the time the next sample arrives. Our algorithm is a practical\nsolution for a leader-following problem when there is no information available\nabout the state of the leader except its instantaneous value at the sampling\ntimes. Our algorithm also allows the followers to track the sampled state of\nthe leader with a locally chosen offset that can be time-varying. When the\nfollowers are mobile agents whose state or part of their state is their\nposition vector, the offset mechanism can be used to enable the followers to\nform a transnational invariant formation about the sampled state of the leader.\nWe prove that the control input of the followers to take them from one sampled\nstate to the next one is minimum energy. We also show in case of the\nhomogeneous followers, after the first sampling epoch the states and inputs of\nall the followers are synchronized with each other. Numerical examples\ndemonstrate our results.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.08008v2"
    },
    {
        "title": "Real-Time Verification for Distributed Cyber-Physical Systems",
        "authors": [
            "Hoang-Dung Tran",
            "Luan Viet Nguyen",
            "Patrick Musau",
            "Weiming Xiang",
            "Taylor T. Johnson"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Safety-critical distributed cyber-physical systems (CPSs) have been found in\na wide range of applications. Notably, they have displayed a great deal of\nutility in intelligent transportation, where autonomous vehicles communicate\nand cooperate with each other via a high-speed communication network. Such\nsystems require an ability to identify maneuvers in real-time that cause\ndangerous circumstances and ensure the implementation always meets\nsafety-critical requirements. In this paper, we propose a real-time\ndecentralized reachability approach for safety verification of a distributed\nmulti-agent CPS with the underlying assumption that all agents are\ntime-synchronized with a low degree of error. In the proposed approach, each\nagent periodically computes its local reachable set and exchanges this\nreachable set with the other agents with the goal of verifying the system\nsafety. Our method, implemented in Java, takes advantages of the timing\ninformation and the reachable set information that are available in the\nexchanged messages to reason about the safety of the whole system in a\ndecentralized manner. Any particular agent can also perform local safety\nverification tasks based on their local clocks by analyzing the messages it\nreceives. We applied the proposed method to verify, in real-time, the safety\nproperties of a group of quadcopters performing a distributed search mission.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.09087v1"
    },
    {
        "title": "Simulating Crowds in Real Time with Agent-Based Modelling and a Particle\n  Filter",
        "authors": [
            "Nick Malleson",
            "Kevin Minors",
            "Le-Minh Kieu",
            "Jonathan A. Ward",
            "Andrew A. West",
            "Alison Heppenstall"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Agent-based modelling is a valuable approach for systems whose behaviour is\ndriven by the interactions between distinct entities. They have shown\nparticular promise as a means of modelling crowds of people in streets, public\ntransport terminals, stadiums, etc. However, the methodology faces a\nfundamental difficulty: there are no established mechanisms for dynamically\nincorporating real-time data into models. This limits simulations that are\ninherently dynamic, such as pedestrian movements, to scenario testing of, for\nexample, the potential impacts of new architectural configurations on\nmovements. This paper begins to address this fundamental gap by demonstrating\nhow a particle filter could be used to incorporate real data into an\nagent-based model of pedestrian movements at run time. The experiments show\nthat it is indeed possible to use a particle filter to perform online (real\ntime) model optimisation. However, as the number of agents increases, the\nnumber of individual particles (and hence the computational complexity)\nrequired increases exponentially. By laying the groundwork for the real-time\nsimulation of crowd movements, this paper has implications for the management\nof complex environments (both nationally and internationally) such as\ntransportation hubs, hospitals, shopping centres, etc.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.09397v1"
    },
    {
        "title": "Independent Generative Adversarial Self-Imitation Learning in\n  Cooperative Multiagent Systems",
        "authors": [
            "Xiaotian Hao",
            "Weixun Wang",
            "Jianye Hao",
            "Yaodong Yang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Many tasks in practice require the collaboration of multiple agents through\nreinforcement learning. In general, cooperative multiagent reinforcement\nlearning algorithms can be classified into two paradigms: Joint Action Learners\n(JALs) and Independent Learners (ILs). In many practical applications, agents\nare unable to observe other agents' actions and rewards, making JALs\ninapplicable. In this work, we focus on independent learning paradigm in which\neach agent makes decisions based on its local observations only. However,\nlearning is challenging in independent settings due to the local viewpoints of\nall agents, which perceive the world as a non-stationary environment due to the\nconcurrently exploring teammates. In this paper, we propose a novel framework\ncalled Independent Generative Adversarial Self-Imitation Learning (IGASIL) to\naddress the coordination problems in fully cooperative multiagent environments.\nTo the best of our knowledge, we are the first to combine self-imitation\nlearning with generative adversarial imitation learning (GAIL) and apply it to\ncooperative multiagent systems. Besides, we put forward a Sub-Curriculum\nExperience Replay mechanism to pick out the past beneficial experiences as much\nas possible and accelerate the self-imitation learning process. Evaluations\nconducted in the testbed of StarCraft unit micromanagement and a commonly\nadopted benchmark show that our IGASIL produces state-of-the-art results and\neven outperforms JALs in terms of both convergence speed and final performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.11468v1"
    },
    {
        "title": "Clustering Strategies of Cooperative Adaptive Cruise Control: Impacts on\n  Human-driven Vehicles",
        "authors": [
            "Zijia Zhong",
            "Mark Nejad",
            "Earl E. Lee",
            "Joyoung Lee"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  As a promising application of connected and automated vehicles (CAVs),\nCooperative Adaptive Cruise Control (CACC) is expected to be deployed on the\npublic road in the near term. Thus far the majority of the CACC studies have\nbeen focusing on the overall network performance with limited insight on the\npotential impact of CAVs on human-driven vehicles (HVs). This paper aims to\nquantify the influence of CAVs on HVs by studying the high-resolution vehicle\ntrajectory data that is obtained from microscopic simulation. Two clustering\nstrategies for CACC are implemented: an ad hoc coordination one and a local\ncoordination one. Results show that the local coordination outperforms the ad\nhoc coordination across all tested market penetration rates (MPRs) in terms of\nnetwork throughput and productivity. The greatest performance difference\nbetween the two strategies is observed at 30% and 40% MPR for throughput and\nproductivity, respectively. However, the distributions of the hard braking\nobservations (as a potential safety impact) for HVs change significantly under\nlocal coordination strategy. Regardless of the clustering strategy, CAVs\nincrease the average lane change frequency for HVs. 30% MPR is the break-even\npoint for local coordination, after which the average lane change frequency\ndecreases from the peak 5.42 to 5.38. Such inverse relationship to MPR is not\nfound in the ah hoc case and the average lane change frequency reaches the\nhighest 5.48 at 40% MPR.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.13204v1"
    },
    {
        "title": "A Turing Test for Crowds",
        "authors": [
            "Jamie Webster",
            "Martyn Amos"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The realism and believability of crowd simulations underpins computational\nstudies of human collective behaviour, with implications for urban design,\npolicing, security and many other areas. Realism concerns the closeness of the\nfit between a simulation and observed data, and believability concerns the\nhuman perception of plausibility. In this paper, we ask two questions, via a\nso-called \"Turing Test\" for crowds: (1) Can human observers distinguish between\nreal and simulated crowds, and (2) Can human observers identify real crowds\nversus simulated crowds? In a study with student volunteers (n=384), we find\nconvincing evidence that non-specialist individuals are able to reliably\ndistinguish between real and simulated crowds. A rather more surprising result\nis that such individuals are overwhelmingly unable to identify real crowds.\nThat is, they can tell real from simulated crowds, but are unable to say which\nis which. Our main conclusion is that (to the lay-person, at least) realistic\ncrowds are not believable (and vice versa).\n",
        "pdf_link": "http://arxiv.org/pdf/1911.06783v1"
    },
    {
        "title": "Dynamic exploration of multi-agent systems with timed periodic tasks",
        "authors": [
            "Johan Arcile",
            "Raymond Devillers",
            "Hanna Klaudel"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We formalise and study multi-agent timed models MAPTs (Multi-Agent with timed\nPeriodic Tasks), where each agent is associated to a regular timed schema upon\nwhich all possibles actions of the agent rely. MAPTs allow for an accelerated\nsemantics and a layered structure of the state space, so that it is possible to\nexplore the latter dynamically and use heuristics to greatly reduce the\ncomputation time needed to address reachability problems. We apply MAPTs to\nexplore state spaces of autonomous vehicles and compare it with other\napproaches in terms of expressivity, abstraction level and computation time.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.07591v1"
    },
    {
        "title": "Scalable Decision-Theoretic Planning in Open and Typed Multiagent\n  Systems",
        "authors": [
            "Adam Eck",
            "Maulik Shah",
            "Prashant Doshi",
            "Leen-Kiat Soh"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In open agent systems, the set of agents that are cooperating or competing\nchanges over time and in ways that are nontrivial to predict. For example, if\ncollaborative robots were tasked with fighting wildfires, they may run out of\nsuppressants and be temporarily unavailable to assist their peers. We consider\nthe problem of planning in these contexts with the additional challenges that\nthe agents are unable to communicate with each other and that there are many of\nthem. Because an agent's optimal action depends on the actions of others, each\nagent must not only predict the actions of its peers, but, before that, reason\nwhether they are even present to perform an action. Addressing openness thus\nrequires agents to model each other's presence, which becomes computationally\nintractable with high numbers of agents. We present a novel, principled, and\nscalable method in this context that enables an agent to reason about others'\npresence in its shared environment and their actions. Our method extrapolates\nmodels of a few peers to the overall behavior of the many-agent system, and\ncombines it with a generalization of Monte Carlo tree search to perform\nindividual agent reasoning in many-agent open environments. Theoretical\nanalyses establish the number of agents to model in order to achieve acceptable\nworst case bounds on extrapolation error, as well as regret bounds on the\nagent's utility from modeling only some neighbors. Simulations of multiagent\nwildfire suppression problems demonstrate our approach's efficacy compared with\nalternative baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.08642v1"
    },
    {
        "title": "Towards a Goal-oriented Agent-based Simulation framework for\n  High-Performance Computing",
        "authors": [
            "Dmitry Gnatyshak",
            "Luis Oliva-Felipe",
            "Sergio Álvarez-Napagao",
            "Julian Padget",
            "Javier Vázquez-Salceda",
            "Dario Garcia-Gasulla",
            "Ulises Cortés"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Currently, agent-based simulation frameworks force the user to choose between\nsimulations involving a large number of agents (at the expense of limited agent\nreasoning capability) or simulations including agents with increased reasoning\ncapabilities (at the expense of a limited number of agents per simulation).\nThis paper describes a first attempt at putting goal-oriented agents into large\nagent-based (micro-)simulations. We discuss a model for goal-oriented agents in\nHigh-Performance Computing (HPC) and then briefly discuss its implementation in\nPyCOMPSs (a library that eases the parallelisation of tasks) to build such a\nplatform that benefits from a large number of agents with the capacity to\nexecute complex cognitive agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.10055v1"
    },
    {
        "title": "HS-CAI: A Hybrid DCOP Algorithm via Combining Search with Context-based\n  Inference",
        "authors": [
            "Dingding Chen",
            "Yanchen Deng",
            "Ziyu Chen",
            "Wenxing Zhang",
            "Zhongshi He"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Search and inference are two main strategies for optimally solving\nDistributed Constraint Optimization Problems (DCOPs). Recently, several\nalgorithms were proposed to combine their advantages. Unfortunately, such\nalgorithms only use an approximated inference as a one-shot preprocessing phase\nto construct the initial lower bounds which lead to inefficient pruning under\nthe limited memory budget. On the other hand, iterative inference algorithms\n(e.g., MB-DPOP) perform a context-based complete inference for all possible\ncontexts but suffer from tremendous traffic overheads. In this paper, $(i)$\nhybridizing search with context-based inference, we propose a complete\nalgorithm for DCOPs, named {HS-CAI} where the inference utilizes the contexts\nderived from the search process to establish tight lower bounds while the\nsearch uses such bounds for efficient pruning and thereby reduces contexts for\nthe inference. Furthermore, $(ii)$ we introduce a context evaluation mechanism\nto select the context patterns for the inference to further reduce the\noverheads incurred by iterative inferences. Finally, $(iii)$ we prove the\ncorrectness of our algorithm and the experimental results demonstrate its\nsuperiority over the state-of-the-art.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.12716v2"
    },
    {
        "title": "Learning Distributed Controllers for V-Formation",
        "authors": [
            "Shouvik Roy",
            "Usama Mehmood",
            "Radu Grosu",
            "Scott A. Smolka",
            "Scott D. Stoller",
            "Ashish Tiwari"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We show how a high-performing, fully distributed and symmetric neural\nV-formation controller can be synthesized from a Centralized MPC (Model\nPredictive Control) controller using Deep Learning. This result is significant\nas we also establish that under very reasonable conditions, it is impossible to\nachieve V-formation using a deterministic, distributed, and symmetric\ncontroller. The learning process we use for the neural V-formation controller\nis significantly enhanced by CEGkR, a Counterexample-Guided k-fold Retraining\ntechnique we introduce, which extends prior work in this direction in important\nways. Our experimental results show that our neural V-formation controller\ngeneralizes to a significantly larger number of agents than for which it was\ntrained (from 7 to 15), and exhibits substantial speedup over the MPC-based\ncontroller. We use a form of statistical model checking to compute confidence\nintervals for our neural V-formation controller's convergence rate and time to\nconvergence.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.00680v1"
    },
    {
        "title": "Crowd simulation for crisis management: the outcomes of the last decade",
        "authors": [
            "George Sidiropoulos",
            "Chairi Kiourt",
            "Lefteris Moussiades"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The last few decades, crowd simulation for crisis management is highlighted\nas an important topic of interest for many scientific fields. As the continues\nevolution of computational resources increases, along with the capabilities of\nArtificial Intelligence, the demand for better and more realistic simulation\nhas become more attractive and popular to scientists. Along those years, there\nhave been published hundreds of research articles and have been created\nnumerous different systems that aim to simulate crowd behaviors, crisis cases\nand emergency evacuation scenarios. For better outcomes, recent research has\nfocused on the separation of the problem of crisis management, to multiple\nresearch sub-fields (categories), such as the navigation of the simulated\npedestrians, their psychology, the group dynamics etc. There have been extended\nresearch works suggesting new methods and techniques for those categories of\nproblems. In this paper, we propose three main research categories, each one\nconsist of several sub-categories, relying on crowd simulation for crisis\nmanagement aspects and we present the outcomes of the last decade, focusing\nmostly on works exploiting multi-agent technologies. We analyze a number of\ntechnologies, methodologies, techniques, tools and systems introduced\nthroughout the last years. A comparative review and discussion of the proposed\ncategories is presented towards the identification of the most efficient\naspects of the proposed categories. A general framework, towards the future\ncrowd simulation for crisis management is presented based on the most efficient\nto yield the most realistic outcomes of the last decades. The paper is\nconcluded with some highlights and open questions for future directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.01216v2"
    },
    {
        "title": "A Maximum Mutual Information Framework for Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Woojun Kim",
            "Whiyoung Jung",
            "Myungsik Cho",
            "Youngchul Sung"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, we propose a maximum mutual information (MMI) framework for\nmulti-agent reinforcement learning (MARL) to enable multiple agents to learn\ncoordinated behaviors by regularizing the accumulated return with the mutual\ninformation between actions. By introducing a latent variable to induce nonzero\nmutual information between actions and applying a variational bound, we derive\na tractable lower bound on the considered MMI-regularized objective function.\nApplying policy iteration to maximize the derived lower bound, we propose a\npractical algorithm named variational maximum mutual information multi-agent\nactor-critic (VM3-AC), which follows centralized learning with decentralized\nexecution (CTDE). We evaluated VM3-AC for several games requiring coordination,\nand numerical results show that VM3-AC outperforms MADDPG and other MARL\nalgorithms in multi-agent tasks requiring coordination.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.02732v1"
    },
    {
        "title": "LFC: Combining Autonomous Agents and Automated Planning in the\n  Multi-Agent Programming Contest",
        "authors": [
            "Rafael C. Cardoso",
            "Angelo Ferrando",
            "Fabio Papacchini"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The 2019 Multi-Agent Programming Contest introduced a new scenario, Agents\nAssemble, where two teams of agents move around a 2D grid and compete to\nassemble complex block structures. In this paper, we describe the strategies\nused by our team that led us to achieve first place in the contest. Our\nstrategies tackle some of the major challenges in the 2019 contest: how to\nexplore and build a map when agents only have access to local vision and no\nglobal coordinates; how to move around the map efficiently even though there\nare dynamic events that can change the cells in the grid; and how to assemble\nand submit complex block structures given that the opposing team may try to\nsabotage us. To implement our strategies, we use the multi-agent systems\ndevelopment platform JaCaMo to program our agents and the Fast Downward planner\nto plan the movement of the agent in the grid. We also provide a brief\ndiscussion of our matches in the contest and give our analysis of how our team\nperformed in each match.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.02736v1"
    },
    {
        "title": "The Multi-Agent Programming Contest: A résumé",
        "authors": [
            "Tobias Ahlbrecht",
            "Jürgen Dix",
            "Niklas Fiekas",
            "Tabajara Krausburg"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The Multi-Agent Programming Contest, MAPC, is an annual event organized since\n2005 out of Clausthal University of Technology. Its aim is to investigate the\npotential of using decentralized, autonomously acting intelligent agents, by\nproviding a complex scenario to be solved in a competitive environment. For\nthis we need suitable benchmarks where agent-based systems can shine. We\npresent previous editions of the contest and also its current scenario and\nresults from its use in the 2019 MAPC with a special focus on its suitability.\nWe conclude with lessons learned over the years.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.02739v1"
    },
    {
        "title": "The Requirement Gatherers' Approach to the 2019 Multi-Agent Programming\n  Contest Scenario",
        "authors": [
            "Michael Vezina",
            "Babak Esfandiari"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The 2019 Multi-Agent Programming Contest (MAPC) scenario poses many\nchallenges for agents participating in the contest. We discuss The Requirement\nGatherers' (TRG) approach to handling the various challenges we faced --\nincluding how we designed our system, how we went about debugging our agents,\nand the strategy we employed to each of our agents. We conclude the paper with\nremarks about the performance of our agents, and what we should have done\ndifferently.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.02816v1"
    },
    {
        "title": "GOAL-DTU: Development of Distributed Intelligence for the Multi-Agent\n  Programming Contest",
        "authors": [
            "Alexander Birch Jensen",
            "Jørgen Villadsen"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We provide a brief description of the GOAL-DTU system for the agent contest,\nincluding the overall strategy and how the system is designed to apply this\nstrategy. Our agents are implemented using the GOAL programming language. We\nevaluate the performance of our agents for the contest, and finally also\ndiscuss how to improve the system based on analysis of its strengths and\nweaknesses.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06844v1"
    },
    {
        "title": "Multi-Agent Programming Contest 2019 FIT BUT Team solution",
        "authors": [
            "Vaclav Uhlir",
            "Frantisek Zboril",
            "Frantisek Vidensky"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  During our participation in MAPC 2019, we have developed two multi-agent\nsystems that have been designed specifically for this competition. The first of\nthe systems is pro-active system that works with pre-specified scenarios and\ntasks agents with generated goals designed for individual agents according to\nassigned role. The second system is designed as more reactive and employs\nlayered architecture with highly dynamic behaviour, where agents select their\nown action based on their perception of usefulness of said action.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.09718v3"
    },
    {
        "title": "Autonomous and Semi-Autonomous Intersection Management: A Survey",
        "authors": [
            "Zijia Zhong",
            "Mark Nejad",
            "Earl E. Lee"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Intersection is a major source of traffic delays and accidents within modern\ntransportation systems. Compared to signalized intersection management,\nautonomous intersection management (AIM) coordinates the intersection crossing\nat an individual vehicle level with additional flexibility. AIM can potentially\neliminate stopping in intersection crossing due to traffic lights while\nmaintaining a safe separation among conflicting movements. In this paper, the\nstate-of-the-art AIM research among various disciplines (e.g., traffic\nengineering, control engineering) is surveyed from the perspective of three\nhierarchical layers: corridor coordination layer, intersection management\nlayer, and vehicle control layer. The key aspects of AIM designs are discussed\nin details, including conflict detection schemes, priority rules, control\ncentralization, computation complexity, etc. The potential improvements for AIM\nevaluation with the emphasis of realistic scenarios are provided. This survey\nserves as a comprehensive review of AIM design and provides promising\ndirections for future research.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.13133v3"
    },
    {
        "title": "A Mathematical Negotiation Mechanism for Distributed Procurement\n  Problems and a Hybrid Algorithm for its Solution",
        "authors": [
            "Zohreh Kaheh",
            "Reza Baradaran Kazemzadeh",
            "Ellips Masehian",
            "Ali Husseinzadeh Kashan"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, a mathematical negotiation mechanism is designed to minimize\nthe negotiators' costs in a distributed procurement problem at two echelons of\nan automotive supply chain. The buyer's costs are procurement cost and shortage\npenalty in a one-period contract. On the other hand, the suppliers intend to\nsolve a multi-period, multi-product production planning to minimize their\ncosts. Such a mechanism provides an alignment among suppliers' production\nplanning and order allocation, also supports the partnership with the valued\nsuppliers by taking suppliers' capacities into account. Such a circumstance has\nbeen modeled via bi-level programming, in which the buyer acts as a leader, and\nthe suppliers individually appear as followers in the lower level. To solve\nthis nonlinear bi-level programming model, a hybrid algorithm by combining the\nparticle swarm optimization (PSO) algorithm with a heuristic algorithm based on\nA search is proposed. The heuristic A algorithm is embedded to solve the\nmixed-integer nonlinear programming (MINLP) sub-problems for each supplier\naccording to the received variable values determined by PSO system particles\n(buyer's request for quotations (RFQs)). The computational analyses have shown\nthat the proposed hybrid algorithm called PSO-A outperforms PSO-SA and\nPSO-Greedy algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.13140v3"
    },
    {
        "title": "A mechanism to promote social behaviour in household load balancing",
        "authors": [
            "Nathan A. Brooks",
            "Simon T. Powers",
            "James M. Borg"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Reducing the peak energy consumption of households is essential for the\neffective use of renewable energy sources, in order to ensure that as much\nhousehold demand as possible can be met by renewable sources. This entails\nspreading out the use of high-powered appliances such as dishwashers and\nwashing machines throughout the day. Traditional approaches to this problem\nhave relied on differential pricing set by a centralised utility company. But\nthis mechanism has not been effective in promoting widespread shifting of\nappliance usage. Here we consider an alternative decentralised mechanism, where\nagents receive an initial allocation of time-slots to use their appliances and\ncan then exchange these with other agents. If agents are willing to be more\nflexible in the exchanges they accept, then overall satisfaction, in terms of\nthe percentage of agents time-slot preferences that are satisfied, will\nincrease. This requires a mechanism that can incentivise agents to be more\nflexible. Building on previous work, we show that a mechanism incorporating\nsocial capital - the tracking of favours given and received - can incentivise\nagents to act flexibly and give favours by accepting exchanges that do not\nimmediately benefit them. We demonstrate that a mechanism that tracks favours\nincreases the overall satisfaction of agents, and crucially allows social\nagents that give favours to outcompete selfish agents that do not under\npayoff-biased social learning. Thus, even completely self-interested agents are\nexpected to learn to produce socially beneficial outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.14526v1"
    },
    {
        "title": "Polarization and Belief Convergence of Agents in Strongly-Connected\n  Influence Graphs",
        "authors": [
            "Mário S. Alvim",
            "Bernardo Amorim",
            "Sophia Knight",
            "Santiago Quintero",
            "Frank Valencia"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We describe a model for polarization in multi-agent systems based on Esteban\nand Ray's classic measure of polarization from economics. Agents evolve by\nupdating their beliefs (opinions) based on the beliefs of others and an\nunderlying influence graph. We show that polarization eventually disappears\n(converges to zero) if the influence graph is strongly-connected. If the\ninfluence graph is a circulation we determine the unique belief value all\nagents converge to. For clique influence graphs we determine the time after\nwhich agents will reach a given difference of opinion. Our results imply that\nif polarization does not disappear then either there is a disconnected subgroup\nof agents or some agent influences others more than she is influenced. Finally,\nwe show that polarization does not necessarily vanish in weakly-connected\ngraphs, and illustrate the model with a series of case studies and simulations\ngiving some insights about polarization.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.02703v1"
    },
    {
        "title": "V2I-Based Platooning Design with Delay Awareness",
        "authors": [
            "Lifeng Wang",
            "Yu Duan",
            "Yun Lai",
            "Shizhuo Mu",
            "Xiang Li"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper studies the vehicle platooning system based on\nvehicle-to-infrastructure (V2I) communication, where all the vehicles in the\nplatoon upload their driving state information to the roadside unit (RSU), and\nRSU makes the platoon control decisions with the assistance of edge computing.\nBy addressing the delay concern, a platoon control approach is proposed to\nachieve plant stability and string stability. The effects of the time headway,\ncommunication and edge computing delays on the stability are quantified. The\nvelocity and size of the stable platoon are calculated, which show the impacts\nof the radio parameters such as massive MIMO antennas and frequency band on the\nplatoon configuration. The handover performance between RSUs in the V2I-based\nplatooning system is quantified by considering the effects of the RSU's\ncoverage and platoon size, which demonstrates that the velocity of a stable\nplatoon should be appropriately chosen, in order to meet the V2I's\nQuality-of-Service and handover constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.03243v1"
    },
    {
        "title": "Learning Compositional Negation in Populations of Roth-Erev and Neural\n  Agents",
        "authors": [
            "Graham Todd",
            "Shane Steinert-Threlkeld",
            "Christopher Potts"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Agent-based models and signalling games are useful tools with which to study\nthe emergence of linguistic communication in a tractable setting. These\ntechniques have been used to study the compositional property of natural\nlanguages, but have been limited in how closely they model real communicators.\nIn this work, we present a novel variant of the classic signalling game that\nexplores the learnability of simple compositional rules concerning negation.\nThe approach builds on the work of Steinert-Threlkeld (2016) by allowing agents\nto determine the identity of the \"function word\" representing negation while\nsimultaneously learning to assign meanings to atomic symbols. We extend the\nanalysis with the introduction of a population of concurrently communicating\nagents, and explore how the complications brought about by a larger population\nsize affect the type and stability of the signalling systems learned. We also\nrelax assumptions of the parametric form of the learning agents and examine how\nneural network-based agents optimized through reinforcement learning behave\nunder various task settings. We find that basic compositional properties are\nrobustly learnable across a wide range of model relaxations and agent\ninstantiations.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.04107v1"
    },
    {
        "title": "Deterministic Privacy Preservation in Static Average Consensus Problem",
        "authors": [
            "Amir-Salar Esteki",
            "Solmaz S. Kia"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper we consider the problem of privacy preservation in the static\naverage consensus problem. This problem normally is solved by proposing privacy\npreservation augmentations for the popular first order Laplacian-based\nalgorithm. These mechanisms however come with computational overhead, may need\ncoordination among the agents to choose their parameters and also alter the\ntransient response of the algorithm. In this paper we show that an alternative\niterative algorithm that is proposed in the literature in the context of\ndynamic average consensus problem has intrinsic privacy preservation and can be\nused as a privacy preserving algorithm that yields the same performance\nbehavior as the well-known Laplacian consensus algorithm but without the\noverheads that come with the existing privacy preservation methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.04213v1"
    },
    {
        "title": "Robust Multi-Agent Reinforcement Learning with Social Empowerment for\n  Coordination and Communication",
        "authors": [
            "T. van der Heiden",
            "C. Salge",
            "E. Gavves",
            "H. van Hoof"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We consider the problem of robust multi-agent reinforcement learning (MARL)\nfor cooperative communication and coordination tasks. MARL agents, mainly those\ntrained in a centralized way, can be brittle because they can adopt policies\nthat act under the expectation that other agents will act a certain way rather\nthan react to their actions. Our objective is to bias the learning process\ntowards finding strategies that remain reactive towards others' behavior.\nSocial empowerment measures the potential influence between agents' actions. We\npropose it as an additional reward term, so agents better adapt to other\nagents' actions. We show that the proposed method results in obtaining higher\nrewards faster and a higher success rate in three cooperative communication and\ncoordination tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.08255v1"
    },
    {
        "title": "A Distributed Simplex Architecture for Multi-Agent Systems",
        "authors": [
            "Usama Mehmood",
            "Scott D. Stoller",
            "Radu Grosu",
            "Shouvik Roy",
            "Amol Damare",
            "Scott A. Smolka"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We present Distributed Simplex Architecture (DSA), a new runtime assurance\ntechnique that provides safety guarantees for multi-agent systems (MASs). DSA\nis inspired by the Simplex control architecture of Sha et al., but with some\nsignificant differences. The traditional Simplex approach is limited to\nsingle-agent systems or a MAS with a centralized control scheme. DSA addresses\nthis limitation by extending the scope of Simplex to include MASs under\ndistributed control. In DSA, each agent has a local instance of traditional\nSimplex such that the preservation of safety in the local instances implies\nsafety for the entire MAS. We provide a proof of safety for DSA, and present\nexperimental results for several case studies, including flocking with\ncollision avoidance, safe navigation of ground rovers through way-points, and\nthe safe operation of a microgrid.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.10153v1"
    },
    {
        "title": "Reinforcement Learning for Unified Allocation and Patrolling in\n  Signaling Games with Uncertainty",
        "authors": [
            "Aravind Venugopal",
            "Elizabeth Bondi",
            "Harshavardhan Kamarthi",
            "Keval Dholakia",
            "Balaraman Ravindran",
            "Milind Tambe"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Green Security Games (GSGs) have been successfully used in the protection of\nvaluable resources such as fisheries, forests and wildlife. While real-world\ndeployment involves both resource allocation and subsequent coordinated\npatrolling with communication and real-time, uncertain information, previous\ngame models do not fully address both of these stages simultaneously.\nFurthermore, adopting existing solution strategies is difficult since they do\nnot scale well for larger, more complex variants of the game models.\n  We therefore first propose a novel GSG model that combines defender\nallocation, patrolling, real-time drone notification to human patrollers, and\ndrones sending warning signals to attackers. The model further incorporates\nuncertainty for real-time decision-making within a team of drones and human\npatrollers. Second, we present CombSGPO, a novel and scalable algorithm based\non reinforcement learning, to compute a defender strategy for this game model.\nCombSGPO performs policy search over a multi-dimensional, discrete action space\nto compute an allocation strategy that is best suited to a best-response\npatrolling strategy for the defender, learnt by training a multi-agent Deep\nQ-Network. We show via experiments that CombSGPO converges to better strategies\nand is more scalable than comparable approaches. Third, we provide a detailed\nanalysis of the coordination and signaling behavior learnt by CombSGPO, showing\ngroup formation between defender resources and patrolling formations based on\nsignaling and notifications between resources. Importantly, we find that\nstrategic signaling emerges in the final learnt strategy. Finally, we perform\nexperiments to evaluate these strategies under different levels of uncertainty.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.10389v1"
    },
    {
        "title": "Bayesian Optimization of Area-based Road Pricing",
        "authors": [
            "Renming Liu",
            "Yu Jiang",
            "Carlos Lima Azevedo"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This study presents a Bayesian Optimization framework for area- and\ndistance-based time-of-day pricing (TODP) for urban networks. The road pricing\noptimization problem can reach high level of complexity depending on the\npricing scheme considered, its associated detailed network properties and the\naffected heterogeneous demand features. We consider heterogeneous travellers\nwith individual-specific trip attributes and departure-time choice parameters\ntogether with a Macroscopic Fundamental Diagram (MFD) model for the urban\nnetwork. Its mathematical formulation is presented and an agent-based\nsimulation framework is constructed as evaluation function for the TODP\noptimization problem. The latter becomes highly nonlinear and relying on an\nexpensive-to-evaluate objective function. We then present and test a Bayesian\nOptimization approach to compute different time-of-day pricing schemes by\nmaximizing social welfare. Our proposed method learns the relationship between\nthe prices and welfare within a few iterations and is able to find good\nsolutions even in scenarios with high dimensionality in the decision variables\nspace, setting a path for complexity reduction in more realistic road pricing\noptimization problems. Furthermore and as expected, the simulation results show\nthat TODP improves the social welfare against the no-pricing case.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.11047v1"
    },
    {
        "title": "Cohorting to isolate asymptomatic spreaders: An agent-based simulation\n  study on the Mumbai Suburban Railway",
        "authors": [
            "Alok Talekar",
            "Sharad Shriram",
            "Nidhin Vaidhiyan",
            "Gaurav Aggarwal",
            "Jiangzhuo Chen",
            "Srini Venkatramanan",
            "Lijing Wang",
            "Aniruddha Adiga",
            "Adam Sadilek",
            "Ashish Tendulkar",
            "Madhav Marathe",
            "Rajesh Sundaresan",
            "Milind Tambe"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The Mumbai Suburban Railways, \\emph{locals}, are a key transit infrastructure\nof the city and is crucial for resuming normal economic activity. To reduce\ndisease transmission, policymakers can enforce reduced crowding and mandate\nwearing of masks. \\emph{Cohorting} -- forming groups of travelers that always\ntravel together, is an additional policy to reduce disease transmission on\n\\textit{locals} without severe restrictions. Cohorting allows us to: ($i$) form\ntraveler bubbles, thereby decreasing the number of distinct interactions over\ntime; ($ii$) potentially quarantine an entire cohort if a single case is\ndetected, making contact tracing more efficient, and ($iii$) target cohorts for\ntesting and early detection of symptomatic as well as asymptomatic cases.\nStudying impact of cohorts using compartmental models is challenging because of\nthe ensuing representational complexity. Agent-based models provide a natural\nway to represent cohorts along with the representation of the cohort members\nwith the larger social network. This paper describes a novel multi-scale\nagent-based model to study the impact of cohorting strategies on COVID-19\ndynamics in Mumbai. We achieve this by modeling the Mumbai urban region using a\ndetailed agent-based model comprising of 12.4 million agents. Individual\ncohorts and their inter-cohort interactions as they travel on locals are\nmodeled using local mean field approximations. The resulting multi-scale model\nin conjunction with a detailed disease transmission and intervention simulator\nis used to assess various cohorting strategies. The results provide a\nquantitative trade-off between cohort size and its impact on disease dynamics\nand well being. The results show that cohorts can provide significant benefit\nin terms of reduced transmission without significantly impacting ridership and\nor economic \\& social activity.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.12839v2"
    },
    {
        "title": "Doubly Stochastic Pairwise Interactions for Agreement and Alignment",
        "authors": [
            "Thomas Dagès",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Random pairwise encounters often occur in large populations, or groups of\nmobile agents, and various types of local interactions that happen at\nencounters account for emergent global phenomena. In particular, in the fields\nof swarm robotics, sociobiology, and social dynamics, several types of local\npairwise interactions were proposed and analysed leading to spatial gathering\nor clustering and agreement in teams of robotic agents coordinated motion, in\nanimal herds, or in human societies. We here propose a very simple stochastic\ninteraction at encounters that leads to agreement or geometric alignment in\nswarms of simple agents, and analyse the process of converging to consensus.\nConsider a group of agents whose \"states\" evolve in time by pairwise\ninteractions: the state of an agent is either a real value (a randomly\ninitialised position within an interval) or a vector that is either\nunconstrained (e.g. the location of the agent in the plane) or constrained to\nhave unit length (e.g. the direction of the agent's motion). The interactions\nare doubly stochastic, in the sense that, at discrete time steps, pairs of\nagents are randomly selected and their new states are independently and\nuniformly set at random in (local) domains or intervals defined by the states\nof the interacting pair. We show that such processes lead, in finite expected\ntime (measured by the number of interactions that occurred) to agreement in\ncase of unconstrained states and alignment when the states are unit vectors.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.13727v2"
    },
    {
        "title": "Knowledge-Based Strategies for Multi-Agent Teams Playing Against Nature",
        "authors": [
            "Dilian Gurov",
            "Valentin Goranko",
            "Edvin Lundberg"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We study teams of agents that play against Nature towards achieving a common\nobjective. The agents are assumed to have imperfect information due to partial\nobservability, and have no communication during the play of the game. We\npropose a natural notion of higher-order knowledge of agents. Based on this\nnotion, we define a class of knowledge-based strategies, and consider the\nproblem of synthesis of strategies of this class. We introduce a multi-agent\nextension, MKBSC, of the well-known Knowledge-Based Subset Construction applied\nto such games. Its iterative applications turn out to compute higher-order\nknowledge of the agents. We show how the MKBSC can be used for the design of\nknowledge-based strategy profiles and investigate the transfer of existence of\nsuch strategies between the original game and in the iterated applications of\nthe MKBSC, under some natural assumptions. We also relate and compare the\n\"intensional\" view on knowledge-based strategies based on explicit knowledge\nrepresentation and update, with the \"extensional\" view on finite memory\nstrategies based on finite transducers and show that, in a certain sense, these\nare equivalent.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.14851v3"
    },
    {
        "title": "Partially Observable Mean Field Reinforcement Learning",
        "authors": [
            "Sriram Ganapathi Subramanian",
            "Matthew E. Taylor",
            "Mark Crowley",
            "Pascal Poupart"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Traditional multi-agent reinforcement learning algorithms are not scalable to\nenvironments with more than a few agents, since these algorithms are\nexponential in the number of agents. Recent research has introduced successful\nmethods to scale multi-agent reinforcement learning algorithms to many agent\nscenarios using mean field theory. Previous work in this field assumes that an\nagent has access to exact cumulative metrics regarding the mean field behaviour\nof the system, which it can then use to take its actions. In this paper, we\nrelax this assumption and maintain a distribution to model the uncertainty\nregarding the mean field of the system. We consider two different settings for\nthis problem. In the first setting, only agents in a fixed neighbourhood are\nvisible, while in the second setting, the visibility of agents is determined at\nrandom based on distances. For each of these settings, we introduce a\nQ-learning based algorithm that can learn effectively. We prove that this\nQ-learning estimate stays very close to the Nash Q-value (under a common set of\nassumptions) for the first setting. We also empirically show our algorithms\noutperform multiple baselines in three different games in the MAgents\nframework, which supports large environments with many agents learning\nsimultaneously to achieve possibly distinct goals.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.15791v3"
    },
    {
        "title": "Agent Based Virus Model using NetLogo: Infection Propagation,\n  Precaution, Recovery, Multi-site Mobility and (Un)Lockdown",
        "authors": [
            "Dibakar Das"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper presents a novel virus propagation model using NetLogo. The model\nallows agents to move across multiple sites using different routes. Routes can\nbe configured, enabled for mobility and (un)locked down independently.\nSimilarly, locations can also be (un)locked down independently. Agents can get\ninfected, propagate their infections to others, can take precautions against\ninfection and also subsequently recover from infection. This model contains\ncertain features that are not present in existing models. The model may be used\nfor educational and research purposes, and the code is made available as open\nsource. This model may also provide a broader framework for more detailed\nsimulations. The results presented are only to demonstrate the model\nfunctionalities and do not serve any other purpose.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00844v1"
    },
    {
        "title": "Convergence Voting: From Pairwise Comparisons to Consensus",
        "authors": [
            "Gergei Bana",
            "Wojciech Jamroga",
            "David Naccache",
            "Peter Y. A. Ryan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  An important aspect of AI design and ethics is to create systems that reflect\naggregate preferences of the society. To this end, the techniques of social\nchoice theory are often utilized. We propose a new social choice function\nmotivated by the PageRank algorithm. The function ranks voting options based on\nthe Condorcet graph of pairwise comparisons. To this end, we transform the\nCondorcet graph into a Markov chain whose stationary distribution provides the\nscores of the options. We show how the values in the stationary distribution\ncan be interpreted as quantified aggregate support for the voting options, to\nwhich the community of voters converges through an imaginary sequence of\nnegotiating steps. Because of that, we suggest the name \"convergence voting\"\nfor the new voting scheme, and \"negotiated community support\" for the resulting\nstationary allocation of scores.\n  Our social choice function can be viewed as a consensus voting method,\nsitting somewhere between Copeland and Borda. On the one hand, it does not\nnecessarily choose the Condorcet winner, as strong support from a part of the\nsociety can outweigh mediocre uniform support. On the other hand, the influence\nof unpopular candidates on the outcome is smaller than in the primary technique\nof consensus voting, i.e., the Borda count. We achieve that without having to\nintroduce an ad hoc weighting that some other methods do.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01995v3"
    },
    {
        "title": "Optimizing Consensus-based Multi-target Tracking with Multiagent Rollout\n  Control Policies",
        "authors": [
            "Tianqi Li",
            "Lucas W. Krakow",
            "Swaminathan Gopalswamy"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper considers a multiagent, connected, robotic fleet where the primary\nfunctionality of the agents is sensing. A distributed multi-sensor control\nstrategy maximizes the value of the collective sensing capability of the fleet,\nusing an information-driven approach. Each agent individually performs sensor\nprocessing (Kalman Filtering and Joint Probabilistic Data Association) to\nidentify trajectories (and associated distributions). Using communications with\nits neighbors the agents enhance the prediction of the trajectories using a\nConsensus of Information approach that iteratively calculates the\nKullback-Leibler average of trajectory distributions, enabling the calculation\nof the value of the collective information for the fleet. The dynamics of the\nagents, the evolution of the identified trajectories for each agent, and the\ndynamics of individual observed objects are captured as a Partially Observable\nMarkov Decision Process (POMDP). Using this POMDP and applying rollout with\nreceding horizon control, an optimized non-myopic control policy that maximizes\nthe collective fleet information value is synthesized. Simulations are\nperformed for a scenario with three heterogeneous UAVs performing coordinated\ntarget tracking that illustrate the proposed methodology and compare the\ncentralized approach with a contemporary sequential multiagent distributed\ndecision technique.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.02919v2"
    },
    {
        "title": "Engineering Swarms of Cyber-Physical Systems with the CPSwarm Workbench",
        "authors": [
            "Micha Sende",
            "Melanie Schranz",
            "Gianluca Prato",
            "Etienne Brosse",
            "Omar Morando",
            "Martina Umlauft"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Engineering swarms of cyber-physical systems (CPSs) is a complex process. We\npresent the CPSwarm workbench that creates an automated design workflow to ease\nthis process. This formalized workflow guides the user from modeling, to code\ngeneration, to deployment, both in simulation and on CPS hardware platforms.\nThe workbench combines existing and emerging tools to solve real-world CPS\nswarm problems. As a proof-of-concept, we use the workbench to design a swarm\nof unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) for a\nsearch and rescue (SAR) use case. We evaluate the resulting swarm behaviors on\nthree levels. First, abstract simulations for rapid prototyping. Second,\ndetailed simulation to test the correctness of the results. Third, deployment\non hardware to demonstrate the applicability. We measure the swarm performance\nin terms of area covered and victims rescued. The results show that the\nperformance of the swarm is proportional to its size. Despite some manual\nsteps, the proposed workbench shows to be well suited to ease the complicated\ntask of deploying a swarm of CPSs.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.13351v1"
    },
    {
        "title": "Democratic Forking: Choosing Sides with Social Choice",
        "authors": [
            "Ben Abramowitz",
            "Edith Elkind",
            "Davide Grossi",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Any community in which membership is optional may eventually break apart, or\nfork. For example, forks may occur in political parties, business partnerships,\nsocial groups, cryptocurrencies, and federated governing bodies. Forking is\ntypically the product of informal social processes or the organized action of\nan aggrieved minority, and it is not always amicable. Forks usually come at a\ncost, and can be seen as consequences of collective decisions that destabilize\nthe community. Here, we provide a social choice setting in which agents can\nreport preferences not only over a set of alternatives, but also over the\npossible forks that may occur in the face of disagreement. We study this social\nchoice setting, concentrating on stability issues and concerns of strategic\nagent behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.03652v2"
    },
    {
        "title": "Preventing Extreme Polarization of Political Attitudes",
        "authors": [
            "Robert Axelrod",
            "Joshua J. Daymude",
            "Stephanie Forrest"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Extreme polarization can undermine democracy by making compromise impossible\nand transforming politics into a zero-sum game. Ideological polarization - the\nextent to which political views are widely dispersed - is already strong among\nelites, but less so among the general public (McCarty, 2019, p. 50-68). Strong\nmutual distrust and hostility between Democrats and Republicans in the U.S.,\ncombined with the elites' already strong ideological polarization, could lead\nto increasing ideological polarization among the public. The paper addresses\ntwo questions: (1) Is there a level of ideological polarization above which\npolarization feeds upon itself to become a runaway process? (2) If so, what\npolicy interventions could prevent such dangerous positive feedback loops? To\nexplore these questions, we present an agent-based model of ideological\npolarization that differentiates between the tendency for two actors to\ninteract (exposure) and how they respond when interactions occur, positing that\ninteraction between similar actors reduces their difference while interaction\nbetween dissimilar actors increases their difference. Our analysis explores the\neffects on polarization of different levels of tolerance to other views,\nresponsiveness to other views, exposure to dissimilar actors, multiple\nideological dimensions, economic self-interest, and external shocks. The\nresults suggest strategies for preventing, or at least slowing, the development\nof extreme polarization.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.06492v2"
    },
    {
        "title": "Utility of Traffic Information in Dynamic Routing: Is Sharing\n  Information Always Useful?",
        "authors": [
            "Mohammad Shaqfeh",
            "Salah Hessien",
            "Erchin Serpedin"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Real-time traffic information can be utilized to enhance the efficiency of\ntransportation networks by dynamically updating routing plans to mitigate\ntraffic jams. However, an interesting question is whether the network\ncoordinator should broadcast real-time traffic information to all network users\nor communicate it selectively to some of them. Which option enhances the\nnetwork efficiency more? In this work, we demonstrate using simulation\nexperiments that sharing real-time traffic information with all network users\nis sub-optimal, and it is actually better to share the information with a\nmajority subset of the total population in order to improve the overall network\nperformance. This result is valid under the assumption that each network user\ndecides its route to destination locally.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.06574v1"
    },
    {
        "title": "Electric Vehicle Charging Scheduling in Green Logistics: Challenges,\n  Approaches and Opportunities",
        "authors": [
            "Luyang Hou",
            "Chun Wang",
            "Jun Yan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Replacing a fossil fuel-powered car with an electric model can halve\ngreenhouse gas emissions over the course of the vehicle's lifetime and reduce\nthe noise pollution in urban areas. In green logistics, a well-scheduled\ncharging ensures an efficient operation of transportation and power systems\nand, at the same time, provides economical and satisfactory charging services\nfor drivers. This paper presents a taxonomy of current electric vehicle\ncharging scheduling problems in green logistics by analyzing its unique\nfeatures with some typical use cases, such as space assignment, routing and\nenergy management; discusses the challenges, i.e., the information availability\nand stakeholders' strategic behaviors that arise in stochastic and\ndecentralized environments; and classifies the existing approaches, as\ncentralized, distributed and decentralized ones, that apply to these\nchallenges. Moreover, we discuss research opportunities in applying\nmarket-based mechanisms, which shall be coordinated with stochastic\noptimization and machine learning, to the decentralized, dynamic and\ndata-driven charging scheduling problems for the management of the future green\nlogistics.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.07635v1"
    },
    {
        "title": "Learning in Nonzero-Sum Stochastic Games with Potentials",
        "authors": [
            "David Mguni",
            "Yutong Wu",
            "Yali Du",
            "Yaodong Yang",
            "Ziyi Wang",
            "Minne Li",
            "Ying Wen",
            "Joel Jennings",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi-agent reinforcement learning (MARL) has become effective in tackling\ndiscrete cooperative game scenarios. However, MARL has yet to penetrate\nsettings beyond those modelled by team and zero-sum games, confining it to a\nsmall subset of multi-agent systems. In this paper, we introduce a new\ngeneration of MARL learners that can handle nonzero-sum payoff structures and\ncontinuous settings. In particular, we study the MARL problem in a class of\ngames known as stochastic potential games (SPGs) with continuous state-action\nspaces. Unlike cooperative games, in which all agents share a common reward,\nSPGs are capable of modelling real-world scenarios where agents seek to fulfil\ntheir individual goals. We prove theoretically our learning method, SPot-AC,\nenables independent agents to learn Nash equilibrium strategies in polynomial\ntime. We demonstrate our framework tackles previously unsolvable tasks such as\nCoordination Navigation and large selfish routing games and that it outperforms\nthe state of the art MARL baselines such as MADDPG and COMIX in such scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.09284v4"
    },
    {
        "title": "Reward-Reinforced Reinforcement Learning for Multi-agent Systems",
        "authors": [
            "Changgang Zheng",
            "Shufan Yang",
            "Juan Parra-Ullauri",
            "Antonio Garcia-Dominguez",
            "Nelly Bencomo"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Reinforcement learning algorithms in multi-agent systems deliver highly\nresilient and adaptable solutions for common problems in\ntelecommunications,aerospace, and industrial robotics. However, achieving an\noptimal global goal remains a persistent obstacle for collaborative multi-agent\nsystems, where learning affects the behaviour of more than one agent. A number\nof nonlinear function approximation methods have been proposed for solving the\nBellman equation, which describe a recursive format of an optimal policy.\nHowever, how to leverage the value distribution based on reinforcement\nlearning, and how to improve the efficiency and efficacy of such systems remain\na challenge. In this work, we developed a reward-reinforced generative\nadversarial network to represent the distribution of the value function,\nreplacing the approximation of Bellman updates. We demonstrated our method is\nresilient and outperforms other conventional reinforcement learning methods.\nThis method is also applied to a practical case study: maximising the number of\nuser connections to autonomous airborne base stations in a mobile communication\nnetwork. Our method maximises the data likelihood using a cost function under\nwhich agents have optimal learned behaviours. This reward-reinforced generative\nadversarial network can be used as ageneric framework for multi-agent learning\nat the system level\n",
        "pdf_link": "http://arxiv.org/pdf/2103.12192v2"
    },
    {
        "title": "Preliminary Experimental Results of Context-Aware Teams of Multiple\n  Autonomous Agents Operating under Constrained Communications",
        "authors": [
            "Jose Martinez-Lorenzo",
            "Jeff Hudack",
            "Yutao Jing",
            "Michael Shaham",
            "Zixuan Liang",
            "Abdullah Al Bashit",
            "Yushu Wu",
            "Weite Zhang",
            "Matthew Skopin",
            "Juan Heredia-Juesas",
            "Yuntao Ma",
            "Tristan Sweeney",
            "Nicolas Ares",
            "Ari Fox"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This work presents and experimentally test the framework used by our\ncontext-aware, distributed team of small Unmanned Aerial Systems (SUAS) capable\nof operating in real-time, in an autonomous fashion, and under constrained\ncommunications. Our framework relies on three layered approach: (1) Operational\nlayer, where fast temporal and narrow spatial decisions are made; (2) Tactical\nLayer, where temporal and spatial decisions are made for a team of agents; and\n(3) Strategical Layer, where slow temporal and wide spatial decisions are made\nfor the team of agents. These three layers are coordinated by an ad-hoc,\nsoftware-defined communications network, which ensures sparse, but timely\ndelivery of messages amongst groups and teams of agents at each layer even\nunder constrained communications. Experimental results are presented for a team\nof 10 small unmanned aerial systems tasked with searching and monitoring a\nperson in an open area. At the operational layer, our use case presents an\nagent autonomously performing searching, detection, localization,\nclassification, identification, tracking, and following of the person, while\navoiding malicious collisions. At the tactical layer, our experimental use case\npresents the cooperative interaction of a group of multiple agents that enable\nthe monitoring of the targeted person over a wider spatial and temporal\nregions. At the strategic layer, our use case involves the detection of complex\nbehaviors-i.e. the person being followed enters a car and runs away, or the\nperson being followed exits the car and runs away-that requires strategic\nresponses to successfully accomplish the mission.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.14123v1"
    },
    {
        "title": "Scalable Planning in Multi-Agent MDPs",
        "authors": [
            "Dinuka Sahabandu",
            "Luyao Niu",
            "Andrew Clark",
            "Radha Poovendran"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi-agent Markov Decision Processes (MMDPs) arise in a variety of\napplications including target tracking, control of multi-robot swarms, and\nmultiplayer games. A key challenge in MMDPs occurs when the state and action\nspaces grow exponentially in the number of agents, making computation of an\noptimal policy computationally intractable for medium- to large-scale problems.\nOne property that has been exploited to mitigate this complexity is transition\nindependence, in which each agent's transition probabilities are independent of\nthe states and actions of other agents. Transition independence enables\nfactorization of the MMDP and computation of local agent policies but does not\nhold for arbitrary MMDPs. In this paper, we propose an approximate transition\ndependence property, called $\\delta$-transition dependence and develop a metric\nfor quantifying how far an MMDP deviates from transition independence. Our\ndefinition of $\\delta$-transition dependence recovers transition independence\nas a special case when $\\delta$ is zero. We develop a polynomial time algorithm\nin the number of agents that achieves a provable bound on the global optimum\nwhen the reward functions are monotone increasing and submodular in the agent\nactions. We evaluate our approach on two case studies, namely, multi-robot\ncontrol and multi-agent patrolling example.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.15894v1"
    },
    {
        "title": "Distributed learning in congested environments with partial information",
        "authors": [
            "Tomer Boyarski",
            "Amir Leshem",
            "Vikram Krishnamurthy"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  How can non-communicating agents learn to share congested resources\nefficiently? This is a challenging task when the agents can access the same\nresource simultaneously (in contrast to multi-agent multi-armed bandit\nproblems) and the resource valuations differ among agents. We present a fully\ndistributed algorithm for learning to share in congested environments and prove\nthat the agents' regret with respect to the optimal allocation is\npoly-logarithmic in the time horizon. Performance in the non-asymptotic regime\nis illustrated in numerical simulations. The distributed algorithm has\napplications in cloud computing and spectrum sharing. Keywords: Distributed\nlearning, congestion games, poly-logarithmic regret.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.15901v2"
    },
    {
        "title": "Optimal Decoy Resource Allocation for Proactive Defense in Probabilistic\n  Attack Graphs",
        "authors": [
            "Haoxiang Ma",
            "Shuo Han",
            "Nandi Leslie",
            "Charles Kamhoua",
            "Jie Fu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper investigates the problem of synthesizing proactive defense systems\nin which the defender can allocate deceptive targets and modify the cost of\nactions for the attacker who aims to compromise security assets in this system.\nWe model the interaction of the attacker and the system using a formal security\nmodel -- a probabilistic attack graph. By allocating fake targets/decoys, the\ndefender aims to distract the attacker from compromising true targets. By\nincreasing the cost of some attack actions, the defender aims to discourage the\nattacker from committing to certain policies and thereby improve the defense.\nTo optimize the defense given limited decoy resources and operational\nconstraints, we formulate the synthesis problem as a bi-level optimization\nproblem, while the defender designs the system, in anticipation of the\nattacker's best response given that the attacker has disinformation about the\nsystem due to the use of deception. Though the general formulation with\nbi-level optimization is NP-hard, we show that under certain assumptions, the\nproblem can be transformed into a constrained optimization problem. We proposed\nan algorithm to approximately solve this constrained optimization problem using\na novel incentive-design method for projected gradient ascent. We demonstrate\nthe effectiveness of the proposed method using extensive numerical experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01336v1"
    },
    {
        "title": "Attention-Based Recurrence for Multi-Agent Reinforcement Learning under\n  Stochastic Partial Observability",
        "authors": [
            "Thomy Phan",
            "Fabian Ritz",
            "Philipp Altmann",
            "Maximilian Zorn",
            "Jonas Nüßlein",
            "Michael Kölle",
            "Thomas Gabor",
            "Claudia Linnhoff-Popien"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Stochastic partial observability poses a major challenge for decentralized\ncoordination in multi-agent reinforcement learning but is largely neglected in\nstate-of-the-art research due to a strong focus on state-based centralized\ntraining for decentralized execution (CTDE) and benchmarks that lack sufficient\nstochasticity like StarCraft Multi-Agent Challenge (SMAC). In this paper, we\npropose Attention-based Embeddings of Recurrence In multi-Agent Learning\n(AERIAL) to approximate value functions under stochastic partial observability.\nAERIAL replaces the true state with a learned representation of multi-agent\nrecurrence, considering more accurate information about decentralized agent\ndecisions than state-based CTDE. We then introduce MessySMAC, a modified\nversion of SMAC with stochastic observations and higher variance in initial\nstates, to provide a more general and configurable benchmark regarding\nstochastic partial observability. We evaluate AERIAL in Dec-Tiger as well as in\na variety of SMAC and MessySMAC maps, and compare the results with state-based\nCTDE. Furthermore, we evaluate the robustness of AERIAL and state-based CTDE\nagainst various stochasticity configurations in MessySMAC.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01649v6"
    },
    {
        "title": "Platoon Leader Selection, User Association and Resource Allocation on a\n  C-V2X based highway: A Reinforcement Learning Approach",
        "authors": [
            "Mohammad Farzanullah",
            "Tho Le-Ngoc"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We consider the problem of dynamic platoon leader selection, user\nassociation, channel assignment, and power allocation on a cellular\nvehicle-to-everything (C-V2X) based highway, where multiple vehicle-to-vehicle\n(V2V) and vehicle-to-infrastructure (V2I) links share the frequency resources.\nThere are multiple roadside units (RSUs) on a highway, and vehicles can form\nplatoons, which has been identified as an advanced use case to increase road\nefficiency. The traditional optimization methods, requiring global channel\ninformation at a central controller, are not viable for high-mobility vehicular\nnetworks. To deal with this challenge, we propose a distributed multi-agent\nreinforcement learning (MARL) for resource allocation (RA). Each platoon\nleader, acting as an agent, can collaborate with other agents for joint\nsub-band selection and power allocation for its V2V links, and joint user\nassociation and power control for its V2I links. Moreover, each platoon can\ndynamically select the vehicle most suitable to be the platoon leader. We aim\nto maximize the V2V and V2I packet delivery probability in the desired latency\nusing the deep Q-learning algorithm. Simulation results indicate that our\nproposed MARL outperforms the centralized hill-climbing algorithm, and platoon\nleader selection helps to improve both V2V and V2I performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.03145v2"
    },
    {
        "title": "Heterogeneous Beliefs and Multi-Population Learning in Network Games",
        "authors": [
            "Shuyue Hu",
            "Harold Soh",
            "Georgios Piliouras"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The effect of population heterogeneity in multi-agent learning is practically\nrelevant but remains far from being well-understood. Motivated by this, we\nintroduce a model of multi-population learning that allows for heterogeneous\nbeliefs within each population and where agents respond to their beliefs via\nsmooth fictitious play (SFP).We show that the system state -- a probability\ndistribution over beliefs -- evolves according to a system of partial\ndifferential equations akin to the continuity equations that commonly desccribe\ntransport phenomena in physical systems. We establish the convergence of SFP to\nQuantal Response Equilibria in different classes of games capturing both\nnetwork competition as well as network coordination. We also prove that the\nbeliefs will eventually homogenize in all network games. Although the initial\nbelief heterogeneity disappears in the limit, we show that it plays a crucial\nrole for equilibrium selection in the case of coordination games as it helps\nselect highly desirable equilibria. Contrary, in the case of network\ncompetition, the resulting limit behavior is independent of the initialization\nof beliefs, even when the underlying game has many distinct Nash equilibria.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.04929v1"
    },
    {
        "title": "Opponent-aware Role-based Learning in Team Competitive Markov Games",
        "authors": [
            "Paramita Koley",
            "Aurghya Maiti",
            "Niloy Ganguly",
            "Sourangshu Bhattacharya"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Team competition in multi-agent Markov games is an increasingly important\nsetting for multi-agent reinforcement learning, due to its general\napplicability in modeling many real-life situations. Multi-agent actor-critic\nmethods are the most suitable class of techniques for learning optimal policies\nin the team competition setting, due to their flexibility in learning\nagent-specific critic functions, which can also learn from other agents. In\nmany real-world team competitive scenarios, the roles of the agents naturally\nemerge, in order to aid in coordination and collaboration within members of the\nteams. However, existing methods for learning emergent roles rely heavily on\nthe Q-learning setup which does not allow learning of agent-specific\nQ-functions. In this paper, we propose RAC, a novel technique for learning the\nemergent roles of agents within a team that are diverse and dynamic. In the\nproposed method, agents also benefit from predicting the roles of the agents in\nthe opponent team. RAC uses the actor-critic framework with role encoder and\nopponent role predictors for learning an optimal policy. Experimentation using\n2 games demonstrates that the policies learned by RAC achieve higher rewards\nthan those learned using state-of-the-art baselines. Moreover, experiments\nsuggest that the agents in a team learn diverse and opponent-aware policies.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.05873v1"
    },
    {
        "title": "Event-Triggered Optimal Formation Tracking Control Using Reinforcement\n  Learning for Large-Scale UAV Systems",
        "authors": [
            "Ziwei Yan",
            "Liang Han",
            "Xiaoduo Li",
            "Jinjie Li",
            "Zhang Ren"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Large-scale UAV switching formation tracking control has been widely applied\nin many fields such as search and rescue, cooperative transportation, and UAV\nlight shows. In order to optimize the control performance and reduce the\ncomputational burden of the system, this study proposes an event-triggered\noptimal formation tracking controller for discrete-time large-scale UAV systems\n(UASs). And an optimal decision - optimal control framework is completed by\nintroducing the Hungarian algorithm and actor-critic neural networks (NNs)\nimplementation. Finally, a large-scale mixed reality experimental platform is\nbuilt to verify the effectiveness of the proposed algorithm, which includes\nlarge-scale virtual UAV nodes and limited physical UAV nodes. This compensates\nfor the limitations of the experimental field and equipment in realworld\nscenario, ensures the experimental safety, significantly reduces the\nexperimental cost, and is suitable for realizing largescale UAV formation light\nshows.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.06749v2"
    },
    {
        "title": "AI Tool for Exploring How Economic Activities Impact Local Ecosystems",
        "authors": [
            "Claes Strannegård",
            "Niklas Engsner",
            "Rasmus Lindgren",
            "Simon Olsson",
            "John Endler"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We present an AI-based ecosystem simulator that uses three-dimensional models\nof the terrain and animal models controlled by deep reinforcement learning. The\nsimulations take place in a game engine environment, which enables continuous\nvisual observation of the ecosystem model. The terrain models are generated\nfrom geographic data with altitudes and land cover type. The animal models\ncombine three-dimensional conformation models with animation schemes and\ndecision-making mechanisms trained with deep reinforcement learning in\nincreasingly complex environments (curriculum learning). We show how AI tools\nof this kind can be used for modeling the development of specific ecosystems\nwith and without different forms of economic activities. In particular, we show\nhow they might be used for modeling local biodiversity effects of land cover\nchange, exploitation of natural resources, pollution, invasive species, and\nclimate change.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10507v2"
    },
    {
        "title": "DIFFER: Decomposing Individual Reward for Fair Experience Replay in\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Xunhan Hu",
            "Jian Zhao",
            "Wengang Zhou",
            "Ruili Feng",
            "Houqiang Li"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Cooperative multi-agent reinforcement learning (MARL) is a challenging task,\nas agents must learn complex and diverse individual strategies from a shared\nteam reward. However, existing methods struggle to distinguish and exploit\nimportant individual experiences, as they lack an effective way to decompose\nthe team reward into individual rewards. To address this challenge, we propose\nDIFFER, a powerful theoretical framework for decomposing individual rewards to\nenable fair experience replay in MARL. By enforcing the invariance of network\ngradients, we establish a partial differential equation whose solution yields\nthe underlying individual reward function. The individual TD-error can then be\ncomputed from the solved closed-form individual rewards, indicating the\nimportance of each piece of experience in the learning task and guiding the\ntraining process. Our method elegantly achieves an equivalence to the original\nlearning framework when individual experiences are homogeneous, while also\nadapting to achieve more muscular efficiency and fairness when diversity is\nobserved.Our extensive experiments on popular benchmarks validate the\neffectiveness of our theory and method, demonstrating significant improvements\nin learning efficiency and fairness.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10574v2"
    },
    {
        "title": "Effect of Swarm Density on Collective Tracking Performance",
        "authors": [
            "Hian Lee Kwa",
            "Julien Philippot",
            "Roland Bouffanais"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  How does the size of a swarm affect its collective action? Despite being\narguably a key parameter, no systematic and satisfactory guiding principles\nexist to select the number of units required for a given task and environment.\nEven when limited by practical considerations, system designers should endeavor\nto identify what a reasonable swarm size should be. Here, we show that this\nfundamental question is closely linked to that of selecting an appropriate\nswarm density. Our analysis of the influence of density on the collective\nperformance of a target tracking task reveals different `phases' corresponding\nto markedly distinct group dynamics. We identify a `transition' phase, in which\na complex emergent collective response arises. Interestingly, the collective\ndynamics within this transition phase exhibit a clear trade-off between\nexploratory actions and exploitative ones. We show that at any density, the\nexploration-exploitation balance can be adjusted to maximize the system's\nperformance through various means, such as by changing the level of\nconnectivity between agents. While the density is the primary factor to be\nconsidered, it should not be the sole one to be accounted for when sizing the\nsystem. Due to the inherent finite-size effects present in physical systems, we\nestablish that the number of constituents primarily affects system-level\nproperties such as exploitation in the transition phase. These results\nillustrate that instead of learning and optimizing a swarm's behavior for a\nspecific set of task parameters, further work should instead concentrate on\nlearning to be adaptive, thereby endowing the swarm with the highly desirable\nfeature of being able to operate effectively over a wide range of\ncircumstances.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10692v1"
    },
    {
        "title": "HoLA Robots: Mitigating Plan-Deviation Attacks in Multi-Robot Systems\n  with Co-Observations and Horizon-Limiting Announcements",
        "authors": [
            "Kacper Wardega",
            "Max von Hippel",
            "Roberto Tron",
            "Cristina Nita-Rotaru",
            "Wenchao Li"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Emerging multi-robot systems rely on cooperation between humans and robots,\nwith robots following automatically generated motion plans to service\napplication-level tasks. Given the safety requirements associated with\noperating in proximity to humans and expensive infrastructure, it is important\nto understand and mitigate the security vulnerabilities of such systems caused\nby compromised robots who diverge from their assigned plans. We focus on\ncentralized systems, where a *central entity* (CE) is responsible for\ndetermining and transmitting the motion plans to the robots, which report their\nlocation as they move following the plan. The CE checks that robots follow\ntheir assigned plans by comparing their expected location to the location they\nself-report. We show that this self-reporting monitoring mechanism is\nvulnerable to *plan-deviation attacks* where compromised robots don't follow\ntheir assigned plans while trying to conceal their movement by mis-reporting\ntheir location. We propose a two-pronged mitigation for plan-deviation attacks:\n(1) an attack detection technique leveraging both the robots' local sensing\ncapabilities to report observations of other robots and *co-observation\nschedules* generated by the CE, and (2) a prevention technique where the CE\nissues *horizon-limiting announcements* to the robots, reducing their\ninstantaneous knowledge of forward lookahead steps in the global motion plan.\nOn a large-scale automated warehouse benchmark, we show that our solution\nenables attack prevention guarantees from a stealthy attacker that has\ncompromised multiple robots.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10704v1"
    },
    {
        "title": "Periodic Multi-Agent Path Planning",
        "authors": [
            "Kazumi Kasaura",
            "Ryo Yonetani",
            "Mai Nishimura"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent path planning (MAPP) is the problem of planning collision-free\ntrajectories from start to goal locations for a team of agents. This work\nexplores a relatively unexplored setting of MAPP where streams of agents have\nto go through the starts and goals with high throughput. We tackle this problem\nby formulating a new variant of MAPP called periodic MAPP in which the timing\nof agent appearances is periodic. The objective with periodic MAPP is to find a\nperiodic plan, a set of collision-free trajectories that the agent streams can\nuse repeatedly over periods, with periods that are as small as possible. To\nmeet this objective, we propose a solution method that is based on constraint\nrelaxation and optimization. We show that the periodic plans once found can be\nused for a more practical case in which agents in a stream can appear at random\ntimes. We confirm the effectiveness of our method compared with baseline\nmethods in terms of throughput in several scenarios that abstract autonomous\nintersection management tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10910v2"
    },
    {
        "title": "A Quantification Approach for Transferability in Lifelike Computing\n  Systems",
        "authors": [
            "Martin Goller",
            "Sven Tomforde"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The basic idea of lifelike computing systems is the transfer of concepts in\nliving systems to technical use that goes even beyond existing concepts of\nself-adaptation and self-organisation (SASO). As a result, these systems become\neven more autonomous and changeable - up to a runtime transfer of the actual\ntarget function. Maintaining controllability requires a complete and dynamic\n(self-)quantification of the system behaviour with regard to aspects of SASO\nbut also, in particular, lifelike properties. In this article, we discuss\npossible approaches for such metrics and establish a first metric for\ntransferability. We analyse the behaviour of the metric using example\napplications and show that it is suitable for describing the system's behaviour\nat runtime.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.12854v1"
    },
    {
        "title": "Multi-sensor Information Processing using Prediction Market-based Belief\n  Aggregation",
        "authors": [
            "Janyl Jumadinova",
            "Prithviraj Dasgupta"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  We consider the problem of information fusion from multiple sensors of\ndifferent types with the objective of improving the confidence of inference\ntasks, such as object classification, performed from the data collected by the\nsensors. We propose a novel technique based on distributed belief aggregation\nusing a multi-agent prediction market to solve this information fusion problem.\nTo monitor the improvement in the confidence of the object classification as\nwell as to dis-incentivize agents from misreporting information, we have\nintroduced a market maker that rewards the agents instantaneously as well as at\nthe end of the inference task, based on the quality of the submitted reports.\nWe have implemented the market maker's reward calculation in the form of a\nscoring rule and have shown analytically that it incentivizes truthful\nrevelation or accurate reporting by each agent. We have experimentally verified\nour technique for multi-sensor information fusion for an automated landmine\ndetection scenario. Our experimental results show that, for identical data\ndistributions and settings, using our information aggregation technique\nincreases the accuracy of object classification favorably as compared to two\nother commonly used techniques for information fusion for landmine detection.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.2207v1"
    },
    {
        "title": "The Cooperative Cleaners Problem in Stochastic Dynamic Environments",
        "authors": [
            "Eyal Regev",
            "Yaniv Altshuler",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  In this paper we study the strengths and limitations of collaborative teams\nof simple agents. In particular, we discuss the efficient use of \"ant robots\"\nfor covering a connected region on the $Z^{2}$ grid, whose area is unknown in\nadvance and which expands stochastically. Specifically, we discuss the problem\nwhere an initial connected region of $S_0$ boundary tiles expand outward with\nprobability $p$ at every time step. On this grid region a group of $k$ limited\nand simple agents operate, in order to clean the unmapped and dynamically\nexpanding region. A preliminary version of this problem was discussed in\n[1],[2] involving a deterministic expansion of a region in the grid.In this\nwork we extend the model and examine cases where the spread of the region is\ndone stochastically, where each tile has some probability $p$ to expand, at\nevery time step. For this extended model we obtain an analytic probabilistic\nlower bounds for the minimal number of agents and minimal time required to\nenable a collaborative coverage of the expanding region, regardless of the\nalgorithm used and the robots' hardware and software specifications. In\naddition, we present an impossibility result, for a variety of regions that\nwould be impossible to completely clean, regardless of the algorithm used.\nFinally, we validate the analytic bounds using extensive empirical computer\nsimulation results.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.6322v1"
    },
    {
        "title": "Foresighted Demand Side Management",
        "authors": [
            "Yuanzhang Xiao",
            "Mihaela van der Schaar"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We consider a smart grid with an independent system operator (ISO), and\ndistributed aggregators who have energy storage and purchase energy from the\nISO to serve its customers. All the entities in the system are foresighted:\neach aggregator seeks to minimize its own long-term payments for energy\npurchase and operational costs of energy storage by deciding how much energy to\nbuy from the ISO, and the ISO seeks to minimize the long-term total cost of the\nsystem (e.g. energy generation costs and the aggregators' costs) by dispatching\nthe energy production among the generators. The decision making of the entities\nis complicated for two reasons. First, the information is decentralized: the\nISO does not know the aggregators' states (i.e. their energy consumption\nrequests from customers and the amount of energy in their storage), and each\naggregator does not know the other aggregators' states or the ISO's state (i.e.\nthe energy generation costs and the status of the transmission lines). Second,\nthe coupling among the aggregators is unknown to them. Specifically, each\naggregator's energy purchase affects the price, and hence the payments of the\nother aggregators. However, none of them knows how its decision influences the\nprice because the price is determined by the ISO based on its state. We propose\na design framework in which the ISO provides each aggregator with a conjectured\nfuture price, and each aggregator distributively minimizes its own long-term\ncost based on its conjectured price as well as its local information. The\nproposed framework can achieve the social optimum despite being decentralized\nand involving complex coupling among the various entities.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.2185v1"
    },
    {
        "title": "Promises, Impositions, and other Directionals",
        "authors": [
            "Jan A. Bergstra",
            "Mark Burgess"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Promises, impositions, proposals, predictions, and suggestions are\ncategorized as voluntary co-operational methods. The class of voluntary\nco-operational methods is included in the class of so-called directionals.\nDirectionals are mechanisms supporting the mutual coordination of autonomous\nagents.\n  Notations are provided capable of expressing residual fragments of\ndirectionals. An extensive example, involving promises about the suitability of\nprograms for tasks imposed on the promisee is presented. The example\nillustrates the dynamics of promises and more specifically the corresponding\nmechanism of trust updating and credibility updating. Trust levels and\ncredibility levels then determine the way certain promises and impositions are\nhandled.\n  The ubiquity of promises and impositions is further demonstrated with two\nextensive examples involving human behaviour: an artificial example about an\nagent planning a purchase, and a realistic example describing technology\nmediated interaction concerning the solution of pay station failure related\nproblems arising for an agent intending to leave the parking area.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3381v1"
    },
    {
        "title": "A Probabilistic Approach for Maintaining Trust Based on Evidence",
        "authors": [
            "Yonghong Wang",
            "Chung-Wei Hang",
            "Munindar P. Singh"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Leading agent-based trust models address two important needs. First, they\nshow how an agent may estimate the trustworthiness of another agent based on\nprior interactions. Second, they show how agents may share their knowledge in\norder to cooperatively assess the trustworthiness of others. However, in\nreal-life settings, information relevant to trust is usually obtained\npiecemeal, not all at once. Unfortunately, the problem of maintaining trust has\ndrawn little attention. Existing approaches handle trust updates in a\nheuristic, not a principled, manner. This paper builds on a formal model that\nconsiders probability and certainty as two dimensions of trust. It proposes a\nmechanism using which an agent can update the amount of trust it places in\nother agents on an ongoing basis. This paper shows via simulation that the\nproposed approach (a) provides accurate estimates of the trustworthiness of\nagents that change behavior frequently; and (b) captures the dynamic behavior\nof the agents. This paper includes an evaluation based on a real dataset drawn\nfrom Amazon Marketplace, a leading e-commerce site.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3862v1"
    },
    {
        "title": "Intelligent Techniques for Resolving Conflicts of Knowledge in\n  Multi-Agent Decision Support Systems",
        "authors": [
            "Khaled M. Khalil",
            "M. Abdel-Aziz",
            "Taymour T. Nazmy",
            "Abdel-Badeeh M. Salem"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper focuses on some of the key intelligent techniques for conflict\nresolution in Multi-Agent Decision Support Systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4381v1"
    },
    {
        "title": "Complexity of Judgment Aggregation",
        "authors": [
            "Ulle Endriss",
            "Umberto Grandi",
            "Daniele Porello"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We analyse the computational complexity of three problems in judgment\naggregation: (1) computing a collective judgment from a profile of individual\njudgments (the winner determination problem); (2) deciding whether a given\nagent can influence the outcome of a judgment aggregation procedure in her\nfavour by reporting insincere judgments (the strategic manipulation problem);\nand (3) deciding whether a given judgment aggregation scenario is guaranteed to\nresult in a logically consistent outcome, independently from what the judgments\nsupplied by the individuals are (the problem of the safety of the agenda). We\nprovide results both for specific aggregation procedures (the quota rules, the\npremise-based procedure, and a distance-based procedure) and for classes of\naggregation procedures characterised in terms of fundamental axioms.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5863v1"
    },
    {
        "title": "Dynamic Hybrid Traffic Flow Modeling",
        "authors": [
            "Hassane Abouaïssa",
            "Yoann Kubera",
            "Gildas Morvan"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  A flow of moving agents can be observed at different scales. Thus, in traffic\nmodeling, three levels are generally considered: the micro, meso and macro\nlevels, representing respectively the interactions between vehicles, groups of\nvehicles sharing common properties (such as a common destination or a common\nlocalization) and flows of vehicles. Each approach is useful in a given\ncontext: micro and meso models allow to simulate road networks with complex\ntopologies such as urban area, while macro models allow to develop control\nstrategies to prevent congestion in highways. However, to simulate large-scale\nroad networks, it can be interesting to integrate different representations,\ne.g., micro and macro, in a single model. Existing models share the same\nlimitation: connections between levels are fixed a priori and cannot be changed\nat runtime. Therefore, to be able to observe some emerging phenomena such as\ncongestion formation or to find the exact location of a jam in a large macro\nsection, a dynamic hybrid modeling approach is needed. In 2013 we started the\ndevelopment of a multi-level agent-based simulator called JAM-FREE within the\nISART project. It allows to simulate large road networks efficiently using a\ndynamic level of detail. This simulator relies on a multi-level agent-based\nmodeling framework called SIMILAR.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.6773v1"
    },
    {
        "title": "Heterogeneous Speed Profiles in Discrete Models for Pedestrian\n  Simulation",
        "authors": [
            "Stefania Bandini",
            "Luca Crociani",
            "Giuseppe Vizzari"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Discrete pedestrian simulation models are viable alternatives to particle\nbased approaches based on a continuous spatial representation. The effects of\ndiscretisation, however, also imply some difficulties in modelling certain\nphenomena that can be observed in reality. This paper focuses on the\npossibility to manage heterogeneity in the walking speed of the simulated\npopulation of pedestrians by modifying an existing multi-agent model extending\nthe floor field approach. Whereas some discrete models allow pedestrians (or\ncars, when applied to traffic modelling) to move more than a single cell per\ntime step, the present work proposes a maximum speed of one cell per step, but\nwe model lower speeds by having pedestrians yielding their movement in some\nturns. Different classes of pedestrians are associated to different desired\nwalking speeds and we define a stochastic mechanism ensuring that they maintain\nan average speed close to this threshold. In the paper we formally describe the\nmodel and we show the results of its application in benchmark scenarios.\nFinally, we also show how this approach can also support the definition of\nslopes and stairs as elements reducing the walking speed of pedestrians\nclimbing them in a simulated scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.8132v1"
    },
    {
        "title": "Changing minds about electric cars: An empirically grounded agent-based\n  modeling approach",
        "authors": [
            "Ingo Wolf",
            "Tobias Schroeder",
            "Jochen Neumann",
            "Gerhard de Haan"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The diffusion of electric vehicles (EVs) is considered an effective policy\nstrategy to meet greenhouse gas reduction targets. For large-scale adoption,\nhowever, demand-side oriented policy measures are required, based on consumers\ntransport needs, values and social norms. We introduce an empirically grounded,\nspatially explicit, agent-based model, InnoMind Innovation diffusion driven by\nchanging Minds), to simulate the effects of policy interventions and social\ninfluence on consumers transport mode preferences. The agents in this model\nrepresent individual consumers. They are calibrated based on empirically\nderived attributes and characteristics of survey respondents. We model agent\ndecision-making with artificial neural networks that account for the role of\nemotions in information processing. We present simulations of 4 scenarios for\nthe diffusion of EVs in the city of Berlin, Germany (3 policy scenarios and 1\nbase case). The results illustrate the varying effectiveness of measures in\ndifferent market segments and the need for appropriate policies tailored to the\nheterogeneous needs of different travelers. Moreover, the simulations suggest\nthat introducing an exclusive zone for EVs in the city would accelerate the\nearly-phase diffusion of EVs more effectively than financial incentives only.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6230v2"
    },
    {
        "title": "Négociation de spectre dans les réseaux de radio cognitive",
        "authors": [
            "Ibtissam Larbi",
            "Badr Benmammar"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In this report, we propose a technique using negotiation based on multi-agent\nsystem (MAS) in the context of cognitive radio network (CRN). The agents are\nparticularly suited to provide responsive solutions to complex problems such as\nthe negotiation of the spectrum in CRN. We have implemented our proposed\nsolution with JADE (Java Agent Development Framework) and we have also evaluate\nthe proposed solution to show its interest.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2217v1"
    },
    {
        "title": "Evaluation of a Conversation Management Toolkit for Multi Agent\n  Programming",
        "authors": [
            "David Lillis",
            "Rem W. Collier",
            "Howell R. Jordan"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The Agent Conversation Reasoning Engine (ACRE) is intended to aid agent\ndevelopers to improve the management and reliability of agent communication. To\nevaluate its effectiveness, a problem scenario was created that could be used\nto compare code written with and without the use of ACRE by groups of test\nsubjects.\n  This paper describes the requirements that the evaluation scenario was\nintended to meet and how these motivated the design of the problem. Two\nexperiments were conducted with two separate sets of students and their\nsolutions were analysed using a combination of simple objective metrics and\nsubjective analysis. The analysis suggested that ACRE by default prevents some\ncommon problems arising that would limit the reliability and extensibility of\nconversation-handling code.\n  As ACRE has to date been integrated only with the Agent Factory multi agent\nframework, it was necessary to verify that the problems identified are not\nunique to that platform. Thus a comparison was made with best practice\ncommunication code written for the Jason platform, in order to demonstrate the\nwider applicability of a system such as ACRE.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.2632v1"
    },
    {
        "title": "DISARM: A Social Distributed Agent Reputation Model based on Defeasible\n  Logic",
        "authors": [
            "Kalliopi Kravari",
            "Nick Bassiliades"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Intelligent Agents act in open and thus risky environments, hence making the\nappropriate decision about who to trust in order to interact with, could be a\nchallenging process. As intelligent agents are gradually enriched with Semantic\nWeb technology, acting on behalf of their users with limited or no human\nintervention, their ability to perform assigned tasks is scrutinized. Hence,\ntrust and reputation models, based on interaction trust or witness reputation,\nhave been proposed, yet they often presuppose the use of a centralized\nauthority. Although such mechanisms are more popular, they are usually faced\nwith skepticism, since users may question the trustworthiness and the\nrobustness of a central authority. Distributed models, on the other hand, are\nmore complex but they provide personalized estimations based on each agent's\ninterests and preferences. To this end, this article proposes DISARM, a novel\ndistributed reputation model. DISARM deals MASs as social networks, enabling\nagents to establish and maintain relationships, limiting the disadvantages of\nthe common distributed approaches. Additionally, it is based on defeasible\nlogic, modeling the way intelligent agents, like humans, draw reasonable\nconclusions from incomplete and possibly conflicting (thus inconclusive)\ninformation. Finally, we provide an evaluation that illustrates the usability\nof the proposed model.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.3334v1"
    },
    {
        "title": "Coalition Structure Generation on Graphs",
        "authors": [
            "Talal Rahwan",
            "Tomasz P. Michalak"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Two fundamental algorithm-design paradigms are Tree Search and Dynamic\nProgramming. The techniques used therein have been shown to complement one\nanother when solving the complete set partitioning problem, also known as the\ncoalition structure generation problem [5]. Inspired by this observation, we\ndevelop in this paper an algorithm to solve the coalition structure generation\nproblem on graphs, where the goal is to identifying an optimal partition of a\ngraph into connected subgraphs. More specifically, we develop a new depth-first\nsearch algorithm, and combine it with an existing dynamic programming algorithm\ndue to Vinyals et al. [9]. The resulting hybrid algorithm is empirically shown\nto significantly outperform both its constituent parts when the\nsubset-evaluation function happens to have certain intuitive properties.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.6516v2"
    },
    {
        "title": "Are Effective Leaders Creative?",
        "authors": [
            "Liane Gabora"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper explains in layperson's terms how an agent-based model was used to\ninvestigate the widely held belief that creativity is an important component of\neffective leadership. Creative leadership was found to increase the mean\nfitness of cultural outputs across an artificial society, but the more creative\nthe followers were, the greater the extent to which the beneficial effect of\ncreative leadership was washed out. Early in a run when the fitness of ideas\nwas low, a form of leadership that entails the highest possible degree of\ncreativity was best for the mean fitness of outputs across the society. As the\nmean fitness of outputs increased a transition inevitably occurs after which\npoint a less creative style of leadership proved most effective. Implications\nof these findings are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.06009v2"
    },
    {
        "title": "Efficient and Flexible Crowdsourcing of Specialized Tasks with\n  Precedence Constraints",
        "authors": [
            "Avhishek Chatterjee",
            "Michael Borokhovich",
            "Lav R. Varshney",
            "Sriram Vishwanath"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Many companies now use crowdsourcing to leverage external (as well as\ninternal) crowds to perform specialized work, and so methods of improving\nefficiency are critical. Tasks in crowdsourcing systems with specialized work\nhave multiple steps and each step requires multiple skills. Steps may have\ndifferent flexibilities in terms of obtaining service from one or multiple\nagents, due to varying levels of dependency among parts of steps. Steps of a\ntask may have precedence constraints among them. Moreover, there are variations\nin loads of different types of tasks requiring different skill-sets and\navailabilities of different types of agents with different skill-sets.\nConsidering these constraints together necessitates the design of novel schemes\nto allocate steps to agents. In addition, large crowdsourcing systems require\nallocation schemes that are simple, fast, decentralized and offer customers\n(task requesters) the freedom to choose agents. In this work we study the\nperformance limits of such crowdsourcing systems and propose efficient\nallocation schemes that provably meet the performance limits under these\nadditional requirements. We demonstrate our algorithms on data from a\ncrowdsourcing platform run by a non-profit company and show significant\nimprovements over current practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.04094v1"
    },
    {
        "title": "Multi-agent System Design for Dummies",
        "authors": [
            "Siyao Li"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Agent technology, a new paradigm in software engineering, has received\nattention from research and industry since 1990s. However, it is still not used\nwidely to date because it requires expertise on both programming and agent\ntechnology; gaps among requirements, agent design, and agent deployment also\npose more difficulties. Goal Net methodology attempts to solve these issues\nwith a goal-oriented approach that resembles human behaviours, and an agent\ndesigner that supports agent development using this philosophy. However, there\nare limitations on existing Goal Net Designer, the design and modelling\ncomponent of the agent designer. Those limitations, including limited access,\ndifficult deployment, inflexibility in user operations, design workflows\nagainst typical Goal Net methodology workflows, and lack of data protection,\nhave inhibited widespread adoption of Goal Net methodology.\n  Motivated by this, this book focuses on improvements on Goal Net Designer. In\nthis project, Goal Net Designer is completely re-implemented using new\ntechnology with optimised software architecture and design. It allows access\nfrom all major desktop operating systems, as well as in web environment via all\nmodern browsers. Enhancements such as refined workflows, model validation tool,\naccess control, team collaboration tool, and link to compiler make Goal Net\nDesigner a fully functional and powerful Integrated Development Environment.\nUser friendliness and usability are greatly enhanced by simplifying user's\nactions to accomplish their tasks. User behaviour logging and quantitative\nfeedback channel are also included to allow Goal Net Designer to continuously\nevolve with the power of big data analytics in future. To evaluate the new Goal\nNet Designer, a teachable agent has been developed with the help of Goal Net\nDesigner and the development process is illustrated in a case study.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.06244v1"
    },
    {
        "title": "JADE, TraSMAPI and SUMO: A tool-chain for simulating traffic light\n  control",
        "authors": [
            "Tiago Azevedo",
            "Paulo J. M. de Araújo",
            "Rosaldo J. F. Rossetti",
            "Ana Paula C. Rocha"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Increased stress, fuel consumption, air pollution, accidents and delays are\nsome of the consequences of traffic congestion usually incurring in tremendous\neconomic impacts, which society aims to remedy in order to leverage a\nsustainable development. Recently, unconventional means for modeling and\ncontrolling such complex traffic systems relying on multi-agent systems have\narisen. This paper contributes to the understanding of such complex and highly\ndynamic systems by proposing an open-source tool-chain to implement\nmulti-agent-based solutions in traffic and transportation. The proposed\napproach relies on two very popular tools in both domains, with focus on\ntraffic light control. This tool-chain consists in combining JADE (Java Agent\nDEvelopment Framework), for the implementation of multi-agent systems, with\nSUMO (Simulation of Urban MObility), for the microscopic simulation of traffic\ninteractions. TraSMAPI (Traffic Simulation Manager Application Programming\nInterface) is used to combine JADE and SUMO allowing communication between\nthem. A demonstration of the concept is presented to illustrate the main\nfeatures of this tool-chain, using Q-Learning as the reinforcement learning\nmethod for each traffic light agent in a simulated network. Results demonstrate\nthe feasibility of the proposed framework as a practical means to experiment\nwith different agent-based designs of intelligent transportation solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.08154v1"
    },
    {
        "title": "Routing Autonomous Vehicles in Congested Transportation Networks:\n  Structural Properties and Coordination Algorithms",
        "authors": [
            "Rick Zhang",
            "Federico Rossi",
            "Marco Pavone"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This paper considers the problem of routing and rebalancing a shared fleet of\nautonomous (i.e., self-driving) vehicles providing on-demand mobility within a\ncapacitated transportation network, where congestion might disrupt throughput.\nWe model the problem within a network flow framework and show that under\nrelatively mild assumptions the rebalancing vehicles, if properly coordinated,\ndo not lead to an increase in congestion (in stark contrast to common belief).\nFrom an algorithmic standpoint, such theoretical insight suggests that the\nproblem of routing customers and rebalancing vehicles can be decoupled, which\nleads to a computationally-efficient routing and rebalancing algorithm for the\nautonomous vehicles. Numerical experiments and case studies corroborate our\ntheoretical insights and show that the proposed algorithm outperforms\nstate-of-the-art point-to-point methods by avoiding excess congestion on the\nroad. Collectively, this paper provides a rigorous approach to the problem of\ncongestion-aware, system-wide coordination of autonomously driving vehicles,\nand to the characterization of the sustainability of such robotic systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.00939v2"
    },
    {
        "title": "Simulation Platform for Multi Agent Based Manufacturing Control System\n  Based on The Hybrid Agent",
        "authors": [
            "Ali Vatankhah barenji",
            "Amir Shaygan",
            "Reza Vatankhah Barenji"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Agent based distributed manufacturing control and scheduling systems are\nsubsets of new manufacturing systems. Multi agent systems (MAS) not only drive\ndesign and engineering control solutions but also influence flexibility,\nagility, and re-configurability, which makes MASs a better centralized systems\nthan its traditional counterparts. However, implementation of all MASs in the\nreal factories are timely, also extremely costly. A simulation environment that\nwould allow independent development and testing of the services and business\nprocesses of the related manufacturing hardware is needed. This paper presents\nthe design and implementation of a userfriendly simulation platform for multi\nagent based manufacturing control systems by considering the shop floor level.\nThe proposed simulation platform can simulate the software level of the factory\nby considering the hardware level of the mentioned factory. An example of the\nsimulation platform is presented for a flexible manufacturing system, which is\nlocated in EMU CIM lab.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.07766v1"
    },
    {
        "title": "A computational intuition pump to examine group creativity: building on\n  the ideas of others",
        "authors": [
            "Ricardo Sosa",
            "Andy M. Connor"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This paper presents a computational approach to modelling group creativity.\nIt presents an analysis of two studies of group creativity selected from\ndifferent research cultures and identifies a common theme (\"idea build-up\")\nthat is then used in the formalisation of an agent-based model used to support\nreasoning about the complex dynamics of building on the ideas of others.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.01853v1"
    },
    {
        "title": "Group decision makers making process - an analytic hierarchy approach",
        "authors": [
            "Marian Dragoi",
            "Ciprian Palaghianu"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  The paper deals with a step-wise analytic hierarchy process (AHP) applied by\na group of decision makers wherein nobody has a dominant position and it is\nunlikely to come to terms with respect to either the weights of different\nobjectives or expected utilities of different alternatives. One of the AHP\noutcomes, that is the consistency index is computed for each decision maker,\nfor all other decision makers but that one, and for the whole group. Doing so,\nthe group is able to assess to which extent each decision maker alters the\ngroup consistency index and a better consistency index could be achieved if the\nassessment procedure is being resumed by the most influential decision maker in\nterms of consistency. The main contribution of the new approach is the\nalgorithm presented in as a flow chart where the condition to stop the process\nmight be either a threshold value for the consistency index, or a given number\nof iterations for the group or decision maker, depending on the degree to which\nthe targeted goal has been decomposed into conflictual objectives.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.02445v1"
    },
    {
        "title": "Variational Inference with Agent-Based Models",
        "authors": [
            "Wen Dong"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  In this paper, we develop a variational method to track and make predictions\nabout a real-world system from continuous imperfect observations about this\nsystem, using an agent-based model that describes the system dynamics. By\ncombining the power of big data with the power of model-thinking in the\nstochastic process framework, we can make many valuable predictions. We show\nhow to track the spread of an epidemic at the individual level and how to make\nshort-term predictions about traffic congestion. This method points to a new\nway to bring together modelers and data miners by turning the real world into a\nliving lab.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.04360v1"
    },
    {
        "title": "Precious Time: Understanding Social Stratification in the Knowledge\n  Society Through Time Allocation",
        "authors": [
            "Michal Kakol",
            "Radoslaw Nielek",
            "Adam Wierzbicki"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The efficient use of available resources is a key factor in achieving success\non both personal and organizational levels. One of the crucial resources in\nknowledge economy is time. The ability to force others to adapt to our schedule\neven if it harms their efficiency can be seen as an outcome of social\nstratification. The principal objective of this paper is to use time allocation\nto model and study the global efficiency of social stratification, and to\nreveal whether hierarchy is an emergent property. A multi-agent model with an\nevolving social network is used to verify our hypotheses. The network's\nevolution is driven by the intensity of inter-agent communications, and the\ncommunications as such depend on the preferences and time resources of the\ncommunicating agents. The entire system is to be perceived as a metaphor of a\nsocial network of people regularly filling out agenda for their meetings for a\nperiod of time. The overall efficiency of the network of those scheduling\nagents is measured by the average utilization of the agent's preferences to\nspeak on specific subjects. The simulation results shed light on the effects of\ndifferent scheduling methods, resource availabilities, and network evolution\nmechanisms on communication system efficiency. The non-stratified systems show\nbetter long-term efficiency. Moreover, in the long term hierarchy disappears in\noverwhelming majority of cases. Some exceptions are observed for cases where\nprivileges are granted on the basis of node degree weighted by relationship\nintensities but only in the short term.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.00968v1"
    },
    {
        "title": "Multi-Robot Data Gathering Under Buffer Constraints and Intermittent\n  Communication",
        "authors": [
            "Meng Guo",
            "Michael M. Zavlanos"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We consider a team of heterogeneous robots which are deployed within a common\nworkspace to gather different types of data. The robots have different roles\ndue to different capabilities: some gather data from the workspace (source\nrobots) and others receive data from source robots and upload them to a data\ncenter (relay robots). The data-gathering tasks are specified locally to each\nsource robot as high-level Linear Temporal Logic (LTL) formulas, that capture\nthe different types of data that need to be gathered at different regions of\ninterest. All robots have a limited buffer to store the data. Thus the data\ngathered by source robots should be transferred to relay robots before their\nbuffers overflow, respecting at the same time limited communication range for\nall robots. The main contribution of this work is a distributed motion\ncoordination and intermittent communication scheme that guarantees the\nsatisfaction of all local tasks, while obeying the above constraints. The robot\nmotion and inter-robot communication are closely coupled and coordinated during\nrun time by scheduling intermittent meeting events to facilitate the local plan\nexecution. We present both numerical simulations and experimental studies to\ndemonstrate the advantages of the proposed method over existing approaches that\npredominantly require all-time network connectivity.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.02092v2"
    },
    {
        "title": "RoboCup 2D Soccer Simulation League: Evaluation Challenges",
        "authors": [
            "Mikhail Prokopenko",
            "Peter Wang",
            "Sebastian Marian",
            "Aijun Bai",
            "Xiao Li",
            "Xiaoping Chen"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We summarise the results of RoboCup 2D Soccer Simulation League in 2016\n(Leipzig), including the main competition and the evaluation round. The\nevaluation round held in Leipzig confirmed the strength of RoboCup-2015\nchampion (WrightEagle, i.e. WE2015) in the League, with only eventual finalists\nof 2016 competition capable of defeating WE2015. An extended, post-Leipzig,\nround-robin tournament which included the top 8 teams of 2016, as well as\nWE2015, with over 1000 games played for each pair, placed WE2015 third behind\nthe champion team (Gliders2016) and the runner-up (HELIOS2016). This\nestablishes WE2015 as a stable benchmark for the 2D Simulation League. We then\ncontrast two ranking methods and suggest two options for future evaluation\nchallenges. The first one, \"The Champions Simulation League\", is proposed to\ninclude 6 previous champions, directly competing against each other in a\nround-robin tournament, with the view to systematically trace the advancements\nin the League. The second proposal, \"The Global Challenge\", is aimed to\nincrease the realism of the environmental conditions during the simulated\ngames, by simulating specific features of different participating countries.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.04315v1"
    },
    {
        "title": "From traffic conflict simulation to traffic crash simulation:\n  introducing traffic safety indicators based on the explicit simulation of\n  potential driver errors",
        "authors": [
            "Vittorio Astarita",
            "Vincenzo Pasquale Giofré"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper introduces a general simulation framework that can allow the\nsimulation of crashes and the evaluation of consequences on existing\nmicrosimulation packages. A specific family of simple and reproducible conflict\nindicators is proposed and applied to many case studies. In this approach\ndriver failures are simulated by assuming that a driver stops reacting to an\nexternal stimulus and keeps driving at the current speed for a given time. The\ntrajectory of the distracted driver vehicle is thus evaluated and projected,\nfor the given time steps, for the established distraction time, over the actual\ntrajectories of other vehicles. Every occurring crash is then evaluated in\nterms of energy involved in the crash, or with any other severity index (which\ncan be easily calculated since the accident dynamics can be accurately\nsimulated). The simulation of a driver error allows not only the typology of\ncrashes to be included, normally accounted for with surrogate safety measures,\nbut also many other type of typical crashes that it is impossible to simulate\nwith microsimulation and traditional methodologies being caused by vehicles who\nare driving on non-conflicting trajectories such as drivers speeding at a red\nlight, drivers taking the wrong lane or side of the street or just driving off\nthe road in isolated accidents against external obstacles or traffic barriers.\nThe total crash energy of all crashes is proposed as an indicator of risk and\nadopted in the case studies. Moreover, the concepts introduced in this paper\nallow scientists to define other relevant variables that can be used as\nsurrogate safety indicators that consider driving errors. Preliminary results\non different case studies have shown a great accordance of safety evaluations\nwith statistical data and empirical expectations and also with other\ntraditional safety indicators that are commonly used in microsimulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.01878v1"
    },
    {
        "title": "Memetic Algorithm-Based Path Generation for Multiple Dubins Vehicles\n  Performing Remote Tasks",
        "authors": [
            "Doo-Hyun Cho",
            "Han-Lim Choi"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper formalizes path planning problem for a group of heterogeneous\nDubins vehicles performing tasks in a remote fashion and develops a memetic\nalgorithm-based method to effectively produce the paths. In the setting, the\nvehicles are initially located at multiple depots in a two-dimensional space\nand the objective of planning is to minimize a weighted sum of the total tour\ncost of the group and the largest individual tour cost amongst the vehicles.\nWhile the presented formulation takes the form of a mixed-integer linear\nprogram (MILP) for which off-the-shelf solvers are available, the MILP solver\neasily loses the tractability as the number of tasks and agents grow.\nTherefore, a memetic algorithm tailored to the presented formulation is\nproposed. The algorithm features a sophisticated encoding scheme to\nefficiently. In addition, a path refinement technique that optimizes on the\ndetailed tours with the sequence of visits fixed is proposed to finally obtain\nfurther optimized trajectories. Comparative numerical experiments show the\nvalidity and efficiency of the proposed methods compared with the previous\nmethods in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.02720v1"
    },
    {
        "title": "NL4Py: Agent-Based Modeling in Python with Parallelizable NetLogo\n  Workspaces",
        "authors": [
            "Chathika Gunaratne",
            "Ivan Garibay"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  External control of agent-based models is vital for complex adaptive systems\nresearch. Often these experiments require vast numbers of simulation runs and\nare computationally expensive. NetLogo is the language of choice for most\nagent-based modelers but lacks direct API access through Python. NL4Py is a\nPython package for the parallel execution of NetLogo simulations via Python,\ndesigned for speed, scalability, and simplicity of use. NL4Py provides access\nto the large number of open-source machine learning and analytics libraries of\nPython and enables convenient and efficient parallelization of NetLogo\nsimulations with minimal coding expertise by domain scientists.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.03292v5"
    },
    {
        "title": "AMoDSim: An Efficient and Modular Simulation Framework for Autonomous\n  Mobility on Demand",
        "authors": [
            "Andrea Di Maria",
            "Andrea Araldo",
            "Giovanni Morana",
            "Antonella Di Stefano"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Urban transportation of next decade is expected to be disrupted by Autonomous\nMobility on Demand (AMoD): AMoD providers will collect ride requests from users\nand will dispatch a fleet of autonomous vehicles to satisfy requests in the\nmost efficient way. Differently from current ride sharing systems, in which\ndriver behavior has a clear impact on the system, AMoD systems will be\nexclusively determined by the dispatching logic. As a consequence, a recent\ninterest in the Operations Research and Computer Science communities has\nfocused on this control logic. The new propositions and methodologies are\ngenerally evaluated via simulation. Unfortunately, there is no simulation\nplatform that has emerged as reference, with the consequence that each author\nuses her own custom-made simulator, applicable only in her specific study, with\nno aim of generalization and without public release. This slows down the\nprogress in the area as researchers cannot build on each other's work and\ncannot share, reproduce and verify the results. The goal of this paper is to\npresent AMoDSim, an open-source simulation platform aimed to fill this gap and\naccelerate research in future ride sharing systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.04813v2"
    },
    {
        "title": "A Communication Protocol for Man-Machine Networks",
        "authors": [
            "Neda Hajiakhoond",
            "Gita Sukthankar"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  One of the most challenging coordination problems in artificial intelligence\nis to achieve successful collaboration across large-scale heterogeneous systems\nthat include Robots, Agents, and People (RAP). In the best case, these RAP\nsystems are potentially capable of leveraging the strengths of the individual\nentities to achieve complex distributed tasks. However, without intelligent\ncommunication protocols, man-machine partnerships are likely to fail as the\nhumans become overloaded with irrelevant information. This paper introduces a\ncommunication protocol for man machine systems and demonstrates that its\nmessage routing performance approaches the central optimized solution in a\nsimulated smart environment scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.07975v1"
    },
    {
        "title": "Factorized Q-Learning for Large-Scale Multi-Agent Systems",
        "authors": [
            "Ming Zhou",
            "Yong Chen",
            "Ying Wen",
            "Yaodong Yang",
            "Yufeng Su",
            "Weinan Zhang",
            "Dell Zhang",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Deep Q-learning has achieved significant success in single-agent decision\nmaking tasks. However, it is challenging to extend Q-learning to large-scale\nmulti-agent scenarios, due to the explosion of action space resulting from the\ncomplex dynamics between the environment and the agents. In this paper, we\npropose to make the computation of multi-agent Q-learning tractable by treating\nthe Q-function (w.r.t. state and joint-action) as a high-order high-dimensional\ntensor and then approximate it with factorized pairwise interactions.\nFurthermore, we utilize a composite deep neural network architecture for\ncomputing the factorized Q-function, share the model parameters among all the\nagents within the same group, and estimate the agents' optimal joint actions\nthrough a coordinate descent type algorithm. All these simplifications greatly\nreduce the model complexity and accelerate the learning process. Extensive\nexperiments on two different multi-agent problems demonstrate the performance\ngain of our proposed approach in comparison with strong baselines, particularly\nwhen there are a large number of agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.03738v4"
    },
    {
        "title": "Towards Efficient Detection and Optimal Response against Sophisticated\n  Opponents",
        "authors": [
            "Tianpei Yang",
            "Zhaopeng Meng",
            "Jianye Hao",
            "Chongjie Zhang",
            "Yan Zheng",
            "Ze Zheng"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Multiagent algorithms often aim to accurately predict the behaviors of other\nagents and find a best response accordingly. Previous works usually assume an\nopponent uses a stationary strategy or randomly switches among several\nstationary ones. However, an opponent may exhibit more sophisticated behaviors\nby adopting more advanced reasoning strategies, e.g., using a Bayesian\nreasoning strategy. This paper proposes a novel approach called Bayes-ToMoP\nwhich can efficiently detect the strategy of opponents using either stationary\nor higher-level reasoning strategies. Bayes-ToMoP also supports the detection\nof previously unseen policies and learning a best-response policy accordingly.\nWe provide a theoretical guarantee of the optimality on detecting the\nopponent's strategies. We also propose a deep version of Bayes-ToMoP by\nextending Bayes-ToMoP with DRL techniques. Experimental results show both\nBayes-ToMoP and deep Bayes-ToMoP outperform the state-of-the-art approaches\nwhen faced with different types of opponents in two-agent competitive games.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.04240v5"
    },
    {
        "title": "Emergence of Scenario-Appropriate Collaborative Behaviors for Teams of\n  Robotic Bodyguards",
        "authors": [
            "Hassam Ullah Sheikh",
            "Ladislau Boloni"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We are considering the problem of controlling a team of robotic bodyguards\nprotecting a VIP from physical assault in the presence of neutral and/or\nadversarial bystanders. This task is part of a much larger class of problems\ninvolving coordinated robot behavior in the presence of humans. This problem is\nchallenging due to the large number of active entities with different agendas,\nthe need of cooperation between the robots as well as the requirement to take\ninto consideration criteria such as social norms and unobtrusiveness in\naddition to the main goal of VIP safety. Furthermore, different settings such\nas street, public space or red carpet require very different behavior from the\nrobot. We describe how a multi-agent reinforcement learning approach can evolve\nbehavior policies for teams of robot bodyguards that compare well with\nhand-engineered approaches. Furthermore, we show that an algorithm inspired by\nuniversal value function approximators can learn policies that exhibit\nappropriate, distinct behavior in environments with different requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.04500v3"
    },
    {
        "title": "Distributed and Efficient Resource Balancing Among Many Suppliers and\n  Consumers",
        "authors": [
            "Kamal Chaturvedi",
            "Jia Yuan Yu",
            "Shrisha Rao"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Achieving a balance of supply and demand in a multi-agent system with many\nindividual self-interested and rational agents that act as suppliers and\nconsumers is a natural problem in a variety of real-life domains---smart power\ngrids, data centers, and others. In this paper, we address the\nprofit-maximization problem for a group of distributed supplier and consumer\nagents, with no inter-agent communication. We simulate a scenario of a market\nwith $S$ suppliers and $C$ consumers such that at every instant, each supplier\nagent supplies a certain quantity and simultaneously, each consumer agent\nconsumes a certain quantity. The information about the total amount supplied\nand consumed is only kept with the center. The proposed algorithm is a\ncombination of the classical additive-increase multiplicative-decrease (AIMD)\nalgorithm in conjunction with a probabilistic rule for the agents to respond to\na capacity signal. This leads to a nonhomogeneous Markov chain and we show\nalmost sure convergence of this chain to the social optimum, for our market of\ndistributed supplier and consumer agents. Employing this AIMD-type algorithm,\nthe center sends a feedback message to the agents in the supplier side if there\nis a scenario of excess supply, or to the consumer agents if there is excess\nconsumption. Each agent has a concave utility function whose derivative tends\nto 0 when an optimum quantity is supplied/consumed. Hence when social\nconvergence is reached, each agent supplies or consumes a quantity which leads\nto its individual maximum profit, without the need of any communication. So\neventually, each agent supplies or consumes a quantity which leads to its\nindividual maximum profit, without communicating with any other agents. Our\nsimulations show the efficacy of this approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.05245v1"
    },
    {
        "title": "Erratic Extremism causes Dynamic Consensus (a new model for\n  one-dimensional opinion dynamics)",
        "authors": [
            "Dmitry Rabinovich",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  A society of agents, with ideological positions, or \"opinions\" measured by\nreal values ranging from $-\\infty$ (the \"far left\") to $+\\infty$ (the \"far\nright\"), is considered. At fixed (unit) time intervals agents repeatedly\nreconsider and change their opinions if and only if they find themselves at the\nextremes of the range of ideological positions held by members of the society.\nExtremist agents are erratic: they become either more radical, and move away\nfrom the positions of other agents, with probability $\\varepsilon$, or more\nmoderate, and move towards the positions held by peers, with probability $(1 -\n\\varepsilon)$. The change in the opinion of the extremists is one unit on the\nreal line. We prove that the agent positions cluster in time, with all\nnon-extremist agents located within a unit interval. However, the consensus\nopinion is dynamic. Due to the extremists' erratic behavior the clustered\nopinion set performs a \"sluggish\" random walk on the entire range of possible\nideological positions (the real line). The inertia of the group, the reluctance\nof the society's agents to change their consensus opinion, increases with the\nsize of the group. The extremists perform biased random walk excursions to the\nright and left and, in time, their actions succeed to move the society of\nagents in random directions. The \"far left\" agent effectively pushes the group\nconsensus toward the right, while the \"far right\" agent counter-balances the\npush and causes the consensus to move toward the left.\n  We believe that this model, and some of its variations, has the potential to\nexplain the real world swings in societal ideologies that we see around us.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06049v3"
    },
    {
        "title": "Pommerman: A Multi-Agent Playground",
        "authors": [
            "Cinjon Resnick",
            "Wes Eldridge",
            "David Ha",
            "Denny Britz",
            "Jakob Foerster",
            "Julian Togelius",
            "Kyunghyun Cho",
            "Joan Bruna"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We present Pommerman, a multi-agent environment based on the classic console\ngame Bomberman. Pommerman consists of a set of scenarios, each having at least\nfour players and containing both cooperative and competitive aspects. We\nbelieve that success in Pommerman will require a diverse set of tools and\nmethods, including planning, opponent/teammate modeling, game theory, and\ncommunication, and consequently can serve well as a multi-agent benchmark. To\ndate, we have already hosted one competition, and our next one will be featured\nin the NIPS 2018 competition track.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07124v2"
    },
    {
        "title": "Deterministic limit of temporal difference reinforcement learning for\n  stochastic games",
        "authors": [
            "Wolfram Barfuss",
            "Jonathan F. Donges",
            "Jürgen Kurths"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Reinforcement learning in multiagent systems has been studied in the fields\nof economic game theory, artificial intelligence and statistical physics by\ndeveloping an analytical understanding of the learning dynamics (often in\nrelation to the replicator dynamics of evolutionary game theory). However, the\nmajority of these analytical studies focuses on repeated normal form games,\nwhich only have a single environmental state. Environmental dynamics, i.e.,\nchanges in the state of an environment affecting the agents' payoffs has\nreceived less attention, lacking a universal method to obtain deterministic\nequations from established multistate reinforcement learning algorithms.\n  In this work we present a novel methodological extension, separating the\ninteraction from the adaptation time scale, to derive the deterministic limit\nof a general class of reinforcement learning algorithms, called temporal\ndifference learning. This form of learning is equipped to function in more\nrealistic multistate environments by using the estimated value of future\nenvironmental states to adapt the agent's behavior. We demonstrate the\npotential of our method with the three well established learning algorithms Q\nlearning, SARSA learning and Actor-Critic learning. Illustrations of their\ndynamics on two multiagent, multistate environments reveal a wide range of\ndifferent dynamical regimes, such as convergence to fixed points, limit cycles,\nand even deterministic chaos.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07225v2"
    },
    {
        "title": "A Novel Warehouse Multi-Robot Automation System with Semi-Complete and\n  Computationally Efficient Path Planning and Adaptive Genetic Task Allocation\n  Algorithms",
        "authors": [
            "Kam Fai Elvis Tsang",
            "Yuqing Ni",
            "Cheuk Fung Raphael Wong",
            "Ling Shi"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We consider the problem of warehouse multi-robot automation system in\ndiscrete-time and discrete-space configuration with focus on the task\nallocation and conflict-free path planning. We present a system design where a\ncentralized server handles the task allocation and each robot performs local\npath planning distributively. A genetic-based task allocation algorithm is\nfirstly presented, with modification to enable heuristic learning. A\nsemi-complete potential field based local path planning algorithm is then\nproposed, named the recursive excitation/relaxation artificial potential field\n(RERAPF). A mathematical proof is also presented to show the semi-completeness\nof the RERAPF algorithm. The main contribution of this paper is the\nmodification of conventional artificial potential field (APF) to be\nsemi-complete while computationally efficient, resolving the traditional issue\nof incompleteness. Simulation results are also presented for performance\nevaluation of the proposed path planning algorithm and the overall system.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07262v2"
    },
    {
        "title": "Improved Bounds on Information Dissemination by Manhattan Random\n  Waypoint Model",
        "authors": [
            "Aria Rezaei",
            "Jie Gao",
            "Jeff M. Phillips",
            "Csaba D. Tóth"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  With the popularity of portable wireless devices it is important to model and\npredict how information or contagions spread by natural human mobility -- for\nunderstanding the spreading of deadly infectious diseases and for improving\ndelay tolerant communication schemes. Formally, we model this problem by\nconsidering $M$ moving agents, where each agent initially carries a\n\\emph{distinct} bit of information. When two agents are at the same location or\nin close proximity to one another, they share all their information with each\nother. We would like to know the time it takes until all bits of information\nreach all agents, called the \\textit{flood time}, and how it depends on the way\nagents move, the size and shape of the network and the number of agents moving\nin the network.\n  We provide rigorous analysis for the \\MRWP model (which takes paths with\nminimum number of turns), a convenient model used previously to analyze mobile\nagents, and find that with high probability the flood time is bounded by\n$O\\big(N\\log M\\lceil(N/M) \\log(NM)\\rceil\\big)$, where $M$ agents move on an\n$N\\times N$ grid. In addition to extensive simulations, we use a data set of\ntaxi trajectories to show that our method can successfully predict flood times\nin both experimental settings and the real world.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07392v1"
    },
    {
        "title": "Supply Chain Management analysis: a simulation approach of the Value\n  Chain Operations Reference model (VCOR)",
        "authors": [
            "Yacine Ouzrout",
            "Matteo Savino",
            "Abdelaziz Bouras",
            "Carlo Di Domenico"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The impact of globalization and worldwide competition has forced firms to\nmodify their strategies towards a real time operation with respect to\ncustomer's requirements. This behaviour, together with the communication\npossibilities offered by the actual Information and Communication Technologies,\nallows the top management to move towards the concept of extended enterprise in\nwhich a collaborative link is established among suppliers, commercial partners\nand customers. When the information flows involve each actor of the chain, from\nsuppliers to the final distribution centers, the extended enterprise becomes a\nvirtual firm, that can be defined as a set of stand-alone operational units\nthat acts to reconfigure themselves as a value chain in order to adapt to the\nbusiness opportunities given by the market. The present work is intended to\nverify through a simulation approach the quantitative advantages that can be\nobtained by the introduction of the Value Chain concept into the Supply Chain\nManagement (SCM). The paper, after a description of the two most known (SCM)\nmethods - SCOR and VCOR - makes a comparison between them by the customer's\npoint of view. In the second part of the work a simulation model has been\ndeveloped to verify the advantage that the VCOR is able to obtain, validating\nit on an industrial case study.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01683v1"
    },
    {
        "title": "Collaboration and integration through information technologies in supply\n  chains",
        "authors": [
            "Gilles Neubert",
            "Yacine Ouzrout",
            "Abdelaziz Bouras"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Supply chain management encompasses various processes including various\nconventional logistics activities, and various other processes These processes\nare supported -- to a certain limit -- by coordination and integration\nmechanisms which are long-term strategies that give competitive advantage\nthrough overall supply chain efficiency. Information Technology, by the way of\ncollecting, sharing and gathering data, exchanging information, optimising\nprocess through package software, is becoming one of the key developments and\nsuccess of these collaboration strategies. This paper proposes a study to\nidentify the methods used for collaborative works in the supply chain and\nfocuses on some of its areas, as between a company and its suppliers (i.e.,\ninventory sharing) and its customers (i.e., customer demand, forecasting), and\nalso the integration of product information in the value chain.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01688v1"
    },
    {
        "title": "Flexible Representative Democracy: An Introduction with Binary Issues",
        "authors": [
            "Ben Abramowitz",
            "Nicholas Mattei"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We introduce Flexible Representative Democracy (FRD), a novel hybrid of\nRepresentative Democracy (RD) and Direct Democracy (DD) in which voters can\nalter the issue-dependent weights of a set of elected representatives. In line\nwith the literature on Interactive Democracy, our model allows the voters to\nactively determine the degree to which the system is direct versus\nrepresentative. However, unlike Liquid Democracy, Flexible Representative\nDemocracy uses strictly non-transitive delegations, making delegation cycles\nimpossible, and maintains a fixed set of accountable, elected representatives.\nWe present FRD and analyze it using a computational approach with issues that\nare binary and symmetric. We compare the outcomes of various voting systems\nusing Direct Democracy with majority voting as an ideal baseline. First, we\ndemonstrate the shortcomings of Representative Democracy in our model. We\nprovide NP-Hardness results for electing an ideal set of representatives,\ndiscuss pathologies, and demonstrate empirically that common multi-winner\nelection rules for selecting representatives do not perform well in\nexpectation. To analyze the effects of adding flexibility, we begin by\nproviding theoretical results on how issue-specific delegations determine\noutcomes. Finally, we provide empirical results comparing the outcomes of\nRepresentative Democracy, proxy voting with fixed sets of proxies across\nissues, and Flexible Representative Democracy with issue-specific delegations.\nOur results show that variants of Proxy Voting yield no discernible benefit\nover unweighted representatives and reveal the potential for Flexible\nRepresentative Democracy to improve outcomes as voter participation increases.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.02921v3"
    },
    {
        "title": "Distributed Cooperative Spectrum Sharing in UAV Networks Using\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Alireza Shamsoshoara",
            "Mehrdad Khaledi",
            "Fatemeh Afghah",
            "Abolfazl Razi",
            "Jonathan Ashdown"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In this paper, we develop a distributed mechanism for spectrum sharing among\na network of unmanned aerial vehicles (UAV) and licensed terrestrial networks.\nThis method can provide a practical solution for situations where the UAV\nnetwork may need external spectrum when dealing with congested spectrum or need\nto change its operating frequency due to security threats. Here we study a\nscenario where the UAV network performs a remote sensing mission. In this\nmodel, the UAVs are categorized into two clusters of relaying and sensing UAVs.\nThe relay UAVs provide a relaying service for a licensed network to obtain\nspectrum access for the rest of UAVs that perform the sensing task. We develop\na distributed mechanism in which the UAVs locally decide whether they need to\nparticipate in relaying or sensing considering the fact that communications\namong UAVs may not be feasible or reliable. The UAVs learn the optimal task\nallocation using a distributed reinforcement learning algorithm. Convergence of\nthe algorithm is discussed and simulation results are presented for different\nscenarios to verify the convergence.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05053v1"
    },
    {
        "title": "Evolving intrinsic motivations for altruistic behavior",
        "authors": [
            "Jane X. Wang",
            "Edward Hughes",
            "Chrisantha Fernando",
            "Wojciech M. Czarnecki",
            "Edgar A. Duenez-Guzman",
            "Joel Z. Leibo"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Multi-agent cooperation is an important feature of the natural world. Many\ntasks involve individual incentives that are misaligned with the common good,\nyet a wide range of organisms from bacteria to insects and humans are able to\novercome their differences and collaborate. Therefore, the emergence of\ncooperative behavior amongst self-interested individuals is an important\nquestion for the fields of multi-agent reinforcement learning (MARL) and\nevolutionary theory. Here, we study a particular class of multi-agent problems\ncalled intertemporal social dilemmas (ISDs), where the conflict between the\nindividual and the group is particularly sharp. By combining MARL with\nappropriately structured natural selection, we demonstrate that individual\ninductive biases for cooperation can be learned in a model-free way. To achieve\nthis, we introduce an innovative modular architecture for deep reinforcement\nlearning agents which supports multi-level selection. We present results in two\nchallenging environments, and interpret these in the context of cultural and\necological evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05931v2"
    },
    {
        "title": "Cost of selfishness in the allocation of cities in the Multiple\n  Travelling Salesmen Problem",
        "authors": [
            "Thierry Moyaux",
            "Eric Marcon"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The decision to centralise or decentralise human organisations requires\nquantified evidence but little is available in the literature. We provide such\ndata in a variant of the Multiple Travelling Salesmen Problem (MTSP) in which\nwe study how the allocation sub-problem may be decentralised among selfish\nselfmen. Our contributions are (i) this modification of the MTSP in order to\ninclude selfishness, (ii) the proposition of organisations to solve this\nmodified MTSP, and (iii) the comparison of these organisations. Our 5\norganisations may be summarised as follows: (i) OptDecentr is a pure\nCentralised Organisation (CO) in which a Central Authority (CA) finds the best\nsolution which could be found by a Decentralised Organisation (DO), (ii)\nCluster and (iii) Auction are CO/DO hybrids, and (iv) P2P and (v) CNP are pure\nDO. Sixth and seventh organisations are used as benchmarks: (vi) NoRealloc is a\npure DO which ignores the allocation problem, and (vii) FullCentr is a pure CO\nwhich solves a different problem, viz., the traditional MTSP. Comparing the\nefficiency of pairs of these mechanisms quantify the price of decentralising an\norganisation. In particular, our model of selfishness in OptDecentr makes the\ntotal route length 30% (respectively, 60%) longer with 5 (respectively, 9)\nsalesmen than the traditional MTSP in FullCentr when the computation time is\nlimited to 30 minutes. With this time limit, our results also seem to indicate\nthat the level of coercion of the CA impacts more the total route length than\nthe level of centralisation.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06355v1"
    },
    {
        "title": "Modelling Agents Endowed with Social Practices: Static Aspects",
        "authors": [
            "Rijk Mercuur",
            "Virginia Dignum",
            "Catholijn M. Jonker"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  To understand societal phenomena through simulation, we need computational\nvariants of socio-cognitive theories. Social Practice Theory has provided a\nunique understanding of social phenomena regarding the routinized, social and\ninterconnected aspects of behaviour. This paper provides the Social Practice\nAgent (SoPrA) model that enables the use of Social Practice Theory (SPT) for\nagent-based simulations. We extract requirements from SPT, construct a\ncomputational model in the Unified Modelling Language, verify its\nimplementation in Netlogo and Prot\\'eg\\'e and show how SoPrA maps on a use case\nof commuting. The next step is to model the dynamic aspect of SPT and validate\nSoPrA's ability to provide understanding in different scenario's. This paper\nprovides the groundwork with a computational model that is a correct depiction\nof SPT, computational feasible and can be directly mapped to the habitual,\nsocial and interconnected aspects of a target scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.10981v1"
    },
    {
        "title": "X*: Anytime Multi-Agent Path Finding for Sparse Domains using\n  Window-Based Iterative Repairs",
        "authors": [
            "Kyle Vedder",
            "Joydeep Biswas"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Real-world multi-agent systems such as warehouse robots operate under\nsignificant time constraints -- in such settings, rather than spending\nsignificant amounts of time solving for optimal paths, it is instead preferable\nto find valid collision-free paths quickly, even if suboptimal, and given\nadditional time, to iteratively refine such paths to improve their cost. In\nsuch domains, we observe that agent-agent collisions are sparse -- they involve\nsmall local subsets of agents, and are geographically contained within a small\nregion of the overall space.\n  Leveraging this insight, we can first plan paths for each agent individually,\nand in the cases of collisions between agents, perform small local repairs\nlimited to local subspace windows. As time permits, these windows can be\nsuccessively grown and the repairs within them refined, thereby improving the\npath quality, and eventually converging to the global joint optimal solution.\nUsing these insights, we present two algorithmic contributions: 1) the Windowed\nAnytime Multiagent Planning Framework (WAMPF) for a class of anytime planners\nthat quickly generate valid paths with suboptimality estimates and generate\noptimal paths given sufficient time, and 2) X*, an efficient WAMPF-based\nplanner. X* is able to efficiently find successive valid solutions by employing\nre-use techniques during the repair growth step of WAMPF.\n  Experimentally, we demonstrate that in sparse domains: 1) X* outperforms\nstate-of-the-art anytime or optimal MAPF solvers in time to valid path, 2) X*\nis competitive with state-of-the-art anytime or optimal MAPF solvers in time to\noptimal path, 3) X* quickly converges to very tight suboptimality bounds, and\n4) X* is competitive with state-of-the-art suboptimal MAPF solvers in time to\nvalid path for small numbers of agents while providing much higher quality\npaths.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.12598v5"
    },
    {
        "title": "Swarm coordination of mini-UAVs for target search using imperfect\n  sensors",
        "authors": [
            "A. L. Alfeo",
            "M. G. C. A. Cimino",
            "N. De Francesco",
            "A. Lazzeri",
            "M. Lega",
            "G. Vaglini"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Unmanned Aerial Vehicles (UAVs) have a great potential to support search\ntasks in unstructured environments. Small, lightweight, low speed and agile\nUAVs, such as multi-rotors platforms can incorporate many kinds of sensors that\nare suitable for detecting object of interests in cluttered outdoor areas.\nHowever, due to their limited endurance, moderate computing power, and\nimperfect sensing, mini-UAVs should be into groups using swarm coordination\nalgorithms to perform tasks in a scalable, reliable and robust manner. In this\npaper a biologically-inspired mechanisms is adopted to coordinate drones\nperforming target search with imperfect sensors. In essence, coordination can\nbe achieved by combining stigmergic and flocking behaviors. Stigmergy occurs\nwhen a drone releases digital pheromone upon sensing of a potential target.\nSuch pheromones can be aggregated and diffused between flocking drones,\ncreating a spatiotemporal attractive potential field. Flocking occurs, as an\nemergent effect of alignment, separation and cohesion, where drones self\norganise with similar heading and dynamic arrangement as a group. The emergent\ncoordination of drones relies on the alignment of stigmergy and flocking\nstrategies. This paper reports on the design of the novel swarming algorithm,\nreviewing different strategies and measuring their performance on a number of\nsynthetic and real-world scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.02885v1"
    },
    {
        "title": "Agent-Based Modelling Approach for Distributed Decision Support in an\n  IoT Network",
        "authors": [
            "Merim Dzaferagic",
            "M. Majid Butt",
            "Maria Murphy",
            "Nicholas Kaminski",
            "Nicola Marchetti"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  An increasing number of emerging applications, e.g., internet of things,\nvehicular communications, augmented reality, and the growing complexity due to\nthe interoperability requirements of these systems, lead to the need to change\nthe tools used for the modeling and analysis of those networks. Agent-Based\nModeling (ABM) as a bottom-up modeling approach considers a network of\nautonomous agents interacting with each other, and therefore represents an\nideal framework to comprehend the interactions of heterogeneous nodes in a\ncomplex environment. Here, we investigate the suitability of ABM to model the\ncommunication aspects of a road traffic management system, as an example of an\nInternet of Things (IoT) network. We model, analyze and compare various Medium\nAccess Control (MAC) layer protocols for two different scenarios, namely\nuncoordinated and coordinated. Besides, we model the scheduling mechanisms for\nthe coordinated scenario as a high level MAC protocol by using three different\napproaches: Centralized Decision Maker, DESYNC and decentralized learning MAC\n(L-MAC). The results clearly show the importance of coordination between\nmultiple decision makers in order to improve the accuracy of information and\nspectrum utilization of the system.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.04585v1"
    },
    {
        "title": "Proposition of an implementation framework enabling benchmarking of\n  Holonic Manufacturing Systems",
        "authors": [
            "Olivier Cardin",
            "Anne L'anton"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Performing an overview of the benchmarking initiatives oriented towards the\nperformance evaluation of Holonic Manufacturing Systems shows that there are\nvery few of them. However, a comparison between all the isolated emu-lation\ndevelopments for benchmarking in literature was made, and showed that many\ncommon features could be extracted. Several deadlocks for a generic approach of\nthese developments are also exhibited. A global architecture dedicated to a\ngeneric performance evaluation platform design is suggested. This architecture\nintegrates a scenario manager, whose main specificities were detailed and\njustified. Those features are meant to both integrate the best practices\nencountered in literature and fulfil the missing aspects to respond to the\nproblematics.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.05669v1"
    },
    {
        "title": "H${}^2$CM-based holonic modeling of a gas pipeline",
        "authors": [
            "Carlos Indriago",
            "Latéfa Ghomri",
            "Olivier Cardin"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  A gas pipeline is a relatively simple physical system, but the optimality of\nthe control is difficult to achieve. When switching from one kind of gas to\nanother , a volume of useless mixture is generated. Therefore, the control\nneeds to both respond to the demand and minimize the volume of lost gas. In\ncase of stable and perfectly known demand, scheduling techniques can be used,\nbut in other cases , calculation times are incompatible with an industrial\napplication. This article introduces the application of H${}^2$CM (Holonic\nHybrid Control Model) generic architecture on this specific case. The study\ncase is extensively presented. Then, the defined holonic architecture\n(H${}^2$CM compatible) is detailed, and the role and functions of each holon\nare presented. Finally, a tentative general control algorithm is suggested,\nwhich gives an insight on the actual algorithms that will be developed in\nperspective of this work.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.05671v1"
    },
    {
        "title": "Swarm Intelligent Algorithm For Re-entrant Hybrid Flow shop Scheduling\n  Problems",
        "authors": [
            "Zhonghua Han",
            "Xutian Tian",
            "Xiaoting Dong",
            "Fanyi Xie"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In order to solve Re-entrant Hybrid Flowshop (RHFS) scheduling problems and\nestablish simulations and processing models, this paper uses Wolf Pack\nAlgorithm (WPA) as global optimization. For local assignment, it takes minimum\nremaining time rule. Scouting behaviors of wolf are changed in former\noptimization by means of levy flight, extending searching ranges and increasing\nrapidity of convergence. When it comes to local extremum of WPA, dynamic\nregenerating individuals with high similarity adds diversity. Hanming distance\nis used to judge individual similarity for increased quality of individuals,\nenhanced search performance of the algorithm in solution space and promoted\nevolutionary vitality.A painting workshop in a bus manufacture enterprise owns\ntypical features of re-entrant hybrid flowshop. Regarding it as the algorithm\napplied target, this paper focus on resolving this problem with LDWPA (Dynamic\nwolf pack algorithm based on Levy Flight). Results show that LDWPA can solve\nre-entrant hybrid flowshop scheduling problems effectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.09660v1"
    },
    {
        "title": "The Emergence of Complex Bodyguard Behavior Through Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Hassam Ullah Sheikh",
            "Ladislau Bölöni"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper we are considering a scenario where a team of robot bodyguards\nare providing physical protection to a VIP in a crowded public space. We show\nthat the problem involves a complex mesh of interactions between the VIP and\nthe robots, between the robots themselves and the robots and the bystanders\nrespectively. We show how recently proposed multi-agent policy gradient\nreinforcement learning algorithms such as MADDPG can be successfully adapted to\nlearn collaborative robot behaviors that provide protection to the VIP.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.09833v1"
    },
    {
        "title": "A structured approach for the implementation of distributed\n  manufacturing simulation",
        "authors": [
            "Sameh M. Saad",
            "Terence Perera",
            "Ruwan Wickramarachchi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Manufacturing has been changing from a mainly inhouse effort to a distributed\nstyle in order to meet new challenges owing to globalization of markets and\nworldwide competition. Distributed simulation provides an attractive solution\nto construct cross enterprise simulations to evaluate the viability of the\nproposed distributed manufacturing enterprises. However, due to its complexity\nand high cost distributed simulation failed to gain a wide acceptance from\nindustrial users. The main objective of this paper is to address these issues\nand present a new structured approach to implement distributed simulation with\ncost effective and easy to implementable tools. A simplified approach for model\npartitioning for distributed simulation is also included in the proposed\napproach. The implementation of distributed manufacturing simulation is\nillustrated with Arena, Microsoft Message Queue (MSMQ) and Visual Basic for\nApplications (VBA).\n",
        "pdf_link": "http://arxiv.org/pdf/1901.10421v1"
    },
    {
        "title": "Determining r- and (r,s)-Robustness of Digraphs Using Mixed Integer\n  Linear Programming",
        "authors": [
            "James Usevitch",
            "Dimitra Panagou"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  There has been an increase in the use of resilient control algorithms based\non the graph theoretic properties of $r$- and $(r,s)$-robustness. These\nalgorithms guarantee consensus of normally behaving agents in the presence of a\nbounded number of arbitrarily misbehaving agents if the values of the integers\n$r$ and $s$ are sufficiently large. However, determining an arbitrary graph's\nrobustness is a highly nontrivial problem. This paper introduces a novel method\nfor determining the $r$- and $(r,s)$-robustness of digraphs using mixed integer\nlinear programming; to the best of the authors' knowledge it is the first time\nthat mixed integer programming methods have been applied to the robustness\ndetermination problem. The approach only requires knowledge of the graph\nLaplacian matrix, and can be formulated with binary integer variables. Mixed\ninteger programming algorithms such as branch-and-bound are used to iteratively\ntighten the lower and upper bounds on $r$ and $s$. Simulations are presented\nwhich compare the performance of this approach to prior robustness\ndetermination algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.11000v2"
    },
    {
        "title": "Efficient Ridesharing Order Dispatching with Mean Field Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Minne Li",
            " Zhiwei",
            " Qin",
            "Yan Jiao",
            "Yaodong Yang",
            "Zhichen Gong",
            "Jun Wang",
            "Chenxi Wang",
            "Guobin Wu",
            "Jieping Ye"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  A fundamental question in any peer-to-peer ridesharing system is how to, both\neffectively and efficiently, dispatch user's ride requests to the right driver\nin real time. Traditional rule-based solutions usually work on a simplified\nproblem setting, which requires a sophisticated hand-crafted weight design for\neither centralized authority control or decentralized multi-agent scheduling\nsystems. Although recent approaches have used reinforcement learning to provide\ncentralized combinatorial optimization algorithms with informative weight\nvalues, their single-agent setting can hardly model the complex interactions\nbetween drivers and orders. In this paper, we address the order dispatching\nproblem using multi-agent reinforcement learning (MARL), which follows the\ndistributed nature of the peer-to-peer ridesharing problem and possesses the\nability to capture the stochastic demand-supply dynamics in large-scale\nridesharing scenarios. Being more reliable than centralized approaches, our\nproposed MARL solutions could also support fully distributed execution through\nrecent advances in the Internet of Vehicles (IoV) and the Vehicle-to-Network\n(V2N). Furthermore, we adopt the mean field approximation to simplify the local\ninteractions by taking an average action among neighborhoods. The mean field\napproximation is capable of globally capturing dynamic demand-supply variations\nby propagating many local interactions between agents and the environment. Our\nextensive experiments have shown the significant improvements of MARL order\ndispatching algorithms over several strong baselines on the gross merchandise\nvolume (GMV), and order response rate measures. Besides, the simulated\nexperiments with real data have also justified that our solution can alleviate\nthe supply-demand gap during the rush hours, thus possessing the capability of\nreducing traffic congestion.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.11454v1"
    },
    {
        "title": "Engineering Token Economy with System Modeling",
        "authors": [
            "Zixuan Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Cryptocurrencies and blockchain networks have attracted tremendous attention\nfrom their volatile price movements and the promise of decentralization.\nHowever, most projects run on business narratives with no way to test and\nverify their assumptions and promises about the future. The complex nature of\nsystem dynamics within networked economies has rendered it difficult to reason\nabout the growth and evolution of these networks. This paper drew concepts from\ndifferential games, classical control engineering, and stochastic dynamical\nsystem to come up with a framework and example to model, simulate, and engineer\nnetworked token economies. A model on a generalized token economy is proposed\nwhere miners provide service to a platform in exchange for a cryptocurrency and\nusers consume service from the platform. Simulations of this model allow us to\nobserve outcomes of complex dynamics and reason about the evolution of the\nsystem. Speculative price movements and engineered block rewards were then\nexperimented to observe their impact on system dynamics and network-level\ngoals. The model presented is necessarily limited so we conclude by exploring\nthose limitations and outlining future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.00899v1"
    },
    {
        "title": "Scenario Generalization of Data-driven Imitation Models in Crowd\n  Simulation",
        "authors": [
            "Gang Qiao",
            "Honglu Zhou",
            "Mubbasir Kapadia",
            "Sejong Yoon",
            "Vladimir Pavlovic"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Crowd simulation, the study of the movement of multiple agents in complex\nenvironments, presents a unique application domain for machine learning. One\nchallenge in crowd simulation is to imitate the movement of expert agents in\nhighly dense crowds. An imitation model could substitute an expert agent if the\nmodel behaves as good as the expert. This will bring many exciting\napplications. However, we believe no prior studies have considered the critical\nquestion of how training data and training methods affect imitators when these\nmodels are applied to novel scenarios. In this work, a general imitation model\nis represented by applying either the Behavior Cloning (BC) training method or\na more sophisticated Generative Adversarial Imitation Learning (GAIL) method,\non three typical types of data domains: standard benchmarks for evaluating\ncrowd models, random sampling of state-action pairs, and egocentric scenarios\nthat capture local interactions. Simulated results suggest that (i) simpler\ntraining methods are overall better than more complex training methods, (ii)\ntraining samples with diverse agent-agent and agent-obstacle interactions are\nbeneficial for reducing collisions when the trained models are applied to new\nscenarios. We additionally evaluated our models in their ability to imitate\nreal world crowd trajectories observed from surveillance videos. Our findings\nindicate that models trained on representative scenarios generalize to new,\nunseen situations observed in real human crowds.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.00738v1"
    },
    {
        "title": "Modeling Communication of Collaborative Multi-Agent System under\n  Epistemic Planning",
        "authors": [
            "Abeer Alshehri",
            "Tim Miller",
            "Liz Sonenberg"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In most multiagent applications, communication is essential among agents to\ncoordinate their actions, and thus achieve their goal. However, communication\noften has a related cost that affects overall system performance. In this\npaper, we draw inspiration from studies of epistemic planning to develop a\ncommunication model for agents that allows them to cooperate and make\ncommunication decisions effectively within a planning task. The proposed model\ntreats a communication process as an action that modifies the epistemic state\nof the team. In two simulated tasks, we evaluate whether agents can cooperate\neffectively and achieve higher performance using communication protocol modeled\nin our epistemic planning framework. Based on an empirical study conducted\nusing search and rescue tasks with different scenarios, our results show that\nthe proposed model improved team performance across all scenarios compared with\nbaseline models.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.02607v2"
    },
    {
        "title": "Cellular automaton model with turning behavior in crowd evacuation",
        "authors": [
            "Daiki Miyagawa",
            "Genki Ichinose"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Effective evacuation policies in emergency situations are important to save\nlives. To develop such policies, simulation models based on cellular automata\nhave been used for crowd evacuation dynamics. In most previous studies of crowd\nevacuations, an evacuee is represented by a $1 \\times 1$ square. However, a\nrectangle ($1 \\times 2$) representation is more suitable for such models than\nthe square representation because of evacuees' shoulder width. The rectangle\nrepresentation gives two new features to evacuees' behaviors: moving sideways\nand turning. We study the effects of these behaviors on crowd evacuation\ndynamics. Hence, we constructed a cellular automaton model where evacuees whose\nshoulder widths are $1 \\times 2$ try to escape from a room in an emergency\nsituation. The simulation results showed that turning behavior can make the\nevacuation time shorter and there is an optimal turning rate for the crowd\nevacuation. Our findings contribute to the effective control of evacuees in\nemergency situations.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.11580v2"
    },
    {
        "title": "Decentralized Cooperative Communication-less Multi-Agent Task Assignment\n  with Monte-Carlo Tree Search",
        "authors": [
            "Mohammadreza Daneshvaramoli",
            "Mohammad Sina Kiarostami",
            "Saleh Khalaj Monfared",
            "Helia Karisani",
            "Hamed Khashehchi",
            "Dara Rahmati",
            "Saeid Gorgin",
            "Amir Rahmati"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Cooperative task assignment is an important subject in multi-agent systems\nwith a wide range of applications. These systems are usually designed with\nmassive communication among the agents to minimize the error in pursuit of the\ngeneral goal of the entire system. In this work, we propose a novel approach\nfor Decentralized Cooperative Communication-less Multi-Agent Task Assignment\n(DCCMATA) employing Monte-Carlo Tree Search (MCTS). Here, each agent can assign\nthe optimal task by itself for itself. We design the system to automatically\nmaximize the success rate, achieving the collective goal effectively. To put it\nanother way, the agents optimally compute each following step, only by knowing\nthe current location of other agents, with no additional communication\noverhead. In contrast with the previously proposed methods which rely on the\ntask assignment procedure for similar problems, we describe a method in which\nthe agents move towards the collective goal. This may lead to scenarios where\nsome agents not necessarily move towards the closest goal. However, the total\nefficiency (makespan) and effectiveness (success ratio) in these cases are\nsignificantly improved. To evaluate our approach, we have tested the algorithm\nwith a wide range of parameters(agents, size, goal). Our implementation\ncompletely solves (Success Rate = %100) a 20*20 grid with 20 goals by 20 agents\nin 7.9 s runtime for each agent. Also, the proposed algorithm runs with the\ncomplexity of O(N^2I^2 + IN^4), where the I and N are the MCTS iterative index\nand grid size, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.12062v3"
    },
    {
        "title": "BARK: Open Behavior Benchmarking in Multi-Agent Environments",
        "authors": [
            "Julian Bernhard",
            "Klemens Esterle",
            "Patrick Hart",
            "Tobias Kessler"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Predicting and planning interactive behaviors in complex traffic situations\npresents a challenging task. Especially in scenarios involving multiple traffic\nparticipants that interact densely, autonomous vehicles still struggle to\ninterpret situations and to eventually achieve their own mission goal. As\ndriving tests are costly and challenging scenarios are hard to find and\nreproduce, simulation is widely used to develop, test, and benchmark behavior\nmodels. However, most simulations rely on datasets and simplistic behavior\nmodels for traffic participants and do not cover the full variety of\nreal-world, interactive human behaviors. In this work, we introduce BARK, an\nopen-source behavior benchmarking environment designed to mitigate the\nshortcomings stated above. In BARK, behavior models are (re-)used for planning,\nprediction, and simulation. A range of models is currently available, such as\nMonte-Carlo Tree Search and Reinforcement Learning-based behavior models. We\nuse a public dataset and sampling-based scenario generation to show the\ninter-exchangeability of behavior models in BARK. We evaluate how well the\nmodels used cope with interactions and how robust they are towards exchanging\nbehavior models. Our evaluation shows that BARK provides a suitable framework\nfor a systematic development of behavior models.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.02604v2"
    },
    {
        "title": "ROMA: Multi-Agent Reinforcement Learning with Emergent Roles",
        "authors": [
            "Tonghan Wang",
            "Heng Dong",
            "Victor Lesser",
            "Chongjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The role concept provides a useful tool to design and understand complex\nmulti-agent systems, which allows agents with a similar role to share similar\nbehaviors. However, existing role-based methods use prior domain knowledge and\npredefine role structures and behaviors. In contrast, multi-agent reinforcement\nlearning (MARL) provides flexibility and adaptability, but less efficiency in\ncomplex tasks. In this paper, we synergize these two paradigms and propose a\nrole-oriented MARL framework (ROMA). In this framework, roles are emergent, and\nagents with similar roles tend to share their learning and to be specialized on\ncertain sub-tasks. To this end, we construct a stochastic role embedding space\nby introducing two novel regularizers and conditioning individual policies on\nroles. Experiments show that our method can learn specialized, dynamic, and\nidentifiable roles, which help our method push forward the state of the art on\nthe StarCraft II micromanagement benchmark. Demonstrative videos are available\nat https://sites.google.com/view/romarl/.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.08039v3"
    },
    {
        "title": "Influence of CAV Clustering Strategies on Mixed Traffic Flow\n  Characteristics: An Analysis of Vehicle Trajectory Data",
        "authors": [
            "Zijia Zhong",
            "Earl E. Lee",
            "Mark Nejad",
            "Joyoung Lee"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Being one of the most promising applications enabled by connected and\nautomated vehicles (CAV) technology, Cooperative Adaptive Cruise Control (CACC)\nis expected to be deployed in the near term on public roads.} Thus far, the\nmajority of the CACC studies have been focusing on the overall network\nperformance with limited insights on the potential impacts of CAVs on\nhuman-driven vehicles (HVs).This paper aims to quantify such impacts by\nstudying the high-resolution vehicle trajectory data that are obtained from\nmicroscopic simulation. Two platoon clustering strategies for CACC- an ad hoc\ncoordination strategy and a local coordination strategy-are implemented.\nResults show that the local coordination outperforms the ad hoc coordination\nacross all tested market penetration rates (MPRs) in terms of network\nthroughput and productivity. According to the two-sample\nKolmogorov-\\textcolor{re}{Smirnov} test, however, the distributions of the hard\nbraking events (as a potential safety impact) for HVs change significantly\nunder local coordination strategy. For both of the clustering strategy, CAVs\nincrease the average lane change frequency for HVs. The break-even point for\naverage lane change frequency between the two strategies is observed at 30%\nMPR, which decreases from 5.42 to 5.38 per vehicle. The average lane change\nfrequency following a monotonically increasing pattern in response to MPR, and\nit reaches the highest 5.48 per vehicle at 40% MPR. Lastly, the interaction\nstate of the car-following model for HVs is analyzed. It is revealed that the\ncomposition of the interaction state could be influenced by CAVs as well. One\nof the apparent trends is that the time spent on approaching state declines\nwith the increasing presence of CAVs.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.08290v2"
    },
    {
        "title": "Resilient Distributed Diffusion in Networks with Adversaries",
        "authors": [
            "Jiani Li",
            "Waseem Abbas",
            "Xenofon Koutsoukos"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, we study resilient distributed diffusion for multi-task\nestimation in the presence of adversaries where networked agents must estimate\ndistinct but correlated states of interest by processing streaming data. We\nshow that in general diffusion strategies are not resilient to malicious agents\nthat do not adhere to the diffusion-based information processing rules. In\nparticular, by exploiting the adaptive weights used for diffusing information,\nwe develop time-dependent attack models that drive normal agents to converge to\nstates selected by the attacker. We show that an attacker that has complete\nknowledge of the system can always drive its targeted agents to its desired\nestimates. Moreover, an attacker that does not have complete knowledge of the\nsystem including streaming data of targeted agents or the parameters they use\nin diffusion algorithms, can still be successful in deploying an attack by\napproximating the needed information. The attack models can be used for both\nstationary and non-stationary state estimation.In addition, we present and\nanalyze a resilient distributed diffusion algorithm that is resilient to any\ndata falsification attack in which the number of compromised agents in the\nlocal neighborhood of a normal agent is bounded. The proposed algorithm\nguarantees that all normal agents converge to their true target states if\nappropriate parameters are selected. We also analyze trade-off between the\nresilience of distributed diffusion and its performance in terms of\nsteady-state mean-square-deviation (MSD) from the correct estimates. Finally,\nwe evaluate the proposed attack models and resilient distributed diffusion\nalgorithm using stationary and non-stationary multi-target localization.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.10563v1"
    },
    {
        "title": "Robust Stochastic Bayesian Games for Behavior Space Coverage",
        "authors": [
            "Julian Bernhard",
            "Alois Knoll"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  A key challenge in multi-agent systems is the design of intelligent agents\nsolving real-world tasks in close interaction with other agents (e.g. humans),\nthereby being confronted with a variety of behavioral variations and limited\nknowledge about the true behaviors of observed agents. The practicability of\nexisting works addressing this challenge is being limited due to using finite\nsets of hypothesis for behavior prediction, the lack of a hypothesis design\nprocess ensuring coverage over all behavioral variations and\nsample-inefficiency when modeling continuous behavioral variations. In this\nwork, we present an approach to this challenge based on a new framework of\nRobust Stochastic Bayesian Games (RSBGs). An RSBG defines hypothesis sets by\npartitioning the physically feasible, continuous behavior space of the other\nagents. It combines the optimality criteria of the Robust Markov Decision\nProcess (RMDP) and the Stochastic Bayesian Game (SBG) to exponentially reduce\nthe sample complexity for planning with hypothesis sets defined over continuous\nbehavior spaces. Our approach outperforms the baseline algorithms in two\nexperiments modeling time-varying intents and large multidimensional behavior\nspaces, while achieving the same performance as a planner with knowledge of the\ntrue behaviors of other agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.11281v3"
    },
    {
        "title": "Resilient Distributed Diffusion for Multi-task Estimation",
        "authors": [
            "Jiani Li",
            "Xenofon Koutsoukos"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Distributed diffusion is a powerful algorithm for multi-task state estimation\nwhich enables networked agents to interact with neighbors to process input data\nand diffuse information across the network. Compared to a centralized approach,\ndiffusion offers multiple advantages that include robustness to node and link\nfailures. In this paper, we consider distributed diffusion for multi-task\nestimation where networked agents must estimate distinct but correlated states\nof interest by processing streaming data. By exploiting the adaptive weights\nused for diffusing information, we develop attack models that drive normal\nagents to converge to states selected by the attacker. The attack models can be\nused for both stationary and non-stationary state estimation. In addition, we\ndevelop a resilient distributed diffusion algorithm under the assumption that\nthe number of compromised nodes in the neighborhood of each normal node is\nbounded by $F$ and we show that resilience may be obtained at the cost of\nperformance degradation. Finally, we evaluate the proposed attack models and\nresilient distributed diffusion algorithm using stationary and non-stationary\nmulti-target localization.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.11911v1"
    },
    {
        "title": "Robust and Deterministic Scheduling of Power Grid Actors",
        "authors": [
            "Emilie Frost",
            "Eric MSP Veith",
            "Lars Fischer"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Modern power grids need to cope with increasingly decentralized, volatile\nenergy sources as well as new business models such as virtual power plants\nconstituted from battery swarms. This warrants both, day-ahead planning of\nlarger schedules for power plants, as well as short-term contracting to counter\nforecast deviations or to accommodate dynamics of the intra-day markets. In\naddition, the geographic distribution of renewable energy sources forces\nscheduling algorithms with a hugely different communication link qualities. In\nthis paper, we present an extension to the Lightweight Power Exchange Protocol\n(LPEP), dubbed LPEP++. It draws on the strength of the LPEP to find the optimal\nsolution of the combinatorial power demand-supply problem with string\nguarantees in acceptable time and extends it with facilities for long-term\nplanning, parallel negotiations and reduces its memory footprint. We\nfurthermore show its robustness towards volatile communication link quality.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.12605v1"
    },
    {
        "title": "An agent-based negotiation model and its implementation in Repast",
        "authors": [
            "S. Bai"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We propose an agent-based model, MNegoti, for simulating multilateral\nnegotiation process, which can be naturally employed in group decision support\nsystem. This model can also be applied to any use case in which negotiation is\ninvolved, in order to simulate the negotiation process. In this report, we\ndiscuss the implementation of the MNegoti model on the basis of the agent-based\nsimulation platform, Repast Simphony. It is worth pointing out that this model\ncan be used to create a java module for any use of agent-based negotiation\nsimulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.06135v1"
    },
    {
        "title": "Should I tear down this wall? Optimizing social metrics by evaluating\n  novel actions",
        "authors": [
            "János Kramár",
            "Neil Rabinowitz",
            "Tom Eccles",
            "Andrea Tacchetti"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  One of the fundamental challenges of governance is deciding when and how to\nintervene in multi-agent systems in order to impact group-wide metrics of\nsuccess. This is particularly challenging when proposed interventions are novel\nand expensive. For example, one may wish to modify a building's layout to\nimprove the efficiency of its escape route. Evaluating such interventions would\ngenerally require access to an elaborate simulator, which must be constructed\nad-hoc for each environment, and can be prohibitively costly or inaccurate.\nHere we examine a simple alternative: Optimize By Observational Extrapolation\n(OBOE). The idea is to use observed behavioural trajectories, without any\ninterventions, to learn predictive models mapping environment states to\nindividual agent outcomes, and then use these to evaluate and select changes.\nWe evaluate OBOE in socially complex gridworld environments and consider novel\nphysical interventions that our models were not trained on. We show that neural\nnetwork models trained to predict agent returns on baseline environments are\neffective at selecting among the interventions. Thus, OBOE can provide guidance\nfor challenging questions like: \"which wall should I tear down in order to\nminimize the Gini index of this group?\"\n",
        "pdf_link": "http://arxiv.org/pdf/2004.07625v1"
    },
    {
        "title": "A Game-Theoretic Utility Network for Cooperative Multi-Agent Decisions\n  in Adversarial Environments",
        "authors": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Underlying relationships among multi-agent systems (MAS) in hazardous\nscenarios can be represented as Game-theoretic models. We measure the\nperformance of MAS achieving tasks from the perspective of balancing success\nprobability and system costs. This paper proposes a new network-based model\ncalled Game-theoretic Utility Tree (GUT), which decomposes high-level\nstrategies into executable low-level actions for cooperative MAS decisions.\nThis is combined with a new payoff measure based on agent needs for real-time\nstrategy games. We present an Explore game domain to evaluate GUT against the\nstate-of-the-art QMIX decision-making method. Conclusive results on extensive\nnumerical simulations indicate that GUT can organize more complex relationships\namong MAS cooperation, helping the group achieve challenging tasks with lower\ncosts and a higher winning rate.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.10950v3"
    },
    {
        "title": "A Microscopic Epidemic Model and Pandemic Prediction Using Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Changliu Liu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper introduces a microscopic approach to model epidemics, which can\nexplicitly consider the consequences of individual's decisions on the spread of\nthe disease. We first formulate a microscopic multi-agent epidemic model where\nevery agent can choose its activity level that affects the spread of the\ndisease. Then by minimizing agents' cost functions, we solve for the optimal\ndecisions for individual agents in the framework of game theory and multi-agent\nreinforcement learning. Given the optimal decisions of all agents, we can make\npredictions about the spread of the disease. We show that there are negative\nexternalities in the sense that infected agents do not have enough incentives\nto protect others, which then necessitates external interventions to regulate\nagents' behaviors. In the discussion section, future directions are pointed out\nto make the model more realistic.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.12959v1"
    },
    {
        "title": "Simulating Self-Organization during Strategic Change: Implications for\n  Organizational Design",
        "authors": [
            "Ananya Sheth",
            "Joseph V. Sinfield"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Self-organization -- a characteristic of complex adaptive systems (CAS) --\nhas been explored in organizational research, in management theory [Mihm et al.\n2003; von Foerster 1984], firm internationalization [Chandra and Wilkinson\n2017], organizational design [Clement and Puranam 2017], and strategic change\n[Foster 2015]. Newer organizational forms such as networks and zero-hierarchy\ncompanies that hold the promise of self-organization are gaining prominence\n[Puranam et al. 2014], and theoretical organizational modeling is a useful\ntechnique to study them proactively via simulation [Puranam et al.2015; Simon\n1976]. In this paper, we introduce a nature-inspired model to understand\nself-organization of collaborative groups in three archetypal organizational\ndesigns: i. fully-networked, ii. siloed, and iii.dynamic, where each design\ncontrols intra-managerial communication in specific ways, and each member has\nreactive or perceptive behavioral tendencies.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.08521v1"
    },
    {
        "title": "A Review of Platforms for the Development of Agent Systems",
        "authors": [
            "Constantin-Valentin Pal",
            "Florin Leon",
            "Marcin Paprzycki",
            "Maria Ganzha"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Agent-based computing is an active field of research with the goal of\nbuilding autonomous software of hardware entities. This task is often\nfacilitated by the use of dedicated, specialized frameworks. For almost thirty\nyears, many such agent platforms have been developed. Meanwhile, some of them\nhave been abandoned, others continue their development and new platforms are\nreleased. This paper presents a up-to-date review of the existing agent\nplatforms and also a historical perspective of this domain. It aims to serve as\na reference point for people interested in developing agent systems. This work\ndetails the main characteristics of the included agent platforms, together with\nlinks to specific projects where they have been used. It distinguishes between\nthe active platforms and those no longer under development or with unclear\nstatus. It also classifies the agent platforms as general purpose ones, free or\ncommercial, and specialized ones, which can be used for particular types of\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.08961v1"
    },
    {
        "title": "Congestion Management for Mobility-on-Demand Schemes that use Electric\n  Vehicles",
        "authors": [
            "Emmanouil Rigas",
            "Konstantinos Tsompanidis"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  To date the majority of commuters use their privately owned vehicle that uses\nan internal combustion engine. This transportation model suffers from low\nvehicle utilization and causes environmental pollution. This paper studies the\nuse of Electric Vehicles (EVs) operating in a Mobility-on-Demand (MoD) scheme\nand tackles the related management challenges. We assume a number of customers\nacting as cooperative agents requesting a set of alternative trips and EVs\ndistributed across a number of pick-up and drop-off stations. In this setting,\nwe propose congestion management algorithms which take as input the trip\nrequests and calculate the EV-to-customer assignment aiming to maximize trip\nexecution by keeping the system balanced in terms of matching demand and\nsupply. We propose a Mixed-Integer-Programming (MIP) optimal offline solution\nwhich assumes full knowledge of customer demand and an equivalent online greedy\nalgorithm that can operate in real time. The online algorithm uses three\nalternative heuristic functions in deciding whether to execute a customer\nrequest: (a) The sum of squares of all EVs in all stations, (b) the percentage\nof trips' destination location fullness and (c) a random choice of trip\nexecution. Through a detailed evaluation, we observe that (a) provides an\nincrease of up to 4.8% compared to (b) and up to 11.5% compared to (c) in terms\nof average trip execution, while all of them achieve close to the optimal\nperformance. At the same time, the optimal scales up to settings consisting of\ntenths of EVs and a few hundreds of customer requests.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.16088v1"
    },
    {
        "title": "Simulation of Wheelchair Movements in Crowd Using Fine Grid Cellular\n  Automata",
        "authors": [
            "Siamak Sarmady",
            "Fazilah Haron",
            "Abdullah Zawawi Talib"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Crowd simulation models are used to assess the performance and safety of\ncrowd systems. In some systems, wheelchairs and other moving objects are\npresent in the crowd. The different size and speed of the wheelchairs could\nsignificantly change the behavior and dynamics of the crowd. In order to\nminimize the risks of overcrowding and other types of accidents, it is\nimportant to properly model the wheelchairs and their interactions with\npedestrians and the environment. Cellular automata are extensively utilized in\ncrowd modeling because of their simple and fast algorithms. Fine grid cellular\nautomata model uses small cells in which moving entities (pedestrians,\nwheelchairs, cars and etc.) occupy several cells. The entities could have\ndifferent sizes, shapes, and speeds. In this article, fine grid cellular\nautomata model has been modified to allow building crowd simulation models with\ndifferent ratios of wheelchairs that could be of different sizes and speed\nprofiles. A scenario of a walkway has been used to evaluate the model. The slow\ndown effect of the slower wheelchairs has been properly reproduced in the\nresults which also match empirical data. Density-speed graphs are also compared\nto crowds comprising of only pedestrians.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.00082v1"
    },
    {
        "title": "Herding stochastic autonomous agents via local control rules and online\n  global target selection strategies",
        "authors": [
            "Fabrizia Auletta",
            "Davide Fiore",
            "Michael J. Richardson",
            "Mario di Bernardo"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this Paper we propose a simple yet effective set of local control rules to\nmake a group of \"herder agents\" collect and contain in a desired region an\nensemble of non-cooperative stochastic \"target agents\" in the plane. We\ninvestigate the robustness of the proposed strategies to variations of the\nnumber of target agents and the strength of the repulsive force they feel when\nin proximity of the herders. Extensive numerical simulations confirm the\neffectiveness of the approach and are complemented by a more realistic\nvalidation on commercially available robotic agents via ROS.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.00386v3"
    },
    {
        "title": "Opinion Diffusion and Campaigning on Society Graphs",
        "authors": [
            "Piotr Faliszewski",
            "Rica Gonen",
            "Martin Koutecký",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We study the effects of campaigning, where the society is partitioned into\nvoter clusters and a diffusion process propagates opinions in a network\nconnecting the clusters. Our model is very powerful and can incorporate many\ncampaigning actions, various partitions of the society into clusters, and very\ngeneral diffusion processes. Perhaps surprisingly, we show that computing the\ncheapest campaign for rigging a given election can usually be done efficiently,\neven with arbitrarily-many voters. Moreover, we report on certain computational\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.00651v1"
    },
    {
        "title": "Reinforcement Learning in Deep Structured Teams: Initial Results with\n  Finite and Infinite Valued Features",
        "authors": [
            "Jalal Arabneydi",
            "Masoud Roudneshin",
            "Amir G. Aghdam"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, we consider Markov chain and linear quadratic models for deep\nstructured teams with discounted and time-average cost functions under two\nnon-classical information structures, namely, deep state sharing and no\nsharing. In deep structured teams, agents are coupled in dynamics and cost\nfunctions through deep state, where deep state refers to a set of orthogonal\nlinear regressions of the states. In this article, we consider a homogeneous\nlinear regression for Markov chain models (i.e., empirical distribution of\nstates) and a few orthonormal linear regressions for linear quadratic models\n(i.e., weighted average of states). Some planning algorithms are developed for\nthe case when the model is known, and some reinforcement learning algorithms\nare proposed for the case when the model is not known completely. The\nconvergence of two model-free (reinforcement learning) algorithms, one for\nMarkov chain models and one for linear quadratic models, is established. The\nresults are then applied to a smart grid.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.02868v4"
    },
    {
        "title": "Converging to a Desired Orientation in a Flock of Agents",
        "authors": [
            "Saar Cohen",
            "Noa Agmon"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This work concentrates on different aspects of the \\textit{consensus\nproblem}, when applying it to a swarm of flocking agents. We examine the\npossible influence an external agent, referred to as {\\em influencing agent}\nhas on the flock. We prove that even a single influencing agent with a\n\\textit{Face Desired Orientation behaviour} that is injected into the flock is\nsufficient for guaranteeing desired consensus of the flock of agents which\nfollow a Vicsek-inspired Model. We further show that in some cases this can be\nguaranteed also in dynamic environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.04686v2"
    },
    {
        "title": "A Decentralized Multi-Objective Optimization Algorithm",
        "authors": [
            "M. J. Blondin",
            "M. T. Hale"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  During the past two decades, multi-agent optimization problems have drawn\nincreased attention from the research community. When multiple objective\nfunctions are present among agents, many works optimize the sum of these\nobjective functions. However, this formulation implies a decision regarding the\nrelative importance of each objective function. In fact, optimizing the sum is\na special case of a multi-objective problem in which all objectives are\nprioritized equally. In this paper, a distributed optimization algorithm that\nexplores Pareto optimal solutions for non-homogeneously weighted sums of\nobjective functions is proposed. This exploration is performed through a new\nrule based on agents' priorities that generates edge weights in agents'\ncommunication graph. These weights determine how agents update their decision\nvariables with information received from other agents in the network. Agents\ninitially disagree on the priorities of the objective functions though they are\ndriven to agree upon them as they optimize. As a result, agents still reach a\ncommon solution. The network-level weight matrix is (non-doubly) stochastic,\nwhich contrasts with many works on the subject in which it is\ndoubly-stochastic. New theoretical analyses are therefore developed to ensure\nconvergence of the proposed algorithm. This paper provides a gradient-based\noptimization algorithm, proof of convergence to solutions, and convergence\nrates of the proposed algorithm. It is shown that agents' initial priorities\ninfluence the convergence rate of the proposed algorithm and that these initial\nchoices affect its long-run behavior. Numerical results performed with\ndifferent numbers of agents illustrate the performance and efficiency of the\nproposed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.04781v1"
    },
    {
        "title": "Event-Triggered Multi-agent Reinforcement Learning with Communication\n  under Limited-bandwidth Constraint",
        "authors": [
            "Guangzheng Hu",
            "Yuanheng Zhu",
            "Dongbin Zhao",
            "Mengchen Zhao",
            "Jianye Hao"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Communicating with each other in a distributed manner and behaving as a group\nare essential in multi-agent reinforcement learning. However, real-world\nmulti-agent systems suffer from restrictions on limited-bandwidth\ncommunication. If the bandwidth is fully occupied, some agents are not able to\nsend messages promptly to others, causing decision delay and impairing\ncooperative effects. Recent related work has started to address the problem but\nstill fails in maximally reducing the consumption of communication resources.\nIn this paper, we propose Event-Triggered Communication Network (ETCNet) to\nenhance the communication efficiency in multi-agent systems by sending messages\nonly when necessary. According to the information theory, the limited bandwidth\nis translated to the penalty threshold of an event-triggered strategy, which\ndetermines whether an agent at each step sends a message or not. Then the\ndesign of the event-triggered strategy is formulated as a constrained Markov\ndecision problem, and reinforcement learning finds the best communication\nprotocol that satisfies the limited bandwidth constraint. Experiments on\ntypical multi-agent tasks demonstrate that ETCNet outperforms other methods in\nterms of the reduction of bandwidth occupancy and still preserves the\ncooperative performance of multi-agent systems at the most.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.04978v1"
    },
    {
        "title": "Privacy-Preserving Distributed Projection LMS for Linear Multitask\n  Networks",
        "authors": [
            "Chengcheng Wang",
            "Wee Peng Tay",
            "Ye Wei",
            "Yuan Wang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We develop a privacy-preserving distributed projection least mean squares\n(LMS) strategy over linear multitask networks, where agents' local parameters\nof interest or tasks are linearly related. Each agent is interested in not only\nimproving its local inference performance via in-network cooperation with\nneighboring agents, but also protecting its own individual task against privacy\nleakage. In our proposed strategy, at each time instant, each agent sends a\nnoisy estimate, which is its local intermediate estimate corrupted by a\nzero-mean additive noise, to its neighboring agents. We derive a sufficient\ncondition to determine the amount of noise to add to each agent's intermediate\nestimate to achieve an optimal trade-off between the network\nmean-square-deviation and an inference privacy constraint. We propose a\ndistributed and adaptive strategy to compute the additive noise powers, and\nstudy the mean and mean-square behaviors and privacy-preserving performance of\nthe proposed strategy. Simulation results demonstrate that our strategy is able\nto balance the trade-off between estimation accuracy and privacy preservation.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.05527v1"
    },
    {
        "title": "Decentralized Multi-Agent Pursuit using Deep Reinforcement Learning",
        "authors": [
            "Cristino de Souza Jr",
            "Rhys Newbury",
            "Akansel Cosgun",
            "Pedro Castillo",
            "Boris Vidolov",
            "Dana Kulic"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Pursuit-evasion is the problem of capturing mobile targets with one or more\npursuers. We use deep reinforcement learning for pursuing an omni-directional\ntarget with multiple, homogeneous agents that are subject to unicycle kinematic\nconstraints. We use shared experience to train a policy for a given number of\npursuers that is executed independently by each agent at run-time. The training\nbenefits from curriculum learning, a sweeping-angle ordering to locally\nrepresent neighboring agents and encouraging good formations with reward\nstructure that combines individual and group rewards. Simulated experiments\nwith a reactive evader and up to eight pursuers show that our learning-based\napproach, with non-holonomic agents, performs on par with classical algorithms\nwith omni-directional agents, and outperforms their non-holonomic adaptations.\nThe learned policy is successfully transferred to the real world in a\nproof-of-concept demonstration with three motion-constrained pursuer drones.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08193v2"
    },
    {
        "title": "Model-free conventions in multi-agent reinforcement learning with\n  heterogeneous preferences",
        "authors": [
            "Raphael Köster",
            "Kevin R. McKee",
            "Richard Everett",
            "Laura Weidinger",
            "William S. Isaac",
            "Edward Hughes",
            "Edgar A. Duéñez-Guzmán",
            "Thore Graepel",
            "Matthew Botvinick",
            "Joel Z. Leibo"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Game theoretic views of convention generally rest on notions of common\nknowledge and hyper-rational models of individual behavior. However, decades of\nwork in behavioral economics have questioned the validity of both foundations.\nMeanwhile, computational neuroscience has contributed a modernized 'dual\nprocess' account of decision-making where model-free (MF) reinforcement\nlearning trades off with model-based (MB) reinforcement learning. The former\ncaptures habitual and procedural learning while the latter captures choices\ntaken via explicit planning and deduction. Some conventions (e.g. international\ntreaties) are likely supported by cognition that resonates with the game\ntheoretic and MB accounts. However, convention formation may also occur via MF\nmechanisms like habit learning; though this possibility has been understudied.\nHere, we demonstrate that complex, large-scale conventions can emerge from MF\nlearning mechanisms. This suggests that some conventions may be supported by\nhabit-like cognition rather than explicit reasoning. We apply MF multi-agent\nreinforcement learning to a temporo-spatially extended game with incomplete\ninformation. In this game, large parts of the state space are reachable only by\ncollective action. However, heterogeneity of tastes makes such coordinated\naction difficult: multiple equilibria are desirable for all players, but\nsubgroups prefer a particular equilibrium over all others. This creates a\ncoordination problem that can be solved by establishing a convention. We\ninvestigate start-up and free rider subproblems as well as the effects of group\nsize, intensity of intrinsic preference, and salience on the emergence dynamics\nof coordination conventions. Results of our simulations show agents establish\nand switch between conventions, even working against their own preferred\noutcome when doing so is necessary for effective coordination.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.09054v2"
    },
    {
        "title": "Algebraic Structures from Concurrent Constraint Programming Calculi for\n  Distributed Information in Multi-Agent Systems",
        "authors": [
            "Michell Guzmán",
            "Sophia Knight",
            "Santiago Quintero",
            "Sergio Ramírez",
            "Camilo Rueda",
            "Frank Valencia"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Spatial constraint systems (scs) are semantic structures for reasoning about\nspatial and epistemic information in concurrent systems. We develop the theory\nof scs to reason about the distributed information of potentially infinite\ngroups. We characterize the notion of distributed information of a group of\nagents as the infimum of the set of join-preserving functions that represent\nthe spaces of the agents in the group. We provide an alternative\ncharacterization of this notion as the greatest family of join-preserving\nfunctions that satisfy certain basic properties. For completely distributive\nlattices, we establish that distributed information of a group is the greatest\ninformation below all possible combinations of information in the spaces of the\nagents in the group that derive a given piece of information. We show\ncompositionality results for these characterizations and conditions under which\ninformation that can be obtained by an infinite group can also be obtained by a\nfinite group. Finally, we provide an application on mathematical morphology\nwhere dilations, one of its fundamental operations, define an scs on a powerset\nlattice. We show that distributed information represents a particular dilation\nin such scs.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.10667v2"
    },
    {
        "title": "Levels of Coupling in Dyadic Interaction: An Analysis of Neural and\n  Behavioral Complexity",
        "authors": [
            "Georgina Montserrat Reséndiz-Benhumea",
            "Ekaterina Sangati",
            "Tom Froese"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  From an enactive approach, some previous studies have demonstrated that\nsocial interaction plays a fundamental role in the dynamics of neural and\nbehavioral complexity of embodied agents. In particular, it has been shown that\nagents with a limited internal structure (2-neuron brains) that evolve in\ninteraction can overcome this limitation and exhibit chaotic neural activity,\ntypically associated with more complex dynamical systems (at least\n3-dimensional). In the present paper we make two contributions to this line of\nwork. First, we propose a conceptual distinction in levels of coupling between\nagents that could have an effect on neural and behavioral complexity. Second,\nwe test the generalizability of previous results by testing agents with richer\ninternal structure and evolving them in a richer, yet non-social, environment.\nWe demonstrate that such agents can achieve levels of complexity comparable to\nagents that evolve in interactive settings. We discuss the significance of this\nresult for the study of interaction.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.01727v1"
    },
    {
        "title": "In the Beginning there were n Agents: Founding and Amending a\n  Constitution",
        "authors": [
            "Ben Abramowitz",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Consider n agents forming an egalitarian, self-governed community. Their\nfirst task is to decide on a decision rule to make further decisions. We start\nfrom a rather general initial agreement on the decision-making process based\nupon a set of intuitive and self-evident axioms, as well as simplifying\nassumptions about the preferences of the agents. From these humble beginnings\nwe derive a decision rule. Crucially, the decision rule also specifies how it\ncan be changed, or amended, and thus acts as a de facto constitution. Our main\ncontribution is in providing an example of an initial agreement that is simple\nand intuitive, and a constitution that logically follows from it. The naive\nagreement is on the basic process of decision making - that agents approve or\ndisapprove proposals; that their vote determines either the acceptance or\nrejection of each proposal; and on the axioms, which are requirements regarding\na constitution that engenders a self-updating decision making process.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.03111v4"
    },
    {
        "title": "Differential Advising in Multi-Agent Reinforcement Learning",
        "authors": [
            "Dayong Ye",
            "Tianqing Zhu",
            "Zishuo Cheng",
            "Wanlei Zhou",
            "Philip S. Yu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Agent advising is one of the main approaches to improve agent learning\nperformance by enabling agents to share advice. Existing advising methods have\na common limitation that an adviser agent can offer advice to an advisee agent\nonly if the advice is created in the same state as the advisee's concerned\nstate. However, in complex environments, it is a very strong requirement that\ntwo states are the same, because a state may consist of multiple dimensions and\ntwo states being the same means that all these dimensions in the two states are\ncorrespondingly identical. Therefore, this requirement may limit the\napplicability of existing advising methods to complex environments. In this\npaper, inspired by the differential privacy scheme, we propose a differential\nadvising method which relaxes this requirement by enabling agents to use advice\nin a state even if the advice is created in a slightly different state.\nCompared with existing methods, agents using the proposed method have more\nopportunity to take advice from others. This paper is the first to adopt the\nconcept of differential privacy on advising to improve agent learning\nperformance instead of addressing security issues. The experimental results\ndemonstrate that the proposed method is more efficient in complex environments\nthan existing methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.03640v1"
    },
    {
        "title": "Modeling skier behavior for planning and management. Dynaski, an\n  agent-based in congested ski-areas",
        "authors": [
            "Alexis Poulhes",
            "Paul Mirial"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In leisure spaces, particularly theme parks and museums, researchers and\nmanagers have long been using simulation tools to tackle the big issue\nassociated with attractiveness, flow management. In this research, we present\nthe management and planning perspective of a multi-agent simulation tool which\nmodels the behavior of skiers in a ski-area. This is the first tool able to\nsimulate and compare management and planning scenarios as well as their impacts\non the comfort of skiers, in particular ski-area waiting times. This paper aims\nto integrate multiple data sources to calibrate the simulation on a real case\nstudy. An original field survey of users during a week details the skier\npopulation. The first average skier speeds are calculated from GPS data on one\nordinary day. The validation data are used to calibrate the parameters of the\nbehavioral model. A demonstration of the simulation tool is conducted on the La\nPlagne ski-area, one of the largest in France. A test case, the construction of\nnew housing in a station near the ski-area, is conducted. An addition of 1620\nnew skiers delays the skier average waiting time by 12 pourcents.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.11976v1"
    },
    {
        "title": "Coalition Control Model: A Dynamic Resource Distribution Method Based on\n  Model Predicative Control",
        "authors": [
            "Weizhi Du",
            "Harvey Tian"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Optimization of resource distribution has been a challenging topic in current\nsociety. To explore this topic, we develop a Coalition Control Model(CCM) based\non the Model Predictive Control(MPC) and test it using a fishing model with\nlinear parameters. The fishing model focuses on the problem of distributing\nfishing fleets in certain regions to maximize fish caught using either\nexhaustive or heuristic search. Our method introduces a communication mechanism\nto allow fishing fleets to merge or split, after which new coalitions can be\nautomatically formed. Having the coalition structure stabilized, the system\nreaches the equilibrium state through the Nash-Bargaining process. Our\nexperiments on the hypothetical fishing model demonstrated that the CCM can\ndynamically distribute limited resources in complex scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.12711v1"
    },
    {
        "title": "Rules of the Road: Safety and Liveness Guarantees for Autonomous\n  Vehicles",
        "authors": [
            "Karena X. Cai",
            "Tung Phan-Minh",
            "Soon-Jo Chung",
            "Richard M. Murray"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The ability to guarantee safety and progress for all vehicles is vital to the\nsuccess of the autonomous vehicle industry. We present a framework for\ndesigning autonomous vehicle behavior in a way that is safe and guarantees\nprogress for all agents. In this paper, we first introduce a new game paradigm\nwhich we term the quasi-simultaneous game. We then define an agent protocol\nthat all agents must use to make decisions in this quasi-simultaneous game\nsetting. According to the protocol, agents first select an intended action\nusing a behavioral profile. Then, the protocol defines whether an agent has\nprecedence to take its intended action or must take a sub-optimal action. The\nprotocol ensures safety under all traffic conditions and liveness for all\nagents under `sparse' traffic conditions. We provide proofs of correctness of\nthe protocol and validate our results in simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.14148v2"
    },
    {
        "title": "A Q-values Sharing Framework for Multiagent Reinforcement Learning under\n  Budget Constraint",
        "authors": [
            "Changxi Zhu",
            "Ho-fung Leung",
            "Shuyue Hu",
            "Yi Cai"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In teacher-student framework, a more experienced agent (teacher) helps\naccelerate the learning of another agent (student) by suggesting actions to\ntake in certain states. In cooperative multiagent reinforcement learning\n(MARL), where agents need to cooperate with one another, a student may fail to\ncooperate well with others even by following the teachers' suggested actions,\nas the polices of all agents are ever changing before convergence. When the\nnumber of times that agents communicate with one another is limited (i.e.,\nthere is budget constraint), the advising strategy that uses actions as advices\nmay not be good enough. We propose a partaker-sharer advising framework (PSAF)\nfor cooperative MARL agents learning with budget constraint. In PSAF, each\nQ-learner can decide when to ask for Q-values and share its Q-values. We\nperform experiments in three typical multiagent learning problems. Evaluation\nresults show that our approach PSAF outperforms existing advising methods under\nboth unlimited and limited budget, and we give an analysis of the impact of\nadvising actions and sharing Q-values on agents' learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.14281v1"
    },
    {
        "title": "Rankings for Bipartite Tournaments via Chain Editing",
        "authors": [
            "Joseph Singleton",
            "Richard Booth"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Ranking the participants of a tournament has applications in voting, paired\ncomparisons analysis, sports and other domains. In this paper we introduce\nbipartite tournaments, which model situations in which two different kinds of\nentity compete indirectly via matches against players of the opposite kind;\nexamples include education (students/exam questions) and solo sports\n(golfers/courses). In particular, we look to find rankings via chain graphs,\nwhich correspond to bipartite tournaments in which the sets of adversaries\ndefeated by the players on one side are nested with respect to set inclusion.\nTournaments of this form have a natural and appealing ranking associated with\nthem. We apply chain editing -- finding the minimum number of edge changes\nrequired to form a chain graph -- as a new mechanism for tournament ranking.\nThe properties of these rankings are investigated in a probabilistic setting,\nwhere they arise as maximum likelihood estimators, and through the axiomatic\nmethod of social choice theory. Despite some nice properties, two problems\nremain: an important anonymity axiom is violated, and chain editing is NP-hard.\nWe address both issues by relaxing the minimisation constraint in chain\nediting, and characterise the resulting ranking methods via a greedy\napproximation algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.02476v1"
    },
    {
        "title": "A negotiating protocol for group decision support systems",
        "authors": [
            "Safia Sadji"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Our contribution concerns interactive decision support systems for group\ndecision support. Through this study, we apply to implement a decisional\nprocess aiming to represent the multiplicity of actors, their diversity, their\nbehaviors and their interactions. In this context, we contribute to the design\nand development of a group decision support system. The system is modeled by a\nmulti agents system while exploiting a negotiation protocol based on mediation\nand concession. This protocol allows decision-makers to express their\npreferences using multicriteria analysis methods, mainly the method by total\naggregation AHP (Hierarchical Process Analysis) and the method by partial\naggregation PROMETHEE II .\n",
        "pdf_link": "http://arxiv.org/pdf/2101.03580v1"
    },
    {
        "title": "VIDA: A simulation model of domestic VIolence in times of social\n  DistAncing",
        "authors": [
            "Lígia Mori Madeira",
            "Bernardo Alves Furtado",
            "Alan Rafael Dill"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Violence against women occurs predominantly in the family and domestic\ncontext. The COVID-19 pandemic led Brazil to recommend and, at times, impose\nsocial distancing, with the partial closure of economic activities, schools,\nand restrictions on events and public services. Preliminary evidence shows that\nintense coexistence increases domestic violence, while social distancing\nmeasures may have prevented access to public services and networks,\ninformation, and help. We propose an agent-based model (ABM), called VIDA, to\nillustrate and examine multi-causal factors that influence events that generate\nviolence. A central part of the model is the multi-causal stress indicator,\ncreated as a probability trigger of domestic violence occurring within the\nfamily environment. Two experimental design tests were performed: (a) absence\nor presence of the deterrence system of domestic violence against women and (b)\nmeasures to increase social distancing. VIDA presents comparative results for\nmetropolitan regions and neighbourhoods considered in the experiments. Results\nsuggest that social distancing measures, particularly those encouraging staying\nat home, may have increased domestic violence against women by about 10%. VIDA\nsuggests further that more populated areas have comparatively fewer cases per\nhundred thousand women than less populous capitals or rural areas of urban\nconcentrations. This paper contributes to the literature by formalising, to the\nbest of our knowledge, the first model of domestic violence through agent-based\nmodelling, using empirical detailed socioeconomic, demographic, educational,\ngender, and race data at the intraurban level (census sectors).\n",
        "pdf_link": "http://arxiv.org/pdf/2101.04057v1"
    },
    {
        "title": "Energy-Optimal Goal Assignment of Multi-Agent System with Goal\n  Trajectories in Polynomials",
        "authors": [
            "Heeseung Bang",
            "Logan Beaver",
            "Andreas A. Malikopoulos"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper, we propose an approach for solving an energy-optimal goal\nassignment problem to generate the desired formation in multi-agent systems.\nEach agent solves a decentralized optimization problem with only local\ninformation about its neighboring agents and the goals. The optimization\nproblem consists of two sub-problems. The first problem seeks to minimize the\nenergy for each agent to reach certain goals, while the second problem entreats\nan optimal combination of goal and agent pairs that minimizes the energy cost.\nBy assuming the goal trajectories are given in a polynomial form, we prove the\nsolution to the formulated problem exists globally. Finally, the effectiveness\nof the proposed approach is validated through the simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.06288v1"
    },
    {
        "title": "Minimal Schedule with Minimal Number of Agents in Attack-Defence Trees",
        "authors": [
            "Jaime Arias",
            "Łukasz Maśko",
            "Wojciech Penczek",
            "Laure Petrucci",
            "Teofil Sidoruk"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Expressing attack-defence trees in a multi-agent setting allows for studying\na new aspect of security scenarios, namely how the number of agents and their\ntask assignment impact the performance, e.g. attack time, of strategies\nexecuted by opposing coalitions. Optimal scheduling of agents' actions, a\nnon-trivial problem, is thus vital. We discuss associated caveats and propose\nan algorithm that synthesises such an assignment, targeting minimal attack time\nand using minimal number of agents for a given attack-defence tree.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.06838v5"
    },
    {
        "title": "The Core of Approval Participatory Budgeting with Uniform Costs (or with\n  up to Four Projects) is Non-Empty",
        "authors": [
            "Reshef Meir"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In the Approval Participatory Budgeting problem an agent prefers a set of\nprojects $W'$ over $W$ if she approves strictly more projects in $W'$. A set of\nprojects $W$ is in the core, if there is no other set of projects $W'$ and set\nof agents $K$ that both prefer $W'$ over $W$ and can fund $W'$. It is an open\nproblem whether the core can be empty, even when project costs are uniform. the\nlatter case is known as the multiwinner voting core.\n  We show that in any instance with uniform costs or with at most four projects\n(and any number of agents), the core is nonempty.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.05082v3"
    },
    {
        "title": "Maintenance scheduling of manufacturing systems based on optimal price\n  of the network",
        "authors": [
            "Pegah Rokhforoz",
            "Olga Fink"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Goods can exhibit positive externalities impacting decisions of customers in\nsocials networks. Suppliers can integrate these externalities in their pricing\nstrategies to increase their revenue. Besides optimizing the prize, suppliers\nalso have to consider their production and maintenance costs. Predictive\nmaintenance has the potential to reduce the maintenance costs and improve the\nsystem availability. To address the joint optimization of pricing with network\nexternalities and predictive maintenance scheduling based on the condition of\nthe system, we propose a bi-level optimization solution based on game theory.\nIn the first level, the manufacturing company decides about the predictive\nmaintenance scheduling of the units and the price of the goods. In the second\nlevel, the customers decide about their consumption using an optimization\napproach in which the objective function depends on their consumption, the\nconsumption levels of other customers who are connected through the graph, and\nthe price of the network which is determined by the supplier. To solve the\nproblem, we propose the leader-multiple-followers game where the supplier as a\nleader predicts the strategies of the followers. Then, customers as the\nfollowers obtain their strategies based on the leader's and other followers'\nstrategies. We demonstrate the effectiveness of our proposed method on a\nsimulated case study. The results demonstrate that knowledge of the social\nnetwork graph results in an increased revenue compared to the case when the\nunderlying social network graph is not known. Moreover, the results demonstrate\nthat obtaining the predictive maintenance scheduling based on the proposed\noptimization approach leads to an increased profit compared to the baseline\ndecision-making (perform maintenance at the degradation limit).\n",
        "pdf_link": "http://arxiv.org/pdf/2104.06654v1"
    },
    {
        "title": "Pincer-Based vs. Same-Direction Strategies of Search for Smart Evaders\n  by Swarms of Agents",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Suppose in a given planar region, there are smart mobile evaders and we want\nto detect them using sweeping agents. We assume that the agents have line\nsensors of equal length. We propose procedures for designing cooperative\nsweeping processes that ensure successful completion of the task, thereby\nderiving conditions on the sweeping speed of the agents and their paths.\nSuccessful completion of the task means that evaders with a known limit on\ntheir speed cannot escape the sweeping agents. A simpler task for the sweeping\nswarm is the confinement of the evaders to their initial domain. The\nfeasibility of completing these tasks depends on geometric and dynamic\nconstraints that impose a lower bound on the speed the sweeping agent must\nhave. This critical speed is derived to ensure the satisfaction of the\nconfinement task. Increasing the speed above the lower bound enables the agents\nto complete the search task as well. We present a quantitative and qualitative\ncomparison analysis between the total search time of same-direction sweep\nprocesses and pincer-movement search strategies. We evaluate the different\nstrategies by using two metrics, total search time and the minimal critical\nspeed required for a successful search. We compare two types of pincer-movement\nsearch processes, circular and spiral, with their same-direction counterparts,\nfor any even number of sweeping agents. We prove that pincer based strategies\nprovide superior results in all practical scenarios and that the spiral pincer\nsweep process allows detection of all evaders while sweeping at nearly\ntheoretically optimal speeds.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.06940v2"
    },
    {
        "title": "Agent-based Framework for Self-Organization of Collective and Autonomous\n  Shuttle Fleets",
        "authors": [
            "Antonio Bucchiarone",
            "Martina De Sanctis",
            "Nelly Bencomo"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The mobility of people is at the center of transportation planning and\ndecision-making of the cities of the future. In order to accelerate the\ntransition to zero-emissions and to maximize air quality benefits, smart cities\nare prioritizing walking, cycling, shared mobility services and public\ntransport over the use of private cars. Extensive progress has been made in\nautonomous and electric cars. Autonomous Vehicles (AV) are increasingly capable\nof moving without full control of humans, automating some aspects of driving,\nsuch as steering or braking. For these reasons, cities are investing in the\ninfrastructure and technology needed to support connected, multi-modal transit\nnetworks that include shared electric Autonomous Vehicles (AV). The\nrelationship between traditional public transport and new mobility services is\nin the spotlight and need to be rethought. This paper proposes an agent-based\nsimulation framework that allows for the creation and simulation of mobility\nscenarios to investigate the impact of new mobility modes on a city daily life.\nIt lets traffic planners explore the cooperative integration of AV using a\ndecentralized control approach. A prototype has been implemented and validated\nwith data of the city of Trento.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.07494v1"
    },
    {
        "title": "Safe Affine Transformation-Based Guidance of a Large-Scale\n  Multi-Quadcopter System (MQS)",
        "authors": [
            "Hossein Rastgoftar",
            "Ilya Kolmanovsky"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper studies the problem of affine transformation-based guidance of a\nmulti-quadcopter system (MQS) in an obstacle-laden environment. Such MQSs can\nperform a variety of cooperative tasks including information collection,\ninspection mapping, disinfection, and firefighting. The MQS affine\ntransformation is an approach to a decentralized leader-follower coordination\nguided by n +1 leaders, where leaders are located at vertices of an n-D\nsimplex, called leading simplex, at any time t. The remaining agents are\nfollowers acquiring the desired affine transformation via local communication.\nFollowers are contained in a rigid-size ball at any time t but they can be\ndistributed either inside or outside the leading simplex. By\neigen-decomposition of the affine transformation coordination, safety in a\nlarge-scale MQS coordination can be ensured by constraining eigenvalues of the\naffine transformation. Given the initial and final configurations of the MQS,\nA-star search is applied to optimally plan safe coordination of a large-scale\nMQS minimizing the travel distance between the the initial and final\nconfiguration. The paper also proposes a proximity-based communication topology\nfor followers to assign communication weights with their in-neighbors and\nacquire the desired coordination with minimal computation cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.07741v1"
    },
    {
        "title": "Hercule: Representing and Reasoning about Norms as a Foundation for\n  Declarative Contracts over Blockchain",
        "authors": [
            "Samuel H. Christie V",
            "Amit K. Chopra",
            "Munindar P. Singh"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Current blockchain approaches for business contracts are based on smart\ncontracts, namely, software programs placed on a blockchain that are\nautomatically executed to realize a contract. However, smart contracts lack\nflexibility and interfere with the autonomy of the parties concerned.\n  We propose Hercule, an approach for declaratively specifying blockchain\napplications in a manner that reflects business contracts. Hercule represents a\ncontract via regulatory norms that capture the involved parties' expectations\nof one another. It computes the states of norms (hence, of contracts) from\nevents in the blockchain. Hercule's novelty and significance lie in that it\noperationalizes declarative contracts over semistructured databases, the\nunderlying representation for practical blockchain such as Hyperledger Fabric\nand Ethereum. Specifically, it exploits the map-reduce capabilities of such\nstores to compute norm states.\n  We demonstrate that our implementation over Hyperledger Fabric can process\nthousands of events per second, sufficient for many applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.08355v1"
    },
    {
        "title": "Continuum Deformation Coordination of Multi-Agent Systems Using\n  Cooperative Localization",
        "authors": [
            "Hossein Rastgoftar",
            "Sergey Nersesov",
            "Hashem Ashrafiuon"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper studies the problem of decentralized continuum deformation\ncoordination of multi-agent systems aided by cooperative localization. We treat\nagents as particles inside a triangular continuum (deformable body) in a2-D\nmotion space and let the continuum deformation coordination be defined by three\nleaders located at vertices of a triangle, called the leading triangle. The\nleaders desired trajectories are assigned as the solution of a constrained\noptimal control problem such that safety requirements are satisfied in the\npresence of disturbance and measurement noise. Followers distributed inside the\nleading tri-angle acquire continuum deformation in a decentralized fashion by\nintegrating cooperative localization and local communication. Specifically,\ncooperative localization estimates the global positions of all agents using\nrelative position measurements based primarily on proximity of agents.\nSimulation results are presented for a network of ten agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.09998v1"
    },
    {
        "title": "Searching with Opponent-Awareness",
        "authors": [
            "Timy Phan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We propose Searching with Opponent-Awareness (SOA), an approach to leverage\nopponent-aware planning without explicit or a priori opponent models for\nimproving performance and social welfare in multi-agent systems. To this end,\nwe develop an opponent-aware MCTS scheme using multi-armed bandits based on\nLearning with Opponent-Learning Awareness (LOLA) and compare its effectiveness\nwith other bandits, including UCB1. Our evaluations include several different\nsettings and show the benefits of SOA are especially evident with increasing\nnumber of agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.10508v1"
    },
    {
        "title": "Influence of group characteristics on agent voting",
        "authors": [
            "Marcin Maleszka"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  A collective of identical agents in a multi-agent system often works together\ntowards the common goal. In situations where no supervisor agents are present\nto make decisions for the group, these agents must achieve some consensus via\nnegotiations and other types of communications. We have previously shown that\nthe structure of the group and the priority of communication has a high\ninfluence on the group decision if consensus theory methods are used. In this\npaper, we explore the influence of preferential communication channels in\nasynchronous group communication in situations, where majority vote and\ndominant value are used. We also show how this relates to consensus approach in\nsuch groups and how to use a combination of both approaches to improve\nperformance of real-life multi-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.12473v1"
    },
    {
        "title": "Tracking and managing deemed abilities",
        "authors": [
            "Nicolas Troquard"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Information about the powers and abilities of acting entities is used to\ncoordinate their actions in societies, either physical or digital. Yet, the\ncommonsensical meaning of an acting entity being deemed able to do something is\nstill missing from the existing specification languages for the web or for\nmulti-agent systems. We advance a general purpose abstract logical account of\nevidence-based ability. A basic model can be thought of as the ongoing trace of\na multi-agent system. Every state records systemic confirmations and\ndisconfirmations of whether an acting entity is able to bring about something.\nQualitative inductive reasoning is then used in order to infer what acting\nentities are deemed able to bring about in the multi-agent system. A\ntemporalised modal language is used to talk about deemed ability, actual\nagency, and confirmation and disconfirmation of deemed ability. What\nconstitutes a confirmation and a disconfirmation is left to the modeller as in\ngeneral it depends on the application at hand. So to illustrate the methodology\nwe propose two extended examples, one in practical philosophy, the other in\nsystem engineering. We first use a logic of agency and ability to obtain a\nversion of Mele's general practical abilities. Then, we look at the management\nof abilities in a supervised system.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.14892v3"
    },
    {
        "title": "Coupling purposes with status-functions in artificial institutions",
        "authors": [
            "Rafhael R. Cunha",
            "Jomi Fred Hübner",
            "Maiquel de Brito"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In multi-agent systems, the agents may have goals that depend on a social,\nshared interpretation about the facts occurring in the system. These are the\nso-called social goals. Artificial institutions provide such a social\ninterpretation by assigning statuses to the concrete elements that compose the\nsystem. These statuses are supposed to enable the assignee element to perform\nfunctions that are not exclusively inherent to their design features. However,\nthe enabled functions are not explicit in the existing models of artificial\ninstitutions. As a consequence, (i) agents may have difficulties to reasoning\nabout how to achieve their own social goals with the help of artificial\ninstitutions and (ii) these institutions are not well instrumented to receive\nincoming agents, in the case of open systems. Considering those problems, this\npaper proposes a model to express the functions -- or the purposes --\nassociated with the status-functions helping the agents to reason about their\nsocial goals and the institution. We evaluate the model by using it in some\nscenarios, showing how the agents can use purposes to reason about the\nsatisfaction of their social goals in institutional contexts and how the\ninstitution can be flexible enough to support new agents operating in the\nsystem.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.00090v1"
    },
    {
        "title": "Run-time Norms Synthesis in Multi-Objective Multi-Agent Systems",
        "authors": [
            "Maha Riad",
            "Fatemeh Golpayegani"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Norms represent behavioural aspects that are encouraged by a social group of\nagents or the majority of agents in a system. Normative systems enable\ncoordinating synthesised norms of heterogeneous agents in complex multi-agent\nsystems autonomously. In real applications, agents have multiple objectives\nthat may contradict each other or contradict the synthesised norms. Therefore,\nagents need a mechanism to understand the impact of a suggested norm on their\nobjectives and decide whether or not to adopt it. To address these challenges,\na utility based norm synthesis (UNS) model is proposed which allows the agents\nto coordinate their behaviour while achieving their conflicting objectives. UNS\nproposes a utility-based case-based reasoning technique, using case-based\nreasoning for run-time norm synthesising in a centralised approach, and a\nutility function derived from the objectives of the system and its operating\nagents to decide whether or not to adopt a norm. The model is evaluated using a\ntwo intersecting roads scenario and the results show its efficacy to optimise\nmultiple objectives while adopting synthesised norms.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.00124v1"
    },
    {
        "title": "A Bayesian model of information cascades",
        "authors": [
            "Sriashalya Srivathsan",
            "Stephen Cranefield",
            "Jeremy Pitt"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  An information cascade is a circumstance where agents make decisions in a\nsequential fashion by following other agents. Bikhchandani et al., predict that\nonce a cascade starts it continues, even if it is wrong, until agents receive\nan external input such as public information. In an information cascade, even\nif an agent has its own personal choice, it is always overridden by observation\nof previous agents' actions. This could mean agents end up in a situation where\nthey may act without valuing their own information. As information cascades can\nhave serious social consequences, it is important to have a good understanding\nof what causes them. We present a detailed Bayesian model of the information\ngained by agents when observing the choices of other agents and their own\nprivate information. Compared to prior work, we remove the high impact of the\nfirst observed agent's action by incorporating a prior probability distribution\nover the information of unobserved agents and investigate an alternative model\nof choice to that considered in prior work: weighted random choice. Our results\nshow that, in contrast to Bikhchandani's results, cascades will not necessarily\noccur and adding prior agents' information will delay the effects of cascades.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03166v1"
    },
    {
        "title": "Solving social dilemmas by reasoning about expectations",
        "authors": [
            "Abira Sengupta",
            "Stephen Cranefield",
            "Jeremy Pitt"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  It has been argued that one role of social constructs, such as institutions,\ntrust and norms, is to coordinate the expectations of autonomous entities in\norder to resolve collective action situations (such as collective risk\ndilemmas) through the coordination of behaviour. While much work has addressed\nthe formal representation of these social constructs, in this paper we focus\nspecifically on the formal representation of, and associated reasoning with,\nthe expectations themselves. In particular, we investigate how explicit\nreasoning about expectations can be used to encode both traditional game theory\nsolution concepts and social mechanisms for the social dilemma situation. We\nuse the Collective Action Simulation Platform (CASP) to model a collective risk\ndilemma based on a flood plain scenario and show how using expectations in the\nreasoning mechanisms of the agents making decisions supports the choice of\ncooperative behaviour.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03552v1"
    },
    {
        "title": "A Social Distancing-Based Facility Location Approach for Combating\n  COVID-19",
        "authors": [
            "Suman Banerjee",
            "Bithika Pal",
            "Maheswar Singhamahapatra"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper, we introduce and study the problem of facility location along\nwith the notion of \\emph{`social distancing'}. The input to the problem is the\nroad network of a city where the nodes are the residential zones, edges are the\nroad segments connecting the zones along with their respective distance. We\nalso have the information about the population at each zone, different types of\nfacilities to be opened and in which number, and their respective demands in\neach zone. The goal of the problem is to locate the facilities such that the\npeople can be served and at the same time the total social distancing is\nmaximized. We formally call this problem as the \\textsc{Social Distancing-Based\nFacility Location Problem}. We mathematically quantify social distancing for a\ngiven allocation of facilities and proposed an optimization model. As the\nproblem is \\textsf{NP-Hard}, we propose a simulation-based and heuristic\napproach for solving this problem. A detailed analysis of both methods has been\ndone. We perform an extensive set of experiments with synthetic datasets. From\nthe results, we observe that the proposed heuristic approach leads to a better\nallocation compared to the simulation-based approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.04598v1"
    },
    {
        "title": "Using Distributed Reinforcement Learning for Resource Orchestration in a\n  Network Slicing Scenario",
        "authors": [
            "Federico Mason",
            "Gianfranco Nencioni",
            "Andrea Zanella"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The Network Slicing (NS) paradigm enables the partition of physical and\nvirtual resources among multiple logical networks, possibly managed by\ndifferent tenants. In such a scenario, network resources need to be dynamically\nallocated according to the slices' requirements. In this paper, we attack the\nabove problem by exploiting a Deep Reinforcement Learning approach. Our\nframework is based on a distributed architecture, where multiple agents\ncooperate towards a common goal. The agents' training is carried out following\nthe Advantage Actor Critic algorithm, which allows to handle continuous action\nspaces. By means of extensive simulations, we show that our approach yields\nbetter performance than both a static allocation of system resources and an\nefficient empirical strategy. At the same time, the proposed system ensures\nhigh adaptability to different scenarios without the need for additional\ntraining.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07946v1"
    },
    {
        "title": "To be a fast adaptive learner: using game history to defeat opponents",
        "authors": [
            "Guangzhao Cheng",
            "Siliang Tang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In many real-world games, such as traders repeatedly bargaining with\ncustomers, it is very hard for a single AI trader to make good deals with\nvarious customers in a few turns, since customers may adopt different\nstrategies even the strategies they choose are quite simple. In this paper, we\nmodel this problem as fast adaptive learning in the finitely repeated games. We\nbelieve that past game history plays a vital role in such a learning procedure,\nand therefore we propose a novel framework (named, F3) to fuse the past and\ncurrent game history with an Opponent Action Estimator (OAE) module that uses\npast game history to estimate the opponent's future behaviors. The experiments\nshow that the agent trained by F3 can quickly defeat opponents who adopt\nunknown new strategies. The F3 trained agent obtains more rewards in a fixed\nnumber of turns than the agents that are trained by deep reinforcement\nlearning. Further studies show that the OAE module in F3 contains\nmeta-knowledge that can even be transferred across different games.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08110v1"
    },
    {
        "title": "Learning to Win, Lose and Cooperate through Reward Signal Evolution",
        "authors": [
            "Rafal Muszynski",
            "Katja Hofmann",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Solving a reinforcement learning problem typically involves correctly\nprespecifying the reward signal from which the algorithm learns. Here, we\napproach the problem of reward signal design by using an evolutionary approach\nto perform a search on the space of all possible reward signals. We introduce a\ngeneral framework for optimizing $N$ goals given $n$ reward signals. Through\nexperiments we demonstrate that such an approach allows agents to learn\nhigh-level goals - such as winning, losing and cooperating - from scratch\nwithout prespecified reward signals in the game of Pong. Some of the solutions\nfound by the algorithm are surprising, in the sense that they would probably\nnot have been chosen by a person trying to hand-code a given behaviour through\na specific reward signal. Furthermore, it seems that the proposed approach may\nalso benefit from higher stability of the training performance when compared\nwith the typical score-based reward signals.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08187v1"
    },
    {
        "title": "Infection in a Confined Space using an Agent-Based Model",
        "authors": [
            "J. A. Sarumi",
            "E. C. Onwubiko",
            "O. L. A. Ogunjimi"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This study examined a simulated confined space modelled as a hospital waiting\narea, where people who could have underlying conditions congregate and mix with\npotentially infectious individuals. It further investigated the impact of the\nvolume of the waiting area, the number of people in the room, the placement of\nthem as well as their weight. The simulation is an agent-based model (ABM).\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10339v1"
    },
    {
        "title": "Evaluating Strategy Exploration in Empirical Game-Theoretic Analysis",
        "authors": [
            "Yongzhao Wang",
            "Qiurui Ma",
            "Michael P. Wellman"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In empirical game-theoretic analysis (EGTA), game models are extended\niteratively through a process of generating new strategies based on learning\nfrom experience with prior strategies. The strategy exploration problem in EGTA\nis how to direct this process so to construct effective models with minimal\niteration. A variety of approaches have been proposed in the literature,\nincluding methods based on classic techniques and novel concepts. Comparing the\nperformance of these alternatives can be surprisingly subtle, depending\nsensitively on criteria adopted and measures employed. We investigate some of\nthe methodological considerations in evaluating strategy exploration, defining\nkey distinctions and identifying a few general principles based on examples and\nexperimental observations. In particular, we emphasize the fact that empirical\ngames create a space of strategies that should be evaluated as a whole. Based\non this fact, we suggest that the minimum regret constrained profile (MRCP)\nprovides a particularly robust basis for evaluating a space of strategies, and\npropose a local search method for MRCP that outperforms previous approaches.\nHowever, the computation of MRCP is not always feasible especially in large\ngames. In this scenario, we highlight consistency considerations for comparing\nacross different approaches. Surprisingly, we find that recent works violate\nthese considerations that are necessary for evaluation, which may result in\nmisleading conclusions on the performance of different approaches. For proper\nevaluation, we propose a new evaluation scheme and demonstrate that our scheme\ncan reveal the true learning performance of different approaches compared to\nprevious evaluation methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10423v1"
    },
    {
        "title": "Towards open-ended evolutionary simulator for developing novel tumour\n  drug delivery systems",
        "authors": [
            "Igor Balaz",
            "Tara Petric",
            "Namid Stillman"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Tumours behave as moving targets that can evade chemotherapeutic treatments\nby rapidly acquiring resistance via various mechanisms. In Balaz et al. (2021,\nBiosystems; 199:104290) we initiated the development of the agent-based\nopen-ended evolutionary simulator of novel drug delivery systems (DDS). It is\nan agent-based simulator where evolvable agents can change their perception of\nthe environment and thus adapt to tumour mutations. Here we mapped the\nparameters of evolvable agent properties to the realistic biochemical\nboundaries and test their efficacy by simulating their behaviour at the cell\nscale using the stochastic simulator, STEPS. We show that the shape of the\nparameter space evolved in our simulator is comparable to those obtained by the\nrational design.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.11760v1"
    },
    {
        "title": "Towards a Very Large Scale Traffic Simulator for Multi-Agent\n  Reinforcement Learning Testbeds",
        "authors": [
            "Zijian Hu",
            "Chengxiang Zhuge",
            "Wei Ma"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Smart traffic control and management become an emerging application for Deep\nReinforcement Learning (DRL) to solve traffic congestion problems in urban\nnetworks. Different traffic control and management policies can be tested on\nthe traffic simulation. Current DRL-based studies are mainly supported by the\nmicroscopic simulation software (e.g., SUMO), while it is not suitable for\ncity-wide control due to the computational burden and gridlock effect. To the\nbest of our knowledge, there is a lack of studies on the large-scale traffic\nsimulator for DRL testbeds, which could further hinder the development of DRL.\nIn view of this, we propose a meso-macro traffic simulator for very large-scale\nDRL scenarios. The proposed simulator integrates mesoscopic and macroscopic\ntraffic simulation models to improve efficiency and eliminate gridlocks. The\nmesoscopic link model simulates flow dynamics on roads, and the macroscopic\nBathtub model depicts vehicle movement in regions. Moreover, both types of\nmodels can be hybridized to accommodate various DRL tasks. This creates portals\nfor mixed transportation applications under different contexts. The result\nshows that the developed simulator only takes 46 seconds to finish a 24-hour\nsimulation in a very large city with 2.2 million vehicles, which is much faster\nthan SUMO. Additionally, we develop a graphic interface for users to visualize\nthe simulation results in a web explorer. In the future, the developed\nmeso-macro traffic simulator could serve as a new environment for very\nlarge-scale DRL problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.13907v1"
    },
    {
        "title": "Iterative Empirical Game Solving via Single Policy Best Response",
        "authors": [
            "Max Olan Smith",
            "Thomas Anthony",
            "Michael P. Wellman"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Policy-Space Response Oracles (PSRO) is a general algorithmic framework for\nlearning policies in multiagent systems by interleaving empirical game analysis\nwith deep reinforcement learning (Deep RL). At each iteration, Deep RL is\ninvoked to train a best response to a mixture of opponent policies. The\nrepeated application of Deep RL poses an expensive computational burden as we\nlook to apply this algorithm to more complex domains. We introduce two\nvariations of PSRO designed to reduce the amount of simulation required during\nDeep RL training. Both algorithms modify how PSRO adds new policies to the\nempirical game, based on learned responses to a single opponent policy. The\nfirst, Mixed-Oracles, transfers knowledge from previous iterations of Deep RL,\nrequiring training only against the opponent's newest policy. The second,\nMixed-Opponents, constructs a pure-strategy opponent by mixing existing\nstrategy's action-value estimates, instead of their policies. Learning against\na single policy mitigates variance in state outcomes that is induced by an\nunobserved distribution of opponents. We empirically demonstrate that these\nalgorithms substantially reduce the amount of simulation during training\nrequired by PSRO, while producing equivalent or better solutions to the game.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.01901v1"
    },
    {
        "title": "UAV Swarm Path Planning with Reinforcement Learning for Field\n  prospecting",
        "authors": [
            "Alejandro Puente-Castro",
            "Daniel Rivero",
            "Alejandro Pazos",
            "Enrique Fernandez-Blanco"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Unmanned Aerial Vehicle (UAV) swarms adoption shows a steady growth among\noperators due to the benefits in time and cost arisen from their use. However,\nthis kind of system faces an important problem which is the calculation of many\noptimal paths for each UAV. Solving this problem would allow a to control many\nUAVs without human intervention at the same time while saving battery between\nrecharges and performing several tasks simultaneously. The main aim is to\ndevelop a system capable of calculating the optimal flight path for a UAV\nswarm. The aim of these paths is to achieve full coverage of a flight area for\ntasks such as field prospection. All this, regardless of the size of maps and\nthe number of UAVs in the swarm. It is not necessary to establish targets or\nany other previous knowledge other than the given map. Experiments have been\nconducted to determine whether it is optimal to establish a single control for\nall UAVs in the swarm or a control for each UAV. The results show that it is\nbetter to use one control for all UAVs because of the shorter flight time. In\naddition, the flight time is greatly affected by the size of the map. The\nresults give starting points for future research such as finding the optimal\nmap size for each situation.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.02322v1"
    },
    {
        "title": "RLupus: Cooperation through emergent communication in The Werewolf\n  social deduction game",
        "authors": [
            "Nicolo' Brandizzi",
            "Davide Grossi",
            "Luca Iocchi"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper focuses on the emergence of communication to support cooperation\nin environments modeled as social deduction games (SDG), that are games where\nplayers communicate freely to deduce each others' hidden intentions. We first\nstate the problem by giving a general formalization of SDG and a possible\nsolution framework based on reinforcement learning. Next, we focus on a\nspecific SDG, known as The Werewolf, and study if and how various forms of\ncommunication influence the outcome of the game. Experimental results show that\nintroducing a communication signal greatly increases the winning chances of a\nclass of players. We also study the effect of the signal's length and range on\nthe overall performance showing a non-linear relationship.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.05018v2"
    },
    {
        "title": "Analysis of Evolved Response Thresholds for Decentralized Dynamic Task\n  Allocation",
        "authors": [
            "H. David Mathias",
            "Annie S. Wu",
            "Daniel Dang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We investigate the application of a multi-objective genetic algorithm to the\nproblem of task allocation in a self-organizing, decentralized, threshold-based\nswarm. Each agent in our system is capable of performing four tasks with a\nresponse threshold for each, and we seek to assign response threshold values to\nall of the agents a swarm such that the collective behavior of the swarm is\noptimized. Random assignment of threshold values according to a uniform\ndistribution is known to be effective; however, this method does not consider\nfeatures of particular problem instances. Dynamic response thresholds have some\nflexibility to address problem specific features through real-time adaptivity,\noften improving swarm performance.\n  In this work, we use a multi-objective genetic algorithm to evolve response\nthresholds for a simulated swarm engaged in a dynamic task allocation problem:\ntwo-dimensional collective tracking. We show that evolved thresholds not only\noutperform uniformly distributed thresholds and dynamic thresholds but achieve\nnearly optimal performance on a variety of tracking problem instances (target\npaths). More importantly, we demonstrate that thresholds evolved for one of\nseveral problem instances generalize to all other problem instances eliminating\nthe need to evolve new thresholds for each problem to be solved. We analyze the\nproperties that allow these paths to serve as universal training instances and\nshow that they are quite natural.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06019v1"
    },
    {
        "title": "A Spatially Dependent Probabilistic Model for House Hunting in Ant\n  Colonies",
        "authors": [
            "Grace Cai",
            "Wendy Wu",
            "Wayne Zhao",
            "Jiajia Zhao",
            "Nancy Lynch"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Ant species such as Temnothorax albipennis select a new nest site in a\ndistributed fashion that, if modeled correctly, can serve as useful information\nfor site selection algorithms for robotic swarms and other applications.\nStudying and replicating the ants' house hunting behavior will also illuminate\nuseful distributed strategies that have evolved in nature. Many of the existing\nmodels of househunting behaviour for T. albipennis make the assumption that all\ncandidate nest sites are equally distant from the ants' home nest, or that an\nant has an equal probability of finding each candidate nest site. However,\nrealistically this is not the case, as nests that are further away from the\nhome nest and nests that are difficult to access are less likely to be found,\neven if they are of higher quality. We extend previous house-hunting models to\naccount for a pairwise distance metric between nests, compare our results to\nthose of real colonies, and use our results to examine the effects of house\nhunting in nests of different spatial orientations. Our incorporation of\ndistances in the ant model appear to match empirical data in situations where a\ndistance-quality tradeoff between nests is relevant. Furthermore, the model\ncontinues to be on par with previous house-hunting models in experiments where\nall candidate nests are equidistant from the home nest, as is typically\nassumed.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06867v1"
    },
    {
        "title": "A learning agent that acquires social norms from public sanctions in\n  decentralized multi-agent settings",
        "authors": [
            "Eugene Vinitsky",
            "Raphael Köster",
            "John P. Agapiou",
            "Edgar Duéñez-Guzmán",
            "Alexander Sasha Vezhnevets",
            "Joel Z. Leibo"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Society is characterized by the presence of a variety of social norms:\ncollective patterns of sanctioning that can prevent miscoordination and\nfree-riding. Inspired by this, we aim to construct learning dynamics where\npotentially beneficial social norms can emerge. Since social norms are\nunderpinned by sanctioning, we introduce a training regime where agents can\naccess all sanctioning events but learning is otherwise decentralized. This\nsetting is technologically interesting because sanctioning events may be the\nonly available public signal in decentralized multi-agent systems where reward\nor policy-sharing is infeasible or undesirable. To achieve collective action in\nthis setting we construct an agent architecture containing a classifier module\nthat categorizes observed behaviors as approved or disapproved, and a\nmotivation to punish in accord with the group. We show that social norms emerge\nin multi-agent systems containing this agent and investigate the conditions\nunder which this helps them achieve socially beneficial outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.09012v5"
    },
    {
        "title": "Policy Regularization via Noisy Advantage Values for Cooperative\n  Multi-agent Actor-Critic methods",
        "authors": [
            "Jian Hu",
            "Siyue Hu",
            "Shih-wei Liao"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Recent works have applied the Proximal Policy Optimization (PPO) to the\nmulti-agent cooperative tasks, such as Independent PPO (IPPO); and vanilla\nMulti-agent PPO (MAPPO) which has a centralized value function. However,\nprevious literature shows that MAPPO may not perform as well as Independent PPO\n(IPPO) and the Fine-tuned QMIX on Starcraft Multi-Agent Challenge (SMAC).\nMAPPO-Feature-Pruned (MAPPO-FP) improves the performance of MAPPO by the\ncarefully designed agent-specific features, which may be not friendly to\nalgorithmic utility. By contrast, we find that MAPPO may face the problem of\n\\textit{The Policies Overfitting in Multi-agent Cooperation(POMAC)}, as they\nlearn policies by the sampled advantage values. Then POMAC may lead to updating\nthe multi-agent policies in a suboptimal direction and prevent the agents from\nexploring better trajectories. In this paper, to mitigate the multi-agent\npolicies overfitting, we propose a novel policy regularization method, which\ndisturbs the advantage values via random Gaussian noise. The experimental\nresults show that our method outperforms the Fine-tuned QMIX, MAPPO-FP, and\nachieves SOTA on SMAC without agent-specific features. We open-source the code\nat \\url{https://github.com/hijkzzz/noisy-mappo}.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.14334v14"
    },
    {
        "title": "Distributed Multi-agent Navigation Based on Reciprocal Collision\n  Avoidance and Locally Confined Multi-agent Path Finding",
        "authors": [
            "Stepan Dergachev",
            "Konstantin Yakovlev"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Avoiding collisions is the core problem in multi-agent navigation. In\ndecentralized settings, when agents have limited communication and sensory\ncapabilities, collisions are typically avoided in a reactive fashion, relying\non local observations/communications. Prominent collision avoidance techniques,\ne.g. ORCA, are computationally efficient and scale well to a large number of\nagents. However, in numerous scenarios, involving navigation through the tight\npassages or confined spaces, deadlocks are likely to occur due to the egoistic\nbehaviour of the agents and as a result, the latter can not achieve their\ngoals. To this end, we suggest an application of the locally confined\nmulti-agent path finding (MAPF) solvers that coordinate sub-groups of the\nagents that appear to be in a deadlock (to detect the latter we suggest a\nsimple, yet efficient ad-hoc routine). We present a way to build a grid-based\nMAPF instance, typically required by modern MAPF solvers. We evaluate two of\nthem in our experiments, i.e. Push and Rotate and a bounded-suboptimal version\nof Conflict Based Search (ECBS), and show that their inclusion into the\nnavigation pipeline significantly increases the success rate, from 15% to 99%\nin certain cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00246v1"
    },
    {
        "title": "Reinforcement Learning Provides a Flexible Approach for Realistic Supply\n  Chain Safety Stock Optimisation",
        "authors": [
            "Edward Elson Kosasih",
            "Alexandra Brintrup"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Although safety stock optimisation has been studied for more than 60 years,\nmost companies still use simplistic means to calculate necessary safety stock\nlevels, partly due to the mismatch between existing analytical methods'\nemphases on deriving provably optimal solutions and companies' preferences to\nsacrifice optimal results in favour of more realistic problem settings. A newly\nemerging method from the field of Artificial Intelligence (AI), namely\nReinforcement Learning (RL), offers promise in finding optimal solutions while\naccommodating more realistic problem features. Unlike analytical-based models,\nRL treats the problem as a black-box simulation environment mitigating against\nthe problem of oversimplifying reality. As such, assumptions on stock keeping\npolicy can be relaxed and a higher number of problem variables can be\naccommodated. While RL has been popular in other domains, its applications in\nsafety stock optimisation remain scarce. In this paper, we investigate three RL\nmethods, namely, Q-Learning, Temporal Difference Advantage Actor-Critic and\nMulti-agent Temporal Difference Advantage Actor-Critic for optimising safety\nstock in a linear chain of independent agents. We find that RL can\nsimultaneously optimise both safety stock level and order quantity parameters\nof an inventory policy, unlike classical safety stock optimisation models where\nonly safety stock level is optimised while order quantity is predetermined\nbased on simple rules. This allows RL to model more complex supply chain\nprocurement behaviour. However, RL takes longer time to arrive at solutions,\nnecessitating future research on identifying and improving trade-offs between\nthe use of AI and mathematical models are needed.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00913v1"
    },
    {
        "title": "Hierarchical Planning for Dynamic Resource Allocation in Smart and\n  Connected Communities",
        "authors": [
            "Geoffrey Pettet",
            "Ayan Mukhopadhyay",
            "Mykel J. Kochenderfer",
            "Abhishek Dubey"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Resource allocation under uncertainty is a classical problem in city-scale\ncyber-physical systems. Consider emergency response as an example; urban\nplanners and first responders optimize the location of ambulances to minimize\nexpected response times to incidents such as road accidents. Typically, such\nproblems deal with sequential decision-making under uncertainty and can be\nmodeled as Markov (or semi-Markov) decision processes. The goal of the\ndecision-maker is to learn a mapping from states to actions that can maximize\nexpected rewards. While online, offline, and decentralized approaches have been\nproposed to tackle such problems, scalability remains a challenge for\nreal-world use-cases. We present a general approach to hierarchical planning\nthat leverages structure in city-level CPS problems for resource allocation. We\nuse emergency response as a case study and show how a large resource allocation\nproblem can be split into smaller problems. We then use Monte-Carlo planning\nfor solving the smaller problems and managing the interaction between them.\nFinally, we use data from Nashville, Tennessee, a major metropolitan area in\nthe United States, to validate our approach. Our experiments show that the\nproposed approach outperforms state-of-the-art approaches used in the field of\nemergency response.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.01292v2"
    },
    {
        "title": "Can We Replicate Real Human Behaviour Using Artificial Neural Networks?",
        "authors": [
            "Georg Jäger",
            "Daniel Reisinger"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Agent-based modelling is a powerful tool when simulating human systems, yet\nwhen human behaviour cannot be described by simple rules or maximising one's\nown profit, we quickly reach the limits of this methodology. Machine learning\nhas the potential to bridge this gap by providing a link between what people\nobserve and how they act in order to reach their goal. In this paper we use a\nframework for agent-based modelling that utilizes human values like fairness,\nconformity and altruism. Using this framework we simulate a public goods game\nand compare to experimental results. We can report good agreement between\nsimulation and experiment and furthermore find that the presented framework\noutperforms strict reinforcement learning. Both the framework and the utility\nfunction are generic enough that they can be used for arbitrary systems, which\nmakes this method a promising candidate for a foundation of a universal\nagent-based model.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.04267v2"
    },
    {
        "title": "Provider-centric Allocation of Drone Swarm Services",
        "authors": [
            "Balsam Alkouz",
            "Athman Bouguettaya"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We propose a novel framework for the allocation of drone swarms for delivery\nservices known as Swarm-based Drone-as-a-Service (SDaaS). The allocation\nframework ensures minimum cost (aka maximum profit) to drone swarm providers\nwhile meeting the time requirement of service consumers. The constraints in the\ndelivery environment (e.g., limited recharging pads) are taken into\nconsideration. We propose three algorithms to select the best allocation of\ndrone swarms given a set of requests from multiple consumers. We conduct a set\nof experiments to evaluate and compare the efficiency of these algorithms\nconsidering the provider's profit, feasibility, requests fulfilment, and drones\nutilization level.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.05173v1"
    },
    {
        "title": "Asynchronous games on Petri nets and ATL",
        "authors": [
            "Federica Adobbati",
            "Luca Bernardinello",
            "Lucia Pomello"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We define a game on distributed Petri nets, where several players interact\nwith each other, and with an environment. The players, or users, have perfect\nknowledge of the current state, and pursue a common goal. Such goal is\nexpressed by Alternating-time Temporal Logic (ATL). The users have a winning\nstrategy if they can cooperate to reach their goal, no matter how the\nenvironment behaves. We show that such a game can be translated into a game on\nconcurrent game structures (introduced in order to give a semantics to ATL). We\ncompare our game with the game on concurrent game structures and discuss the\ndifferences between the two approaches. Finally, we show that, when we consider\nmemoryless strategies and a fragment of ATL, we can construct a concurrent game\nstructure from the Petri net, such that an ATL formula is verified on the net\nif, and only if, it is verified on the game structure.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.06866v1"
    },
    {
        "title": "An agent-based model for modal shift in public transport",
        "authors": [
            "Thibaut Barbet",
            "Amine Nacer-Weill",
            "Changtao Yang",
            "Juste Raimbault"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Modal shift in public transport as a consequence of a disruption on a line\nhas in some cases unforeseen consequences such as an increase in congestion in\nthe rest of the network. How information is provided to users and their\nbehavior plays a central role in such configurations. We introduce here a\nsimple and stylised agent-based model aimed at understanding the impact of\nbehavioural parameters on modal shift. The model is applied on a case study\nbased on a stated preference survey for a segment of Paris suburban train\nnetwork. We systematically explore the parameter space and show non-trivial\npatterns of congestion for some values of discrete choice parameters linked to\nperceived wait time and congestion. We also apply a genetic optimisation\nalgorithm to the model to search for optimal compromises between congestion in\ndifferent modes.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.11399v1"
    },
    {
        "title": "Resource-Aware Adaptation of Heterogeneous Strategies for Coalition\n  Formation",
        "authors": [
            "Anusha Srikanthan",
            "Harish Ravichandar"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Existing approaches to coalition formation often assume that requirements\nassociated with tasks are precisely specified by the human operator. However,\nprior work has demonstrated that humans, while extremely adept at solving\ncomplex problems, struggle to explicitly state their solution strategy.\nFurther, existing approaches often ignore the fact that experts may utilize\ndifferent, but equally-valid, solutions (i.e., heterogeneous strategies) to the\nsame problem. In this work, we propose a two-part framework to address these\nchallenges. First, we tackle the challenge of inferring implicit strategies\ndirectly from expert demonstrations of coalition formation. To this end, we\nmodel and infer such heterogeneous strategies as capability-based requirements\nassociated with each task. Next, we propose a method capable of adaptively\nselecting one of the inferred strategies that best suits the target team\nwithout requiring additional training. Specifically, we formulate and solve a\nconstrained optimization problem that simultaneously selects the most\nappropriate strategy given the target team's capabilities, and allocates its\nconstituents into appropriate coalitions. We evaluate our approach against\nseveral baselines, including some that resemble existing approaches, using\ndetailed numerical simulations, StarCraft II battles, and a multi-robot\nemergency-response scenario. Our results indicate that our framework\nconsistently outperforms all baselines in terms of requirement satisfaction,\nresource utilization, and task success rates.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.02733v2"
    },
    {
        "title": "Game Theory and Machine Learning in UAVs-Assisted Wireless Communication\n  Networks: A Survey",
        "authors": [
            "M. Zhou",
            "Y. Guan",
            "M. Hayajneh",
            "K. Niu",
            "C. Abdallah"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In recent years, Unmanned Aerial Vehicles (UAVs) have been used in fields\nsuch as architecture, business delivery, military and civilian theaters, and\nmany others. With increased applications comes the increased demand for\nadvanced algorithms for resource allocation and energy management. As is well\nknown, game theory and machine learning are two powerful tools already widely\nused in the wireless communication field and there are numerous surveys of game\ntheory and machine learning usage in wireless communication. Existing surveys\nhowever focus either on game theory or machine learning and due to this fact,\nthe current article surveys both game-theoretic and machine learning algorithms\nfor use by UAVs in Wireless Communication Networks (U-WCNs). We also discuss\nhow to combine game theory and machine learning for solving problems in U-WCNs\nand identify several future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.03495v1"
    },
    {
        "title": "Graph Attention Network-based Multi-agent Reinforcement Learning for\n  Slicing Resource Management in Dense Cellular Network",
        "authors": [
            "Yan Shao",
            "Rongpeng Li",
            "Bing Hu",
            "Yingxiao Wu",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Network slicing (NS) management devotes to providing various services to meet\ndistinct requirements over the same physical communication infrastructure and\nallocating resources on demands. Considering a dense cellular network scenario\nthat contains several NS over multiple base stations (BSs), it remains\nchallenging to design a proper real-time inter-slice resource management\nstrategy, so as to cope with frequent BS handover and satisfy the fluctuations\nof distinct service requirements. In this paper, we propose to formulate this\nchallenge as a multi-agent reinforcement learning (MARL) problem in which each\nBS represents an agent. Then, we leverage graph attention network (GAT) to\nstrengthen the temporal and spatial cooperation between agents. Furthermore, we\nincorporate GAT into deep reinforcement learning (DRL) and correspondingly\ndesign an intelligent real-time inter-slice resource management strategy. More\nspecially, we testify the universal effectiveness of GAT for advancing DRL in\nthe multi-agent system, by applying GAT on the top of both the value-based\nmethod deep Q-network (DQN) and a combination of policy-based and value-based\nmethod advantage actor-critic (A2C). Finally, we verify the superiority of the\nGAT-based MARL algorithms through extensive simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.05063v1"
    },
    {
        "title": "Developer Operations and Engineering Multi-Agent Systems",
        "authors": [
            "Timotheus Kampik",
            "Cleber Jorge Amaral",
            "Jomi Fred Hübner"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper, we propose the integration of approaches to Engineering\nMulti-Agent Systems (EMAS) with the Developer Operations (DevOps) industry best\npractice. Whilst DevOps facilitates the organizational autonomy of software\nteams, as well as the technological automation of testing, deployment, and\noperations pipelines, EMAS and the agent-oriented programming paradigm help\ninstill autonomy into software artifacts. We discuss the benefits of\nintegrating DevOps and EMAS, for example by highlighting the need for\nagent-oriented abstractions for quality assurance and test automation\napproaches. More generally, we introduce an agent-oriented perspective on the\nDevOps life-cycle and list a range of research challenges that are relevant for\nthe integration of the DevOps and EMAS perspectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.08117v1"
    },
    {
        "title": "Heterogeneous Graph Attention Networks for Learning Diverse\n  Communication",
        "authors": [
            "Esmaeil Seraj",
            "Zheyuan Wang",
            "Rohan Paleja",
            "Matthew Sklar",
            "Anirudh Patel",
            "Matthew Gombolay"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi-agent teaming achieves better performance when there is communication\namong participating agents allowing them to coordinate their actions for\nmaximizing shared utility. However, when collaborating a team of agents with\ndifferent action and observation spaces, information sharing is not\nstraightforward and requires customized communication protocols, depending on\nsender and receiver types. Without properly modeling such heterogeneity in\nagents, communication becomes less helpful and could even deteriorate the\nmulti-agent cooperation performance. We propose heterogeneous graph attention\nnetworks, called HetNet, to learn efficient and diverse communication models\nfor coordinating heterogeneous agents towards accomplishing tasks that are of\ncollaborative nature. We propose a Multi-Agent Heterogeneous Actor-Critic\n(MAHAC) learning paradigm to obtain collaborative per-class policies and\neffective communication protocols for composite robot teams. Our proposed\nframework is evaluated against multiple baselines in a complex environment in\nwhich agents of different types must communicate and cooperate to satisfy the\nobjectives. Experimental results show that HetNet outperforms the baselines in\nlearning sophisticated multi-agent communication protocols by achieving\n$\\sim$10\\% improvements in performance metrics.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.09568v2"
    },
    {
        "title": "GRAL: Localization of Floating Wireless Sensors in Pipe Networks",
        "authors": [
            "Martin Haug",
            "Felix Lorenz",
            "Lauritz Thamsen"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Mobile wireless sensors are increasingly recognized as a valuable tool for\nmonitoring critical infrastructures. An important use case is the discovery of\nleaks and inflows in pipe networks using a swarm of floating sensor nodes.\nWhile passively drifting along, the devices must track their individual\npositions so critical points can later be located. Since pipelines are often\nsituated in inaccessible places, large portions of the network can be shielded\nfrom radio and satellite signals, rendering conventional positioning systems\nineffective.\n  In this paper, we propose a novel algorithm for assigning location estimates\nto recorded measurements once the sensor node leaves the inaccessible area and\ntransmits them via a gateway. The solution is range-free and makes use of a\npriori information about the target pipeline network. We further describe two\nextended variants of our algorithm which use data of encounters with other\nsensor nodes to improve accuracy. Finally, we evaluate all variants with\nrespect to various network topologies and different numbers of mobile nodes in\na simulation. The results show that our algorithm localizes measurements with\nan average accuracy between 4.81% and 7.58%, depending on the variability of\nflow speed and the sparsity of reference points.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.00294v1"
    },
    {
        "title": "Modelling Strategic Deceptive Planning in Adversarial Multi-Agent\n  Systems",
        "authors": [
            "Lyndon Benke",
            "Michael Papasimeon",
            "Tim Miller"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Deception is virtually ubiquitous in warfare, and should be a central\nconsideration for military operations research. However, studies of agent\nbehaviour in simulated operations have typically neglected to include explicit\nmodels of deception. This paper proposes that a computational model that\napproximates the human deceptive planning process would enable the authentic\nrepresentation of strategic deception in multi-agent systems. The proposed\ndeceptive planning model provides a framework for studying, explaining, and\ndiscovering deceptive behaviours, enabling the generation of novel solutions to\nadversarial planning problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.03092v1"
    },
    {
        "title": "A Scalable Last-Mile Delivery Service: From Simulation to Scaled\n  Experiment",
        "authors": [
            "Meera Ratnagiri",
            "Clare O'Dwyer",
            "Logan E. Beaver",
            "Heeseung Bang",
            "Behdad Chalaki",
            "Andreas A. Malikopoulos"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper, we investigate the problem of a last-mile delivery service\nthat selects up to $N$ available vehicles to deliver $M$ packages from a\ncentralized depot to $M$ delivery locations. The objective of the last-mile\ndelivery service is to jointly maximize customer satisfaction (minimize\ndelivery time) and minimize operating cost (minimize total travel time) by\nselecting the optimal number of vehicles to perform the deliveries. We model\nthis as an assignment (vehicles to packages) and path planning (determining the\ndelivery order and route) problem, which is equivalent to the NP-hard multiple\ntraveling salesperson problem. We propose a scalable heuristic algorithm, which\nsacrifices some optimality to achieve a reasonable computational cost for a\nhigh number of packages. The algorithm combines hierarchical clustering with a\ngreedy search. To validate our approach, we compare the results of our\nsimulation to experiments in a $1$:$25$ scale robotic testbed for future\nmobility systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.05995v1"
    },
    {
        "title": "Enriching a CP-Net by Asymmetric Merging",
        "authors": [
            "Stijn Henckens",
            "Mostafa Mohajeri Parizi",
            "Giovanni Sileno"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Conditional ceteris paribus preference networks (CP-nets) are commonly used\nto capture qualitative conditional preferences. In many use cases, when the\npreferential structure of an agent is incomplete, information from other\npreferential structures (e.g. that of other users) preferences can be used to\nfill in the gaps. Earlier works proposed methods to symmetrically merge\nmultiple incomplete CP-nets by means of voting semantics. However, the merged\nCP-net can contain preference relations that do not fit to a given user's\noriginal preference profile. This paper proposes an asymmetric merging (or\nenriching) method to obtain and fill-in preference relations of a user's CP-net\nfrom another CP-net in a way that preserves the original preference relations.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.10110v1"
    },
    {
        "title": "An Efficient Simulation-Based Travel Demand Calibration Algorithm for\n  Large-Scale Metropolitan Traffic Models",
        "authors": [
            "Neha Arora",
            "Yi-fan Chen",
            "Sanjay Ganapathy",
            "Yechen Li",
            "Ziheng Lin",
            "Carolina Osorio",
            "Andrew Tomkins",
            "Iveel Tsogsuren"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Metropolitan scale vehicular traffic modeling is used by a variety of private\nand public sector urban mobility stakeholders to inform the design and\noperations of road networks. High-resolution stochastic traffic simulators are\nincreasingly used to describe detailed demand-supply interactions. The design\nof efficient calibration techniques remains a major challenge. This paper\nconsiders a class of high-dimensional calibration problems known as\norigin-destination (OD) calibration. We formulate the problem as a continuous\nsimulation-based optimization problem. Our proposed algorithm builds upon\nrecent metamodel methods that tackle the simulation-based problem by solving a\nsequence of approximate analytical optimization problems, which rely on the use\nof analytical network models. In this paper, we formulate a network model\ndefined as a system of linear equations, the dimension of which scales linearly\nwith the number of roads with field data and independently of the dimension of\nthe route choice set. This makes the approach suitable for large-scale\nmetropolitan networks. The approach has enhanced efficiency compared with past\nmetamodel formulations that are based on systems of nonlinear, rather than\nlinear, equations. It also has enhanced efficiency compared to traditional\ncalibration methods that resort to simulation-based estimates of traffic\nassignment matrices, while the proposed approach uses analytical approximations\nof these matrices. We benchmark the approach considering a peak period Salt\nLake City case study and calibrate based on field vehicular count data. The new\nformulation yields solutions with good performance and is suitable for\nlarge-scale road networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.11392v1"
    },
    {
        "title": "The use of multi-agent systems for modeling technological processes",
        "authors": [
            "Sergey Petrovich Bobkov",
            "Irina Aleksandrovna Astrakhantseva"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The article is devoted to the issues of using discrete simulation models for\nmodeling some basic technological processes. In the scientific work, models in\nthe form of multi-agent systems have been investigated, which allow us to\nconsider a continuous environment as a set of interacting elements (agents),\nthe behavior of which obeys local functions. The authors describe the basic\ntechniques and general methodology for the development of deterministic\nagent-based models. The paper considers the use of multi-agent systems for\nmodeling thermal conductivity, taking into account the nonlinearity of the\nprocess, in homogeneity of the material and the presence of volumetric heat\nsources of variable power in it. The obtained scientific results are in good\nagreement with the generally accepted classical approaches and do not\ncontradict the provisions adopted in the theory of thermal phenomena.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.13196v1"
    },
    {
        "title": "A Spatial Agent-Based Model for Preemptive Evacuation Decisions During\n  Typhoon",
        "authors": [
            "Rey C. Rodrigueza",
            "Maria Regina Justina E. Estuar"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Natural disasters continue to cause tremendous damage to human lives and\nproperties. The Philippines, due to its geographic location, is considered a\nnatural disaster-prone country experiencing an average of 20 tropical cyclones\nannually. Understanding what factors significantly affect decision making\nduring crucial evacuation stages could help in making decisions on how to\nprepare for disasters, how to act appropriately and strategically respond\nduring and after a calamity. In this work, an agent-based model for preemptive\nevacuation decisions during typhoon is presented. In the model, civilians are\nrepresented by households and their evacuation decisions were based from\ncalculated perceived risk. Also, rescuer and shelter manager agents were\nincluded as facilitators during the preemptive evacuation process. National and\nmunicipal census data were employed in the model, particularly for the\ndemographics of household agents. Further, geospatial data of a village in a\ntyphoon-susceptible municipality was used to represent the environment. The\ndecision to evacuate or not to evacuate depends on the agent's perceived risk\nwhich also depends on three decision factors: characteristics of the decision\nmaker (CDM); capacity related factors (CRF); and hazard related factors (HRF).\nFinally, the number of households who decided to evacuate or opted to stay as\ninfluenced by the model`s decision factors were determined during simulations.\nSensitivity analysis using linear regression shows that all parameters used in\nthe model are significant in the evacuation decision of household agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.14459v1"
    },
    {
        "title": "Achieving safe minimum circle circumnavigation around multiple targets:\n  a dynamic compensation approach",
        "authors": [
            "Chao Wang",
            "Yingjing Shi",
            "Rui Li",
            "Yongduan Song"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Minimum circle circumnavigation is proposed in this paper, which is of\nspecial value in target monitoring, capturing and/or attacking. In this paper,\na safe minimum circle circumnavigation of multiple targets based on bearing\nmeasurements is studied. In contrast with the traditional circumnavigation\nproblem, with the new pattern, one agent is able to enclose multiple targets\nalong a minimum circle with the desired enclosing distance and tangential\nspeed. To achieve the minimum circle circumnavigation, an algorithm including\ndynamic compensators and a control protocol is proposed, by which collision is\navoided between the agent and the multiple targets during the whole moving\nprocess. Moreover, the control protocol developed for a single agent is further\nextended to the scenarios of multiple agents by adding a coordination mechanism\ninto the tangential velocity term, which drives the agents to distribute evenly\non each expected circular orbit with the same radius or different radius.\nSimulations results illustrate the effectiveness of the proposed methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.05103v1"
    },
    {
        "title": "Directionality Reinforcement Learning to Operate Multi-Agent System\n  without Communication",
        "authors": [
            "Fumito Uwano",
            "Keiki Takadama"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper establishes directionality reinforcement learning (DRL) technique\nto propose the complete decentralized multi-agent reinforcement learning method\nwhich can achieve cooperation based on each agent's learning: no communication\nand no observation. Concretely, DRL adds the direction \"agents have to learn to\nreach the farthest goal among reachable ones\" to learning agents to operate the\nagents cooperatively. Furthermore, to investigate the effectiveness of the DRL,\nthis paper compare Q-learning agent with DRL with previous learning agent in\nmaze problems. Experimental results derive that (1) DRL performs better than\nthe previous method in terms of the spending time, (2) the direction makes\nagents learn yielding action for others, and (3) DRL suggests achieving\nmultiagent learning with few costs for any number of agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.05773v1"
    },
    {
        "title": "An Artificial Bee Colony Based Algorithm for Continuous Distributed\n  Constraint Optimization Problems",
        "authors": [
            "K. M. Merajul Arefin",
            "Mashrur Rashik",
            "Saaduddin Mahmud",
            "Md. Mosaddek Khan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Distributed Constraint Optimization Problems (DCOPs) are a frequently used\nframework in which a set of independent agents choose values from their\nrespective discrete domains to maximize their utility. Although this\nformulation is typically appropriate, there are a number of real-world\napplications in which the decision variables are continuous-valued and the\nconstraints are represented in functional form. To address this, Continuous\nDistributed Constraint Optimization Problems (C-DCOPs), an extension of the\nDCOPs paradigm, have recently grown the interest of the multi-agent systems\nfield. To date, among different approaches, population-based algorithms are\nshown to be most effective for solving C-DCOPs. Considering the potential of\npopulation-based approaches, we propose a new C-DCOPs solver inspired by a\nwell-known population-based algorithm Artificial Bee Colony (ABC).\nAdditionally, we provide a new exploration method that aids in the further\nimprovement of the algorithm's solution quality. Finally, We theoretically\nprove that our approach is an anytime algorithm and empirically show it\nproduces significantly better results than the state-of-the-art C-DCOPs\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.07780v1"
    },
    {
        "title": "MLFC: From 10 to 50 Planners in the Multi-Agent Programming Contest",
        "authors": [
            "Rafael C. Cardoso",
            "Angelo Ferrando",
            "Fabio Papacchini",
            "Matt Luckcuck",
            "Sven Linker",
            "Terry R. Payne"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper, we describe the strategies used by our team, MLFC, that led us\nto achieve the 2nd place in the 15th edition of the Multi-Agent Programming\nContest. The scenario used in the contest is an extension of the previous\nedition (14th) \"Agents Assemble\" wherein two teams of agents move around a 2D\ngrid and compete to assemble complex block structures. We discuss the languages\nand tools used during the development of our team. Then, we summarise the main\nstrategies that were carried over from our previous participation in the 14th\nedition and list the limitations (if any) of using these strategies in the\nlatest contest edition. We also developed new strategies that were made\nspecifically for the extended scenario: cartography (determining the size of\nthe map); formal verification of the map merging protocol (to provide\nassurances that it works when increasing the number of agents); plan cache\n(efficiently scaling the number of planners); task achievement (forming groups\nof agents to achieve tasks); and bullies (agents that focus on stopping agents\nfrom the opposing team). Finally, we give a brief overview of our performance\nin the contest and discuss what we believe were our shortcomings.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08172v2"
    },
    {
        "title": "A Reinforcement Learning Approach for Re-allocating Drone Swarm Services",
        "authors": [
            "Balsam Alkouz",
            "Athman Bouguettaya"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We propose a novel framework for the re-allocation of drone swarms for\ndelivery services known as Swarm-based Drone-as-a-Service (SDaaS). The\nre-allocation framework ensures maximum profit to drone swarm providers while\nmeeting the time requirement of service consumers. The constraints in the\ndelivery environment (e.g., limited recharging pads) are taken into\nconsideration. We utilize reinforcement learning (RL) to select the best\nallocation and scheduling of drone swarms given a set of requests from multiple\nconsumers. We conduct a set of experiments to evaluate and compare the\nefficiency of the proposed approach considering the provider's profit and\nrun-time efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.13525v1"
    },
    {
        "title": "Profit equitably: An investigation of market maker's impact on equitable\n  outcomes",
        "authors": [
            "Kshama Dwarakanath",
            "Svitlana S Vyetrenko",
            "Tucker Balch"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We look at discovering the impact of market microstructure on equitability\nfor market participants at public exchanges such as the New York Stock Exchange\nor NASDAQ. Are these environments equitable venues for low-frequency\nparticipants (such as retail investors)? In particular, can market makers\ncontribute to equitability for these agents? We use a simulator to assess the\neffect a market marker can have on equality of outcomes for consumer or retail\ntraders by adjusting its parameters. Upon numerically quantifying market\nequitability by the entropy of the price returns distribution of consumer\nagents, we demonstrate that market makers indeed support equitability and that\na negative correlation is observed between the profits of the market maker and\nequitability. We then use multi objective reinforcement learning to\nconcurrently optimize for the two objectives of consumer agent equitability and\nmarket maker profitability, which leads us to learn policies that facilitate\nlower market volatility and tighter spreads for comparable profit levels.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.00094v1"
    },
    {
        "title": "Status-quo policy gradient in Multi-Agent Reinforcement Learning",
        "authors": [
            "Pinkesh Badjatiya",
            "Mausoom Sarkar",
            "Nikaash Puri",
            "Jayakumar Subramanian",
            "Abhishek Sinha",
            "Siddharth Singh",
            "Balaji Krishnamurthy"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Individual rationality, which involves maximizing expected individual\nreturns, does not always lead to high-utility individual or group outcomes in\nmulti-agent problems. For instance, in multi-agent social dilemmas,\nReinforcement Learning (RL) agents trained to maximize individual rewards\nconverge to a low-utility mutually harmful equilibrium. In contrast, humans\nevolve useful strategies in such social dilemmas. Inspired by ideas from human\npsychology that attribute this behavior to the status-quo bias, we present a\nstatus-quo loss (SQLoss) and the corresponding policy gradient algorithm that\nincorporates this bias in an RL agent. We demonstrate that agents trained with\nSQLoss learn high-utility policies in several social dilemma matrix games\n(Prisoner's Dilemma, Stag Hunt matrix variant, Chicken Game). We show how\nSQLoss outperforms existing state-of-the-art methods to obtain high-utility\npolicies in visual input non-matrix games (Coin Game and Stag Hunt visual input\nvariant) using pre-trained cooperation and defection oracles. Finally, we show\nthat SQLoss extends to a 4-agent setting by demonstrating the emergence of\ncooperative behavior in the popular Braess' paradox.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.11692v1"
    },
    {
        "title": "Towards an Adaptive and Normative Multi-Agent System Metamodel and\n  Language: Existing Approaches and Research Opportunities",
        "authors": [
            "Marx Viana",
            "Paulo Alencar",
            "Carlos Lucena"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Several Multi-Agent System (MAS) metamodels and languages have been proposed\nin the literature to support the development of agent-based applications. MAS\nmetamodels are used to capture a collection of concepts the relevant entities\nand relationships in the MAS domain, which include entities such as agent,\nmessage, role, action and plan, and relationships that represent, for example,\nthat a role is responsible for one or more tasks. In addition, to models, MAS\nmodeling languages have also been used to support the development of MASs in a\nwide variety of domains, including social networking, robotics, security and\nsmart city environments. However, there is a lack of support in these models\nand languages for abstractions involving norms and adaptations as well as their\ninteractions. This paper presents a survey of some existing metamodels and\nlanguages and compares their expressiveness using abstractions related to\nagents, norms and adaptation. The comparison serves as a basis for the\ndefinition of a new MAS metamodeling.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.13084v1"
    },
    {
        "title": "Empirical Game-Theoretic Analysis for Mean Field Games",
        "authors": [
            "Yongzhao Wang",
            "Michael P. Wellman"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We present a simulation-based approach for solution of mean field games\n(MFGs), using the framework of empirical game-theoretical analysis (EGTA). Our\nprimary method employs a version of the double oracle, iteratively adding\nstrategies based on best response to the equilibrium of the empirical MFG among\nstrategies considered so far. We present Fictitious Play (FP) and Replicator\nDynamics as two subroutines for computing the empirical game equilibrium. Each\nsubroutine is implemented with a query-based method rather than maintaining an\nexplicit payoff matrix as in typical EGTA methods due to a representation issue\nwe highlight for MFGs. By introducing game model learning and regularization,\nwe significantly improve the sample efficiency of the primary method without\nsacrificing the overall learning performance. Theoretically, we prove that a\nNash equilibrium (NE) exists in the empirical MFG and show the convergence of\niterative EGTA to NE of the full MFG with either subroutine. We test the\nperformance of iterative EGTA in various games and show that it outperforms\ndirectly applying FP to MFGs in terms of iterations of strategy introduction.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.00900v5"
    },
    {
        "title": "Multi-Agent Intention Sharing via Leader-Follower Forest",
        "authors": [
            "Zeyang Liu",
            "Lipeng Wan",
            "Xue sui",
            "Kewu Sun",
            "Xuguang Lan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Intention sharing is crucial for efficient cooperation under partially\nobservable environments in multi-agent reinforcement learning (MARL). However,\nmessage deceiving, i.e., a mismatch between the propagated intentions and the\nfinal decisions, may happen when agents change strategies simultaneously\naccording to received intentions. Message deceiving leads to potential\nmiscoordination and difficulty for policy learning. This paper proposes the\nleader-follower forest (LFF) to learn the hierarchical relationship between\nagents based on interdependencies, achieving one-sided intention sharing in\nmulti-agent communication. By limiting the flowings of intentions through\ndirected edges, intention sharing via LFF (IS-LFF) can eliminate message\ndeceiving effectively and achieve better coordination. In addition, a twostage\nlearning algorithm is proposed to train the forest and the agent network. We\nevaluate IS-LFF on multiple partially observable MARL benchmarks, and the\nexperimental results show that our method outperforms state-of-the-art\ncommunication algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.01078v1"
    },
    {
        "title": "LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent\n  Learning",
        "authors": [
            "David Henry Mguni",
            "Taher Jafferjee",
            "Jianhong Wang",
            "Oliver Slumbers",
            "Nicolas Perez-Nieves",
            "Feifei Tong",
            "Li Yang",
            "Jiangcheng Zhu",
            "Yaodong Yang",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Efficient exploration is important for reinforcement learners to achieve high\nrewards. In multi-agent systems, coordinated exploration and behaviour is\ncritical for agents to jointly achieve optimal outcomes. In this paper, we\nintroduce a new general framework for improving coordination and performance of\nmulti-agent reinforcement learners (MARL). Our framework, named Learnable\nIntrinsic-Reward Generation Selection algorithm (LIGS) introduces an adaptive\nlearner, Generator that observes the agents and learns to construct intrinsic\nrewards online that coordinate the agents' joint exploration and joint\nbehaviour. Using a novel combination of MARL and switching controls, LIGS\ndetermines the best states to learn to add intrinsic rewards which leads to a\nhighly efficient learning process. LIGS can subdivide complex tasks making them\neasier to solve and enables systems of MARL agents to quickly solve\nenvironments with sparse rewards. LIGS can seamlessly adopt existing MARL\nalgorithms and, our theory shows that it ensures convergence to policies that\ndeliver higher system performance. We demonstrate its superior performance in\nchallenging tasks in Foraging and StarCraft II.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.02618v2"
    },
    {
        "title": "The Partially Observable Asynchronous Multi-Agent Cooperation Challenge",
        "authors": [
            "Meng Yao",
            "Qiyue Yin",
            "Jun Yang",
            "Tongtong Yu",
            "Shengqi Shen",
            "Junge Zhang",
            "Bin Liang",
            "Kaiqi Huang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi-agent reinforcement learning (MARL) has received increasing attention\nfor its applications in various domains. Researchers have paid much attention\non its partially observable and cooperative settings for meeting real-world\nrequirements. For testing performance of different algorithms, standardized\nenvironments are designed such as the StarCraft Multi-Agent Challenge, which is\none of the most successful MARL benchmarks. To our best knowledge, most of\ncurrent environments are synchronous, where agents execute actions in the same\npace. However, heterogeneous agents usually have their own action spaces and\nthere is no guarantee for actions from different agents to have the same\nexecuted cycle, which leads to asynchronous multi-agent cooperation. Inspired\nfrom the Wargame, a confrontation game between two armies abstracted from real\nworld environment, we propose the first Partially Observable Asynchronous\nmulti-agent Cooperation challenge (POAC) for the MARL community. Specifically,\nPOAC supports two teams of heterogeneous agents to fight with each other, where\nan agent selects actions based on its own observations and cooperates\nasynchronously with its allies. Moreover, POAC is a light weight, flexible and\neasy to use environment, which can be configured by users to meet different\nexperimental requirements such as self-play model, human-AI model and so on.\nAlong with our benchmark, we offer six game scenarios of varying difficulties\nwith the built-in rule-based AI as opponents. Finally, since most MARL\nalgorithms are designed for synchronous agents, we revise several\nrepresentatives to meet the asynchronous setting, and the relatively poor\nexperimental results validate the challenge of POAC. Source code is released in\n\\url{http://turingai.ia.ac.cn/data\\_center/show}.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.03809v1"
    },
    {
        "title": "Greedy-based Value Representation for Optimal Coordination in\n  Multi-agent Reinforcement Learning",
        "authors": [
            "Lipeng Wan",
            "Zeyang Liu",
            "Xingyu Chen",
            "Han Wang",
            "Xuguang Lan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Due to the representation limitation of the joint Q value function,\nmulti-agent reinforcement learning methods with linear value decomposition\n(LVD) or monotonic value decomposition (MVD) suffer from relative\novergeneralization. As a result, they can not ensure optimal consistency (i.e.,\nthe correspondence between individual greedy actions and the maximal true Q\nvalue). In this paper, we derive the expression of the joint Q value function\nof LVD and MVD. According to the expression, we draw a transition diagram,\nwhere each self-transition node (STN) is a possible convergence. To ensure\noptimal consistency, the optimal node is required to be the unique STN.\nTherefore, we propose the greedy-based value representation (GVR), which turns\nthe optimal node into an STN via inferior target shaping and further eliminates\nthe non-optimal STNs via superior experience replay. In addition, GVR achieves\nan adaptive trade-off between optimality and stability. Our method outperforms\nstate-of-the-art baselines in experiments on various benchmarks. Theoretical\nproofs and empirical results on matrix games demonstrate that GVR ensures\noptimal consistency under sufficient exploration.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.04454v2"
    },
    {
        "title": "A General Auxiliary Controller for Multi-agent Flocking",
        "authors": [
            "Jinfan Zhou",
            "Jiyu Cheng",
            "Lin Zhang",
            "Wei Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We aim to improve the performance of multi-agent flocking behavior by\nquantifying the structural significance of each agent. We designed a confidence\nscore(ConfScore) to measure the spatial significance of each agent. The score\nwill be used by an auxiliary controller to refine the velocity of agents. The\nagents will be enforced to follow the motion of the leader agents whose\nConfScores are high. We demonstrate the efficacy of the auxiliary controller by\napplying it to several existing algorithms including learning-based and\nnon-learning-based methods. Furthermore, we examined how the auxiliary\ncontroller can help improve the performance under different settings of\ncommunication radius, number of agents and maximum initial velocity.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.06023v1"
    },
    {
        "title": "Decentralized Mean Field Games",
        "authors": [
            "Sriram Ganapathi Subramanian",
            "Matthew E. Taylor",
            "Mark Crowley",
            "Pascal Poupart"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multiagent reinforcement learning algorithms have not been widely adopted in\nlarge scale environments with many agents as they often scale poorly with the\nnumber of agents. Using mean field theory to aggregate agents has been proposed\nas a solution to this problem. However, almost all previous methods in this\narea make a strong assumption of a centralized system where all the agents in\nthe environment learn the same policy and are effectively indistinguishable\nfrom each other. In this paper, we relax this assumption about\nindistinguishable agents and propose a new mean field system known as\nDecentralized Mean Field Games, where each agent can be quite different from\nothers. All agents learn independent policies in a decentralized fashion, based\non their local observations. We define a theoretical solution concept for this\nsystem and provide a fixed point guarantee for a Q-learning based algorithm in\nthis system. A practical consequence of our approach is that we can address a\n`chicken-and-egg' problem in empirical mean field reinforcement learning\nalgorithms. Further, we provide Q-learning and actor-critic algorithms that use\nthe decentralized mean field learning approach and give stronger performances\ncompared to common baselines in this area. In our setting, agents do not need\nto be clones of each other and learn in a fully decentralized fashion. Hence,\nfor the first time, we show the application of mean field learning methods in\nfully competitive environments, large-scale continuous action space\nenvironments, and other environments with heterogeneous agents. Importantly, we\nalso apply the mean field method in a ride-sharing problem using a real-world\ndataset. We propose a decentralized solution to this problem, which is more\npractical than existing centralized training methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.09099v5"
    },
    {
        "title": "A Predictive Autonomous Decision Aid for Calibrating Human-Autonomy\n  Reliance in Multi-Agent Task Assignment",
        "authors": [
            "Larkin Heintzman",
            "Ryan K. Williams"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this work, we develop a game-theoretic modeling of the interaction between\na human operator and an autonomous decision aid when they collaborate in a\nmulti-agent task allocation setting. In this setting, we propose a decision aid\nthat is designed to calibrate the operator's reliance on the aid through a\nsequence of interactions to improve overall human-autonomy team performance.\nThe autonomous decision aid employs a long short-term memory (LSTM) neural\nnetwork for human action prediction and a Bayesian parameter filtering method\nto improve future interactions, resulting in an aid that can adapt to the\ndynamics of human reliance. The proposed method is then tested against a large\nset of simulated human operators from the choice prediction competition (CPC18)\ndata set, and shown to significantly improve human-autonomy interactions when\ncompared to a myopic decision aid that only suggests predicted human actions\nwithout an understanding of reliance.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10252v1"
    },
    {
        "title": "Adaptive Incentive Design with Multi-Agent Meta-Gradient Reinforcement\n  Learning",
        "authors": [
            "Jiachen Yang",
            "Ethan Wang",
            "Rakshit Trivedi",
            "Tuo Zhao",
            "Hongyuan Zha"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Critical sectors of human society are progressing toward the adoption of\npowerful artificial intelligence (AI) agents, which are trained individually on\nbehalf of self-interested principals but deployed in a shared environment.\nShort of direct centralized regulation of AI, which is as difficult an issue as\nregulation of human actions, one must design institutional mechanisms that\nindirectly guide agents' behaviors to safeguard and improve social welfare in\nthe shared environment. Our paper focuses on one important class of such\nmechanisms: the problem of adaptive incentive design, whereby a central planner\nintervenes on the payoffs of an agent population via incentives in order to\noptimize a system objective. To tackle this problem in high-dimensional\nenvironments whose dynamics may be unknown or too complex to model, we propose\na model-free meta-gradient method to learn an adaptive incentive function in\nthe context of multi-agent reinforcement learning. Via the principle of online\ncross-validation, the incentive designer explicitly accounts for its impact on\nagents' learning and, through them, the impact on future social welfare.\nExperiments on didactic benchmark problems show that the proposed method can\ninduce selfish agents to learn near-optimal cooperative behavior and\nsignificantly outperform learning-oblivious baselines. When applied to a\ncomplex simulated economy, the proposed method finds tax policies that achieve\nbetter trade-off between economic productivity and equality than baselines, a\nresult that we interpret via a detailed behavioral analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10859v1"
    },
    {
        "title": "A Survey of Event-triggered Control for Nonlinear Multiagent Systems\n  with Guaranteed Steady-State Performance",
        "authors": [
            "Gurmu Meseret Debele"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  With the gradual advancement of a novel idea of the distributed control of\nthe multiagent systems, an event-triggered control protocol has received\nsignificant research attention, especially in designing the controller for the\nnonlinear multiagent system. Compared to other widely used control conditions,\nthe event-triggered control of the nonlinear system has a significant\ncapability to improve resource utilization in real-life scenarios such as using\nand controlling the intelligent control input of each agent. It is worth\nmentioning that a group of interconnected agents have a network communication\ntopology to transmit the feedback information state across the networked link.\nThe transmission of information among a group of agents ensures that each agent\nreaches the consensus agreement cooperatively. The cooperative protocol of the\ndistributed control of nonlinear multiagent system also ensures the proper\ninformation flow between each agent, irrespective of communication delays,\nvariability of environment, and switching of the communication topology via the\nevent-triggered control protocol. Consequently, event-triggered control for\nnonlinear multi-agent systems via steady-state performance will be investigated\nin this paper. The steady-state performances of a nonlinear closed-loop system\ndemonstrate the stabilization, output regulation, and output synchronization\nproblem of the nonlinear system using proper control protocol to achieve a\nconsensus in a multiagent system will also be discussed. Based on the\nsteady-state conditions of the nonlinear system, the consensus agreement among\nthe agents will be realized.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.13560v2"
    },
    {
        "title": "A Review on Controllability of Multi-Agent Systems using Switched\n  Network",
        "authors": [
            "Javeria Noor"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Controllability refers to a situation in which a Multi-agent System may be\nsteered from one state to another using specified rules. As a result, there is\nbelief in achieving a given condition by explicit advances. The level of\ndynamism in the topology and the level of determinism in the environment are\ntwo fundamental criteria that determine multi-agent system controllability. The\ntopology of a powerful multi-agent system changes on a regular basis, altering\nthe connections between agents and hence their cooperative effort. This survey\nfocuses on the controllability of MAS in a switching network with a leader that\nfollows the closest neighbour collaboration rule. The leader/pioneer is a\nsingle agent that functions as an output to control other agents/members.\nBecause the results of activities are unknown under non-deterministic\nsituations, agents must choose new activities after observing the aftereffects\nof their prior actions, which causes time delay and limits agent proactivity.\nControllability is often achieved in a concentrated manner in the literature,\nwhere a certain leader educates supporters how to achieve a specific goal.\nControllability has different applications which incorporates managing\nairplane, vehicle, and robots.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.13675v1"
    },
    {
        "title": "Algorithm-Level Confidentiality for Average Consensus on Time-Varying\n  Directed Graphs",
        "authors": [
            "Huan Gao",
            "Yongqiang Wang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Average consensus plays a key role in distributed networks, with applications\nranging from time synchronization, information fusion, load balancing, to\ndecentralized control. Existing average consensus algorithms require individual\nagents to exchange explicit state values with their neighbors, which leads to\nthe undesirable disclosure of sensitive information in the state. In this\npaper, we propose a novel average consensus algorithm for time-varying directed\ngraphs that can protect the confidentiality of a participating agent against\nother participating agents. The algorithm injects randomness in interaction to\nobfuscate information on the algorithm-level and can ensure\ninformation-theoretic privacy without the assistance of any trusted third party\nor data aggregator. By leveraging the inherent robustness of consensus dynamics\nagainst random variations in interaction, our proposed algorithm can also\nguarantee the accuracy of average consensus. The algorithm is distinctly\ndifferent from differential-privacy based average consensus approaches which\nenable confidentiality through compromising accuracy in obtained consensus\nvalue. Numerical simulations confirm the effectiveness and efficiency of our\nproposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.00293v2"
    },
    {
        "title": "Deep Learnable Strategy Templates for Multi-Issue Bilateral Negotiation",
        "authors": [
            "Pallavi Bagga",
            "Nicola Paoletti",
            "Kostas Stathis"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We study how to exploit the notion of strategy templates to learn strategies\nfor multi-issue bilateral negotiation. Each strategy template consists of a set\nof interpretable parameterized tactics that are used to decide an optimal\naction at any time. We use deep reinforcement learning throughout an\nactor-critic architecture to estimate the tactic parameter values for a\nthreshold utility, when to accept an offer and how to generate a new bid. This\ncontrasts with existing work that only estimates the threshold utility for\nthose tactics. We pre-train the strategy by supervision from the dataset\ncollected using \"teacher strategies\", thereby decreasing the exploration time\nrequired for learning during negotiation. As a result, we build automated\nagents for multi-issue negotiations that can adapt to different negotiation\ndomains without the need to be pre-programmed. We empirically show that our\nwork outperforms the state-of-the-art in terms of the individual as well as\nsocial efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02455v1"
    },
    {
        "title": "A Negotiating Strategy for a Hybrid Goal Function in Multilateral\n  Negotiation",
        "authors": [
            "Alon Stern",
            "Sarit Kraus",
            "David Sarne"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In various multi-agent negotiation settings, a negotiator's utility depends,\neither partially or fully, on the sum of negotiators' utilities (i.e., social\nwelfare). While the need for effective negotiating-agent designs that take into\naccount social welfare has been acknowledged in recent work, and even\nestablished as a category in automated negotiating agent competitions, very few\ndesigns have been proposed to date. In this paper, we present the design\nprinciples and results of an extensive evaluation of agent HerbT+, a\nnegotiating agent aiming to maximize a linear tradeoff between individual and\nsocial welfare. Our evaluation framework relies on the automated negotiating\nagents competition (ANAC) and includes a thorough comparison of performance\nwith the top 15 agents submitted between 2015-2018 based on negotiations\ninvolving 63 agents submitted to these competitions. We find that, except for a\nfew minor exceptions, when social-welfare plays a substantial role in the\nagent's goal function, our agent outperforms all other tested designs.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.04126v1"
    },
    {
        "title": "Equilibration Analysis and Control of Coordinating Decision-Making\n  Populations",
        "authors": [
            "Negar Sakhaei",
            "Zeinab Maleki",
            "Pouria Ramazi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Whether a population of decision-making individuals will reach a state of\nsatisfactory decisions is a fundamental problem in studying collective\nbehaviors. In the framework of evolutionary game theory and by means of\npotential functions, researchers have established equilibrium convergence under\ndifferent update rules, including best-response and imitation, by imposing\ncertain conditions on agents' utility functions. Then by using the proposed\npotential functions, they have been able to control these populations towards\nsome desired equilibrium. Nevertheless, finding a potential function is often\ndaunting, if not near impossible. We introduce the so-called coordinating agent\nwho tends to switch to a decision only if at least another agent has done so.\nWe prove that any population of coordinating agents, a coordinating population,\nalmost surely equilibrates. Apparently, some binary network games that were\nproven to equilibrate using potential functions are coordinating, and some\ncoloring problems can be solved using this notion. We additionally show that\nany mixed network of agents following best-response, imitation, or rational\nimitation, and associated with coordination payoff matrices is coordinating,\nand hence, equilibrates. As a second contribution, we provide an\nincentive-based control algorithm that leads coordinating populations to a\ndesired equilibrium. The algorithm iteratively maximizes the ratio of the\nnumber of agents choosing the desired decision to the provided incentive. It\nperforms near optimal and as well as specialized algorithms proposed for\nbest-response and imitation; however, it does not require a potential function.\nTherefore, this control algorithm can be readily applied in general situations\nwhere no potential function is yet found for a given decision-making\npopulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.04185v1"
    },
    {
        "title": "GCS: Graph-based Coordination Strategy for Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Jingqing Ruan",
            "Yali Du",
            "Xuantang Xiong",
            "Dengpeng Xing",
            "Xiyun Li",
            "Linghui Meng",
            "Haifeng Zhang",
            "Jun Wang",
            "Bo Xu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Many real-world scenarios involve a team of agents that have to coordinate\ntheir policies to achieve a shared goal. Previous studies mainly focus on\ndecentralized control to maximize a common reward and barely consider the\ncoordination among control policies, which is critical in dynamic and\ncomplicated environments. In this work, we propose factorizing the joint team\npolicy into a graph generator and graph-based coordinated policy to enable\ncoordinated behaviours among agents. The graph generator adopts an\nencoder-decoder framework that outputs directed acyclic graphs (DAGs) to\ncapture the underlying dynamic decision structure. We also apply the\nDAGness-constrained and DAG depth-constrained optimization in the graph\ngenerator to balance efficiency and performance. The graph-based coordinated\npolicy exploits the generated decision structure. The graph generator and\ncoordinated policy are trained simultaneously to maximize the discounted\nreturn. Empirical evaluations on Collaborative Gaussian Squeeze, Cooperative\nNavigation, and Google Research Football demonstrate the superiority of the\nproposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06257v1"
    },
    {
        "title": "Speed-vs-Accuracy Tradeoff in Collective Estimation: An Adaptive\n  Exploration-Exploitation Case",
        "authors": [
            "Mohsen Raoufi",
            "Heiko Hamann",
            "Pawel Romanczuk"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The tradeoff between accuracy and speed is considered fundamental to\nindividual and collective decision-making. In this paper, we focus on\ncollective estimation as an example of collective decision-making. The task is\nto estimate the average scalar intensity of a desired feature in the\nenvironment. The solution we propose consists of exploration and exploitation\nphases, where the switching time is a factor dictating the balance between the\ntwo phases. By decomposing the total accuracy into bias and variance, we\nexplain that diversity and social interactions could promote the accuracy of\nthe collective decision. We also show how the exploration-vs-exploitation\ntradeoff relates to the speed-vs-accuracy tradeoff. One significant finding of\nour work is that there is an optimal duration for exploration to compromise\nbetween speed and accuracy. This duration cannot be determined offline for an\nunknown environment. Hence, we propose an adaptive, distributed mechanism\nenabling individual agents to decide in a decentralized manner when to switch.\nMoreover, the spatial consequence of the exploitation phase is an emergent\ncollective movement, leading to the aggregation of the collective at the\niso-contours of the mean intensity of the environmental field in the spatial\ndomain. Examples of potential applications for such a fully distributed\ncollective estimation model are spillage capturing and source localization.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.07123v1"
    },
    {
        "title": "Proportional Ranking in Primary Elections: A Case Study",
        "authors": [
            "Ariel Rosenfeld",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Many democratic political parties hold primary elections, which nicely\nreflects their democratic nature and promote, among other things, the\ndemocratic value of inclusiveness. However, the methods currently used for\nholding such primary elections may not be the most suitable, especially if some\nform of proportional ranking is desired. In this paper, we compare different\nalgorithmic methods for holding primaries (i.e., different aggregation methods\nfor voters' ballots), by evaluating the degree of proportional ranking that is\nachieved by each of them using real-world data. In particular, we compare six\ndifferent algorithms by analyzing real-world data from a recent primary\nelection conducted by the Israeli Democratit party. Technically, we analyze\nunique voter data and evaluate the proportionality achieved by means of cluster\nanalysis, aiming at pinpointing the representation that is granted to different\nvoter groups under each of the algorithmic methods considered. Our finding\nsuggest that, contrary to the most-prominent primaries algorithm used (i.e.,\nApproval), other methods such as Sequential Proportional Approval or Phragmen\ncan bring about better proportional ranking and thus may be better suited for\nprimary elections in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.07305v1"
    },
    {
        "title": "Effect of intervention policies in an agent based spatial epidemic model\n  of Gwalior",
        "authors": [
            "W. Wilfred Godfrey"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Covid-19 has ravaged the entire world and it may not be the last such to\nravage the world. COMOKIT [3] is an agent based spatial modeling tool to study\nthe effect of covid -19 in a geographical area by creating heterogenous\nsynthetic agents and their behaviours. This paper presents comokit based case\nstudy on Gwalior region with respect to various intervention policies to curb\nthe spread of the disease.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.07545v1"
    },
    {
        "title": "Minimizing Expected Intrusion Detection Time in Adversarial Patrolling",
        "authors": [
            "David Klaška",
            "Antonín Kučera",
            "Vít Musil",
            "Vojtěch Řehák"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In adversarial patrolling games, a mobile Defender strives to discover\nintrusions at vulnerable targets initiated by an Attacker. The Attacker's\nutility is traditionally defined as the probability of completing an attack,\npossibly weighted by target costs. However, in many real-world scenarios, the\nactual damage caused by the Attacker depends on the \\emph{time} elapsed since\nthe attack's initiation to its detection. We introduce a formal model for such\nscenarios, and we show that the Defender always has an \\emph{optimal} strategy\nachieving maximal protection. We also prove that \\emph{finite-memory}\nDefender's strategies are sufficient for achieving protection arbitrarily close\nto the optimum. Then, we design an efficient \\emph{strategy synthesis}\nalgorithm based on differentiable programming and gradient descent.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.01095v1"
    },
    {
        "title": "Hacking the Colony: On the Disruptive Effect of Misleading Pheromone and\n  How to Defend Against It",
        "authors": [
            "Ashay Aswale",
            "Antonio Lopez",
            "Aukkawut Ammartayakun",
            "Carlo Pinciroli"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Ants have evolved to seek and retrieve food by leaving trails of pheromones.\nThis mechanism has inspired several approaches to decentralized multi-robot\ncoordination. However, in this paper, we show that pheromone trails are a\nfragile mechanism for coordination, and can be sabotaged to starve the colony.\nWe introduce detractors: malicious agents that leave a misleading, but\nindistinguishable, trail of food pheromone to distract and trap cooperator ants\nin the nest. We analyze the effectiveness of detractors with respect to\nparameters such as evaporation rate of misleading pheromone and fraction of\ndetractors in the colony. In addition, we propose a countermeasure to this\nattack by introducing a new type of pheromone: the cautionary pheromone.\nCooperator ants secrete this type of pheromone atop existing food trails as a\nwarning. When the cautionary pheromone intensity exceeds the food pheromone\nintensity, cooperator ants ignore overlapping food pheromone. We show that,\ndespite its simplicity, this defense mechanism can limit, but not nullify, the\neffect of detractors. Ultimately, our work shows that pheromone-based\ncoordination, while effective, is also fragile.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.01808v2"
    },
    {
        "title": "Allocation of Indivisible Items with Individual Preference Graphs",
        "authors": [
            "Nina Chiarelli",
            "Clément Dallard",
            "Andreas Darmann",
            "Stefan Lendl",
            "Martin Milanič",
            "Peter Muršič",
            "Ulrich Pferschy",
            "Nevena Pivač"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper studies the allocation of indivisible items to agents, when each\nagent's preferences are expressed by means of a directed acyclic graph. The\nvertices of each preference graph represent the subset of items approved of by\nthe respective agent. An arc $(a,b)$ in such a graph means that the respective\nagent prefers item $a$ over item $b$. We introduce a new measure of\ndissatisfaction of an agent by counting the number of non-assigned items which\nare approved of by the agent and for which no more preferred item is allocated\nto the agent. Considering two problem variants, we seek an allocation of the\nitems to the agents in a way that minimizes (i) the total dissatisfaction over\nall agents or (ii) the maximum dissatisfaction among the agents. For both\noptimization problems we study the status of computational complexity and\nobtain NP-hardness results as well as polynomial algorithms with respect to\nnatural underlying graph structures, such as stars, trees, paths, and\nmatchings. We also analyze the parameterized complexity of the two problems\nwith respect to various parameters related to the number of agents, the\ndissatisfaction threshold, the vertex degrees of the preference graphs, and the\ntreewidth.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04465v1"
    },
    {
        "title": "Grassroots Currencies: Foundations for Grassroots Digital Economies",
        "authors": [
            "Ehud Shapiro"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Grassroots currencies are means for turning mutual trust into liquidity, with\nthe goal of providing foundations for grassroots digital economies. Grassroots\ncoins are units of debt that can be issued by anyone -- people, corporations,\ncooperatives, banks, municipalities and governments -- and traded by anyone.\nThey are more similar to `inside money' (a medium of exchange backed by private\ncredit) and to fiat currencies (for which the issuer controls scarcity) than to\nglobal cryptocurrencies such as Bitcoin or Ethereum, which are unbacked and for\nwhich scarcity is controlled by the protocol.\n  In this paper we introduce the principles that underlie grassroots\ncurrencies; show that they naturally admit basic fiat currency measures\nregarding foreign trade such as foreign debt, trade balance, and velocity, and\nbasic accounting measures such as cash ratio, quick ratio, and current ratio;\nelaborate economic scenarios enabled by these principles for grassroots\ncurrencies issued by natural and legal persons; relate grassroots currencies to\nextant work, including notions of personal currencies, community currencies,\ncryptocurrencies, and inside money; formally specify grassroots currencies as\ndigital entities, governed by the Grassroots Currencies Protocol; discuss the\nsecurity (safety, liveness, and privacy) of the protocol; and prove that the\nprotocol is grassroots. An implementation of grassroots currencies via a\nblocklace-based payment system is described elsewhere.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05619v17"
    },
    {
        "title": "Disentangling Successor Features for Coordination in Multi-agent\n  Reinforcement Learning",
        "authors": [
            "Seung Hyun Kim",
            "Neale Van Stralen",
            "Girish Chowdhary",
            "Huy T. Tran"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent reinforcement learning (MARL) is a promising framework for\nsolving complex tasks with many agents. However, a key challenge in MARL is\ndefining private utility functions that ensure coordination when training\ndecentralized agents. This challenge is especially prevalent in unstructured\ntasks with sparse rewards and many agents. We show that successor features can\nhelp address this challenge by disentangling an individual agent's impact on\nthe global value function from that of all other agents. We use this\ndisentanglement to compactly represent private utilities that support stable\ntraining of decentralized agents in unstructured tasks. We implement our\napproach using a centralized training, decentralized execution architecture and\ntest it in a variety of multi-agent environments. Our results show improved\nperformance and training time relative to existing methods and suggest that\ndisentanglement of successor features offers a promising approach to\ncoordination in MARL.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07741v1"
    },
    {
        "title": "SIPOMDPLite-Net: Lightweight, Self-Interested Learning and Planning in\n  POSGs with Sparse Interactions",
        "authors": [
            "Gengyu Zhang",
            "Prashant Doshi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This work introduces sIPOMDPLite-net, a deep neural network (DNN)\narchitecture for decentralized, self-interested agent control in partially\nobservable stochastic games (POSGs) with sparse interactions between agents.\nThe network learns to plan in contexts modeled by the interactive partially\nobservable Markov decision process (I-POMDP) Lite framework and uses\nhierarchical value iteration networks to simulate the solution of nested MDPs,\nwhich I-POMDP Lite attributes to the other agent to model its behavior and\npredict its intention. We train sIPOMDPLite-net with expert demonstrations on\nsmall two-agent Tiger-grid tasks, for which it accurately learns the underlying\nI-POMDP Lite model and near-optimal policy, and the policy continues to perform\nwell on larger grids and real-world maps. As such, sIPOMDPLite-net shows good\ntransfer capabilities and offers a lighter learning and planning approach for\nindividual, self-interested agents in multiagent settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.11188v1"
    },
    {
        "title": "Practical Abstraction for Model Checking of Multi-Agent Systems",
        "authors": [
            "Wojciech Jamroga",
            "Yan Kim"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Model checking of multi-agent systems (MAS) is known to be hard, both\ntheoretically and in practice. A smart abstraction of the state space may\nsignificantly reduce the model, and facilitate the verification. In this paper,\nwe propose and study an intuitive agent-based abstraction scheme, based on the\nremoval of variables in the representation of a MAS. This allows to do the\nreduction without generating the global model of the system. Moreover, the\nprocess is easy to understand and control even for domain experts with little\nknowledge of computer science. We formally prove the correctness of the\napproach, and evaluate the gains experimentally on models of a postal voting\nprocedure.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.12016v4"
    },
    {
        "title": "Complexity of Deliberative Coalition Formation",
        "authors": [
            "Edith Elkind",
            "Abheek Ghosh",
            "Paul Goldberg"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Elkind et al. (AAAI, 2021) introduced a model for deliberative coalition\nformation, where a community wishes to identify a strongly supported proposal\nfrom a space of alternatives, in order to change the status quo. In their\nmodel, agents and proposals are points in a metric space, agents' preferences\nare determined by distances, and agents deliberate by dynamically forming\ncoalitions around proposals that they prefer over the status quo. The\ndeliberation process operates via k-compromise transitions, where agents from k\n(current) coalitions come together to form a larger coalition in order to\nsupport a (perhaps new) proposal, possibly leaving behind some of the\ndissenting agents from their old coalitions. A deliberation succeeds if it\nterminates by identifying a proposal with the largest possible support. For\ndeliberation in d dimensions, Elkind et al. consider two variants of their\nmodel: in the Euclidean model, proposals and agent locations are points in R^d\nand the distance is measured according to ||...||_2; and in the hypercube\nmodel, proposals and agent locations are vertices of the d-dimensional\nhypercube and the metric is the Hamming distance. They show that in the\ncontinuous model 2-compromises are guaranteed to succeed, but in the discrete\nmodel for deliberation to succeed it may be necessary to use k-compromises with\nk >= d. We complement their analysis by (1) proving that in both models it is\nhard to find a proposal with a high degree of support, and even a 2-compromise\ntransition may be hard to compute; (2) showing that a sequence of 2-compromise\ntransitions may be exponentially long; (3) strengthening the lower bound on the\nsize of the compromise for the d-hypercube model from d to 2^{\\Omega(d)}.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.12594v1"
    },
    {
        "title": "Investigating the Role of Pedestrian Groups in Shared Spaces through\n  Simulation Modeling",
        "authors": [
            "Suhair Ahmed",
            "Fatema T. Johora",
            "Jörg P. Müller"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In shared space environments, urban space is shared among different types of\nroad users, who frequently interact with each other to negotiate priority and\ncoordinate their trajectories. Instead of traffic rules, interactions among\nthem are conducted by informal rules like speed limitations and by social\nprotocols e.g., courtesy behavior. Social groups (socially related road users\nwho walk together) are an essential phenomenon in shared spaces and affect the\nsafety and efficiency of such environments. To replicate group phenomena and\nsystematically study their influence in shared spaces; realistic models of\nsocial groups and the integration of these models into shared space simulations\nare required. In this work, we focus on pedestrian groups and adopt an extended\nversion of the social force model in conjunction with a game-theoretic model to\nsimulate their movements. The novelty of our paper is in the modeling of\ninteractions between social groups and vehicles. We validate our model by\nsimulating scenarios involving interaction between social groups and also\ngroup-to-vehicle interaction.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.13410v1"
    },
    {
        "title": "On Intercultural Transferability and Calibration of Heterogeneous Shared\n  Space Motion Models",
        "authors": [
            "Fatema T. Johora",
            "Jörg P. Müller"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Modelling and simulation of mixed-traffic zones is an important tool for\ntransportation planners to assess safety, efficiency, and human-friendliness of\nfuture urban areas. This paper addresses problems of calibration and\ntransferability of existing shared space models when applied to scenarios that\ndiffer in terms of cultural aspects, traffic conditions, and spatial layout. In\nparticular, the first contribution of this work is an enhancement of the\nGame-Theoretic Social Force Model (GSFM) by a generic methodology for largely\nautomated model calibration; we illustrate the use of the calibration method\nfor a shared space environment in Germany. The second contribution is an\ninvestigation into transferability of shared space models. We define criteria\nfor model transferability and present a case study, in which we analyse and\nevaluate transferability of the model we constructed based on the ``German\ndataset'' to a different shared space environment from China. Our results\nindicate that although -- as to be expected -- the model faces difficulties to\nreplicate the movement behaviours of road users from a new environment, by\nadding social norms (derived through analysis) of that environment to our\nmodel, satisfactory improvement of model accuracy can be obtained with limited\neffort.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.13419v1"
    },
    {
        "title": "Pippi: Practical Protocol Instantiation",
        "authors": [
            "Samuel H. Christie V",
            "Amit K. Chopra",
            "Munindar P. Singh"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  A protocol specifies interactions between roles, which together constitute a\nmultiagent system (MAS). Enacting a protocol presupposes that agents are bound\nto the its roles. Existing protocol-based approaches, however, do not\nadequately treat the practical aspects of how roles bindings come about.\n  Pippi addresses this problem of MAS instantiation. It proposes the notion of\na metaprotocol, enacting which instantiates a MAS suitable for enacting a given\nprotocol. Pippi demonstrates the subtleties involved in instantiating MAS\narising from protocol composition, correlation, and decentralization. To\naddress these subtleties and further support practical application patterns, we\nintroduce an enhanced protocol language, with support for parameter types\n(including role and protocol typed parameters, for metaprotocols), interface\nflexibility, and binding constraints. We discuss the realization of our\napproach through an extended agent architecture, including the novel concept of\na MAS adapter for contact management. We evaluate Pippi's expressiveness by\ndemonstrating common patterns for agent discovery.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.00086v1"
    },
    {
        "title": "STV+AGR: Towards Practical Verification of Strategic Ability Using\n  Assume-Guarantee Reasoning",
        "authors": [
            "Damian Kurpiewski",
            "Łukasz Mikulski",
            "Wojciech Jamroga"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We present a substantially expanded version of our tool STV for strategy\nsynthesis and verification of strategic abilities. The new version provides a\nweb interface and support for assume-guarantee verification of multi-agent\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.01033v2"
    },
    {
        "title": "The Dynamics of Q-learning in Population Games: a Physics-Inspired\n  Continuity Equation Model",
        "authors": [
            "Shuyue Hu",
            "Chin-Wing Leung",
            "Ho-fung Leung",
            "Harold Soh"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Although learning has found wide application in multi-agent systems, its\neffects on the temporal evolution of a system are far from understood. This\npaper focuses on the dynamics of Q-learning in large-scale multi-agent systems\nmodeled as population games. We revisit the replicator equation model for\nQ-learning dynamics and observe that this model is inappropriate for our\nconcerned setting. Motivated by this, we develop a new formal model, which\nbears a formal connection with the continuity equation in physics. We show that\nour model always accurately describes the Q-learning dynamics in population\ngames across different initial settings of MASs and game configurations. We\nalso show that our model can be applied to different exploration mechanisms,\ndescribe the mean dynamics, and be extended to Q-learning in 2-player and\nn-player games. Last but not least, we show that our model can provide insights\ninto algorithm parameters and facilitate parameter tuning.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.01500v1"
    },
    {
        "title": "Towards Safe and Efficient Swarm-Human Collaboration: A Hierarchical\n  Multi-Agent Pickup and Delivery framework",
        "authors": [
            "Xin Gong",
            "Tieniu Wang",
            "Yukang Cui",
            "Tingwen Huang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The multi-Agent Pickup and Delivery (MAPD) problem is crucial in the realm of\nIntelligent Storage Systems (ISSs), where multiple robots are assigned with\ntime-varying, heterogeneous, and potentially uncertain tasks. When it comes to\nHuman-Swarm Hybrid System ((HS)$_2$), robots and human workers will accomplish\nthe MAPD tasks in collaboration. Herein, we propose a Human-Swarm Hybrid System\nPickup and Delivery ((HS)$_2$PD) framework, which is predominant in future\nISSs. A two-layer decision framework based on the prediction horizon window is\nestablished in light of the unpredictability of human behavior and the dynamic\nchanges of tasks. The first layer is a two-level programming problem to solve\nthe problems of mode assignment and TA. The second layer is devoted to the\nexact path of each agent via solving mixed-integer programming (MIP) problems.\nAn integrated algorithm for the (HS)$_2$PD problem is summarized. The\npracticality and validity of the above algorithm are illustrated via a\nnumerical simulation example towards (HS)$_2$PD tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.04052v1"
    },
    {
        "title": "Multi-Objective Multi-Agent Planning for Discovering and Tracking\n  Multiple Mobile Objects",
        "authors": [
            "Hoa Van Nguyen",
            "Ba-Ngu Vo",
            "Ba-Tuong Vo",
            "Hamid Rezatofighi",
            "Damith C. Ranasinghe"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We consider the online planning problem for a team of agents to discover and\ntrack an unknown and time-varying number of moving objects from onboard sensor\nmeasurements with uncertain measurement-object origins. Since the onboard\nsensors have limited field-of-views, the usual planning strategy based solely\non either tracking detected objects or discovering unseen objects is\ninadequate. To address this, we formulate a new information-based\nmulti-objective multi-agent control problem, cast as a partially observable\nMarkov decision process (POMDP). The resulting multi-agent planning problem is\nexponentially complex due to the unknown data association between objects and\nmulti-sensor measurements; hence, computing an optimal control action is\nintractable. We prove that the proposed multi-objective value function is a\nmonotone submodular set function, which admits low-cost suboptimal solutions\nvia greedy search with a tight optimality bound. The resulting planning\nalgorithm has a linear complexity in the number of objects and measurements\nacross the sensors, and quadratic in the number of agents. We demonstrate the\nproposed solution via a series of numerical experiments with a real-world\ndataset.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.04551v4"
    },
    {
        "title": "A smart electric bike for smart cities",
        "authors": [
            "Shaun Sweeney",
            "Robert Shorten",
            "David Timoney",
            "Giovanni Russo",
            "Francesco Pilla"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This is a Masters Thesis completed at University College Dublin, Ireland in\n2017 which involved augmenting an off-the-shelf electric bike with sensors to\nenable new services to be delivered to cyclists in cities. The application of\nprimary interest was to control the cyclist's ventilation rate based on the\nconcentration of local air pollutants. Detailed modelling and system design is\npresented for our Cyberphysical system which consisted of a modified BTwin\ne-bike, Cycle Analyst sensors, the cyclist themselves, a Bluetooth connected\nsmartphone and our algorithms. Control algorithms to regulate the proportion of\npower the cyclist provided as a proxy for their ventilation rate were proposed\nand validated in a basic way, which were later proven significantly further in\nFurther Work (see IEEE Transactions on Intelligent Transportation Systems\npaper: https://ieeexplore.ieee.org/abstract/document/8357977). The basic idea\nwas to provide more electrical assistance to cyclists in areas of high air\npollution to reduce the cyclist ventilation rate and thereby the amount of air\npollutants inhaled. This presents an interesting control challenge due to the\nhuman-in-the-loop characteristics and the potential for impactful real life\napplications. A background literature review is provided on energy as it\nrelates to cycling and some other applications are also discussed. A link to a\nvideo which demonstrates the system is provided, and also to a blog published\nby IBM Research about the system.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06679v1"
    },
    {
        "title": "A Decentralised Multi-Agent Reinforcement Learning Approach for the\n  Same-Day Delivery Problem",
        "authors": [
            "Elvin Ngu",
            "Leandro Parada",
            "Jose Javier Escribano Macias",
            "Panagiotis Angeloudis"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Same-Day Delivery services are becoming increasingly popular in recent years.\nThese have been usually modelled by previous studies as a certain class of\nDynamic Vehicle Routing Problem (DVRP) where goods must be delivered from a\ndepot to a set of customers in the same day that the orders were placed.\nAdaptive exact solution methods for DVRPs can become intractable even for small\nproblem instances. In this paper, we formulate the SDDP as a Markov Decision\nProcess (MDP) and solve it using a parameter-sharing Deep Q-Network, which\ncorresponds to a decentralised Multi-Agent Reinforcement Learning (MARL)\napproach. For this, we create a multi-agent grid-based SDD environment,\nconsisting of multiple vehicles, a central depot and dynamic order generation.\nIn addition, we introduce zone-specific order generation and reward\nprobabilities. We compare the performance of our proposed MARL approach against\na Mixed Inter Programming (MIP) solution. Results show that our proposed MARL\nframework performs on par with MIP-based policy when the number of orders is\nrelatively low. For problem instances with higher order arrival rates,\ncomputational results show that the MARL approach underperforms the MIP by up\nto 30%. The performance gap between both methods becomes smaller when\nzone-specific parameters are employed. The gap is reduced from 30% to 3% for a\n5x5 grid scenario with 30 orders. Execution time results indicate that the MARL\napproach is, on average, 65 times faster than the MIP-based policy, and\ntherefore may be more advantageous for real-time control, at least for\nsmall-sized instances.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.11658v1"
    },
    {
        "title": "Congestion-aware path coordination game with Markov decision process\n  dynamics",
        "authors": [
            "Sarah H. Q. Li",
            "Dan Calderone",
            "Behcet Acikmese"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Inspired by the path coordination problem arising from robo-taxis, warehouse\nmanagement, and mixed-vehicle routing problems, we model a group of\nheterogeneous players responding to stochastic demands as a congestion game\nunder Markov decision process dynamics. Players share a common state-action\nspace but have unique transition dynamics, and each player's unique cost is a\n{function} of the joint state-action probability distribution. For a class of\nplayer cost functions, we formulate the player-specific optimization problem,\nprove the equivalence between the Nash equilibrium and the solution of a\npotential minimization problem, and derive dynamic programming approaches to\nsolve the Nash equilibrium. We apply this game to model multi-agent path\ncoordination and introduce congestion-based cost functions that enable players\nto complete individual tasks while avoiding congestion with their opponents.\nFinally, we present a learning algorithm for finding the Nash equilibrium that\nhas linear complexity in the number of players. We demonstrate our game model\non a multi-robot warehouse \\change{path coordination problem}, in which robots\nautonomously retrieve and deliver packages while avoiding congested paths.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.12133v2"
    },
    {
        "title": "Bisimulations for Verifying Strategic Abilities with an Application to\n  the ThreeBallot Voting Protocol",
        "authors": [
            "Francesco Belardinelli",
            "Rodica Condurache",
            "Catalin Dima",
            "Wojciech Jamroga",
            "Michal Knapik"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We propose a notion of alternating bisimulation for strategic abilities under\nimperfect information. The bisimulation preserves formulas of ATL$^*$ for both\nthe {\\em objective} and {\\em subjective} variants of the state-based semantics\nwith imperfect information, which are commonly used in the modeling and\nverification of multi-agent systems. Furthermore, we apply the theoretical\nresult to the verification of coercion-resistance in the ThreeBallot voting\nsystem, a voting protocol that does not use cryptography. In particular, we\nshow that natural simplifications of an initial model of the protocol are in\nfact bisimulations of the original model, and therefore satisfy the same\nATL$^*$ properties, including coercion-resistance. These simplifications allow\nthe model-checking tool MCMAS to terminate on models with a larger number of\nvoters and candidates, compared with the initial model.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.13692v3"
    },
    {
        "title": "UNMAS: Multi-Agent Reinforcement Learning for Unshaped Cooperative\n  Scenarios",
        "authors": [
            "Jiajun Chai",
            "Weifan Li",
            "Yuanheng Zhu",
            "Dongbin Zhao",
            "Zhe Ma",
            "Kewu Sun",
            "Jishiyu Ding"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent reinforcement learning methods such as VDN, QMIX, and QTRAN that\nadopt centralized training with decentralized execution (CTDE) framework have\nshown promising results in cooperation and competition. However, in some\nmulti-agent scenarios, the number of agents and the size of action set actually\nvary over time. We call these unshaped scenarios, and the methods mentioned\nabove fail in performing satisfyingly. In this paper, we propose a new method\ncalled Unshaped Networks for Multi-Agent Systems (UNMAS) that adapts to the\nnumber and size changes in multi-agent systems. We propose the self-weighting\nmixing network to factorize the joint action-value. Its adaption to the change\nin agent number is attributed to the nonlinear mapping from each-agent Q value\nto the joint action-value with individual weights. Besides, in order to address\nthe change in action set, each agent constructs an individual action-value\nnetwork that is composed of two streams to evaluate the constant\nenvironment-oriented subset and the varying unit-oriented subset. We evaluate\nUNMAS on various StarCraft II micro-management scenarios and compare the\nresults with several state-of-the-art MARL algorithms. The superiority of UNMAS\nis demonstrated by its highest winning rates especially on the most difficult\nscenario 3s5z_vs_3s6z. The agents learn to perform effectively cooperative\nbehaviors while other MARL algorithms fail in. Animated demonstrations and\nsource code are provided in https://sites.google.com/view/unmas.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.14477v1"
    },
    {
        "title": "A-DRIVE: Autonomous Deadlock Detection and Recovery at Road\n  Intersections for Connected and Automated Vehicles",
        "authors": [
            "Shunsuke Aoki",
            " Ragunathan",
            " Rajkumar"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Connected and Automated Vehicles (CAVs) are highly expected to improve\ntraffic throughput and safety at road intersections, single-track lanes, and\nconstruction zones. However, multiple CAVs can block each other and create a\nmutual deadlock around these road segments (i) when vehicle systems have a\nfailure, such as a communication failure, control failure, or localization\nfailure and/or (ii) when vehicles use a long shared road segment. In this\npaper, we present an Autonomous Deadlock Detection and Recovery Protocol at\nIntersections for Automated Vehicles named A-DRIVE that is a decentralized and\ntime-sensitive technique to improve traffic throughput and shorten worst-case\nrecovery time. To enable the deadlock recovery with automated vehicles and with\nhuman-driven vehicles, A-DRIVE includes two components: V2V communication-based\nA-DRIVE and Local perception-based A-DRIVE. V2V communication-based A-DRIVE is\ndesigned for homogeneous traffic environments in which all the vehicles are\nconnected and automated. Local perception-based A-DRIVE is for mixed traffic,\nwhere CAVs, non-connected automated vehicles, and human-driven vehicles\nco-exist and cooperate with one another. Since these two components are not\nexclusive, CAVs inclusively and seamlessly use them in practice. Finally, our\nsimulation results show that A-DRIVE improves traffic throughput compared to a\nbaseline protocol.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.04910v1"
    },
    {
        "title": "Agent-based Constraint Solving for Resource Allocation in Manycore\n  Systems",
        "authors": [
            "Volker Wenzel",
            "Lars Bauer",
            "Wolfgang Schröder-Preikschat",
            "Jörg Henkel"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  For efficiency reasons, manycore systems are increasingly heterogeneous,\nwhich makes the mapping of complex workloads a key problem with a high\noptimization potential. Constraints express the application requirements like\nwhich core type to choose, how many cores to choose, exclusively or\nnon-exclusively, using a certain core, etc. In this work, we propose a\ndecentralized solution for solving application resource constraints by means of\nan agent-based approach in order to obtain scalability. We translate the\nconstraints into a Distributed Constraint Optimization Problem (DCOP) and\npropose a local search algorithm RESMGM to solve them. For the first time, we\ndemonstrate the viability and efficiency of the DCOP approach for heterogeneous\nmanycore systems. Our RESMGM algorithm supports a far wider range of\nconstraints than state-of-the-art, leading to superior results, but still has\ncomparable overheads w.r.t. computation and communication.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.06603v1"
    },
    {
        "title": "Machine Learning Approaches to Automated Mechanism Design for Public\n  Project Problem",
        "authors": [
            "Guanhua Wang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Mechanism design is a central research branch in microeconomics. An effective\nmechanism can significantly improve performance and efficiency of social\ndecisions under desired objectives, such as to maximize social welfare or to\nmaximize revenue for agents. However, mechanism design is challenging for many\ncommon models including the public project problem model which we study in this\nthesis. A typical public project problem is a group of agents crowdfunding a\npublic project (e.g., building a bridge). The mechanism will decide the payment\nand allocation for each agent (e.g., how much the agent pays, and whether the\nagent can use it) according to their valuations. The mechanism can be applied\nto various economic scenarios, including those related to cyber security. There\nare different constraints and optimized objectives for different public project\nscenarios (sub-problems), making it unrealistic to design a universal mechanism\nthat fits all scenarios, and designing mechanisms for different settings\nmanually is a taxing job. Therefore, we explore automated mechanism design\n(AMD) of public project problems under different constraints.\n  In this thesis, we focus on the public project problem, which includes many\nsub-problems (excludable/non-excludable, divisible/indivisible,\nbinary/non-binary). We study the classical public project model and extend this\nmodel to other related areas such as the zero-day exploit markets. For\ndifferent sub-problems of the public project problem, we adopt different novel\nmachine learning techniques to design optimal or near-optimal mechanisms via\nautomated mechanism design. We evaluate our mechanisms by theoretical analysis\nor experimentally comparing our mechanisms against existing mechanisms. The\nexperiments and theoretical results show that our mechanisms are better than\nstate-of-the-art automated or manual mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.07315v1"
    },
    {
        "title": "Lane-Free Crossing of CAVs through Intersections as a Minimum-Time\n  Optimal Control Problem",
        "authors": [
            "Mahdi Amouzadi",
            "Mobolaji Olawumi Orisatoki",
            "Arash M. Dizqah"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Unlike conventional cars, connected and autonomous vehicles (CAVs) can cross\nintersections in a lane-free order and utilise the whole area of intersections.\nThis paper presents a minimum-time optimal control problem to centrally control\nthe CAVs to simultaneously cross an intersection in the shortest possible time.\nDual problem theory is employed to convexify the constraints of CAVs to avoid\ncollision with each other and with road boundaries. The developed formulation\nis smooth and solvable by gradient-based algorithms. Simulation results show\nthat the proposed strategy reduces the crossing time of intersections by an\naverage of 52% and 54% as compared to, respectively, the state-of-the-art\nreservation-based and lane-free methods. Furthermore, the crossing time by the\nproposed strategy is fixed to a constant value for an intersection regardless\nof the number of CAVs.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.08270v1"
    },
    {
        "title": "Dynamic Interlining in Bus Operations",
        "authors": [
            "Seyedmostafa Zahedi",
            "Haris N. Koutsopoulos",
            "Zhenliang Ma"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The paper introduces and evaluates the concept of the dynamic interlining of\nbuses. Dynamic interlining is an operational strategy for routes that have a\nterminal station at a common hub, that allows a portion of (or all) the fleet\nto be shared among the routes belonging to the hub (shared fleet) as needed.\nThe shared fleet is dispatched on an on-demand basis to serve scheduled trips\non any route to avoid delays and regulate services. The paper examines\nsystematically the impacts of dynamic interlining on service reliability. It\nformulates the dispatching problem as an optimization problem and uses\nsimulation to evaluate the dynamic interlining strategy under a variety of\noperating conditions. Using bus routes in Boston Massachusetts Bay\nTransportation Authority (MBTA) as a case study, the feasibility of the\nstrategy, as well as factors that affect its performance are investigated.\nResults show that dynamic interlining can improve service reliability\n(increases on-time departures and decreases departure headways variability at\nthe hub). The fraction of the fleet that is shared has the most dominant impact\non performance. In the case where all buses are dynamically interlined, the\nperformance improves as route frequency increases and more routes participate\nin the strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.09971v1"
    },
    {
        "title": "On the role of population heterogeneity in emergent communication",
        "authors": [
            "Mathieu Rita",
            "Florian Strub",
            "Jean-Bastien Grill",
            "Olivier Pietquin",
            "Emmanuel Dupoux"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Populations have often been perceived as a structuring component for language\nto emerge and evolve: the larger the population, the more structured the\nlanguage. While this observation is widespread in the sociolinguistic\nliterature, it has not been consistently reproduced in computer simulations\nwith neural agents. In this paper, we thus aim to clarify this apparent\ncontradiction. We explore emergent language properties by varying agent\npopulation size in the speaker-listener Lewis Game. After reproducing the\nexperimental difference, we challenge the simulation assumption that the agent\ncommunity is homogeneous. We first investigate how speaker-listener asymmetry\nalters language structure to examine two potential diversity factors: training\nspeed and network capacity. We find out that emergent language properties are\nonly altered by the relative difference of learning speeds between speaker and\nlistener, and not by their absolute values. From then, we leverage this\nobservation to control population heterogeneity without introducing confounding\nfactors. We finally show that introducing such training speed heterogeneities\nnaturally sort out the initial contradiction: larger simulated communities\nstart developing more stable and structured languages.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.12982v1"
    },
    {
        "title": "Data assimilation with agent-based models using Markov chain sampling",
        "authors": [
            "Daniel Tang",
            "Nick Malleson"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Every day, weather forecasting centres around the world make use of noisy,\nincomplete observations of the atmosphere to update their weather forecasts.\nThis process is known as data assimilation, data fusion or state estimation and\nis best expressed as Bayesian inference: given a set of observations, some\nprior beliefs and a model of the target system, what is the probability\ndistribution of some set of unobserved quantities or latent variables at some\ntime, possibly in the future?\n  While data assimilation has developed rapidly in some areas, relatively\nlittle progress has been made in performing data assimilation with agent-based\nmodels. This has hampered the use of agent-based models to make quantitative\nclaims about real-world systems.\n  Here we present an algorithm that uses Markov-Chain-Monte-Carlo methods to\ngenerate samples of the parameters and trajectories of an agent-based model\nover a window of time given a set of possibly noisy, aggregated and incomplete\nobservations of the system. This can be used as-is, or as part of a data\nassimilation cycle or sequential-MCMC algorithm.\n  Our algorithm is applicable to time-stepping, agent-based models whose agents\nhave a finite set of states and a finite number of ways of acting on the world.\nAs presented the algorithm is only practical for agents with a few bytes of\ninternal state although we discuss ways of removing this restriction. We\ndemonstrate the algorithm by performing data assimilation with an agent-based,\nspatial predator-prey model.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.01616v1"
    },
    {
        "title": "On the Complexity of Majority Illusion in Social Networks",
        "authors": [
            "Umberto Grandi",
            "Grzegorz Lisowski",
            "M. S. Ramanujan",
            "Paolo Turrini"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Majority illusion occurs in a social network when the majority of the network\nnodes belong to a certain type but each node's neighbours mostly belong to a\ndifferent type, therefore creating the wrong perception, i.e., the illusion,\nthat the majority type is different from the actual one. From a system\nengineering point of view, we want to devise algorithms to detect and,\ncrucially, correct this undesirable phenomenon. In this paper we initiate the\ncomputational study of majority illusion in social networks, providing\ncomplexity results for its occurrence and avoidance. Namely, we show that\nidentifying whether a network can be labelled such that majority illusion is\npresent, as well as the problem of removing an illusion by adding or deleting\nedges of the network, are NP-complete problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.02056v1"
    },
    {
        "title": "Utility-Based Context-Aware Multi-Agent Recommendation System for Energy\n  Efficiency in Residential Buildings",
        "authors": [
            "Valentyna Riabchuk",
            "Leon Hagel",
            "Felix Germaine",
            "Alona Zharova"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  A significant part of CO2 emissions is due to high electricity consumption in\nresidential buildings. Using load shifting can help to improve the households'\nenergy efficiency. To nudge changes in energy consumption behavior, simple but\npowerful architectures are vital. This paper presents a novel algorithm of a\nrecommendation system generating device usage recommendations and suggests a\nframework for evaluating its performance by analyzing potential energy cost\nsavings. As a utility-based recommender system, it models user preferences\ndepending on habitual device usage patterns, user availability, and device\nusage costs. As a context-aware system, it requires an external hourly\nelectricity price signal and appliance-level energy consumption data. Due to a\nmulti-agent architecture, it provides flexibility and allows for adjustments\nand further enhancements. Empirical results show that the system can provide\nenergy cost savings of 18% and more for most studied households.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.02704v1"
    },
    {
        "title": "Learning to Cooperate with Completely Unknown Teammates",
        "authors": [
            "Alexandre Neves",
            "Alberto Sardinha"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  A key goal of ad hoc teamwork is to develop a learning agent that cooperates\nwith unknown teams, without resorting to any pre-coordination protocol. Despite\na vast number of ad hoc teamwork algorithms in the literature, most of them\ncannot address the problem of learning to cooperate with a completely unknown\nteam, unless it learns from scratch. This article presents a novel approach\nthat uses transfer learning alongside the state-of-the-art PLASTIC-Policy to\nadapt to completely unknown teammates quickly. We test our solution within the\nHalf Field Offense simulator with five different teammates. The teammates were\ndesigned independently by developers from different countries and at different\ntimes. Our empirical evaluation shows that it is advantageous for an ad hoc\nagent to leverage its past knowledge when adapting to a new team instead of\nlearning how to cooperate with it from scratch.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.03289v1"
    },
    {
        "title": "Collaborative Multi-Radars Tracking by Distributed Auctions",
        "authors": [
            "Pierre Larrenie",
            "Cédric Buron",
            "Frédéric Barbaresco"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we present an algorithm which lies in the domain of task\nallocation for a set of static autonomous radars with rotating antennas. It\nallows a set of radars to allocate in a fully decentralized way a set of active\ntracking tasks according to their location, considering that a target can be\ntracked by several radars, in order to improve accuracy with which the target\nis tracked. The allocation algorithm proceeds through a collaborative and fully\ndecentralized auction protocol, using a collaborative auction protocol\n(Consensus Based Bundle Auction algorithm). Our algorithm is based on a double\nuse of our allocation protocol among the radars. The latter begin by allocating\ntargets, then launch a second round of allocation if theyhave resources left,\nin order to improve accuracy on targets already tracked. Our algorithm is also\nable to adapt to dynamism, i.e. to take into account the fact that the targets\nare moving and that the radar(s) most suitable for Tracking them changes as the\nmission progresses. To do this, the algorithm is restarted on a regular basis,\nto ensure that a bid made by a radar can decrease when the target moves away\nfrom it. Since our algorithm is based on collaborative auctions, it does not\nplan the following rounds, assuming that the targets are not predictable enough\nfor this. Our algorithm is however based on radars capable of anticipating the\npositions of short-term targets, thanks to a Kalman filter. The algorithm will\nbe illustrated based on a multi-radar tracking scenario where the radars,\nautonomous, must follow a set of targets in order to reduce the position\nuncertainty of the targets. Standby aspects will not be considered in this\nscenario. It is assumed that the radars can pick up targets in active pursuit,\nwith an area ofuncertainty corresponding to their distance.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.05334v1"
    },
    {
        "title": "Decentralized Autonomous Organizations for Tax Credit's Tracking",
        "authors": [
            "Giovanni De Gasperis",
            "Sante Dino Facchini",
            "Alessio Susco"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Tax credit stimulus and fiscal bonuses had a very important impact on Italian\neconomy in the last decade. Along with a huge expansion in constructions a\nrelevant increase in scams and frauds has come too. The aim of this article is\nto design a possible system to track and control the whole tax credit process\nfrom its generation to its redeem through a Decentralized Autonomous\nOrganization architecture enriched with a Multi Agent Systems to implement\ncontrollers.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10075v1"
    },
    {
        "title": "Multi-stage Resilience Management of Smart Power Distribution Systems: A\n  Stochastic Robust Optimization Model",
        "authors": [
            "Nariman L. Dehghani",
            "Abdollah Shafieezadeh"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Significant outages from weather and climate extremes have highlighted the\ncritical need for resilience-centered risk management of the grid. This paper\nproposes a multi-stage stochastic robust optimization (SRO) model that advances\nthe existing planning frameworks on two main fronts. First, it captures\ninteractions of operational measures with hardening decisions. Second, it\nproperly treats the multitude of uncertainties in planning. The SRO model\ncoordinates hardening and system operational measures for smart power\ndistribution systems equipped with distributed generation units and switches.\nTo capture the uncertainty in the incurred damage by extreme events, an\nuncertainty set is developed by integrating probabilistic information of\nhurricanes with the performance of overhead structures. A novel probabilistic\nmodel for the repair time of damaged lines is derived to account for the\nuncertainty in the recovery process. A solution strategy based on the\nintegration of a differential evolution algorithm and a mixed-integer solver is\ndesigned to solve the resilience maximization model. The proposed approach is\napplied to a modified IEEE 33-bus system with 485 utility poles and a 118-bus\nsystem with 1841 poles. The systems are mapped on the Harris County, TX, U.S.\nResults reveal that optimal hardening decisions can be significantly influenced\nby resilience operational measures.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10459v1"
    },
    {
        "title": "Zero-Emission Delivery for Logistics and Transportation: Challenges,\n  Research Issues, and Opportunities",
        "authors": [
            "J. Bukhari",
            "A. G. Somanagoudar",
            "L. Hou",
            "O. Herrera",
            "W. Merida"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Greenhouse gas, produced from various industries such as Power,\nManufacturing, Transport, Chemical, or Agriculture, is the major source of\nglobal warming. While the transport industry is among the top three major\ncontributors, accounting for 16.2% of global emissions. To counter this, many\ncountries are responding actively to achieve net or absolute zero-emission\ngoals by replacing fossil fuel with renewable energy sources. In response to\nthis initiative, this chapter provides a systematic review of the use of\nzero-emission vehicles for a specific use case of package delivery. It first\ncompares different green delivery systems that use unmanned aerial vehicles,\nelectric vehicles, and fuel-cell trucks for certain weight categories.\nSpecifically, a coordination of unmanned aerial vehicle and ground-based\nelectric truck envisions a new paradigm of ground-based zero-emission vehicles\nwhere unmanned aerial vehicles can fly in the air beyond the visual line of\nsight empowered by future-generation wireless technologies. The integration of\nzero-emission vehicles for package delivery will encounter many challenges in\nanalyzing, modelling, planning, and designing a green logistics system. This\nchapter investigates these challenges in the adoption of zero-emission vehicles\nwith the existing research issues from a technical, environmental, economic,\nand political point of view. In addition, this study also sheds a new research\nperspective on artificial intelligence and integrated solutions for\nzero-emission deliveries.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.15606v1"
    },
    {
        "title": "Learning Generalizable Risk-Sensitive Policies to Coordinate in\n  Decentralized Multi-Agent General-Sum Games",
        "authors": [
            "Ziyi Liu",
            "Xian Guo",
            "Yongchun Fang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  While various multi-agent reinforcement learning methods have been proposed\nin cooperative settings, few works investigate how self-interested learning\nagents achieve mutual coordination in decentralized general-sum games and\ngeneralize pre-trained policies to non-cooperative opponents during execution.\nIn this paper, we present Generalizable Risk-Sensitive Policy (GRSP). GRSP\nlearns the distributions over agent's return and estimate a dynamic\nrisk-seeking bonus to discover risky coordination strategies. Furthermore, to\navoid overfitting to training opponents, GRSP learns an auxiliary opponent\nmodeling task to infer opponents' types and dynamically alter corresponding\nstrategies during execution. Empirically, agents trained via GRSP can achieve\nmutual coordination during training stably and avoid being exploited by\nnon-cooperative opponents during execution. To the best of our knowledge, it is\nthe first method to learn coordination strategies between agents both in\niterated prisoner's dilemma (IPD) and iterated stag hunt (ISH) without shaping\nopponents or rewards, and firstly consider generalization during execution.\nFurthermore, we show that GRSP can be scaled to high-dimensional settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.15859v3"
    },
    {
        "title": "A Geometry-Sensitive Quorum Sensing Algorithm for the Best-of-N Site\n  Selection Problem",
        "authors": [
            "Grace Cai",
            "Nancy Lynch"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The house hunting behavior of the Temnothorax albipennis ant allows the\ncolony to explore several nest choices and agree on the best one. Their\nbehavior serves as the basis for many bio-inspired swarm models to solve the\nsame problem. However, many of the existing site selection models in both\ninsect colony and swarm literature test the model's accuracy and decision time\nonly on setups where all potential site choices are equidistant from the\nswarm's starting location. These models do not account for the geographic\nchallenges that result from site choices with different geometry. For example,\nalthough actual ant colonies are capable of consistently choosing a higher\nquality, further site instead of a lower quality, closer site, existing models\nare much less accurate in this scenario. Existing models are also more prone to\ncommitting to a low quality site if it is on the path between the agents'\nstarting site and a higher quality site. We present a new model for the site\nselection problem and verify via simulation that is able to better handle these\ngeographic challenges. Our results provide insight into the types of challenges\nsite selection models face when distance is taken into account. Our work will\nallow swarms to be robust to more realistic situations where sites could be\ndistributed in the environment in many different ways.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00587v1"
    },
    {
        "title": "Post-Disaster Repair Crew Assignment Optimization Using Minimum Latency",
        "authors": [
            "Anakin Dey",
            "Melkior Ornik"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Across infrastructure domains, physical damage caused by storms and other\nweather events often requires costly and time-sensitive repairs to restore\nservices as quickly as possible. While recent studies have used agent-based\nmodels to estimate the cost of repairs, the implemented strategies for\nassignment of repair crews to different locations are generally human-driven or\nbased on simple rules. In order to find performant strategies, we continue with\nan agent-based model, but approach this problem as a combinational optimization\nproblem known as the Minimum Weighted Latency Problem for multiple repair\ncrews. We apply a partitioning algorithm that balances the assignment of\ntargets amongst all the crews using two different heuristics that optimize\neither the importance of repair locations or the travel time between them. We\nbenchmark our algorithm on both randomly generated graphs as well as data\nderived from a real-world urban environment, and show that our algorithm\ndelivers significantly better assignments than existing methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00597v3"
    },
    {
        "title": "Explainability in Mechanism Design: Recent Advances and the Road Ahead",
        "authors": [
            "Sharadhi Alape Suryanarayana",
            "David Sarne",
            "Sarit Kraus"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Designing and implementing explainable systems is seen as the next step\ntowards increasing user trust in, acceptance of and reliance on Artificial\nIntelligence (AI) systems. While explaining choices made by black-box\nalgorithms such as machine learning and deep learning has occupied most of the\nlimelight, systems that attempt to explain decisions (even simple ones) in the\ncontext of social choice are steadily catching up. In this paper, we provide a\ncomprehensive survey of explainability in mechanism design, a domain\ncharacterized by economically motivated agents and often having no single\nchoice that maximizes all individual utility functions. We discuss the main\nproperties and goals of explainability in mechanism design, distinguishing them\nfrom those of Explainable AI in general. This discussion is followed by a\nthorough review of the challenges one may face when working on Explainable\nMechanism Design and propose a few solution concepts to those.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.03031v2"
    },
    {
        "title": "A Route Network Planning Method for Urban Air Delivery",
        "authors": [
            "Xinyu He",
            "Fang He",
            "Lishuai Li",
            "Lei Zhang",
            "Gang Xiao"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  High-tech giants and start-ups are investing in drone technologies to provide\nurban air delivery service, which is expected to solve the last-mile problem\nand mitigate road traffic congestion. However, air delivery service will not\nscale up without proper traffic management for drones in dense urban\nenvironment. Currently, a range of Concepts of Operations (ConOps) for unmanned\naircraft system traffic management (UTM) are being proposed and evaluated by\nresearchers, operators, and regulators. Among these, the tube-based (or\ncorridor-based) ConOps has emerged in operations in some regions of the world\nfor drone deliveries and is expected to continue serving certain scenarios that\nwith dense and complex airspace and requires centralized control in the future.\nTowards the tube-based ConOps, we develop a route network planning method to\ndesign routes (tubes) in a complex urban environment in this paper. In this\nmethod, we propose a priority structure to decouple the network planning\nproblem, which is NP-hard, into single-path planning problems. We also\nintroduce a novel space cost function to enable the design of dense and aligned\nroutes in a network. The proposed method is tested on various scenarios and\ncompared with other state-of-the-art methods. Results show that our method can\ngenerate near-optimal route networks with significant computational\ntime-savings.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.03085v2"
    },
    {
        "title": "About Digital Twins, agents, and multiagent systems: a\n  cross-fertilisation journey",
        "authors": [
            "Stefano Mariani",
            "Marco Picone",
            "Alessandro Ricci"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Digital Twins (DTs) are rapidly emerging as a fundamental brick of\nengineering cyber-physical systems, but their notion is still mostly bound to\nspecific business domains (e.g. manufacturing), goals (e.g. product design), or\napplication domains (e.g. the Internet of Things). As such, their value as\ngeneral purpose engineering abstractions is yet to be fully revealed. In this\npaper, we relate DTs with agents and multiagent systems, as the latter are\narguably the most rich abstractions available for the engineering of complex\nsocio-technical and cyber-physical systems, and the former could both fill in\nsome gaps in agent-oriented engineering and benefit from an agent-oriented\ninterpretation -- in a cross-fertilisation journey.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.03253v1"
    },
    {
        "title": "Characterizing Properties and Trade-offs of Centralized Delegation\n  Mechanisms in Liquid Democracy",
        "authors": [
            "Brian Brubach",
            "Audrey Ballarin",
            "Heeba Nazeer"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Liquid democracy is a form of transitive delegative democracy that has\nreceived a flurry of scholarly attention from the computer science community in\nrecent years. In its simplest form, every agent starts with one vote and may\nhave other votes assigned to them via delegation from other agents. They can\nchoose to delegate all votes assigned to them to another agent or vote directly\nwith all votes assigned to them. However, many proposed realizations of liquid\ndemocracy allow for agents to express their delegation/voting preferences in\nmore complex ways (e.g., a ranked list of potential delegates) and employ a\ncentralized delegation mechanism to compute the final vote tally. In doing so,\ncentralized delegation mechanisms can make decisions that affect the outcome of\na vote and where/whether agents are able to delegate their votes. Much of the\nanalysis thus far has focused on the ability of these mechanisms to make a\ncorrect choice. We extend this analysis by introducing and formalizing other\nimportant properties of a centralized delegation mechanism in liquid democracy\nwith respect to crucial features such as accountability, transparency,\nexplainability, fairness, and user agency. In addition, we evaluate existing\nmethods in terms of these properties, show how some prior work can be augmented\nto achieve desirable properties, prove impossibility results for achieving\ncertain sets of properties simultaneously, and highlight directions for future\nwork.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.05339v1"
    },
    {
        "title": "Convergence and Stability of Coupled Belief--Strategy Learning Dynamics\n  in Continuous Games",
        "authors": [
            "Manxi Wu",
            "Saurabh Amin",
            "Asuman Ozdaglar"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We propose a learning dynamics to model how strategic agents repeatedly play\na continuous game while relying on an information platform to learn an unknown\npayoff-relevant parameter. In each time step, the platform updates a belief\nestimate of the parameter based on players' strategies and realized payoffs\nusing Bayes's rule. Then, players adopt a generic learning rule to adjust their\nstrategies based on the updated belief. We present results on the convergence\nof beliefs and strategies and the properties of convergent fixed points of the\ndynamics. We obtain sufficient and necessary conditions for the existence of\nglobally stable fixed points. We also provide sufficient conditions for the\nlocal stability of fixed points. These results provide an approach to analyzing\nthe long-term outcomes that arise from the interplay between Bayesian belief\nlearning and strategy learning in games, and enable us to characterize\nconditions under which learning leads to a complete information equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.05637v2"
    },
    {
        "title": "On-the-fly Adaptation of Patrolling Strategies in Changing Environments",
        "authors": [
            "Tomáš Brázdil",
            "David Klaška",
            "Antonín Kučera",
            "Vít Musil",
            "Petr Novotný",
            "Vojtěch Řehák"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We consider the problem of efficient patrolling strategy adaptation in a\nchanging environment where the topology of Defender's moves and the importance\nof guarded targets change unpredictably. The Defender must instantly switch to\na new strategy optimized for the new environment, not disrupting the ongoing\npatrolling task, and the new strategy must be computed promptly under all\ncircumstances. Since strategy switching may cause unintended security risks\ncompromising the achieved protection, our solution includes mechanisms for\ndetecting and mitigating this problem. The efficiency of our framework is\nevaluated experimentally.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.08096v1"
    },
    {
        "title": "Cooperative Edge Caching via Multi Agent Reinforcement Learning in Fog\n  Radio Access Networks",
        "authors": [
            "Qi Chang",
            "Yanxiang Jiang",
            "Fu-Chun Zheng",
            "Mehdi Bennis",
            "Xiaohu You"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, the cooperative edge caching problem in fog radio access\nnetworks (F-RANs) is investigated. To minimize the content transmission delay,\nwe formulate the cooperative caching optimization problem to find the globally\noptimal caching strategy.By considering the non-deterministic polynomial hard\n(NP-hard) property of this problem, a Multi Agent Reinforcement Learning\n(MARL)-based cooperative caching scheme is proposed.Our proposed scheme applies\ndouble deep Q-network (DDQN) in every fog access point (F-AP), and introduces\nthe communication process in multi-agent system. Every F-AP records the\nhistorical caching strategies of its associated F-APs as the observations of\ncommunication procedure.By exchanging the observations, F-APs can leverage the\ncooperation and make the globally optimal caching strategy.Simulation results\nshow that the proposed MARL-based cooperative caching scheme has remarkable\nperformance compared with the benchmark schemes in minimizing the content\ntransmission delay.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09549v1"
    },
    {
        "title": "A Fast Algorithm for Robust Action Selection in Multi-Agent Systems",
        "authors": [
            "Jun Liu",
            "Ryan K. Williams"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we consider a robust action selection problem in multi-agent\nsystems where performance must be guaranteed when the system suffers a\nworst-case attack on its agents. Specifically, agents are tasked with selecting\nactions from a common ground set according to individualized objective\nfunctions, and we aim to protect the system against attacks. In our problem\nformulation, attackers attempt to disrupt the system by removing an agent's\ncontribution after knowing the system solution and thus can attack perfectly.\nTo protect the multi-agent system against such attacks, we aim to maximize the\nminimum performance of all agents' individual objective functions under\nattacks. Thus, we propose a fast algorithm with tunable parameters for\nbalancing complexity and performance, yielding substantially improved time\ncomplexity and performance compared to recent methods. Finally, we provide\nMonte Carlo simulations to demonstrate the performance of the proposed\nalgorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.11824v1"
    },
    {
        "title": "Insect-inspired Visually-guided Decentralized Swarming",
        "authors": [
            "Mehdi Yadipour",
            "Imraan A. Faruque"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper addresses the need for fast, lightweight, vision-guided swarming\nunder limited computation and no explicit communication network or position\nsource. The study develops a multi-agent optic flow sensing framework, then\nintegrates perfect information distributed feedback with optic flow sensing to\ncreate an analogous visually-guided feedback path for idealized inter-agent\nvelocity and distance structures. The Cucker-Smale flocking example is used to\ndevelop vision-guided swarming with rigorous asymptotic convergence guarantees,\nincluding under ignorance of agent size.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.12482v1"
    },
    {
        "title": "Quick Relaxation in Collective Motion",
        "authors": [
            "Bernard Chazelle",
            "Kritkorn Karntikoon"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We establish sufficient conditions for the quick relaxation to kinetic\nequilibrium in the classic Vicsek-Cucker-Smale model of bird flocking. The\nconvergence time is polynomial in the number of birds as long as the number of\nflocks remains bounded. This new result relies on two key ingredients:\nexploiting the convex geometry of embedded averaging systems; and deriving new\nbounds on the s-energy of disconnected agreement systems. We also apply our\ntechniques to bound the relaxation time of certain pattern-formation robotic\nsystems investigated by Sugihara and Suzuki.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00213v1"
    },
    {
        "title": "Metacognitive Decision Making Framework for Multi-UAV Target Search\n  Without Communication",
        "authors": [
            "J. Senthilnath",
            "K. Harikumar",
            "S. Suresh"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper presents a new Metacognitive Decision Making (MDM) framework\ninspired by human-like metacognitive principles. The MDM framework is\nincorporated in unmanned aerial vehicles (UAVs) deployed for decentralized\nstochastic search without communication for detecting stationary targets\n(fixed/sudden pop-up) and dynamic targets. The UAVs are equipped with multiple\nsensors (varying sensing capability) and search for targets in a largely\nunknown area. The MDM framework consists of a metacognitive component and a\nself-cognitive component. The metacognitive component helps to self-regulate\nthe search with multiple sensors addressing the issues of\n\"which-sensor-to-use\", \"when-to-switch-sensor\", and \"how-to-search\". Each\nsensor possesses inverse characteristics for the sensing attributes like\nsensing range and accuracy. Based on the information gathered by multiple\nsensors carried by each UAV, the self-cognitive component regulates different\nlevels of stochastic search and switching levels for effective searching. The\nlower levels of search aim to localize the search space for the possible\npresence of a target (detection) with different sensors. The highest level of a\nsearch exploits the search space for target confirmation using the sensor with\nthe highest accuracy among all sensors. The performance of the MDM framework\nwith two sensors having low accuracy with wide range sensor for detection and\nincreased accuracy with low range sensor for confirmation is evaluated through\nMonte-Carlo simulations and compared with six multi-UAV stochastic search\nalgorithms (three self-cognitive searches and three self and social-cognitive\nbased search). The results indicate that the MDM framework is efficient in\ndetecting and confirming targets in an unknown environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00725v2"
    },
    {
        "title": "Hierarchical Dynamic Routing in Complex Networks via\n  Topologically-decoupled and Cooperative Reinforcement Learning Agents",
        "authors": [
            "Shiyuan Hu",
            "Shihan Xiao"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The transport capacity of a communication network can be characterized by the\ntransition from a free-flow state to a congested state. Here, we propose a\ndynamic routing strategy in complex networks based on hierarchical bypass\nselections. The routing decisions are made by the reinforcement learning agents\nimplemented at selected nodes with high betweenness centrality. The learning\nprocesses of the agents are decoupled from each other due to the degeneracy of\ntheir bypasses. Through interactions mediated by the underlying traffic\ndynamics, the agents act cooperatively, and coherent actions arise\nspontaneously. With only a small number of agents, the transport capacities are\nsignificantly improved, including in real-world Internet networks at the router\nlevel and the autonomous system level. Our strategy is also resilient to link\nremovals.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00763v1"
    },
    {
        "title": "NVIF: Neighboring Variational Information Flow for Large-Scale\n  Cooperative Multi-Agent Scenarios",
        "authors": [
            "Jiajun Chai",
            "Yuanheng Zhu",
            "Dongbin Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Communication-based multi-agent reinforcement learning (MARL) provides\ninformation exchange between agents, which promotes the cooperation. However,\nexisting methods cannot perform well in the large-scale multi-agent system. In\nthis paper, we adopt neighboring communication and propose a Neighboring\nVariational Information Flow (NVIF) to provide efficient communication for\nagents. It employs variational auto-encoder to compress the shared information\ninto a latent state. This communication protocol does not rely dependently on a\nspecific task, so that it can be pre-trained to stabilize the MARL training.\nBesides. we combine NVIF with Proximal Policy Optimization (NVIF-PPO) and Deep\nQ Network (NVIF-DQN), and present a theoretical analysis to illustrate NVIF-PPO\ncan promote cooperation. We evaluate the NVIF-PPO and NVIF-DQN on MAgent, a\nwidely used large-scale multi-agent environment, by two tasks with different\nmap sizes. Experiments show that our method outperforms other compared methods,\nand can learn effective and scalable cooperation strategies in the large-scale\nmulti-agent system.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00964v1"
    },
    {
        "title": "EasyABM: a lightweight and easy to use heterogeneous agent-based\n  modelling tool written in Julia",
        "authors": [
            "Renu Solanki",
            "Monisha Khanna",
            "Shailly Anand",
            "Anita Gulati",
            "Prateek Kumar",
            "Munendra Kumar",
            "Dushyant Kumar"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Agent based modelling is a computational approach that aims to understand the\nbehaviour of complex systems through simplified interactions of programmable\nobjects in computer memory called agents. Agent based models (ABMs) are\npredominantly used in fields of biology, ecology, social sciences and economics\nwhere the systems of interest often consist of several interacting entities. In\nthis work, we present a Julia package EasyABM.jl for simplifying the process of\nstudying agent based models. EasyABM.jl provides an intuitive and easy to\nunderstand functional approach for building and analysing agent based models.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.02107v1"
    },
    {
        "title": "A Distributed Diffusion Kalman Filter In Multitask Networks",
        "authors": [
            "Ijeoma Amuche Chikwendu",
            "Kulevome Delanyo Kwame Bensah",
            "Chiagoziem Chima Ukwuoma",
            "Chukwuebuka Joseph Ejiyi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The Distributed Diffusion Kalman Filter (DDKF) algorithm in all its magnitude\nhas earned great attention lately and has shown an elaborate way to address the\nissue of distributed optimization over networks. Estimation and tracking of a\nsingle state vector collectively by nodes have been the point of focus. In\nreality, however, there are several multi-task-oriented issues where the\noptimal state vector for each node may not be the same. Its objective is to\nknow many related tasks simultaneously, rather than the typical single-task\nproblems. This work considers sensor networks for distributed multi-task\ntracking in which individual nodes communicate with its immediate nodes. A\ndiffusion-based distributed multi-task tracking algorithm is developed. This is\ndone by implementing an unsupervised adaptive clustering process, which aids\nnodes in forming clusters and collaborating on tasks. For distributed target\ntracking, an adaptive clustering approach, which gives agents the ability to\nidentify and select through adaptive adjustments of combination weights nodes\nwho to collaborate with and who not to in order to estimate the common state\nvector. This gave rise to an effective level of cooperation for improving state\nvector estimation accuracy, especially in cases where a cluster's background\nexperience is unknown. To demonstrate the efficiency of our algorithm, computer\nsimulations were conducted. Comparison has been carried out for the Diffusion\nKalman Filter multitask with respect to the Adapt then combine (ATC) diffusion\nschemes utilizing both static and adaptive combination weights. Results showed\nthat the ATC diffusion schemes algorithm has great performance with the\nadaptive combiners as compared to static combiners.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.03181v1"
    },
    {
        "title": "Cooperative Marine Operations via Ad Hoc Teams",
        "authors": [
            "Ignacio Carlucho",
            "Arrasy Rahman",
            "William Ard",
            "Elliot Fosong",
            "Corina Barbalata",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  While research in ad hoc teamwork has great potential for solving real-world\nrobotic applications, most developments so far have been focusing on\nenvironments with simple dynamics. In this article, we discuss how the problem\nof ad hoc teamwork can be of special interest for marine robotics and how it\ncan aid marine operations. Particularly, we present a set of challenges that\nneed to be addressed for achieving ad hoc teamwork in underwater environments\nand we discuss possible solutions based on current state-of-the-art\ndevelopments in the ad hoc teamwork literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.07498v1"
    },
    {
        "title": "Towards VEsNA, a Framework for Managing Virtual Environments via Natural\n  Language Agents",
        "authors": [
            "Andrea Gatti",
            "Viviana Mascardi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Automating a factory where robots are involved is neither trivial nor cheap.\nEngineering the factory automation process in such a way that return of\ninterest is maximized and risk for workers and equipment is minimized, is hence\nof paramount importance. Simulation can be a game changer in this scenario but\nrequires advanced programming skills that domain experts and industrial\ndesigners might not have. In this paper we present the preliminary design and\nimplementation of a general-purpose framework for creating and exploiting\nVirtual Environments via Natural language Agents (VEsNA). VEsNA takes advantage\nof agent-based technologies and natural language processing to enhance the\ndesign of virtual environments. The natural language input provided to VEsNA is\nunderstood by a chatbot and passed to a cognitive intelligent agent that\nimplements the logic behind displacing objects in the virtual environment. In\nthe VEsNA vision, the intelligent agent will be able to reason on this\ndisplacement and on its compliance to legal and normative constraints. It will\nalso be able to implement what-if analysis and case-based reasoning. Objects\npopulating the virtual environment will include active objects and will\npopulate a dynamic simulation whose outcomes will be interpreted by the\ncognitive agent; explanations and suggestions will be passed back to the user\nby the chatbot.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.09711v1"
    },
    {
        "title": "Distributed control for geometric pattern formation of large-scale\n  multirobot systems",
        "authors": [
            "Andrea Giusti",
            "Gian Carlo Maffettone",
            "Davide Fiore",
            "Marco Coraggio",
            "Mario di Bernardo"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Geometric pattern formation is crucial in many tasks involving large-scale\nmulti-agent systems. Examples include mobile agents performing surveillance,\nswarm of drones or robots, or smart transportation systems. Currently, most\ncontrol strategies proposed to achieve pattern formation in network systems\neither show good performance but require expensive sensors and communication\ndevices, or have lesser sensor requirements but behave more poorly. Also, they\noften require certain prescribed structural interconnections between the agents\n(e.g., regular lattices, all-to-all networks etc). In this paper, we provide a\ndistributed displacement-based control law that allows large group of agents to\nachieve triangular and square lattices, with low sensor requirements and\nwithout needing communication between the agents. Also, a simple, yet powerful,\nadaptation law is proposed to automatically tune the control gains in order to\nreduce the design effort, while improving robustness and flexibility. We show\nthe validity and robustness of our approach via numerical simulations and\nexperiments, comparing it with other approaches from the existing literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.14567v1"
    },
    {
        "title": "A Model for Multi-Agent Heterogeneous Interaction Problems",
        "authors": [
            "Christopher D. Hsu",
            "Mulugeta A. Haile",
            "Pratik Chaudhari"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We introduce a model for multi-agent interaction problems to understand how a\nheterogeneous team of agents should organize its resources to tackle a\nheterogeneous team of attackers. This model is inspired by how the human immune\nsystem tackles a diverse set of pathogens. The key property of this model is a\n``cross-reactivity'' kernel which enables a particular defender type to respond\nstrongly to some attacker types but weakly to a few different types of\nattackers. We show how due to such cross-reactivity, the defender team can\noptimally counteract a heterogeneous attacker team using very few types of\ndefender agents, and thereby minimize its resources. We study this model in\ndifferent settings to characterize a set of guiding principles for control\nproblems with heterogeneous teams of agents, e.g., sensitivity of the harm to\nsub-optimal defender distributions, and competition between defenders gives\nnear-optimal behavior using decentralized computation of the control. We also\ncompare this model with existing approaches including reinforcement-learned\npolicies, perimeter defense, and coverage control.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.01430v4"
    },
    {
        "title": "Finite-time Motion Planning of Multi-agent Systems with Collision\n  Avoidance",
        "authors": [
            "Yilei Jiang",
            "Dongkun Han"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Finite-time motion planning with collision avoidance is a challenging issue\nin multi-agent systems. This paper proposes a novel distributed controller\nbased on a new Lyapunov barrier function which guarantees finite-time stability\nfor multi-agent systems without collisions. First, the problem of finite-time\nmotion planning of multi-agent systems is formulated. Then, a novel finite-time\ndistributed controller is developed based on a Lyapunov barrier function.\nFinally, numerical simulations demonstrate the effectiveness of proposed\nmethod.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.02020v1"
    },
    {
        "title": "Distributed Event-triggered Control of Networked Strict-feedback Systems\n  Via Intermittent State Feedback",
        "authors": [
            "Libei Sun",
            "Xiucai Huang",
            "Yongduan Song"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  It poses technical difficulty to achieve stable tracking even for single\nmismatched nonlinear strict-feedback systems when intermittent state feedback\nis utilized. The underlying problem becomes even more complicated if such\nsystems are networked with directed communication and state-triggering setting.\nIn this work, we present a fully distributed neuroadaptive tracking control\nscheme for multiple agent systems in strict-feedback form using triggered state\nfrom the agent itself and the triggered states from the neighbor agents. To\ncircumvent the non-differentiability of virtual controllers stemming from\nstate-triggering, we first develop a distributed continuous control scheme\nunder regular state feedback, upon which we construct the distributed\nevent-triggered control scheme by replacing the states in the preceding scheme\nwith the triggered ones. Several useful lemmas are introduced to allow the\nstability condition to be established with such replacement, ensuring that all\nthe closed-loop signals are semi-globally uniformly ultimately bounded (SGUUB),\nwith the output tracking error converging to a residual set around zero.\nBesides, with proper choices of the design parameters, the tracking performance\nin the mean square sense can be improved. Numerical simulation verifies the\nbenefits and efficiency of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.02415v2"
    },
    {
        "title": "Modelling the Rise and Fall of Two-Sided Mobility Markets with\n  Microsimulation",
        "authors": [
            "Farnoud Ghasemi",
            "Rafał Kucharski"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we propose a novel modelling framework to reproduce the market\nentry strategies for two-sided mobility platforms. In the MaaSSim agent-based\nsimulator, we develop a co-evolutionary model to represent day-to-day dynamics\nof the two-sided mobility market with agents making rational decisions to\nmaximize their perceived utility. Participation probability of agents depends\non utility, composed of: experience, word of mouth and marketing components\nadjusted by agents every day with the novel S-shaped formulas - better suited\n(in our opinion) to reproduce market entry dynamics than previous approaches.\nWith such a rich representation, we can realistically model a variety of market\nentry strategies and create significant network effects to reproduce the rise\nand fall of two-side mobility platforms. To illustrate model capabilities, we\nsimulate a 400-day evolution of 200 drivers and 2000 travelers on a\nroad-network of Amsterdam. We design a six-stage market entry strategy with\nconsecutive: kick-off, discount, launch, growth, maturity and greed stages.\nAfter 25 days the platform offers discounts, yet it starts gaining market share\nonly when the marketing campaign launches at day 50. Campaign finishes after 50\ndays, which does not stop the growth, now fueled mainly with a positive word of\nmouth effect and experiences. The platform ends discounts after 200 days and\nreaches the steady maturity period, after which its greedy strategy leads to\ncollapse of its market share and profit. All above simulated with a single\nbehavioral model, which well reproduces how agents of both sides adapts to\nplatform actions.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.02496v2"
    },
    {
        "title": "Agents Incorporating Identity and Dynamic Teams in Social Dilemmas",
        "authors": [
            "Kyle Tilbury",
            "Jesse Hoey"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We present our preliminary work on a multi-agent system involving the complex\nhuman phenomena of identity and dynamic teams. We outline our ongoing\nexperimentation into understanding how these factors can eliminate some of the\nnaive assumptions of current multi-agent approaches. These include a lack of\ncomplex heterogeneity between agents and unchanging team structures. We outline\nthe human social psychological basis for identity, one's sense of self, and\ndynamic teams, the changing nature of human teams. We describe our application\nof these factors to a multi-agent system and our expectations for how they\nmight improve the system's applicability to more complex problems, with\nspecific relevance to ad hoc teamwork. We expect that the inclusion of more\ncomplex human processes, like identity and dynamic teams, will help with the\neventual goal of having effective human-agent teams.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03293v2"
    },
    {
        "title": "An Agent-Based Fleet Management Model for First- and Last-Mile Services",
        "authors": [
            "Saumya Bhatnagar",
            "Tarun Rambha",
            "Gitakrishnan Ramadurai"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  With the growth of cars and car-sharing applications, commuters in many\ncities, particularly developing countries, are shifting away from public\ntransport. These shifts have affected two key stakeholders: transit operators\nand first- and last-mile (FLM) services. Although most cities continue to\ninvest heavily in bus and metro projects to make public transit attractive,\nridership in these systems has often failed to reach targeted levels. FLM\nservice providers also experience lower demand and revenues in the wake of\nshifts to other means of transport. Effective FLM options are required to\nprevent this phenomenon and make public transport attractive for commuters. One\npossible solution is to forge partnerships between public transport and FLM\nproviders that offer competitive joint mobility options. Such solutions require\nprudent allocation of supply and optimised strategies for FLM operations and\nride-sharing. To this end, we build an agent- and event-based simulation model\nwhich captures interactions between passengers and FLM services using\nstatecharts, vehicle routing models, and other trip matching rules. An\noptimisation model for allocating FLM vehicles at different transit stations is\nproposed to reduce unserved requests. Using real-world metro transit demand\ndata from Bengaluru, India, the effectiveness of our approach in improving FLM\nconnectivity and quantifying the benefits of sharing trips is demonstrated.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.04563v2"
    },
    {
        "title": "Diversifying Message Aggregation in Multi-Agent Communication via\n  Normalized Tensor Nuclear Norm Regularization",
        "authors": [
            "Yuanzhao Zhai",
            "Kele Xu",
            "Bo Ding",
            "Dawei Feng",
            "Zijian Gao",
            "Huaimin Wang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Aggregating messages is a key component for the communication of multi-agent\nreinforcement learning (Comm-MARL). Recently, it has witnessed the prevalence\nof graph attention networks (GAT) in Comm-MARL, where agents can be represented\nas nodes and messages can be aggregated via the weighted passing. While\nsuccessful, GAT can lead to homogeneity in the strategies of message\naggregation, and the ``core'' agent may excessively influence other agents'\nbehaviors, which can severely limit the multi-agent coordination. To address\nthis challenge, we first study the adjacency tensor of the communication graph\nand demonstrate that the homogeneity of message aggregation could be measured\nby the normalized tensor rank. Since the rank optimization problem is known to\nbe NP-hard, we define a new nuclear norm, which is a convex surrogate of\nnormalized tensor rank, to replace the rank. Leveraging the norm, we further\npropose a plug-and-play regularizer on the adjacency tensor, named Normalized\nTensor Nuclear Norm Regularization (NTNNR), to actively enrich the diversity of\nmessage aggregation during the training stage. We extensively evaluate GAT with\nthe proposed regularizer in both cooperative and mixed cooperative-competitive\nscenarios. The results demonstrate that aggregating messages using\nNTNNR-enhanced GAT can improve the efficiency of the training and achieve\nhigher asymptotic performance than existing message aggregation methods. When\nNTNNR is applied to existing graph-attention Comm-MARL methods, we also observe\nsignificant performance improvements on the StarCraft II micromanagement\nbenchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.05414v2"
    },
    {
        "title": "Modelleme ve Simulasyon",
        "authors": [
            "Serdar Abut"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Computer modeling and simulation is used to analyze system behavior and\nevaluate strategies for operating in descriptive or predictive modes. In this\npart of the book, modeling and simulation approaches that have been proposed\nsince the 1970s have been tried to be presented. Simulation models used in\nsocial sciences, risk management and cloud-based information systems are tried\nto be summarized, and information about agent-based modeling and simulation\napproach is given.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.06344v1"
    },
    {
        "title": "Fair Division meets Vehicle Routing: Fairness for Drivers with Monotone\n  Profits",
        "authors": [
            "Martin Damyanov Aleksandrov"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We propose a new model for fair division and vehicle routing, where drivers\nhave monotone profit preferences, and their vehicles have feasibility\nconstraints, for customer requests. For this model, we design two new axiomatic\nnotions for fairness for drivers: FEQ1 and FEF1. FEQ1 encodes driver pairwise\nbounded equitability. FEF1 encodes driver pairwise bounded envy freeness. We\ncompare FEQ1 and FEF1 with popular fair division notions such as EQ1 and EF1.\nWe also give algorithms for guaranteeing FEQ1 and FEF1, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.07094v1"
    },
    {
        "title": "A Multi-Criteria Metaheuristic Algorithm for Distributed Optimization of\n  Electric Energy Storage",
        "authors": [
            "Rico Schrage",
            "Paul Hendrik Tiemann",
            "Astrid Nieße"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The distributed schedule optimization of energy storage constitutes a\nchallenge. Such algorithms often expect an input set containing all feasible\nschedules or respectively require to efficiently search the schedule space. It\nis hardly possible to accomplish this with energy storage due to its high\nflexibility. In this paper, the problem is introduced in detail and addressed\nby a metaheuristic algorithm, which generates a preselection of schedules.\nThree contributions are presented to achieve this goal: First, an extension for\na distributed schedule optimization allowing a simultaneous optimization is\ndeveloped. Second, an evolutionary algorithm is designed to generate optimized\nschedules. Third, the algorithm is extended to include an arbitrary local\ncriterion. It is shown that the presented approach is suitable to schedule\nelectric energy storage in real households and industries with different\ngenerator and storage types.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.07185v2"
    },
    {
        "title": "Blockchain-based traffic management for Advanced Air Mobility",
        "authors": [
            "I. Romani de Oliveira",
            "T. Matsumoto",
            "E. C. Pinto Neto"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The large public interest in Advanced Air Mobility (AAM) will soon lead to\ncongested skies overhead cities, analogously to what happened with other\ntransportation means, including commercial aviation. In the latter case, the\ncombination of large distances and demanded number flights is such that a\nsystem with centralized control, with most of the decisions made by human\noperators, is safe. However, for AAM, it is expected a much higher demand,\nbecause it will be used for people's daily commutes. Thus, higher automation\nlevels will become a requirement for coordinating this traffic, which might not\nbe effectively managed by humans. The establishment of fixed air routes can\nabate complexity, however at the cost of limiting capacity and decreasing\nefficiency. Another alternative is the use of a powerful central system based\non Artificial Intelligence (AI), which would allow flexible trajectories and\nhigher efficiency. However, such system would require concentrated investment,\ncould contain Single-Points-of-Failure (SPoFs), would be a highly sought target\nof malicious attacks, and would be subject to periods of unavailability.\n  This work proposes a new technology that solves the problem of managing the\nhigh complexity of the AAM traffic with a secure distributed approach, without\nthe need for a proprietary centralized automation system. This technology\nenables distributed airspace allocation management and conflict resolution by\nmeans of trusted shared data structures and associated smart contracts running\non a blockchain ecosystem. This way, it greatly reduces the risk of system\noutages due to SPoFs, by allowing peer-to-peer conflict resolution, and being\nmore resilient to failures in the ground communication infrastructure.\nFurthermore, it provides priority-based balancing mechanisms that help to\nregulate fairness among participants in the utilization of the airspace.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.09312v1"
    },
    {
        "title": "Exploring Task-oriented Communication in Multi-agent System: A Deep\n  Reinforcement Learning Approach",
        "authors": [
            "Guojun He"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The multi-agent system (MAS) enables the sharing of capabilities among\nagents, such that collaborative tasks can be accomplished with high scalability\nand efficiency. MAS is increasingly widely applied in various fields.\nMeanwhile, the large-scale and time-sensitive data transmission between agents\nbrings challenges to the communication system. The traditional wireless\ncommunication ignores the content of the data and its impact on the task\nexecution at the receiver, which makes it difficult to guarantee the timeliness\nand relevance of the information. This limitation leads to that traditional\nwireless communication struggles to effectively support emerging multi-agent\ncollaborative applications. Faced with this dilemma, task-oriented\ncommunication is a potential solution, which aims to transmit task-relevant\ninformation to improve task execution performance. However, multi-agent\ncollaboration itself is a complex class of sequential decision problems. It is\nchallenging to explore efficient information flow in this context. In this\narticle, we use deep reinforcement learning (DRL) to explore task-oriented\ncommunication in MAS. We begin with a discussion on the application of DRL to\ntask-oriented communication. We then envision a task-oriented communication\narchitecture for MAS, and discuss the designs based on DRL. Finally, we discuss\nopen problems for future research and conclude this article.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.10165v2"
    },
    {
        "title": "Entropy Enhanced Multi-Agent Coordination Based on Hierarchical Graph\n  Learning for Continuous Action Space",
        "authors": [
            "Yining Chen",
            "Ke Wang",
            "Guanghua Song",
            "Xiaohong Jiang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In most existing studies on large-scale multi-agent coordination, the control\nmethods aim to learn discrete policies for agents with finite choices. They\nrarely consider selecting actions directly from continuous action spaces to\nprovide more accurate control, which makes them unsuitable for more complex\ntasks. To solve the control issue due to large-scale multi-agent systems with\ncontinuous action spaces, we propose a novel MARL coordination control method\nthat derives stable continuous policies. By optimizing policies with maximum\nentropy learning, agents improve their exploration in execution and acquire an\nexcellent performance after training. We also employ hierarchical graph\nattention networks (HGAT) and gated recurrent units (GRU) to improve the\nscalability and transferability of our method. The experiments show that our\nmethod consistently outperforms all baselines in large-scale multi-agent\ncooperative reconnaissance tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.10676v1"
    },
    {
        "title": "Inferring Topology of Networked Dynamical Systems by Active Excitations",
        "authors": [
            "Yushan Li",
            "Jianping He",
            "Cailian Chen",
            "Xinping Guan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Topology inference for networked dynamical systems (NDSs) has received\nconsiderable attention in recent years. The majority of pioneering works have\ndealt with inferring the topology from abundant observations of NDSs, so as to\napproximate the real one asymptotically. Leveraging the characteristic that\nNDSs will react to various disturbances and the disturbance's influence will\nconsistently spread, this paper focuses on inferring the topology by a few\nactive excitations. The key challenge is to distinguish different influences of\nsystem noises and excitations from the exhibited state deviations, where the\ninfluences will decay with time and the exciatation cannot be arbitrarily\nlarge. To practice, we propose a one-shot excitation based inference method to\ninfer $h$-hop neighbors of a node. The excitation conditions for accurate\none-hop neighbor inference are first derived with probability guarantees. Then,\nwe extend the results to $h$-hop neighbor inference and multiple excitations\ncases, providing the explicit relationships between the inference accuracy and\nexcitation magnitude. Specifically, the excitation based inference method is\nnot only suitable for scenarios where abundant observations are unavailable,\nbut also can be leveraged as auxiliary means to improve the accuracy of\nexisting methods. Simulations are conducted to verify the analytical results.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.11276v1"
    },
    {
        "title": "Emergence of group hierarchy",
        "authors": [
            "Guillaume Deffuant",
            "Thibaut Roubin"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We consider an opinion dynamics model where, during random pair interactions,\neach agent modifies her opinions about both agents of the random pair and also\nabout some other agents, chosen randomly. Moreover, each agent belongs to a\nsingle group and the opinions within the group are attracted to their average.\nIn simulations starting from neutral opinions, we observe the emergence of a\ngroup hierarchy. We derive a moment approximation that provides equations\nruling the evolution of the average opinion of agents in a group about the\nagents of another group. This approximation explains how the group hierarchy\nemerges.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12149v1"
    },
    {
        "title": "Towards A Complete Multi-Agent Pathfinding Algorithm For Large Agents",
        "authors": [
            "Stepan Dergachev",
            "Konstantin Yakovlev"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent pathfinding (MAPF) is a challenging problem which is hard to\nsolve optimally even when simplifying assumptions are adopted, e.g. planar\ngraphs (typically -- grids), discretized time, uniform duration of move and\nwait actions etc. On the other hand, MAPF under such restrictive assumptions\n(also known as the Classical MAPF) is equivalent to the so-called pebble motion\nproblem for which non-optimal polynomial time algorithms do exist. Recently, a\nbody of works emerged that investigated MAPF beyond the basic setting and, in\nparticular, considered agents of arbitrary size and shape. Still, to the best\nof our knowledge no complete algorithms for such MAPF variant exists. In this\nwork we attempt to narrow this gap by considering MAPF for large agents and\nsuggesting how this problem can be reduced to pebble motion on (general)\ngraphs. The crux of this reduction is the procedure that moves away the agents\naway from the edge which is needed to perform a move action of the current\nagent. We consider different variants of how this procedure can be implemented\nand present a variant of the pebble motion algorithm which incorporates this\nprocedure. Unfortunately, the algorithm is still incomplete, but empirically we\nshow that it is able to solve much more MAPF instances (under the strict time\nlimit) with large agents on arbitrary non-planar graphs (roadmaps) compared to\nthe state-of-the-art MAPF solver -- Continous Conflict-Based Search (CCBS).\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12236v1"
    },
    {
        "title": "A repeated unknown game: Decentralized task offloading in vehicular fog\n  computing",
        "authors": [
            "Byungjin Cho",
            "Yu Xiao"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Offloading computation to nearby edge/fog computing nodes, including the ones\ncarried by moving vehicles, e.g., vehicular fog nodes (VFN), has proved to be a\npromising approach for enabling low-latency and compute-intensive mobility\napplications, such as cooperative and autonomous driving. This work considers\nvehicular fog computing scenarios where the clients of computation offloading\nservices try to minimize their own costs while deciding which VFNs to offload\ntheir tasks. We focus on decentralized multi-agent decision-making in a\nrepeated unknown game where each agent, e.g., service client, can observe only\nits own action and realized cost. In other words, each agent is unaware of the\ngame composition or even the existence of opponents. We apply a completely\nuncoupled learning rule to generalize the decentralized decision-making\nalgorithm presented in \\cite{Cho2021} for the multi-agent case. The multi-agent\nsolution proposed in this work can capture the unknown offloading cost\nvariations susceptive to resource congestion under an adversarial framework\nwhere each agent may take implicit cost estimation and suitable resource choice\nadapting to the dynamics associated with volatile supply and demand. According\nto the evaluation via simulation, this work reveals that such individual\nperturbations for robustness to uncertainty and adaptation to dynamicity ensure\na certain level of optimality in terms of social welfare, e.g., converging the\nactual sequence of play with unknown and asymmetric attributes and lowering the\ncorrespondent cost in social welfare due to the self-interested behaviors of\nagents.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01353v2"
    },
    {
        "title": "Learning to Deceive in Multi-Agent Hidden Role Games",
        "authors": [
            "Matthew Aitchison",
            "Lyndon Benke",
            "Penny Sweetser"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Deception is prevalent in human social settings. However, studies into the\neffect of deception on reinforcement learning algorithms have been limited to\nsimplistic settings, restricting their applicability to complex real-world\nproblems. This paper addresses this by introducing a new mixed\ncompetitive-cooperative multi-agent reinforcement learning (MARL) environment\ninspired by popular role-based deception games such as Werewolf, Avalon, and\nAmong Us. The environment's unique challenge lies in the necessity to cooperate\nwith other agents despite not knowing if they are friend or foe. Furthermore,\nwe introduce a model of deception, which we call Bayesian belief manipulation\n(BBM) and demonstrate its effectiveness at deceiving other agents in this\nenvironment while also increasing the deceiving agent's performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01551v1"
    },
    {
        "title": "Empirically grounded agent-based policy evaluation of the adoption of\n  sustainable lighting under the European Ecodesign Directive",
        "authors": [
            "Gido H. Schoenmacker",
            "Wander Jager",
            "Rineke Verbrugge"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Twelve years ago, the European Union began with the gradual phase-out of\nenergy-inefficient incandescent light bulbs under the Ecodesign Directive. In\nthis work, we implement an agent-based simulation to model the consumer\nbehaviour in the EU lighting market with the goal to explain consumer behaviour\nand explore alternative policies. Agents are based on the Consumat II model,\nhave individual preferences based on empirical market research, gather\nexperience from past actions, and socially interact with each other in a\ndynamic environment. Our findings suggest that the adoption of energy-friendly\nlighting alternatives was hindered by a low level of consumer interest combined\nwith high-enough levels of satisfaction about incandescent bulbs and that\ninformation campaigns can partially address this. These findings offer insight\ninto both individual-level driving forces of behaviour and society-level\noutcomes in a niche market. With this, our work demonstrates the strengths of\nagent-based models for policy generation and evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.05109v1"
    },
    {
        "title": "Exploration and Coverage with Swarms of Settling Agents",
        "authors": [
            "Ori Rappel",
            "Joseph Ben-Asher",
            "Alfred Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We consider several algorithms for exploring and filling an unknown,\nconnected region, by simple, airborne agents. The agents are assumed to be\nidentical, autonomous, anonymous and to have a finite amount of memory. The\nregion is modeled as a connected sub-set of a regular grid composed of square\ncells. The algorithms described herein are suited for Micro Air Vehicles (MAV)\nsince these air vehicles enable unobstructed views of the ground below and can\nmove freely in space at various heights. The agents explore the region by\napplying various action-rules based on locally acquired information Some of\nthem may settle in unoccupied cells as the exploration progresses. Settled\nagents become virtual pheromones for the exploration and coverage process,\nbeacons that subsequently aid the remaining, and still exploring, mobile\nagents. We introduce a backward propagating information diffusion process as a\nway to implement a deterministic indicator of process termination and guide the\nmobile agents. For the proposed algorithms, complete covering of the graph in\nfinite time is guaranteed when the size of the region is fixed. Bounds on the\ncoverage times are also derived. Extensive simulation results exhibit good\nagreement with the theoretical predictions.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.05512v2"
    },
    {
        "title": "Collective Adaptation in Multi-Agent Systems: How Predator Confusion\n  Shapes Swarm-Like Behaviors",
        "authors": [
            "Georgi Ivanov",
            "George Palamas"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Popular hypotheses about the origins of collective adaptation are related to\ntwo basic behaviours: protection from predators and a combined search for food\nresources. Among the anti-predator explanations, the predator confusion\nhypothesis suggests that groups of individuals moving in a swarm aim to\noverwhelm the predator while the dilution of risk hypothesis suggests that the\nprobability of a single prey being targeted by a predator is lower in larger\ngroups. In this paper, we explore how emergent behaviors arise from a\npredator-driven process as an adaptive response to external stimuli perceived\nas threatening. Moreover, we suggest a predator confusion process to provide a\nselective pressure for the prey to evolve group formations. We analyze the\nforaging and prey-predator dynamics evolved in terms of group density and\nformation, behavior consistency, predator evasion and success rate, and\nforaging rate. Two agents' perceptual models are compared. A local observation\nmodel, where agents can only see what's in their immediate vicinity, and a\nglobal observation model, where agents are able to see the predator at all\ntimes. Both models were evolved for predator avoidance, foraging and collision\navoidance, using reinforcement learning in a simulated game environment. Our\nresults suggest that the dilution of risk factor is sufficient to evolve group\nformations, and the predator confusion effect could play an important role in\nthe evolution of collaborative behaviors. Finally, we show how variations in\nthe information exchange of this social order can impact the global collective\nbehaviors.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.06338v1"
    },
    {
        "title": "ASIR: Robust Agent-based Representation Of SIR Model",
        "authors": [
            "Boyan Xu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Compartmental models (written as $CM$) and agent-based models (written as\n$AM$) are dominant methods in the field of epidemic simulation. But in the\nliterature there lacks discussion on how to build the \\textbf{quantitative\nrelationship} between them. In this paper, we propose an agent-based $SIR$\nmodel: $ASIR$. $ASIR$ can robustly reproduce the infection curve predicted by a\ngiven SIR model (the simplest $CM$.) Notably, one can deduce any parameter of\n$ASIR$ from parameters of $SIR$ without manual tuning. $ASIR$ offers\nepidemiologists a method to transform a calibrated $SIR$ model into an\nagent-based model that inherit $SIR$'s performance without another round of\ncalibration. The design $ASIR$ is inspirational for building a general\nquantitative relationship between $CM$ and $AM$.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.08214v1"
    },
    {
        "title": "Too Global To Be Local: Swarm Consensus in Adversarial Settings",
        "authors": [
            "Lior Moshe",
            "Noa Agmon"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Reaching a consensus in a swarm of robots is one of the fundamental problems\nin swarm robotics, examining the possibility of reaching an agreement within\nthe swarm members. The recently-introduced contamination problem offers a new\nperspective of the problem, in which swarm members should reach a consensus in\nspite of the existence of adversarial members that intentionally act to divert\nthe swarm members towards a different consensus. In this paper, we search for a\nconsensus-reaching algorithm under the contamination problem setting by taking\na top-down approach: We transform the problem to a centralized two-player game\nin which each player controls the behavior of a subset of the swarm, trying to\nforce the entire swarm to converge to an agreement on its own value. We define\na performance metric for each players performance, proving a correlation\nbetween this metric and the chances of the player to win the game. We then\npresent the globally optimal solution to the game and prove that unfortunately\nit is unattainable in a distributed setting, due to the challenging\ncharacteristics of the swarm members. We therefore examine the problem on a\nsimplified swarm model, and compare the performance of the globally optimal\nstrategy with locally optimal strategies, demonstrating its superiority in\nrigorous simulation experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.08587v1"
    },
    {
        "title": "Synthesis of Cost-Optimal Multi-Agent Systems for Resource Allocation",
        "authors": [
            "Nils Timm",
            "Josua Botha"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent systems for resource allocation (MRAs) have been introduced as a\nconcept for modelling competitive resource allocation problems in distributed\ncomputing. An MRA is composed of a set of agents and a set of resources. Each\nagent has goals in terms of allocating certain resources. For MRAs it is\ntypically of importance that they are designed in a way such that there exists\na strategy that guarantees that all agents will achieve their goals. The\ncorresponding model checking problem is to determine whether such a winning\nstrategy exists or not, and the synthesis problem is to actually build the\nstrategy. While winning strategies ensure that all goals will be achieved,\nfollowing such strategies does not necessarily involve an optimal use of\nresources.\n  In this paper, we present a technique that allows to synthesise cost-optimal\nsolutions to distributed resource allocation problems. We consider a scenario\nwhere system components such as agents and resources involve costs. A\nmulti-agent system shall be designed that is cost-minimal but still capable of\naccomplishing a given set of goals. Our approach synthesises a winning strategy\nthat minimises the cumulative costs of the components that are required for\nachieving the goals. The technique is based on a propositional logic encoding\nand a reduction of the synthesis problem to the maximum satisfiability problem\n(Max-SAT). Hence, a Max-SAT solver can be used to perform the synthesis. From a\ntruth assignment that maximises the number of satisfied clauses of the encoding\na cost-optimal winning strategy as well as a cost-optimal system can be\nimmediately derived.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.09473v1"
    },
    {
        "title": "Rethinking Individual Global Max in Cooperative Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Yitian Hong",
            "Yaochu Jin",
            "Yang Tang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In cooperative multi-agent reinforcement learning, centralized training and\ndecentralized execution (CTDE) has achieved remarkable success. Individual\nGlobal Max (IGM) decomposition, which is an important element of CTDE, measures\nthe consistency between local and joint policies. The majority of IGM-based\nresearch focuses on how to establish this consistent relationship, but little\nattention has been paid to examining IGM's potential flaws. In this work, we\nreveal that the IGM condition is a lossy decomposition, and the error of lossy\ndecomposition will accumulated in hypernetwork-based methods. To address the\nabove issue, we propose to adopt an imitation learning strategy to separate the\nlossy decomposition from Bellman iterations, thereby avoiding error\naccumulation. The proposed strategy is theoretically proved and empirically\nverified on the StarCraft Multi-Agent Challenge benchmark problem with zero\nsight view. The results also confirm that the proposed method outperforms\nstate-of-the-art IGM-based approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.09640v1"
    },
    {
        "title": "Introducing emotions in the reasoning cycle ofnormative aware agents",
        "authors": [
            "Daniel Perez",
            "Estefania Argente",
            "Elena Del Val",
            "Soledad Valero"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Human relationships are complex processes that often involve following\ncertain rules that regulate interactions and/or expected outcomes. These rules\nmay be imposed by an authority or established by society. In multi-agent\nsystems, normative systems have extensively addressed aspects such as norm\nsynthesis, norm conflict detection, as well as norm emergence. However, if\nhuman behaviour is to be adequately simulated, not only normative aspects but\nalso emotional aspects have to be taken into account. In this paper, we propose\na Jason agent architecture that incorporates norms and emotions in its\nreasoning process to determine which plan (actions) to execute. The proposal is\nevaluated through a scenario based on a social network, which allows us to\nanalyse the benefits of using emotional normative agents to achieve simulations\ncloser to real human world.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.10049v1"
    },
    {
        "title": "Stabilizability of multi-agent systems under event-triggered controllers",
        "authors": [
            "Yinshuang Sun",
            "Zhijian Ji",
            "Yungang Liu",
            "Chong Lin"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In view of the problems of large consumption of communication and computing\nresources in the control process, this note studies a fundamental property for\na class of multi-agent systems under event-triggered strategy: the\nS-stabilizability of a group of multi-agent systems with general linear\ndynamics under weakly connected directed topology. The results indicate that\nthe S-stabilizability can be described in some way that the stabilizability\nregion and feedback gain can evaluate the performance of the protocol. Firstly,\na new distributed event-triggered protocol is proposed. Under this protocol, a\nkind of hybrid static and dynamic event-triggered strategy are presented,\nrespectively. In particular, by using Lyapunov stability theory and graph\npartition tool, it is proved that the proposed event-triggered control strategy\ncan guarantee the closed-loop system achieve S-stabilizability effectively, if\nat least one vertex in each iSCC cell receives information from the leader,\nwhich reflects the ability of distributed control law. Further, we demonstrate\nthat the stabilizability can be realized if the initial system matrix A is\nHurwitz. Moreover, it is confirmed that the designed static event-triggered\ncondition is a limit case of dynamic event condition and can guarantee\nZeno-free behavior. Finally, the validity of the theoretical results is proved\nby numerical simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.11958v1"
    },
    {
        "title": "Constrained Multi-Agent Path Finding on Directed Graphs",
        "authors": [
            "Stefano Ardizzoni",
            "Luca Consolini",
            "Marco Locatelli",
            "Irene Saccani"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We discuss C-MP and C-MAPF, generalizations of the classical Motion Planning\n(MP) and Multi-Agent Path Finding (MAPF) problems on a directed graph G.\nNamely, we enforce an upper bound on the number of agents that occupy each\nmember of a family of vertex subsets. For instance, this constraint allows\nmaintaining a safety distance between agents. We prove that finding a feasible\nsolution of C-MP and C-MAPF is NP-hard, and we propose a reduction method to\nconvert them to standard MP and MAPF. This reduction method consists in finding\na subset of nodes W and a reduced graph G/W, such that a solution of MAPF on\nG/W provides a solution of C-MAPF on G. Moreover, we study the problem of\nfinding W of maximum cardinality, which is strongly NP-hard.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12506v1"
    },
    {
        "title": "Generalizing Liquid Democracy to multi-agent delegation: A Voting Power\n  Measure and Equilibrium Analysis",
        "authors": [
            "Francisco M. Bersetche"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this study, we propose a generalization of the classic model of liquid\ndemocracy that allows fractional delegation of voting weight, while\nsimultaneously allowing for the existence of equilibrium states. Our approach\nempowers agents to partition and delegate their votes to multiple\nrepresentatives, all while retaining a fraction of the voting power for\nthemselves. We introduce a penalty mechanism for the length of delegation\nchains. We discuss the desirable properties of a reasonable generalization of\nthe classic model, and prove that smaller penalty factors bring the model\ncloser to satisfying these properties. In the subsequent section, we explore\nthe presence of equilibrium states in a general delegation game utilizing the\nproposed voting measure. In contrast to the classical model, we demonstrate\nthat this game exhibits pure strategy Nash equilibria, contingent upon the\nimposition of a penalty on the length of delegation chains.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.14128v3"
    },
    {
        "title": "Combining Theory of Mind and Abduction for Cooperation under Imperfect\n  Information",
        "authors": [
            "Nieves Montes",
            "Nardine Osman",
            "Carles Sierra"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we formalise and implement an agent model for cooperation\nunder imperfect information. It is based on Theory of Mind (the cognitive\nability to understand the mental state of others) and abductive reasoning (the\ninference paradigm that computes explanations from observations). The\ncombination of these two techniques allows agents to derive the motives behind\nthe actions of their peers, and incorporate this knowledge into their own\ndecision-making. We have implemented this model in a totally domain-independent\nfashion and successfully tested it for the cooperative card game Hanabi.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.15279v1"
    },
    {
        "title": "Communication-Enabled Deep Reinforcement Learning to Optimise\n  Energy-Efficiency in UAV-Assisted Networks",
        "authors": [
            "Babatunji Omoniwa",
            "Boris Galkin",
            "Ivana Dusparic"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Unmanned aerial vehicles (UAVs) are increasingly deployed to provide wireless\nconnectivity to static and mobile ground users in situations of increased\nnetwork demand or points of failure in existing terrestrial cellular\ninfrastructure. However, UAVs are energy-constrained and experience the\nchallenge of interference from nearby UAV cells sharing the same frequency\nspectrum, thereby impacting the system's energy efficiency (EE). Recent\napproaches focus on optimising the system's EE by optimising the trajectory of\nUAVs serving only static ground users and neglecting mobile users. Several\nothers neglect the impact of interference from nearby UAV cells, assuming an\ninterference-free network environment. Despite growing research interest in\ndecentralised control over centralised UAVs' control, direct collaboration\namong UAVs to improve coordination while optimising the systems' EE has not\nbeen adequately explored. To address this, we propose a direct collaborative\ncommunication-enabled multi-agent decentralised double deep Q-network\n(CMAD-DDQN) approach. The CMAD-DDQN is a collaborative algorithm that allows\nUAVs to explicitly share their telemetry via existing 3GPP guidelines by\ncommunicating with their nearest neighbours. This allows the agent-controlled\nUAVs to optimise their 3D flight trajectories by filling up knowledge gaps and\nconverging to optimal policies. Simulation results show that the proposed\napproach outperforms existing baselines in terms of maximising the systems' EE\nwithout degrading coverage performance in the network. The CMAD-DDQN approach\noutperforms the MAD-DDQN that neglects direct collaboration among UAVs, the\nmulti-agent deep deterministic policy gradient (MADDPG) and random policy\napproaches that consider a 2D UAV deployment design while neglecting\ninterference from nearby UAV cells by about 15%, 65% and 85%, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00041v2"
    },
    {
        "title": "Integrating Conventional Headway Control with Reinforcement Learning to\n  Avoid Bus Bunching",
        "authors": [
            "Xiheng Wang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Bus bunching is a natural-occurring phenomenon that undermines the efficiency\nand stability of the public transportation system. The mainstream solutions\ncontrol the bus to intentionally stay longer at certain stations. Existing\ncontrol methods include conventional methods that provide a formula to\ncalculate the control time and reinforcement learning (RL) methods that\ndetermine the control policy through repeated interactions with the system. In\nthis paper, we propose an integrated proximal policy optimization model with\ndual-headway (IPPO-DH). IPPO-DH integrates the conventional headway control\nwith reinforcement learning, so that it acquires the advantages of both\nalgorithms -- it is more efficient in normal environments and more stable in\nharsh ones. To demonstrate such an advantage, we design a bus simulation\nenvironment and compare IPPO-DH with RL and several conventional methods. The\nresults show that the proposed model maintains the application value of the\nconventional method by avoiding the instability of the RL method in certain\nenvironments, and improves the efficiency compared with the conventional\ncontrol, shedding new light on real-world bus transit system optimization.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00201v1"
    },
    {
        "title": "Economic-Driven Adaptive Traffic Signal Control",
        "authors": [
            "Shan Jiang",
            "Yufei Huang",
            "Mohsen Jafari",
            "Mohammad Jalayer"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  With the emerging connected-vehicle technologies and smart roads, the need\nfor intelligent adaptive traffic signal controls is more than ever before. This\npaper proposes a novel Economic-driven Adaptive Traffic Signal Control (eATSC)\nmodel with a hyper control variable - interest rate defined in economics for\ntraffic signal control at signalized intersections. The eATSC uses a continuous\ncompounding function that captures both the total number of vehicles and the\naccumulated waiting time of each vehicle to compute penalties for different\ndirections. The computed penalties grow with waiting time and is used for\nsignal control decisions. Each intersection is assigned two intelligent agents\nadjusting interest rate and signal length for different directions according to\nthe traffic patterns, respectively. The problem is formulated as a Markov\nDecision Process (MDP) problem to reduce congestions, and a two-agent Double\nDueling Deep Q Network (DDDQN) is utilized to solve the problem. Under the\noptimal policy, the agents can select the optimal interest rates and signal\ntime to minimize the likelihood of traffic congestion. To evaluate the\nsuperiority of our method, a VISSIM simulation model with classic four-leg\nsignalized intersections is developed. The results indicate that the proposed\nmodel is adequately able to maintain healthy traffic flow at the intersection.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00645v1"
    },
    {
        "title": "Agent swarms: cooperation and coordination under stringent\n  communications constraint",
        "authors": [
            "Paul Kinsler",
            "Sean Holman",
            "Andrew Elliott",
            "Cathryn N. Mitchell",
            "R. Eddie Wilson"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Here we consider the communications tactics appropriate for a group of agents\nthat need to \"swarm\" together in a highly adversarial environment. Specfically,\nwhilst they need to cooperate by exchanging information with each other about\ntheir location and their plans; at the same time they also need to keep such\ncommunications to an absolute minimum. This might be due to a need for stealth,\nor otherwise be relevant to situations where communications are signficantly\nrestricted. Complicating this process is that we assume each agent has (a) no\nmeans of passively locating others, (b) it must rely on being updated by\nreception of appropriate messages; and if no such update messages arrive, (c)\nthen their own beliefs about other agents will gradually become out of date and\nincreasingly inaccurate. Here we use a geometry-free multi-agent model that is\ncapable of allowing for message-based information transfer between agents with\ndifferent intrinsic connectivities, as would be present in a spatial\narrangement of agents. We present agent-centric performance metrics that\nrequire only minimal assumptions, and show how simulated outcome distributions,\nrisks, and connectivities depend on the ratio of information gain to loss. We\nalso show that checking for too-long round-trip times can be an effective\nminimal-information filter for determining which agents to no longer target\nwith messages.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.01163v2"
    },
    {
        "title": "Agent-Based Modelling for Urban Analytics: State of the Art and\n  Challenges",
        "authors": [
            "Nick Malleson",
            "Mark Birkin",
            "Daniel Birks",
            "Jiaqi Ge",
            "Alison Heppenstall",
            "Ed Manley",
            "Josie McCulloch",
            "Patricia Ternes"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Agent-based modelling (ABM) is a facet of wider Multi-Agent Systems (MAS)\nresearch that explores the collective behaviour of individual `agents', and the\nimplications that their behaviour and interactions have for wider systemic\nbehaviour. The method has been shown to hold considerable value in exploring\nand understanding human societies, but is still largely confined to use in\nacademia. This is particularly evident in the field of Urban Analytics; one\nthat is characterised by the use of new forms of data in combination with\ncomputational approaches to gain insight into urban processes. In Urban\nAnalytics, ABM is gaining popularity as a valuable method for understanding the\nlow-level interactions that ultimately drive cities, but as yet is rarely used\nby stakeholders (planners, governments, etc.) to address real policy problems.\nThis paper presents the state-of-the-art in the application of ABM at the\ninterface of MAS and Urban Analytics by a group of ABM researchers who are\naffiliated with the Urban Analytics programme of the Alan Turing Institute in\nLondon (UK). It addresses issues around modelling behaviour, the use of new\nforms of data, the calibration of models under high uncertainty, real-time\nmodelling, the use of AI techniques, large-scale models, and the implications\nfor modelling policy. The discussion also contextualises current research in\nwider debates around Data Science, Artificial Intelligence, and MAS more\nbroadly.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.06955v1"
    },
    {
        "title": "On the Computation of Distributed Knowledge as the Greatest Lower Bound\n  of Knowledge",
        "authors": [
            "Santiago Quintero",
            "Carlos Pinzón",
            "Sergio Ramírez",
            "Frank Valencia"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Let $L$ be a finite lattice and $\\mathcal{E}(L)$ be the set of join\nendomorphisms of $L$. We consider the problem of given $L$ and $f,g \\in\n\\mathcal{E}(L)$, finding the greatest lower bound $f \\sqcap_{{\\scriptsize\n\\mathcal{E}(L)}} g$ in the lattice $\\mathcal{E}(L)$. (1) We show that if $L$ is\ndistributive, the problem can be solved in time $O(n)$ where $n=| L |$. The\nprevious upper bound was $O(n^2)$. (2) We provide new algorithms for arbitrary\nlattices and give experimental evidence that they are significantly faster than\nthe existing algorithm. (3) We characterize the standard notion of distributed\nknowledge of a group as the greatest lower bound of the join-endomorphisms\nrepresenting the knowledge of each member of the group. (4) We show that\ndeciding whether an agent has the distributed knowledge of two other agents can\nbe computed in time $O(n^2)$ where $n$ is the size of the underlying set of\nstates. (5) For the special case of $S5$ knowledge, we show that it can be\ndecided in time $O(n\\alpha_{n})$ where $\\alpha_{n}$ is the inverse of the\nAckermann function.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.08128v2"
    },
    {
        "title": "Verification of the Socio-Technical Aspects of Voting: The Case of the\n  Polish Postal Vote 2020",
        "authors": [
            "Wojciech Jamroga",
            "Peter Y. A. Ryan",
            "Yan Kim"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Voting procedures are designed and implemented by people, for people, and\nwith significant human involvement. Thus, one should take into account the\nhuman factors in order to comprehensively analyze properties of an election and\ndetect threats. In particular, it is essential to assess how actions and\nstrategies of the involved agents (voters, municipal office employees, mail\nclerks) can influence the outcome of other agents' actions as well as the\noverall outcome of the election. In this paper, we present our first attempt to\ncapture those aspects in a formal multi-agent model of the Polish presidential\nelection 2020. The election marked the first time when postal vote was\nuniversally available in Poland. Unfortunately, the voting scheme was prepared\nunder time pressure and political pressure, and without the involvement of\nexperts. This might have opened up possibilities for various kinds of ballot\nfraud, in-house coercion, etc. We propose a preliminary scalable model of the\nprocedure in the form of a Multi-Agent Graph, and formalize selected integrity\nand security properties by formulas of agent logics. Then, we transform the\nmodels and formulas so that they can be input to the state-of-art model checker\nUppaal. The first series of experiments demonstrates that verification scales\nrather badly due to the state-space explosion. However, we show that a recently\ndeveloped technique of user-friendly model reduction by variable abstraction\nallows us to verify more complex scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.10694v2"
    },
    {
        "title": "Shepherding Heterogeneous Flock with Model-Based Discrimination",
        "authors": [
            "Anna Fujioka",
            "Masaki Ogura",
            "Naoki Wakamiya"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The problem of guiding a flock of agents to a destination by the repulsion\nforces exerted by a smaller number of external agents is called the shepherding\nproblem. This problem has attracted attention due to its potential\napplications, including diverting birds away for preventing airplane accidents,\nrecovering spilled oil in the ocean, and guiding a swarm of robots for mapping.\nAlthough there have been various studies on the shepherding problem, most of\nthem place the uniformity assumption on the dynamics of agents to be guided.\nHowever, we can find various practical situations where this assumption does\nnot necessarily hold. In this paper, we propose a shepherding method for a\nflock of agents consisting of normal agents to be guided and other variant\nagents. In this method, the shepherd discriminates normal and variant agents\nbased on their behaviors' deviation from the one predicted by the potentially\ninaccurate model of the normal agents. As for the discrimination process, we\npropose two methods using static and dynamic thresholds. Our simulation results\nshow that the proposed methods outperform a conventional method for various\ntypes of variant agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.11055v1"
    },
    {
        "title": "Explainable Multi-Agent Recommendation System for Energy-Efficient\n  Decision Support in Smart Homes",
        "authors": [
            "Alona Zharova",
            "Annika Boer",
            "Julia Knoblauch",
            "Kai Ingo Schewina",
            "Jana Vihs"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Understandable and persuasive recommendations support the electricity\nconsumers' behavioral change to tackle the energy efficiency problem.\nGenerating load shifting recommendations for household appliances as\nexplainable increases the transparency and trustworthiness of the system. This\npaper proposes an explainable multi-agent recommendation system for load\nshifting for household appliances. First, we provide agents with enhanced\npredictive capacity by including weather data, applying state-of-the-art\nmodels, and tuning the hyperparameters. Second, we suggest an Explainability\nAgent providing transparent recommendations. We also provide an overview of the\npredictive and explainability performance. Third, we discuss the impact and\nscaling potential of the suggested approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.11218v2"
    },
    {
        "title": "An Opponent-Aware Reinforcement Learning Method for Team-to-Team\n  Multi-Vehicle Pursuit via Maximizing Mutual Information Indicator",
        "authors": [
            "Qinwen Wang",
            "Xinhang Li",
            "Zheng Yuan",
            "Yiying Yang",
            "Chen Xu",
            "Lin Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The pursuit-evasion game in Smart City brings a profound impact on the\nMulti-vehicle Pursuit (MVP) problem, when police cars cooperatively pursue\nsuspected vehicles. Existing studies on the MVP problems tend to set evading\nvehicles to move randomly or in a fixed prescribed route. The opponent modeling\nmethod has proven considerable promise in tackling the non-stationary caused by\nthe adversary agent. However, most of them focus on two-player competitive\ngames and easy scenarios without the interference of environments. This paper\nconsiders a Team-to-Team Multi-vehicle Pursuit (T2TMVP) problem in the\ncomplicated urban traffic scene where the evading vehicles adopt the\npre-trained dynamic strategies to execute decisions intelligently. To solve\nthis problem, we propose an opponent-aware reinforcement learning via\nmaximizing mutual information indicator (OARLM2I2) method to improve pursuit\nefficiency in the complicated environment. First, a sequential encoding-based\nopponents joint strategy modeling (SEOJSM) mechanism is proposed to generate\nevading vehicles' joint strategy model, which assists the multi-agent\ndecision-making process based on deep Q-network (DQN). Then, we design a mutual\ninformation-united loss, simultaneously considering the reward fed back from\nthe environment and the effectiveness of opponents' joint strategy model, to\nupdate pursuing vehicles' decision-making process. Extensive experiments based\non SUMO demonstrate our method outperforms other baselines by 21.48% on average\nin reducing pursuit time. The code is available at\n\\url{https://github.com/ANT-ITS/OARLM2I2}.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.13015v1"
    },
    {
        "title": "Defense Against Smart Invaders with Swarms of Sweeping Agents",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The goal of this research is to devise guaranteed defense policies that allow\nto protect a given region from the entrance of smart mobile invaders by\ndetecting them using a team of defending agents equipped with identical line\nsensors. By designing cooperative defense strategies that ensure all invaders\nare detected, conditions on the defenders' speed are derived. Successful\naccomplishment of the defense task implies invaders with a known limit on their\nspeed cannot slip past the defenders and enter the guarded region undetected.\nThe desired outcome of the defense protocols is to defend the area and\nadditionally to expand it as much as possible. Expansion becomes possible if\nthe defenders' speed exceeds a critical speed that is necessary to only defend\nthe initial region. We present results on the total search time, critical\nspeeds and maximal expansion possible for two types of novel pincer-movement\ndefense processes, circular and spiral, for any even number of defenders. The\nproposed spiral process allows to detect invaders at nearly the lowest\ntheoretically optimal speed, and if this speed is exceeded, it also allows to\nexpand the protected region almost to the maximal area.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.16063v2"
    },
    {
        "title": "Satellite Navigation and Coordination with Limited Information Sharing",
        "authors": [
            "Sydney Dolan",
            "Siddharth Nayak",
            "Hamsa Balakrishnan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We explore space traffic management as an application of collision-free\nnavigation in multi-agent systems where vehicles have limited observation and\ncommunication ranges. We investigate the effectiveness of transferring a\ncollision avoidance multi-agent reinforcement (MARL) model trained on a ground\nenvironment to a space one. We demonstrate that the transfer learning model\noutperforms a model that is trained directly on the space environment.\nFurthermore, we find that our approach works well even when we consider the\nperturbations to satellite dynamics caused by the Earth's oblateness. Finally,\nwe show how our methods can be used to evaluate the benefits of\ninformation-sharing between satellite operators in order to improve\ncoordination.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03658v3"
    },
    {
        "title": "Policy-Based Reinforcement Learning for Assortative Matching in Human\n  Behavior Modeling",
        "authors": [
            "Ou Deng",
            "Qun Jin"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper explores human behavior in virtual networked communities,\nspecifically individuals or groups' potential and expressive capacity to\nrespond to internal and external stimuli, with assortative matching as a\ntypical example. A modeling approach based on Multi-Agent Reinforcement\nLearning (MARL) is proposed, adding a multi-head attention function to the A3C\nalgorithm to enhance learning effectiveness. This approach simulates human\nbehavior in certain scenarios through various environmental parameter settings\nand agent action strategies. In our experiment, reinforcement learning is\nemployed to serve specific agents that learn from environment status and\ncompetitor behaviors, optimizing strategies to achieve better results. The\nsimulation includes individual and group levels, displaying possible paths to\nforming competitive advantages. This modeling approach provides a means for\nfurther analysis of the evolutionary dynamics of human behavior, communities,\nand organizations in various socioeconomic issues.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03936v3"
    },
    {
        "title": "Autotelic Reinforcement Learning in Multi-Agent Environments",
        "authors": [
            "Eleni Nisioti",
            "Elías Masquil",
            "Gautier Hamon",
            "and Clément Moulin-Frier"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In the intrinsically motivated skills acquisition problem, the agent is set\nin an environment without any pre-defined goals and needs to acquire an\nopen-ended repertoire of skills. To do so the agent needs to be autotelic\n(deriving from the Greek auto (self) and telos (end goal)): it needs to\ngenerate goals and learn to achieve them following its own intrinsic motivation\nrather than external supervision. Autotelic agents have so far been considered\nin isolation. But many applications of open-ended learning entail groups of\nagents. Multi-agent environments pose an additional challenge for autotelic\nagents: to discover and master goals that require cooperation agents must\npursue them simultaneously, but they have low chances of doing so if they\nsample them independently. In this work, we propose a new learning paradigm for\nmodeling such settings, the Decentralized Intrinsically Motivated Skills\nAcquisition Problem (Dec-IMSAP), and employ it to solve cooperative navigation\ntasks. First, we show that agents setting their goals independently fail to\nmaster the full diversity of goals. Then, we show that a sufficient condition\nfor achieving this is to ensure that a group aligns its goals, i.e., the agents\npursue the same cooperative goal. Our empirical analysis shows that alignment\nenables specialization, an efficient strategy for cooperation. Finally, we\nintroduce the Goal-coordination game, a fully-decentralized emergent\ncommunication algorithm, where goal alignment emerges from the maximization of\nindividual rewards in multi-goal cooperative environments and show that it is\nable to reach equal performance to a centralized training baseline that\nguarantees aligned goals. To our knowledge, this is the first contribution\naddressing the problem of intrinsically motivated multi-agent goal exploration\nin a decentralized training paradigm.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.06082v2"
    },
    {
        "title": "Promoting Social Behaviour in Reducing Peak Electricity Consumption\n  Using Multi-Agent Systems",
        "authors": [
            "Nathan A. Brooks",
            "Simon T. Powers",
            "James M. Borg"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  As we transition to renewable energy sources, addressing their inflexibility\nduring peak demand becomes crucial. It is therefore important to reduce the\npeak load placed on our energy system. For households, this entails spreading\nhigh-power appliance usage like dishwashers and washing machines throughout the\nday. Traditional approaches to spreading out usage have relied on differential\npricing set by a centralised utility company, but this has been ineffective.\nOur previous research investigated a decentralised mechanism where agents\nreceive an initial allocation of time-slots to use their appliances, which they\ncan exchange with others. This was found to be an effective approach to\nreducing the peak load when we introduced social capital, the tracking of\nfavours, to incentivise agents to accept exchanges that do not immediately\nbenefit them. This system encouraged self-interested agents to learn socially\nbeneficial behaviour to earn social capital that they could later use to\nimprove their own performance. In this paper we expand this work by\nimplementing real world household appliance usage data to ensure that our\nmechanism could adapt to the challenging demand needs of real households. We\nalso demonstrate how smaller and more diverse populations can optimise more\neffectively than larger community energy systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.10198v2"
    },
    {
        "title": "An adaptive route choice model for integrated fixed and flexible transit\n  systems",
        "authors": [
            "David Leffler",
            "Wilco Burghout",
            "Oded Cats",
            "Erik Jenelius"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Over the past decade, there has been a surge of interest in the transport\ncommunity in the application of agent-based simulation models to evaluate\nflexible transit solutions characterized by different degrees of short-term\nflexibility in routing and scheduling. A central modeling decision in the\ndevelopment of an agent-based simulation model for the evaluation of flexible\ntransit is how one chooses to represent the mode- and route-choices of\ntravelers. The real-time adaptive behavior of travelers is intuitively\nimportant to model in the presence of a flexible transit service, where the\nrouting and scheduling of vehicles is highly dependent on supply-demand\ndynamics at a closer to real-time temporal resolution. We propose a\nutility-based transit route-choice model with representation of within-day\nadaptive travel behavior and between-day learning where station-based\nfixed-transit, flexible-transit, and active-mode alternatives may be\ndynamically combined in a single path. To enable experimentation, this\nroute-choice model is implemented within an agent-based dynamic public transit\nsimulation framework. Model properties are first explored in a choice between\nfixed- and flexible-transit modes for a toy network. The framework is then\napplied to illustrate level-of-service trade-offs and analyze traveler mode\nchoices within a mixed fixed- and flexible transit system in a case study based\non a real-life branched transit service in Stockholm, Sweden.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.10802v1"
    },
    {
        "title": "Backdoor Attacks on Multiagent Collaborative Systems",
        "authors": [
            "Shuo Chen",
            "Yue Qiu",
            "Jie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Backdoor attacks on reinforcement learning implant a backdoor in a victim\nagent's policy. Once the victim observes the trigger signal, it will switch to\nthe abnormal mode and fail its task. Most of the attacks assume the adversary\ncan arbitrarily modify the victim's observations, which may not be practical.\nOne work proposes to let one adversary agent use its actions to affect its\nopponent in two-agent competitive games, so that the opponent quickly fails\nafter observing certain trigger actions. However, in multiagent collaborative\nsystems, agents may not always be able to observe others. When and how much the\nadversary agent can affect others are uncertain, and we want the adversary\nagent to trigger others for as few times as possible. To solve this problem, we\nfirst design a novel training framework to produce auxiliary rewards that\nmeasure the extent to which the other agents'observations being affected. Then\nwe use the auxiliary rewards to train a trigger policy which enables the\nadversary agent to efficiently affect the others' observations. Given these\naffected observations, we further train the other agents to perform abnormally.\nExtensive experiments demonstrate that the proposed method enables the\nadversary agent to lure the others into the abnormal mode with only a few\nactions.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.11455v1"
    },
    {
        "title": "An agent-based simulation model of pedestrian evacuation based on\n  Bayesian Nash Equilibrium",
        "authors": [
            "Yiyu Wang",
            "Jiaqi Ge",
            "Alexis Comber"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This research incorporates Bayesian game theory into pedestrian evacuation in\nan agent-based model. Three pedestrian behaviours were compared: Random Follow,\nShortest Route and Bayesian Nash Equilibrium (BNE), as well as combinations of\nthese. The results showed that BNE pedestrians were able to evacuate more\nquickly as they predict congestion levels in their next step and adjust their\ndirections to avoid congestion, closely matching the behaviours of evacuating\npedestrians in reality. A series of simulation experiments were conducted to\nevaluate whether and how BNE affects pedestrian evacuation procedures. The\nresults showed that: 1) BNE has a large impact on reducing evacuation time; 2)\nBNE pedestrians displayed more intelligent and efficient evacuating behaviours;\n3) As the proportion of BNE users rises, average evacuation time decreases, and\naverage comfort level increases. A detailed description of the model and\nrelevant experimental results is provided in this paper. Several limitations as\nwell as further works are also identified.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.14260v1"
    },
    {
        "title": "ADOPT: A system for Alerting Drivers to Occluded Pedestrian Traffic",
        "authors": [
            "Abrar Alali",
            "Stephan Olariu",
            "Shubham Jain"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Recent statistics reveal an alarming increase in accidents involving\npedestrians (especially children) crossing the street. A common philosophy of\nexisting pedestrian detection approaches is that this task should be undertaken\nby the moving cars themselves. In sharp departure from this philosophy, we\npropose to enlist the help of cars parked along the sidewalk to detect and\nprotect crossing pedestrians. In support of this goal, we propose ADOPT: a\nsystem for Alerting Drivers to Occluded Pedestrian Traffic. ADOPT lays the\ntheoretical foundations of a system that uses parked cars to: (1) detect the\npresence of a group of crossing pedestrians - a crossing cohort; (2) predict\nthe time the last member of the cohort takes to clear the street; (3) send\nalert messages to those approaching cars that may reach the crossing area while\npedestrians are still in the street; and, (4) show how approaching cars can\nadjust their speed, given several simultaneous crossing locations. Importantly,\nin ADOPT all communications occur over very short distances and at very low\npower. Our extensive simulations using SUMO-generated pedestrian and car\ntraffic have shown the effectiveness of ADOPT in detecting and protecting\ncrossing pedestrians.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.00137v1"
    },
    {
        "title": "Decision Market Based Learning For Multi-agent Contextual Bandit\n  Problems",
        "authors": [
            "Wenlong Wang",
            "Thomas Pfeiffer"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Information is often stored in a distributed and proprietary form, and agents\nwho own information are often self-interested and require incentives to reveal\ntheir information. Suitable mechanisms are required to elicit and aggregate\nsuch distributed information for decision making. In this paper, we use\nsimulations to investigate the use of decision markets as mechanisms in a\nmulti-agent learning system to aggregate distributed information for\ndecision-making in a contextual bandit problem. The system utilises strictly\nproper decision scoring rules to assess the accuracy of probabilistic reports\nfrom agents, which allows agents to learn to solve the contextual bandit\nproblem jointly. Our simulations show that our multi-agent system with\ndistributed information can be trained as efficiently as a centralised\ncounterpart with a single agent that receives all information. Moreover, we use\nour system to investigate scenarios with deterministic decision scoring rules\nwhich are not incentive compatible. We observe the emergence of more complex\ndynamics with manipulative behaviour, which agrees with existing theoretical\nanalyses.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.00271v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning with Reward Delays",
        "authors": [
            "Yuyang Zhang",
            "Runyu Zhang",
            "Yuantao Gu",
            "Na Li"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper considers multi-agent reinforcement learning (MARL) where the\nrewards are received after delays and the delay time varies across agents and\nacross time steps. Based on the V-learning framework, this paper proposes MARL\nalgorithms that efficiently deal with reward delays. When the delays are\nfinite, our algorithm reaches a coarse correlated equilibrium (CCE) with rate\n$\\tilde{\\mathcal{O}}(\\frac{H^3\\sqrt{S\\mathcal{T}_K}}{K}+\\frac{H^3\\sqrt{SA}}{\\sqrt{K}})$\nwhere $K$ is the number of episodes, $H$ is the planning horizon, $S$ is the\nsize of the state space, $A$ is the size of the largest action space, and\n$\\mathcal{T}_K$ is the measure of total delay formally defined in the paper.\nMoreover, our algorithm is extended to cases with infinite delays through a\nreward skipping scheme. It achieves convergence rate similar to the finite\ndelay case.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.01441v2"
    },
    {
        "title": "Agent Miner: An Algorithm for Discovering Agent Systems from Event Data",
        "authors": [
            "Andrei Tour",
            "Artem Polyvyanyy",
            "Anna Kalenkova",
            "Arik Senderovich"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Process discovery studies ways to use event data generated by business\nprocesses and recorded by IT systems to construct models that describe the\nprocesses. Existing discovery algorithms are predominantly concerned with\nconstructing process models that represent the control flow of the processes.\nAgent system mining argues that business processes often emerge from\ninteractions of autonomous agents and uses event data to construct models of\nthe agents and their interactions. This paper presents and evaluates Agent\nMiner, an algorithm for discovering models of agents and their interactions\nfrom event data composing the system that has executed the processes which\ngenerated the input data. The conducted evaluation using our open-source\nimplementation of Agent Miner and publicly available industrial datasets\nconfirms that our algorithm can provide insights into the process participants\nand their interaction patterns and often discovers models that describe the\nbusiness processes more faithfully than process models discovered using\nconventional process discovery algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.01454v3"
    },
    {
        "title": "Learning Trust Over Directed Graphs in Multiagent Systems (extended\n  version)",
        "authors": [
            "Orhan Eren Akgün",
            "Arif Kerem Dayı",
            "Stephanie Gil",
            "Angelia Nedić"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We address the problem of learning the legitimacy of other agents in a\nmultiagent network when an unknown subset is comprised of malicious actors. We\nspecifically derive results for the case of directed graphs and where\nstochastic side information, or observations of trust, is available. We refer\nto this as ``learning trust'' since agents must identify which neighbors in the\nnetwork are reliable, and we derive a protocol to achieve this. We also provide\nanalytical results showing that under this protocol i) agents can learn the\nlegitimacy of all other agents almost surely, and that ii) the opinions of the\nagents converge in mean to the true legitimacy of all other agents in the\nnetwork. Lastly, we provide numerical studies showing that our convergence\nresults hold in practice for various network topologies and variations in the\nnumber of malicious agents in the network.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.02661v2"
    },
    {
        "title": "An Agent-based Realisation for a continuous Model Adaption Approach in\n  intelligent Digital Twins",
        "authors": [
            "Daniel Dittler",
            "Peter Lierhammer",
            "Dominik Braun",
            "Timo Müller",
            "Nasser Jazdi",
            "Michael Weyrich"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The trend in industrial automation is towards networking, intelligence and\nautonomy. Digital Twins, which serve as virtual representations, are becoming\nincreasingly important in this context. The Digital Twin of a modular\nproduction system contains many different models that are mostly created for\nspecific applications and fulfil different requirements. Especially simulation\nmodels, which are created in the development phase, can be used during the\noperational phase for applications such as prognosis or operation-parallel\nsimulation. Due to the high heterogeneity of the model landscape in the context\nof a modular production system, the plant operator is faced with the challenge\nof adapting the models in order to ensure an application-oriented realism in\nthe event of changes to the asset and its environment or the addition of\napplications. Therefore, this paper proposes a concept for the continuous model\nadaption in the Digital Twin of a modular production system during the\noperational phase. The benefits are then demonstrated by an application\nscenario and an agent-based realisation.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.03681v1"
    },
    {
        "title": "Activity-Based Recommendations for Demand Response in Smart Sustainable\n  Buildings",
        "authors": [
            "Alona Zharova",
            "Laura Löschmann"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The energy consumption of private households amounts to approximately 30% of\nthe total global energy consumption, causing a large share of the CO2 emissions\nthrough energy production. An intelligent demand response via load shifting\nincreases the energy efficiency of residential buildings by nudging residents\nto change their energy consumption behavior. This paper introduces an activity\nprediction-based framework for the utility-based context-aware multi-agent\nrecommendation system that generates an activity shifting schedule for a\n24-hour time horizon to either focus on CO2 emissions or energy cost savings.\nIn particular, we design and implement an Activity Agent that uses hourly\nenergy consumption data. It does not require further sensorial data or activity\nlabels which reduces implementation costs and the need for extensive user\ninput. Moreover, the system enhances the utility option of saving energy costs\nby saving CO2 emissions and provides the possibility to focus on both\ndimensions. The empirical results show that while setting the focus on CO2\nemissions savings, the system provides an average of 12% of emissions savings\nand 7% of cost savings. When focusing on energy cost savings, 20% of energy\ncosts and 6% of emissions savings are possible for the studied households in\ncase of accepting all recommendations. Recommending an activity schedule, the\nsystem uses the same terms residents describe their domestic life. Therefore,\nrecommendations can be more easily integrated into daily life supporting the\nacceptance of the system in a long-term perspective.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.05173v1"
    },
    {
        "title": "Automated Configuration and Usage of Strategy Portfolios for Bargaining",
        "authors": [
            "Bram M. Renting",
            "Holger H. Hoos",
            "Catholijn M. Jonker"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Bargaining can be used to resolve mixed-motive games in multi-agent systems.\nAlthough there is an abundance of negotiation strategies implemented in\nautomated negotiating agents, most agents are based on single fixed strategies,\nwhile it is widely acknowledged that there is no single best-performing\nstrategy for all negotiation settings.\n  In this paper, we focus on bargaining settings where opponents are repeatedly\nencountered, but the bargaining problems change. We introduce a novel method\nthat automatically creates and deploys a portfolio of complementary negotiation\nstrategies using a training set and optimise pay-off in never-before-seen\nbargaining settings through per-setting strategy selection. Our method relies\non the following contributions. We introduce a feature representation that\ncaptures characteristics for both the opponent and the bargaining problem. We\nmodel the behaviour of an opponent during a negotiation based on its actions,\nwhich is indicative of its negotiation strategy, in order to be more effective\nin future encounters.\n  Our combination of feature-based methods generalises to new negotiation\nsettings, as in practice, over time, it selects effective counter strategies in\nfuture encounters. Our approach is tested in an ANAC-like tournament, and we\nshow that we are capable of winning such a tournament with a 5.6% increase in\npay-off compared to the runner-up agent.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.10228v1"
    },
    {
        "title": "Analysis of Integrating Blockchain Technologies into Multi-Agent Systems",
        "authors": [
            "Chelsea R. Woodward"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-Agent Systems, a division of Intelligent Systems diversely applied in\nmultiple disciplines. Desired for their efficiency in solving complex problems\nat a low cost. However, identified vulnerabilities include system security,\nintegrity, and identity management. Blockchain Technologies was chosen for\nanalysis in providing a suitable solution due to features of transparency,\nencryption, and trust.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.12313v1"
    },
    {
        "title": "Task Placement and Resource Allocation for Edge Machine Learning: A\n  GNN-based Multi-Agent Reinforcement Learning Paradigm",
        "authors": [
            "Yihong Li",
            "Xiaoxi Zhang",
            "Tianyu Zeng",
            "Jingpu Duan",
            "Chuan Wu",
            "Di Wu",
            "Xu Chen"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Machine learning (ML) tasks are one of the major workloads in today's edge\ncomputing networks. Existing edge-cloud schedulers allocate the requested\namounts of resources to each task, falling short of best utilizing the limited\nedge resources for ML tasks. This paper proposes TapFinger, a distributed\nscheduler for edge clusters that minimizes the total completion time of ML\ntasks through co-optimizing task placement and fine-grained multi-resource\nallocation. To learn the tasks' uncertain resource sensitivity and enable\ndistributed scheduling, we adopt multi-agent reinforcement learning (MARL) and\npropose several techniques to make it efficient, including a heterogeneous\ngraph attention network as the MARL backbone, a tailored task selection phase\nin the actor network, and the integration of Bayes' theorem and masking\nschemes. We first implement a single-task scheduling version, which schedules\nat most one task each time. Then we generalize to the multi-task scheduling\ncase, in which a sequence of tasks is scheduled simultaneously. Our design can\nmitigate the expanded decision space and yield fast convergence to optimal\nscheduling solutions. Extensive experiments using synthetic and test-bed ML\ntask traces show that TapFinger can achieve up to 54.9% reduction in the\naverage task completion time and improve resource efficiency as compared to\nstate-of-the-art schedulers.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00571v2"
    },
    {
        "title": "Towards Modelling and Verification of Social Explainable AI",
        "authors": [
            "Damian Kurpiewski",
            "Wojciech Jamroga",
            "Teofil Sidoruk"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Social Explainable AI (SAI) is a new direction in artificial intelligence\nthat emphasises decentralisation, transparency, social context, and focus on\nthe human users. SAI research is still at an early stage. Consequently, it\nconcentrates on delivering the intended functionalities, but largely ignores\nthe possibility of unwelcome behaviours due to malicious or erroneous activity.\nWe propose that, in order to capture the breadth of relevant aspects, one can\nuse models and logics of strategic ability, that have been developed in\nmulti-agent systems. Using the STV model checker, we take the first step\ntowards the formal modelling and verification of SAI environments, in\nparticular of their resistance to various types of attacks by compromised AI\nmodules.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.01063v2"
    },
    {
        "title": "Scalability Bottlenecks in Multi-Agent Reinforcement Learning Systems",
        "authors": [
            "Kailash Gogineni",
            "Peng Wei",
            "Tian Lan",
            "Guru Venkataramani"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) is a promising area of research\nthat can model and control multiple, autonomous decision-making agents. During\nonline training, MARL algorithms involve performance-intensive computations\nsuch as exploration and exploitation phases originating from large\nobservation-action space belonging to multiple agents. In this article, we seek\nto characterize the scalability bottlenecks in several popular classes of MARL\nalgorithms during their training phases. Our experimental results reveal new\ninsights into the key modules of MARL algorithms that limit the scalability,\nand outline potential strategies that may help address these performance\nissues.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05007v1"
    },
    {
        "title": "Improving Zero-Shot Coordination Performance Based on Policy Similarity",
        "authors": [
            "Lebin Yu",
            "Yunbo Qiu",
            "Quanming Yao",
            "Xudong Zhang",
            "Jian Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Over these years, multi-agent reinforcement learning has achieved remarkable\nperformance in multi-agent planning and scheduling tasks. It typically follows\nthe self-play setting, where agents are trained by playing with a fixed group\nof agents. However, in the face of zero-shot coordination, where an agent must\ncoordinate with unseen partners, self-play agents may fail. Several methods\nhave been proposed to handle this problem, but they either take a lot of time\nor lack generalizability. In this paper, we firstly reveal an important\nphenomenon: the zero-shot coordination performance is strongly linearly\ncorrelated with the similarity between an agent's training partner and testing\npartner. Inspired by it, we put forward a Similarity-Based Robust Training\n(SBRT) scheme that improves agents' zero-shot coordination performance by\ndisturbing their partners' actions during training according to a pre-defined\npolicy similarity value. To validate its effectiveness, we apply our scheme to\nthree multi-agent reinforcement learning frameworks and achieve better\nperformance compared with previous methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05063v1"
    },
    {
        "title": "Graph Learning Based Decision Support for Multi-Aircraft Take-Off and\n  Landing at Urban Air Mobility Vertiports",
        "authors": [
            "Prajit KrisshnaKumar",
            "Jhoel Witter",
            "Steve Paul",
            "Karthik Dantu",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Majority of aircraft under the Urban Air Mobility (UAM) concept are expected\nto be of the electric vertical takeoff and landing (eVTOL) vehicle type, which\nwill operate out of vertiports. While this is akin to the relationship between\ngeneral aviation aircraft and airports, the conceived location of vertiports\nwithin dense urban environments presents unique challenges in managing the air\ntraffic served by a vertiport. This challenge becomes pronounced within\nincreasing frequency of scheduled landings and take-offs. This paper assumes a\ncentralized air traffic controller (ATC) to explore the performance of a new AI\ndriven ATC approach to manage the eVTOLs served by the vertiport. Minimum\nseparation-driven safety and delays are the two important considerations in\nthis case. The ATC problem is modeled as a task allocation problem, and\nuncertainties due to communication disruptions (e.g., poor link quality) and\ninclement weather (e.g., high gust effects) are added as a small probability of\naction failures. To learn the vertiport ATC policy, a novel graph-based\nreinforcement learning (RL) solution called \"Urban Air Mobility- Vertiport\nSchedule Management (UAM-VSM)\" is developed. This approach uses graph\nconvolutional networks (GCNs) to abstract the vertiport space and eVTOL space\nas graphs, and aggregate information for a centralized ATC agent to help\ngeneralize the environment. Unreal Engine combined with Airsim is used as the\nsimulation environment over which training and testing occurs. Uncertainties\nare considered only during testing, due to the high cost of Mc sampling over\nsuch realistic simulations. The proposed graph RL method demonstrates\nsignificantly better performance on the test scenarios when compared against a\nfeasible random decision-making baseline and a first come first serve (FCFS)\nbaseline, including the ability to generalize to unseen scenarios and with\nuncertainties.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05849v1"
    },
    {
        "title": "MANSA: Learning Fast and Slow in Multi-Agent Systems",
        "authors": [
            "David Mguni",
            "Haojun Chen",
            "Taher Jafferjee",
            "Jianhong Wang",
            "Long Fei",
            "Xidong Feng",
            "Stephen McAleer",
            "Feifei Tong",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In multi-agent reinforcement learning (MARL), independent learning (IL) often\nshows remarkable performance and easily scales with the number of agents. Yet,\nusing IL can be inefficient and runs the risk of failing to successfully train,\nparticularly in scenarios that require agents to coordinate their actions.\nUsing centralised learning (CL) enables MARL agents to quickly learn how to\ncoordinate their behaviour but employing CL everywhere is often prohibitively\nexpensive in real-world applications. Besides, using CL in value-based methods\noften needs strong representational constraints (e.g. individual-global-max\ncondition) that can lead to poor performance if violated. In this paper, we\nintroduce a novel plug & play IL framework named Multi-Agent Network Selection\nAlgorithm (MANSA) which selectively employs CL only at states that require\ncoordination. At its core, MANSA has an additional agent that uses switching\ncontrols to quickly learn the best states to activate CL during training, using\nCL only where necessary and vastly reducing the computational burden of CL. Our\ntheory proves MANSA preserves cooperative MARL convergence properties, boosts\nIL performance and can optimally make use of a fixed budget on the number CL\ncalls. We show empirically in Level-based Foraging (LBF) and StarCraft\nMulti-agent Challenge (SMAC) that MANSA achieves fast, superior and more\nreliable performance while making 40% fewer CL calls in SMAC and using CL at\nonly 1% CL calls in LBF.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05910v3"
    },
    {
        "title": "Converging to Stability in Two-Sided Bandits: The Case of Unknown\n  Preferences on Both Sides of a Matching Market",
        "authors": [
            "Gaurab Pokharel",
            "Sanmay Das"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We study the problem of repeated two-sided matching with uncertain\npreferences (two-sided bandits), and no explicit communication between agents.\nRecent work has developed algorithms that converge to stable matchings when one\nside (the proposers or agents) must learn their preferences, but the\npreferences of the other side (the proposees or arms) are common knowledge, and\nthe matching mechanism uses simultaneous proposals at each round. We develop\nnew algorithms that converge to stable matchings for two more challenging\nsettings: one where the arm preferences are no longer common knowledge, and a\nsecond, more general one where the arms are also uncertain about their own\npreferences. In our algorithms, agents start with optimistic beliefs about\narms' preferences, updating these preferences over time, and combining beliefs\nabout preferences with beliefs about the value of matching when choosing whom\nto propose to.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.06176v1"
    },
    {
        "title": "A Theory of Mind Approach as Test-Time Mitigation Against Emergent\n  Adversarial Communication",
        "authors": [
            "Nancirose Piazza",
            "Vahid Behzadan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-Agent Systems (MAS) is the study of multi-agent interactions in a\nshared environment. Communication for cooperation is a fundamental construct\nfor sharing information in partially observable environments. Cooperative\nMulti-Agent Reinforcement Learning (CoMARL) is a learning framework where we\nlearn agent policies either with cooperative mechanisms or policies that\nexhibit cooperative behavior. Explicitly, there are works on learning to\ncommunicate messages from CoMARL agents; however, non-cooperative agents, when\ncapable of access a cooperative team's communication channel, have been shown\nto learn adversarial communication messages, sabotaging the cooperative team's\nperformance particularly when objectives depend on finite resources. To address\nthis issue, we propose a technique which leverages local formulations of\nTheory-of-Mind (ToM) to distinguish exhibited cooperative behavior from\nnon-cooperative behavior before accepting messages from any agent. We\ndemonstrate the efficacy and feasibility of the proposed technique in empirical\nevaluations in a centralized training, decentralized execution (CTDE) CoMARL\nbenchmark. Furthermore, while we propose our explicit ToM defense for\ntest-time, we emphasize that ToM is a construct for designing a cognitive\ndefense rather than be the objective of the defense.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.07176v1"
    },
    {
        "title": "Crowd simulation incorporating a route choice model and similarity\n  evaluation using real large-scale data",
        "authors": [
            "Ryo Nishida",
            "Masaki Onishi",
            "Koichi Hashimoto"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Modeling and simulation approaches that express crowd movement with\nmathematical models are widely and actively studied to understand crowd\nmovement and resolve crowd accidents. Existing literature on crowd modeling\nfocuses on only the decision-making of walking behavior. However, the\ndecision-making of route choice, which is a higher-level decision, should also\nbe modeled for constructing more practical simulations. Furthermore, the\nreproducibility evaluation of the crowd simulation incorporating the route\nchoice model using real data is insufficient. Therefore, we generalize and\npropose a crowd simulation framework that includes actual crowd movement\nmeasurements, route choice model estimation, and crowd simulator construction.\nWe use the Discrete choice model as the route choice model and the Social force\nmodel as the walking model. In experiments, we measure crowd movements during\nan evacuation drill in a theater and a firework event where tens of thousands\nof people moved and prove that the crowd simulation incorporating the route\nchoice model can reproduce the real large-scale crowd movement more accurately.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.10421v2"
    },
    {
        "title": "CrowdLogo: crowd simulation in NetLogo",
        "authors": [
            "Davide Foini",
            "Magdalena Rzyska",
            "Katharina Baschmakov",
            "Sergio Murino"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Planning the evacuation of people from crowded places, such as squares,\nstadiums, or indoor arenas during emergency scenarios is a fundamental task\nthat authorities must deal with. This article summarizes the work of the\nauthors to simulate an emergency scenario in a square using NetLogo, a\nmulti-agent programmable modeling environment. The emergency scenario is based\non a real event, which took place in Piazza San Carlo, Turin, on the 3rd of\nJune 2017. The authors have developed a model and conducted various\nexperiments, the results of which are presented, discussed and analyzed. The\narticle concludes by offering suggestions for further research and summarizing\nthe key takeaways.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.11036v1"
    },
    {
        "title": "Inequity aversion reduces travel time in the traffic light control\n  problem",
        "authors": [
            "Mersad Hassanjani",
            "Farinaz Alamiyan-Harandi",
            "Pouria Ramazi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The traffic light control problem is to improve the traffic flow by\ncoordinating between the traffic lights. Recently, a successful deep\nreinforcement learning model, CoLight, was developed to capture the influences\nof neighboring intersections by a graph attention network. We propose IACoLight\nthat boosts up to 11.4% the performance of CoLight by incorporating the\nInequity Aversion (IA) model that reshapes each agent's reward by adding or\nsubtracting advantageous or disadvantageous reward inequities compared to other\nagents. Unlike in the other applications of IA, where both advantageous and\ndisadvantageous inequities are punished by considering negative coefficients,\nwe allowed them to be also rewarded and explored a range of both positive and\nnegative coefficients. Our experiments demonstrated that making CoLight agents\naverse to inequities improved the vehicles' average travel time and rewarding\nrather than punishing advantageous inequities enhanced the results.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12053v1"
    },
    {
        "title": "Ask and You Shall be Served: Representing and Solving Multi-agent\n  Optimization Problems with Service Requesters and Providers",
        "authors": [
            "Maya Lavie",
            "Tehila Caspi",
            "Omer Lev",
            "Roei Zivan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In scenarios with numerous emergencies that arise and require the assistance\nof various rescue units (e.g., medical, fire, \\& police forces), the rescue\nunits would ideally be allocated quickly and distributedly while aiming to\nminimize casualties. This is one of many examples of distributed settings with\nservice providers (the rescue units) and service requesters (the emergencies)\nwhich we term \\textit{service oriented settings}. Allocating the service\nproviders in a distributed manner while aiming for a global optimum is hard to\nmodel, let alone achieve, using the existing Distributed Constraint\nOptimization Problem (DCOP) framework. Hence, the need for a novel approach and\ncorresponding algorithms.\n  We present the Service Oriented Multi-Agent Optimization Problem (SOMAOP), a\nnew framework that overcomes the shortcomings of DCOP in service oriented\nsettings. We evaluate the framework using various algorithms based on auctions\nand matching algorithms (e.g., Gale Shapely). We empirically show that\nalgorithms based on repeated auctions converge to a high quality solution very\nfast, while repeated matching problems converge slower, but produce higher\nquality solutions. We demonstrate the advantages of our approach over standard\nincomplete DCOP algorithms and a greedy centralized algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.14507v1"
    },
    {
        "title": "Mitigating Skewed Bidding for Conference Paper Assignment",
        "authors": [
            "Inbal Rozencweig",
            "Reshef Meir",
            "Nick Mattei",
            "Ofra Amir"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The explosion of conference paper submissions in AI and related fields, has\nunderscored the need to improve many aspects of the peer review process,\nespecially the matching of papers and reviewers. Recent work argues that the\nkey to improve this matching is to modify aspects of the \\emph{bidding phase}\nitself, to ensure that the set of bids over papers is balanced, and in\nparticular to avoid \\emph{orphan papers}, i.e., those papers that receive no\nbids. In an attempt to understand and mitigate this problem, we have developed\na flexible bidding platform to test adaptations to the bidding process. Using\nthis platform, we performed a field experiment during the bidding phase of a\nmedium-size international workshop that compared two bidding methods. We\nfurther examined via controlled experiments on Amazon Mechanical Turk various\nfactors that affect bidding, in particular the order in which papers are\npresented \\cite{cabanac2013capitalizing,fiez2020super}; and information on\npaper demand \\cite{meir2021market}. Our results suggest that several simple\nadaptations, that can be added to any existing platform, may significantly\nreduce the skew in bids, thereby improving the allocation for both reviewers\nand conference organizers.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00435v1"
    },
    {
        "title": "Beacon-based Distributed Structure Formation in Multi-agent Systems",
        "authors": [
            "Tamzidul Mina",
            "Wonse Jo",
            "Shyam S. Kannan",
            "Byung-Cheol Min"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Autonomous shape and structure formation is an important problem in the\ndomain of large-scale multi-agent systems. In this paper, we propose a 3D\nstructure representation method and a distributed structure formation strategy\nwhere settled agents guide free moving agents to a prescribed location to\nsettle in the structure. Agents at the structure formation frontier looking for\nneighbors to settle act as beacons, generating a surface gradient throughout\nthe formed structure propagated by settled agents. Free-moving agents follow\nthe surface gradient along the formed structure surface to the formation\nfrontier, where they eventually reach the closest beacon and settle to continue\nthe structure formation following a local bidding process. Agent behavior is\ngoverned by a finite state machine implementation, along with potential\nfield-based motion control laws. We also discuss appropriate rules for\nrecovering from stagnation points. Simulation experiments are presented to show\nplanar and 3D structure formations with continuous and discontinuous\nboundary/surfaces, which validate the proposed strategy, followed by a\nscalability analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00920v2"
    },
    {
        "title": "D-HAL: Distributed Hierarchical Adversarial Learning for Multi-Agent\n  Interaction in Autonomous Intersection Management",
        "authors": [
            "Guanzhou Li",
            "Jianping Wu",
            "Yujing He"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Autonomous Intersection Management (AIM) provides a signal-free intersection\nscheduling paradigm for Connected Autonomous Vehicles (CAVs). Distributed\nlearning method has emerged as an attractive branch of AIM research. Compared\nwith centralized AIM, distributed AIM can be deployed to CAVs at a lower cost,\nand compared with rule-based and optimization-based method, learning-based\nmethod can treat various complicated real-time intersection scenarios more\nflexibly. Deep reinforcement learning (DRL) is the mainstream approach in\ndistributed learning to address AIM problems. However, the large-scale\nsimultaneous interactive decision of multiple agents and the rapid changes of\nenvironment caused by interactions pose challenges for DRL, making its reward\ncurve oscillating and hard to converge, and ultimately leading to a compromise\nin safety and computing efficiency. For this, we propose a non-RL learning\nframework, called Distributed Hierarchical Adversarial Learning (D-HAL). The\nframework includes an actor network that generates the actions of each CAV at\neach step. The immediate discriminator evaluates the interaction performance of\nthe actor network at the current step, while the final discriminator makes the\nfinal evaluation of the overall trajectory from a series of interactions. In\nthis framework, the long-term outcome of the behavior no longer motivates the\nactor network in terms of discounted rewards, but rather through a designed\nadversarial loss function with discriminative labels. The proposed model is\nevaluated at a four-way-six-lane intersection, and outperforms several\nstate-of-the-art methods on ensuring safety and reducing travel time.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.02630v1"
    },
    {
        "title": "Impact of baggage collection behaviour on aircraft evacuation",
        "authors": [
            "Dan Hodgson",
            "Christian Tonge",
            "Martyn Amos"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Recent reports of emergency aircraft evacuations have highlighted an\nincreasing tendency amongst evacuees to ignore clear safety warnings and to\ncollect and carry personal items of baggage during egress. However, relatively\nlittle work has so far been done on quantifying the impact of such behaviour on\nthe evacuation process. In this paper, we report the results of validated\nsimulation experiments (using the Boeing 777 wide-body aircraft), which confirm\nthat even a relatively low level of baggage collection can significantly delay\nevacuation. Our platform provides one possible framework for the investigation\nof processes and mitigation tactics to minimise the impact of baggage\ncollection behaviour in future.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.03264v1"
    },
    {
        "title": "Multi-trip algorithm for multi-depot rural postman problem with\n  rechargeable vehicles",
        "authors": [
            "Eashwar Sathyamurthy",
            "Jeffrey W. Herrmann",
            "Shapour Azarm"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper studies an extension of the rural postman problem with multiple\ndepots and rechargeable and reusable vehicles capable of multiple trips with\ncapacity constraints. This paper presents a new Mixed Integer Linear\nProgramming (MILP) formulation to find optimal solutions to the problem. The\npaper also proposes a new heuristic called the multi-trip algorithm for the\nproblem whose solutions are compared against solutions of heuristics from\nliterature and the optimal solutions obtained from the MILP formulation by\ntesting them on both benchmark instances and real-world instances generated\nfrom road maps. Results show that the proposed heuristic was able to solve all\nthe instances and produce better solutions than heuristics from the literature\non 37 of 39 total instances. Due to the high requirement of memory and compute\npower, the Gurobi optimizer used for solving the MILP formulation, although it\nproduced optimal solutions, was only able to solve benchmark instances but not\nreal-world instances.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.03481v1"
    },
    {
        "title": "Resource-aware Probability-based Collaborative Odor Source Localization\n  Using Multiple UAVs",
        "authors": [
            "Shan Wang",
            "Sheng Sun",
            "Min Liu",
            "Bo Gao",
            "Yuwei Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Benefitting from UAVs' characteristics of flexible deployment and\ncontrollable movement in 3D space, odor source localization with multiple UAVs\nhas been a hot research area in recent years. Considering the limited resources\nand insufficient battery capacities of UAVs, it is necessary to fast locate the\nodor source with low-complexity computation and minimal interaction under\ncomplicated environmental states. To this end, we propose a multi-UAV\ncollaboration based odor source localization (\\textit{MUC-OSL}) method, where\nsource estimation and UAV navigation are iteratively performed, aiming to\naccelerate the searching process and reduce the resource consumption of UAVs.\nSpecifically, in the source estimation phase, we present a collaborative\nparticle filter algorithm on the basis of UAVs' cognitive difference and\nGaussian fitting to improve source estimation accuracy. In the following\nnavigation phase, an adaptive path planning algorithm is designed based on\nPartially Observable Markov Decision Process (POMDP) to distributedly determine\nthe subsequent flying direction and moving steps of each UAV. The results of\nexperiments conducted on two simulation platforms demonstrate that\n\\textit{MUC-OSL} outperforms existing efforts in terms of mean search time and\nsuccess rate, and effectively reduces the resource consumption of UAVs.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.03830v1"
    },
    {
        "title": "Learning Adaptable Risk-Sensitive Policies to Coordinate in Multi-Agent\n  General-Sum Games",
        "authors": [
            "Ziyi Liu",
            "Yongchun Fang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In general-sum games, the interaction of self-interested learning agents\ncommonly leads to socially worse outcomes, such as defect-defect in the\niterated stag hunt (ISH). Previous works address this challenge by sharing\nrewards or shaping their opponents' learning process, which require too strong\nassumptions. In this paper, we demonstrate that agents trained to optimize\nexpected returns are more likely to choose a safe action that leads to\nguaranteed but lower rewards. However, there typically exists a risky action\nthat leads to higher rewards in the long run only if agents cooperate, e.g.,\ncooperate-cooperate in ISH. To overcome this, we propose using action value\ndistribution to characterize the decision's risk and corresponding potential\npayoffs. Specifically, we present Adaptable Risk-Sensitive Policy (ARSP). ARSP\nlearns the distributions over agent's return and estimates a dynamic\nrisk-seeking bonus to discover risky coordination strategies. Furthermore, to\navoid overfitting training opponents, ARSP learns an auxiliary opponent\nmodeling task to infer opponents' types and dynamically alter corresponding\nstrategies during execution. Empirically, agents trained via ARSP can achieve\nstable coordination during training without accessing opponent's rewards or\nlearning process, and can adapt to non-cooperative opponents during execution.\nTo the best of our knowledge, it is the first method to learn coordination\nstrategies between agents both in iterated prisoner's dilemma (IPD) and\niterated stag hunt (ISH) without shaping opponents or rewards, and can adapt to\nopponents with distinct strategies during execution. Furthermore, we show that\nARSP can be scaled to high-dimensional settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.07850v1"
    },
    {
        "title": "Optimized Control-Centric Communication in Cooperative Adaptive Cruise\n  Control Systems",
        "authors": [
            "Mahdi Razzaghpour",
            "Shahriar Shahram",
            "Rodolfo Valiente",
            "Mahdi Zaman",
            "Yaser P. Fallah"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this study, we explore an innovative approach to enhance cooperative\ndriving in vehicle platooning systems through the use of vehicle-to-everything\n(V2X) communication technologies. As Connected and Autonomous Vehicles (CAVs)\nintegrate into increasingly dense traffic networks, the challenge of\nefficiently managing communication resources becomes crucial. Our focus is on\noptimizing communication strategies to support the growing network of\ninterconnected vehicles without compromising traffic safety and efficiency. We\nintroduce a novel control-aware communication framework designed to reduce\ncommunication overhead while maintaining essential performance standards in\nvehicle platoons. This method pivots from traditional periodic communication to\nmore adaptable aperiodic or event-triggered schemes. Additionally, we integrate\nModel-Based Communication (MBC) to enhance vehicle perception under suboptimal\ncommunication conditions. By merging control-aware communication with MBC, our\napproach effectively controls vehicle platoons, striking a balance between\ncommunication resource conservation and control performance. The results show a\nmarked decrease in communication frequency by 47\\%, with minimal impact on\ncontrol accuracy, such as less than 1\\% variation in speed. Extensive\nsimulations validate the effectiveness of our combined approach in managing\ncommunication and control in vehicle platoons, offering a promising solution\nfor future cooperative driving systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.08076v2"
    },
    {
        "title": "Coordinating Fully-Cooperative Agents Using Hierarchical Learning\n  Anticipation",
        "authors": [
            "Ariyan Bighashdel",
            "Daan de Geus",
            "Pavol Jancura",
            "Gijs Dubbelman"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Learning anticipation is a reasoning paradigm in multi-agent reinforcement\nlearning, where agents, during learning, consider the anticipated learning of\nother agents. There has been substantial research into the role of learning\nanticipation in improving cooperation among self-interested agents in\ngeneral-sum games. Two primary examples are Learning with Opponent-Learning\nAwareness (LOLA), which anticipates and shapes the opponent's learning process\nto ensure cooperation among self-interested agents in various games such as\niterated prisoner's dilemma, and Look-Ahead (LA), which uses learning\nanticipation to guarantee convergence in games with cyclic behaviors. So far,\nthe effectiveness of applying learning anticipation to fully-cooperative games\nhas not been explored. In this study, we aim to research the influence of\nlearning anticipation on coordination among common-interested agents. We first\nillustrate that both LOLA and LA, when applied to fully-cooperative games,\ndegrade coordination among agents, causing worst-case outcomes. Subsequently,\nto overcome this miscoordination behavior, we propose Hierarchical Learning\nAnticipation (HLA), where agents anticipate the learning of other agents in a\nhierarchical fashion. Specifically, HLA assigns agents to several hierarchy\nlevels to properly regulate their reasonings. Our theoretical and empirical\nfindings confirm that HLA can significantly improve coordination among\ncommon-interested agents in fully-cooperative normal-form games. With HLA, to\nthe best of our knowledge, we are the first to unlock the benefits of learning\nanticipation for fully-cooperative games.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.08307v2"
    },
    {
        "title": "Inferring Occluded Agent Behavior in Dynamic Games from Noise Corrupted\n  Observations",
        "authors": [
            "Tianyu Qiu",
            "David Fridovich-Keil"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In mobile robotics and autonomous driving, it is natural to model agent\ninteractions as the Nash equilibrium of a noncooperative, dynamic game. These\nmethods inherently rely on observations from sensors such as lidars and cameras\nto identify agents participating in the game and, therefore, have difficulty\nwhen some agents are occluded. To address this limitation, this paper presents\nan occlusion-aware game-theoretic inference method to estimate the locations of\npotentially occluded agents, and simultaneously infer the intentions of both\nvisible and occluded agents, which best accounts for the observations of\nvisible agents. Additionally, we propose a receding horizon planning strategy\nbased on an occlusion-aware contingency game designed to navigate in scenarios\nwith potentially occluded agents. Monte Carlo simulations validate our\napproach, demonstrating that it accurately estimates the game model and\ntrajectories for both visible and occluded agents using noisy observations of\nvisible agents. Our planning pipeline significantly enhances navigation safety\nwhen compared to occlusion-ignorant baseline as well.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.09744v3"
    },
    {
        "title": "Event-triggered privacy preserving consensus control with edge-based\n  additive noise",
        "authors": [
            "Limei Liang",
            "Ruiqi Ding",
            "Shuai Liu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this article, we investigate the distributed privacy preserving weighted\nconsensus control problem for linear continuous-time multi-agent systems under\nthe event-triggering communication mode. A novel event-triggered privacy\npreserving consensus scheme is proposed, which can be divided into three\nphases. First, for each agent, an event-triggered mechanism is designed to\ndetermine whether the current state is transmitted to the corresponding\nneighbor agents, which avoids the frequent real-time communication. Then, to\nprotect the privacy of initial states from disclosure, the edge-based mutually\nindependent standard white noise is added to each communication channel.\nFurther, to attenuate the effect of noise on consensus control, we propose a\nstochastic approximation type protocol for each agent. By using the tools of\nstochastic analysis and graph theory, the asymptotic property and convergence\naccuracy of consensus error is analyzed. Finally, a numerical simulation is\ngiven to illustrate the effectiveness of the proposed scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.10547v1"
    },
    {
        "title": "Fair Healthcare Rationing to Maximize Dynamic Utilities",
        "authors": [
            "Aadityan Ganesh",
            "Prajakta Nimbhorkar",
            "Pratik Ghosal",
            "Vishwa Prakash HV"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Allocation of scarce healthcare resources under limited logistic and\ninfrastructural facilities is a major issue in the modern society. We consider\nthe problem of allocation of healthcare resources like vaccines to people or\nhospital beds to patients in an online manner. Our model takes into account the\narrival of resources on a day-to-day basis, different categories of agents, the\npossible unavailability of agents on certain days, and the utility associated\nwith each allotment as well as its variation over time.\n  We propose a model where priorities for various categories are modelled in\nterms of utilities of agents. We give online and offline algorithms to compute\nan allocation that respects eligibility of agents into different categories,\nand incentivizes agents not to hide their eligibility for some category. The\noffline algorithm gives an optimal allocation while the on-line algorithm gives\nan approximation to the optimal allocation in terms of total utility. Our\nalgorithms are efficient, and maintain fairness among different categories of\nagents. Our models have applications in other areas like refugee settlement and\nvisa allocation. We evaluate the performance of our algorithms on real-life and\nsynthetic datasets. The experimental results show that the online algorithm is\nfast and performs better than the given theoretical bound in terms of total\nutility. Moreover, the experimental results confirm that our utility-based\nmodel correctly captures the priorities of categories\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11053v1"
    },
    {
        "title": "Team Coordination on Graphs with State-Dependent Edge Cost",
        "authors": [
            "Sara Oughourli",
            "Manshi Limbu",
            "Zechen Hu",
            "Xuan Wang",
            "Xuesu Xiao",
            "Daigo Shishika"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper studies a team coordination problem in a graph environment.\nSpecifically, we incorporate \"support\" action which an agent can take to reduce\nthe cost for its teammate to traverse some edges that have higher costs\notherwise. Due to this added feature, the graph traversal is no longer a\nstandard multi-agent path planning problem. To solve this new problem, we\npropose a novel formulation by posing it as a planning problem in the joint\nstate space: the joint state graph (JSG). Since the edges of JSG implicitly\nincorporate the support actions taken by the agents, we are able to now\noptimize the joint actions by solving a standard single-agent path planning\nproblem in JSG. One main drawback of this approach is the curse of\ndimensionality in both the number of agents and the size of the graph. To\nimprove scalability in graph size, we further propose a hierarchical\ndecomposition method to perform path planning in two levels. We provide\ncomplexity analysis as well as a statistical analysis to demonstrate the\nefficiency of our algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11457v1"
    },
    {
        "title": "Pooled Grocery Delivery with Tight Deadlines from Multiple Depots",
        "authors": [
            "Maximilian Kronmueller",
            "Andres Fielbaum",
            "Javier Alonso-Mora"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We study routing for on-demand last-mile logistics with two crucial novel\nfeatures: i) Multiple depots, optimizing where to pick-up every order, ii)\nAllowing vehicles to perform depot returns prior to being empty, thus adapting\ntheir routes to include new orders online. Both features result in shorter\ndistances and more agile planning. We propose a scalable dynamic method to\ndeliver orders as fast as possible. Following a rolling horizon approach, each\ntime step the following is executed. First, define potential pick-up locations\nand identify which groups of orders can be transported together, with which\nvehicle and following which route. Then, decide which of these potential groups\nof orders will be executed and by which vehicle by solving an integer linear\nprogram. We simulate one day of service in Amsterdam that considers 10,000\nrequests, compare results to several strategies and test different scenarios.\nResults underpin the advantages of the proposed method\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11804v1"
    },
    {
        "title": "Stochastic Graph Neural Network-based Value Decomposition for MARL in\n  Internet of Vehicles",
        "authors": [
            "Baidi Xiao",
            "Rongpeng Li",
            "Fei Wang",
            "Chenghui Peng",
            "Jianjun Wu",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Autonomous driving has witnessed incredible advances in the past several\ndecades, while Multi-Agent Reinforcement Learning (MARL) promises to satisfy\nthe essential need of autonomous vehicle control in a wireless connected\nvehicle networks. In MARL, how to effectively decompose a global feedback into\nthe relative contributions of individual agents belongs to one of the most\nfundamental problems. However, the environment volatility due to vehicle\nmovement and wireless disturbance could significantly shape time-varying\ntopological relationships among agents, thus making the Value Decomposition\n(VD) challenging. Therefore, in order to cope with this annoying volatility, it\nbecomes imperative to design a dynamic VD framework. Hence, in this paper, we\npropose a novel Stochastic VMIX (SVMIX) methodology by taking account of\ndynamic topological features during the VD and incorporating the corresponding\ncomponents into a multi-agent actor-critic architecture. In particular,\nStochastic Graph Neural Network (SGNN) is leveraged to effectively capture\nunderlying dynamics in topological features and improve the flexibility of VD\nagainst the environment volatility. Finally, the superiority of SVMIX is\nverified through extensive simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.13213v1"
    },
    {
        "title": "An Agent-Based Model for Poverty and Discrimination Policy-Making",
        "authors": [
            "Nieves Montes",
            "Georgina Curto",
            "Nardine Osman",
            "Carles Sierra"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The deceleration of global poverty reduction in the last decades suggests\nthat traditional redistribution policies are losing their effectiveness.\nAlternative ways to work towards the #1 United Nations Sustainable Development\nGoal (poverty eradication) are required. NGOs have insistingly denounced the\ncriminalization of poverty, and the social science literature suggests that\ndiscrimination against the poor (a phenomenon known as aporophobia) could\nconstitute a brake to the fight against poverty. This paper describes a\nproposal for an agent-based model to examine the impact that aporophobia at the\ninstitutional level has on poverty levels. This aporophobia agent-based model\n(AABM) will first be applied to a case study in the city of Barcelona. The\nregulatory environment is central to the model, since aporophobia has been\nidentified in the legal framework. The AABM presented in this paper constitutes\na cornerstone to obtain empirical evidence, in a non-invasive way, on the\ncausal relationship between aporophobia and poverty levels. The simulations\nthat will be generated based on the AABM have the potential to inform a new\ngeneration of poverty reduction policies, which act not only on the\nredistribution of wealth but also on the discrimination of the poor.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.13994v1"
    },
    {
        "title": "A Method for Emerging Empirical Age Structures in Agent-Based Models\n  with Exogenous Survival Probabilities",
        "authors": [
            "Kathyrn R. Fair",
            "Omar A. Guerrero"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  For many applications of agent-based models (ABMs), an agent's age influences\nimportant decisions (e.g. their contribution to/withdrawal from pension funds,\ntheir level of risk aversion in decision-making, etc.) and outcomes in their\nlife cycle (e.g. their susceptibility to disease). These considerations make it\ncrucial to accurately capture the age distribution of the population being\nconsidered. Often, empirical survival probabilities cannot be used in ABMs to\ngenerate the observed age structure due to discrepancies between samples or\nmodels (between the ABM and the survival statistical model used to produce\nempirical rates). In these cases, imputing empirical survival probabilities\nwill not generate the observed age structure of the population, and assumptions\nsuch as exogenous agent inflows are necessary (but not necessarily empirically\nvalid). In this paper, we propose a method that allows for the preservation of\nagent age-structure without the exogenous influx of agents, even when only a\nsubset of the population is being modelled. We demonstrate the flexibility and\naccuracy of our methodology by performing simulations of several real-world age\ndistributions. This method is a useful tool for those developing ABMs across a\nbroad range of applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.17317v1"
    },
    {
        "title": "Models as Agents: Optimizing Multi-Step Predictions of Interactive Local\n  Models in Model-Based Multi-Agent Reinforcement Learning",
        "authors": [
            "Zifan Wu",
            "Chao Yu",
            "Chen Chen",
            "Jianye Hao",
            "Hankz Hankui Zhuo"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Research in model-based reinforcement learning has made significant progress\nin recent years. Compared to single-agent settings, the exponential dimension\ngrowth of the joint state-action space in multi-agent systems dramatically\nincreases the complexity of the environment dynamics, which makes it infeasible\nto learn an accurate global model and thus necessitates the use of agent-wise\nlocal models. However, during multi-step model rollouts, the prediction of one\nlocal model can affect the predictions of other local models in the next step.\nAs a result, local prediction errors can be propagated to other localities and\neventually give rise to considerably large global errors. Furthermore, since\nthe models are generally used to predict for multiple steps, simply minimizing\none-step prediction errors regardless of their long-term effect on other models\nmay further aggravate the propagation of local errors. To this end, we propose\nModels as AGents (MAG), a multi-agent model optimization framework that\nreversely treats the local models as multi-step decision making agents and the\ncurrent policies as the dynamics during the model rollout process. In this way,\nthe local models are able to consider the multi-step mutual affect between each\nother before making predictions. Theoretically, we show that the objective of\nMAG is approximately equivalent to maximizing a lower bound of the true\nenvironment return. Experiments on the challenging StarCraft II benchmark\ndemonstrate the effectiveness of MAG.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.17984v1"
    },
    {
        "title": "Exploring Global Climate Cooperation through AI: An Assessment of the\n  AI4GCC Framework by simulations",
        "authors": [
            "Xavier Marjou",
            "Arnaud Braud",
            "Gaël Fromentoux"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In scenarios where a single player cannot control other players, cooperative\nAI is a recent technology that takes advantage of deep learning to assess\nwhether cooperation might occur. One main difficulty of this approach is that\nit requires a certain level of consensus on the protocol (actions and rules),\nat least from a majority of players. In our work, we study the simulations\nperformed on the cooperative AI tool proposed in the context of AI for Global\nClimate Cooperation (AI4GCC) competition. We experimented simulations with and\nwithout the AI4GCC default negotiation, including with regions configured\nslightly differently in terms of labor and/or technology growth. These first\nresults showed that the AI4GCC framework offers a promising cooperative\nframework to experiment with global warming mitigation. We also propose future\nwork to strengthen this framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.17990v1"
    },
    {
        "title": "Dynamic Adversarial Resource Allocation: the dDAB Game",
        "authors": [
            "Daigo Shishika",
            "Yue Guan",
            "Jason R. Marden",
            "Michael Dorothy",
            "Panagiotis Tsiotras",
            "Vijay Kumar"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This work proposes a dynamic and adversarial resource allocation problem in a\ngraph environment, which is referred to as the dynamic Defender-Attacker Blotto\n(dDAB) game. A team of defender robots is tasked to ensure numerical advantage\nat every node in the graph against a team of attacker robots. The engagement is\nformulated as a discrete-time dynamic game, where the two teams reallocate\ntheir robots in sequence and each robot can move at most one hop at each time\nstep. The game terminates with the attacker's victory if any node has more\nattacker robots than defender robots. Our goal is to identify the necessary and\nsufficient number of defender robots to guarantee defense. Through a\nreachability analysis, we first solve the problem for the case where the\nattacker team stays as a single group. The results are then generalized to the\ncase where the attacker team can freely split and merge into subteams.\nCrucially, our analysis indicates that there is no incentive for the attacker\nteam to split, which significantly reduces the search space for the attacker's\nwinning strategies and also enables us to design defender counter-strategies\nusing superposition. We also present an efficient numerical algorithm to\nidentify the necessary and sufficient number of defender robots to defend a\ngiven graph. Finally, we present illustrative examples to verify the efficacy\nof the proposed framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02172v1"
    },
    {
        "title": "Constructing and deconstructing bias: modeling privilege and mentorship\n  in agent-based simulations",
        "authors": [
            "Andria L. Smith",
            "Simon Heuschkel",
            "Ksenia Keplinger",
            "Charley M. Wu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Bias exists in how we pick leaders, who we perceive as being influential, and\nwho we interact with, not only in society, but in organizational contexts.\nDrawing from leadership emergence and social influence theories, we investigate\npotential interventions that support diverse leaders. Using agent-based\nsimulations, we model a collective search process on a fitness landscape.\nAgents combine individual and social learning, and are represented as a feature\nvector blending relevant (e.g., individual learning characteristics) and\nirrelevant (e.g., race or gender) features. Agents use rational principles of\nlearning to estimate feature weights on the basis of performance predictions,\nwhich are used to dynamically define social influence in their network. We show\nhow biases arise based on historic privilege, but can be drastically reduced\nthrough the use of an intervention (e.g. mentorship). This work provides\nimportant insights into the cognitive mechanisms underlying bias construction\nand deconstruction, while pointing towards real-world interventions to be\ntested in future empirical work.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02351v1"
    },
    {
        "title": "Selecting Representative Bodies: An Axiomatic View",
        "authors": [
            "Manon Revel",
            "Niclas Boehmer",
            "Rachael Colley",
            "Markus Brill",
            "Piotr Faliszewski",
            "Edith Elkind"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  As the world's democratic institutions are challenged by dissatisfied\ncitizens, political scientists and also computer scientists have proposed and\nanalyzed various (innovative) methods to select representative bodies, a\ncrucial task in every democracy. However, a unified framework to analyze and\ncompare different selection mechanisms is missing, resulting in very few\ncomparative works. To address this gap, we advocate employing concepts and\ntools from computational social choice in order to devise a model in which\ndifferent selection mechanisms can be formalized. Such a model would allow for\ndesirable representation axioms to be conceptualized and evaluated. We make the\nfirst step in this direction by proposing a unifying mathematical formulation\nof different selection mechanisms as well as various social-choice-inspired\naxioms such as proportionality and monotonicity.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02774v1"
    },
    {
        "title": "Shepherding Heterogeneous Flocks: Overview and Prospect",
        "authors": [
            "Anna Fujioka",
            "Masaki Ogura",
            "Naoki Wakamiya"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The problem of guiding a flock of several autonomous agents using repulsion\nforce exerted by a smaller number of agents is called the shepherding problem\nand has been attracting attention due to its potential engineering\napplications. Although several works propose methodologies for achieving the\nshepherding task in this context, most assume that sheep agents have the same\ndynamics, which only sometimes holds in reality. The objective of this\ndiscussion paper is to overview a recent research trend addressing the gap\nmentioned above between the commonly placed uniformity assumption and the\nreality. Specifically, we first introduce recent guidance methods for\nheterogeneous flocks and then describe the prospects of the shepherding problem\nfor heterogeneous flocks.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.03951v1"
    },
    {
        "title": "Dynamics-Based Algorithm-Level Privacy Preservation for Push-Sum Average\n  Consensus",
        "authors": [
            "Huqiang Cheng",
            "Mengying Xie",
            "Xiaowei Yang",
            "Qingguo Lü",
            "Huaqing Li"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In the intricate dance of multi-agent systems, achieving average consensus is\nnot just vital--it is the backbone of their functionality. In conventional\naverage consensus algorithms, all agents reach an agreement by individual\ncalculations and sharing information with their respective neighbors.\nNevertheless, the information interactions that occur in the communication\nnetwork may make sensitive information be revealed. In this paper, we develop a\nnew privacy-preserving average consensus method on unbalanced directed\nnetworks. Specifically, we ensure privacy preservation by carefully embedding\nrandomness in mixing weights to confuse communications and introducing an extra\nauxiliary parameter to mask the state-updated rule in several initial\niterations. In parallel, we exploit the intrinsic robustness of consensus\ndynamics to guarantee that the average consensus is precisely achieved.\nTheoretical results demonstrate that the designed algorithms can converge\nlinearly to the exact average consensus value and can guarantee privacy\npreservation of agents against both honest-but-curious and eavesdropping\nattacks. The designed algorithms are fundamentally different compared to\ndifferential privacy based algorithms that enable privacy preservation via\nsacrificing consensus performance. Finally, numerical experiments validate the\ncorrectness of the theoretical findings.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.08018v3"
    },
    {
        "title": "Capacity Allocation and Pricing of High Occupancy Toll Lane Systems with\n  Heterogeneous Travelers",
        "authors": [
            "Haripriya Pulyassary",
            "Ruifan Yang",
            "Zhanhao Zhang",
            "Manxi Wu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this article, we study the optimal design of High Occupancy Toll (HOT)\nlanes. In our setup, the traffic authority determines the road capacity\nallocation between HOT lanes and ordinary lanes, as well as the toll price\ncharged for travelers who use the HOT lanes but do not meet the high-occupancy\neligibility criteria. We build a game-theoretic model to analyze the decisions\nmade by travelers with heterogeneous values of time and carpool disutilities,\nwho choose between paying or forming carpools to take the HOT lanes, or taking\nthe ordinary lanes. Travelers' payoffs depend on the congestion cost of the\nlane that they take, the payment and the carpool disutilities. We provide a\ncomplete characterization of travelers' equilibrium strategies and resulting\ntravel times for any capacity allocation and toll price. We also calibrate our\nmodel on the California Interstate highway 880 and compute the optimal capacity\nallocation and toll design.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09234v2"
    },
    {
        "title": "PID-inspired modifications in response threshold models in swarm\n  intelligent systems",
        "authors": [
            "Maryam Kebari",
            "Annie S. Wu",
            "H. David Mathias"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this study, we investigate the effectiveness of using the PID\n(Proportional - Integral - Derivative) control loop factors for modifying\nresponse thresholds in a decentralized, non-communicating, threshold-based\nswarm. Each agent in our swarm has a set of four thresholds, each corresponding\nto a task the agent is capable of performing. The agent will act on a\nparticular task if the stimulus is higher than its corresponding threshold. The\nability to modify their thresholds allows the agents to specialize dynamically\nin response to task demands. Current approaches to dynamic thresholds typically\nuse a learning and forgetting process to adjust thresholds. These methods are\nable to effectively specialize once, but can have difficulty re-specializing if\nthe task demands change. Our approach, inspired by the PID control loop, alters\nthe threshold values based on the current task demand value, the change in task\ndemand, and the cumulative sum of previous task demands. We show that our\nPID-inspired method is scalable and outperforms fixed and current learning and\nforgetting response thresholds with non-changing, constant, and abrupt changes\nin task demand. This superior performance is due to the ability of our method\nto re-specialize repeatedly in response to changing task demands.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12385v1"
    },
    {
        "title": "N$\\text{A}^\\text{2}$Q: Neural Attention Additive Model for Interpretable\n  Multi-Agent Q-Learning",
        "authors": [
            "Zichuan Liu",
            "Yuanyang Zhu",
            "Chunlin Chen"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Value decomposition is widely used in cooperative multi-agent reinforcement\nlearning, however, its implicit credit assignment mechanism is not yet fully\nunderstood due to black-box networks. In this work, we study an interpretable\nvalue decomposition framework via the family of generalized additive models. We\npresent a novel method, named Neural Attention Additive Q-learning\n(N$\\text{A}^\\text{2}$Q), providing inherent intelligibility of collaboration\nbehavior. N$\\text{A}^\\text{2}$Q can explicitly factorize the optimal joint\npolicy induced by enriching shape functions to model all possible coalitions of\nagents into individual policies. Moreover, we construct identity semantics to\npromote estimating credits together with the global state and individual value\nfunctions, where local semantic masks help us diagnose whether each agent\ncaptures relevant-task information. Extensive experiments show that\nN$\\text{A}^\\text{2}$Q consistently achieves superior performance compared to\ndifferent state-of-the-art methods on all challenging tasks, while yielding\nhuman-like interpretability.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.13383v4"
    },
    {
        "title": "Guaranteed Evader Detection in Multi-Agent Search Tasks using Pincer\n  Trajectories",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Assume that inside an initial planar area there are smart mobile evaders\nattempting to avoid detection by a team of sweeping searching agents. All\nsweepers detect evaders with fan-shaped sensors, modeling the field of view of\nreal cameras. Detection of all evaders is guaranteed with cooperative sweeping\nstrategies, by setting requirements on sweepers' speed, and by carefully\ndesigning their trajectories. Assume the smart evaders have an upper limit on\ntheir speed which is a-priori known to the sweeping team. An easier task for\nthe team of sweepers is to confine evaders to the domain in which they are\ninitially located. The sweepers accomplish the confinement task if they move\nsufficiently fast and detect evaders by applying an appropriate search\nstrategy. Any given search strategy results in a minimal sweeper's speed in\norder to be able to detect all evaders. The minimal speed guarantees the\nability of the sweeping team to confine evaders to their original domain, and\nif the sweepers move faster they are able to detect all evaders that are\npresent in the region. We present results on the total search time for a novel\npincer-movement based search protocol that utilizes complementary trajectories\nalong with adaptive sensor geometries for any even number of pursuers.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00533v1"
    },
    {
        "title": "AI-Assisted Ethics? Considerations of AI Simulation for the Ethical\n  Assessment and Design of Assistive Technologies",
        "authors": [
            "Silke Schicktanz",
            "Johannes Welsch",
            "Mark Schweda",
            "Andreas Hein",
            "Jochem W. Rieger",
            "Thomas Kirste"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Current ethical debates on the use of artificial intelligence (AI) in health\ncare treat AI as a product of technology in three ways: First, by assessing\nrisks and potential benefits of currently developed AI-enabled products with\nethical checklists; second, by proposing ex ante lists of ethical values seen\nas relevant for the design and development of assisting technology, and third,\nby promoting AI technology to use moral reasoning as part of the automation\nprocess. Subsequently, we propose a fourth approach to AI, namely as a\nmethodological tool to assist ethical reflection. We provide a concept of an\nAI-simulation informed by three separate elements: 1) stochastic human behavior\nmodels based on behavioral data for simulating realistic settings, 2)\nqualitative empirical data on value statements regarding internal policy, and\n3) visualization components that aid in understanding the impact of changes in\nthese variables. The potential of this approach is to inform an\ninterdisciplinary field about anticipated ethical challenges or ethical\ntrade-offs in concrete settings and, hence, to spark a re-evaluation of design\nand implementation plans. This may be particularly useful for applications that\ndeal with extremely complex values and behavior or with limitations on the\ncommunication resources of affected persons (e.g., persons with dementia care\nor for care of persons with cognitive impairment). Simulation does not replace\nethical reflection but does allow for detailed, context-sensitive analysis\nduring the design process and prior to implementation. Finally, we discuss the\ninherently quantitative methods of analysis afforded by stochastic simulations\nas well as the potential for ethical discussions and how simulations with AI\ncan improve traditional forms of thought experiments and future-oriented\ntechnology assessment.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00566v1"
    },
    {
        "title": "Cooperative Driving of Connected Autonomous Vehicles in Heterogeneous\n  Mixed Traffic: A Game Theoretic Approach",
        "authors": [
            "Shiyu Fang",
            "Peng Hang",
            "Chongfeng Wei",
            "Yang Xing",
            "Jian Sun"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  High-density, unsignalized intersection has always been a bottleneck of\nefficiency and safety. The emergence of Connected Autonomous Vehicles (CAVs)\nresults in a mixed traffic condition, further increasing the complexity of the\ntransportation system. Against this background, this paper aims to study the\nintricate and heterogeneous interaction of vehicles and conflict resolution at\nthe high-density, mixed, unsignalized intersection. Theoretical insights about\nthe interaction between CAVs and Human-driven Vehicles (HVs) and the\ncooperation of CAVs are synthesized, based on which a novel cooperative\ndecision-making framework in heterogeneous mixed traffic is proposed.\nNormalized Cooperative game is concatenated with Level-k game (NCL game) to\ngenerate a system optimal solution. Then Lattice planner generates the optimal\nand collision-free trajectories for CAVs. To reproduce HVs in mixed traffic,\ninteractions from naturalistic human driving data are extracted as prior\nknowledge. Non-cooperative game and Inverse Reinforcement Learning (IRL) are\nintegrated to mimic the decision making of heterogeneous HVs. Finally, three\ncases are conducted to verify the performance of the proposed algorithm,\nincluding the comparative analysis with different methods, the case study under\ndifferent Rates of Penetration (ROP) and the interaction analysis with\nheterogeneous HVs. It is found that the proposed cooperative decision-making\nframework is beneficial to the driving conflict resolution and the traffic\nefficiency improvement of the mixed unsignalized intersection. Besides, due to\nthe consideration of driving heterogeneity, better human-machine interaction\nand cooperation can be realized in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.03563v1"
    },
    {
        "title": "Multi-Objective Task Assignment and Multiagent Planning with Hybrid\n  GPU-CPU Acceleration",
        "authors": [
            "Thomas Robinson",
            "Guoxin Su"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Allocation and planning with a collection of tasks and a group of agents is\nan important problem in multiagent systems. One commonly faced bottleneck is\nscalability, as in general the multiagent model increases exponentially in size\nwith the number of agents. We consider the combination of random task\nassignment and multiagent planning under multiple-objective constraints, and\nshow that this problem can be decentralised to individual agent-task models. We\npresent an algorithm of point-oriented Pareto computation, which checks whether\na point corresponding to given cost and probability thresholds for our formal\nproblem is feasible or not. If the given point is infeasible, our algorithm\nfinds a Pareto-optimal point which is closest to the given point. We provide\nthe first multi-objective model checking framework that simultaneously uses GPU\nand multi-core acceleration. Our framework manages CPU and GPU devices as a\nload balancing problem for parallel computation. Our experiments demonstrate\nthat parallelisation achieves significant run time speed-up over sequential\ncomputation.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.04397v1"
    },
    {
        "title": "Optimal Scheduling of Agents in ADTrees: Specialised Algorithm and\n  Declarative Models",
        "authors": [
            "Jaime Arias",
            "Carlos Olarte",
            "Laure Petrucci",
            "Łukasz Maśko",
            "Wojciech Penczek",
            "Teofil Sidoruk"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Expressing attack-defence trees in a multi-agent setting allows for studying\na new aspect of security scenarios, namely how the number of agents and their\ntask assignment impact the performance, e.g. attack time, of strategies\nexecuted by opposing coalitions. Optimal scheduling of agents' actions, a\nnon-trivial problem, is thus vital. We discuss associated caveats and propose\nan algorithm that synthesises such an assignment, targeting minimal attack time\nand using the minimal number of agents for a given attack-defence tree. We also\ninvestigate an alternative approach for the same problem using Rewriting Logic,\nstarting with a simple and elegant declarative model, whose correctness (in\nterms of schedule's optimality) is self-evident. We then refine this\nspecification, inspired by the design of our specialised algorithm, to obtain\nan efficient system that can be used as a playground to explore various aspects\nof attack-defence trees. We compare the two approaches on different benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.04616v2"
    },
    {
        "title": "Fast Teammate Adaptation in the Presence of Sudden Policy Change",
        "authors": [
            "Ziqian Zhang",
            "Lei Yuan",
            "Lihe Li",
            "Ke Xue",
            "Chengxing Jia",
            "Cong Guan",
            "Chao Qian",
            "Yang Yu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In cooperative multi-agent reinforcement learning (MARL), where an agent\ncoordinates with teammate(s) for a shared goal, it may sustain non-stationary\ncaused by the policy change of teammates. Prior works mainly concentrate on the\npolicy change during the training phase or teammates altering cross episodes,\nignoring the fact that teammates may suffer from policy change suddenly within\nan episode, which might lead to miscoordination and poor performance as a\nresult. We formulate the problem as an open Dec-POMDP, where we control some\nagents to coordinate with uncontrolled teammates, whose policies could be\nchanged within one episode. Then we develop a new framework, fast teammates\nadaptation (Fastap), to address the problem. Concretely, we first train\nversatile teammates' policies and assign them to different clusters via the\nChinese Restaurant Process (CRP). Then, we train the controlled agent(s) to\ncoordinate with the sampled uncontrolled teammates by capturing their\nidentifications as context for fast adaptation. Finally, each agent applies its\nlocal information to anticipate the teammates' context for decision-making\naccordingly. This process proceeds alternately, leading to a robust policy that\ncan adapt to any teammates during the decentralized execution phase. We show in\nmultiple multi-agent benchmarks that Fastap can achieve superior performance\nthan multiple baselines in stationary and non-stationary scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.05911v1"
    },
    {
        "title": "Learning Optimal \"Pigovian Tax\" in Sequential Social Dilemmas",
        "authors": [
            "Yun Hua",
            "Shang Gao",
            "Wenhao Li",
            "Bo Jin",
            "Xiangfeng Wang",
            "Hongyuan Zha"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In multi-agent reinforcement learning, each agent acts to maximize its\nindividual accumulated rewards. Nevertheless, individual accumulated rewards\ncould not fully reflect how others perceive them, resulting in selfish\nbehaviors that undermine global performance. The externality theory, defined as\n``the activities of one economic actor affect the activities of another in ways\nthat are not reflected in market transactions,'' is applicable to analyze the\nsocial dilemmas in MARL. One of its most profound non-market solutions,\n``Pigovian Tax'', which internalizes externalities by taxing those who create\nnegative externalities and subsidizing those who create positive externalities,\ncould aid in developing a mechanism to resolve MARL's social dilemmas. The\npurpose of this paper is to apply externality theory to analyze social dilemmas\nin MARL. To internalize the externalities in MARL, the \\textbf{L}earning\n\\textbf{O}ptimal \\textbf{P}igovian \\textbf{T}ax method (LOPT), is proposed,\nwhere an additional agent is introduced to learn the tax/allowance allocation\npolicy so as to approximate the optimal ``Pigovian Tax'' which accurately\nreflects the externalities for all agents. Furthermore, a reward shaping\nmechanism based on the approximated optimal ``Pigovian Tax'' is applied to\nreduce the social cost of each agent and tries to alleviate the social\ndilemmas. Compared with existing state-of-the-art methods, the proposed LOPT\nleads to higher collective social welfare in both the Escape Room and the\nCleanup environments, which shows the superiority of our method in solving\nsocial dilemmas.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.06227v1"
    },
    {
        "title": "Spiral Sweeping Search for Smart Evaders",
        "authors": [
            "Roee M. Francos",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Consider a given planar circular region, in which there is an unknown number\nof smart mobile evaders. We wish to detect evaders using a line formation of\nsweeping agents whose total sensing length is predetermined. We propose\nprocedures for designing spiral sweeping protocols that ensure the successful\ncompletion of the task, thus deriving conditions on the sweeping speed of the\nlinear formation and its path. Successful completion of the task implies that\nevaders with a given limit on their speed cannot escape the sweeping agents. A\nsimpler task for the sweeping formation is the confinement of evaders to a\ndesired region, such as their original domain. The feasibility of completing\nthese tasks depends on geometric and dynamic constraints that impose a lower\nbound on the speed that the sweeping agents must have. This critical speed is\nderived to ensure the satisfaction of the confinement task. Increasing the\nspeed above the lower bound enables the sweepers to complete the search task as\nwell. We develop two spiral line formation search processes for smart evaders,\nthat address current limitations in search against smart evaders. Additionally,\nwe present a quantitative and qualitative comparison analysis between the total\nsearch time of circular line formation sweep processes and spiral line\nformation processes. We evaluate the different strategies by using two metrics,\ntotal search time and the minimal critical speed required for a successful\nsearch.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08137v1"
    },
    {
        "title": "More Like Real World Game Challenge for Partially Observable Multi-Agent\n  Cooperation",
        "authors": [
            "Meng Yao",
            "Xueou Feng",
            "Qiyue Yin"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Some standardized environments have been designed for partially observable\nmulti-agent cooperation, but we find most current environments are synchronous,\nwhereas real-world agents often have their own action spaces leading to\nasynchrony. Furthermore, fixed agents number limits the scalability of action\nspace, whereas in reality agents number can change resulting in a flexible\naction space. In addition, current environments are balanced, which is not\nalways the case in the real world where there may be an ability gap between\ndifferent parties leading to asymmetry. Finally, current environments tend to\nhave less stochasticity with simple state transitions, whereas real-world\nenvironments can be highly stochastic and result in extremely risky. To address\nthis gap, we propose WarGame Challenge (WGC) inspired by the Wargame. WGC is a\nlightweight, flexible, and easy-to-use environment with a clear framework that\ncan be easily configured by users. Along with the benchmark, we provide MARL\nbaseline algorithms such as QMIX and a toolkit to help algorithms complete\nperformance tests on WGC. Finally, we present baseline experiment results,\nwhich demonstrate the challenges of WGC. We think WGC enrichs the partially\nobservable multi-agent cooperation domain and introduces more challenges that\nbetter reflect the real-world characteristics. Code is release in\nhttp://turingai.ia.ac.cn/data\\_center/show/10.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08394v1"
    },
    {
        "title": "Multi-Cluster Aggregative Games: A Linearly Convergent Nash Equilibrium\n  Seeking Algorithm and its Applications in Energy Management",
        "authors": [
            "Yue Chen",
            "Peng Yi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We propose a type of non-cooperative game, termed multi-cluster aggregative\ngame, which is composed of clusters as players, where each cluster consists of\ncollaborative agents with cost functions depending on their own decisions and\nthe aggregate quantity of each participant cluster to modeling large-scale and\nhierarchical multi-agent systems. This novel game model is motivated by\ndecision-making problems in competitive-cooperative network systems with\nlarge-scale nodes, such as the Energy Internet. To address challenges arising\nin seeking Nash equilibrium for such network systems, we develop an algorithm\nwith a hierarchical communication topology which is a hybrid with distributed\nand semi-decentralized protocols. The upper level consists of cluster\ncoordinators estimating the aggregate quantities with local communications,\nwhile the lower level is cluster subnets composed of its coordinator and agents\naiming to track the gradient of the corresponding cluster. In particular, the\nclusters exchange the aggregate quantities instead of their decisions to\nrelieve the burden of communication. Under strongly monotone and mildly\nLipschitz continuous assumptions, we rigorously prove that the algorithm\nlinearly converges to a Nash equilibrium with a fixed step size.We present the\napplications in the context of the Energy Internet. Furthermore, the numerical\nresults verify the effectiveness of the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08802v1"
    },
    {
        "title": "Exploration of unknown indoor regions by a swarm of energy-constrained\n  drones",
        "authors": [
            "Ori Rappel",
            "Joseph Z. Ben-Asher",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Several distributed algorithms are presented for the exploration of unknown\nindoor regions by a swarm of flying, energy constrained agents. The agents,\nwhich are identical, autonomous, anonymous and oblivious, uniformly cover the\nregion and thus explore it using predefined action rules based on locally\nsensed information and the energy level of the agents. While flying drones have\nmany advantages in search and rescue scenarios, their main drawback is a high\npower consumption during flight combined with limited, on-board energy.\nFurthermore, in these scenarios agent size is severely limited and consequently\nso are the total weight and capabilities of the agents. The region is modeled\nas a connected sub-set of a regular grid composed of square cells that the\nagents enter, over time, via entry points. Some of the agents may settle in\nunoccupied cells as the exploration progresses. Settled agents conserve energy\nand become virtual pheromones for the exploration and coverage process, beacons\nthat subsequently aid the remaining, and still exploring, mobile agents. The\ntermination of the coverage process is based on a backward propagating\ninformation diffusion scheme. Various algorithmical alternatives are discussed\nand upper bounds derived and compared to experimental results. Finally, an\noptimal entry rate that minimizes the total energy consumption is derived for\nthe case of a linear regions.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08957v1"
    },
    {
        "title": "Deliberation and Voting in Approval-Based Multi-Winner Elections",
        "authors": [
            "Kanav Mehra",
            "Nanda Kishore Sreenivas",
            "Kate Larson"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Citizen-focused democratic processes where participants deliberate on\nalternatives and then vote to make the final decision are increasingly popular\ntoday. While the computational social choice literature has extensively\ninvestigated voting rules, there is limited work that explicitly looks at the\ninterplay of the deliberative process and voting. In this paper, we build a\ndeliberation model using established models from the opinion-dynamics\nliterature and study the effect of different deliberation mechanisms on voting\noutcomes achieved when using well-studied voting rules. Our results show that\ndeliberation generally improves welfare and representation guarantees, but the\nresults are sensitive to how the deliberation process is organized. We also\nshow, experimentally, that simple voting rules, such as approval voting,\nperform as well as more sophisticated rules such as proportional approval\nvoting or method of equal shares if deliberation is properly supported. This\nhas ramifications on the practical use of such voting rules in citizen-focused\ndemocratic processes.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.08970v1"
    },
    {
        "title": "Synthesizing Resilient Strategies for Infinite-Horizon Objectives in\n  Multi-Agent Systems",
        "authors": [
            "David Klaška",
            "Antonín Kučera",
            "Martin Kurečka",
            "Vít Musil",
            "Petr Novotný",
            "Vojtěch Řehák"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We consider the problem of synthesizing resilient and stochastically stable\nstrategies for systems of cooperating agents striving to minimize the expected\ntime between consecutive visits to selected locations in a known environment. A\nstrategy profile is resilient if it retains its functionality even if some of\nthe agents fail, and stochastically stable if the visiting time variance is\nsmall. We design a novel specification language for objectives involving\nresilience and stochastic stability, and we show how to efficiently compute\nstrategy profiles (for both autonomous and coordinated agents) optimizing these\nobjectives. Our experiments show that our strategy synthesis algorithm can\nconstruct highly non-trivial and efficient strategy profiles for environments\nwith general topology.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.10070v1"
    },
    {
        "title": "Developing Multi-Agent Systems with Degrees of Neuro-Symbolic\n  Integration [A Position Paper]",
        "authors": [
            "Louise Dennis",
            "Marie Farrell",
            "Michael Fisher"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this short position paper we highlight our ongoing work on verifiable\nheterogeneous multi-agent systems and, in particular, the complex (and often\nnon-functional) issues that impact the choice of structure within each agent.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11534v1"
    },
    {
        "title": "Spatial community structure impedes language amalgamation in a\n  population-based iterated learning model",
        "authors": [
            "George Sains",
            "Conor Houghton",
            "Seth Bullock"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The iterated learning model is an agent-based model of language evolution\nnotable for demonstrating the emergence of compositional language. In its\noriginal form, it modelled language evolution along a single chain of\nteacher-pupil interactions; here we modify the model to allow more complex\npatterns of communication within a population and use the extended model to\nquantify the effect of within-community and between-community communication\nfrequency on language development. We find that a small amount of\nbetween-community communication can lead to population-wide language\nconvergence but that this global language amalgamation is more difficult to\nachieve when communities are spatially embedded.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11962v1"
    },
    {
        "title": "Towards Efficient Multi-Agent Learning Systems",
        "authors": [
            "Kailash Gogineni",
            "Peng Wei",
            "Tian Lan",
            "Guru Venkataramani"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) is an increasingly important\nresearch field that can model and control multiple large-scale autonomous\nsystems. Despite its achievements, existing multi-agent learning methods\ntypically involve expensive computations in terms of training time and power\narising from large observation-action space and a huge number of training\nsteps. Therefore, a key challenge is understanding and characterizing the\ncomputationally intensive functions in several popular classes of MARL\nalgorithms during their training phases. Our preliminary experiments reveal new\ninsights into the key modules of MARL algorithms that limit the adoption of\nMARL in real-world systems. We explore neighbor sampling strategy to improve\ncache locality and observe performance improvement ranging from 26.66% (3\nagents) to 27.39% (12 agents) during the computationally intensive mini-batch\nsampling phase. Additionally, we demonstrate that improving the locality leads\nto an end-to-end training time reduction of 10.2% (for 12 agents) compared to\nexisting multi-agent algorithms without significant degradation in the mean\nreward.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13411v2"
    },
    {
        "title": "An Ising-like model for language evolution",
        "authors": [
            "Conor Houghton"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  I propose a novel Ising-like model of language evolution. In a simple way,\nIsing-like models represent the countervailing tendencies towards convergence\nand change present in language evolution. In the ordinary Ising-model, a node\non a graph, in this case representing a language speaker, interacts with all\nits neighbors. In contrast, in the model proposed here, a node only interacts\nwith the neighboring node whose state-vector is most similar to its own. This\nreflects the tendency of people to interact with others who speak a similar\nlanguage. Unlike the ordinary Ising model, which tends towards language\ncontinua, this new model allows language boundaries.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13916v1"
    },
    {
        "title": "Feasible Action-Space Reduction as a Metric of Causal Responsibility in\n  Multi-Agent Spatial Interactions",
        "authors": [
            "Ashwin George",
            "Luciano Cavalcante Siebert",
            "David Abbink",
            "Arkady Zgonnikov"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Modelling causal responsibility in multi-agent spatial interactions is\ncrucial for safety and efficiency of interactions of humans with autonomous\nagents. However, current formal metrics and models of responsibility either\nlack grounding in ethical and philosophical concepts of responsibility, or\ncannot be applied to spatial interactions. In this work we propose a metric of\ncausal responsibility which is tailored to multi-agent spatial interactions,\nfor instance interactions in traffic. In such interactions, a given agent can,\nby reducing another agent's feasible action space, influence the latter.\nTherefore, we propose feasible action space reduction (FeAR) as a metric of\ncausal responsibility among agents. Specifically, we look at ex-post causal\nresponsibility for simultaneous actions. We propose the use of Moves de Rigueur\n(MdR) - a consistent set of prescribed actions for agents - to model the effect\nof norms on responsibility allocation. We apply the metric in a grid world\nsimulation for spatial interactions and show how the actions, contexts, and\nnorms affect the causal responsibility ascribed to agents. Finally, we\ndemonstrate the application of this metric in complex multi-agent interactions.\nWe argue that the FeAR metric is a step towards an interdisciplinary framework\nfor quantifying responsibility that is needed to ensure safety and meaningful\nhuman control in human-AI systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.15003v2"
    },
    {
        "title": "AccMER: Accelerating Multi-Agent Experience Replay with Cache\n  Locality-aware Prioritization",
        "authors": [
            "Kailash Gogineni",
            "Yongsheng Mei",
            "Peng Wei",
            "Tian Lan",
            "Guru Venkataramani"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-Agent Experience Replay (MER) is a key component of off-policy\nreinforcement learning~(RL) algorithms. By remembering and reusing experiences\nfrom the past, experience replay significantly improves the stability of RL\nalgorithms and their learning efficiency. In many scenarios, multiple agents\ninteract in a shared environment during online training under centralized\ntraining and decentralized execution~(CTDE) paradigm. Current multi-agent\nreinforcement learning~(MARL) algorithms consider experience replay with\nuniform sampling or based on priority weights to improve transition data sample\nefficiency in the sampling phase. However, moving transition data histories for\neach agent through the processor memory hierarchy is a performance limiter.\nAlso, as the agents' transitions continuously renew every iteration, the finite\ncache capacity results in increased cache misses.\n  To this end, we propose \\name, that repeatedly reuses the\ntransitions~(experiences) for a window of $n$ steps in order to improve the\ncache locality and minimize the transition data movement, instead of sampling\nnew transitions at each step. Specifically, our optimization uses priority\nweights to select the transitions so that only high-priority transitions will\nbe reused frequently, thereby improving the cache performance. Our experimental\nresults on the Predator-Prey environment demonstrate the effectiveness of\nreusing the essential transitions based on the priority weights, where we\nobserve an end-to-end training time reduction of $25.4\\%$~(for $32$ agents)\ncompared to existing prioritized MER algorithms without notable degradation in\nthe mean reward.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.00187v1"
    },
    {
        "title": "The Benefits of Interaction Constraints in Distributed Autonomous\n  Systems",
        "authors": [
            "Michael Crosscombe",
            "Jonathan Lawry"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The design of distributed autonomous systems often omits consideration of the\nunderlying network dynamics. Recent works in multi-agent systems and swarm\nrobotics alike have highlighted the impact that the interactions between agents\nhave on the collective behaviours exhibited by the system. In this paper, we\nseek to highlight the role that the underlying interaction network plays in\ndetermining the performance of the collective behaviour of a system, comparing\nits impact with that of the physical network. We contextualise this by defining\na collective learning problem in which agents must reach a consensus about\ntheir environment in the presence of noisy information. We show that the\nphysical connectivity of the agents plays a less important role than when an\ninteraction network of limited connectivity is imposed on the system to\nconstrain agent communication. Constraining agent interactions in this way\ndrastically improves the performance of the system in a collective learning\ncontext. Additionally, we provide further evidence for the idea that `less is\nmore' when it comes to propagating information in distributed autonomous\nsystems for the purpose of collective learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.01179v1"
    },
    {
        "title": "Distributed Flocking Control of Aerial Vehicles Based on a Markov Random\n  Field",
        "authors": [
            "Guobin Zhu",
            "Shanwei Fan",
            "Qingrui Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The distributed flocking control of collective aerial vehicles has\nextraordinary advantages in scalability and reliability, \\emph{etc.} However,\nit is still challenging to design a reliable, efficient, and responsive\nflocking algorithm. In this paper, a distributed predictive flocking framework\nis presented based on a Markov random field (MRF). The MRF is used to\ncharacterize the optimization problem that is eventually resolved by\ndiscretizing the input space. Potential functions are employed to describe the\ninteractions between aerial vehicles and as indicators of flight performance.\nThe dynamic constraints are taken into account in the candidate feasible\ntrajectories which correspond to random variables. Numerical simulation shows\nthat compared with some existing latest methods, the proposed algorithm has\nbetter-flocking cohesion and control efficiency performances. Experiments are\nalso conducted to demonstrate the feasibility of the proposed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.03505v1"
    },
    {
        "title": "Multi-agent Exploration with Sub-state Entropy Estimation",
        "authors": [
            "Jian Tao",
            "Yang Zhang",
            "Yangkun Chen",
            "Xiu Li"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Researchers have integrated exploration techniques into multi-agent\nreinforcement learning (MARL) algorithms, drawing on their remarkable success\nin deep reinforcement learning. Nonetheless, exploration in MARL presents a\nmore substantial challenge, as agents need to coordinate their efforts in order\nto achieve comprehensive state coverage. Reaching a unanimous agreement on\nwhich kinds of states warrant exploring can be a struggle for agents in this\ncontext. We introduce \\textbf{M}ulti-agent \\textbf{E}xploration based on\n\\textbf{S}ub-state \\textbf{E}ntropy (MESE) to address this limitation. This\nnovel approach incentivizes agents to explore states cooperatively by directing\nthem to achieve consensus via an extra team reward. Calculating the additional\nreward is based on the novelty of the current sub-state that merits cooperative\nexploration. MESE employs a conditioned entropy approach to select the\nsub-state, using particle-based entropy estimation to calculate the entropy.\nMESE is a plug-and-play module that can be seamlessly integrated into most\nexisting MARL algorithms, which makes it a highly effective tool for\nreinforcement learning. Our experiments demonstrate that MESE can substantially\nimprove the MAPPO's performance on various tasks in the StarCraft multi-agent\nchallenge (SMAC).\n",
        "pdf_link": "http://arxiv.org/pdf/2306.06382v1"
    },
    {
        "title": "Herd's Eye View: Improving Game AI Agent Learning with Collaborative\n  Perception",
        "authors": [
            "Andrew Nash",
            "Andrew Vardy",
            "David Churchill"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We present a novel perception model named Herd's Eye View (HEV) that adopts a\nglobal perspective derived from multiple agents to boost the decision-making\ncapabilities of reinforcement learning (RL) agents in multi-agent environments,\nspecifically in the context of game AI. The HEV approach utilizes cooperative\nperception to empower RL agents with a global reasoning ability, enhancing\ntheir decision-making. We demonstrate the effectiveness of the HEV within\nsimulated game environments and highlight its superior performance compared to\ntraditional ego-centric perception models. This work contributes to cooperative\nperception and multi-agent reinforcement learning by offering a more realistic\nand efficient perspective for global coordination and decision-making within\ngame environments. Moreover, our approach promotes broader AI applications\nbeyond gaming by addressing constraints faced by AI in other fields such as\nrobotics. The code is available at https://github.com/andrewnash/Herds-Eye-View\n",
        "pdf_link": "http://arxiv.org/pdf/2306.06544v2"
    },
    {
        "title": "Controlling Type Confounding in Ad Hoc Teamwork with Instance-wise\n  Teammate Feedback Rectification",
        "authors": [
            "Dong Xing",
            "Pengjie Gu",
            "Qian Zheng",
            "Xinrun Wang",
            "Shanqi Liu",
            "Longtao Zheng",
            "Bo An",
            "Gang Pan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Ad hoc teamwork requires an agent to cooperate with unknown teammates without\nprior coordination. Many works propose to abstract teammate instances into\nhigh-level representation of types and then pre-train the best response for\neach type. However, most of them do not consider the distribution of teammate\ninstances within a type. This could expose the agent to the hidden risk of\n\\emph{type confounding}. In the worst case, the best response for an abstract\nteammate type could be the worst response for all specific instances of that\ntype. This work addresses the issue from the lens of causal inference. We first\ntheoretically demonstrate that this phenomenon is due to the spurious\ncorrelation brought by uncontrolled teammate distribution. Then, we propose our\nsolution, CTCAT, which disentangles such correlation through an instance-wise\nteammate feedback rectification. This operation reweights the interaction of\nteammate instances within a shared type to reduce the influence of type\nconfounding. The effect of CTCAT is evaluated in multiple domains, including\nclassic ad hoc teamwork tasks and real-world scenarios. Results show that CTCAT\nis robust to the influence of type confounding, a practical issue that directly\nhazards the robustness of our trained agents but was unnoticed in previous\nworks.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.10944v1"
    },
    {
        "title": "The Effect of Noise on the Emergence of Continuous Norms and its\n  Evolutionary Dynamics",
        "authors": [
            "Stavros Anagnou",
            "Daniel Polani",
            "Christoph Salge"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We examine the effect of noise on societies of agents using an agent-based\nmodel of evolutionary norm emergence. Generally, we see that noisy societies\nare more selfish, smaller and discontent, and are caught in rounds of perpetual\npunishment preventing them from flourishing. Surprisingly, despite the effect\nof noise on the population, it does not seem to evolve away. We carry out\nfurther analysis and provide reasons for why this may be the case. Furthermore,\nwe claim that our framework that evolves the noise/ambiguity of norms may be a\nnew way to model the tight/loose framework of norms, suggesting that despite\nambiguous norms detrimental effect on society, evolution does not favour\nclarity.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.12345v2"
    },
    {
        "title": "One-Shot Traffic Assignment with Forward-Looking Penalization",
        "authors": [
            "Giuliano Cornacchia",
            "Mirco Nanni",
            "Luca Pappalardo"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Traffic assignment (TA) is crucial in optimizing transportation systems and\nconsists in efficiently assigning routes to a collection of trips. Existing TA\nalgorithms often do not adequately consider real-time traffic conditions,\nresulting in inefficient route assignments. This paper introduces METIS, a\ncooperative, one-shot TA algorithm that combines alternative routing with edge\npenalization and informed route scoring. We conduct experiments in several\ncities to evaluate the performance of METIS against state-of-the-art one-shot\nmethods. Compared to the best baseline, METIS significantly reduces CO2\nemissions by 18% in Milan, 28\\% in Florence, and 46% in Rome, improving trip\ndistribution considerably while still having low computational time. Our study\nproposes METIS as a promising solution for optimizing TA and urban\ntransportation systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.13704v1"
    },
    {
        "title": "TVDO: Tchebycheff Value-Decomposition Optimization for Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Xiaoliang Hu",
            "Pengcheng Guo",
            "Chuanwei Zhou",
            "Tong Zhang",
            "Zhen Cui"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In cooperative multi-agent reinforcement learning (MARL) settings, the\ncentralized training with decentralized execution (CTDE) becomes customary\nrecently due to the physical demand. However, the most dilemma is the\ninconsistency of jointly-trained policies and individually-optimized actions.\nIn this work, we propose a novel value-based multi-objective learning approach,\nnamed Tchebycheff value decomposition optimization (TVDO), to overcome the\nabove dilemma. In particular, a nonlinear Tchebycheff aggregation method is\ndesigned to transform the MARL task into multi-objective optimal counterpart by\ntightly constraining the upper bound of individual action-value bias. We\ntheoretically prove that TVDO well satisfies the necessary and sufficient\ncondition of individual global max (IGM) with no extra limitations, which\nexactly guarantees the consistency between the global and individual optimal\naction-value function. Empirically, in the climb and penalty game, we verify\nthat TVDO represents precisely from global to individual value factorization\nwith a guarantee of the policy consistency. Furthermore, we also evaluate TVDO\nin the challenging scenarios of StarCraft II micromanagement tasks, and\nextensive experiments demonstrate that TVDO achieves more competitive\nperformances than several state-of-the-art MARL methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.13979v1"
    },
    {
        "title": "Multi-Agent Cooperation via Unsupervised Learning of Joint Intentions",
        "authors": [
            "Shanqi Liu",
            "Weiwei Liu",
            "Wenzhou Chen",
            "Guanzhong Tian",
            "Yong Liu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The field of cooperative multi-agent reinforcement learning (MARL) has seen\nwidespread use in addressing complex coordination tasks. While value\ndecomposition methods in MARL have been popular, they have limitations in\nsolving tasks with non-monotonic returns, restricting their general\napplication. Our work highlights the significance of joint intentions in\ncooperation, which can overcome non-monotonic problems and increase the\ninterpretability of the learning process. To this end, we present a novel MARL\nmethod that leverages learnable joint intentions. Our method employs a\nhierarchical framework consisting of a joint intention policy and a behavior\npolicy to formulate the optimal cooperative policy. The joint intentions are\nautonomously learned in a latent space through unsupervised learning and enable\nthe method adaptable to different agent configurations. Our results demonstrate\nsignificant performance improvements in both the StarCraft micromanagement\nbenchmark and challenging MAgent domains, showcasing the effectiveness of our\nmethod in learning meaningful joint intentions.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.02200v1"
    },
    {
        "title": "Wireless Multi-Agent Generative AI: From Connected Intelligence to\n  Collective Intelligence",
        "authors": [
            "Hang Zou",
            "Qiyang Zhao",
            "Lina Bariah",
            "Mehdi Bennis",
            "Merouane Debbah"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The convergence of generative large language models (LLMs), edge networks,\nand multi-agent systems represents a groundbreaking synergy that holds immense\npromise for future wireless generations, harnessing the power of collective\nintelligence and paving the way for self-governed networks where intelligent\ndecision-making happens right at the edge. This article puts the stepping-stone\nfor incorporating multi-agent generative artificial intelligence (AI) in\nwireless networks, and sets the scene for realizing on-device LLMs, where\nmulti-agent LLMs are collaboratively planning and solving tasks to achieve a\nnumber of network goals. We further investigate the profound limitations of\ncloud-based LLMs, and explore multi-agent LLMs from a game theoretic\nperspective, where agents collaboratively solve tasks in competitive\nenvironments. Moreover, we establish the underpinnings for the architecture\ndesign of wireless multi-agent generative AI systems at the network level and\nthe agent level, and we identify the wireless technologies that are envisioned\nto play a key role in enabling on-device LLM. To demonstrate the promising\npotentials of wireless multi-agent generative AI networks, we highlight the\nbenefits that can be achieved when implementing wireless generative agents in\nintent-based networking, and we provide a case study to showcase how on-device\nLLMs can contribute to solving network intents in a collaborative fashion. We\nfinally shed lights on potential challenges and sketch a research roadmap\ntowards realizing the vision of wireless collective intelligence.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.02757v1"
    },
    {
        "title": "Sensor Allocation and Online-Learning-based Path Planning for Maritime\n  Situational Awareness Enhancement: A Multi-Agent Approach",
        "authors": [
            "Bach Long Nguyen",
            "Anh-Dzung Doan",
            "Tat-Jun Chin",
            "Christophe Guettier",
            "Surabhi Gupta",
            "Estelle Parra",
            "Ian Reid",
            "Markus Wagner"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Countries with access to large bodies of water often aim to protect their\nmaritime transport by employing maritime surveillance systems. However, the\nnumber of available sensors (e.g., cameras) is typically small compared to the\nto-be-monitored targets, and their Field of View (FOV) and range are often\nlimited. This makes improving the situational awareness of maritime transports\nchallenging. To this end, we propose a method that not only distributes\nmultiple sensors but also plans paths for them to observe multiple targets,\nwhile minimizing the time needed to achieve situational awareness. In\nparticular, we provide a formulation of this sensor allocation and path\nplanning problem which considers the partial awareness of the targets' state,\nas well as the unawareness of the targets' trajectories. To solve the problem\nwe present two algorithms: 1) a greedy algorithm for assigning sensors to\ntargets, and 2) a distributed multi-agent path planning algorithm based on\nregret-matching learning. Because a quick convergence is a requirement for\nalgorithms developed for high mobility environments, we employ a forgetting\nfactor to quickly converge to correlated equilibrium solutions. Experimental\nresults show that our combined approach achieves situational awareness more\nquickly than related work.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.02790v2"
    },
    {
        "title": "Collision Detection for Multi-Robot Motion Planning with Efficient\n  Quad-Tree Update and Skipping",
        "authors": [
            "Abdel Zaro",
            "Ardalan Tajbakhsh",
            "Aaron M. Johnson"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper presents a novel and efficient collision checking approach called\nUpdating and Collision Check Skipping Quad-tree (USQ) for multi-robot motion\nplanning. USQ extends the standard quad-tree data structure through a\ntime-efficient update mechanism, which significantly reduces the total number\nof collision checks and the collision checking time. In addition, it handles\ntransitions at the quad-tree quadrant boundaries based on worst-case\ntrajectories of agents. These extensions make quad-trees suitable for efficient\ncollision checking in multi-robot motion planning of large robot teams. We\nevaluate the efficiency of USQ in comparison with Regenerating Quad-tree (RQ)\nfrom scratch at each timestep and naive pairwise collision checking across a\nvariety of randomized environments. The results indicate that USQ significantly\nreduces the number of collision checks and the collision checking time compared\nto other baselines for different numbers of robots and map sizes. In a 50-robot\nexperiment, USQ accurately detected all collisions, outperforming RQ which has\nlonger run-times and/or misses up to 25% of collisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.07602v1"
    },
    {
        "title": "Practical Model Reductions for Verification of Multi-Agent Systems",
        "authors": [
            "Wojciech Jamroga",
            "Yan Kim"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Formal verification of intelligent agents is often computationally infeasible\ndue to state-space explosion. We present a tool for reducing the impact of the\nexplosion by means of state abstraction that is (a) easy to use and understand\nby non-experts, and (b) agent-based in the sense that it operates on a modular\nrepresentation of the system, rather than on its huge explicit state model.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.10068v2"
    },
    {
        "title": "An algorithm with improved complexity for pebble motion/multi-agent path\n  finding on trees",
        "authors": [
            "Stefano Ardizzoni",
            "Irene Saccani",
            "Luca Consolini",
            "Marco Locatelli",
            "Bernhard Nebel"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The pebble motion on trees (PMT) problem consists in finding a feasible\nsequence of moves that repositions a set of pebbles to assigned target\nvertices. This problem has been widely studied because, in many cases, the more\ngeneral Multi-Agent path finding (MAPF) problem on graphs can be reduced to\nPMT.\n  We propose a simple and easy to implement procedure, which finds solutions of\nlength O(knc + n^2), where n is the number of nodes, $k$ is the number of\npebbles, and c the maximum length of corridors in the tree. This complexity\nresult is more detailed than the current best known result O(n^3), which is\nequal to our result in the worst case, but does not capture the dependency on c\nand k.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12770v1"
    },
    {
        "title": "Deep Calibration of Multi-Agent Model for Simulating Real-World Stock\n  Trading",
        "authors": [
            "Tianlang He",
            "Keyan Lu",
            "Xianfeng Jiao",
            "Tianfan Xu",
            "Chang Xu",
            "Yang Liu",
            "Weiqing Liu",
            "S. -H. Gary Chan",
            "Jiang Bian"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent market model is a stock trading simulation system, which\ngenerates order flow given the agent variable of the model. We study\ncalibrating the agent variable to simulate the order flow of any given\nhistorical trading day. In contrast to the traditional calibration that relies\non the inefficient iterative search, we propose DeepCal, the first search-free\napproach that uses deep learning to calibrate multi-agent market model. DeepCal\nlearns from a novel surrogate-trading loss function to address the\nnon-differentiable issue induced by the multi-agent model and introduces a\ncondition-aware variable estimator, adapting the trading simulation to\ndifferent market conditions to enhance explainability. Through extensive\nexperiments on real order-book data over a whole year, DeepCal has demonstrated\ncomparable simulation accuracy (<0.36 in Kolmogorov-Smirnov statistic) to\ntraditional search-based approaches without the need for variable search, and\ncan effectively capture the correlation between agent variable and multiple\nmarket-condition indexes~(PPI, PMI, CPI, market trend and market noise).\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12987v2"
    },
    {
        "title": "Using Multi-Agent MicroServices (MAMS) for Agent Based Modelling",
        "authors": [
            "Martynas Jagutis",
            "Sean Russell",
            "Rem Collier"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper demonstrates the use of the Multi-Agent MicroServices (MAMS)\narchitectural style through a case study based around the development of a\nprototype traffic simulation in which agents model a population of individuals\nwho travel from home to work and vice versa by car.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.14745v1"
    },
    {
        "title": "MatrixWorld: A pursuit-evasion platform for safe multi-agent\n  coordination and autocurricula",
        "authors": [
            "Lijun Sun",
            "Yu-Cheng Chang",
            "Chao Lyu",
            "Chin-Teng Lin",
            "Yuhui Shi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent reinforcement learning (MARL) achieves encouraging performance in\nsolving complex tasks. However, the safety of MARL policies is one critical\nconcern that impedes their real-world applications. Popular multi-agent\nbenchmarks focus on diverse tasks yet provide limited safety support.\nTherefore, this work proposes a safety-constrained multi-agent environment:\nMatrixWorld, based on the general pursuit-evasion game. Particularly, a\nsafety-constrained multi-agent action execution model is proposed for the\nsoftware implementation of safe multi-agent environments based on diverse\nsafety definitions. It (1) extends the vertex conflict among homogeneous /\ncooperative agents to heterogeneous / adversarial settings, and (2) proposes\nthree types of resolutions for each type of conflict, aiming at providing\nrational and unbiased feedback for safe MARL. Besides, MatrixWorld is also a\nlightweight co-evolution framework for the learning of pursuit tasks, evasion\ntasks, or both, where more pursuit-evasion variants can be designed based on\ndifferent practical meanings of safety. As a brief survey, we review and\nanalyze the co-evolution mechanism in the multi-agent setting, which clearly\nreveals its relationships with autocurricula, self-play, arms races, and\nadversarial learning. Thus, MatrixWorld can also serve as the first environment\nfor autocurricula research, where ideas can be quickly verified and well\nunderstood.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.14854v2"
    },
    {
        "title": "Learning to Collaborate by Grouping: a Consensus-oriented Strategy for\n  Multi-agent Reinforcement Learning",
        "authors": [
            "Jingqing Ruan",
            "Xiaotian Hao",
            "Dong Li",
            "Hangyu Mao"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent systems require effective coordination between groups and\nindividuals to achieve common goals. However, current multi-agent reinforcement\nlearning (MARL) methods primarily focus on improving individual policies and do\nnot adequately address group-level policies, which leads to weak cooperation.\nTo address this issue, we propose a novel Consensus-oriented Strategy (CoS)\nthat emphasizes group and individual policies simultaneously. Specifically, CoS\ncomprises two main components: (a) the vector quantized group consensus module,\nwhich extracts discrete latent embeddings that represent the stable and\ndiscriminative group consensus, and (b) the group consensus-oriented strategy,\nwhich integrates the group policy using a hypernet and the individual policies\nusing the group consensus, thereby promoting coordination at both the group and\nindividual levels. Through empirical experiments on cooperative navigation\ntasks with both discrete and continuous spaces, as well as Google research\nfootball, we demonstrate that CoS outperforms state-of-the-art MARL algorithms\nand achieves better collaboration, thus providing a promising solution for\nachieving effective coordination in multi-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.15530v1"
    },
    {
        "title": "Integrated Private Data Trading Systems for Data Marketplaces",
        "authors": [
            "Weidong Li",
            "Mengxiao Zhang",
            "Libo Zhang",
            "Jiamou Liu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In the digital age, data is a valuable commodity, and data marketplaces offer\nlucrative opportunities for data owners to monetize their private data.\nHowever, data privacy is a significant concern, and differential privacy has\nbecome a popular solution to address this issue. Private data trading systems\n(PDQS) facilitate the trade of private data by determining which data owners to\npurchase data from, the amount of privacy purchased, and providing specific\naggregation statistics while protecting the privacy of data owners. However,\nexisting PDQS with separated procurement and query processes are prone to\nover-perturbation of private data and lack trustworthiness. To address this\nissue, this paper proposes a framework for PDQS with an integrated procurement\nand query process to avoid excessive perturbation of private data. We also\npresent two instances of this framework, one based on a greedy approach and\nanother based on a neural network. Our experimental results show that both of\nour mechanisms outperformed the separately conducted procurement and query\nmechanism under the same budget regarding accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.16317v1"
    },
    {
        "title": "BEAM: The Modeling Framework for Behavior, Energy, Autonomy & Mobility",
        "authors": [
            "Haitam Laarabi",
            "Zachary Needell",
            "Rashid Waraich",
            "Cristian Poliziani",
            "Tom Wenzel"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This report outlines the concepts, mechanisms and inner dynamics of the BEAM\n(Behavior, Energy, Autonomy, and Mobility) modeling framework. BEAM is an\nopen-source large-scale high-resolution transportation model that harnesses the\nprinciples of the actor model of computation to build a powerful and efficient\nagent-based model of travel behavior. It allows a detailed microscopic view of\nhow people make travel choices and interact with the transportation system,\nenabling more accurate simulations of human mobility and urban transport\nnetworks. It also allows the analysis of numerous spatially defined but\ninteracting layers, and integrates them into a cohesive representation of a\nregional transportation system. This integrated picture provides invaluable\ninsights to policy makers and other stakeholders about how changes to the\ntransportation system result in changes to traffic congestion, mode share,\nenergy use, and emissions throughout a modeled region. These capabilities are\ndemonstrated with a case study of New York City that showcase BEAM's\napplication in a very large and intricate urban transportation system, without\nrelying on existing travel demand models. The unique ability of BEAM to\nsimulate individual behaviors, integrate with other models, and adapt to\ndifferent real-world scenarios underscores its importance in the rapidly\nevolving field of transportation and emphasizes its potential as a valuable\nproof-of-concept tool to contribute to more informed and effective policy and\nplanning decisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.02073v1"
    },
    {
        "title": "Communication-Efficient Cooperative Multi-Agent PPO via Regulated\n  Segment Mixture in Internet of Vehicles",
        "authors": [
            "Xiaoxue Yu",
            "Rongpeng Li",
            "Fei Wang",
            "Chenghui Peng",
            "Chengchao Liang",
            "Zhifeng Zhao",
            "Honggang Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) has become a classic paradigm to\nsolve diverse, intelligent control tasks like autonomous driving in Internet of\nVehicles (IoV). However, the widely assumed existence of a central node to\nimplement centralized federated learning-assisted MARL might be impractical in\nhighly dynamic scenarios, and the excessive communication overheads possibly\noverwhelm the IoV system. Therefore, in this paper, we design a communication\nefficient cooperative MARL algorithm, named RSM-MAPPO, to reduce the\ncommunication overheads in a fully distributed architecture. In particular,\nRSM-MAPPO enhances the multi-agent Proximal Policy Optimization (PPO) by\nincorporating the idea of segment mixture and augmenting multiple model\nreplicas from received neighboring policy segments. Afterwards, RSM-MAPPO\nadopts a theory-guided metric to regulate the selection of contributive\nreplicas to guarantee the policy improvement. Finally, extensive simulations in\na mixed-autonomy traffic control scenario verify the effectiveness of the\nRSM-MAPPO algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.04198v1"
    },
    {
        "title": "Rafting Towards Consensus: Formation Control of Distributed Dynamical\n  Systems",
        "authors": [
            "Abbas Tariverdi",
            "Jim Torresen"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we introduce a novel adaptation of the Raft consensus\nalgorithm for achieving emergent formation control in multi-agent systems with\na single integrator dynamics. This strategy, dubbed \"Rafting,\" enables robust\ncooperation between distributed nodes, thereby facilitating the achievement of\ndesired geometric configurations. Our framework takes advantage of the Raft\nalgorithm's inherent fault tolerance and strong consistency guarantees to\nextend its applicability to distributed formation control tasks. Following the\nintroduction of a decentralized mechanism for aggregating agent states, a\nsynchronization protocol for information exchange and consensus formation is\nproposed. The Raft consensus algorithm combines leader election, log\nreplication, and state machine application to steer agents toward a common,\ncollaborative goal. A series of detailed simulations validate the efficacy and\nrobustness of our method under various conditions, including partial network\nfailures and disturbances. The outcomes demonstrate the algorithm's potential\nand open up new possibilities in swarm robotics, autonomous transportation, and\ndistributed computation. The implementation of the algorithms presented in this\npaper is available at https://github.com/abbas-tari/raft.git.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.10097v1"
    },
    {
        "title": "Capacity ATL",
        "authors": [
            "Gabriel Ballot",
            "Vadim Malvone",
            "Jean Leneutre",
            "Youssef Laarouchi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Model checking strategic abilities was successfully developed and applied\nsince the early 2000s to ensure properties in Multi-Agent System. In this\npaper, we introduce the notion of capacities giving different abilities to an\nagent. This applies naturally to systems where multiple entities can play the\nsame role in the game, such as different client versions in protocol analysis,\ndifferent robots in heterogeneous fleets, different personality traits in\nsocial structure modeling, or different attacker profiles in a cybersecurity\nsetting. With the capacity of other agents being unknown at the beginning of\nthe game, the longstanding problems of imperfect information arise. Our\ncontribution is the following: (i) we define a new class of concurrent game\nstructures where the agents have different capacities that modify their action\nlist and (ii) we introduce a logic extending Alternating-time Temporal Logic to\nreason about these games.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.11039v1"
    },
    {
        "title": "(Mis)align: A Simple Dynamic Framework for Modeling Interpersonal\n  Coordination",
        "authors": [
            "Grace Qiyuan Miao",
            "Rick Dale",
            "Alexia Galati"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  As people coordinate in daily interactions, they engage in different patterns\nof behavior to achieve successful outcomes. This includes both synchrony - the\ntemporal coordination of the same behaviors at the same time - and\ncomplementarity - the coordination of the same or different behaviors that may\noccur at different relative times. Using computational methods, we develop a\nsimple framework to describe the interpersonal dynamics of behavioral synchrony\nand complementarity over time, and explore their task dependence. A key feature\nof this framework is the inclusion of a task context that mediates\ninteractions, and consists of active, inactive, and inhibitory constraints on\ncommunication. Initial simulation results show that these task constraints can\nbe a robust predictor of simulated agents' behaviors over time. We also show\nthat the framework can reproduce some general patterns observed in human\ninteraction data. We describe preliminary theoretical implications from these\nresults, and relate them to broader proposals of synergistic self-organization\nin communication.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.15864v1"
    },
    {
        "title": "Trustworthy Distributed Average Consensus based on Locally Assessed\n  Trust Evaluations",
        "authors": [
            "Christoforos N. Hadjicostis",
            "Alejandro D. Dominguez-Garcia"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper proposes a distributed algorithm for average consensus in a\nmulti-agent system under a fixed bidirectional communication topology, in the\npresence of malicious agents (nodes) that may try to influence the average\nconsensus outcome by manipulating their updates. The proposed algorithm\nconverges asymptotically to the average of the initial values of the\nnon-malicious nodes, which we refer to as the trustworthy average, as long as\nthe underlying topology that describes the information exchange among the\nnon-malicious nodes is connected. We first present a distributed iterative\nalgorithm that assumes that each node receives (at each iteration or\nperiodically) side information about the trustworthiness of the other nodes,\nand it uses such trust assessments to determine whether or not to incorporate\nmessages received from its neighbors, as well as to make proper adjustments in\nits calculation depending on whether a previously trustworthy neighbor becomes\nuntrustworthy or vice-versa. We show that, as long as the trust assessments for\neach non-malicious node eventually reflect correctly the status (malicious or\nnon-malicious) of its neighboring nodes, the algorithm guarantees asymptotic\nconvergence to the trustworthy average. We subsequently discuss how the\nproposed algorithm can be enhanced with functionality that enables each node to\nobtain trust assessments about its neighbors by utilizing information that it\nreceives from its two-hop neighbors at infrequent, perhaps randomly chosen,\ntime instants.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.00920v1"
    },
    {
        "title": "Cooperative Filtering with Range Measurements: A Distributed Constrained\n  Zonotopic Method",
        "authors": [
            "Yu Ding",
            "Yirui Cong",
            "Xiangke Wang",
            "Long Cheng"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This article studies the distributed estimation problem of a multi-agent\nsystem with bounded absolute and relative range measurements. Parts of the\nagents are with high-accuracy absolute measurements, which are considered as\nanchors; the other agents utilize lowaccuracy absolute and relative range\nmeasurements, each derives an uncertain range that contains its true state in a\ndistributed manner. Different from previous studies, we design a distributed\nalgorithm to handle the range measurements based on extended constrained\nzonotopes, which has low computational complexity and high precision. With our\nproposed algorithm, agents can derive their uncertain range sequentially along\nthe chain topology, such that agents with low-accuracy sensors can benefit from\nthe high-accuracy absolute measurements of anchors and improve the estimation\nperformance. Simulation results corroborate the effectiveness of our proposed\nalgorithm and verify our method can significantly improve the estimation\naccuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.01185v1"
    },
    {
        "title": "A dynamic state-based model of crowds",
        "authors": [
            "Martyn Amos",
            "Steve Gwynne",
            "Anne Templeton"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We consider the problem of categorizing and describing the dynamic properties\nand behaviours of crowds over time. Previous work has tended to focus on a\nrelatively static \"typology\"-based approach, which does not account for the\nfact that crowds can change, often quite rapidly. Moreover, the labels attached\nto crowd behaviours are often subjective and/or value-laden. Here, we present\nan alternative approach, loosely based on the statechart formalism from\ncomputer science. This uses relatively \"agnostic\" labels, which means that we\ndo not prescribe the behaviour of an individual, but provide a context within\nwhich an individual might behave. This naturally describes the time-series\nevolution of a crowd as \"threads\" of states, and allows for the dynamic\nhandling of an arbitrary number of \"sub-crowds\".\n",
        "pdf_link": "http://arxiv.org/pdf/2309.01257v1"
    },
    {
        "title": "SHAPE: A Framework for Evaluating the Ethicality of Influence",
        "authors": [
            "Elfia Bezou-Vrakatseli",
            "Benedikt Brückner",
            "Luke Thorburn"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Agents often exert influence when interacting with humans and non-human\nagents. However, the ethical status of such influence is often unclear. In this\npaper, we present the SHAPE framework, which lists reasons why influence may be\nunethical. We draw on literature from descriptive and moral philosophy and\nconnect it to machine learning to help guide ethical considerations when\ndeveloping algorithms with potential influence. Lastly, we explore mechanisms\nfor governing algorithmic systems that influence people, inspired by mechanisms\nused in journalism, human subject research, and advertising.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.04352v2"
    },
    {
        "title": "Enhancing the Performance of Multi-Agent Reinforcement Learning for\n  Controlling HVAC Systems",
        "authors": [
            "Daniel Bayer",
            "Marco Pruckner"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Systems for heating, ventilation and air-conditioning (HVAC) of buildings are\ntraditionally controlled by a rule-based approach. In order to reduce the\nenergy consumption and the environmental impact of HVAC systems more advanced\ncontrol methods such as reinforcement learning are promising. Reinforcement\nlearning (RL) strategies offer a good alternative, as user feedback can be\nintegrated more easily and presence can also be incorporated. Moreover,\nmulti-agent RL approaches scale well and can be generalized. In this paper, we\npropose a multi-agent RL framework based on existing work that learns reducing\non one hand energy consumption by optimizing HVAC control and on the other hand\nuser feedback by occupants about uncomfortable room temperatures. Second, we\nshow how to reduce training time required for proper RL-agent-training by using\nparameter sharing between the multiple agents and apply different pretraining\ntechniques. Results show that our framework is capable of reducing the energy\nby around 6% when controlling a complete building or 8% for a single room zone.\nThe occupants complaints are acceptable or even better compared to a rule-based\nbaseline. Additionally, our performance analysis show that the training time\ncan be drastically reduced by using parameter sharing.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.06940v1"
    },
    {
        "title": "Logic of Awareness in Agent's Reasoning",
        "authors": [
            "Yudai Kubono",
            "Teeradaj Racharak",
            "Satoshi Tojo"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The aim of this study is to formally express awareness for modeling practical\nagent communication. The notion of awareness has been proposed as a set of\npropositions for each agent, to which he/she pays attention, and has\ncontributed to avoiding \\textit{logical omniscience}. However, when an agent\nguesses another agent's knowledge states, what matters are not propositions but\nare accessible possible worlds. Therefore, we introduce a partition of possible\nworlds connected to awareness, that is an equivalence relation, to denote\n\\textit{indistinguishable} worlds. Our logic is called Awareness Logic with\nPartition ($\\mathcal{ALP}$). In this paper, we first show a running example to\nillustrate a practical social game. Thereafter, we introduce syntax and Kripke\nsemantics of the logic and prove its completeness. Finally, we outline an idea\nto incorporate some epistemic actions with dynamic operators that change the\nstate of awareness.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.09214v3"
    },
    {
        "title": "Ontology-Based Feedback to Improve Runtime Control for Multi-Agent\n  Manufacturing Systems",
        "authors": [
            "Jonghan Lim",
            "Leander Pfeiffer",
            "Felix Ocker",
            "Birgit Vogel-Heuser",
            "Ilya Kovalenko"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Improving the overall equipment effectiveness (OEE) of machines on the shop\nfloor is crucial to ensure the productivity and efficiency of manufacturing\nsystems. To achieve the goal of increased OEE, there is a need to develop\nflexible runtime control strategies for the system. Decentralized strategies,\nsuch as multi-agent systems, have proven effective in improving system\nflexibility. However, runtime multi-agent control of complex manufacturing\nsystems can be challenging as the agents require extensive communication and\ncomputational efforts to coordinate agent activities. One way to improve\ncommunication speed and cooperation capabilities between system agents is by\nproviding a common language between these agents to represent knowledge about\nsystem behavior. The integration of ontology into multi-agent systems in\nmanufacturing provides agents with the capability to continuously update and\nrefine their knowledge in a global context. This paper contributes to the\ndesign of an ontology for multi-agent systems in manufacturing, introducing an\nextendable knowledge base and a methodology for continuously updating the\nproduction data by agents during runtime. To demonstrate the effectiveness of\nthe proposed framework, a case study is conducted in a simulated environment,\nwhich shows improvements in OEE during runtime.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10132v1"
    },
    {
        "title": "Game-theoretic Occlusion-Aware Motion Planning: an Efficient\n  Hybrid-Information Approach",
        "authors": [
            "Kushagra Gupta",
            "David Fridovich-Keil"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We present a novel algorithm for game-theoretic trajectory planning, tailored\nfor settings in which agents can only observe one another in specific regions\nof the state space. Such problems arise naturally in the context of multi-robot\nnavigation, where occlusions due to environment geometry naturally mask agents'\nview of one another. In this paper, we formalize these settings as dynamic\ngames with a hybrid information structure, which interleaves so-called\n\"open-loop\" periods (in which agents cannot observe one another) with\n\"feedback\" periods (with full state observability). We present two main\ncontributions. First, we study a canonical variant of these hybrid information\ngames in which agents' dynamics are linear, and objectives are convex and\nquadratic. Here, we build upon classical solution methods for the open-loop and\nfeedback variants of these games to derive an algorithm for the hybrid\ninformation case that matches the cubic runtime of the classical settings.\nSecond, we consider a far broader class of problems in which agents' dynamics\nare nonlinear, and objectives are nonquadratic; we reduce these problems to\nsequences of hybrid information linear-quadratic games and empirically\ndemonstrate that iteratively solving these simpler problems with the proposed\nalgorithm yields reliable convergence to approximate Nash equilibria through\nsimulation studies of overtaking and intersection traffic scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10901v2"
    },
    {
        "title": "Quantifying Feature Importance of Games and Strategies via Shapley\n  Values",
        "authors": [
            "Satoru Fujii"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Recent advances in game informatics have enabled us to find strong strategies\nacross a diverse range of games. However, these strategies are usually\ndifficult for humans to interpret. On the other hand, research in Explainable\nArtificial Intelligence (XAI) has seen a notable surge in scholarly activity.\nInterpreting strong or near-optimal strategies or the game itself can provide\nvaluable insights. In this paper, we propose two methods to quantify the\nfeature importance using Shapley values: one for the game itself and another\nfor individual AIs. We empirically show that our proposed methods yield\nintuitive explanations that resonate with and augment human understanding.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.11991v2"
    },
    {
        "title": "Learning to Coordinate with Anyone",
        "authors": [
            "Lei Yuan",
            "Lihe Li",
            "Ziqian Zhang",
            "Feng Chen",
            "Tianyi Zhang",
            "Cong Guan",
            "Yang Yu",
            "Zhi-Hua Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In open multi-agent environments, the agents may encounter unexpected\nteammates. Classical multi-agent learning approaches train agents that can only\ncoordinate with seen teammates. Recent studies attempted to generate diverse\nteammates to enhance the generalizable coordination ability, but were\nrestricted by pre-defined teammates. In this work, our aim is to train agents\nwith strong coordination ability by generating teammates that fully cover the\nteammate policy space, so that agents can coordinate with any teammates. Since\nthe teammate policy space is too huge to be enumerated, we find only dissimilar\nteammates that are incompatible with controllable agents, which highly reduces\nthe number of teammates that need to be trained with. However, it is hard to\ndetermine the number of such incompatible teammates beforehand. We therefore\nintroduce a continual multi-agent learning process, in which the agent learns\nto coordinate with different teammates until no more incompatible teammates can\nbe found. The above idea is implemented in the proposed Macop (Multi-agent\ncompatible policy learning) algorithm. We conduct experiments in 8 scenarios\nfrom 4 environments that have distinct coordination patterns. Experiments show\nthat Macop generates training teammates with much lower compatibility than\nprevious methods. As a result, in all scenarios Macop achieves the best overall\ncoordination ability while never significantly worse than the baselines,\nshowing strong generalization ability.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.12633v1"
    },
    {
        "title": "Multi-Agent Digital Twinning for Collaborative Logistics: Framework and\n  Implementation",
        "authors": [
            "Liming Xu",
            "Stephen Mak",
            "Stefan Schoepf",
            "Michael Ostroumov",
            "Alexandra Brintrup"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Collaborative logistics has been widely recognised as an effective avenue to\nreduce carbon emissions by enhanced truck utilisation and reduced travel\ndistance. However, stakeholders' participation in collaborations is hindered by\ninformation-sharing barriers and the absence of integrated systems. We, thus,\nin this paper addresses these barriers by investigating an integrated platform\nthat foster collaboration through the integration of agents with digital twins.\nSpecifically, we employ a multi-agent system approach to integrate stakeholders\nand physical mobile assets in collaborative logistics, representing them as\nagents. We introduce a loosely-coupled system architecture that facilitates the\nconnection between physical and digital systems, enabling the integration of\nagents with digital twins. Using this architecture, we implement the platform\n(or testbed). The resulting testbed, comprising a physical environment and a\ndigital replica, is a digital twin that integrates distributed entities\ninvolved in collaborative logistics. The effectiveness of the testbed is\ndemonstrated through a carrier collaboration scenario. This paper is among the\nearliest few efforts to investigate the integration of agents and digital twin\nconcepts and goes beyond the conceptual discussion of existing studies to the\ntechnical implementation of such integration.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.12781v2"
    },
    {
        "title": "Boosting Studies of Multi-Agent Reinforcement Learning on Google\n  Research Football Environment: the Past, Present, and Future",
        "authors": [
            "Yan Song",
            "He Jiang",
            "Haifeng Zhang",
            "Zheng Tian",
            "Weinan Zhang",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Even though Google Research Football (GRF) was initially benchmarked and\nstudied as a single-agent environment in its original paper, recent years have\nwitnessed an increasing focus on its multi-agent nature by researchers\nutilizing it as a testbed for Multi-Agent Reinforcement Learning (MARL).\nHowever, the absence of standardized environment settings and unified\nevaluation metrics for multi-agent scenarios hampers the consistent\nunderstanding of various studies. Furthermore, the challenging 5-vs-5 and\n11-vs-11 full-game scenarios have received limited thorough examination due to\ntheir substantial training complexities. To address these gaps, this paper\nextends the original environment by not only standardizing the environment\nsettings and benchmarking cooperative learning algorithms across different\nscenarios, including the most challenging full-game scenarios, but also by\ndiscussing approaches to enhance football AI from diverse perspectives and\nintroducing related research tools. Specifically, we provide a distributed and\nasynchronous population-based self-play framework with diverse pre-trained\npolicies for faster training, two football-specific analytical tools for deeper\ninvestigation, and an online leaderboard for broader evaluation. The overall\nexpectation of this work is to advance the study of Multi-Agent Reinforcement\nLearning on Google Research Football environment, with the ultimate goal of\nbenefiting real-world sports beyond virtual games.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.12951v1"
    },
    {
        "title": "Optimization on the smallest eigenvalue of grounded Laplacian matrix via\n  edge addition",
        "authors": [
            "Xiaotian Zhou",
            "Haoxin Sun",
            "Wei Li",
            "Zhongzhi Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The grounded Laplacian matrix $\\LL_{-S}$ of a graph $\\calG=(V,E)$ with\n$n=|V|$ nodes and $m=|E|$ edges is a $(n-s)\\times (n-s)$ submatrix of its\nLaplacian matrix $\\LL$, obtained from $\\LL$ by deleting rows and columns\ncorresponding to $s=|S| \\ll n $ ground nodes forming set $S\\subset V$. The\nsmallest eigenvalue of $\\LL_{-S}$ plays an important role in various practical\nscenarios, such as characterizing the convergence rate of leader-follower\nopinion dynamics, with a larger eigenvalue indicating faster convergence of\nopinion. In this paper, we study the problem of adding $k \\ll n$ edges among\nall the nonexistent edges forming the candidate edge set $Q = (V\\times\nV)\\backslash E$, in order to maximize the smallest eigenvalue of the grounded\nLaplacian matrix. We show that the objective function of the combinatorial\noptimization problem is monotone but non-submodular. To solve the problem, we\nfirst simplify the problem by restricting the candidate edge set $Q$ to be\n$(S\\times (V\\backslash S))\\backslash E$, and prove that it has the same optimal\nsolution as the original problem, although the size of set $Q$ is reduced from\n$O(n^2)$ to $O(n)$. Then, we propose two greedy approximation algorithms. One\nis a simple greedy algorithm with an approximation ratio\n$(1-e^{-\\alpha\\gamma})/\\alpha$ and time complexity $O(kn^4)$, where $\\gamma$\nand $\\alpha$ are, respectively, submodularity ratio and curvature, whose bounds\nare provided for some particular cases. The other is a fast greedy algorithm\nwithout approximation guarantee, which has a running time $\\tilde{O}(km)$,\nwhere $\\tilde{O}(\\cdot)$ suppresses the ${\\rm poly} (\\log n)$ factors. Numerous\nexperiments on various real networks are performed to validate the superiority\nof our algorithms, in terms of effectiveness and efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.17019v1"
    },
    {
        "title": "Network Preference Dynamics using Lattice Theory",
        "authors": [
            "Hans Riess",
            "Gregory Henselman-Petrusek",
            "Michael C. Munger",
            "Robert Ghrist",
            "Zachary I. Bell",
            "Michael M. Zavlanos"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Preferences, fundamental in all forms of strategic behavior and collective\ndecision-making, in their raw form, are an abstract ordering on a set of\nalternatives. Agents, we assume, revise their preferences as they gain more\ninformation about other agents. Exploiting the ordered algebraic structure of\npreferences, we introduce a message-passing algorithm for heterogeneous agents\ndistributed over a network to update their preferences based on aggregations of\nthe preferences of their neighbors in a graph. We demonstrate the existence of\nequilibrium points of the resulting global dynamical system of local preference\nupdates and provide a sufficient condition for trajectories to converge to\nequilibria: stable preferences. Finally, we present numerical simulations\ndemonstrating our preliminary results.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.00179v2"
    },
    {
        "title": "Ride Acceptance Behaviour Investigation of Ride-sourcing Drivers Through\n  Agent-based Simulation",
        "authors": [
            "Farnoud Ghasemi",
            "Peyman Ashkrof",
            "Rafal Kucharski"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Ride-sourcing platforms such as Uber and Lyft offer drivers (i.e., platform\nsuppliers) considerable freedom of choice in multiple aspects. At the\noperational level, drivers can freely accept or decline trip requests that can\nsignificantly impact system performance in terms of travellers' waiting time,\ndrivers' idle time and income. Despite the extensive research into the\nsupply-side operations, the behavioural aspects, particularly drivers' ride\nacceptance behaviour remains so far largely unknown. To this end, we reproduce\nthe dynamics of a two-sided mobility platform on the road network of Delft\nusing an agent-based simulator. Then, we implement a ride acceptance decision\nmodel enabling drivers to apply their acceptance strategies. Our findings\nreveal that drivers who follow the decision model, on average, earn higher\nincome compared to drivers who randomly accept trip requests. The overall\nincome equality between drivers with the acceptance decision is higher and\ntravellers experience lower waiting time in this setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.05588v1"
    },
    {
        "title": "A Blockchain-driven Architecture for Usage Control in Solid",
        "authors": [
            "Davide Basile",
            "Claudio Di Ciccio",
            "Valerio Goretti",
            "Sabrina Kirrane"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Decentralization initiatives like Solid enable data owners to control who has\naccess to their data and to stimulate innovation by creating both application\nand data markets. Once data owners share their data with others, though, it is\nno longer possible for them to control how their data are used. To address this\nissue, we propose a usage control architecture to monitor compliance with usage\ncontrol policies. To this end, our solution relies on blockchain and trusted\nexecution environments. We demonstrate the potential of the architecture by\ndescribing the various workflows needed to realize a motivating use case\nscenario for data markets. Additionally, we discuss the merits of the approach\nfrom privacy, security, integrateability, and affordability perspectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.05731v1"
    },
    {
        "title": "Transactive Multi-Agent Systems over Flow Networks",
        "authors": [
            "Yijun Chen",
            "Zeinab Salehi",
            "Elizabeth L. Ratnam",
            "Ian R. Petersen",
            "Guodong Shi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper presented insights into the implementation of transactive\nmulti-agent systems over flow networks where local resources are decentralized.\nAgents have local resource demand and supply, and are interconnected through a\nflow network to support the sharing of local resources while respecting\nrestricted sharing/flow capacity. We first establish a competitive market with\na pricing mechanism that internalizes flow capacity constraints into agents'\nprivate decisions. We then demonstrate through duality theory that competitive\nequilibrium and social welfare equilibrium exist and agree under convexity\nassumptions, indicating the efficiency of the pricing mechanism. Additionally,\na new social acceptance sharing problem is defined to investigate homogeneous\npricing when the optimal sharing prices at all agents under competitive\nequilibrium are always equal for social acceptance. A conceptual computation\nmethod is proposed, prescribing a class of socially admissible utility\nfunctions to solve the social acceptance problem. A special case of\nlinear-quadratic multi-agent systems over undirected star graphs is provided as\na pedagogical example of how to explicitly prescribe socially admissible\nutility functions. Finally, extensive experiments are provided to validate the\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.05942v1"
    },
    {
        "title": "Multi-Value Alignment in Normative Multi-Agent System: An Evolutionary\n  Optimisation Approach",
        "authors": [
            "Maha Riad",
            "Vinicius de Carvalho",
            "Fatemeh Golpayegani"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Value-alignment in normative multi-agent systems is used to promote a certain\nvalue and to ensure the consistent behaviour of agents in autonomous\nintelligent systems with human values. However, the current literature is\nlimited to the incorporation of effective norms for single-value alignment with\nno consideration of agents' heterogeneity and the requirement of simultaneous\npromotion and alignment of multiple values. This research proposes a\nmulti-value promotion model that uses multi-objective evolutionary algorithms\nand decentralised reasoning to produce the optimum parametric set of norms that\nis aligned with multiple simultaneous values of heterogeneous agents and the\nsystem. To understand various aspects of this complex problem, several\nevolutionary algorithms were used to find a set of optimised norm parameters\nconsidering two toy tax scenarios with two and five values are considered. The\nresults are analysed from different perspectives to show the impact of a\nselected evolutionary algorithm on the solution, and the importance of\nunderstanding the relation between values when prioritising them.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.08362v1"
    },
    {
        "title": "Community Consensus: Converging Locally despite Adversaries and\n  Heterogeneous Connectivity",
        "authors": [
            "Cristina Gava",
            "Aron Vekassy",
            "Matthew Cavorsi",
            "Stephanie Gil",
            "Frederik Mallmann-Trenn"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We introduce the concept of community consensus in the presence of malicious\nagents using a well-known median-based consensus algorithm. We consider\nnetworks that have multiple well-connected regions that we term communities,\ncharacterized by specific robustness and minimum degree properties. Prior work\nderives conditions on properties that are necessary and sufficient for\nachieving global consensus in a network. This, however, requires the minimum\ndegree of the network graph to be proportional to the number of malicious\nagents in the network, which is not very practical in large networks. In this\nwork, we present a natural generalization of this previous result. We\ncharacterize cases where, although global consensus is not reached, some\nsubsets of agents $V_i$ will still converge to the same values $M_i$ among\nthemselves. To reach this new type of consensus, we define more relaxed\nrequirements in terms of the number of malicious agents in each community, and\nthe number $k$ of edges connecting an agent in a community to agents external\nto the community.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.08488v2"
    },
    {
        "title": "On Implementing Autonomous Supply Chains: a Multi-Agent System Approach",
        "authors": [
            "Liming Xu",
            "Stephen Mak",
            "Maria Minaricova",
            "Alexandra Brintrup"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Trade restrictions, the COVID-19 pandemic, and geopolitical conflicts have\nsignificantly exposed vulnerabilities within traditional global supply chains.\nThese events underscore the need for organisations to establish more resilient\nand flexible supply chains. To address these challenges, the concept of the\nautonomous supply chain (ASC), characterised by predictive and\nself-decision-making capabilities, has recently emerged as a promising\nsolution. However, research on ASCs is relatively limited, with no existing\nstudies specifically focusing on their implementations. This paper aims to\naddress this gap by presenting an implementation of ASC using a multi-agent\napproach. It presents a methodology for the analysis and design of such an\nagent-based ASC system (A2SC). This paper provides a concrete case study, the\nautonomous meat supply chain, which showcases the practical implementation of\nthe A2SC system using the proposed methodology. Additionally, a system\narchitecture and a toolkit for developing such A2SC systems are presented.\nDespite limitations, this work demonstrates a promising approach for\nimplementing an effective ASC system.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09435v2"
    },
    {
        "title": "Crowd Modeling and Control via Cooperative Adaptive Filtering",
        "authors": [
            "Zirui Wan",
            "Saeid Sanei"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper introduces a crowd modeling and motion control approach that\nemploys diffusion adaptation within an adaptive network. In the network, nodes\ncollaboratively address specific estimation problems while simultaneously\nmoving as agents governed by certain motion control mechanisms. Our research\ndelves into the behaviors of agents when they encounter spatial constraints.\nWithin this framework, agents pursue several objectives, such as target\ntracking, coherent motion, and obstacle evasion. Throughout their navigation,\nthey demonstrate a nature of self-organization and self-adjustment that drives\nthem to maintain certain social distances with each other, and adaptively\nadjust their behaviors in response to the environmental changes. Our findings\nsuggest a promising approach to mitigate the spread of viral pandemics and\naverting stampedes.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09519v2"
    },
    {
        "title": "Stealthy Terrain-Aware Multi-Agent Active Search",
        "authors": [
            "Nikhil Angad Bakshi",
            "Jeff Schneider"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Stealthy multi-agent active search is the problem of making efficient\nsequential data-collection decisions to identify an unknown number of sparsely\nlocated targets while adapting to new sensing information and concealing the\nsearch agents' location from the targets. This problem is applicable to\nreconnaissance tasks wherein the safety of the search agents can be compromised\nas the targets may be adversarial. Prior work usually focuses either on\nadversarial search, where the risk of revealing the agents' location to the\ntargets is ignored or evasion strategies where efficient search is ignored. We\npresent the Stealthy Terrain-Aware Reconnaissance (STAR) algorithm, a\nmulti-objective parallelized Thompson sampling-based algorithm that relies on a\nstrong topographical prior to reason over changing visibility risk over the\ncourse of the search. The STAR algorithm outperforms existing state-of-the-art\nmulti-agent active search methods on both rate of recovery of targets as well\nas minimising risk even when subject to noisy observations, communication\nfailures and an unknown number of targets.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.10961v1"
    },
    {
        "title": "Cormas: The Software for Participatory Modelling and its Application for\n  Managing Natural Resources in Senegal",
        "authors": [
            "Oleksandr Zaitsev",
            "François Vendel",
            "Etienne Delay"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Cormas is an agent-based simulation platform developed in the late 90s by the\nGreen research at CIRAD unit to support the management of natural resources and\nunderstand the interactions between natural and social dynamics. This platform\nis well-suited for a participatory simulation approach that empowers local\nstakeholders by including them in all modelling and knowledge-sharing steps. In\nthis short paper, we present the Cormas platform and discuss its unique\nfeatures and their importance for the participatory simulation approach. We\nthen present the early results of our ongoing study on managing pastoral\nresources in the Sahel region, identify the problems faced by local\nstakeholders, and discuss the potential use of Cormas at the next stage of our\nstudy to collectively model and understand the effective ways of managing the\nshared agro-sylvo-pastoral resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.12534v1"
    },
    {
        "title": "Decentralized approaches for autonomous vehicles coordination",
        "authors": [
            "Luca Gherardini",
            "Giacomo Cabri",
            "Manuela Montangero"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The coordination of autonomous vehicles is an open field that is addressed by\ndifferent researches comprising many different techniques. In this paper we\nfocus on decentralized approaches able to provide adaptability to different\ninfrastructural and traffic conditions. We formalize an Emergent Behavior\nApproach that, as per our knowledge, has never been performed for this purpose,\nand a Decentralized Auction approach. We compare them against existing\ncentralized negotiation approaches based on auctions and we determine under\nwhich conditions each approach is preferable to the others.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.13346v1"
    },
    {
        "title": "Assume-Guarantee Verification of Strategic Ability",
        "authors": [
            "Łukasz Mikulski",
            "Wojciech Jamroga",
            "Damian Kurpiewski"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Model checking of strategic abilities is a notoriously hard problem, even\nmore so in the realistic case of agents with imperfect information.\nAssume-guarantee reasoning can be of great help here, providing a way to\ndecompose the complex problem into a small set of exponentially easier\nsubproblems. In this paper, we propose two schemes for assume-guarantee\nverification of alternating-time temporal logic with imperfect information. We\nprove the soundness of both schemes, and discuss their completeness. We\nillustrate the method by examples based on known benchmarks, and show\nexperimental results that demonstrate the practical benefits of the approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.15686v1"
    },
    {
        "title": "Agent-based models of social behaviour and communication in evacuations:\n  A systematic review",
        "authors": [
            "Anne Templeton",
            "Hui Xie",
            "Steve Gwynne",
            "Aoife Hunt",
            "Pete Thompson",
            "Gerta Köster"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Most modern agent-based evacuation models involve interactions between\nevacuees. However, the assumed reasons for interactions and portrayal of them\nmay be overly simple. Research from social psychology suggests that people\ninteract and communicate with one another when evacuating and evacuee response\nis impacted by the way information is communicated. Thus, we conducted a\nsystematic review of agent-based evacuation models to identify 1) how social\ninteractions and communication approaches between agents are simulated, and 2)\nwhat key variables related to evacuation are addressed in these models. We\nsearched Web of Science and ScienceDirect to identify articles that simulated\ninformation exchange between agents during evacuations, and social behaviour\nduring evacuations. From the final 70 included articles, we categorised eight\ntypes of social interaction that increased in social complexity from collision\navoidance to social influence based on strength of social connections with\nother agents. In the 17 models which simulated communication, we categorised\nfour ways that agents communicate information: spatially through information\ntrails or radii around agents, via social networks and via external\ncommunication. Finally, the variables either manipulated or measured in the\nmodels were categorised into the following groups: environmental condition,\npersonal attributes of the agents, procedure, and source of information. We\ndiscuss promising directions for agent-based evacuation models to capture the\neffects of communication and group dynamics on evacuee behaviour. Moreover, we\ndemonstrate how communication and group dynamics may impact the variables\ncommonly used in agent-based evacuation models.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.15761v1"
    },
    {
        "title": "Verification of Multi-Agent Properties in Electronic Voting: A Case\n  Study",
        "authors": [
            "Damian Kurpiewski",
            "Wojciech Jamroga",
            "Łukasz Maśko",
            "Łukasz Mikulski",
            "Witold Pazderski",
            "Wojciech Penczek",
            "Teofil Sidoruk"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Formal verification of multi-agent systems is hard, both theoretically and in\npractice. In particular, studies that use a single verification technique\ntypically show limited efficiency, and allow to verify only toy examples. Here,\nwe propose some new techniques and combine them with several recently developed\nones to see what progress can be achieved for a real-life scenario. Namely, we\nuse fixpoint approximation, domination-based strategy search, partial order\nreduction, and parallelization to verify heterogeneous scalable models of the\nSelene e-voting protocol. The experimental results show that the combination\nallows to verify requirements for much more sophisticated models than\npreviously.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.15789v1"
    },
    {
        "title": "Pretty Good Strategies and Where to Find Them",
        "authors": [
            "Wojciech Jamroga",
            "Damian Kurpiewski"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Synthesis of bulletproof strategies in imperfect information scenarios is a\nnotoriously hard problem. In this paper, we suggest that it is sometimes a\nviable alternative to aim at \"reasonably good\" strategies instead. This makes\nsense not only when an ideal strategy cannot be found due to the complexity of\nthe problem, but also when no winning strategy exists at all. We propose an\nalgorithm for synthesis of such \"pretty good\" strategies. The idea is to first\ngenerate a surely winning strategy with perfect information, and then\niteratively improve it with respect to two criteria of dominance: one based on\nthe amount of conflicting decisions in the strategy, and the other related to\nthe tightness of its outcome set. We focus on reachability goals and evaluate\nthe algorithm experimentally with very promising results.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.16531v1"
    },
    {
        "title": "Scalable Verification of Strategy Logic through Three-valued Abstraction",
        "authors": [
            "Francesco Belardinelli",
            "Angelo Ferrando",
            "Wojciech Jamroga",
            "Vadim Malvone",
            "Aniello Murano"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The model checking problem for multi-agent systems against Strategy Logic\nspecifications is known to be non-elementary. On this logic several fragments\nhave been defined to tackle this issue but at the expense of expressiveness. In\nthis paper, we propose a three-valued semantics for Strategy Logic upon which\nwe define an abstraction method. We show that the latter semantics is an\napproximation of the classic two-valued one for Strategy Logic. Furthermore, we\nextend MCMAS, an open-source model checker for multi-agent specifications, to\nincorporate our abstraction method and present some promising experimental\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.17219v1"
    },
    {
        "title": "Computationally Feasible Strategies",
        "authors": [
            "Catalin Dima",
            "Wojciech Jamroga"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Real-life agents seldom have unlimited reasoning power. In this paper, we\npropose and study a new formal notion of computationally bounded strategic\nability in multi-agent systems. The notion characterizes the ability of a set\nof agents to synthesize an executable strategy in the form of a Turing machine\nwithin a given complexity class, that ensures the satisfaction of a temporal\nobjective in a parameterized game arena. We show that the new concept induces a\nproper hierarchy of strategic abilities -- in particular, polynomial-time\nabilities are strictly weaker than the exponential-time ones. We also propose\nan ``adaptive'' variant of computational ability which allows for different\nstrategies for each parameter value, and show that the two notions do not\ncoincide. Finally, we define and study the model-checking problem for\ncomputational strategies. We show that the problem is undecidable even for\nseverely restricted inputs, and present our first steps towards decidable\nfragments.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.17234v1"
    },
    {
        "title": "Strategic Abilities of Forgetful Agents in Stochastic Environments",
        "authors": [
            "Francesco Belardinelli",
            "Wojciech Jamroga",
            "Munyque Mittelmann",
            "Aniello Murano"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we investigate the probabilistic variants of the strategy\nlogics ATL and ATL* under imperfect information. Specifically, we present novel\ndecidability and complexity results when the model transitions are stochastic\nand agents play uniform strategies. That is, the semantics of the logics are\nbased on multi-agent, stochastic transition systems with imperfect information,\nwhich combine two sources of uncertainty, namely, the partial observability\nagents have on the environment, and the likelihood of transitions to occur from\na system state. Since the model checking problem is undecidable in general in\nthis setting, we restrict our attention to agents with memoryless (positional)\nstrategies. The resulting setting captures the situation in which agents have\nqualitative uncertainty of the local state and quantitative uncertainty about\nthe occurrence of future events. We illustrate the usefulness of this setting\nwith meaningful examples.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.17240v1"
    },
    {
        "title": "Distributed Nonlinear Filtering using Triangular Transport Maps",
        "authors": [
            "Daniel Grange",
            "Ricardo Baptista",
            "Amirhossein Taghvaei",
            "Allen Tannenbaum",
            "Sean Phillips"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The distributed filtering problem sequentially estimates a global state\nvariable using observations from a network of local sensors with different\nmeasurement models. In this work, we introduce a novel methodology for\ndistributed nonlinear filtering by combining techniques from transportation of\nmeasures, dimensionality reduction, and consensus algorithms. We illustrate our\nmethodology on a satellite pose estimation problem from a network of direct and\nindirect observers. The numerical results serve as a proof of concept, offering\nnew venues for theoretical and applied research in the domain of distributed\nfiltering.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.19000v1"
    },
    {
        "title": "A Multi-agent Reinforcement Learning Study of Emergence of Social\n  Classes out of Arbitrary Governance: The Role of Environment",
        "authors": [
            "Aslan S. Dizaji"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  There are several theories in economics regarding the roots or causes of\nprosperity in a society. One of these theories or hypotheses -- named geography\nhypothesis -- mentions that the reason why some countries are prosperous and\nsome others are poor is the geographical location of the countries in the world\nas makes their climate and environment favorable or unfavorable regarding\nnatural resources. Another competing hypothesis states that man-made\ninstitutions particularly inclusive political institutions are the reasons why\nsome countries are prosperous and some others are poor. On the other hand,\nthere is a specific political theory developed for the long-term social\ndevelopment in Iran -- named Arbitrary Rule and Aridisolatic Society which\nparticularly emphasizes on the role of aridity to shape arbitrary political and\neconomical institutions in Iran, without any functional social classes in the\nsociety. In this paper, by extending the AI-Economist -- a recently developed\ntwo-level multi-agent reinforcement learning environment -- I show that when\nthe central planner is ruling the environment by arbitrary rules, the society\nevolves through different paths in different environments. In the environment\nhaving band-like vertical isolated patches of natural resources, all mobile\nagents are equally exploited by the central planner and the central planner is\nalso not gaining any income, while in the society having more uniformly\ndistributed natural resources, the productivity and Maximin are higher and the\nsociety generates a heterogeneous stratified social structure. All these\nfindings provide a partial answer to the above debate and reconcile the role of\ngeography and political institutions on the long-term development in a region.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.19903v1"
    },
    {
        "title": "Multi-Valued Verification of Strategic Ability",
        "authors": [
            "Wojciech Jamroga",
            "Beata Konikowska",
            "Damian Kurpiewski",
            "Wojciech Penczek"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Some multi-agent scenarios call for the possibility of evaluating\nspecifications in a richer domain of truth values. Examples include runtime\nmonitoring of a temporal property over a growing prefix of an infinite path,\ninconsistency analysis in distributed databases, and verification methods that\nuse incomplete anytime algorithms, such as bounded model checking. In this\npaper, we present multi-valued alternating-time temporal logic (mv-ATL*), an\nexpressive logic to specify strategic abilities in multi-agent systems. It is\nwell known that, for branching-time logics, a general method for\nmodel-independent translation from multi-valued to two-valued model checking\nexists. We show that the method cannot be directly extended to mv-ATL*. We also\npropose two ways of overcoming the problem. Firstly, we identify constraints on\nformulas for which the model-independent translation can be suitably adapted.\nSecondly, we present a model-dependent reduction that can be applied to all\nformulas of mv-ATL*. We show that, in all cases, the complexity of verification\nincreases only linearly when new truth values are added to the evaluation\ndomain. We also consider several examples that show possible applications of\nmv-ATL* and motivate its use for model checking multi-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.20344v1"
    },
    {
        "title": "Where to Deploy an Airborne Relay in Unknown Environments: Feasible\n  Locations for Throughput and LoS Enhancement",
        "authors": [
            "Juan David Pabon",
            "Matthew C. Valenti",
            "Xi Yu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The deployment of heterogeneous teams of both air and ground mobile assets\ncombines the advantages of mobility, sensing capability, and operational\nduration when performing complex tasks. Air assets in such teams act to relay\ninformation between ground assets but must maintain unblocked paths to enable\nhigh-capacity communication modes. Obstacles in the operational environment may\nblock the line of sight (LoS) between air assets and ground assets depending on\ntheir locations and heights. In this paper, we analyze the probability of\nspanning a two-hop communication between a pair of ground assets deployed in an\nenvironment with obstacles at random locations and with random heights (i.e. a\nPoisson Forest) using an air asset at any location near the ground assets. We\nprovide a closed-form expression of the LoS probability based on the\n3-dimensional locations of the air asset. We then compute a 3-D manifold of the\nair asset locations that satisfy a given LoS probability constraint. We further\nconsider throughput as a measure of communication quality, and use it as an\noptimization objective.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.00791v1"
    },
    {
        "title": "Cooperative Label-Free Moving Target Fencing for Second-Order\n  Multi-Agent Systems with Rigid Formation",
        "authors": [
            "Bin-Bin Hu",
            "Hai-Tao Zhang",
            "Yang Shi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper proposes a label-free controller for a second-order multi-agent\nsystem to cooperatively fence a moving target of variational velocity into a\nconvex hull formed by the agents whereas maintaining a rigid formation.\nTherein, no label is predetermined for a specified agent. To attain a rigid\nformation with guaranteed collision avoidance, each controller consists of two\nterms: a dynamic regulator with an internal model to drive agents towards the\nmoving target merely by position information feedback, and a repulsive force\nbetween each pair of adjacent agents. Significantly, sufficient conditions are\nderived to guarantee the asymptotic stability of the closed-loop systems\ngoverned by the proposed fencing controller. Rigorous analysis is provided to\neliminate the strong nonlinear couplings induced by the label-free property.\nFinally, the effectiveness of the controller is substantiated by numerical\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.00978v1"
    },
    {
        "title": "Revisiting MAB based approaches to recursive delegation",
        "authors": [
            "Nir Oren"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper we examine the effectiveness of several multi-arm bandit\nalgorithms when used as a trust system to select agents to delegate tasks to.\nIn contrast to existing work, we allow for recursive delegation to occur. That\nis, a task delegated to one agent can be delegated onwards by that agent, with\nfurther delegation possible until some agent finally executes the task. We show\nthat modifications to the standard multi-arm bandit algorithms can provide\nimprovements in performance in such recursive delegation settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.01243v1"
    },
    {
        "title": "Secured Fiscal Credit Model: Multi-Agent Systems And Decentralized\n  Autonomous Organisations For Tax Credit's Tracking",
        "authors": [
            "Giovanni De Gasperis",
            "Sante Dino Facchini",
            "Ivan Letteri"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Tax incentives and fiscal bonuses have had a significant impact on the\nItalian economy over the past decade. In particular, the \"Superbonus 110\" tax\nrelief in 2020, offering a generous 110% deduction for expenses related to\nenergy efficiency improvements and seismic risk reduction in buildings, has\nplayed a pivotal role. However, the surge in construction activities has also\nbrought about an unfortunate increase in fraudulent activities. To address this\nchallenge, our research introduces a practical system for monitoring and\nmanaging the entire process of the Superbonus 110 tax credit, from its\ninitiation to redemption. This system leverages artificial intelligence and\nblockchain technology to streamline tax credit management and incorporates\ncontrollers based on a Decentralised Autonomous Organisation architecture,\nbolstered by a Multi-agent System. The outcome of our work is a system capable\nof establishing a tokenomics framework that caters to the needs and\nfunctionalities of both investors and operators. Moreover, it features a robust\ncontrol system to prevent inadvertent errors like double spending,\noverspending, and deceitful practices such as false claims of completed work.\nThe collaborative approach between the Decentralised Autonomous Organisation\nand the Multi-agent System enhances trust and security levels among\nparticipants in a competitive environment where potential fraudsters might\nattempt to exploit the system. It also enables comprehensive tracking and\nmonitoring of the entire Superbonus process. In the realm of engineering, our\nproject represents an innovative fusion of blockchain technology and\nMulti-agent Systems, advancing the application of artificial intelligence. This\nintegration guarantees the validation, recording, and execution of transactions\nwith a remarkable level of trust and transparency.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.01584v2"
    },
    {
        "title": "A Brain-inspired Theory of Collective Mind Model for Efficient Social\n  Cooperation",
        "authors": [
            "Zhuoya Zhao",
            "Feifei Zhao",
            "Shiwen Wang",
            "Yinqian Sun",
            "Yi Zeng"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Social intelligence manifests the capability, often referred to as the Theory\nof Mind (ToM), to discern others' behavioral intentions, beliefs, and other\nmental states. ToM is especially important in multi-agent and human-machine\ninteraction environments because each agent needs to understand the mental\nstates of other agents in order to better respond, interact, and collaborate.\nRecent research indicates that the ToM model possesses the capability to infer\nbeliefs, intentions, and anticipate future observations and actions;\nnonetheless, its deployment in tackling intricate tasks remains notably\nlimited. The challenges arise when the number of agents increases, the\nenvironment becomes more complex, and interacting with the environment and\npredicting the mental state of each other becomes difficult and time consuming.\nTo overcome such limits, we take inspiration from the Theory of Collective Mind\n(ToCM) mechanism, predicting observations of all other agents into a unified\nbut plural representation and discerning how our own actions affect this mental\nstate representation. Based on this foundation, we construct an imaginative\nspace to simulate the multi-agent interaction process, thus improving the\nefficiency of cooperation among multiple agents in complex decision-making\nenvironments. In various cooperative tasks with different numbers of agents,\nthe experimental results highlight the superior cooperative efficiency and\nperformance of our approach compared to the Multi-Agent Reinforcement Learning\n(MARL) baselines. We achieve consistent boost on SNN- and DNN-based decision\nnetworks, and demonstrate that ToCM's inferences about others' mental states\ncan be transferred to new tasks for quickly and flexible adaptation.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.03150v2"
    },
    {
        "title": "A Theoretical Framework for Simulating Organizations",
        "authors": [
            "Edmundo Barrientos Palma"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This work proposes a theoretical framework using a systemic modeling paradigm\nto implement computational agents in the simulation of organizations. The\npotential of its use is demonstrated in the modeling of supply chains. Finally,\nresearch tending to develop an organizational modeling system in real-time is\nproposed.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06246v1"
    },
    {
        "title": "What Do You Care About: Inferring Values from Emotions",
        "authors": [
            "Jieting Luo",
            "Mehdi Dastani",
            "Thomas Studer",
            "Beishui Liao"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Observers can glean information from others' emotional expressions through\nthe act of drawing inferences from another individual's emotional expressions.\nIt is important for socially aware artificial systems to be capable of doing\nthat as it can facilitate social interaction among agents, and is particularly\nimportant in human-robot interaction for supporting a more personalized\ntreatment of users. In this short paper, we propose a methodology for\ndeveloping a formal model that allows agents to infer another agent's values\nfrom her emotion expressions.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06250v1"
    },
    {
        "title": "Online Reachability Analysis and Space Convexification for Autonomous\n  Racing",
        "authors": [
            "Sergiy Bogomolov",
            "Taylor T. Johnson",
            "Diego Manzanas Lopez",
            "Patrick Musau",
            "Paulius Stankaitis"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper presents an optimisation-based approach for an obstacle avoidance\nproblem within an autonomous vehicle racing context. Our control regime\nleverages online reachability analysis and sensor data to compute the maximal\nsafe traversable region that an agent can traverse within the environment. The\nidea is to first compute a non-convex safe region, which then can be\nconvexified via a novel coupled separating hyperplane algorithm. This derived\nsafe area is then used to formulate a nonlinear model-predictive control\nproblem that seeks to find an optimal and safe driving trajectory. We evaluate\nthe proposed approach through a series of diverse experiments and assess the\nruntime requirements of our proposed approach through an analysis of the\neffects of a set of varying optimisation objectives for generating these\ncoupled hyperplanes.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09781v1"
    },
    {
        "title": "Parallel and Sequential Resources Networks",
        "authors": [
            "Alexandre Benatti",
            "Luciano da F. Costa"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  A large number of real and abstract systems involve the transformation of\nsome basic resource into respective products under the action of multiple\nprocessing agents, which can be understood as multiple-agent production systems\n(MAP). At each discrete time instant, for each agent, a fraction of the\nresources is assumed to be kept, forwarded to other agents, or converted into\nwork with some efficiency. The present work describes a systematic study of\nnine basic MAP architectures subdivided into two main groups, namely parallel\nand sequential distribution of resources from a single respective source.\nSeveral types of interconnections among the involved processing agents are also\nconsidered. The resulting MAP architectures are studied in terms of the total\namount of work, the dispersion of the resources (states) among the agents, and\nthe transition times from the start of operation until the respective steady\nstate. Several interesting results are obtained and discussed, including the\nobservation that some of the parallel designs were able to yield maximum work\nand minimum state dispersion, achieved at the expense of the transition time\nand use of several interconnections between the source and the agents. The\nresults obtained for the sequential designs indicate that relatively high\nperformance can be obtained for some specific cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09867v1"
    },
    {
        "title": "A Framework for Modeling, Analyzing, and Decision-Making in Disease\n  Spread Dynamics and Medicine/Vaccine Distribution",
        "authors": [
            "Zenin Easa Panthakkalakath",
            " Neeraj",
            "Jimson Mathew"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The challenges posed by epidemics and pandemics are immense, especially if\nthe causes are novel. This article introduces a versatile open-source\nsimulation framework designed to model intricate dynamics of infectious\ndiseases across diverse population centres. Taking inspiration from historical\nprecedents such as the Spanish flu and COVID-19, and geographical economic\ntheories such as Central place theory, the simulation integrates agent-based\nmodelling to depict the movement and interactions of individuals within\ndifferent settlement hierarchies. Additionally, the framework provides a tool\nfor decision-makers to assess and strategize optimal distribution plans for\nlimited resources like vaccines or cures as well as to impose mobility\nrestrictions.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09984v1"
    },
    {
        "title": "A Random Walk Approach for Simulation-Based Continuous Dynamic Traffic\n  Assignment",
        "authors": [
            "Kaveh Khoshkhah",
            "Mozhgan Pourmoradnasseri",
            "Sadok Ben Yahia",
            "Amnir Hadachi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper presents a new simulation-based approach to address the stochastic\nDynamic Traffic Assignment (DTA) problem, focusing on large congested networks\nand dynamic settings. The proposed methodology incorporates a random walk model\ninspired by the theoretical concept of the \\textit{equivalent impedance}\nmethod, specifically designed to overcome the limitations of traditional\nMultinomial Logit (MNL) models in handling overlapping routes and scaling\nissues. By iteratively contracting non-overlapping subnetworks into virtual\nlinks and computing equivalent virtual travel costs, the route choice\ndecision-making process is shifted to intersections, enabling a more accurate\nrepresentation of travelers' choices as traffic conditions evolve and allowing\nmore accurate performance under fine-grained temporal segmentation.\n  The approach leverages Directed Acyclic Graphs (DAGs) structure to\nefficiently find all routes between two nodes, thus obviating the need for\nroute enumeration, which is intractable in general networks. While with the\ncalculation approach of downstream node choice probabilities, all available\nroutes in the network can be selected with non-zero probability.\n  To evaluate the effectiveness of the proposed method, experiments are\nconducted on two synthetic networks under congested demand scenarios using\nSimulation of Urban MObility (SUMO), an open-source microscopic traffic\nsimulation software. The results demonstrate the method's robustness, faster\nconvergence, and realistic trip distribution compared to traditional route\nassignment methods, making it an ideal proposal for real-time or\nresource-intensive applications such as microscopic demand calibration.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.12440v1"
    },
    {
        "title": "Large-scale Package Deliveries with Unmanned Aerial Vehicles using\n  Collective Learning",
        "authors": [
            "Arun Narayanan",
            "Evangelos Pournaras",
            "Pedro H. J. Nardelli"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Unmanned aerial vehicles (UAVs) have significant practical advantages for\ndelivering packages, and many logistics companies have begun deploying UAVs for\ncommercial package deliveries. To deliver packages quickly and\ncost-effectively, the routes taken by UAVs from depots to customers must be\noptimized. This route optimization problem, a type of capacitated vehicle\nrouting problem, has recently attracted considerable research interest.\nHowever, few papers have dealt with large-scale deliveries, where the number of\ncustomers exceed 1000. We present an innovative, practical package delivery\nmodel wherein multiple UAVs deliver multiple packages to customers who are\ncompensated for late deliveries. Further, we propose an innovative methodology\nthat combines a new plan-generation algorithm with a collective-learning\nheuristic to quickly determine cost-effective paths of UAVs even for\nlarge-scale deliveries up to 10000 customers. Specialized settings are applied\nto a collective-learning heuristic, the Iterative Economic Planning and\nOptimized Selections (I-EPOS) in order to coordinate collective actions of the\nUAVs. To demonstrate our methodology, we applied our highly flexible approach\nto a depot in Heathrow Airport, London. We show that a coordinated approach, in\nwhich the UAVs collectively determine their flight paths, leads to lower\noperational costs than an uncoordinated approach. Further, the coordinated\napproach enables large-scale package deliveries.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.13489v1"
    },
    {
        "title": "An Agent-Based Discrete Event Simulation of Teleoperated Driving in\n  Freight Transport Operations: The Fleet Sizing Problem",
        "authors": [
            "Bahman Madadi",
            "Ali Nadi",
            "Gonçalo Homem de Almeida Correia",
            "Thierry Verduijn",
            "Lóránt Tavasszy"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Teleoperated or remote-controlled driving complements automated driving and\nacts as transitional technology toward full automation. An economic advantage\nof teleoperated driving in logistics operations lies in managing fleets with\nfewer teleoperators compared to vehicles with in-vehicle drivers. This\nalleviates growing truck driver shortage problems in the logistics industry and\nsaves costs. However, a trade-off exists between the teleoperator-to-vehicle\nratio and the service level of teleoperation. This study designs a simulation\nframework to explore this trade-off generating multiple performance indicators\nas proxies for teleoperation service level. By applying the framework, we\nidentify factors influencing the trade-off and optimal teleoperator-to-vehicle\nratios under different scenarios. Our case study on road freight tours in The\nNetherlands reveals that for any operational setting, a\nteleoperation-to-vehicle ratio below one can manage all freight truck tours\nwithout delay, while one represents the current situation. The minimum\nteleoperator-to-vehicle ratio for zero-delay operations is never above 0.6,\nimplying a minimum of 40% teleoperation labor cost saving. For operations where\na small delay is allowed, teleoperator-to-vehicle ratios as low as 0.4 are\nshown to be feasible, which indicates potential savings of up to 60%. This\nconfirms great promise for a positive business case for the teleoperated\ndriving as a service.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.14225v1"
    },
    {
        "title": "Multi-agent statistical discriminative sub-trajectory mining and an\n  application to NBA basketball",
        "authors": [
            "Rory Bunker",
            "Vo Nguyen Le Duy",
            "Yasuo Tabei",
            "Ichiro Takeuchi",
            "Keisuke Fujii"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Improvements in tracking technology through optical and computer vision\nsystems have enabled a greater understanding of the movement-based behaviour of\nmultiple agents, including in team sports. In this study, a Multi-Agent\nStatistically Discriminative Sub-Trajectory Mining (MA-Stat-DSM) method is\nproposed that takes a set of binary-labelled agent trajectory matrices as input\nand incorporates Hausdorff distance to identify sub-matrices that statistically\nsignificantly discriminate between the two groups of labelled trajectory\nmatrices. Utilizing 2015/16 SportVU NBA tracking data, agent trajectory\nmatrices representing attacks consisting of the trajectories of five agents\n(the ball, shooter, last passer, shooter defender, and last passer defender),\nwere truncated to correspond to the time interval following the receipt of the\nball by the last passer, and labelled as effective or ineffective based on a\ndefinition of attack effectiveness that we devise in the current study. After\nidentifying appropriate parameters for MA-Stat-DSM by iteratively applying it\nto all matches involving the two top- and two bottom-placed teams from the\n2015/16 NBA season, the method was then applied to selected matches and could\nidentify and visualize the portions of plays, e.g., involving passing, on-,\nand/or off-the-ball movements, which were most relevant in rendering attacks\neffective or ineffective.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.16564v1"
    },
    {
        "title": "mango: A Modular Python-Based Agent Simulation Framework",
        "authors": [
            "Rico Schrage",
            "Jens Sager",
            "Jan Philipp Hörding",
            "Stefanie Holly"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Agent-based simulations, especially those including communication, are\ncomplex to model and execute. To help researchers deal with this complexity and\nto encourage modular and maintainable research software, the Python-based\nframework mango (modular python agent framework) has been developed. The\nframework enables users to quickly implement software agents with different\ncommunication protocols (e.g., TCP) and message codecs (e.g., JSON).\nFurthermore, mango provides various options for developing an integrated agent\nsimulation. This includes a scheduler module, which can control the agents'\ntasks, a (distributed) clock mechanism for time synchronization, and a specific\nsimulation component, which can be coupled with other (co-)simulation software.\nThese features are complemented by modular implementation patterns and a\nwell-evaluated performance with the ability to simulate across multiple\nprocesses to ensure scalability.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17688v1"
    },
    {
        "title": "A Survey of Progress on Cooperative Multi-agent Reinforcement Learning\n  in Open Environment",
        "authors": [
            "Lei Yuan",
            "Ziqian Zhang",
            "Lihe Li",
            "Cong Guan",
            "Yang Yu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent Reinforcement Learning (MARL) has gained wide attention in recent\nyears and has made progress in various fields. Specifically, cooperative MARL\nfocuses on training a team of agents to cooperatively achieve tasks that are\ndifficult for a single agent to handle. It has shown great potential in\napplications such as path planning, autonomous driving, active voltage control,\nand dynamic algorithm configuration. One of the research focuses in the field\nof cooperative MARL is how to improve the coordination efficiency of the\nsystem, while research work has mainly been conducted in simple, static, and\nclosed environment settings. To promote the application of artificial\nintelligence in real-world, some research has begun to explore multi-agent\ncoordination in open environments. These works have made progress in exploring\nand researching the environments where important factors might change. However,\nthe mainstream work still lacks a comprehensive review of the research\ndirection. In this paper, starting from the concept of reinforcement learning,\nwe subsequently introduce multi-agent systems (MAS), cooperative MARL, typical\nmethods, and test environments. Then, we summarize the research work of\ncooperative MARL from closed to open environments, extract multiple research\ndirections, and introduce typical works. Finally, we summarize the strengths\nand weaknesses of the current research, and look forward to the future\ndevelopment direction and research problems in cooperative MARL in open\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.01058v1"
    },
    {
        "title": "Attention-Guided Contrastive Role Representations for Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Zican Hu",
            "Zongzhang Zhang",
            "Huaxiong Li",
            "Chunlin Chen",
            "Hongyu Ding",
            "Zhi Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Real-world multi-agent tasks usually involve dynamic team composition with\nthe emergence of roles, which should also be a key to efficient cooperation in\nmulti-agent reinforcement learning (MARL). Drawing inspiration from the\ncorrelation between roles and agent's behavior patterns, we propose a novel\nframework of **A**ttention-guided **CO**ntrastive **R**ole representation\nlearning for **M**ARL (**ACORM**) to promote behavior heterogeneity, knowledge\ntransfer, and skillful coordination across agents. First, we introduce mutual\ninformation maximization to formalize role representation learning, derive a\ncontrastive learning objective, and concisely approximate the distribution of\nnegative pairs. Second, we leverage an attention mechanism to prompt the global\nstate to attend to learned role representations in value decomposition,\nimplicitly guiding agent coordination in a skillful role space to yield more\nexpressive credit assignment. Experiments on challenging StarCraft II\nmicromanagement and Google research football tasks demonstrate the\nstate-of-the-art performance of our method and its advantages over existing\napproaches. Our code is available at\n[https://github.com/NJU-RL/ACORM](https://github.com/NJU-RL/ACORM).\n",
        "pdf_link": "http://arxiv.org/pdf/2312.04819v2"
    },
    {
        "title": "Distributed Autonomous Organizations as Public Services Supplying\n  Platform",
        "authors": [
            "Giovanni De Gasperis",
            "Sante Dino Facchini",
            "Maurizio Michilli"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Servizi Elaborazioni Dati SpA is a public company owned by Municipality of L\nAquila, it supplies the institution with network services and software\napplications for distributing services to citizens. The future policy of the\ncompany is to enlarge the offer of its services to nearby communities that are\nunable to set up and maintain their own network and software structures. This\npaper presents thus a possible architecture model to support small\nmunicipalities in supplying public services to citizens, with the aid of SED\nSpa. Through second level platforms based on Blockchain networks and\nMulti-agents Systems running on smart contracts, the system will focus on Waste\nTax (Ta.Ri) management system in the Fascicolo del Cittadino environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.05189v1"
    },
    {
        "title": "Stein Coverage: a Variational Inference Approach to\n  Distribution-matching Multisensor Deployment",
        "authors": [
            "Donipolo Ghimire",
            "Solmaz S. Kia"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper examines the spatial coverage optimization problem for multiple\nsensors in a known convex environment, where the coverage service of each\nsensor is heterogeneous and anisotropic. We introduce the Stein Coverage\nalgorithm, a distribution-matching coverage approach that aims to place sensors\nat positions and orientations such that their collective coverage distribution\nis as close as possible to the event distribution. To select the most important\nrepresentative points from the coverage event distribution, Stein Coverage\nutilizes the Stein Variational Gradient Descent (SVGD), a deterministic\nsampling method from the variational inference literature. An innovation in our\nwork is the introduction of a repulsive force between the samples in the SVGD\nalgorithm to spread the samples and avoid footprint overlap for the deployed\nsensors. After pinpointing the points of interest for deployment, Stein\nCoverage solves the multisensor assignment problem using a bipartite optimal\nmatching process. Simulations demonstrate the advantages of the Stein Coverage\nmethod compared to conventional Voronoi partitioning multisensor deployment\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.07001v1"
    },
    {
        "title": "Multi-Agent Path Finding with Continuous Time Using SAT Modulo Linear\n  Real Arithmetic",
        "authors": [
            "Tomáš Kolárik",
            "Stefan Ratschan",
            "Pavel Surynek"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper introduces a new approach to solving a continuous-time version of\nthe multi-agent path finding problem. The algorithm translates the problem into\nan extension of the classical Boolean satisfiability problem, satisfiability\nmodulo theories (SMT), that can be solved by off-the-shelf solvers. This\nenables the exploitation of conflict generalization techniques that such\nsolvers can handle. Computational experiments show that the new approach scales\nbetter with respect to the available computation time than state-of-the art\napproaches and is usually able to avoid their exponential behavior on a class\nof benchmark problems modeling a typical bottleneck situation.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.08051v2"
    },
    {
        "title": "From Centralized to Self-Supervised: Pursuing Realistic Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Violet Xiang",
            "Logan Cross",
            "Jan-Philipp Fränken",
            "Nick Haber"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In real-world environments, autonomous agents rely on their egocentric\nobservations. They must learn adaptive strategies to interact with others who\npossess mixed motivations, discernible only through visible cues. Several\nMulti-Agent Reinforcement Learning (MARL) methods adopt centralized approaches\nthat involve either centralized training or reward-sharing, often violating the\nrealistic ways in which living organisms, like animals or humans, process\ninformation and interact. MARL strategies deploying decentralized training with\nintrinsic motivation offer a self-supervised approach, enable agents to develop\nflexible social strategies through the interaction of autonomous agents.\nHowever, by contrasting the self-supervised and centralized methods, we reveal\nthat populations trained with reward-sharing methods surpass those using\nself-supervised methods in a mixed-motive environment. We link this superiority\nto specialized role emergence and an agent's expertise in its role.\nInterestingly, this gap shrinks in pure-motive settings, emphasizing the need\nfor evaluations in more complex, realistic environments (mixed-motive). Our\npreliminary results suggest a gap in population performance that can be closed\nby improving self-supervised methods and thereby pushing MARL closer to\nreal-world readiness.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.08662v1"
    },
    {
        "title": "Communication-Efficient Soft Actor-Critic Policy Collaboration via\n  Regulated Segment Mixture",
        "authors": [
            "Xiaoxue Yu",
            "Rongpeng Li",
            "Chengchao Liang",
            "Zhifeng Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) has emerged as a foundational\napproach for addressing diverse, intelligent control tasks in various scenarios\nlike the Internet of Vehicles, Internet of Things, and Unmanned Aerial\nVehicles. However, the widely assumed existence of a central node for\ncentralized, federated learning-assisted MARL might be impractical in highly\ndynamic environments. This can lead to excessive communication overhead,\npotentially overwhelming the system. To address these challenges, we design a\nnovel communication-efficient, fully distributed algorithm for collaborative\nMARL under the frameworks of Soft Actor-Critic (SAC) and Decentralized\nFederated Learning (DFL), named RSM-MASAC. In particular, RSM-MASAC enhances\nmulti-agent collaboration and prioritizes higher communication efficiency in\ndynamic systems by incorporating the concept of segmented aggregation in DFL\nand augmenting multiple model replicas from received neighboring policy\nsegments, which are subsequently employed as reconstructed referential policies\nfor mixing. Distinctively diverging from traditional RL approaches, RSM-MASAC\nintroduces new bounds under the framework of Maximum Entropy Reinforcement\nLearning (MERL). Correspondingly, it adopts a theory-guided mixture metric to\nregulate the selection of contributive referential policies, thus guaranteeing\nsoft policy improvement during the communication-assisted mixing phase.\nFinally, the extensive simulations in mixed-autonomy traffic control scenarios\nverify the effectiveness and superiority of our algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.10123v3"
    },
    {
        "title": "Cautiously-Optimistic Knowledge Sharing for Cooperative Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Yanwen Ba",
            "Xuan Liu",
            "Xinning Chen",
            "Hao Wang",
            "Yang Xu",
            "Kenli Li",
            "Shigeng Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  While decentralized training is attractive in multi-agent reinforcement\nlearning (MARL) for its excellent scalability and robustness, its inherent\ncoordination challenges in collaborative tasks result in numerous interactions\nfor agents to learn good policies. To alleviate this problem, action advising\nmethods make experienced agents share their knowledge about what to do, while\nless experienced agents strictly follow the received advice. However, this\nmethod of sharing and utilizing knowledge may hinder the team's exploration of\nbetter states, as agents can be unduly influenced by suboptimal or even adverse\nadvice, especially in the early stages of learning. Inspired by the fact that\nhumans can learn not only from the success but also from the failure of others,\nthis paper proposes a novel knowledge sharing framework called\nCautiously-Optimistic kNowledge Sharing (CONS). CONS enables each agent to\nshare both positive and negative knowledge and cautiously assimilate knowledge\nfrom others, thereby enhancing the efficiency of early-stage exploration and\nthe agents' robustness to adverse advice. Moreover, considering the continuous\nimprovement of policies, agents value negative knowledge more in the early\nstages of learning and shift their focus to positive knowledge in the later\nstages. Our framework can be easily integrated into existing Q-learning based\nmethods without introducing additional training costs. We evaluate CONS in\nseveral challenging multi-agent tasks and find it excels in environments where\noptimal behavioral patterns are difficult to discover, surpassing the baselines\nin terms of convergence rate and final performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.12095v1"
    },
    {
        "title": "Action Duration Generalization for Exact Multi-Agent Collective\n  Construction",
        "authors": [
            "Martin Rameš",
            "Pavel Surynek"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper addresses exact approaches to multi-agent collective construction\nproblem which tasks a group of cooperative agents to build a given structure in\na blocksworld under the gravity constraint. We propose a generalization of the\nexisting exact model based on mixed integer linear programming by accommodating\nvarying agent action durations. We refer to the model as a fraction-time model.\nThe generalization by introducing action duration enables one to create a more\nrealistic model for various domains. It provides a significant reduction of\nplan execution duration at the cost of increased computational time, which\nrises steeply the closer the model gets to the exact real-world action\nduration. We also propose a makespan estimation function for the fraction-time\nmodel. This can be used to estimate the construction time reduction size for\nthe purpose of cost-benefit analysis. The fraction-time model and the makespan\nestimation function have been evaluated in a series of experiments using a set\nof benchmark structures. The results show a significant reduction of plan\nexecution duration for non-constant duration actions due to decreasing\nsynchronization overhead at the end of each action. According to the results,\nthe makespan estimation function provides a reasonably accurate estimate of the\nmakespan.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.13485v1"
    },
    {
        "title": "ConcaveQ: Non-Monotonic Value Function Factorization via Concave\n  Representations in Deep Multi-Agent Reinforcement Learning",
        "authors": [
            "Huiqun Li",
            "Hanhan Zhou",
            "Yifei Zou",
            "Dongxiao Yu",
            "Tian Lan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Value function factorization has achieved great success in multi-agent\nreinforcement learning by optimizing joint action-value functions through the\nmaximization of factorized per-agent utilities. To ensure\nIndividual-Global-Maximum property, existing works often focus on value\nfactorization using monotonic functions, which are known to result in\nrestricted representation expressiveness. In this paper, we analyze the\nlimitations of monotonic factorization and present ConcaveQ, a novel\nnon-monotonic value function factorization approach that goes beyond monotonic\nmixing functions and employs neural network representations of concave mixing\nfunctions. Leveraging the concave property in factorization, an iterative\naction selection scheme is developed to obtain optimal joint actions during\ntraining. It is used to update agents' local policy networks, enabling fully\ndecentralized execution. The effectiveness of the proposed ConcaveQ is\nvalidated across scenarios involving multi-agent predator-prey environment and\nStarCraft II micromanagement tasks. Empirical results exhibit significant\nimprovement of ConcaveQ over state-of-the-art multi-agent reinforcement\nlearning approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.15555v1"
    },
    {
        "title": "Multi-Task Multi-Agent Shared Layers are Universal Cognition of\n  Multi-Agent Coordination",
        "authors": [
            "Jiawei Wang",
            "Jian Zhao",
            "Zhengtao Cao",
            "Ruili Feng",
            "Rongjun Qin",
            "Yang Yu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent reinforcement learning shines as the pinnacle of multi-agent\nsystems, conquering intricate real-world challenges, fostering collaboration\nand coordination among agents, and unleashing the potential for intelligent\ndecision-making across domains. However, training a multi-agent reinforcement\nlearning network is a formidable endeavor, demanding substantial computational\nresources to interact with diverse environmental variables, extract state\nrepresentations, and acquire decision-making knowledge. The recent\nbreakthroughs in large-scale pre-trained models ignite our curiosity: Can we\nuncover shared knowledge in multi-agent reinforcement learning and leverage\npre-trained models to expedite training for future tasks? Addressing this\nissue, we present an innovative multi-task learning approach that aims to\nextract and harness common decision-making knowledge, like cooperation and\ncompetition, across different tasks. Our approach involves concurrent training\nof multiple multi-agent tasks, with each task employing independent front-end\nperception layers while sharing back-end decision-making layers. This effective\ndecoupling of state representation extraction from decision-making allows for\nmore efficient training and better transferability. To evaluate the efficacy of\nour proposed approach, we conduct comprehensive experiments in two distinct\nenvironments: the StarCraft Multi-agent Challenge (SMAC) and the Google\nResearch Football (GRF) environments. The experimental results unequivocally\ndemonstrate the smooth transferability of the shared decision-making network to\nother tasks, thereby significantly reducing training costs and improving final\nperformance. Furthermore, visualizations authenticate the presence of general\nmulti-agent decision-making knowledge within the shared network layers, further\nvalidating the effectiveness of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.15674v1"
    },
    {
        "title": "LLM Harmony: Multi-Agent Communication for Problem Solving",
        "authors": [
            "Sumedh Rasal"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large Language Models (LLMs) have revolutionized Natural Language Processing\nbut exhibit limitations, particularly in autonomously addressing novel\nchallenges such as reasoning and problem-solving. Traditional techniques like\nchain-of-thought prompting necessitate explicit human guidance. This paper\nintroduces a novel multi-agent communication framework, inspired by the CAMEL\nmodel, to enhance LLMs' autonomous problem-solving capabilities. The framework\nemploys multiple LLM agents, each with a distinct persona, engaged in\nrole-playing communication, offering a nuanced and adaptable approach to\ndiverse problem scenarios. Extensive experimentation demonstrates the\nframework's superior performance and adaptability, providing valuable insights\ninto the collaborative potential of multiple agents in overcoming the\nlimitations of individual models.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.01312v1"
    },
    {
        "title": "A Decentralized Multiagent-Based Task Scheduling Framework for Handling\n  Uncertain Events in Fog Computing",
        "authors": [
            "Yikun Yang",
            "Fenghui Ren",
            "Minjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Fog computing has become an attractive research topic in recent years. As an\nextension of the cloud, fog computing provides computing resources for Internet\nof Things (IoT) applications through communicative fog nodes located at the\nnetwork edge. Fog nodes assist cloud services in handling real-time and mobile\napplications by bringing the processing capability to where the data is\ngenerated. However, the introduction of fog nodes can increase scheduling\nopenness and uncertainty. The scheduling issues in fog computing need to\nconsider the geography, load balancing, and network latency between IoT\ndevices, fog nodes, as well as the parent cloud. Besides, the scheduling\nmethods also need to deal with the occurrence of uncertain events in real-time\nso as to ensure service reliability. This paper proposes an agent-based\nframework with a decentralized structure to construct the architecture of fog\ncomputing, while three agent-based algorithms are proposed to implement the\nscheduling, load balance, and rescheduling processes. The proposed framework is\nimplemented by JADE and evaluated on the iFogSim toolkit. Experimental results\nshow that the proposed scheduling framework can adaptively schedule tasks and\nresources for different service requests in fog computing and can also improve\nthe task success rate when uncertain events occur.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.02219v1"
    },
    {
        "title": "A BDI Agent-Based Task Scheduling Framework for Cloud Computing",
        "authors": [
            "Yikun Yang",
            "Fenghui Ren",
            "Minjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Cloud computing is an attractive technology for providing computing resources\nover the Internet. Task scheduling is a critical issue in cloud computing,\nwhere an efficient task scheduling method can improve overall cloud\nperformance. Since cloud computing is a large-scale and geographically\ndistributed environment, traditional scheduling methods that allocate resources\nin a centralized manner are ineffective. Besides, traditional methods are\ndifficult to make rational decisions timely when the external environment\nchanges. This paper proposes a decentralized BDI (belief-desire-intention)\nagent-based scheduling framework for cloud computing. BDI agents have\nadvantages in modelling dynamic environments because BDI agents can update\ntheir beliefs, change desires, and trigger behaviours based on environmental\nchanges. Besides, to avoid communication stuck caused by environmental\nuncertainties, the asynchronous communication mode with a notify listener is\nemployed. The proposed framework covers both the task scheduling and\nrescheduling stages with the consideration of uncertain events that can\ninterrupt task executions. Two agent-based algorithms are proposed to implement\nthe task scheduling and rescheduling processes, and a novel recommendation\nmechanism is presented in the scheduling stage to reduce the impact of\ninformation synchronization delays. The proposed framework is implemented by\nJADEX and tested on CloudSim. The experimental results show that our framework\ncan minimize the task makespan, balance the resource utilization in a\nlarge-scale environment, and maximize the task success rate when uncertain\nevents occur.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.02223v1"
    },
    {
        "title": "Modeling Processes of Neighborhood Change",
        "authors": [
            "J. Carlos Martínez Mori",
            "Zhanzhan Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  An urban planner might design the spatial layout of transportation amenities\nso as to improve accessibility for underserved communities -- a fairness\nobjective. However, implementing such a design might trigger processes of\nneighborhood change that change who benefits from these amenities in the long\nterm. If so, has the planner really achieved their fairness objective? Can\nalgorithmic decision-making anticipate second order effects? In this paper, we\ntake a step in this direction by formulating processes of neighborhood change\nas instances of no-regret dynamics; a collective learning process in which a\nset of strategic agents rapidly reach a state of approximate equilibrium. We\nmathematize concepts of neighborhood change to model the incentive structures\nimpacting individual dwelling-site decision-making. Our model accounts for\naffordability, access to relevant transit amenities, community ties, and site\nupkeep. We showcase our model with computational experiments that provide\nsemi-quantitative insights on the spatial economics of neighborhood change,\nparticularly on the influence of residential zoning policy and the placement of\ntransit amenities.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03307v2"
    },
    {
        "title": "Transparency as Delayed Observability in Multi-Agent Systems",
        "authors": [
            "Kshama Dwarakanath",
            "Svitlana Vyetrenko",
            "Toks Oyebode",
            "Tucker Balch"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Is transparency always beneficial in complex systems such as traffic networks\nand stock markets? How is transparency defined in multi-agent systems, and what\nis its optimal degree at which social welfare is highest? We take an\nagent-based view to define transparency (or its lacking) as delay in agent\nobservability of environment states, and utilize simulations to analyze the\nimpact of delay on social welfare. To model the adaptation of agent strategies\nwith varying delays, we model agents as learners maximizing the same objectives\nunder different delays in a simulated environment. Focusing on two agent types\n- constrained and unconstrained, we use multi-agent reinforcement learning to\nevaluate the impact of delay on agent outcomes and social welfare. Empirical\ndemonstration of our framework in simulated financial markets shows opposing\ntrends in outcomes of the constrained and unconstrained agents with delay, with\nan optimal partial transparency regime at which social welfare is maximal.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.05563v1"
    },
    {
        "title": "Confidence-Based Curriculum Learning for Multi-Agent Path Finding",
        "authors": [
            "Thomy Phan",
            "Joseph Driscoll",
            "Justin Romberg",
            "Sven Koenig"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  A wide range of real-world applications can be formulated as Multi-Agent Path\nFinding (MAPF) problem, where the goal is to find collision-free paths for\nmultiple agents with individual start and goal locations. State-of-the-art MAPF\nsolvers are mainly centralized and depend on global information, which limits\ntheir scalability and flexibility regarding changes or new maps that would\nrequire expensive replanning. Multi-agent reinforcement learning (MARL) offers\nan alternative way by learning decentralized policies that can generalize over\na variety of maps. While there exist some prior works that attempt to connect\nboth areas, the proposed techniques are heavily engineered and very complex due\nto the integration of many mechanisms that limit generality and are expensive\nto use. We argue that much simpler and general approaches are needed to bring\nthe areas of MARL and MAPF closer together with significantly lower costs. In\nthis paper, we propose Confidence-based Auto-Curriculum for Team Update\nStability (CACTUS) as a lightweight MARL approach to MAPF. CACTUS defines a\nsimple reverse curriculum scheme, where the goal of each agent is randomly\nplaced within an allocation radius around the agent's start location. The\nallocation radius increases gradually as all agents improve, which is assessed\nby a confidence-based measure. We evaluate CACTUS in various maps of different\nsizes, obstacle densities, and numbers of agents. Our experiments demonstrate\nbetter performance and generalization capabilities than state-of-the-art MARL\napproaches with less than 600,000 trainable parameters, which is less than 5%\nof the neural network size of current MARL approaches to MAPF.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.05860v2"
    },
    {
        "title": "Multi-Agent Based Simulation for Investigating Electric Vehicle Adoption\n  and Its Impacts on Electricity Distribution Grids and CO2 Emissions",
        "authors": [
            "Kristoffer Christensen",
            "Zheng Grace Ma",
            "Bo Nørregaard Jørgensen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Electric vehicles are expected to significantly contribute to CO2-eq.\nemissions reduction, but the increasing number of EVs also introduces\nchal-lenges to the energy system, and to what extent it contributes to\nachieving cli-mate goals remains unknown. Static modeling and assumption-based\nsimula-tions have been used for such investigation, but they cannot capture the\nrealistic ecosystem dynamics. To fill the gap, this paper investigates the\nimpacts of two adoption curves of private EVs on the electricity distribution\ngrids and national climate goals. This paper develops a multi-agent based\nsimulation with two adoption curves, the Traditional EV charging strategy,\nvarious EV models, driv-ing patterns, and CO2-eq. emission data to capture the\nfull ecosystem dynamics during a long-term period from 2020 to 2032. The Danish\n2030 climate goal and a Danish distribution network with 126 residential\nconsumers are chosen as the case study. The results show that both EV adoption\ncurves of 1 million and 775k EVs by 2030 will not satisfy the Danish climate\ngoal of reducing transport sector emissions by 30% by 2030. The results also\nshow that the current resi-dential electricity distribution grids cannot handle\nthe load from increasing EVs. The first grid overload will occur in 2031\n(around 16 and 24 months later for the 1 million and 775k EVs adopted by 2030)\nwith a 67% share of EVs in the grid.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.06192v1"
    },
    {
        "title": "Emergency Localization for Mobile Ground Users: An Adaptive UAV\n  Trajectory Planning Method",
        "authors": [
            "Zhihao Zhu",
            "Jiafan He",
            "Luyang Hou",
            "Lianming Xu",
            "Wendi Zhu",
            "Li Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In emergency search and rescue scenarios, the quick location of trapped\npeople is essential. However, disasters can render the Global Positioning\nSystem (GPS) unusable. Unmanned aerial vehicles (UAVs) with localization\ndevices can serve as mobile anchors due to their agility and high line-of-sight\n(LoS) probability. Nonetheless, the number of available UAVs during the initial\nstages of disaster relief is limited, and innovative methods are needed to\nquickly plan UAV trajectories to locate non-uniformly distributed dynamic\ntargets while ensuring localization accuracy. To address this challenge, we\ndesign a single UAV localization method without hovering, use the maximum\nlikelihood estimation (MLE) method to estimate the location of mobile users and\ndefine the upper bound of the localization error by considering users'\nmovement.Combining this localization method and localization error-index, we\nutilize the enhanced particle swarm optimization (EPSO) algorithm and edge\naccess strategy to develop a low complexity localization-oriented adaptive\ntrajectory planning algorithm. Simulation results demonstrate that our method\noutperforms other baseline algorithms, enabling faster localization without\ncompromising localization accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.07256v1"
    },
    {
        "title": "Agent-Based Modeling of C. Difficile Spread in Hospitals: Assessing\n  Contribution of High-Touch vs. Low-Touch Surfaces and Inoculations'\n  Containment Impact",
        "authors": [
            "Sina Abdidizaji",
            "Ali Khodabandeh Yalabadi",
            "Mehdi Yazdani-Jahromi",
            "Ozlem Ozmen Garibay",
            "Ivan Garibay"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Health issues and pandemics remain paramount concerns in the contemporary\nera. Clostridioides Difficile Infection (CDI) stands out as a critical\nhealthcare-associated infection with global implications. Effectively\nunderstanding the mechanisms of infection dissemination within healthcare units\nand hospitals is imperative to implement targeted containment measures. In this\nstudy, we address the limitations of prior research by Sulyok et al., where\nthey delineated two distinct categories of surfaces as high-touch and low-touch\nfomites, and subsequently evaluated the viral spread contribution of each\nsurface utilizing mathematical modeling and Ordinary Differential Equations\n(ODE). Acknowledging the indispensable role of spatial features and\nheterogeneity in the modeling of hospital and healthcare settings, we employ\nagent-based modeling to capture new insights. By incorporating spatial\nconsiderations and heterogeneous patients, we explore the impact of high-touch\nand low-touch surfaces on contamination transmission between patients.\nFurthermore, the study encompasses a comprehensive assessment of various\ncleaning protocols, with differing intervals and detergent cleaning efficacies,\nin order to identify the most optimal cleaning strategy and the most important\nfactor amidst the array of alternatives. Our results indicate that, among\nvarious factors, the frequency of cleaning intervals is the most critical\nelement for controlling the spread of CDI in a hospital environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11656v1"
    },
    {
        "title": "Towards a satisfactory conversion of messages among agent-based\n  information systems",
        "authors": [
            "Idoia Berges",
            "Jesús Bermúdez",
            "Alfredo Goñi",
            "Arantza Illarramendi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Over the last years, there has been a change of perspective concerning the\nmanagement of information systems, since they are no longer isolated and need\nto communicate with others. However, from a semantic point of view, real\ncommunication is difficult to achieve due to the heterogeneity of the systems.\nWe present a proposal which, considering information systems are represented by\nsoftware agents, provides a framework that favours a semantic communication\namong them, overcoming the heterogeneity of their agent communication\nlanguages. The main components of the framework are a suite of ontologies --\nconceptualizing communication acts -- that will be used for generating the\ncommunication conversion, and an Event Calculus interpretation of the\ncommunications, which will be used for formalizing the notion of a satisfactory\nconversion. Moreover, we present a motivating example in order to complete the\nexplanation of the whole picture.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11823v1"
    },
    {
        "title": "Semantic Web Technology for Agent Communication Protocols",
        "authors": [
            "Idoia Berges",
            "Jesús Bermúdez",
            "Alfredo Goñi",
            "Arantza Illarramendi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  One relevant aspect in the development of the Semantic Web framework is the\nachievement of a real inter-agents communication capability at the semantic\nlevel. The agents should be able to communicate and understand each other using\nstandard communication protocols freely, that is, without needing a laborious a\npriori preparation, before the communication takes place. For that setting we\npresent in this paper a proposal that promotes to describe standard\ncommunication protocols using Semantic Web technology (specifically, OWL-DL and\nSWRL). Those protocols are constituted by communication acts. In our proposal\nthose communication acts are described as terms that belong to a communication\nacts ontology, that we have developed, called CommOnt. The intended semantics\nassociated to the communication acts in the ontology is expressed through\nsocial commitments that are formalized as fluents in the Event Calculus. In\nsummary, OWL-DL reasoners and rule engines help in our proposal for reasoning\nabout protocols. We define some comparison relationships (dealing with notions\nof equivalence and specialization) between protocols used by agents from\ndifferent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11841v1"
    },
    {
        "title": "Transcending To Notions",
        "authors": [
            "Sama Sai Karthik",
            "Jayati Deshmukh",
            "Janvi Chhabra",
            "Arpitha Malavalli",
            "Srinath Srinivasa"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Social identities play an important role in the dynamics of human societies,\nand it can be argued that some sense of identification with a larger cause or\nidea plays a critical role in making humans act responsibly. Often social\nactivists strive to get populations to identify with some cause or notion --\nlike green energy, diversity, etc. in order to bring about desired social\nchanges. We explore the problem of designing computational models for social\nidentities in the context of autonomous AI agents. For this, we propose an\nagent model that enables agents to identify with certain notions and show how\nthis affects collective outcomes. We also contrast between associations of\nidentity with rational preferences. The proposed model is simulated in an\napplication context of urban mobility, where we show how changes in social\nidentity affect mobility patterns and collective outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12159v2"
    },
    {
        "title": "Backpropagation Through Agents",
        "authors": [
            "Zhiyuan Li",
            "Wenshuai Zhao",
            "Lijun Wu",
            "Joni Pajarinen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  A fundamental challenge in multi-agent reinforcement learning (MARL) is to\nlearn the joint policy in an extremely large search space, which grows\nexponentially with the number of agents. Moreover, fully decentralized policy\nfactorization significantly restricts the search space, which may lead to\nsub-optimal policies. In contrast, the auto-regressive joint policy can\nrepresent a much richer class of joint policies by factorizing the joint policy\ninto the product of a series of conditional individual policies. While such\nfactorization introduces the action dependency among agents explicitly in\nsequential execution, it does not take full advantage of the dependency during\nlearning. In particular, the subsequent agents do not give the preceding agents\nfeedback about their decisions. In this paper, we propose a new framework\nBack-Propagation Through Agents (BPTA) that directly accounts for both agents'\nown policy updates and the learning of their dependent counterparts. This is\nachieved by propagating the feedback through action chains. With the proposed\nframework, our Bidirectional Proximal Policy Optimisation (BPPO) outperforms\nthe state-of-the-art methods. Extensive experiments on matrix games,\nStarCraftII v2, Multi-agent MuJoCo, and Google Research Football demonstrate\nthe effectiveness of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12574v1"
    },
    {
        "title": "STEMFold: Stochastic Temporal Manifold for Multi-Agent Interactions in\n  the Presence of Hidden Agents",
        "authors": [
            "Hemant Kumawat",
            "Biswadeep Chakraborty",
            "Saibal Mukhopadhyay"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Learning accurate, data-driven predictive models for multiple interacting\nagents following unknown dynamics is crucial in many real-world physical and\nsocial systems. In many scenarios, dynamics prediction must be performed under\nincomplete observations, i.e., only a subset of agents are known and observable\nfrom a larger topological system while the behaviors of the unobserved agents\nand their interactions with the observed agents are not known. When only\nincomplete observations of a dynamical system are available, so that some\nstates remain hidden, it is generally not possible to learn a closed-form model\nin these variables using either analytic or data-driven techniques. In this\nwork, we propose STEMFold, a spatiotemporal attention-based generative model,\nto learn a stochastic manifold to predict the underlying unmeasured dynamics of\nthe multi-agent system from observations of only visible agents. Our analytical\nresults motivate STEMFold design using a spatiotemporal graph with time anchors\nto effectively map the observations of visible agents to a stochastic manifold\nwith no prior information about interaction graph topology. We empirically\nevaluated our method on two simulations and two real-world datasets, where it\noutperformed existing networks in predicting complex multiagent interactions,\neven with many unobserved agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14522v2"
    },
    {
        "title": "A mechanism for discovering semantic relationships among agent\n  communication protocols",
        "authors": [
            "Idoia Berges",
            "Jesús Bermúdez",
            "Alfredo Goñi",
            "Arantza Illarramendi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  One relevant aspect in the development of the Semantic Web framework is the\nachievement of a real inter-agents communication capability at the semantic\nlevel. Agents should be able to communicate with each other freely using\ndifferent communication protocols, constituted by communication acts. For that\nscenario, we introduce in this paper an efficient mechanism presenting the\nfollowing main features: - It promotes the description of the communication\nacts of protocols as classes that belong to a communication acts ontology, and\nassociates to those acts a social commitment semantics formalized through\npredicates in the Event Calculus. - It is sustained on the idea that different\nprotocols can be compared semantically by looking to the set of fluents\nassociated to each branch of the protocols. Those sets are generated using\nSemantic Web technology rules. - It discovers the following types of protocol\nrelationships: equivalence, specialization, restriction, prefix, suffix, infix\nand complement_to_infix.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16216v1"
    },
    {
        "title": "Camouflage Adversarial Attacks on Multiple Agent Systems",
        "authors": [
            "Ziqing Lu",
            "Guanlin Liu",
            "Lifeng Lai",
            "Weiyu Xu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The multi-agent reinforcement learning systems (MARL) based on the Markov\ndecision process (MDP) have emerged in many critical applications. To improve\nthe robustness/defense of MARL systems against adversarial attacks, the study\nof various adversarial attacks on reinforcement learning systems is very\nimportant. Previous works on adversarial attacks considered some possible\nfeatures to attack in MDP, such as the action poisoning attacks, the reward\npoisoning attacks, and the state perception attacks. In this paper, we propose\na brand-new form of attack called the camouflage attack in the MARL systems. In\nthe camouflage attack, the attackers change the appearances of some objects\nwithout changing the actual objects themselves; and the camouflaged appearances\nmay look the same to all the targeted recipient (victim) agents. The\ncamouflaged appearances can mislead the recipient agents to misguided actions.\nWe design algorithms that give the optimal camouflage attacks minimizing the\nrewards of recipient agents. Our numerical and theoretical results show that\ncamouflage attacks can rival the more conventional, but likely more difficult\nstate perception attacks. We also investigate cost-constrained camouflage\nattacks and showed numerically how cost budgets affect the attack performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.17405v1"
    },
    {
        "title": "Anytime Multi-Agent Path Finding using Operation Parallelism in Large\n  Neighborhood Search",
        "authors": [
            "Shao-Hung Chan",
            "Zhe Chen",
            "Dian-Lun Lin",
            "Yue Zhang",
            "Daniel Harabor",
            "Tsung-Wei Huang",
            "Sven Koenig",
            "Thomy Phan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Path Finding (MAPF) is the problem of finding a set of\ncollision-free paths for multiple agents in a shared environment while\nminimizing the sum of travel time. Since solving the MAPF problem optimally is\nNP-hard, anytime algorithms based on Large Neighborhood Search (LNS) are\npromising to find good-quality solutions in a scalable way by iteratively\ndestroying and repairing the paths. We propose Destroy-Repair Operation\nParallelism for LNS (DROP-LNS), a parallel framework that performs multiple\ndestroy and repair operations concurrently to explore more regions of the\nsearch space within a limited time budget. Unlike classic MAPF approaches,\nDROP-LNS can exploit parallelized hardware to improve the solution quality. We\nalso formulate two variants of parallelism and conduct experimental\nevaluations. The results show that DROP-LNS significantly outperforms the\nstate-of-the-art and the variants.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01961v1"
    },
    {
        "title": "Quantifying Population Exposure to Long-term PM10: A City-wide\n  Agent-based Assessment",
        "authors": [
            "Hyesop Shin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This study evaluates the health effects of long-term exposure to PM10 in\nSeoul. Building on the preliminary model Shin and Bithell (2019), an in-silico\nagent-based model (ABM) is used to simulate the travel patterns of individuals\naccording to their origins and destinations. During the simulation, each\nperson, with their inherent socio-economic attributes and allocated origin and\ndestination location, is assumed to commute to and from the same places for 10\nconsecutive years. A nominal measure of their health is set to decrease\nwhenever the concentration of PM10 exceeds the national standard. Sensitivity\nanalysis on calibrated parameters reveals increased vulnerability among certain\ndemographic groups, particularly those aged over 65 and under 15, with a\nsignificant health decline associated with road proximity. The study reveals a\nsubstantial health disparity after 7,000 simulation ticks (equivalent to 10\nyears), especially under scenarios of a 3% annual increase in pollution levels.\nLong-term exposure to PM10 has a significant impact on health vulnerabilities,\ndespite initial resilience being minimal. The study emphasises the importance\nof future research that takes into account different pollution thresholds as\nwell as more detailed models of population dynamics and pollution generation in\norder to better understand and mitigate the health effects of air pollution on\ndiverse urban populations.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.05029v1"
    },
    {
        "title": "Enriched multi-agent middleware for building rule-based distributed\n  security solutions for IoT environments",
        "authors": [
            "Francisco José Aguayo-Canela",
            "Héctor Alaiz-Moretón",
            "María Teresa García-Ordás",
            "José Alberto Benítez-Andrades",
            "Carmen Benavides",
            "Isaías García-Rodríguez"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The increasing number of connected devices and the complexity of Internet of\nThings (IoT) ecosystems are demanding new architectures for managing and\nsecuring these networked environments. Intrusion Detection Systems (IDS) are\nsecurity solutions that help to detect and mitigate the threats that IoT\nsystems face, but there is a need for new IDS strategies and architectures.\nThis paper describes a development environment that allows the programming and\ndebugging of distributed, rule-based multi-agent IDS solutions. The proposed\nsolution consists in the integration of a rule engine into the agent, the use\nof a specialized, wrapping agent class with a graphical user interface for\nprogramming and debugging purposes, and a mechanism for the incremental\ncomposition of behaviors. A comparative study and an example IDS are used to\ntest and show the suitability and validity of the approach. The JADE\nmulti-agent middleware has been used for the practical implementations.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.09499v1"
    },
    {
        "title": "Middleware-based multi-agent development environment for building and\n  testing distributed intelligent systems",
        "authors": [
            "Francisco José Aguayo-Canela",
            "Héctor Alaiz-Moretón",
            "María Teresa García-Ordás",
            "José Alberto Benítez-Andrades",
            "Carmen Benavides",
            "Paulo Novais",
            "Isaías García-Rodríguez"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The spread of the Internet of Things (IoT) is demanding new, powerful\narchitectures for handling the huge amounts of data produced by the IoT\ndevices. In many scenarios, many existing isolated solutions applied to IoT\ndevices use a set of rules to detect, report and mitigate malware activities or\nthreats. This paper describes a development environment that allows the\nprogramming and debugging of such rule-based multi-agent solutions. The\nsolution consists of the integration of a rule engine into the agent, the use\nof a specialized, wrapping agent class with a graphical user interface for\nprogramming and testing purposes, and a mechanism for the incremental\ncomposition of behaviors. Finally, a set of examples and a comparative study\nwere accomplished to test the suitability and validity of the approach. The\nJADE multi-agent middleware has been used for the practical implementation of\nthe approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.10385v1"
    },
    {
        "title": "Adaptive Decision-Making for Autonomous Vehicles: A Learning-Enhanced\n  Game-Theoretic Approach in Interactive Environments",
        "authors": [
            "Heye Huang",
            "Jinxin Liu",
            "Guanya Shi",
            "Shiyue Zhao",
            "Boqi Li",
            "Jianqiang Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper proposes an adaptive behavioral decision-making method for\nautonomous vehicles (AVs) focusing on complex merging scenarios. Leveraging\nprinciples from non-cooperative game theory, we develop a vehicle interaction\nbehavior model that defines key traffic elements and integrates a\nmultifactorial reward function. Maximum entropy inverse reinforcement learning\n(IRL) is employed for behavior model parameter optimization. Optimal matching\nparameters can be obtained using the interaction behavior feature vector and\nthe behavior probabilities output by the vehicle interaction model. Further, a\nbehavioral decision-making method adapted to dynamic environments is proposed.\nBy establishing a mapping model between multiple environmental variables and\nmodel parameters, it enables parameters online learning and recognition, and\nachieves to output interactive behavior probabilities of AVs. Quantitative\nanalysis employing naturalistic driving datasets (highD and exiD) and\nreal-vehicle test data validates the model's high consistency with human\ndecision-making. In 188 tested interaction scenarios, the average human-like\nsimilarity rate is 81.73%, with a notable 83.12% in the highD dataset.\nFurthermore, in 145 dynamic interactions, the method matches human decisions at\n77.12%, with 6913 consistence instances. Moreover, in real-vehicle tests, a\n72.73% similarity with 0% safety violations are obtained. Results demonstrate\nthe effectiveness of our proposed method in enabling AVs to make informed\nadaptive behavior decisions in interactive environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11467v2"
    },
    {
        "title": "Online Physical Enhanced Residual Learning for Connected Autonomous\n  Vehicles Platoon Centralized Control",
        "authors": [
            "Hang Zhou",
            "Heye Huang",
            "Peng Zhang",
            "Haotian Shi",
            "Keke Long",
            "Xiaopeng Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper introduces an online physical enhanced residual learning (PERL)\nframework for Connected Autonomous Vehicles (CAVs) platoon, aimed at addressing\nthe challenges posed by the dynamic and unpredictable nature of traffic\nenvironments. The proposed framework synergistically combines a physical model,\nrepresented by Model Predictive Control (MPC), with data-driven online\nQ-learning. The MPC controller, enhanced for centralized CAV platoons, employs\nvehicle velocity as a control input and focuses on multi-objective cooperative\noptimization. The learning-based residual controller enriches the MPC with\nprior knowledge and corrects residuals caused by traffic disturbances. The PERL\nframework not only retains the interpretability and transparency of\nphysics-based models but also significantly improves computational efficiency\nand control accuracy in real-world scenarios. The experimental results present\nthat the online Q-learning PERL controller, in comparison to the MPC controller\nand PERL controller with a neural network, exhibits significantly reduced\nposition and velocity errors. Specifically, the PERL's cumulative absolute\nposition and velocity errors are, on average, 86.73% and 55.28% lower than the\nMPC's, and 12.82% and 18.83% lower than the neural network-based PERL's, in\nfour tests with different reference trajectories and errors. The results\ndemonstrate our advanced framework's superior accuracy and quick convergence\ncapabilities, proving its effectiveness in maintaining platoon stability under\ndiverse conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11468v1"
    },
    {
        "title": "Navigating simplicity and complexity of social-ecological systems\n  through a dialog between dynamical systems and agent-based models",
        "authors": [
            "Sonja Radosavljevic",
            "Udita Sanga",
            "Maja Schlüter"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Social-ecological systems research aims to understand the nature of\nsocial-ecological phenomena, to find ways to foster or manage conditions under\nwhich desired phenomena occur or to reduce the negative consequences of\nundesirable phenomena. Such challenges are often addressed using dynamical\nsystems models (DSM) or agent-based models (ABM). Here we develop an iterative\nprocedure for combining DSM and ABM to leverage their strengths and gain\ninsights that surpass insights obtained by each approach separately. The\nprocedure uses results of an ABM as inputs for a DSM development. In the\nfollowing steps, results of the DSM analyses guide future analysis of the ABM\nand vice versa. This dialogue, more than having a tight connection between the\nmodels, enables pushing the research frontier, expanding the set of research\nquestions and insights. We illustrate our method with the example of poverty\ntraps and innovation in agricultural systems, but our conclusions are general\nand can be applied to other DSM-ABM combinations.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.12086v2"
    },
    {
        "title": "Distributed Finite-time Differentiator for Multi-agent Systems Under\n  Directed Graph",
        "authors": [
            "Weile Chen",
            "Haibo Du",
            "Shihua Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper proposes a new distributed finite-time differentiator (DFD) for\nmulti-agent systems (MAS) under directed graph, which extends the\ndifferentiator algorithm from the centralized case to the distributed case by\nonly using relative/absolute position information. By skillfully constructing a\nLyapunov function, the finite-time stability of the closed-loop system under\nDFD is proved. Inspired by the duality principle of control theory, a\ndistributed continuous finite-time output consensus algorithm extended from DFD\nfor a class of leader-follower MAS is provided, which not only completely\nsuppresses disturbance, but also avoids chattering. Finally, several simulation\nexamples are given to verify the effectiveness of the DFD.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.16260v1"
    },
    {
        "title": "Navigating Complexity: Orchestrated Problem Solving with Multi-Agent\n  LLMs",
        "authors": [
            "Sumedh Rasal",
            "E. J. Hauer"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nsolving various tasks, yet they often struggle with comprehensively addressing\ncomplex and vague problems. Existing approaches, including multi-agent LLM\nsystems, offer solutions to certain challenges but still require manual setup\nand lack scalability. To address this gap, we propose a novel approach\nleveraging decomposition to enable LLMs to tackle vague problems effectively.\n  Our approach involves an orchestrating LLM that interacts with users to\nunderstand the problem and then decomposes it into tangible sub-problems.\nInstead of expecting the LLM to solve the entire problem in one go, we train it\nto ask follow-up questions to gain a deeper understanding of the user's\nrequirements. Once the problem is adequately understood, the orchestrating LLM\ndivides it into smaller, manageable sub-problems. Each sub-problem is then\nassigned to specialized LLM agents or non-LLM functions for resolution. These\nagents work in parallel to solve their respective sub-problems, with the\norchestrating LLM overseeing the process and compiling the solutions into a\ncomprehensive answer for the user. By adopting this decomposition approach, we\nalleviate the constraints imposed by token limitations on LLM outputs and\nempower them to provide nuanced solutions to complex and ambiguous problems.\n  Through our approach, we aim to enable LLMs to think and operate more like\nhumans, breaking down complex problems into manageable parts and\ncollaboratively solving them. This not only enhances the problem-solving\ncapabilities of LLMs but also offers a scalable and efficient method for\naddressing a wide range of real-world challenges.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.16713v2"
    },
    {
        "title": "A Multi-agent Reinforcement Learning Study of Evolution of Communication\n  and Teaching under Libertarian and Utilitarian Governing Systems",
        "authors": [
            "Aslan S. Dizaji"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Laboratory experiments have shown that communication plays an important role\nin solving social dilemmas. Here, by extending the AI-Economist, a mixed motive\nmulti-agent reinforcement learning environment, I intend to find an answer to\nthe following descriptive question: which governing system does facilitate the\nemergence and evolution of communication and teaching among agents? To answer\nthis question, the AI-Economist is extended by a voting mechanism to simulate\nthree different governing systems across individualistic-collectivistic axis,\nfrom full-libertarian to Full-Utilitarian governing systems. Moreover, the\nAI-Economist is further extended to include communication with possible\nmisalignment, a variant of signalling game, by letting agents to build houses\ntogether if they are able to name mutually complement material resources by the\nsame letter. Moreover, another extension is made to the AI-Economist to include\nteaching with possible misalignment, again a variant of signalling game, by\nletting half the agents as teachers who know how to use mutually complement\nmaterial resources to build houses but are not capable of building actual\nhouses, and the other half as students who do not have this information but are\nable to actually build those houses if teachers teach them. I found a strong\nevidence that collectivistic environment such as Full-Utilitarian system is\nmore favourable for the emergence of communication and teaching, or more\nprecisely, evolution of language alignment. Moreover, I found some evidence\nthat evolution of language alignment through communication and teaching under\ncollectivistic governing systems makes individuals more advantageously inequity\naverse. As a result, there is a positive correlation between evolution of\nlanguage alignment and equality in the society.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.02369v1"
    },
    {
        "title": "Cooperative Task Execution in Multi-Agent Systems",
        "authors": [
            " Karishma",
            "Shrisha Rao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We propose a multi-agent system that enables groups of agents to collaborate\nand work autonomously to execute tasks. Groups can work in a decentralized\nmanner and can adapt to dynamic changes in the environment. Groups of agents\nsolve assigned tasks by exploring the solution space cooperatively based on the\nhighest reward first. The tasks have a dependency structure associated with\nthem. We rigorously evaluated the performance of the system and the individual\ngroup performance using centralized and decentralized control approaches for\ntask distribution. Based on the results, the centralized approach is more\nefficient for systems with a less-dependent system $G_{18}$ (a well-known\nprogram graph that contains $18$ nodes with few links), while the decentralized\napproach performs better for systems with a highly-dependent system $G_{40}$ (a\nprogram graph that contains $40$ highly interlinked nodes). We also evaluated\ntask allocation to groups that do not have interdependence. Our findings reveal\nthat there was significantly less difference in the number of tasks allocated\nto each group in a less-dependent system than in a highly-dependent one. The\nexperimental results showed that a large number of small-size cooperative\ngroups of agents unequivocally improved the system's performance compared to a\nsmall number of large-size cooperative groups of agents. Therefore, it is\nessential to identify the optimal group size for a system to enhance its\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.04370v2"
    },
    {
        "title": "Distributed Multi-objective Optimization in Cyber-Physical Energy\n  Systems",
        "authors": [
            "Sanja Stark",
            "Emilie Frost",
            "Marvin Nebel-Wenner"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Managing complex Cyber-Physical Energy Systems (CPES) requires solving\nvarious optimization problems with multiple objectives and constraints. As\ndistributed control architectures are becoming more popular in CPES for certain\ntasks due to their flexibility, robustness, and privacy protection,\nmulti-objective optimization must also be distributed. For this purpose, we\npresent MO-COHDA, a fully distributed, agent-based algorithm, for solving\nmulti-objective optimization problems of CPES. MO-COHDA allows an easy and\nflexible adaptation to different use cases and integration of custom\nfunctionality. To evaluate the effectiveness of MO-COHDA, we compare it to a\ncentral NSGA-2 algorithm using multi-objective benchmark functions from the ZDT\nproblem suite. The results show that MO-COHDA can approximate the reference\nfront of the benchmark problems well and is suitable for solving\nmulti-objective optimization problems. In addition, an example use case of\nscheduling a group of generation units while optimizing three different\nobjectives was evaluated to show how MO-COHDA can be easily applied to\nreal-world optimization problems in CPES.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.04627v1"
    },
    {
        "title": "Engineering consensus in static networks with unknown disruptors",
        "authors": [
            "Agathe Bouis",
            "Christopher Lowe",
            "Ruaridh A. Clark",
            "Malcolm Macdonald"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Distributed control increases system scalability, flexibility, and\nredundancy. Foundational to such decentralisation is consensus formation, by\nwhich decision-making and coordination are achieved. However, decentralised\nmulti-agent systems are inherently vulnerable to disruption. To develop a\nresilient consensus approach, inspiration is taken from the study of social\nsystems and their dynamics; specifically, the Deffuant Model. A dynamic\nalgorithm is presented enabling efficient consensus to be reached with an\nunknown number of disruptors present within a multi-agent system. By inverting\ntypical social tolerance, agents filter out extremist non-standard opinions\nthat would drive them away from consensus. This approach allows distributed\nsystems to deal with unknown disruptions, without knowledge of the network\ntopology or the numbers and behaviours of the disruptors. A disruptor-agnostic\nalgorithm is particularly suitable to real-world applications where this\ninformation is typically unknown. Faster and tighter convergence can be\nachieved across a range of scenarios with the social dynamics inspired\nalgorithm, compared with standard Mean-Subsequence-Reduced-type methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.05272v1"
    },
    {
        "title": "Invariant Properties of Linear-Iterative Distributed Averaging\n  Algorithms and Application to Error Detection",
        "authors": [
            "Christoforos N. Hadjicostis",
            "Alejandro D. Dominguez-Garcia"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We consider the problem of average consensus in a distributed system\ncomprising a set of nodes that can exchange information among themselves. We\nfocus on a class of algorithms for solving such a problem whereby each node\nmaintains a state and updates it iteratively as a linear combination of the\nstates maintained by its in-neighbors, i.e., nodes from which it receives\ninformation directly. Averaging algorithms within this class can be thought of\nas discrete-time linear time-varying systems without external driving inputs\nand whose state matrix is column stochastic. As a result, the algorithms\nexhibit a global invariance property in that the sum of the state variables\nremains constant at all times. In this paper, we report on another invariance\nproperty for the aforementioned class of averaging algorithms. This property is\nlocal to each node and reflects the conservation of certain quantities\ncapturing an aggregate of all the values received by a node from its\nin-neighbors and all the values sent by said node to its out-neighbors (i.e.,\nnodes to which it sends information directly) throughout the execution of the\naveraging algorithm. We show how this newly-discovered invariant can be\nleveraged for detecting errors while executing the averaging algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.06007v1"
    },
    {
        "title": "IDEAS: Information-Driven EV Admission in Charging Station Considering\n  User Impatience to Improve QoS and Station Utilization",
        "authors": [
            "Animesh Chattopadhyay",
            "Subrat Kar"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Our work delves into user behaviour at Electric Vehicle(EV) charging stations\nduring peak times, particularly focusing on how impatience drives balking (not\njoining queues) and reneging (leaving queues prematurely). We introduce an\nAgent-based simulation framework that incorporates user optimism levels\n(pessimistic, standard, and optimistic) in the queue dynamics. Unlike previous\nwork, this framework highlights the crucial role of human behaviour in shaping\nstation efficiency for peak demand. The simulation reveals a key issue: balking\noften occurs due to a lack of queue insights, creating user dilemmas. To\naddress this, we propose real-time sharing of wait time metrics with arriving\nEV users at the station. This ensures better Quality of Service (QoS) with\nuser-informed queue joining and demonstrates significant reductions in reneging\n(up to 94%) improving the charging operation. Further analysis shows that\ncharging speed decreases significantly beyond 80%, but most users prioritize\nfull charges due to range anxiety, leading to a longer queue. To address this,\nwe propose a two-mode, two-port charger design with power-sharing options. This\nallows users to fast-charge to 80% and automatically switch to slow charging,\nenabling fast charging on the second port. Thus, increasing fast charger\navailability and throughput by up to 5%. As the mobility sector transitions\ntowards intelligent traffic, our modelling framework, which integrates human\ndecision-making within automated planning, provides valuable insights for\noptimizing charging station efficiency and improving the user experience. This\napproach is particularly relevant during the introduction phase of new\nstations, when historical data might be limited.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.06223v1"
    },
    {
        "title": "The Geometry of Cyclical Social Trends",
        "authors": [
            "Bernard Chazelle",
            "Kritkorn Karntikoon",
            "Jakob Nogler"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We investigate the emergence of periodic behavior in opinion dynamics and its\nunderlying geometry. For this, we use a bounded-confidence model with\ncontrarian agents in a convolution social network. This means that agents adapt\ntheir opinions by interacting with their neighbors in a time-varying social\nnetwork. Being contrarian, the agents are kept from reaching consensus. This is\nthe key feature that allows the emergence of cyclical trends. We show that the\nsystems either converge to nonconsensual equilibrium or are attracted to\nperiodic or quasi-periodic orbits. We bound the dimension of the attractors and\nthe period of cyclical trends. We exhibit instances where each orbit is dense\nand uniformly distributed within its attractor. We also investigate the case of\nrandomly changing social networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.06376v1"
    },
    {
        "title": "V2AIX: A Multi-Modal Real-World Dataset of ETSI ITS V2X Messages in\n  Public Road Traffic",
        "authors": [
            "Guido Kueppers",
            "Jean-Pierre Busch",
            "Lennart Reiher",
            "Lutz Eckstein"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Connectivity is a main driver for the ongoing megatrend of automated\nmobility: future Cooperative Intelligent Transport Systems (C-ITS) will connect\nroad vehicles, traffic signals, roadside infrastructure, and even vulnerable\nroad users, sharing data and compute for safer, more efficient, and more\ncomfortable mobility. In terms of communication technology for realizing such\nvehicle-to-everything (V2X) communication, the WLAN-based peer-to-peer approach\n(IEEE 802.11p, ITS-G5 in Europe) competes with C-V2X based on cellular\ntechnologies (4G and beyond). Irrespective of the underlying communication\nstandard, common message interfaces are crucial for a common understanding\nbetween vehicles, especially from different manufacturers. Targeting this\nissue, the European Telecommunications Standards Institute (ETSI) has been\nstandardizing V2X message formats such as the Cooperative Awareness Message\n(CAM). In this work, we present V2AIX, a multi-modal real-world dataset of ETSI\nITS messages gathered in public road traffic, the first of its kind. Collected\nin measurement drives and with stationary infrastructure, we have recorded more\nthan 285 000 V2X messages from more than 2380 vehicles and roadside units in\npublic road traffic. Alongside a first analysis of the dataset, we present a\nway of integrating ETSI ITS V2X messages into the Robot Operating System (ROS).\nThis enables researchers to not only thoroughly analyze real-world V2X data,\nbut to also study and implement standardized V2X messages in ROS-based\nautomated driving applications. The full dataset is publicly available for\nnon-commercial use at v2aix.ika.rwth-aachen.de.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.10221v2"
    },
    {
        "title": "MARPF: Multi-Agent and Multi-Rack Path Finding",
        "authors": [
            "Hiroya Makino",
            "Yoshihiro Ohama",
            "Seigo Ito"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In environments where many automated guided vehicles (AGVs) operate, planning\nefficient, collision-free paths is essential. Related research has mainly\nfocused on environments with pre-defined passages, resulting in space\ninefficiency. We attempt to relax this assumption. In this study, we define\nmulti-agent and multi-rack path finding (MARPF) as the problem of planning\npaths for AGVs to convey target racks to their designated locations in\nenvironments without passages. In such environments, an AGV without a rack can\npass under racks, whereas one with a rack cannot pass under racks to avoid\ncollisions. MARPF entails conveying the target racks without collisions, while\nthe obstacle racks are relocated to prevent any interference with the target\nracks. We formulated MARPF as an integer linear programming problem in a\nnetwork flow. To distinguish situations in which an AGV is or is not loading a\nrack, the proposed method introduces two virtual layers into the network. We\noptimized the AGVs' movements to move obstacle racks and convey the target\nracks. The formulation and applicability of the algorithm were validated\nthrough numerical experiments. The results indicated that the proposed\nalgorithm addressed issues in environments with dense racks.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.12376v3"
    },
    {
        "title": "Optimizing Ride-Pooling Revenue: Pricing Strategies and Driver-Traveller\n  Dynamics",
        "authors": [
            "Usman Akhtar",
            "Farnoud Ghasemi",
            "Rafal Kucharski"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Ride-pooling, to gain momentum, needs to be attractive for all the parties\ninvolved. This includes also drivers, who are naturally reluctant to serve\npooled rides. This can be controlled by the platform's pricing strategy, which\ncan stimulate drivers to serve pooled rides. Here, we propose an agent-based\nframework, where drivers serve rides that maximise their utility. We simulate a\nseries of scenarios in Delft and compare three strategies. Our results show\nthat drivers, when they maximize their profits, earn more than in both the\nsolo-rides and only-pooled rides scenarios. This shows that serving pooled\nrides can be beneficial as well for drivers, yet typically not all pooled rides\nare attractive for drivers. The proposed framework may be further applied to\npropose discriminative pricing in which the full potential of ride-pooling is\nexploited, with benefits for the platform, travellers, and (which is novel\nhere) to the drivers.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.13384v1"
    },
    {
        "title": "Multi-agent Reinforcement Traffic Signal Control based on Interpretable\n  Influence Mechanism and Biased ReLU Approximation",
        "authors": [
            "Zhiyue Luo",
            "Jun Xu",
            "Fanglin Chen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Traffic signal control is important in intelligent transportation system, of\nwhich cooperative control is difficult to realize but yet vital. Many methods\nmodel multi-intersection traffic networks as grids and address the problem\nusing multi-agent reinforcement learning (RL). Despite these existing studies,\nthere is an opportunity to further enhance our understanding of the\nconnectivity and globality of the traffic networks by capturing the\nspatiotemporal traffic information with efficient neural networks in deep RL.\nIn this paper, we propose a novel multi-agent actor-critic framework based on\nan interpretable influence mechanism with a centralized learning and\ndecentralized execution method. Specifically, we first construct an\nactor-critic framework, for which the piecewise linear neural network (PWLNN),\nnamed biased ReLU (BReLU), is used as the function approximator to obtain a\nmore accurate and theoretically grounded approximation. Finally, our proposed\nframework is validated on two synthetic traffic networks to coordinate signal\ncontrol between intersections, achieving lower traffic delays across the entire\ntraffic network compared to state-of-the-art (SOTA) performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.13639v1"
    },
    {
        "title": "Motion Prediction of Multi-agent systems with Multi-view clustering",
        "authors": [
            "Anegi James",
            "Efstathios Bakolas"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper presents a method for future motion prediction of multi-agent\nsystems by including group formation information and future intent. Formation\nof groups depends on a physics-based clustering method that follows the\nagglomerative hierarchical clustering algorithm. We identify clusters that\nincorporate the minimum cost-to-go function of a relevant optimal control\nproblem as a metric for clustering between the groups among agents, where\ngroups with similar associated costs are assumed to be likely to move together.\nThe cost metric accounts for proximity to other agents as well as the intended\ngoal of each agent. An unscented Kalman filter based approach is used to update\nthe established clusters as well as add new clusters when new information is\nobtained. Our approach is verified through non-trivial numerical simulations\nimplementing the proposed algorithm on different datasets pertaining to a\nvariety of scenarios and agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.13905v1"
    },
    {
        "title": "An Agent-Centric Perspective on Norm Enforcement and Sanctions",
        "authors": [
            "Elena Yan",
            "Luis G. Nardin",
            "Jomi F. Hübner",
            "Olivier Boissier"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In increasingly autonomous and highly distributed multi-agent systems,\ncentralized coordination becomes impractical and raises the need for governance\nand enforcement mechanisms from an agent-centric perspective. In our conceptual\nview, sanctioning norm enforcement is part of this agent-centric approach and\nthey aim at promoting norm compliance while preserving agents' autonomy. The\nfew works dealing with sanctioning norm enforcement and sanctions from the\nagent-centric perspective present limitations regarding the representation of\nsanctions and the comprehensiveness of their norm enforcement process. To\naddress these drawbacks, we propose the NPL(s), an extension of the NPL\nnormative programming language enriched with the representation of norms and\nsanctions as first-class abstractions. We also propose a BDI normative agent\narchitecture embedding an engine for processing the NPL(s) language and a set\nof capabilities for approaching more comprehensively the sanctioning norm\nenforcement process. We apply our contributions in a case study for improving\nthe robustness of agents' decision-making in a production automation system.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.15128v1"
    },
    {
        "title": "Team Coordination on Graphs: Problem, Analysis, and Algorithms",
        "authors": [
            "Yanlin Zhou",
            "Manshi Limbu",
            "Gregory J. Stein",
            "Xuan Wang",
            "Daigo Shishika",
            "Xuesu Xiao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Team Coordination on Graphs with Risky Edges (TCGRE) is a recently emerged\nproblem, in which a robot team collectively reduces graph traversal cost\nthrough support from one robot to another when the latter traverses a risky\nedge. Resembling the traditional Multi-Agent Path Finding (MAPF) problem, both\nclassical and learning-based methods have been proposed to solve TCGRE,\nhowever, they lacked either computational efficiency or optimality assurance.\nIn this paper, we reformulate TCGRE as a constrained optimization problem and\nperform a rigorous mathematical analysis. Our theoretical analysis shows the\nNP-hardness of TCGRE by reduction from the Maximum 3D Matching problem and that\nefficient decomposition is a key to tackle this combinatorial optimization\nproblem. Furthermore, we design three classes of algorithms to solve TCGRE,\ni.e., Joint State Graph (JSG) based, coordination based, and receding-horizon\nsub-team based solutions. Each of these proposed algorithms enjoy different\nprovable optimality and efficiency characteristics that are demonstrated in our\nextensive experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.15946v3"
    },
    {
        "title": "Social Deliberation vs. Social Contracts in Self-Governing Voluntary\n  Organisations",
        "authors": [
            "Matthew Scott",
            "Asimina Mertzani",
            "Ciske Smit",
            "Stefan Sarkadi",
            "Jeremy Pitt"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Self-organising multi-agent systems regulate their components' behaviour\nvoluntarily, according to a set of socially-constructed, mutually-agreed, and\nmutable social arrangements. In some systems, these arrangements may be applied\nwith a frequency, at a scale and within implicit cost constraints such that\nperformance becomes a pressing issue. This paper introduces the\n\\textit{Megabike Scenario}, which consists of a negotiated agreement on a\nrelatively 'large' set of conventional rules, 'frequent' 'democratic'\ndecision-making according to those rules, and a resource-bounded imperative to\nreach 'correct' decisions. A formalism is defined for effective rule\nrepresentation and processing in the scenario, and is evaluated against five\ninterleaved socio-functional requirements. System performance is also evaluated\nempirically through simulation. We conclude that to self-organise their social\narrangements, agents need some awareness of their own limitations and the value\nof compromise.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.16329v1"
    },
    {
        "title": "Norm Violation Detection in Multi-Agent Systems using Large Language\n  Models: A Pilot Study",
        "authors": [
            "Shawn He",
            "Surangika Ranathunga",
            "Stephen Cranefield",
            "Bastin Tony Roy Savarimuthu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Norms are an important component of the social fabric of society by\nprescribing expected behaviour. In Multi-Agent Systems (MAS), agents\ninteracting within a society are equipped to possess social capabilities such\nas reasoning about norms and trust. Norms have long been of interest within the\nNormative Multi-Agent Systems community with researchers studying topics such\nas norm emergence, norm violation detection and sanctioning. However, these\nstudies have some limitations: they are often limited to simple domains, norms\nhave been represented using a variety of representations with no standard\napproach emerging, and the symbolic reasoning mechanisms generally used may\nsuffer from a lack of extensibility and robustness. In contrast, Large Language\nModels (LLMs) offer opportunities to discover and reason about norms across a\nlarge range of social situations. This paper evaluates the capability of LLMs\nto detecting norm violations. Based on simulated data from 80 stories in a\nhousehold context, with varying complexities, we investigated whether 10 norms\nare violated. For our evaluations we first obtained the ground truth from three\nhuman evaluators for each story. Then, the majority result was compared against\nthe results from three well-known LLM models (Llama 2 7B, Mixtral 7B and\nChatGPT-4). Our results show the promise of ChatGPT-4 for detecting norm\nviolations, with Mixtral some distance behind. Also, we identify areas where\nthese models perform poorly and discuss implications for future work.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.16517v2"
    },
    {
        "title": "A CRISP-DM-based Methodology for Assessing Agent-based Simulation Models\n  using Process Mining",
        "authors": [
            "Rob H. Bemthuis",
            "Ruben R. Govers",
            "Amin Asadi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Agent-based simulation (ABS) models are potent tools for analyzing complex\nsystems. However, understanding and validating ABS models can be a significant\nchallenge. To address this challenge, cutting-edge data-driven techniques offer\nsophisticated capabilities for analyzing the outcomes of ABS models. One such\ntechnique is process mining, which encompasses a range of methods for\ndiscovering, monitoring, and enhancing processes by extracting knowledge from\nevent logs. However, applying process mining to event logs derived from ABSs is\nnot trivial, and deriving meaningful insights from the resulting process models\nadds an additional layer of complexity. Although process mining is invaluable\nin extracting insights from ABS models, there is a lack of comprehensive\nmethodological guidance for its application in ABS evaluation in the research\nlandscape. In this paper, we propose a methodology, based on the CRoss-Industry\nStandard Process for Data Mining (CRISP-DM) methodology, to assess ABS models\nusing process mining techniques. We incorporate process mining techniques into\nthe stages of the CRISP-DM methodology, facilitating the analysis of ABS model\nbehaviors and their underlying processes. We demonstrate our methodology using\nan established agent-based model, Schelling model of segregation. Our results\nshow that our proposed methodology can effectively assess ABS models through\nproduced event logs, potentially paving the way for enhanced agent-based model\nvalidity and more insightful decision-making.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.01114v1"
    },
    {
        "title": "MEDIATE: Mutually Endorsed Distributed Incentive Acknowledgment Token\n  Exchange",
        "authors": [
            "Philipp Altmann",
            "Katharina Winter",
            "Michael Kölle",
            "Maximilian Zorn",
            "Thomy Phan",
            "Claudia Linnhoff-Popien"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Recent advances in multi-agent systems (MAS) have shown that incorporating\npeer incentivization (PI) mechanisms vastly improves cooperation. Especially in\nsocial dilemmas, communication between the agents helps to overcome sub-optimal\nNash equilibria. However, incentivization tokens need to be carefully selected.\nFurthermore, real-world applications might yield increased privacy requirements\nand limited exchange. Therefore, we extend the PI protocol for mutual\nacknowledgment token exchange (MATE) and provide additional analysis on the\nimpact of the chosen tokens. Building upon those insights, we propose mutually\nendorsed distributed incentive acknowledgment token exchange (MEDIATE), an\nextended PI architecture employing automatic token derivation via decentralized\nconsensus. Empirical results show the stable agreement on appropriate tokens\nyielding superior performance compared to static tokens and state-of-the-art\napproaches in different social dilemma environments with various reward\ndistributions.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.03431v1"
    },
    {
        "title": "No Panacea in Planning: Algorithm Selection for Suboptimal Multi-Agent\n  Path Finding",
        "authors": [
            "Weizhe Chen",
            "Zhihan Wang",
            "Jiaoyang Li",
            "Sven Koenig",
            "Bistra Dilkina"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Since more and more algorithms are proposed for multi-agent path finding\n(MAPF) and each of them has its strengths, choosing the correct one for a\nspecific scenario that fulfills some specified requirements is an important\ntask. Previous research in algorithm selection for MAPF built a standard\nworkflow and showed that machine learning can help. In this paper, we study\ngeneral solvers for MAPF, which further include suboptimal algorithms. We\npropose different groups of optimization objectives and learning tasks to\nhandle the new tradeoff between runtime and solution quality. We conduct\nextensive experiments to show that the same loss can not be used for different\ngroups of optimization objectives, and that standard computer vision models are\nno worse than customized architecture. We also provide insightful discussions\non how feature-sensitive pre-processing is needed for learning for MAPF, and\nhow different learning metrics are correlated to different learning tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.03554v1"
    },
    {
        "title": "The Power in Communication: Power Regularization of Communication for\n  Autonomy in Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Nancirose Piazza",
            "Vahid Behzadan",
            "Stefan Sarkadi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Communication plays a vital role for coordination in Multi-Agent\nReinforcement Learning (MARL) systems. However, misaligned agents can exploit\nother agents' trust and delegated power to the communication medium. In this\npaper, we propose power regularization as a method to limit the adverse effects\nof communication by misaligned agents, specifically communication which impairs\nthe performance of cooperative agents. Power is a measure of the influence one\nagent's actions have over another agent's policy. By introducing power\nregularization, we aim to allow designers to control or reduce agents'\ndependency on communication when appropriate, and make them more resilient to\nperformance deterioration due to misuses of communication. We investigate\nseveral environments in which power regularization can be a valuable capability\nfor learning different policies that reduce the effect of power dynamics\nbetween agents during communication.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.06387v1"
    },
    {
        "title": "Q-ITAGS: Quality-Optimized Spatio-Temporal Heterogeneous Task Allocation\n  with a Time Budget",
        "authors": [
            "Glen Neville",
            "Jiazhen Liu",
            "Sonia Chernova",
            "Harish Ravichandar"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Complex multi-objective missions require the coordination of heterogeneous\nrobots at multiple inter-connected levels, such as coalition formation,\nscheduling, and motion planning. The associated challenges are exacerbated when\nsolutions to these interconnected problems need to simultaneously maximize task\nperformance and respect practical constraints on time and resources. In this\nwork, we formulate a new class of spatiotemporal heterogeneous task allocation\nproblems that formalize these complexities. We then contribute a novel\nframework, named Quality-Optimized Incremental Task Allocation Graph Search\n(Q-ITAGS), to solve such problems. Q-ITAGS offers a flexible interleaved\nframework that i) explicitly models and optimizes the effect of the collective\ncapabilities on task performance via learnable trait-quality maps, and ii)\nrespects both resource and spatiotemporal constraints including a\nuser-specified time budget (i.e. maximum makespan). In addition to algorithmic\ncontributions, we derive theoretical suboptimality bounds in terms of task\nperformance that varies as a function of a single hyperparameter. Detailed\nexperiments involving a simulated emergency response task and a real-world\nvideo game dataset reveal that i) Q-ITAGS results in superior team performance\ncompared to a state-of-the-art method, while also respecting complex\nspatiotemporal and resource constraints, ii) Q-ITAGS efficiently learns\ntrait-quality maps to enable effective trade-off between task performance and\nresource constraints, and iii) Q-ITAGS suboptimality bounds consistently hold\nin practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.07902v3"
    },
    {
        "title": "An Agent-Based Model of Elephant Crop Raid Dynamics in the\n  Periyar-Agasthyamalai Complex, India",
        "authors": [
            "Anjali Purathekandy",
            "Meera Anna Oommen",
            "Martin Wikelski",
            "Deepak N Subramani"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Human-wildlife conflict challenges conservation worldwide, which requires\ninnovative management solutions. We developed a prototype Agent-Based Model\n(ABM) to simulate interactions between humans and solitary bull Asian elephants\nin the Periyar-Agasthyamalai complex of the Western Ghats in Kerala, India. The\nmain challenges were the complex behavior of elephants and insufficient\nmovement data from the region. Using literature, expert insights, and field\nsurveys, we created a prototype behavior model that incorporates crop\nhabituation, thermoregulation, and aggression. We designed a four-step\ncalibration method to adapt relocation data from radio-tagged elephants in\nIndonesia to model elephant movements in the model domain. The ABM's structure,\nincluding the assumptions, submodels, and data usage are detailed following the\nOverview, Design concepts, Details protocol. The ABM simulates various food\navailability scenarios to study elephant behavior and environmental impact on\nspace use and conflict patterns. The results indicate that the wet months\nincrease conflict and thermoregulation significantly influences elephant\nmovements and crop raiding. Starvation and crop habituation intensify these\npatterns. This prototype ABM is an initial model that offers information on the\ndevelopment of a decision support system in wildlife management and will be\nfurther enhanced with layers of complexity and subtlety across various\ndimensions. Access the ABM at\nhttps://github.com/quest-lab-iisc/abm-elephant-project.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.09024v2"
    },
    {
        "title": "Mean Field Correlated Imitation Learning",
        "authors": [
            "Zhiyu Zhao",
            "Qirui Mi",
            "Ning Yang",
            "Xue Yan",
            "Haifeng Zhang",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We investigate multi-agent imitation learning (IL) within the framework of\nmean field games (MFGs), considering the presence of time-varying correlated\nsignals. Existing MFG IL algorithms assume demonstrations are sampled from Mean\nField Nash Equilibria (MFNE), limiting their adaptability to real-world\nscenarios. For example, in the traffic network equilibrium influenced by public\nrouting recommendations, recommendations introduce time-varying correlated\nsignals into the game, not captured by MFNE and other existing correlated\nequilibrium concepts. To address this gap, we propose Adaptive Mean Field\nCorrelated Equilibrium (AMFCE), a general equilibrium incorporating\ntime-varying correlated signals. We establish the existence of AMFCE under mild\nconditions and prove that MFNE is a subclass of AMFCE. We further propose\nCorrelated Mean Field Imitation Learning (CMFIL), a novel IL framework designed\nto recover the AMFCE, accompanied by a theoretical guarantee on the quality of\nthe recovered policy. Experimental results, including a real-world traffic flow\nprediction problem, demonstrate the superiority of CMFIL over state-of-the-art\nIL baselines, highlighting the potential of CMFIL in understanding large\npopulation behavior under correlated signals.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.09324v2"
    },
    {
        "title": "On the external concurrency of current BDI frameworks for MAS",
        "authors": [
            "Martina Baiardi",
            "Samuele Burattini",
            "Giovanni Ciatto",
            "Danilo Pianini",
            "Alessandro Ricci",
            "Andrea Omicini"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The execution of Belief-Desire-Intention (BDI) agents in a Multi-Agent System\n(MAS) can be practically implemented on top of low-level concurrency mechanisms\nthat impact on efficiency, determinism, and reproducibility. We argue that\ndevelopers should specify the MAS behaviour independently of the execution\nmodel, and choose or configure the concurrency model later on, according to the\nspecific needs of their target domain, leaving the MAS specification\nunaffected. We identify patterns for mapping the agent execution over the\nunderlying concurrency abstractions, and investigate which concurrency models\nare supported by some of the most commonly used BDI platforms. Although most\nframeworks support multiple concurrency models, we find that they mostly hide\nthem under the hood, making them opaque to the developer, and actually limiting\nthe possibility of fine-tuning the MAS.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.10397v2"
    },
    {
        "title": "Concurrency Model of BDI Programming Frameworks: Why Should We Control\n  It?",
        "authors": [
            "Martina Baiardi",
            "Samuele Burattini",
            "Giovanni Ciatto",
            "Danilo Pianini",
            "Andrea Omicini",
            "Alessandro Ricci"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We provide a taxonomy of concurrency models for BDI frameworks, elicited by\nanalysing state-of-the-art technologies, and aimed at helping both BDI\ndesigners and developers in making informed decisions. Comparison among BDI\ntechnologies w.r.t. concurrency models reveals heterogeneous support, and low\ncustomisability.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.10421v1"
    },
    {
        "title": "Circular Distribution of Agents using Convex Layers",
        "authors": [
            "Gautam Kumar",
            "Ashwini Ratnoo"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This article considers the problem of conflict-free distribution of agents on\na circular periphery encompassing all agents. The two key elements of the\nproposed policy include the construction of a set of convex layers (nested\nconvex polygons) using the initial positions of the agents, and a novel search\nspace region for each of the agents. The search space for an agent on a convex\nlayer is defined as the region enclosed between the lines passing through the\nagent's position and normal to its supporting edges. Guaranteeing\ncollision-free paths, a goal assignment policy designates a unique goal\nposition within the search space of an agent at the initial time itself,\nrequiring no further computation thereafter. In contrast to the existing\nliterature, this work presents a one-shot, collision-free solution to the\ncircular distribution problem by utilizing only the initial positions of the\nagents. Illustrative examples demonstrate the effectiveness of the proposed\npolicy.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.11351v2"
    },
    {
        "title": "JointPPO: Diving Deeper into the Effectiveness of PPO in Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Chenxing Liu",
            "Guizhong Liu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  While Centralized Training with Decentralized Execution (CTDE) has become the\nprevailing paradigm in Multi-Agent Reinforcement Learning (MARL), it may not be\nsuitable for scenarios in which agents can fully communicate and share\nobservations with each other. Fully centralized methods, also know as\nCentralized Training with Centralized Execution (CTCE) methods, can fully\nutilize observations of all the agents by treating the entire system as a\nsingle agent. However, traditional CTCE methods suffer from scalability issues\ndue to the exponential growth of the joint action space. To address these\nchallenges, in this paper we propose JointPPO, a CTCE method that uses Proximal\nPolicy Optimization (PPO) to directly optimize the joint policy of the\nmulti-agent system. JointPPO decomposes the joint policy into conditional\nprobabilities, transforming the decision-making process into a sequence\ngeneration task. A Transformer-based joint policy network is constructed,\ntrained with a PPO loss tailored for the joint policy. JointPPO effectively\nhandles a large joint action space and extends PPO to multi-agent setting in a\nclear and concise manner. Extensive experiments on the StarCraft Multi-Agent\nChallenge (SMAC) testbed demonstrate the superiority of JointPPO over strong\nbaselines. Ablation experiments and analyses are conducted to explores the\nfactors influencing JointPPO's performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.11831v2"
    },
    {
        "title": "Multi-AUV Cooperative Underwater Multi-Target Tracking Based on\n  Dynamic-Switching-enabled Multi-Agent Reinforcement Learning",
        "authors": [
            "Shengbo Wang",
            "Chuan Lin",
            "Guangjie Han",
            "Shengchao Zhu",
            "Zhixian Li",
            "Zhenyu Wang",
            "Yunpeng Ma"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In recent years, autonomous underwater vehicle (AUV) swarms are gradually\nbecoming popular and have been widely promoted in ocean exploration or\nunderwater tracking, etc. In this paper, we propose a multi-AUV cooperative\nunderwater multi-target tracking algorithm especially when the real underwater\nfactors are taken into account. We first give normally modelling approach for\nthe underwater sonar-based detection and the ocean current interference on the\ntarget tracking process. Then, based on software-defined networking (SDN), we\nregard the AUV swarm as a underwater ad-hoc network and propose a hierarchical\nsoftware-defined multi-AUV reinforcement learning (HSARL) architecture. Based\non the proposed HSARL architecture, we propose the \"Dynamic-Switching\"\nmechanism, it includes \"Dynamic-Switching Attention\" and \"Dynamic-Switching\nResampling\" mechanisms which accelerate the HSARL algorithm's convergence speed\nand effectively prevents it from getting stuck in a local optimum state.\nAdditionally, we introduce the reward reshaping mechanism for further\naccelerating the convergence speed of the proposed HSARL algorithm in early\nphase. Finally, based on a proposed AUV classification method, we propose a\ncooperative tracking algorithm called Dynamic-Switching-Based MARL\n(DSBM)-driven tracking algorithm. Evaluation results demonstrate that our\nproposed DSBM tracking algorithm can perform precise underwater multi-target\ntracking, comparing with many of recent research products in terms of various\nimportant metrics.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.13654v3"
    },
    {
        "title": "Liquid-Graph Time-Constant Network for Multi-Agent Systems Control",
        "authors": [
            "Antonio Marino",
            "Claudio Pacchierotti",
            "Paolo Robuffo Giordano"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper, we propose the Liquid-Graph Time-constant (LGTC) network, a\ncontinuous graph neural network(GNN) model for control of multi-agent systems\nbased on therecent Liquid Time Constant (LTC) network. We analyse itsstability\nleveraging contraction analysis and propose a closed-form model that preserves\nthe model contraction rate and doesnot require solving an ODE at each\niteration. Compared todiscrete models like Graph Gated Neural Networks\n(GGNNs),the higher expressivity of the proposed model guaranteesremarkable\nperformance while reducing the large amountof communicated variables normally\nrequired by GNNs. Weevaluate our model on a distributed multi-agent control\ncasestudy (flocking) taking into account variable communicationrange and\nscalability under non-instantaneous communication\n",
        "pdf_link": "http://arxiv.org/pdf/2404.13982v2"
    },
    {
        "title": "AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks",
        "authors": [
            "Jeremy Harper"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The proliferation of large language models (LLMs) and their integration into\nmulti-agent systems has paved the way for sophisticated automation in various\ndomains. This paper introduces AutoGenesisAgent, a multi-agent system that\nautonomously designs and deploys other multi-agent systems tailored for\nspecific tasks. AutoGenesisAgent comprises several specialized agents including\nSystem Understanding, System Design, Agent Generator, and several others that\ncollectively manage the lifecycle of creating functional multi-agent systems\nfrom initial concept to deployment. Each agent in AutoGenesisAgent has distinct\nresponsibilities ranging from interpreting input prompts to optimizing system\nperformance, culminating, in the deployment of a ready-to-use system. This\nproof-of-concept study discusses the design, implementation, and lessons\nlearned from developing AutoGenesisAgent, highlighting its capability to\ngenerate and refine multi-agent systems autonomously, thereby reducing the need\nfor extensive human oversight in the initial stages of system design. Keywords:\nmulti-agent systems, large language models, system design automation, agent\narchitecture, autonomous systems, software deployment\n",
        "pdf_link": "http://arxiv.org/pdf/2404.17017v1"
    },
    {
        "title": "A multi-agent model of hierarchical decision dynamics",
        "authors": [
            "Paul Kinsler"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Decision making can be difficult when there are many actors (or agents) who\nmay be coordinating or competing to achieve their various ideas of the optimum\noutcome. Here I present a simple decision making model with an explicitly\nhierarchical binary-tree structure, and evaluate how this might cooperate to\ntake actions that match its various evaluations of the uncertain state of the\nworld. Key features of agent behaviour are (a) the separation of its decision\nmaking process into three distinct steps: observation, judgement, and action;\nand (b) the evolution of coordination by the sharing of judgements.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.17477v1"
    },
    {
        "title": "Asymmetric Information Enhanced Mapping Framework for Multirobot\n  Exploration based on Deep Reinforcement Learning",
        "authors": [
            "Jiyu Cheng",
            "Junhui Fan",
            "Xiaolei Li",
            "Paul L. Rosin",
            "Yibin Li",
            "Wei Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Despite the great development of multirobot technologies, efficiently and\ncollaboratively exploring an unknown environment is still a big challenge. In\nthis paper, we propose AIM-Mapping, a Asymmetric InforMation Enhanced Mapping\nframework. The framework fully utilizes the privilege information in the\ntraining process to help construct the environment representation as well as\nthe supervised signal in an asymmetric actor-critic training framework.\nSpecifically, privilege information is used to evaluate the exploration\nperformance through an asymmetric feature representation module and a mutual\ninformation evaluation module. The decision-making network uses the trained\nfeature encoder to extract structure information from the environment and\ncombines it with a topological map constructed based on geometric distance.\nUtilizing this kind of topological map representation, we employ topological\ngraph matching to assign corresponding boundary points to each robot as\nlong-term goal points. We conduct experiments in real-world-like scenarios\nusing the Gibson simulation environments. It validates that the proposed\nmethod, when compared to existing methods, achieves great performance\nimprovement.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.18089v2"
    },
    {
        "title": "Multi-Agent Synchronization Tasks",
        "authors": [
            "Rolando Fernandez",
            "Garrett Warnell",
            "Derrik E. Asher",
            "Peter Stone"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In multi-agent reinforcement learning (MARL), coordination plays a crucial\nrole in enhancing agents' performance beyond what they could achieve through\ncooperation alone. The interdependence of agents' actions, coupled with the\nneed for communication, leads to a domain where effective coordination is\ncrucial. In this paper, we introduce and define $\\textit{Multi-Agent\nSynchronization Tasks}$ (MSTs), a novel subset of multi-agent tasks. We\ndescribe one MST, that we call $\\textit{Synchronized Predator-Prey}$, offering\na detailed description that will serve as the basis for evaluating a selection\nof recent state-of-the-art (SOTA) MARL algorithms explicitly designed to\naddress coordination challenges through the use of communication strategies.\nFurthermore, we present empirical evidence that reveals the limitations of the\nalgorithms assessed to solve MSTs, demonstrating their inability to scale\neffectively beyond 2-agent coordination tasks in scenarios where communication\nis a requisite component. Finally, the results raise questions about the\napplicability of recent SOTA approaches for complex coordination tasks (i.e.\nMSTs) and prompt further exploration into the underlying causes of their\nlimitations in this context.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.18798v1"
    },
    {
        "title": "Analyzing Transport Policies in Developing Countries with ABM",
        "authors": [
            "Kathleen Salazar-Serna",
            "Lorena Cadavid",
            "Carlos Franco"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Deciphering travel behavior and mode choices is a critical aspect of\neffective urban transportation system management, particularly in developing\ncountries where unique socio-economic and cultural conditions complicate\ndecision-making. Agent-based simulations offer a valuable tool for modeling\ntransportation systems, enabling a nuanced understanding and policy impact\nevaluation. This work aims to shed light on the effects of transport policies\nand analyzes travel behavior by simulating agents making mode choices for their\ndaily commutes. Agents gather information from the environment and their social\nnetwork to assess the optimal transport option based on personal satisfaction\ncriteria. Our findings, stemming from simulating a free-fare policy for public\ntransit in a developing-country city, reveal a significant influence on\ndecision-making, fostering public service use while positively influencing\npollution levels, accident rates, and travel speed.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.19745v1"
    },
    {
        "title": "Traffic Performance GPT (TP-GPT): Real-Time Data Informed Intelligent\n  ChatBot for Transportation Surveillance and Management",
        "authors": [
            "Bingzhang Wang",
            "Zhiyu Cai",
            "Muhammad Monjurul Karim",
            "Chenxi Liu",
            "Yinhai Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The digitization of traffic sensing infrastructure has significantly\naccumulated an extensive traffic data warehouse, which presents unprecedented\nchallenges for transportation analytics. The complexities associated with\nquerying large-scale multi-table databases require specialized programming\nexpertise and labor-intensive development. Additionally, traditional analysis\nmethods have focused mainly on numerical data, often neglecting the semantic\naspects that could enhance interpretability and understanding. Furthermore,\nreal-time traffic data access is typically limited due to privacy concerns. To\nbridge this gap, the integration of Large Language Models (LLMs) into the\ndomain of traffic management presents a transformative approach to addressing\nthe complexities and challenges inherent in modern transportation systems. This\npaper proposes an intelligent online chatbot, TP-GPT, for efficient customized\ntransportation surveillance and management empowered by a large real-time\ntraffic database. The innovative framework leverages contextual and generative\nintelligence of language models to generate accurate SQL queries and natural\nlanguage interpretations by employing transportation-specialized prompts,\nChain-of-Thought prompting, few-shot learning, multi-agent collaboration\nstrategy, and chat memory. Experimental study demonstrates that our approach\noutperforms state-of-the-art baselines such as GPT-4 and PaLM 2 on a\nchallenging traffic-analysis benchmark TransQuery. TP-GPT would aid researchers\nand practitioners in real-time transportation surveillance and management in a\nprivacy-preserving, equitable, and customizable manner.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.03076v1"
    },
    {
        "title": "A Multi-Agent Rollout Approach for Highway Bottleneck Decongenston in\n  Mixed Autonomy",
        "authors": [
            "Lu Liu",
            "Maonan Wang",
            "Man-On Pun",
            "Xi Xiong"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The integration of autonomous vehicles (AVs) into the existing transportation\ninfrastructure offers a promising solution to alleviate congestion and enhance\nmobility. This research explores a novel approach to traffic optimization by\nemploying a multi-agent rollout approach within a mixed autonomy environment.\nThe study concentrates on coordinating the speed of human-driven vehicles by\nlongitudinally controlling AVs, aiming to dynamically optimize traffic flow and\nalleviate congestion at highway bottlenecks in real-time. We model the problem\nas a decentralized partially observable Markov decision process (Dec-POMDP) and\npropose an improved multi-agent rollout algorithm. By employing agent-by-agent\npolicy iterations, our approach implicitly considers cooperation among multiple\nagents and seamlessly adapts to complex scenarios where the number of agents\ndynamically varies. Validated in a real-world network with varying AV\npenetration rates and traffic flow, the simulations demonstrate that the\nmulti-agent rollout algorithm significantly enhances performance, reducing\naverage travel time on bottleneck segments by 9.42% with a 10% AV penetration\nrate.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.03132v1"
    },
    {
        "title": "A Guide to Re-Implementing Agent-based Models: Experiences from the\n  HUMAT Model",
        "authors": [
            "Önder Gürcan",
            "Timo Szczepanska",
            "Patrycja Antosz"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Replicating existing agent-based models poses significant challenges,\nparticularly for those new to the field. This article presents an\nall-encompassing guide to re-implementing agent-based models, encompassing\nvital concepts such as comprehending the original model, utilizing agent-based\nmodeling frameworks, simulation design, model validation, and more. By\nembracing the proposed guide, researchers and practitioners can gain a profound\nunderstanding of the entire re-implementation process, resulting in heightened\naccuracy and reliability of simulations for complex systems. Furthermore, this\narticle showcases the re-implementation of the HUMAT socio-cognitive\narchitecture, with a specific focus on designing a versatile,\nlanguage-independent model. The encountered challenges and pitfalls in the\nre-implementation process are thoroughly discussed, empowering readers with\npractical insights. Embrace this guide to expedite model development while\nensuring robust and precise simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.03994v1"
    },
    {
        "title": "Fair Voting Outcomes with Impact and Novelty Compromises? Unraveling\n  Biases in Electing Participatory Budgeting Winners",
        "authors": [
            "Sajan Maharjan",
            "Srijoni Majumdar",
            "Evangelos Pournaras"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Participatory budgeting, as a paradigm for democratic innovations, engages\ncitizens in the distribution of a public budget to projects, which they propose\nand vote for implementation. So far, voting algorithms have been proposed and\nstudied in social choice literature to elect projects that are popular, while\nothers prioritize on a proportional representation of voters' preferences, for\ninstance, the rule of equal shares. However, the anticipated impact and novelty\nin the broader society by the winning projects, as selected by different\nalgorithms, remains totally under-explored, lacking both a universal theory of\nimpact for voting and a rigorous unifying framework for impact and novelty\nassessments. This paper tackles this grand challenge towards new axiomatic\nfoundations for designing effective and fair voting methods. This is via new\nand striking insights derived from a large-scale analysis of biases over 345\nreal-world voting outcomes, characterized for the first time by a novel\nportfolio of impact and novelty metrics. We find strong causal evidence that\nequal shares comes with impact loss in several infrastructural projects of\ndifferent cost levels that have been so far over-represented. However, it also\ncomes with a novel, yet over-represented, impact gain in welfare, education and\nculture. We discuss broader implications of these results and how impact loss\ncan be mitigated at the stage of campaign design and project ideation.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.05085v3"
    },
    {
        "title": "Safe by Design Autonomous Driving Systems",
        "authors": [
            "Marius Bozga",
            "Joseph Sifakis"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Developing safe autonomous driving systems is a major scientific and\ntechnical challenge. Existing AI-based end-to-end solutions do not offer the\nnecessary safety guarantees, while traditional systems engineering approaches\nare defeated by the complexity of the problem. Currently, there is an\nincreasing interest in hybrid design solutions, integrating machine learning\ncomponents, when necessary, while using model-based components for goal\nmanagement and planning.\n  We study a method for building safe by design autonomous driving systems,\nbased on the assumption that the capability to drive boils down to the\ncoordinated execution of a given set of driving operations. The assumption is\nsubstantiated by a compositionality result considering that autopilots are\ndynamic systems receiving a small number of types of vistas as input, each\nvista defining a free space in its neighborhood. It is shown that safe driving\nfor each type of vista in the corresponding free space, implies safe driving\nfor any possible scenario under some easy-to-check conditions concerning the\ntransition between vistas. The designed autopilot comprises distinct control\npolicies one per type of vista, articulated in two consecutive phases. The\nfirst phase consists of carefully managing a potentially risky situation by\nvirtually reducing speed, while the second phase consists of exiting the\nsituation by accelerating.\n  The autopilots designed use for their predictions simple functions\ncharacterizing the acceleration and deceleration capabilities of the vehicles.\nThey cover the main driving operations, including entering a main road,\novertaking, crossing intersections protected by traffic lights or signals, and\ndriving on freeways. The results presented reinforce the case for hybrid\nsolutions that incorporate mathematically elegant and robust decision methods\nthat are safe by design.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.11995v1"
    },
    {
        "title": "Learning to connect in action: Measuring and understanding the emergence\n  of boundary spanners in volatile times",
        "authors": [
            "Vittorio Nespeca",
            "Tina Comes",
            "Frances Brazier"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Collective intelligence of diverse groups is key for tackling many of today's\ngrand challenges such as fostering resilience and climate adaptation.\nInformation exchange across such diverse groups is crucial for collective\nintelligence, especially in volatile environments. To facilitate inter-group\ninformation exchange, Informational Boundary Spanners (IBSs) as pivotal\ninformation exchange 'hubs' are promising. However, the mechanisms that drive\nthe emergence of IBSs remain poorly understood. To address this gap there is\nfirst a need for a method to identify and measure the emergence of IBSs.\nSecond, an Agent-Based Modelling (ABM) framework is not available to\nsystematically study mechanisms for the emergence of IBSs in volatile\nenvironments. Third, even though the ability to learn who provides high-quality\ninformation is thought to be essential to explain the emergence of IBSs, a\nrigorous test of this mechanism is missing. The learning mechanism is\nformalized using an ABM framework, with the model's outputs analyzed using the\nproposed IBS emergence measurement method. To illustrate both the method and\nthe learning mechanism, we present a case study focused on information sharing\nin the volatile environment of a disaster. The study shows that learning\nconstitutes a mechanism for the emergence of effective IBSs in (a)\nlow-volatility environments characterised by low uncertainty and (b) in\nhigh-volatility environments characterised by rapid change if the number of\ninter-group connections is sufficient. With the method and model, this paper\naims to lay the foundations for exploring mechanisms for the emergence of IBSs\nthat facilitate inter-group information exchange. This article advances\ncollective intelligence by providing the essential elements for measuring and\nunderstanding the emergence of IBSs and exploring the effect of learning on\ntheir emergence in volatile environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.11998v1"
    },
    {
        "title": "Towards a Distributed Platform for Normative Reasoning and Value\n  Alignment in Multi-Agent Systems",
        "authors": [
            "Miguel Garcia-Bohigues",
            "Carmengelys Cordova",
            "Joaquin Taverner",
            "Javier Palanca",
            "Elena del Val",
            "Estefania Argente"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper presents an extended version of the SPADE platform, which aims to\nempower intelligent agent systems with normative reasoning and value alignment\ncapabilities. Normative reasoning involves evaluating social norms and their\nimpact on decision-making, while value alignment ensures agents' actions are in\nline with desired principles and ethical guidelines. The extended platform\nequips agents with normative awareness and reasoning capabilities based on\ndeontic logic, allowing them to assess the appropriateness of their actions and\nmake informed decisions. By integrating normative reasoning and value\nalignment, the platform enhances agents' social intelligence and promotes\nresponsible and ethical behaviors in complex environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.13543v1"
    },
    {
        "title": "Distributed and Decentralized Control and Task Allocation for Flexible\n  Swarms",
        "authors": [
            "Yigal Koifman",
            "Ariel Barel",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper introduces a novel bio-mimetic approach for distributed control of\nrobotic swarms, inspired by the collective behaviors of swarms in nature such\nas schools of fish and flocks of birds. The agents are assumed to have limited\nsensory perception, lack memory, be Identical, anonymous, and operate without\ninteragent explicit communication. Despite these limitations, we demonstrate\nthat collaborative exploration and task allocation can be executed by applying\nsimple local rules of interactions between the agents. A comprehensive model\ncomprised of agent, formation, and swarm layers is proposed in this paper,\nwhere each layer performs a specific function in shaping the swarm's collective\nbehavior, thereby contributing to the emergence of the anticipated behaviors.\nWe consider four principles combined in the design of the distributed control\nprocess: Cohesiveness, Flexibility, Attraction-Repulsion, and Peristaltic\nMotion. We design the control algorithms as reactive behaviour that enables the\nswarm to maintain connectivity, adapt to dynamic environments, spread out and\ncover a region with a size determined by the number of agents, and respond to\nvarious local task requirements. We explore some simple broadcast control-based\nsteering methods, that result in inducing \"anonymous ad-hoc leaders\" among the\nagents, capable of guiding the swarm towards yet unexplored regions with\nfurther tasks. Our analysis is complemented by simulations, validating the\nefficacy of our algorithms. The experiments with various scenarios showcase the\nswarm`s capability to self-organize and perform tasks effectively under the\nproposed framework. The possible implementations include domains that\nnecessitate emergent coordination and control in multi-agent systems, without\nthe need for advanced individual abilities or direct communication.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.13941v1"
    },
    {
        "title": "Enabling Sustainable Freight Forwarding Network via Collaborative Games",
        "authors": [
            "Pang-Jin Tan",
            "Shih-Fen Cheng",
            "Richard Chen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Freight forwarding plays a crucial role in facilitating global trade and\nlogistics. However, as the freight forwarding market is extremely fragmented,\nfreight forwarders often face the issue of not being able to fill the available\nshipping capacity. This recurrent issue motivates the creation of various\nfreight forwarding networks that aim at exchanging capacities and demands so\nthat the resource utilization of individual freight forwarders can be\nmaximized. In this paper, we focus on how to design such a collaborative\nnetwork based on collaborative game theory, with the Shapley value representing\na fair scheme for profit sharing. Noting that the exact computation of Shapley\nvalues is intractable for large-scale real-world scenarios, we incorporate the\nobservation that collaboration among two forwarders is only possible if their\nservice routes and demands overlap. This leads to a new class of collaborative\ngames called the Locally Collaborative Games (LCGs), where agents can only\ncollaborate with their neighbors. We propose an efficient approach to compute\nShapley values for LCGs, and numerically demonstrate that our approach\nsignificantly outperforms the state-of-the-art approach for a wide variety of\nnetwork structures.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.14198v1"
    },
    {
        "title": "AI-Olympics: Exploring the Generalization of Agents through Open\n  Competitions",
        "authors": [
            "Chen Wang",
            "Yan Song",
            "Shuai Wu",
            "Sa Wu",
            "Ruizhi Zhang",
            "Shu Lin",
            "Haifeng Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Between 2021 and 2023, AI-Olympics, a series of online AI competitions was\nhosted by the online evaluation platform Jidi in collaboration with the IJCAI\ncommittee. In these competitions, an agent is required to accomplish diverse\nsports tasks in a two-dimensional continuous world, while competing against an\nopponent. This paper provides a brief overview of the competition series and\nhighlights notable findings. We aim to contribute insights to the field of\nmulti-agent decision-making and explore the generalization of agents through\nengineering efforts.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.14358v1"
    },
    {
        "title": "Finite-time convergence to an $ε$-efficient Nash equilibrium in\n  potential games",
        "authors": [
            "Anna Maddux",
            "Reda Ouhamma",
            "Maryam Kamgarpour"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper investigates the convergence time of log-linear learning to an\n$\\epsilon$-efficient Nash equilibrium (NE) in potential games. In such games,\nan efficient NE is defined as the maximizer of the potential function. Previous\nliterature provides asymptotic convergence rates to efficient Nash equilibria,\nand existing finite-time rates are limited to potential games with further\nassumptions such as the interchangeability of players. In this paper, we prove\nthe first finite-time convergence to an $\\epsilon$-efficient NE in general\npotential games. Our bounds depend polynomially on $1/\\epsilon$, an improvement\nover previous bounds that are exponential in $1/\\epsilon$ and only hold for\nsubclasses of potential games. We then strengthen our convergence result in two\ndirections: first, we show that a variant of log-linear learning that requires\na factor $A$ less feedback on the utility per round enjoys a similar\nconvergence time; second, we demonstrate the robustness of our convergence\nguarantee if log-linear learning is subject to small perturbations such as\nalterations in the learning rule or noise-corrupted utilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.15497v3"
    },
    {
        "title": "Knowing What Not to Do: Leverage Language Model Insights for Action\n  Space Pruning in Multi-agent Reinforcement Learning",
        "authors": [
            "Zhihao Liu",
            "Xianliang Yang",
            "Zichuan Liu",
            "Yifan Xia",
            "Wei Jiang",
            "Yuanyu Zhang",
            "Lijuan Li",
            "Guoliang Fan",
            "Lei Song",
            "Bian Jiang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent reinforcement learning (MARL) is employed to develop autonomous\nagents that can learn to adopt cooperative or competitive strategies within\ncomplex environments. However, the linear increase in the number of agents\nleads to a combinatorial explosion of the action space, which may result in\nalgorithmic instability, difficulty in convergence, or entrapment in local\noptima. While researchers have designed a variety of effective algorithms to\ncompress the action space, these methods also introduce new challenges, such as\nthe need for manually designed prior knowledge or reliance on the structure of\nthe problem, which diminishes the applicability of these techniques. In this\npaper, we introduce Evolutionary action SPAce Reduction with Knowledge\n(eSpark), an exploration function generation framework driven by large language\nmodels (LLMs) to boost exploration and prune unnecessary actions in MARL. Using\njust a basic prompt that outlines the overall task and setting, eSpark is\ncapable of generating exploration functions in a zero-shot manner, identifying\nand pruning redundant or irrelevant state-action pairs, and then achieving\nautonomous improvement from policy feedback. In reinforcement learning tasks\ninvolving inventory management and traffic light control encompassing a total\nof 15 scenarios, eSpark consistently outperforms the combined MARL algorithm in\nall scenarios, achieving an average performance gain of 34.4% and 9.9% in the\ntwo types of tasks respectively. Additionally, eSpark has proven to be capable\nof managing situations with a large number of agents, securing a 29.7%\nimprovement in scalability challenges that featured over 500 agents. The code\ncan be found in https://github.com/LiuZhihao2022/eSpark.git.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.16854v1"
    },
    {
        "title": "Act Natural! Projecting Autonomous System Trajectories Into Naturalistic\n  Behavior Sets",
        "authors": [
            "Hamzah I. Khan",
            "Adam J. Thorpe",
            "David Fridovich-Keil"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Autonomous agents operating around human actors must consider how their\nbehaviors might affect those humans, even when not directly interacting with\nthem. To this end, it is often beneficial to be predictable and appear\nnaturalistic. Existing methods to address this problem use human actor intent\nmodeling or imitation learning techniques, but these approaches rarely capture\nall possible motivations for human behavior or require significant amounts of\ndata. In contrast, we propose a technique for modeling naturalistic behavior as\na set of convex hulls computed over a relatively small dataset of human\nbehavior. Given this set, we design an optimization-based filter which projects\narbitrary trajectories into it to make them more naturalistic for autonomous\nagents to execute while also satisfying dynamics constraints. We demonstrate\nour methods on real-world human driving data from the inD intersection dataset\n(Bock et al., 2020).\n",
        "pdf_link": "http://arxiv.org/pdf/2405.19292v1"
    },
    {
        "title": "Normative Modules: A Generative Agent Architecture for Learning Norms\n  that Supports Multi-Agent Cooperation",
        "authors": [
            "Atrisha Sarkar",
            "Andrei Ioan Muresanu",
            "Carter Blair",
            "Aaryam Sharma",
            "Rakshit S Trivedi",
            "Gillian K Hadfield"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Generative agents, which implement behaviors using a large language model\n(LLM) to interpret and evaluate an environment, has demonstrated the capacity\nto solve complex tasks across many social and technological domains. However,\nwhen these agents interact with other agents and humans in presence of social\nstructures such as existing norms, fostering cooperation between them is a\nfundamental challenge. In this paper, we develop the framework of a 'Normative\nModule': an architecture designed to enhance cooperation by enabling agents to\nrecognize and adapt to the normative infrastructure of a given environment. We\nfocus on the equilibrium selection aspect of the cooperation problem and inform\nour agent design based on the existence of classification institutions that\nimplement correlated equilibrium to provide effective resolution of the\nequilibrium selection problem. Specifically, the normative module enables\nagents to learn through peer interactions which of multiple candidate\ninstitutions in the environment, does a group treat as authoritative. By\nenabling normative competence in this sense, agents gain ability to coordinate\ntheir sanctioning behaviour; coordinated sanctioning behaviour in turn shapes\nprimary behaviour within a social environment, leading to higher average\nwelfare. We design a new environment that supports institutions and evaluate\nthe proposed framework based on two key criteria derived from agent\ninteractions with peers and institutions: (i) the agent's ability to disregard\nnon-authoritative institutions and (ii) the agent's ability to identify\nauthoritative institutions among several options. We show that these\ncapabilities allow the agent to achieve more stable cooperative outcomes\ncompared to baseline agents without the normative module, paving the way for\nresearch in a new avenue of designing environments and agents that account for\nnormative infrastructure.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.19328v1"
    },
    {
        "title": "Dispersion of personal spaces",
        "authors": [
            "Jaroslav Horáček",
            "Miroslav Rada"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  There are many entities that disseminate in the physical space - information,\ngossip, mood, innovation etc. Personal spaces are also entities that disperse\nand interplay. In this work we study the emergence of configurations formed by\nparticipants when choosing a place to sit in a rectangular auditorium. Based on\nexperimental questionnaire data we design several models and assess their\nrelevancy to a real time-lapse footage of lecture hall being filled up. The\nmain focus is to compare the evolution of entropy of occupied seat\nconfigurations in time. Even though the process of choosing a seat is complex\nand could depend on various properties of participants or environment, some of\nthe developed models can capture at least basic essence of the real processes.\nAfter introducing the problem of seat selection and related results in close\nresearch areas, we introduce preliminary collected data and build models of\nseat selection based on them. We compare the resulting models to the real\nobservational data and discuss areas of future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.19895v1"
    },
    {
        "title": "LAGMA: LAtent Goal-guided Multi-Agent Reinforcement Learning",
        "authors": [
            "Hyungho Na",
            "Il-chul Moon"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In cooperative multi-agent reinforcement learning (MARL), agents collaborate\nto achieve common goals, such as defeating enemies and scoring a goal. However,\nlearning goal-reaching paths toward such a semantic goal takes a considerable\namount of time in complex tasks and the trained model often fails to find such\npaths. To address this, we present LAtent Goal-guided Multi-Agent reinforcement\nlearning (LAGMA), which generates a goal-reaching trajectory in latent space\nand provides a latent goal-guided incentive to transitions toward this\nreference trajectory. LAGMA consists of three major components: (a) quantized\nlatent space constructed via a modified VQ-VAE for efficient sample\nutilization, (b) goal-reaching trajectory generation via extended VQ codebook,\nand (c) latent goal-guided intrinsic reward generation to encourage transitions\ntowards the sampled goal-reaching path. The proposed method is evaluated by\nStarCraft II with both dense and sparse reward settings and Google Research\nFootball. Empirical results show further performance improvement over\nstate-of-the-art baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.19998v1"
    },
    {
        "title": "Distributed maze exploration using multiple agents and optimal goal\n  assignment",
        "authors": [
            "Manousos Linardakis",
            "Iraklis Varlamis",
            "Georgios Th. Papadopoulos"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Robotic exploration has long captivated researchers aiming to map complex\nenvironments efficiently. Techniques such as potential fields and frontier\nexploration have traditionally been employed in this pursuit, primarily\nfocusing on solitary agents. Recent advancements have shifted towards\noptimizing exploration efficiency through multiagent systems. However, many\nexisting approaches overlook critical real-world factors, such as broadcast\nrange limitations, communication costs, and coverage overlap. This paper\naddresses these gaps by proposing a distributed maze exploration strategy\n(CU-LVP) that assumes constrained broadcast ranges and utilizes Voronoi\ndiagrams for better area partitioning. By adapting traditional multiagent\nmethods to distributed environments with limited broadcast ranges, this study\nevaluates their performance across diverse maze topologies, demonstrating the\nefficacy and practical applicability of the proposed method. The code and\nexperimental results supporting this study are available in the following\nrepository: https://github.com/manouslinard/multiagent-exploration/.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.20232v1"
    },
    {
        "title": "Satellites swarm cooperation for pursuit-attachment tasks with\n  transformer-based reinforcement learning",
        "authors": [
            "yonghao Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The on-orbit intelligent planning of satellites swarm has attracted\nincreasing attention from scholars. Especially in tasks such as the pursuit and\nattachment of non-cooperative satellites, satellites swarm must achieve\ncoordinated cooperation with limited resources. The study proposes a\nreinforcement learning framework that integrates the transformer and expert\nnetworks. Firstly, under the constraints of incomplete information about\nnon-cooperative satellites, an implicit multi-satellites cooperation strategy\nwas designed using a communication sharing mechanism. Subsequently, for the\ncharacteristics of the pursuit-attachment tasks, the multi-agent reinforcement\nlearning framework is improved by introducing transformers and expert networks\ninspired by transfer learning ideas. To address the issue of satellites swarm\nscalability, sequence modelling based on transformers is utilized to craft\nmemory-augmented policy networks, meanwhile increasing the scalability of the\nswarm. By comparing the convergence curves with other algorithms, it is shown\nthat the proposed method is qualified for pursuit-attachment tasks of\nsatellites swarm. Additionally, simulations under different maneuvering\nstrategies of non-cooperative satellites respectively demonstrate the\nrobustness of the algorithm and the task efficiency of the swarm system. The\nsuccess rate of pursuit-attachment tasks is analyzed through Monte Carlo\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01061v1"
    },
    {
        "title": "Popularity-based Alternative Routing",
        "authors": [
            "Giuliano Cornacchia",
            "Ludovico Lemma",
            "Luca Pappalardo"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Alternative routing is crucial to minimize the environmental impact of urban\ntransportation while enhancing road network efficiency and reducing traffic\ncongestion. Existing methods neglect information about road popularity,\npossibly leading to unintended consequences such as increasing emissions and\ncongestion. This paper introduces Polaris, an alternative routing algorithm\nthat exploits road popularity to optimize traffic distribution and reduce CO2\nemissions. Polaris leverages the novel concept of K-road layers, which\nmitigates the feedback loop effect where redirecting vehicles to less popular\nroads could increase their popularity in the future. We conduct experiments in\nthree cities to evaluate Polaris against state-of-the-art alternative routing\nalgorithms. Our results demonstrate that Polaris significantly reduces the\noveruse of highly popular road edges and traversed regulated intersections,\nshowcasing its ability to generate efficient routes and distribute traffic more\nevenly. Furthermore, Polaris achieves substantial CO2 reductions, outperforming\nexisting alternative routing strategies. Finally, we compare Polaris to an\nalgorithm that coordinates vehicles centrally to distribute them more evenly on\nthe road network. Our findings reveal that Polaris performs comparably well,\neven with much less information, highlighting its potential as an efficient and\nsustainable solution for urban traffic management.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.05388v1"
    },
    {
        "title": "Arbitrary-Order Distributed Finite-Time Differentiator for Multi-Agent\n  Systems",
        "authors": [
            "Weile Chen",
            "Haibo Du",
            "Shihua Li",
            "Xinghuo Yu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper proposes arbitrary-order distributed finite-time differentiator\n(AODFD) for leader-follower multi-agent systems (MAS) under directed graph by\nonly using relative or absolute output information. By using arbitrary-order\ndistributed finite-time differentiator via relative output information\n(AODFD-R), each follower agent can obtain the relative output information\nbetween itself and leader and the relative output's arbitrary-order\nderivatives, where the information to be measured is only the local relative\noutput information between each follower agent and its neighboring agents. As a\nsimple extension of AODFD-R, the arbitrary-order distributed finite-time\ndifferentiator via absolute output information (AODFD-A) is also given. The\nfinite-time stability of the closed-loop system under AODFD is proved by\nconstructing a Lyapunov function skillfully. Finally, several simulation\nexamples are given to verify the effectiveness of the AODFD.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.07031v2"
    },
    {
        "title": "Choreographing the Rhythms of Observation: Dynamics for Ranged Observer\n  Bipartite-Unipartite SpatioTemporal (ROBUST) Networks",
        "authors": [
            "Ted Edward Holmberg"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Existing network analysis methods struggle to optimize observer placements in\ndynamic environments with limited visibility. This dissertation introduces the\nnovel ROBUST (Ranged Observer Bipartite-Unipartite SpatioTemporal) framework,\noffering a significant advancement in modeling, analyzing, and optimizing\nobserver networks within complex spatiotemporal domains. ROBUST leverages a\nunique bipartite-unipartite approach, distinguishing between observer and\nobservable entities while incorporating spatial constraints and temporal\ndynamics.\n  This research extends spatiotemporal network theory by introducing novel\ngraph-based measures, including myopic degree, spatial closeness centrality,\nand edge length proportion. These measures, coupled with advanced clustering\ntechniques like Proximal Recurrence, provide insights into network structure,\nresilience, and the effectiveness of observer placements. The ROBUST framework\ndemonstrates superior resource allocation and strategic responsiveness compared\nto conventional models. Case studies in oceanographic monitoring, urban safety\nnetworks, and multi-agent path planning showcases its practical applicability\nand adaptability. Results demonstrate significant improvements in coverage,\nresponse times, and overall network efficiency.\n  This work paves the way for future research in incorporating imperfect\nknowledge, refining temporal pathing methodologies, and expanding the scope of\napplications. By bridging theoretical advancements with practical solutions,\nROBUST stands as a significant contribution to the field, promising to inform\nand inspire ongoing and future endeavors in network optimization and\nmulti-agent system planning.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.07473v4"
    },
    {
        "title": "KAOS: Large Model Multi-Agent Operating System",
        "authors": [
            "Zhao Zhuo",
            "Rongzhen Li",
            "Kai Liu",
            "Huhai Zou",
            "KaiMao Li",
            "Jie Yu",
            "Tianhao Sun",
            "Qingbo Wu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The intelligent interaction model based on large models reduces the\ndifferences in user experience across various system platforms but faces\nchallenges in multi-agent collaboration and resource sharing. To demonstrate a\nuniform user experience across different foundational software platforms and\naddress resource coordination management challenges, this paper proposes KAOS,\na multi-agent operating system based on the open-source Kylin. The research\nmethod involves empowering agents with large models to serve applications.\nFirst, by introducing management role agents and vertical multi-agent\ncollaboration to construct or replace typical application software. Second, by\nstudying system-level shared resource scheduling strategies to enhance user\nexperience and optimize resource utilization. And finally, by validating the\nefficiency and superiority of the large model multi-agent operating system\nthrough real applications and scoring intelligence. The feasibility of this\nsystem is demonstrated, providing a new perspective for the development of\nmulti-agent operating systems. Experimental results show significant advantages\nof multi-agent collaboration in various application scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11342v3"
    },
    {
        "title": "Decentralized Collaborative Pricing and Shunting for Multiple EV\n  Charging Stations Based on Multi-Agent Reinforcement Learning",
        "authors": [
            "Tianhao Bu",
            "Hang Li",
            "Guojie Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The extraordinary electric vehicle (EV) popularization in the recent years\nhas facilitated research studies in alleviating EV energy charging demand.\nPrevious studies primarily focused on the optimizations over charging stations\n(CS) profit and EV users cost savings through charge/discharge scheduling\nevents. In this work, the random behaviors of EVs are considered, with EV users\npreferences over multi-CS characteristics modelled to imitate the potential CS\nselection disequilibrium. A price scheduling strategy under decentralized\ncollaborative framework is proposed to achieve EV shunting in a multi-CS\nenvironment, while minimizing the charging cost through multi agent\nreinforcement learning. The proposed problem is formulated as a Markov Decision\nProcess (MDP) with uncertain transition probability.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11496v1"
    },
    {
        "title": "Resource Allocation with Karma Mechanisms",
        "authors": [
            "Kevin Riehl",
            "Anastasios Kouvelas",
            "Michail Makridis"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Monetary markets serve as established resource allocation mechanisms,\ntypically achieving efficient solutions with limited information. However, they\nare susceptible to market failures, particularly under the presence of public\ngoods, externalities, or inequality of economic power. Moreover, in many\nresource allocating contexts, money faces social, ethical, and legal\nconstraints. Consequently, research increasingly explores artificial currencies\nand non-monetary markets, with Karma emerging as a notable concept. Karma, a\nnon-tradeable, resource-inherent currency for prosumer resources, operates on\nthe principles of contribution and consumption of specific resources. It\nembodies fairness, near incentive compatibility, Pareto-efficiency, robustness\nto population heterogeneity, and can incentivize a reduction in resource\nscarcity. The literature on Karma is scattered across disciplines, varies in\nscope, and lacks of conceptual clarity and coherence. Thus, this study\nundertakes a comprehensive review of the Karma mechanism, systematically\ncomparing its resource allocation applications and elucidating overlooked\nmechanism design elements. Through a systematic mapping study, this review\nsituates Karma within its literature context, offers a structured design\nparameter framework, and develops a road-map for future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14728v1"
    },
    {
        "title": "Autonomous Decision Making for Air Taxi Networks",
        "authors": [
            "Alex Vesel"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Future urban air mobility systems are expected to be operated by rideshare\ncompanies as fleets, which will require fully autonomous air traffic control\nsystems and an order of magnitude increase in airspace capacity. Such a system\nmust not only be safe, but also highly responsive to customer demand. This\npaper proposes the air traffic network problem (ATNP), which models the\noptimization problem of future cooperative air taxi networks. We propose a\nthree-phase decision making model that efficiently assigns vehicles to\npassengers, determines flight levels to reduce collision risk, and resolves\naircraft conflicts by selectively applying Monte Carlo tree search. We develop\na simulator for the ATNP and show that our approach has increased safety and\nreduced passenger waiting time compared to greedy and first-dispatch protocols\nover potential vertiport layouts across the Bay Area and New York City.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14832v1"
    },
    {
        "title": "Effects of non-uniform number of actions by Hawkes process on spatial\n  cooperation",
        "authors": [
            "Daiki Miyagawa",
            "Genki Ichinose"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The emergence of cooperative behavior, despite natural selection favoring\nrational self-interest, presents a significant evolutionary puzzle.\nEvolutionary game theory elucidates why cooperative behavior can be\nadvantageous for survival. However, the impact of non-uniformity in the\nfrequency of actions, particularly when actions are altered in the short term,\nhas received little scholarly attention. To demonstrate the relationship\nbetween the non-uniformity in the frequency of actions and the evolution of\ncooperation, we conducted multi-agent simulations of evolutionary games. In our\nmodel, each agent performs actions in a chain-reaction, resulting in a\nnon-uniform distribution of the number of actions. To achieve a variety of\nnon-uniform action frequency, we introduced two types of chain-reaction rules:\none where an agent's actions trigger subsequent actions, and another where an\nagent's actions depend on the actions of others. Our results revealed that\ncooperation evolves more effectively in scenarios with even slight\nnon-uniformity in action frequency compared to completely uniform cases. In\naddition, scenarios where agents' actions are primarily triggered by their own\nprevious actions more effectively support cooperation, whereas those triggered\nby others' actions are less effective. This implies that a few highly active\nindividuals contribute positively to cooperation, while the tendency to follow\nothers' actions can hinder it.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.15036v1"
    },
    {
        "title": "Model Checking of vGOAL",
        "authors": [
            "Yi Yang",
            "Tom Holvoet"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Developing autonomous decision-making requires safety assurance. Agent\nprogramming languages like AgentSpeak and Gwendolen provide tools for\nprogramming autonomous decision-making. However, despite numerous efforts to\napply model checking to these languages, challenges persist such as a faithful\nsemantic mapping between agent programs and the generated models, efficient\nmodel generation, and efficient model checking.\n  As an extension of the agent programming language GOAL, vGOAL has been\nproposed to formally specify autonomous decisions with an emphasis on safety.\nThis paper tackles the mentioned challenges through two automated\nmodel-checking processes for vGOAL: one for Computation Tree Logic and another\nfor Probabilistic Computation Tree Logic. Compared with the existing\nmodel-checking approaches of agent programming languages, it has three main\nadvantages. First, it efficiently performs automated model-checking analysis\nfor a given vGOAL specification, including efficiently generating input models\nfor NuSMV and Storm and leveraging these efficient model checkers. Second, the\nsemantic equivalence is established for both nondeterministic models and\nprobabilistic models of vGOAL: from vGOAL to transition systems or DTMCs.\nThird, an algorithm is proposed for efficiently detecting errors, which is\nparticularly useful for vGOAL specifications that describe complex scenarios.\nValidation and experiments in a real-world autonomous logistic system with\nthree autonomous mobile robots illustrate both the efficiency and practical\nusability of the automated CTL and PCTL model-checking process for vGOAL.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.17206v1"
    },
    {
        "title": "Learnings from Implementation of a BDI Agent-based Battery-less Wireless\n  Sensor",
        "authors": [
            "Ganesh Ramanathan",
            "Andres Gomez",
            "Simon Mayer"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Battery-less embedded devices powered by energy harvesting are increasingly\nbeing used in wireless sensing applications. However, their limited and often\nuncertain energy availability challenges designing application programs. To\nexamine if BDI-based agent programming can address this challenge, we used it\nfor a real-life application involving an environmental sensor that works on\nenergy harvested from ambient light. This yielded the first ever implementation\nof a BDI agent on a low-power battery-less and energy-harvesting embedded\nsystem. Furthermore, it uncovered conceptual integration challenges between\nembedded systems and BDI-based agent programming that, if overcome, will\nsimplify the deployment of more autonomous systems on low-power devices with\nnon-deterministic energy availability. Specifically, we (1) mapped essential\ndevice states to default \\textit{internal} beliefs, (2) recognized and\naddressed the need for beliefs in general to be \\textit{short-} or\n\\textit{long-term}, and (3) propose dynamic annotation of intentions with their\nrun-time energy impact. We show that incorporating these extensions not only\nsimplified the programming but also improved code readability and understanding\nof its behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.17303v1"
    },
    {
        "title": "Intrinsic Action Tendency Consistency for Cooperative Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Junkai Zhang",
            "Yifan Zhang",
            "Xi Sheryl Zhang",
            "Yifan Zang",
            "Jian Cheng"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Efficient collaboration in the centralized training with decentralized\nexecution (CTDE) paradigm remains a challenge in cooperative multi-agent\nsystems. We identify divergent action tendencies among agents as a significant\nobstacle to CTDE's training efficiency, requiring a large number of training\nsamples to achieve a unified consensus on agents' policies. This divergence\nstems from the lack of adequate team consensus-related guidance signals during\ncredit assignments in CTDE. To address this, we propose Intrinsic Action\nTendency Consistency, a novel approach for cooperative multi-agent\nreinforcement learning. It integrates intrinsic rewards, obtained through an\naction model, into a reward-additive CTDE (RA-CTDE) framework. We formulate an\naction model that enables surrounding agents to predict the central agent's\naction tendency. Leveraging these predictions, we compute a cooperative\nintrinsic reward that encourages agents to match their actions with their\nneighbors' predictions. We establish the equivalence between RA-CTDE and CTDE\nthrough theoretical analyses, demonstrating that CTDE's training process can be\nachieved using agents' individual targets. Building on this insight, we\nintroduce a novel method to combine intrinsic rewards and CTDE. Extensive\nexperiments on challenging tasks in SMAC and GRF benchmarks showcase the\nimproved performance of our method.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18152v2"
    },
    {
        "title": "Formation Under Communication Constraints: Control Performance Meets\n  Channel Capacity",
        "authors": [
            "Yaru Chen",
            "Yirui Cong",
            "Xiangyun Zhou",
            "Long Cheng",
            "Xiangke Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In wireless communication-based formation control systems, the control\nperformance is significantly impacted by the channel capacity of each\ncommunication link between agents. This relationship, however, remains\nunder-investigated in the existing studies. To address this gap, the formation\ncontrol problem of classical second-order multi-agent systems with bounded\nprocess noises was considered taking into account the channel capacity. More\nspecifically, the model of communication links between agents is first\nestablished, based on a new concept -- guaranteed communication region, which\ncharacterizes all possible locations for successful message decoding in the\npresent of control-system uncertainty. Furthermore, we rigorously prove that,\nthe guaranteed communication region does not unboundedly increase with the\ntransmission time, which indicates an important trade-off between the\nguaranteed communication region and the data rate. The fundamental limits of\ndata rate for any desired accuracy are also obtained. Finally, the integrated\ndesign to achieve the desired formation accuracy is proposed, where an\nestimation-based controller and transmit power control strategy are developed.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18961v2"
    },
    {
        "title": "Cooperative Target Capture using Voronoi Region Shaping",
        "authors": [
            "Gautam Kumar",
            "Ashwini Ratnoo"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper discusses a cooperative strategy for capturing a target using\nmultiple pursuers in a planar scenario. Given an initial position distribution\nof pursuers, the Voronoi Diagram is employed to characterize the target's\nproximity region. The key idea is to dynamically shape that region using a\npolicy that directs its vertices towards its instantaneous centroid. Analysis\nof the resulting dynamics deduces the velocity control inputs for the pursuers.\nAs the main result, target's proximity region is shown to shrink exponentially\nirrespective of its speed and evasion policy. Simulation results demonstrate\nthe characteristics of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.19181v1"
    },
    {
        "title": "Multi-UAVs end-to-end Distributed Trajectory Generation over Point Cloud\n  Data",
        "authors": [
            "Antonio Marino",
            "Claudio Pacchierotti",
            "Paolo Robuffo Giordano"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper introduces an end-to-end trajectory planning algorithm tailored\nfor multi-UAV systems that generates collision-free trajectories in\nenvironments populated with both static and dynamic obstacles, leveraging point\ncloud data. Our approach consists of a 2-fork neural network fed with sensing\nand localization data, able to communicate intermediate learned features among\nthe agents. One network branch crafts an initial collision-free trajectory\nestimate, while the other devises a neural collision constraint for subsequent\noptimization, ensuring trajectory continuity and adherence to physicalactuation\nlimits. Extensive simulations in challenging cluttered environments, involving\nup to 25 robots and 25% obstacle density, show a collision avoidance success\nrate in the range of 100 -- 85%. Finally, we introduce a saliency map\ncomputation method acting on the point cloud data, offering qualitative\ninsights into our methodology.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.19742v1"
    },
    {
        "title": "Identification of LFT Structured Descriptor Systems with Slow and\n  Non-uniform Sampling",
        "authors": [
            "Tong Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Time domain identification is studied in this paper for parameters of a\ncontinuous-time multi-input multi-output descriptor system, with these\nparameters affecting system matrices through a linear fractional\ntransformation. Sampling is permitted to be slow and non-uniform, and there are\nno necessities to satisfy the Nyquist frequency restrictions. This model can be\nused to described the behaviors of a networked dynamic system, and the obtained\nresults can be straightforwardly applied to an ordinary state-space model, as\nwell as a lumped system. An explicit formula is obtained respectively for the\ntransient and steady-state responses of the system stimulated by an arbitrary\nsignal. Some relations have been derived between the system steady-state\nresponse and its transfer function matrix (TFM), which reveal that the value of\na TFM at almost any interested point, as well as its derivatives and a right\ntangential interpolation along an arbitrary direction, can in principle be\nestimated from input-output experimental data. Based on these relations, an\nestimation algorithm is suggested respectively for the parameters of the\ndescriptor system and the values of its TFM. Their properties like asymptotic\nunbiasedness, consistency, etc., are analyzed. A simple numerical example is\nincluded to illustrate characteristics of the suggested estimation algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.00629v4"
    },
    {
        "title": "Field Deployment of Multi-Agent Reinforcement Learning Based Variable\n  Speed Limit Controllers",
        "authors": [
            "Yuhang Zhang",
            "Zhiyao Zhang",
            "Marcos Quiñones-Grueiro",
            "William Barbour",
            "Clay Weston",
            "Gautam Biswas",
            "Daniel Work"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This article presents the first field deployment of a multi-agent\nreinforcement-learning (MARL) based variable speed limit (VSL) control system\non the I-24 freeway near Nashville, Tennessee. We describe how we train MARL\nagents in a traffic simulator and directly deploy the simulation-based policy\non a 17-mile stretch of Interstate 24 with 67 VSL controllers. We use invalid\naction masking and several safety guards to ensure the posted speed limits\nsatisfy the real-world constraints from the traffic management center and the\nTennessee Department of Transportation. Since the time of launch of the system\nthrough April, 2024, the system has made approximately 10,000,000 decisions on\n8,000,000 trips. The analysis of the controller shows that the MARL policy\ntakes control for up to 98% of the time without intervention from safety\nguards. The time-space diagrams of traffic speed and control commands\nillustrate how the algorithm behaves during rush hour. Finally, we quantify the\ndomain mismatch between the simulation and real-world data and demonstrate the\nrobustness of the MARL policy to this mismatch.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.08021v1"
    },
    {
        "title": "Revolutionizing Bridge Operation and Maintenance with LLM-based Agents:\n  An Overview of Applications and Insights",
        "authors": [
            "Xinyu Chen",
            "Lianzhen Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In various industrial fields of human social development, people have been\nexploring methods aimed at freeing human labor. Constructing LLM-based agents\nis considered to be one of the most effective tools to achieve this goal.\nAgent, as a kind of human-like intelligent entity with the ability of\nperception, planning, decision-making, and action, has created great production\nvalue in many fields. However, the bridge O&M field shows a relatively low\nlevel of intelligence compared to other industries. Nevertheless, the bridge\nO&M field has developed numerous intelligent inspection devices, machine\nlearning algorithms, and autonomous evaluation and decision-making methods,\nwhich provide a feasible basis for breakthroughs in artificial intelligence in\nthis field. The aim of this study is to explore the impact of AI bodies based\non large-scale language models on the field of bridge O&M and to analyze the\npotential challenges and opportunities it brings to the core tasks of bridge\nO&M. Through in-depth research and analysis, this paper expects to provide a\nmore comprehensive perspective for understanding the application of\nintelligentsia in this field.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.10064v4"
    },
    {
        "title": "Multi-robot maze exploration using an efficient cost-utility method",
        "authors": [
            "Manousos Linardakis",
            "Iraklis Varlamis",
            "Georgios Th. Papadopoulos"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In the field of modern robotics, robots are proving to be useful in tackling\nhigh-risk situations, such as navigating hazardous environments like burning\nbuildings, earthquake-stricken areas, or patrolling crime-ridden streets, as\nwell as exploring uncharted caves. These scenarios share similarities with maze\nexploration problems in terms of complexity. While several methods have been\nproposed for single-agent systems, ranging from potential fields to flood-fill\nmethods, recent research endeavors have focused on creating methods tailored\nfor multiple agents to enhance the quality and efficiency of maze coverage. The\ncontribution of this paper is the implementation of established maze\nexploration methods and their comparison with a new cost-utility algorithm\ndesigned for multiple agents, which combines the existing methodologies to\noptimize exploration outcomes. Through a comprehensive and comparative\nanalysis, this paper evaluates the performance of the new approach against the\nimplemented baseline methods from the literature, highlighting its efficacy and\npotential advantages in various scenarios. The code and experimental results\nsupporting this study are available in the following repository\n(https://github.com/manouslinard/multiagent-exploration/).\n",
        "pdf_link": "http://arxiv.org/pdf/2407.14218v1"
    },
    {
        "title": "DataStorm-EM: Exploration of Alternative Timelines within\n  Continuous-Coupled Simulation Ensembles",
        "authors": [
            "Fahim Tasneema Azad",
            "Javier Redondo Anton",
            "Shubhodeep Mitra",
            "Fateh Singh",
            "Hans Behrens",
            "Mao-Lin Li",
            "Bilgehan Arslan",
            "K. Selçuk Candan",
            "Maria Luisa Sapino"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Many socio-economical critical domains (such as sustainability, public\nhealth, and disasters) are characterized by highly complex and dynamic systems,\nrequiring data and model-driven simulations to support decision-making. Due to\na large number of unknowns, decision-makers usually need to generate ensembles\nof stochastic scenarios, requiring hundreds or thousands of individual\nsimulation instances, each with different parameter settings corresponding to\ndistinct scenarios, As the number of model parameters increases, the number of\npotential timelines one can simulate increases exponentially. Consequently,\nsimulation ensembles are inherently sparse, even when they are extremely large.\nThis necessitates a platform for (a) deciding which simulation instances to\nexecute and (b) given a large simulation ensemble, enabling decision-makers to\nexplore the resulting alternative timelines, by extracting and visualizing\nconsistent, yet diverse timelines from continuous-coupled simulation ensembles.\nIn this article, we present DataStorm-EM platform for data- and model-driven\nsimulation ensemble management, optimization, analysis, and exploration,\ndescribe underlying challenges and present our solution.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.14571v1"
    },
    {
        "title": "B2MAPO: A Batch-by-Batch Multi-Agent Policy Optimization to Balance\n  Performance and Efficiency",
        "authors": [
            "Wenjing Zhang",
            "Wei Zhang",
            "Wenqing Hu",
            "Yifan Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Most multi-agent reinforcement learning approaches adopt two types of policy\noptimization methods that either update policy simultaneously or sequentially.\nSimultaneously updating policies of all agents introduces non-stationarity\nproblem. Although sequentially updating policies agent-by-agent in an\nappropriate order improves policy performance, it is prone to low efficiency\ndue to sequential execution, resulting in longer model training and execution\ntime. Intuitively, partitioning policies of all agents according to their\ninterdependence and updating joint policy batch-by-batch can effectively\nbalance performance and efficiency. However, how to determine the optimal batch\npartition of policies and batch updating order are challenging problems.\nFirstly, a sequential batched policy updating scheme, B2MAPO (Batch by Batch\nMulti-Agent Policy Optimization), is proposed with a theoretical guarantee of\nthe monotonic incrementally tightened bound. Secondly, a universal modulized\nplug-and-play B2MAPO hierarchical framework, which satisfies CTDE principle, is\ndesigned to conveniently integrate any MARL models to fully exploit and merge\ntheir merits, including policy optimality and inference efficiency. Next, a\nDAG-based B2MAPO algorithm is devised, which is a carefully designed\nimplementation of B2MAPO framework. Comprehensive experimental results\nconducted on StarCraftII Multi-agent Challenge and Google Football Research\ndemonstrate the performance of DAG-based B2MAPO algorithm outperforms baseline\nmethods. Meanwhile, compared with A2PO, our algorithm reduces the model\ntraining and execution time by 60.4% and 78.7%, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.15077v2"
    },
    {
        "title": "(Demo) Systematic Experimentation Using Scenarios in Agent Simulation:\n  Going Beyond Parameter Space",
        "authors": [
            "Vivek Nallur",
            "Pedram Aghaei",
            "Graham Finlay"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper demonstrates a disconnected ABM architecture that enables domain\nexperts, and non-programmers to add qualitative insights into the ABM model\nwithout the intervention of the programmer. This role separation within the\narchitecture allows policy-makers to systematically experiment with multiple\npolicy interventions, different starting conditions, and visualizations to\ninterrogate their ABM\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16294v1"
    },
    {
        "title": "Stochastic Games with Minimally Bounded Action Costs",
        "authors": [
            "David Mguni"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In many multi-player interactions, players incur strictly positive costs each\ntime they execute actions e.g. 'menu costs' or transaction costs in financial\nsystems. Since acting at each available opportunity would accumulate\nprohibitively large costs, the resulting decision problem is one in which\nplayers must make strategic decisions about when to execute actions in addition\nto their choice of action. This paper analyses a discrete-time stochastic game\n(SG) in which players face minimally bounded positive costs for each action and\ninfluence the system using impulse controls. We prove SGs of two-sided impulse\ncontrol have a unique value and characterise the saddle point equilibrium in\nwhich the players execute actions at strategically chosen times in accordance\nwith Markovian strategies. We prove the game respects a dynamic programming\nprinciple and that the Markov perfect equilibrium can be computed as a limit\npoint of a sequence of Bellman operations. We then introduce a new Q-learning\nvariant which we show converges almost surely to the value of the game enabling\nsolutions to be extracted in unknown settings. Lastly, we extend our results to\nsettings with budgetory constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.18010v2"
    },
    {
        "title": "Navigation services amplify concentration of traffic and emissions in\n  our cities",
        "authors": [
            "Giuliano Cornacchia",
            "Mirco Nanni",
            "Dino Pedreschi",
            "Luca Pappalardo"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The proliferation of human-AI ecosystems involving human interaction with\nalgorithms, such as assistants and recommenders, raises concerns about\nlarge-scale social behaviour. Despite evidence of such phenomena across several\ncontexts, the collective impact of GPS navigation services remains unclear:\nwhile beneficial to the user, they can also cause chaos if too many vehicles\nare driven through the same few roads. Our study employs a simulation framework\nto assess navigation services' influence on road network usage and CO2\nemissions. The results demonstrate a universal pattern of amplified conformity:\nincreasing adoption rates of navigation services cause a reduction of route\ndiversity of mobile travellers and increased concentration of traffic and\nemissions on fewer roads, thus exacerbating an unequal distribution of negative\nexternalities on selected neighbourhoods. Although navigation services\nrecommendations can help reduce CO2 emissions when their adoption rate is low,\nthese benefits diminish or even disappear when the adoption rate is high and\nexceeds a certain city- and service-dependent threshold. We summarize these\ndiscoveries in a non-linear function that connects the marginal increase of\nconformity with the marginal reduction in CO2 emissions. Our simulation\napproach addresses the challenges posed by the complexity of transportation\nsystems and the lack of data and algorithmic transparency.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.20004v1"
    },
    {
        "title": "Eliminating Majority Illusion is Easy",
        "authors": [
            "Jack Dippel",
            "Max Dupré la Tour",
            "April Niu",
            "Sanjukta Roy",
            "Adrian Vetta"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Majority Illusion is a phenomenon in social networks wherein the decision by\nthe majority of the network is not the same as one's personal social circle's\nmajority, leading to an incorrect perception of the majority in a large\nnetwork. In this paper, we present polynomial-time algorithms which can\neliminate majority illusion in a network by altering as few connections as\npossible. Additionally, we prove that the more general problem of ensuring all\nneighbourhoods in the network are at least a $p$-fraction of the majority is\nNP-hard for most values of $p$.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.20187v1"
    },
    {
        "title": "Finite-Time Analysis of Asynchronous Multi-Agent TD Learning",
        "authors": [
            "Nicolò Dal Fabbro",
            "Arman Adibi",
            "Aritra Mitra",
            "George J. Pappas"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Recent research endeavours have theoretically shown the beneficial effect of\ncooperation in multi-agent reinforcement learning (MARL). In a setting\ninvolving $N$ agents, this beneficial effect usually comes in the form of an\n$N$-fold linear convergence speedup, i.e., a reduction - proportional to $N$ -\nin the number of iterations required to reach a certain convergence precision.\nIn this paper, we show for the first time that this speedup property also holds\nfor a MARL framework subject to asynchronous delays in the local agents'\nupdates. In particular, we consider a policy evaluation problem in which\nmultiple agents cooperate to evaluate a common policy by communicating with a\ncentral aggregator. In this setting, we study the finite-time convergence of\n\\texttt{AsyncMATD}, an asynchronous multi-agent temporal difference (TD)\nlearning algorithm in which agents' local TD update directions are subject to\nasynchronous bounded delays. Our main contribution is providing a finite-time\nanalysis of \\texttt{AsyncMATD}, for which we establish a linear convergence\nspeedup while highlighting the effect of time-varying asynchronous delays on\nthe resulting convergence rate.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.20441v1"
    },
    {
        "title": "Agentic LLM Workflows for Generating Patient-Friendly Medical Reports",
        "authors": [
            "Malavikha Sudarshan",
            "Sophie Shih",
            "Estella Yee",
            "Alina Yang",
            "John Zou",
            "Cathy Chen",
            "Quan Zhou",
            "Leon Chen",
            "Chinmay Singhal",
            "George Shih"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The application of Large Language Models (LLMs) in healthcare is expanding\nrapidly, with one potential use case being the translation of formal medical\nreports into patient-legible equivalents. Currently, LLM outputs often need to\nbe edited and evaluated by a human to ensure both factual accuracy and\ncomprehensibility, and this is true for the above use case. We aim to minimize\nthis step by proposing an agentic workflow with the Reflexion framework, which\nuses iterative self-reflection to correct outputs from an LLM. This pipeline\nwas tested and compared to zero-shot prompting on 16 randomized radiology\nreports. In our multi-agent approach, reports had an accuracy rate of 94.94%\nwhen looking at verification of ICD-10 codes, compared to zero-shot prompted\nreports, which had an accuracy rate of 68.23%. Additionally, 81.25% of the\nfinal reflected reports required no corrections for accuracy or readability,\nwhile only 25% of zero-shot prompted reports met these criteria without needing\nmodifications. These results indicate that our approach presents a feasible\nmethod for communicating clinical findings to patients in a quick, efficient\nand coherent manner whilst also retaining medical accuracy. The codebase is\navailable for viewing at\nhttp://github.com/malavikhasudarshan/Multi-Agent-Patient-Letter-Generation.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01112v2"
    },
    {
        "title": "Asynchronous Credit Assignment Framework for Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Yongheng Liang",
            "Hejun Wu",
            "Haitao Wang",
            "Hao Cai"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Credit assignment is a core problem that distinguishes agents' marginal\ncontributions for optimizing cooperative strategies in multi-agent\nreinforcement learning (MARL). Current credit assignment methods usually assume\nsynchronous decision-making among agents. However, a prerequisite for many\nrealistic cooperative tasks is asynchronous decision-making by agents, without\nwaiting for others to avoid disastrous consequences. To address this issue, we\npropose an asynchronous credit assignment framework with a problem model called\nADEX-POMDP and a multiplicative value decomposition (MVD) algorithm. ADEX-POMDP\nis an asynchronous problem model with extra virtual agents for a decentralized\npartially observable markov decision process. We prove that ADEX-POMDP\npreserves both the task equilibrium and the algorithm convergence. MVD utilizes\nmultiplicative interaction to efficiently capture the interactions of\nasynchronous decisions, and we theoretically demonstrate its advantages in\nhandling asynchronous tasks. Experimental results show that on two asynchronous\ndecision-making benchmarks, Overcooked and POAC, MVD not only consistently\noutperforms state-of-the-art MARL methods but also provides the\ninterpretability for asynchronous cooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.03692v1"
    },
    {
        "title": "Emergence in Multi-Agent Systems: A Safety Perspective",
        "authors": [
            "Philipp Altmann",
            "Julian Schönberger",
            "Steffen Illium",
            "Maximilian Zorn",
            "Fabian Ritz",
            "Tom Haider",
            "Simon Burton",
            "Thomas Gabor"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Emergent effects can arise in multi-agent systems (MAS) where execution is\ndecentralized and reliant on local information. These effects may range from\nminor deviations in behavior to catastrophic system failures. To formally\ndefine these effects, we identify misalignments between the global inherent\nspecification (the true specification) and its local approximation (such as the\nconfiguration of different reward components or observations). Using\nestablished safety terminology, we develop a framework to understand these\nemergent effects. To showcase the resulting implications, we use two broadly\nconfigurable exemplary gridworld scenarios, where insufficient specification\nleads to unintended behavior deviations when derived independently. Recognizing\nthat a global adaptation might not always be feasible, we propose adjusting the\nunderlying parameterizations to mitigate these issues, thereby improving the\nsystem's alignment and reducing the risk of emergent failures.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.04514v1"
    },
    {
        "title": "Bridging Training and Execution via Dynamic Directed Graph-Based\n  Communication in Cooperative Multi-Agent Systems",
        "authors": [
            "Zhuohui Zhang",
            "Bin He",
            "Bin Cheng",
            "Gang Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent systems must learn to communicate and understand interactions\nbetween agents to achieve cooperative goals in partially observed tasks.\nHowever, existing approaches lack a dynamic directed communication mechanism\nand rely on global states, thus diminishing the role of communication in\ncentralized training. Thus, we propose the Transformer-based graph coarsening\nnetwork (TGCNet), a novel multi-agent reinforcement learning (MARL) algorithm.\nTGCNet learns the topological structure of a dynamic directed graph to\nrepresent the communication policy and integrates graph coarsening networks to\napproximate the representation of global state during training. It also\nutilizes the Transformer decoder for feature extraction during execution.\nExperiments on multiple cooperative MARL benchmarks demonstrate\nstate-of-the-art performance compared to popular MARL algorithms. Further\nablation studies validate the effectiveness of our dynamic directed graph\ncommunication mechanism and graph coarsening networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07397v2"
    },
    {
        "title": "Multilevel Graph Reinforcement Learning for Consistent Cognitive\n  Decision-making in Heterogeneous Mixed Autonomy",
        "authors": [
            "Xin Gao",
            "Zhaoyang Ma",
            "Xueyuan Li",
            "Xiaoqiang Meng",
            "Zirui Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In the realm of heterogeneous mixed autonomy, vehicles experience dynamic\nspatial correlations and nonlinear temporal interactions in a complex,\nnon-Euclidean space. These complexities pose significant challenges to\ntraditional decision-making frameworks. Addressing this, we propose a\nhierarchical reinforcement learning framework integrated with multilevel graph\nrepresentations, which effectively comprehends and models the spatiotemporal\ninteractions among vehicles navigating through uncertain traffic conditions\nwith varying decision-making systems. Rooted in multilevel graph representation\ntheory, our approach encapsulates spatiotemporal relationships inherent in\nnon-Euclidean spaces. A weighted graph represents spatiotemporal features\nbetween nodes, addressing the degree imbalance inherent in dynamic graphs. We\nintegrate asynchronous parallel hierarchical reinforcement learning with a\nmultilevel graph representation and a multi-head attention mechanism, which\nenables connected autonomous vehicles (CAVs) to exhibit capabilities akin to\nhuman cognition, facilitating consistent decision-making across various\ncritical dimensions. The proposed decision-making strategy is validated in\nchallenging environments characterized by high density, randomness, and\ndynamism on highway roads. We assess the performance of our framework through\nablation studies, comparative analyses, and spatiotemporal trajectory\nevaluations. This study presents a quantitative analysis of decision-making\nmechanisms mirroring human cognitive functions in the realm of heterogeneous\nmixed autonomy, promoting the development of multi-dimensional decision-making\nstrategies and a sophisticated distribution of attentional resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.08516v1"
    },
    {
        "title": "Value-Enriched Population Synthesis: Integrating a Motivational Layer",
        "authors": [
            "Alba Aguilera",
            "Miquel Albertí",
            "Nardine Osman",
            "Georgina Curto"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In recent years, computational improvements have allowed for more nuanced,\ndata-driven and geographically explicit agent-based simulations. So far,\nsimulations have struggled to adequately represent the attributes that motivate\nthe actions of the agents. In fact, existing population synthesis frameworks\ngenerate agent profiles limited to socio-demographic attributes. In this paper,\nwe introduce a novel value-enriched population synthesis framework that\nintegrates a motivational layer with the traditional individual and household\nsocio-demographic layers. Our research highlights the significance of extending\nthe profile of agents in synthetic populations by incorporating data on values,\nideologies, opinions and vital priorities, which motivate the agents'\nbehaviour. This motivational layer can help us develop a more nuanced\ndecision-making mechanism for the agents in social simulation settings. Our\nmethodology integrates microdata and macrodata within different Bayesian\nnetwork structures. This contribution allows to generate synthetic populations\nwith integrated value systems that preserve the inherent socio-demographic\ndistributions of the real population in any specific region.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.09407v1"
    },
    {
        "title": "Algorithmic Contract Design with Reinforcement Learning Agents",
        "authors": [
            "David Molina Concha",
            "Kyeonghyeon Park",
            "Hyun-Rok Lee",
            "Taesik Lee",
            "Chi-Guhn Lee"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We introduce a novel problem setting for algorithmic contract design, named\nthe principal-MARL contract design problem. This setting extends traditional\ncontract design to account for dynamic and stochastic environments using Markov\nGames and Multi-Agent Reinforcement Learning. To tackle this problem, we\npropose a Multi-Objective Bayesian Optimization (MOBO) framework named\nConstrained Pareto Maximum Entropy Search (cPMES). Our approach integrates MOBO\nand MARL to explore the highly constrained contract design space, identifying\npromising incentive and recruitment decisions. cPMES transforms the\nprincipal-MARL contract design problem into an unconstrained multi-objective\nproblem, leveraging the probability of feasibility as part of the objectives\nand ensuring promising designs predicted on the feasibility border are included\nin the Pareto front. By focusing the entropy prediction on designs within the\nPareto set, cPMES mitigates the risk of the search strategy being overwhelmed\nby entropy from constraints. We demonstrate the effectiveness of cPMES through\nextensive benchmark studies in synthetic and simulated environments, showing\nits ability to find feasible contract designs that maximize the principal's\nobjectives. Additionally, we provide theoretical support with a sub-linear\nregret bound concerning the number of iterations.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.09686v1"
    },
    {
        "title": "MegaAgent: A Practical Framework for Autonomous Cooperation in\n  Large-Scale LLM Agent Systems",
        "authors": [
            "Qian Wang",
            "Tianyu Wang",
            "Qinbin Li",
            "Jingsheng Liang",
            "Bingsheng He"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the emergence of large language models (LLMs), LLM-powered multi-agent\nsystems (LLM-MA systems) have been proposed to tackle real-world tasks.\nHowever, their agents mostly follow predefined Standard Operating Procedures\n(SOPs) that remain unchanged across the whole interaction, lacking autonomy and\nscalability. Additionally, current solutions often overlook the necessity for\neffective agent cooperation. To address the above limitations, we propose\nMegaAgent, a practical framework designed for autonomous cooperation in\nlarge-scale LLM Agent systems. MegaAgent leverages the autonomy of agents to\ndynamically generate agents based on task requirements, incorporating features\nsuch as automatically dividing tasks, systematic planning and monitoring of\nagent activities, and managing concurrent operations. In addition, MegaAgent is\ndesigned with a hierarchical structure and employs system-level parallelism to\nenhance performance and boost communication. We demonstrate the effectiveness\nof MegaAgent through Gobang game development, showing that it outperforms\npopular LLM-MA systems; and national policy simulation, demonstrating its high\nautonomy and potential to rapidly scale up to 590 agents while ensuring\neffective cooperation among them. Our results indicate that MegaAgent is the\nfirst autonomous large-scale LLM-MA system with no pre-defined SOPs, high\neffectiveness and scalability, paving the way for further research in this\nfield. Our code is at https://anonymous.4open.science/r/MegaAgent-81F3.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.09955v2"
    },
    {
        "title": "Analyzing the Impact of Electric Vehicles on Local Energy Systems using\n  Digital Twins",
        "authors": [
            "Daniel René Bayer",
            "Marco Pruckner"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The electrification of the transportation and heating sector, the so-called\nsector coupling, is one of the core elements to achieve independence from\nfossil fuels. As it highly affects the electricity demand, especially on the\nlocal level, the integrated modeling and simulation of all sectors is a\npromising approach for analyzing design decisions or complex control\nstrategies. This paper analyzes the increase in electricity demand resulting\nfrom sector coupling, mainly due to integrating electric vehicles into urban\nenergy systems. Therefore, we utilize a digital twin of an existing local\nenergy system and extend it with a mobility simulation model to evaluate the\nimpact of electric vehicles on the distribution grid level. Our findings\nindicate a significant rise in annual electricity consumption attributed to\nelectric vehicles, with home charging alone resulting in a 78% increase.\nHowever, we demonstrate that integrating photovoltaic and battery energy\nstorage systems can effectively mitigate this rise.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.10763v1"
    },
    {
        "title": "Multi-Agent Based Simulation for Investigating Centralized Charging\n  Strategies and their Impact on Electric Vehicle Home Charging Ecosystem",
        "authors": [
            "Kristoffer Christensen",
            "Bo Nørregaard Jørgensen",
            "Zheng Grace Ma"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper addresses the critical integration of electric vehicles (EVs) into\nthe electricity grid, which is essential for achieving carbon neutrality by\n2050. The rapid increase in EV adoption poses significant challenges to the\nexisting grid infrastructure, particularly in managing the increasing\nelectricity demand and mitigating the risk of grid overloads. Centralized EV\ncharging strategies are investigated due to their potential to optimize grid\nstability and efficiency, compared to decentralized approaches that may\nexacerbate grid stress. Utilizing a multi-agent based simulation model, the\nstudy provides a realistic representation of the electric vehicle home charging\necosystem in a case study of Strib, Denmark. The findings show that the\nEarliest-deadline-first and Round Robin perform best with 100% EV adoption in\nterms of EV user satisfaction. The simulation considers a realistic adoption\ncurve, EV charging strategies, EV models, and driving patterns to capture the\nfull ecosystem dynamics over a long-term period with high resolution (hourly).\nAdditionally, the study offers detailed load profiles for future distribution\ngrids, demonstrating how centralized charging strategies can efficiently manage\ngrid loads and prevent overloads.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.10773v1"
    },
    {
        "title": "Multi-agent based modeling for investigating excess heat utilization\n  from electrolyzer production to district heating network",
        "authors": [
            "Kristoffer Christensen",
            "Bo Nørregaard Jørgensen",
            "Zheng Grace Ma"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Power-to-Hydrogen is crucial for the renewable energy transition, yet\nexisting literature lacks business models for the significant excess heat it\ngenerates. This study addresses this by evaluating three models for selling\nelectrolyzer-generated heat to district heating grids: constant, flexible, and\nrenewable-source hydrogen production, with and without heat sales. Using\nagent-based modeling and multi-criteria decision-making methods (VIKOR, TOPSIS,\nPROMETHEE), it finds that selling excess heat can cut hydrogen production costs\nby 5.6%. The optimal model operates flexibly with electricity spot prices,\nincludes heat sales, and maintains a hydrogen price of 3.3 EUR/kg.\nEnvironmentally, hydrogen production from grid electricity could emit up to\n13,783.8 tons of CO2 over four years from 2023. The best economic and\nenvironmental model uses renewable sources and sells heat at 3.5 EUR/kg\n",
        "pdf_link": "http://arxiv.org/pdf/2408.10783v1"
    },
    {
        "title": "Multi-Agent Based Simulation for Decentralized Electric Vehicle Charging\n  Strategies and their Impacts",
        "authors": [
            "Kristoffer Christensen",
            "Bo Nørregaard Jørgensen",
            "Zheng Grace Ma"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The growing shift towards a Smart Grid involves integrating numerous new\ndigital energy solutions into the energy ecosystems to address problems arising\nfrom the transition to carbon neutrality, particularly in linking the\nelectricity and transportation sectors. Yet, this shift brings challenges due\nto mass electric vehicle adoption and the lack of methods to adequately assess\nvarious EV charging algorithms and their ecosystem impacts. This paper\nintroduces a multi-agent based simulation model, validated through a case study\nof a Danish radial distribution network serving 126 households. The study\nreveals that traditional charging leads to grid overload by 2031 at 67% EV\npenetration, while decentralized strategies like Real-Time Pricing could cause\noverloads as early as 2028. The developed multi-agent based simulation\ndemonstrates its ability to offer detailed, hourly analysis of future load\nprofiles in distribution grids, and therefore, can be applied to other\nprospective scenarios in similar energy systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.10790v1"
    },
    {
        "title": "Reaching New Heights in Multi-Agent Collective Construction",
        "authors": [
            "Martin Rameš",
            "Pavel Surynek"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We propose a new approach for multi-agent collective construction, based on\nthe idea of reversible ramps. Our ReRamp algorithm utilizes reversible\nside-ramps to generate construction plans for ramped block structures higher\nand larger than was previously possible using state-of-the-art planning\nalgorithms, given the same building area. We compare the ReRamp algorithm to\nsimilar state-of-the-art algorithms on a set of benchmark instances, where we\ndemonstrate its superior computational speed. We also establish in our\nexperiments that the ReRamp algorithm is capable of generating plans for a\nsingle-story house, an important milestone on the road to real-world\nmulti-agent construction applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.13615v1"
    },
    {
        "title": "Decentralized Unlabeled Multi-agent Pathfinding Via Target And Priority\n  Swapping (With Supplementary)",
        "authors": [
            "Stepan Dergachev",
            "Konstantin Yakovlev"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper we study a challenging variant of the multi-agent pathfinding\nproblem (MAPF), when a set of agents must reach a set of goal locations, but it\ndoes not matter which agent reaches a specific goal - Anonymous MAPF (AMAPF).\nCurrent optimal and suboptimal AMAPF solvers rely on the existence of a\ncentralized controller which is in charge of both target assignment and\npathfinding. We extend the state of the art and present the first AMAPF solver\ncapable of solving the problem at hand in a fully decentralized fashion, when\neach agent makes decisions individually and relies only on the local\ncommunication with the others. The core of our method is a priority and target\nswapping procedure tailored to produce consistent goal assignments (i.e. making\nsure that no two agents are heading towards the same goal). Coupled with an\nestablished rule-based path planning, we end up with a TP-SWAP, an efficient\nand flexible approach to solve decentralized AMAPF. On the theoretical side, we\nprove that TP-SWAP is complete (i.e. TP-SWAP guarantees that each target will\nbe reached by some agent). Empirically, we evaluate TP-SWAP across a wide range\nof setups and compare it to both centralized and decentralized baselines.\nIndeed, TP-SWAP outperforms the fully-decentralized competitor and can even\noutperform the semi-decentralized one (i.e. the one relying on the initial\nconsistent goal assignment) in terms of flowtime (a widespread cost objective\nin MAPF\n",
        "pdf_link": "http://arxiv.org/pdf/2408.14948v1"
    },
    {
        "title": "Evolution of Social Norms in LLM Agents using Natural Language",
        "authors": [
            "Ilya Horiguchi",
            "Takahide Yoshida",
            "Takashi Ikegami"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Recent advancements in Large Language Models (LLMs) have spurred a surge of\ninterest in leveraging these models for game-theoretical simulations, where\nLLMs act as individual agents engaging in social interactions. This study\nexplores the potential for LLM agents to spontaneously generate and adhere to\nnormative strategies through natural language discourse, building upon the\nfoundational work of Axelrod's metanorm games. Our experiments demonstrate that\nthrough dialogue, LLM agents can form complex social norms, such as\nmetanorms-norms enforcing the punishment of those who do not punish\ncheating-purely through natural language interaction. The results affirm the\neffectiveness of using LLM agents for simulating social interactions and\nunderstanding the emergence and evolution of complex strategies and norms\nthrough natural language. Future work may extend these findings by\nincorporating a wider range of scenarios and agent characteristics, aiming to\nuncover more nuanced mechanisms behind social norm formation.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.00993v1"
    },
    {
        "title": "Context-Aware Agent-based Model for Smart Long Distance Transport System",
        "authors": [
            "Muhammad Raees",
            "Afzal Ahmed"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Long-distance transport plays a vital role in the economic growth of\ncountries. However, there is a lack of systems being developed for monitoring\nand support of long-route vehicles (LRV). Sustainable and context-aware\ntransport systems with modern technologies are needed. We model for\nlong-distance vehicle transportation monitoring and support systems in a\nmulti-agent environment. Our model incorporates the distance vehicle transport\nmechanism through agent-based modeling (ABM). This model constitutes the design\nprotocol of ABM called Overview, Design, and Details (ODD). This model\nconstitutes that every category of agents is offering information as a service.\nHence, a federation of services through protocol for the communication between\nsensors and software components is desired. Such integration of services\nsupports monitoring and tracking of vehicles on the route. The model\nsimulations provide useful results for the integration of services based on\nsmart objects.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.02434v1"
    },
    {
        "title": "Towards Multi-agent Policy-based Directed Hypergraph Learning for\n  Traffic Signal Control",
        "authors": [
            "Kang Wang",
            "Zhishu Shen",
            "Zhenwei Wang",
            "Tiehua Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Deep reinforcement learning (DRL) methods that incorporate graph neural\nnetworks (GNNs) have been extensively studied for intelligent traffic signal\ncontrol, which aims to coordinate traffic signals effectively across multiple\nintersections. Despite this progress, the standard graph learning used in these\nmethods still struggles to capture higher-order correlations in real-world\ntraffic flow. In this paper, we propose a multi-agent proximal policy\noptimization framework DHG-PPO, which incorporates PPO and directed hypergraph\nmodule to extract the spatio-temporal attributes of the road networks. DHG-PPO\nenables multiple agents to ingeniously interact through the dynamical\nconstruction of hypergraph. The effectiveness of DHG-PPO is validated in terms\nof average travel time and throughput against state-of-the-art baselines\nthrough extensive experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05037v1"
    },
    {
        "title": "Enhancing the Performance of Multi-Vehicle Navigation in Unstructured\n  Environments using Hard Sample Mining",
        "authors": [
            "Yining Ma",
            "Ang Li",
            "Qadeer Khan",
            "Daniel Cremers"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Contemporary research in autonomous driving has demonstrated tremendous\npotential in emulating the traits of human driving. However, they primarily\ncater to areas with well built road infrastructure and appropriate traffic\nmanagement systems. Therefore, in the absence of traffic signals or in\nunstructured environments, these self-driving algorithms are expected to fail.\nThis paper proposes a strategy for autonomously navigating multiple vehicles in\nclose proximity to their desired destinations without traffic rules in\nunstructured environments.\n  Graphical Neural Networks (GNNs) have demonstrated good utility for this task\nof multi-vehicle control. Among the different alternatives of training GNNs,\nsupervised methods have proven to be most data-efficient, albeit require ground\ntruth labels. However, these labels may not always be available, particularly\nin unstructured environments without traffic regulations. Therefore, a tedious\noptimization process may be required to determine them while ensuring that the\nvehicles reach their desired destination and do not collide with each other or\nany obstacles. Therefore, in order to expedite the training process, it is\nessential to reduce the optimization time and select only those samples for\nlabeling that add most value to the training. In this paper, we propose a warm\nstart method that first uses a pre-trained model trained on a simpler subset of\ndata. Inference is then done on more complicated scenarios, to determine the\nhard samples wherein the model faces the greatest predicament. This is measured\nby the difficulty vehicles encounter in reaching their desired destination\nwithout collision. Experimental results demonstrate that mining for hard\nsamples in this manner reduces the requirement for supervised training data by\n10 fold. Videos and code can be found here:\n\\url{https://yininghase.github.io/multiagent-collision-mining/}.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.05119v1"
    },
    {
        "title": "Foragax: An Agent-Based Modelling Framework Based on JAX",
        "authors": [
            "Siddharth Chaturvedi",
            "Ahmed El-Gazzar",
            "Marcel van Gerven"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Foraging for resources is a ubiquitous activity conducted by living organisms\nin a shared environment to maintain their homeostasis. Modelling multi-agent\nforaging in-silico allows us to study both individual and collective emergent\nbehaviour in a tractable manner. Agent-based modelling has proven to be\neffective in simulating such tasks, though scaling the simulations to\naccommodate large numbers of agents with complex dynamics remains challenging.\nIn this work, we present Foragax, a general-purpose, scalable,\nhardware-accelerated, multi-agent foraging toolkit. Leveraging the JAX library,\nour toolkit can simulate thousands of agents foraging in a common environment,\nin an end-to-end vectorized and differentiable manner. The toolkit provides\nagent-based modelling tools to model various foraging tasks, including options\nto design custom spatial and temporal agent dynamics, control policies, sensor\nmodels, and boundary conditions. Further, the number of agents during such\nsimulations can be increased or decreased based on custom rules. While applied\nto foraging, the toolkit can also be used to model and simulate a wide range of\nother multi-agent scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06345v3"
    },
    {
        "title": "A Quality Diversity Approach to Automatically Generate Multi-Agent Path\n  Finding Benchmark Maps",
        "authors": [
            "Cheng Qian",
            "Yulun Zhang",
            "Varun Bhatt",
            "Matthew Christopher Fontaine",
            "Stefanos Nikolaidis",
            "Jiaoyang Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We use the Quality Diversity (QD) algorithm with Neural Cellular Automata\n(NCA) to generate benchmark maps for Multi-Agent Path Finding (MAPF)\nalgorithms. Previously, MAPF algorithms are tested using fixed, human-designed\nbenchmark maps. However, such fixed benchmark maps have several problems.\nFirst, these maps may not cover all the potential failure scenarios for the\nalgorithms. Second, when comparing different algorithms, fixed benchmark maps\nmay introduce bias leading to unfair comparisons between algorithms. In this\nwork, we take advantage of the QD algorithm and NCA with different objectives\nand diversity measures to generate maps with patterns to comprehensively\nunderstand the performance of MAPF algorithms and be able to make fair\ncomparisons between two MAPF algorithms to provide further information on the\nselection between two algorithms. Empirically, we employ this technique to\ngenerate diverse benchmark maps to evaluate and compare the behavior of\ndifferent types of MAPF algorithms such as bounded-suboptimal algorithms,\nsuboptimal algorithms, and reinforcement-learning-based algorithms. Through\nboth single-planner experiments and comparisons between algorithms, we identify\npatterns where each algorithm excels and detect disparities in runtime or\nsuccess rates between different algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06888v2"
    },
    {
        "title": "Simultaneous Topology Estimation and Synchronization of Dynamical\n  Networks with Time-varying Topology",
        "authors": [
            "Nana Wang",
            "Esteban Restrepo",
            "Dimos V. Dimarogonas"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We propose an adaptive control strategy for the simultaneous estimation of\ntopology and synchronization in complex dynamical networks with unknown,\ntime-varying topology. Our approach transforms the problem of time-varying\ntopology estimation into a problem of estimating the time-varying weights of a\ncomplete graph, utilizing an edge-agreement framework. We introduce two\nauxiliary networks: one that satisfies the persistent excitation condition to\nfacilitate topology estimation, while the other, a uniform-$\\delta$\npersistently exciting network, ensures the boundedness of both weight\nestimation and synchronization errors, assuming bounded time-varying weights\nand their derivatives. A relevant numerical example shows the efficiency of our\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.08404v1"
    },
    {
        "title": "Learning Nudges for Conditional Cooperation: A Multi-Agent Reinforcement\n  Learning Model",
        "authors": [
            "Shatayu Kulkarni",
            "Sabine Brunswicker"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The public goods game describes a social dilemma in which a large proportion\nof agents act as conditional cooperators (CC): they only act cooperatively if\nthey see others acting cooperatively because they satisfice with the social\nnorm to be in line with what others are doing instead of optimizing\ncooperation. CCs are guided by aspiration-based reinforcement learning guided\nby past experiences of interactions with others and satisficing aspirations. In\nmany real-world settings, reinforcing social norms do not emerge. In this\npaper, we propose that an optimizing reinforcement agent can facilitate\ncooperation through nudges, i.e. indirect mechanisms for cooperation to happen.\nThe agent's goal is to motivate CCs into cooperation through its own actions to\ncreate social norms that signal that others are cooperating. We introduce a\nmulti-agent reinforcement learning model for public goods games, with 3 CC\nlearning agents using aspirational reinforcement learning and 1 nudging agent\nusing deep reinforcement learning to learn nudges that optimize cooperation.\nFor our nudging agent, we model two distinct reward functions, one maximizing\nthe total game return (sum DRL) and one maximizing the number of cooperative\ncontributions contributions higher than a proportional threshold (prop DRL).\nOur results show that our aspiration-based RL model for CC agents is consistent\nwith empirically observed CC behavior. Games combining 3 CC RL agents and one\nnudging RL agent outperform the baseline consisting of 4 CC RL agents only. The\nsum DRL nudging agent increases the total sum of contributions by 8.22% and the\ntotal proportion of cooperative contributions by 12.42%, while the prop nudging\nDRL increases the total sum of contributions by 8.85% and the total proportion\nof cooperative contributions by 14.87%. Our findings advance the literature on\npublic goods games and reinforcement learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09509v1"
    },
    {
        "title": "Bearing-Distance Based Flocking with Zone-Based Interactions",
        "authors": [
            "Hossein B. Jond"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper presents a novel zone-based flocking control approach suitable for\ndynamic multi-agent systems (MAS). Inspired by Reynolds behavioral rules for\n$boids$, flocking behavioral rules with the zones of repulsion, conflict,\nattraction, and surveillance are introduced. For each agent, using only bearing\nand distance measurements, behavioral deviation vectors quantify the deviations\nfrom the local separation, local and global flock velocity alignment, local\ncohesion, obstacle avoidance and boundary conditions, and strategic separation\nfor avoiding alien agents. The control strategy uses the local perception-based\nbehavioral deviation vectors to guide each agent's motion. Additionally, the\ncontrol strategy incorporates a directionally-aware obstacle avoidance\nmechanism that prioritizes obstacles in the agent's forward path. We also\nintroduce a simplified flocking model where agents interact with their\nneighbors within a single perception zone, without dividing it into separate\ninteraction zones. Simulation results validate the effectiveness of the models\nin creating flexible, adaptable, and scalable flocking behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.10047v3"
    },
    {
        "title": "Heterogeneous Mixed Traffic Control and Coordination",
        "authors": [
            "Iftekharul Islam",
            "Weizi Li",
            "Shuai Li",
            "Kevin Heaslip"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Urban intersections, filled with a diverse mix of vehicles from small cars to\nlarge semi-trailers, present a persistent challenge for traffic control and\nmanagement. This reality drives our investigation into how robot vehicles (RVs)\ncan transform such heterogeneous traffic flow, particularly at unsignalized\nintersections where traditional control methods often falter during power\nfailures and emergencies. Using reinforcement learning (RL) and real-world\ntraffic data, we study heterogeneous mixed traffic across complex intersections\nunder gradual automation by varying RV penetration from 10% to 90%. The results\nare compelling: average waiting times decrease by up to 86% and 91% compared to\nsignalized and unsignalized intersections, respectively. Additionally, we\nuncover a \"rarity advantage,\" where less frequent vehicles, such as trucks,\nbenefit the most from RV coordination (by up to 87%). RVs' presence also leads\nto lower CO2 emissions and fuel consumption compared to managing traffic via\ntraffic lights. Moreover, space headways decrease across all vehicle types as\nRV rate increases, indicating better road space utilization.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12330v1"
    },
    {
        "title": "Social impact of CAVs -- coexistence of machines and humans in the\n  context of route choice",
        "authors": [
            "Grzegorz Jamróz",
            "Ahmet Onur Akman",
            "Anastasia Psarou",
            "Zoltán Györgi Varga",
            "Rafał Kucharski"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Suppose in a stable urban traffic system populated only by human driven\nvehicles (HDVs), a given proportion (e.g. 10%) is replaced by a fleet of\nConnected and Autonomous Vehicles (CAVs), which share information and pursue a\ncollective goal. Suppose these vehicles are centrally coordinated and differ\nfrom HDVs only by their collective capacities allowing them to make more\nefficient routing decisions before the travel on a given day begins. Suppose\nthere is a choice between two routes and every day each driver makes a decision\nwhich route to take. Human drivers maximize their utility. CAVs might optimize\ndifferent goals, such as the total travel time of the fleet. We show that in\nthis plausible futuristic setting, the strategy CAVs are allowed to adopt may\nresult in human drivers either benefitting or being systematically\ndisadvantaged and urban networks becoming more or less optimal. Consequently,\nsome regulatory measures might become indispensable.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12839v1"
    },
    {
        "title": "Introducing Anisotropic Fields for Enhanced Diversity in Crowd\n  Simulation",
        "authors": [
            "Yihao Li",
            "Junyu Liu",
            "Xiaoyu Guan",
            "Hanming Hou",
            "Tianyu Huang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large crowds exhibit intricate behaviors and significant emergent properties,\nyet existing crowd simulation systems often lack behavioral diversity,\nresulting in homogeneous simulation outcomes. To address this limitation, we\npropose incorporating anisotropic fields (AFs) as a fundamental structure for\ndepicting the uncertainty in crowd movement. By leveraging AFs, our method can\nrapidly generate crowd simulations with intricate behavioral patterns that\nbetter reflect the inherent complexity of real crowds. The AFs are generated\neither through intuitive sketching or extracted from real crowd videos,\nenabling flexible and efficient crowd simulation systems. We demonstrate the\neffectiveness of our approach through several representative scenarios,\nshowcasing a significant improvement in behavioral diversity compared to\nclassical methods. Our findings indicate that by incorporating AFs, crowd\nsimulation systems can achieve a much higher similarity to real-world crowd\nsystems. Our code is publicly available at\nhttps://github.com/tomblack2014/AF\\_Generation.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.15831v1"
    },
    {
        "title": "Language Grounded Multi-agent Reinforcement Learning with\n  Human-interpretable Communication",
        "authors": [
            "Huao Li",
            "Hossein Nourkhiz Mahjoub",
            "Behdad Chalaki",
            "Vaishnav Tadiparthi",
            "Kwonjoon Lee",
            "Ehsan Moradi-Pari",
            "Charles Michael Lewis",
            "Katia P Sycara"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) methods have shown promise in\nenabling agents to learn a shared communication protocol from scratch and\naccomplish challenging team tasks. However, the learned language is usually not\ninterpretable to humans or other agents not co-trained together, limiting its\napplicability in ad-hoc teamwork scenarios. In this work, we propose a novel\ncomputational pipeline that aligns the communication space between MARL agents\nwith an embedding space of human natural language by grounding agent\ncommunications on synthetic data generated by embodied Large Language Models\n(LLMs) in interactive teamwork scenarios. Our results demonstrate that\nintroducing language grounding not only maintains task performance but also\naccelerates the emergence of communication. Furthermore, the learned\ncommunication protocols exhibit zero-shot generalization capabilities in ad-hoc\nteamwork scenarios with unseen teammates and novel task states. This work\npresents a significant step toward enabling effective communication and\ncollaboration between artificial agents and humans in real-world teamwork\nsettings.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.17348v2"
    },
    {
        "title": "Multi-UAV Enabled MEC Networks: Optimizing Delay through Intelligent 3D\n  Trajectory Planning and Resource Allocation",
        "authors": [
            "Zhiying Wang",
            "Tianxi Wei",
            "Gang Sun",
            "Xinyue Liu",
            "Hongfang Yu",
            "Dusit Niyato"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Mobile Edge Computing (MEC) reduces the computational burden on terminal\ndevices by shortening the distance between these devices and computing nodes.\nIntegrating Unmanned Aerial Vehicles (UAVs) with enhanced MEC networks can\nleverage the high mobility of UAVs to flexibly adjust network topology, further\nexpanding the applicability of MEC. However, in highly dynamic and complex\nreal-world environments, it is crucial to balance task offloading effectiveness\nwith algorithm performance. This paper investigates a multi-UAV communication\nnetwork equipped with edge computing nodes to assist terminal users in task\ncomputation. Our goal is to reduce the task processing delay for users through\nthe joint optimization of discrete computation modes, continuous 3D\ntrajectories, and resource assignment. To address the challenges posed by the\nmixed action space, we propose a Multi-UAV Edge Computing Resource Scheduling\n(MUECRS) algorithm, which comprises two key components: 1) trajectory\noptimization, and 2) computation mode and resource management. Experimental\nresults demonstrate our method effectively designs the 3D flight trajectories\nof UAVs, enabling rapid terminal coverage. Furthermore, the proposed algorithm\nachieves efficient resource deployment and scheduling, outperforming\ncomparative algorithms by at least 16.7%, demonstrating superior adaptability\nand robustness.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.17882v1"
    },
    {
        "title": "Variational Auto-encoder Based Solutions to Interactive Dynamic\n  Influence Diagrams",
        "authors": [
            "Yinghui Pan",
            "Biyang Ma",
            "Hanyi Zhang",
            "Yifeng Zeng"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Addressing multiagent decision problems in AI, especially those involving\ncollaborative or competitive agents acting concurrently in a partially\nobservable and stochastic environment, remains a formidable challenge. While\nInteractive Dynamic Influence Diagrams~(I-DIDs) have offered a promising\ndecision framework for such problems, they encounter limitations when the\nsubject agent encounters unknown behaviors exhibited by other agents that are\nnot explicitly modeled within the I-DID. This can lead to sub-optimal responses\nfrom the subject agent. In this paper, we propose a novel data-driven approach\nthat utilizes an encoder-decoder architecture, particularly a variational\nautoencoder, to enhance I-DID solutions. By integrating a perplexity-based tree\nloss function into the optimization algorithm of the variational autoencoder,\ncoupled with the advantages of Zig-Zag One-Hot encoding and decoding, we\ngenerate potential behaviors of other agents within the I-DID that are more\nlikely to contain their true behaviors, even from limited interactions. This\nnew approach enables the subject agent to respond more appropriately to unknown\nbehaviors, thus improving its decision quality. We empirically demonstrate the\neffectiveness of the proposed approach in two well-established problem domains,\nhighlighting its potential for handling multi-agent decision problems with\nunknown behaviors. This work is the first time of using neural networks based\napproaches to deal with the I-DID challenge in agent planning and learning\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.19965v1"
    },
    {
        "title": "MARLadona - Towards Cooperative Team Play Using Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Zichong Li",
            "Filip Bjelonic",
            "Victor Klemm",
            "Marco Hutter"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Robot soccer, in its full complexity, poses an unsolved research challenge.\nCurrent solutions heavily rely on engineered heuristic strategies, which lack\nrobustness and adaptability. Deep reinforcement learning has gained significant\ntraction in various complex robotics tasks such as locomotion, manipulation,\nand competitive games (e.g., AlphaZero, OpenAI Five), making it a promising\nsolution to the robot soccer problem. This paper introduces MARLadona. A\ndecentralized multi-agent reinforcement learning (MARL) training pipeline\ncapable of producing agents with sophisticated team play behavior, bridging the\nshortcomings of heuristic methods. Further, we created an open-source\nmulti-agent soccer environment based on Isaac Gym. Utilizing our MARL framework\nand a modified a global entity encoder as our core architecture, our approach\nachieves a 66.8% win rate against HELIOS agent, which employs a\nstate-of-the-art heuristic strategy. Furthermore, we provided an in-depth\nanalysis of the policy behavior and interpreted the agent's intention using the\ncritic network.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.20326v2"
    },
    {
        "title": "Social coordination perpetuates stereotypic expectations and behaviors\n  across generations in deep multi-agent reinforcement learning",
        "authors": [
            "Rebekah A. Gelpí",
            "Yikai Tang",
            "Ethan C. Jackson",
            "William A. Cunningham"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Despite often being perceived as morally objectionable, stereotypes are a\ncommon feature of social groups, a phenomenon that has often been attributed to\nbiased motivations or limits on the ability to process information. We argue\nthat one reason for this continued prevalence is that pre-existing expectations\nabout how others will behave, in the context of social coordination, can change\nthe behaviors of one's social partners, creating the very stereotype one\nexpected to see, even in the absence of other potential sources of\nstereotyping. We use a computational model of dynamic social coordination to\nillustrate how this \"feedback loop\" can emerge, engendering and entrenching\nstereotypic behavior, and then show that human behavior on the task generates a\ncomparable feedback loop. Notably, people's choices on the task are not related\nto social dominance or system justification, suggesting biased motivations are\nnot necessary to maintain these stereotypes.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.01763v1"
    },
    {
        "title": "YOLO-MARL: You Only LLM Once for Multi-agent Reinforcement Learning",
        "authors": [
            "Yuan Zhuang",
            "Yi Shen",
            "Zhili Zhang",
            "Yuxiao Chen",
            "Fei Miao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Advancements in deep multi-agent reinforcement learning (MARL) have\npositioned it as a promising approach for decision-making in cooperative games.\nHowever, it still remains challenging for MARL agents to learn cooperative\nstrategies for some game environments. Recently, large language models (LLMs)\nhave demonstrated emergent reasoning capabilities, making them promising\ncandidates for enhancing coordination among the agents. However, due to the\nmodel size of LLMs, it can be expensive to frequently infer LLMs for actions\nthat agents can take. In this work, we propose You Only LLM Once for MARL\n(YOLO-MARL), a novel framework that leverages the high-level task planning\ncapabilities of LLMs to improve the policy learning process of multi-agents in\ncooperative games. Notably, for each game environment, YOLO-MARL only requires\none time interaction with LLMs in the proposed strategy generation, state\ninterpretation and planning function generation modules, before the MARL policy\ntraining process. This avoids the ongoing costs and computational time\nassociated with frequent LLMs API calls during training. Moreover, the trained\ndecentralized normal-sized neural network-based policies operate independently\nof the LLM. We evaluate our method across three different environments and\ndemonstrate that YOLO-MARL outperforms traditional MARL algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.03997v1"
    },
    {
        "title": "Dynamic Programming based Local Search approaches for Multi-Agent Path\n  Finding problems on Directed Graphs",
        "authors": [
            "Irene Saccani",
            "Stefano Ardizzoni",
            "Luca Consolini",
            "Marco Locatelli"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Among sub-optimal Multi-Agent Path Finding (MAPF) solvers, rule-based\nalgorithms are particularly appealing since they are complete. Even in crowded\nscenarios, they allow finding a feasible solution that brings each agent to its\ntarget, preventing deadlock situations. However, generally, rule-based\nalgorithms provide much longer solutions than the shortest one. The main\ncontribution of this paper is introducing a new local search procedure for\nimproving a known feasible solution. We start from a feasible sub-optimal\nsolution, and perform a local search in a neighborhood of this solution. If we\nare able to find a shorter solution, we repeat this procedure until the\nsolution cannot be shortened anymore. At the end, we obtain a solution that is\nstill sub-optimal, but generally of much better quality than the initial one.\nWe propose two different local search policies. In the first, we explore all\npaths in which the agents positions remain in a neighborhood of the\ncorresponding positions of the reference solution. In the second, we set an\nupper limit to the number of agents that can change their path with respect to\nthe reference solution. These two different policies can also be alternated. We\nexplore the neighborhoods by dynamic programming. The fact that our search is\nlocal is fundamental in terms of time complexity. Indeed, if the dynamic\nprogramming approach is applied to the full MAPF problem, the number of\nexplored states grows exponentially with the number of agents. Instead, the\nintroduction of a locality constraint allows exploring the neghborhoods in a\ntime that grows polynomially with respect to the number of agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.07954v1"
    },
    {
        "title": "Crowd IQ -- Aggregating Opinions to Boost Performance",
        "authors": [
            "Michal Kosinski",
            "Yoram Bachrach",
            "Thore Graepel",
            "Giergji Kasneci",
            "Jurgen Van Gael"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We show how the quality of decisions based on the aggregated opinions of the\ncrowd can be conveniently studied using a sample of individual responses to a\nstandard IQ questionnaire. We aggregated the responses to the IQ questionnaire\nusing simple majority voting and a machine learning approach based on a\nprobabilistic graphical model. The score for the aggregated questionnaire,\nCrowd IQ, serves as a quality measure of decisions based on aggregating\nopinions, which also allows quantifying individual and crowd performance on the\nsame scale. We show that Crowd IQ grows quickly with the size of the crowd but\nsaturates, and that for small homogeneous crowds the Crowd IQ significantly\nexceeds the IQ of even their most intelligent member. We investigate\nalternative ways of aggregating the responses and the impact of the aggregation\nmethod on the resulting Crowd IQ. We also discuss Contextual IQ, a method of\nquantifying the individual participant's contribution to the Crowd IQ based on\nthe Shapley value from cooperative game theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.10004v1"
    },
    {
        "title": "A Multi-LLM Orchestration Engine for Personalized, Context-Rich\n  Assistance",
        "authors": [
            "Sumedh Rasal"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In recent years, large language models have demonstrated remarkable\ncapabilities in natural language understanding and generation. However, these\nmodels often struggle with hallucinations and maintaining long term contextual\nrelevance, particularly when dealing with private or local data. This paper\npresents a novel architecture that addresses these challenges by integrating an\norchestration engine that utilizes multiple LLMs in conjunction with a temporal\ngraph database and a vector database. The proposed system captures user\ninteractions, builds a graph representation of conversations, and stores nodes\nand edges that map associations between key concepts, entities, and behaviors\nover time. This graph based structure allows the system to develop an evolving\nunderstanding of the user preferences, providing personalized and contextually\nrelevant answers. In addition to this, a vector database encodes private data\nto supply detailed information when needed, allowing the LLM to access and\nsynthesize complex responses. To further enhance reliability, the orchestration\nengine coordinates multiple LLMs to generate comprehensive answers and\niteratively reflect on their accuracy. The result is an adaptive, privacy\ncentric AI assistant capable of offering deeper, more relevant interactions\nwhile minimizing the risk of hallucinations. This paper outlines the\narchitecture, methodology, and potential applications of this system,\ncontributing a new direction in personalized, context aware AI assistance.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.10039v1"
    },
    {
        "title": "Large Language Model-Driven Cross-Domain Orchestration Using Multi-Agent\n  Workflow",
        "authors": [
            "Xiaonan Xu",
            "Haoshuo Chen",
            "Jesse E. Simsarian",
            "Roland Ryf",
            "Nicolas K. Fontaine",
            "Mikael Mazur",
            "Lauren Dallachiesa",
            "David T. Neilson"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We showcase an application that leverages multiple agents, powered by large\nlanguage models and integrated tools, to collaboratively solve complex network\noperation tasks across various domains. The tasks include real-time topology\nretrieval, network optimization using physical models, and fiber switching\nfacilitated by a robotic arm.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.10831v1"
    },
    {
        "title": "Agent-Based Modelling of Older Adult Needs for Autonomous\n  Mobility-on-Demand: A Case Study in Winnipeg, Canada",
        "authors": [
            "Manon Prédhumeau",
            "Ed Manley"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  As the populations continue to age across many nations, ensuring accessible\nand efficient transportation options for older adults has become an\nincreasingly important concern. Autonomous Mobility-on-Demand (AMoD) systems\nhave emerged as a potential solution to address the needs faced by older adults\nin their daily mobility. However, estimation of older adult mobility needs, and\nhow they vary over space and time, is crucial for effective planning and\nimplementation of such service, and conventional four-step approaches lack the\ngranularity to fully account for these needs. To address this challenge, we\npropose an agent-based model of older adults mobility demand in Winnipeg,\nCanada. The model is built for 2022 using primarily open data, and is\nimplemented in the Multi-Agent Transport Simulation (MATSim) toolkit. After\ncalibration to accurately reproduce observed travel behaviors, a new AMoD\nservice is tested in simulation and its potential adoption among Winnipeg older\nadults is explored. The model can help policy makers to estimate the needs of\nthe elderly populations for door-to-door transportation and can guide the\ndesign of AMoD transport systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.11416v1"
    },
    {
        "title": "Corridor Generating Algorithm for Multi-Agent Pathfinding",
        "authors": [
            "Arseniy Pertzovsky"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper, we solve the classical Multi-agent Pathfinding (MAPF) problem.\nExisting approaches struggle to solve dense MAPF instances. In this paper, we\npropose a Corridor Generating Algorithm for MAPF, namely CGA-MAPF. In CGA-MAPF,\nthe agents build \\emph{corridors}, a set of connected vertices, from current\nlocations towards agents' goals and evacuate other agents out of the corridors\nto avoid collisions and deadlocks. The proposed algorithm has a reachability\nproperty, i.e. every agent is guaranteed to reach its goal location at some\npoint. In the experimental section, we demonstrate that CGA-MAPF outperforms\nbaseline algorithms in terms of success rate across diverse MAPF benchmark\ngrids, achieving state-of-the-art performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.12397v1"
    },
    {
        "title": "Enhancing LLM Trading Performance with Fact-Subjectivity Aware Reasoning",
        "authors": [
            "Qian Wang",
            "Yuchen Gao",
            "Zhenheng Tang",
            "Bingqiao Luo",
            "Bingsheng He"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  While many studies prove more advanced LLMs perform better on tasks such as\nmath and coding, we notice that in cryptocurrency trading, stronger LLMs work\nworse than weaker LLMs often. To study how this counter-intuitive phenomenon\noccurs, we examine the LLM reasoning processes on making trading decisions. We\nfind that separating the reasoning process into factual and subjective\ncomponents can lead to higher profits. Building on this insight, we introduce a\nmulti-agent framework, FS-ReasoningAgent, which enables LLMs to recognize and\nlearn from both factual and subjective reasoning. Extensive experiments\ndemonstrate that this framework enhances LLM trading performance in\ncryptocurrency markets. Additionally, an ablation study reveals that relying on\nsubjective news tends to generate higher returns in bull markets, whereas\nfocusing on factual information yields better results in bear markets. Our code\nand data are available at\n\\url{https://anonymous.4open.science/r/FS-ReasoningAgent-B55F/}.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.12464v2"
    },
    {
        "title": "Aegis:An Advanced LLM-Based Multi-Agent for Intelligent Functional\n  Safety Engineering",
        "authors": [
            "Lu Shi",
            "Bin Qi",
            "Jiarui Luo",
            "Yang Zhang",
            "Zhanzhao Liang",
            "Zhaowei Gao",
            "Wenke Deng",
            "Lin Sun"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Functional safety is a critical aspect of automotive engineering,\nencompassing all phases of a vehicle's lifecycle, including design,\ndevelopment, production, operation, and decommissioning. This domain involves\nhighly knowledge-intensive tasks. This paper introduces Aegis: An Advanced\nLLM-Based Multi-Agent for Intelligent Functional Safety Engineering. Aegis is\nspecifically designed to support complex functional safety tasks within the\nautomotive sector. It is tailored to perform Hazard Analysis and Risk\nAssessment(HARA), document Functional Safety Requirements(FSR), and plan test\ncases for Automatic Emergency Braking(AEB) systems. The most advanced version,\nAegis-Max, leverages Retrieval-Augmented Generation(RAG) and reflective\nmechanisms to enhance its capability in managing complex, knowledge-intensive\ntasks. Additionally, targeted prompt refinement by professional functional\nsafety practitioners can significantly optimize Aegis's performance in the\nfunctional safety domain. This paper demonstrates the potential of Aegis to\nimprove the efficiency and effectiveness of functional safety processes in\nautomotive engineering.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.12475v2"
    },
    {
        "title": "DTPPO: Dual-Transformer Encoder-based Proximal Policy Optimization for\n  Multi-UAV Navigation in Unseen Complex Environments",
        "authors": [
            "Anning Wei",
            "Jintao Liang",
            "Kaiyuan Lin",
            "Ziyue Li",
            "Rui Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Existing multi-agent deep reinforcement learning (MADRL) methods for\nmulti-UAV navigation face challenges in generalization, particularly when\napplied to unseen complex environments. To address these limitations, we\npropose a Dual-Transformer Encoder-based Proximal Policy Optimization (DTPPO)\nmethod. DTPPO enhances multi-UAV collaboration through a Spatial Transformer,\nwhich models inter-agent dynamics, and a Temporal Transformer, which captures\ntemporal dependencies to improve generalization across diverse environments.\nThis architecture allows UAVs to navigate new, unseen environments without\nretraining. Extensive simulations demonstrate that DTPPO outperforms current\nMADRL methods in terms of transferability, obstacle avoidance, and navigation\nefficiency across environments with varying obstacle densities. The results\nconfirm DTPPO's effectiveness as a robust solution for multi-UAV navigation in\nboth known and unseen scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.15205v1"
    },
    {
        "title": "Towards Efficient Collaboration via Graph Modeling in Reinforcement\n  Learning",
        "authors": [
            "Wenzhe Fan",
            "Zishun Yu",
            "Chengdong Ma",
            "Changye Li",
            "Yaodong Yang",
            "Xinhua Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In multi-agent reinforcement learning, a commonly considered paradigm is\ncentralized training with decentralized execution. However, in this framework,\ndecentralized execution restricts the development of coordinated policies due\nto the local observation limitation. In this paper, we consider the cooperation\namong neighboring agents during execution and formulate their interactions as a\ngraph. Thus, we introduce a novel encoder-decoder architecture named\nFactor-based Multi-Agent Transformer ($f$-MAT) that utilizes a transformer to\nenable communication between neighboring agents during both training and\nexecution. By dividing agents into different overlapping groups and\nrepresenting each group with a factor, $f$-MAT achieves efficient message\npassing and parallel action generation through factor-based attention layers.\nEmpirical results in networked systems such as traffic scheduling and power\ncontrol demonstrate that $f$-MAT achieves superior performance compared to\nstrong baselines, thereby paving the way for handling complex collaborative\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.15841v3"
    },
    {
        "title": "IBGP: Imperfect Byzantine Generals Problem for Zero-Shot Robustness in\n  Communicative Multi-Agent Systems",
        "authors": [
            "Yihuan Mao",
            "Yipeng Kang",
            "Peilun Li",
            "Ning Zhang",
            "Wei Xu",
            "Chongjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  As large language model (LLM) agents increasingly integrate into our\ninfrastructure, their robust coordination and message synchronization become\nvital. The Byzantine Generals Problem (BGP) is a critical model for\nconstructing resilient multi-agent systems (MAS) under adversarial attacks. It\ndescribes a scenario where malicious agents with unknown identities exist in\nthe system-situations that, in our context, could result from LLM agents'\nhallucinations or external attacks. In BGP, the objective of the entire system\nis to reach a consensus on the action to be taken. Traditional BGP requires\nglobal consensus among all agents; however, in practical scenarios, global\nconsensus is not always necessary and can even be inefficient. Therefore, there\nis a pressing need to explore a refined version of BGP that aligns with the\nlocal coordination patterns observed in MAS. We refer to this refined version\nas Imperfect BGP (IBGP) in our research, aiming to address this discrepancy. To\ntackle this issue, we propose a framework that leverages consensus protocols\nwithin general MAS settings, providing provable resilience against\ncommunication attacks and adaptability to changing environments, as validated\nby empirical results. Additionally, we present a case study in a sensor network\nenvironment to illustrate the practical application of our protocol.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.16237v2"
    },
    {
        "title": "Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning\n  for Inventory Control in Supply Chains",
        "authors": [
            "Niki Kotecha",
            "Antonio del Rio Chanona"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Inventory control in modern supply chains has attracted significant attention\ndue to the increasing number of disruptive shocks and the challenges posed by\ncomplex dynamics, uncertainties, and limited collaboration. Traditional\nmethods, which often rely on static parameters, struggle to adapt to changing\nenvironments. This paper proposes a Multi-Agent Reinforcement Learning (MARL)\nframework with Graph Neural Networks (GNNs) for state representation to address\nthese limitations.\n  Our approach redefines the action space by parameterizing heuristic inventory\ncontrol policies, making it adaptive as the parameters dynamically adjust based\non system conditions. By leveraging the inherent graph structure of supply\nchains, our framework enables agents to learn the system's topology, and we\nemploy a centralized learning, decentralized execution scheme that allows\nagents to learn collaboratively while overcoming information-sharing\nconstraints. Additionally, we incorporate global mean pooling and\nregularization techniques to enhance performance.\n  We test the capabilities of our proposed approach on four different supply\nchain configurations and conduct a sensitivity analysis. This work paves the\nway for utilizing MARL-GNN frameworks to improve inventory management in\ncomplex, decentralized supply chain environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.18631v1"
    },
    {
        "title": "The Signaler-Responder Game: Learning to Communicate using Thompson\n  Sampling",
        "authors": [
            "Radhika Bhuckory",
            "Bhaskar Krishnamachari"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We are interested in studying how heterogeneous agents can learn to\ncommunicate and cooperate with each other without being explicitly\npre-programmed to do so. Motivated by this goal, we present and analyze a\ndistributed solution to a two-player signaler-responder game which is defined\nas follows. The signaler agent has a random, exogenous need and can choose from\nfour different strategies: never signal, always signal, signal when need, and\nsignal when no need. The responder agent can choose to either ignore or respond\nto the signal. We define a reward to both agents when they cooperate to satisfy\nthe signaler's need, and costs associated with communication, response and\nunmet needs. We identify pure Nash equilibria of the game and the conditions\nunder which they occur. As a solution for this game, we propose two new\ndistributed Bayesian learning algorithms, one for each agent, based on the\nclassic Thompson Sampling policy for multi-armed bandits. These algorithms\nallow both agents to update beliefs about both the exogenous need and the\nbehavior of the other agent and optimize their own expected reward. We show\nthat by using these policies, the agents are able to intelligently adapt their\nstrategies over multiple iterations to attain efficient, reward-maximizing\nequilibria under different settings, communicating and cooperating when it is\nrewarding to do so, and not communicating or cooperating when it is too\nexpensive.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.19962v1"
    },
    {
        "title": "Relational Weight Optimization for Enhancing Team Performance in\n  Multi-Agent Multi-Armed Bandits",
        "authors": [
            "Monish Reddy Kotturu",
            "Saniya Vahedian Movahed",
            "Paul Robinette",
            "Kshitij Jerath",
            "Amanda Redlich",
            "Reza Azadeh"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We introduce an approach to improve team performance in a Multi-Agent\nMulti-Armed Bandit (MAMAB) framework using Fastest Mixing Markov Chain (FMMC)\nand Fastest Distributed Linear Averaging (FDLA) optimization algorithms. The\nmulti-agent team is represented using a fixed relational network and simulated\nusing the Coop-UCB2 algorithm. The edge weights of the communication network\ndirectly impact the time taken to reach distributed consensus. Our goal is to\nshrink the timescale on which the convergence of the consensus occurs to\nachieve optimal team performance and maximize reward. Through our experiments,\nwe show that the convergence to team consensus occurs slightly faster in large\nconstrained networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.23379v1"
    },
    {
        "title": "CPIG: Leveraging Consistency Policy with Intention Guidance for\n  Multi-agent Exploration",
        "authors": [
            "Yuqian Fu",
            "Yuanheng Zhu",
            "Haoran Li",
            "Zijie Zhao",
            "Jiajun Chai",
            "Dongbin Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Efficient exploration is crucial in cooperative multi-agent reinforcement\nlearning (MARL), especially in sparse-reward settings. However, due to the\nreliance on the unimodal policy, existing methods are prone to falling into the\nlocal optima, hindering the effective exploration of better policies.\nFurthermore, in sparse-reward settings, each agent tends to receive a scarce\nreward, which poses significant challenges to inter-agent cooperation. This not\nonly increases the difficulty of policy learning but also degrades the overall\nperformance of multi-agent tasks. To address these issues, we propose a\nConsistency Policy with Intention Guidance (CPIG), with two primary components:\n(a) introducing a multimodal policy to enhance the agent's exploration\ncapability, and (b) sharing the intention among agents to foster agent\ncooperation. For component (a), CPIG incorporates a Consistency model as the\npolicy, leveraging its multimodal nature and stochastic characteristics to\nfacilitate exploration. Regarding component (b), we introduce an Intention\nLearner to deduce the intention on the global state from each agent's local\nobservation. This intention then serves as a guidance for the Consistency\nPolicy, promoting cooperation among agents. The proposed method is evaluated in\nmulti-agent particle environments (MPE) and multi-agent MuJoCo (MAMuJoCo).\nEmpirical results demonstrate that our method not only achieves comparable\nperformance to various baselines in dense-reward environments but also\nsignificantly enhances performance in sparse-reward settings, outperforming\nstate-of-the-art (SOTA) algorithms by 20%.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.03603v2"
    },
    {
        "title": "Do you want to play a game? Learning to play Tic-Tac-Toe in Hypermedia\n  Environments",
        "authors": [
            "Katharine Beaumont",
            "Rem Collier"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We demonstrate the integration of Transfer Learning into a hypermedia\nMulti-Agent System using the Multi-Agent MicroServices (MAMS) architectural\nstyle. Agents use RDF knowledge stores to reason over information and apply\nReinforcement Learning techniques to learn how to interact with a Tic-Tac-Toe\nAPI. Agents form advisor-advisee relationships in order to speed up individual\nlearning and exploit and learn from data on the Web.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06398v1"
    },
    {
        "title": "MA-DV2F: A Multi-Agent Navigation Framework using Dynamic Velocity\n  Vector Field",
        "authors": [
            "Yining Ma",
            "Qadeer Khan",
            "Daniel Cremers"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper we propose MA-DV2F: Multi-Agent Dynamic Velocity Vector Field.\nIt is a framework for simultaneously controlling a group of vehicles in\nchallenging environments. DV2F is generated for each vehicle independently and\nprovides a map of reference orientation and speed that a vehicle must attain at\nany point on the navigation grid such that it safely reaches its target. The\nfield is dynamically updated depending on the speed and proximity of the\nego-vehicle to other agents. This dynamic adaptation of the velocity vector\nfield allows prevention of imminent collisions. Experimental results show that\nMA-DV2F outperforms concurrent methods in terms of safety, computational\nefficiency and accuracy in reaching the target when scaling to a large number\nof vehicles. Project page for this work can be found here:\nhttps://yininghase.github.io/MA-DV2F/\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06404v1"
    },
    {
        "title": "Generalist Virtual Agents: A Survey on Autonomous Agents Across Digital\n  Platforms",
        "authors": [
            "Minghe Gao",
            "Wendong Bu",
            "Bingchen Miao",
            "Yang Wu",
            "Yunfei Li",
            "Juncheng Li",
            "Siliang Tang",
            "Qi Wu",
            "Yueting Zhuang",
            "Meng Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper, we introduce the Generalist Virtual Agent (GVA), an autonomous\nentity engineered to function across diverse digital platforms and\nenvironments, assisting users by executing a variety of tasks. This survey\ndelves into the evolution of GVAs, tracing their progress from early\nintelligent assistants to contemporary implementations that incorporate\nlarge-scale models. We explore both the philosophical underpinnings and\npractical foundations of GVAs, addressing their developmental challenges and\nthe methodologies currently employed in their design and operation. By\npresenting a detailed taxonomy of GVA environments, tasks, and capabilities,\nthis paper aims to bridge the theoretical and practical aspects of GVAs,\nconcluding those that operate in environments closely mirroring the real world\nare more likely to demonstrate human-like intelligence. We discuss potential\nfuture directions for GVA research, highlighting the necessity for realistic\nevaluation metrics and the enhancement of long-sequence decision-making\ncapabilities to advance the field toward more systematic or embodied\napplications. This work not only synthesizes the existing body of literature\nbut also proposes frameworks for future investigations, contributing\nsignificantly to the ongoing development of intelligent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.10943v1"
    },
    {
        "title": "Autonomous System Safety Properties with Multi-Machine Hybrid Event-B",
        "authors": [
            "Richard Banach"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Event-B is a well known methodology for the verified design and development\nof systems that can be characterised as discrete transition systems. Hybrid\nEvent-B is a conservative extension that interleaves the discrete transitions\nof Event-B (assumed to be temporally isolated) with episodes of continuously\nvarying state change. While a single Hybrid Event-B machine is sufficient for\napplications with a single locus of control, it will not do for autonomous\nsystems, which have several loci of control by default. Multi-machine Hybrid\nEvent-B is designed to allow the specification of systems with several loci of\ncontrol. The formalism is succinctly surveyed, pointing out the subtle semantic\nissues involved. The multi-machine formalism is then used to specify a\nrelatively simple incident response system, involving a controller, two drones\nand three responders, working in a partly coordinated and partly independent\nfashion to manage a putative hazardous scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.14168v1"
    },
    {
        "title": "Agent-Based Modeling for Multimodal Transportation of $CO_2$ for Carbon\n  Capture, Utilization, and Storage: CCUS-Agent",
        "authors": [
            "Majbah Uddin",
            "Robin Clark",
            "Michael Hilliard",
            "Joshua Thompson",
            "Matthew Langholtz",
            "Erin Webb"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  To understand the system-level interactions between the entities in Carbon\nCapture, Utilization, and Storage (CCUS), an agent-based foundational modeling\ntool, CCUS-Agent, is developed for a large-scale study of transportation flows\nand infrastructure in the United States. Key features of the tool include (i)\nmodular design, (ii) multiple transportation modes, (iii) capabilities for\nextension, and (iv) testing against various system components and networks of\nsmall and large sizes. Five matching algorithms for CO2 supply agents (e.g.,\npowerplants and industrial facilities) and demand agents (e.g., storage and\nutilization sites) are explored: Most Profitable First Year (MPFY), Most\nProfitable All Years (MPAY), Shortest Total Distance First Year (SDFY),\nShortest Total Distance All Years (SDAY), and Shortest distance to long-haul\ntransport All Years (ACAY). Before matching, the supply agent, demand agent,\nand route must be available, and the connection must be profitable. A\nprofitable connection means the supply agent portion of revenue from the 45Q\ntax credit must cover the supply agent costs and all transportation costs,\nwhile the demand agent revenue portion must cover all demand agent costs. A\ncase study employing over 5,500 supply and demand agents and multimodal CCUS\ntransportation infrastructure in the contiguous United States is conducted. The\nresults suggest that it is possible to capture over 9 billion tonnes (GT) of\nCO2 from 2025 to 2043, which will increase significantly to 22 GT if the\ncapture costs are reduced by 40%. The MPFY and SDFY algorithms capture more CO2\nearlier in the time horizon, while the MPAY and SDAY algorithms capture more\nlater in the time horizon.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.14438v1"
    },
    {
        "title": "Enhancing Clinical Trial Patient Matching through Knowledge Augmentation\n  with Multi-Agents",
        "authors": [
            "Hanwen Shi",
            "Jin Zhang",
            "Kunpeng Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Matching patients effectively and efficiently for clinical trials is a\nsignificant challenge due to the complexity and variability of patient profiles\nand trial criteria. This paper presents a novel framework, Multi-Agents for\nKnowledge Augmentation (MAKA), designed to enhance patient-trial matching by\ndynamically supplementing matching prompts with external, domain-specific\nknowledge. The MAKA architecture consists of five key components: a knowledge\nprobing agent that detects gaps in domain knowledge, a navigation agent that\nmanages interactions among multiple specialized knowledge augmentation agents,\na knowledge augmentation agent that incorporates relevant information into\npatient-trial matching prompts, a supervision agent aligning the outputs from\nother agents with the instructions and a matching agent making the final\nselection decision. This approach enhances the accuracy and contextual richness\nof patient matching, addresses inherent knowledge gaps in both trail criteria\nand large language models (LLMs), and improves the alignment between patient\ncharacteristics and the criteria.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.14637v1"
    },
    {
        "title": "Online Guidance Graph Optimization for Lifelong Multi-Agent Path Finding",
        "authors": [
            "Hongzhi Zang",
            "Yulun Zhang",
            "He Jiang",
            "Zhe Chen",
            "Daniel Harabor",
            "Peter J. Stuckey",
            "Jiaoyang Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We study the problem of optimizing a guidance policy capable of dynamically\nguiding the agents for lifelong Multi-Agent Path Finding based on real-time\ntraffic patterns. Multi-Agent Path Finding (MAPF) focuses on moving multiple\nagents from their starts to goals without collisions. Its lifelong variant,\nLMAPF, continuously assigns new goals to agents. In this work, we focus on\nimproving the solution quality of PIBT, a state-of-the-art rule-based LMAPF\nalgorithm, by optimizing a policy to generate adaptive guidance. We design two\npipelines to incorporate guidance in PIBT in two different ways. We demonstrate\nthe superiority of the optimized policy over both static guidance and\nhuman-designed policies. Additionally, we explore scenarios where task\ndistribution changes over time, a challenging yet common situation in\nreal-world applications that is rarely explored in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.16506v2"
    },
    {
        "title": "Incentives to Build Houses, Trade Houses, or Trade House Building Skills\n  in Simulated Worlds under Various Governing Systems or Institutions:\n  Comparing Multi-agent Reinforcement Learning to Generative Agent-based Model",
        "authors": [
            "Aslan S. Dizaji"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  It has been shown that social institutions impact human motivations to\nproduce different behaviours, such as amount of working or specialisation in\nlabor. With advancement in artificial intelligence (AI), specifically large\nlanguage models (LLMs), now it is possible to perform in-silico simulations to\ntest various hypotheses around this topic. Here, I simulate two somewhat\nsimilar worlds using multi-agent reinforcement learning (MARL) framework of the\nAI-Economist and generative agent-based model (GABM) framework of the\nConcordia. In the extended versions of the AI-Economist and Concordia, the\nagents are able to build houses, trade houses, and trade house building skill.\nMoreover, along the individualistic-collectivists axis, there are a set of\nthree governing systems: Full-Libertarian, Semi-Libertarian/Utilitarian, and\nFull-Utilitarian. Additionally, in the extended AI-Economist, the\nSemi-Libertarian/Utilitarian system is further divided to a set of three\ngoverning institutions along the discriminative axis: Inclusive, Arbitrary, and\nExtractive. Building on these, I am able to show that among governing systems\nand institutions of the extended AI-Economist, under the\nSemi-Libertarian/Utilitarian and Inclusive government, the ratios of building\nhouses to trading houses and trading house building skill are higher than the\nrest. Furthermore, I am able to show that in the extended Concordia when the\ncentral government care about equality in the society, the Full-Utilitarian\nsystem generates agents building more houses and trading more house building\nskill. In contrast, these economic activities are higher under the\nFull-Libertarian system when the central government cares about productivity in\nthe society. Overall, the focus of this paper is to compare and contrast two\nadvanced techniques of AI, MARL and GABM, to simulate a similar social\nphenomena with limitations.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.17724v1"
    },
    {
        "title": "Normative Feeling: Socially Patterned Affective Mechanisms",
        "authors": [
            "Stavros Anagnou",
            "Daniel Polani",
            "Christoph Salge"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Norms and the normative processes that enforce them such as social\nmaintenance are considered fundamental building blocks of human societies,\nshaping many aspects of our cognition. However, emerging work argues that the\nbuilding blocks of normativity emerged much earlier in evolution than\npreviously considered. In light of this, we argue that normative processes must\nbe taken into account to consider the evolution of even ancient processes such\nas affect. We show through an agent-based model (with an evolvable model of\naffect) that different affective dispositions emerge when taking into account\nsocial maintenance. Further, we demonstrate that social maintenance results in\nthe emergence of a minimal population regulation mechanism in a dynamic\nenvironment, without the need to predict the state of the environment or reason\nabout the mental state of others. We use a cultural interpretation of our model\nto derive a new definition of norm emergence which distinguishes between\nindirect and direct social maintenance. Indirect social maintenance tends to\none equilibrium (similar to environmental scaffolding) and the richer direct\nsocial maintenance results in many possible equilibria in behaviour, capturing\nan important aspect of normative behaviour in that it bears a certain degree of\narbitrariness. We also distinguish between single-variable and mechanistic\nnormative regularities. A mechanistic regularity, rather than a particular\nbehaviour specified by one value e.g. walking speed, is a collection of values\nthat specify a culturally patterned version of a psychological mechanism e.g. a\ndisposition. This is how culture reprograms entire cognitive and physiological\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.18037v2"
    },
    {
        "title": "RMIO: A Model-Based MARL Framework for Scenarios with Observation Loss\n  in Some Agents",
        "authors": [
            "Shi Zifeng",
            "Liu Meiqin",
            "Zhang Senlin",
            "Zheng Ronghao",
            "Dong Shanling"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In recent years, model-based reinforcement learning (MBRL) has emerged as a\nsolution to address sample complexity in multi-agent reinforcement learning\n(MARL) by modeling agent-environment dynamics to improve sample efficiency.\nHowever, most MBRL methods assume complete and continuous observations from\neach agent during the inference stage, which can be overly idealistic in\npractical applications. A novel model-based MARL approach called RMIO is\nintroduced to address this limitation, specifically designed for scenarios\nwhere observation is lost in some agent. RMIO leverages the world model to\nreconstruct missing observations, and further reduces reconstruction errors\nthrough inter-agent information integration to ensure stable multi-agent\ndecision-making. Secondly, unlike CTCE methods such as MAMBA, RMIO adopts the\nCTDE paradigm in standard environment, and enabling limited communication only\nwhen agents lack observation data, thereby reducing reliance on communication.\nAdditionally, RMIO improves asymptotic performance through strategies such as\nreward smoothing, a dual-layer experience replay buffer, and an RNN-augmented\npolicy model, surpassing previous work. Our experiments conducted in both the\nSMAC and MaMuJoCo environments demonstrate that RMIO outperforms current\nstate-of-the-art approaches in terms of asymptotic convergence performance and\npolicy robustness, both in standard mission settings and in scenarios involving\nobservation loss.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.19639v1"
    },
    {
        "title": "Neural Power-Optimal Magnetorquer Solution for Multi-Agent Formation and\n  Attitude Control",
        "authors": [
            "Yuta Takahashi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper presents an efficient algorithm for finding the power-optimal\ncurrents of magnetorquer, a satellite attitude actuator in Earth orbit, for\nmulti-agent formation and attitude control. Specifically, this study\ndemonstrates that a set of power-optimal solutions can be derived through\nsequential convex programming and proposes a method to approximate these\nsolutions using a deep neural network (DNN). The practicality of this DNN model\nis demonstrated through numerical simulations of formation and attitude\ncontrol.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.00548v1"
    },
    {
        "title": "Distributed Task Allocation for Multi-Agent Systems: A Submodular\n  Optimization Approach",
        "authors": [
            "Jing Liu",
            "Fangfei Li",
            "Xin Jin",
            "Yang Tang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper investigates dynamic task allocation for multi-agent systems\n(MASs) under resource constraints, with a focus on maximizing the global\nutility of agents while ensuring a conflict-free allocation of targets. We\npresent a more adaptable submodular maximization framework for the MAS task\nallocation under resource constraints. Our proposed distributed greedy bundles\nalgorithm (DGBA) is specifically designed to address communication limitations\nin MASs and provides rigorous approximation guarantees for submodular\nmaximization under $q$-independent systems, with low computational complexity.\nSpecifically, DGBA can generate a feasible task allocation policy within\npolynomial time complexity, significantly reducing space complexity compared to\nexisting methods. To demonstrate practical viability of our approach, we apply\nDGBA to the scenario of active observation information acquisition within a\nmicro-satellite constellation, transforming the NP-hard task allocation problem\ninto a tractable submodular maximization problem under a $q$-independent system\nconstraint. Our method not only provides a specific performance bound but also\nsurpasses benchmark algorithms in metrics such as utility, cost, communication\ntime, and running time.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.02146v1"
    },
    {
        "title": "Modeling Speculative Trading Patterns in Token Markets: An Agent-Based\n  Analysis with TokenLab",
        "authors": [
            "Mengjue Wang",
            "Stylianos Kampakis"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper presents the application of Tokenlab, an agent-based modeling\nframework designed to analyze price dynamics and speculative behavior within\ntoken-based economies. By decomposing complex token systems into discrete agent\ninteractions governed by fundamental behavioral rules, Tokenlab simplifies the\nsimulation of otherwise intricate market scenarios. Its core innovation lies in\nits ability to model a range of speculative strategies and assess their\ncollective influence on token price evolution.\n  Through a novel controller mechanism, Tokenlab facilitates the simulation of\nmultiple speculator archetypes and their interactions, thereby providing\nvaluable insights into market sentiment and price formation. This method\nenables a systematic exploration of how varying degrees of speculative activity\nand evolving strategies across different market stages shape token price\ntrajectories. Our findings enhance the understanding of speculation in token\nmarkets and present a quantitative framework for measuring and interpreting\nmarket heat indicators.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.07512v1"
    },
    {
        "title": "A systematic review of norm emergence in multi-agent systems",
        "authors": [
            "Carmengelys Cordova",
            "Joaquin Taverner",
            "Elena Del Val",
            "Estefania Argente"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent systems (MAS) have gained relevance in the field of artificial\nintelligence by offering tools for modelling complex environments where\nautonomous agents interact to achieve common or individual goals. In these\nsystems, norms emerge as a fundamental component to regulate the behaviour of\nagents, promoting cooperation, coordination and conflict resolution. This\narticle presents a systematic review, following the PRISMA method, on the\nemergence of norms in MAS, exploring the main mechanisms and factors that\ninfluence this process. Sociological, structural, emotional and cognitive\naspects that facilitate the creation, propagation and reinforcement of norms\nare addressed. The findings highlight the crucial role of social network\ntopology, as well as the importance of emotions and shared values in the\nadoption and maintenance of norms. Furthermore, opportunities are identified\nfor future research that more explicitly integrates emotional and ethical\ndynamics in the design of adaptive normative systems. This work provides a\ncomprehensive overview of the current state of research on norm emergence in\nMAS, serving as a basis for advancing the development of more efficient and\nflexible systems in artificial and real-world contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.10609v1"
    },
    {
        "title": "Enhancing Multiagent Genetic Network Programming Performance Using\n  Search Space Reduction",
        "authors": [
            "Ali Kohan",
            "Mohamad Roshanzamir",
            "Roohallah Alizadehsani"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Genetic Network Programming (GNP) is an evolutionary algorithm that extends\nGenetic Programming (GP). It is typically used in agent control problems. In\ncontrast to GP, which employs a tree structure, GNP utilizes a directed graph\nstructure. During the evolutionary process, the connections between nodes\nchange to discover the optimal strategy. Due to the large number of node\nconnections, GNP has a large search space, making it challenging to identify an\nappropriate graph structure. One way to reduce this search space is by\nutilizing simplified operators that restrict the changeable node connections to\nthose participating in the fitness function. However, this method has not been\napplied to GNP structures that use separate graphs for each agent, such as\nsituation-based GNP (SBGNP). This paper proposes a method to apply simplified\noperators to SBGNP. To evaluate the performance of this method, we tested it on\nthe Tileworld benchmark, where the algorithm demonstrated improvements in\naverage fitness.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.11146v1"
    },
    {
        "title": "Efficient Multiagent Planning via Shared Action Suggestions",
        "authors": [
            "Dylan M. Asmar",
            "Mykel J. Kochenderfer"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Decentralized partially observable Markov decision processes with\ncommunication (Dec-POMDP-Com) provide a framework for multiagent decision\nmaking under uncertainty, but the NEXP-complete complexity renders solutions\nintractable in general. While sharing actions and observations can reduce the\ncomplexity to PSPACE-complete, we propose an approach that bridges POMDPs and\nDec-POMDPs by communicating only suggested joint actions, eliminating the need\nto share observations while maintaining performance comparable to fully\ncentralized planning and execution. Our algorithm estimates joint beliefs using\nshared actions to prune infeasible beliefs. Each agent maintains possible\nbelief sets for other agents, pruning them based on suggested actions to form\nan estimated joint belief usable with any centralized policy. This approach\nrequires solving a POMDP for each agent, reducing computational complexity\nwhile preserving performance. We demonstrate its effectiveness on several\nDec-POMDP benchmarks showing performance comparable to centralized methods when\nshared actions enable effective belief pruning. This action-based communication\nframework offers a natural avenue for integrating human-agent cooperation,\nopening new directions for scalable multiagent planning under uncertainty, with\napplications in both autonomous systems and human-agent teams.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.11430v1"
    },
    {
        "title": "On the Use of Abundant Road Speed Data for Travel Demand Calibration of\n  Urban Traffic Simulators",
        "authors": [
            "Suyash Vishnoi",
            "Akhil Shetty",
            "Iveel Tsogsuren",
            "Neha Arora",
            "Carolina Osorio"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This work develops a compute-efficient algorithm to tackle a fundamental\nproblem in transportation: that of urban travel demand estimation. It focuses\non the calibration of origin-destination travel demand input parameters for\nhigh-resolution traffic simulation models. It considers the use of abundant\ntraffic road speed data. The travel demand calibration problem is formulated as\na continuous, high-dimensional, simulation-based optimization (SO) problem with\nbound constraints. There is a lack of compute efficient algorithms to tackle\nthis problem. We propose the use of an SO algorithm that relies on an\nefficient, analytical, differentiable, physics-based traffic model, known as a\nmetamodel or surrogate model. We formulate a metamodel that enables the use of\nroad speed data. Tests are performed on a Salt Lake City network. We study how\nthe amount of data, as well as the congestion levels, impact both in-sample and\nout-of-sample performance. The proposed method outperforms the benchmark for\nboth in-sample and out-of-sample performance by 84.4% and 72.2% in terms of\nspeeds and counts, respectively. Most importantly, the proposed method yields\nthe highest compute efficiency, identifying solutions with good performance\nwithin few simulation function evaluations (i.e., with small samples).\n",
        "pdf_link": "http://arxiv.org/pdf/2412.14089v1"
    },
    {
        "title": "Knowledge Graph-Based Multi-Agent Path Planning in Dynamic Environments\n  using WAITR",
        "authors": [
            "Ted Edward Holmberg",
            "Elias Ioup",
            "Mahdi Abdelguerfi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper addresses the challenge of multi-agent path planning for efficient\ndata collection in dynamic, uncertain environments, exemplified by autonomous\nunderwater vehicles (AUVs) navigating the Gulf of Mexico. Traditional greedy\nalgorithms, though computationally efficient, often fall short in long-term\nplanning due to their short-sighted nature, missing crucial data collection\nopportunities and increasing exposure to hazards. To address these limitations,\nwe introduce WAITR (Weighted Aggregate Inter-Temporal Reward), a novel\npath-planning framework that integrates a knowledge graph with pathlet-based\nplanning, segmenting the environment into dynamic, speed-adjusted sub-regions\n(pathlets). This structure enables coordinated, adaptive planning, as agents\ncan operate within time-bound regions while dynamically responding to\nenvironmental changes. WAITR's cumulative scoring mechanism balances immediate\ndata collection with long-term optimization of Points of Interest (POIs),\nensuring safer navigation and comprehensive data coverage. Experimental results\nshow that WAITR substantially improves POI coverage and reduces exposure to\nhazards, achieving up to 27.1\\% greater event coverage than traditional greedy\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.19469v1"
    },
    {
        "title": "Decentralized Unlabeled Multi-Agent Navigation in Continuous Space",
        "authors": [
            "Stepan Dergachev",
            "Konstantin Yakovlev"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this work, we study the problem where a group of mobile agents needs to\nreach a set of goal locations, but it does not matter which agent reaches a\nspecific goal. Unlike most of the existing works on this topic that typically\nassume the existence of the centralized planner (or controller) and limit the\nagents' moves to a predefined graph of locations and transitions between them,\nin this work we focus on the decentralized scenarios, when each agent acts\nindividually relying only on local observations/communications and is free to\nmove in arbitrary direction at any time. Our iterative approach involves agents\nindividually selecting goals, exchanging them, planning paths, and at each time\nstep choose actions that balance between progressing along the paths and\navoiding collisions. The proposed method is shown to be complete under specific\nassumptions on how agents progress towards their current goals, and our\nempirical evaluation demonstrates its superiority over a baseline decentralized\nnavigation approach in success rate (i.e. is able to solve more problem\ninstances under a given time limit) and a comparison with the centralized TSWAP\nalgorithm reveals its efficiency in minimizing trajectory lengths for mission\naccomplishment.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.20233v1"
    },
    {
        "title": "Advances in Multi-agent Reinforcement Learning: Persistent Autonomy and\n  Robot Learning Lab Report 2024",
        "authors": [
            "Reza Azadeh"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) approaches have emerged as popular\nsolutions to address the general challenges of cooperation in multi-agent\nenvironments, where the success of achieving shared or individual goals\ncritically depends on the coordination and collaboration between agents.\nHowever, existing cooperative MARL methods face several challenges intrinsic to\nmulti-agent systems, such as the curse of dimensionality, non-stationarity, and\nthe need for a global exploration strategy. Moreover, the presence of agents\nwith constraints (e.g., limited battery life, restricted mobility) or distinct\nroles further exacerbates these challenges. This document provides an overview\nof recent advances in Multi-Agent Reinforcement Learning (MARL) conducted at\nthe Persistent Autonomy and Robot Learning (PeARL) lab at the University of\nMassachusetts Lowell. We briefly discuss various research directions and\npresent a selection of approaches proposed in our most recent publications. For\neach proposed approach, we also highlight potential future directions to\nfurther advance the field.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.21088v1"
    },
    {
        "title": "Dynamic Graph Communication for Decentralised Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Ben McClusky"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This work presents a novel communication framework for decentralized\nmulti-agent systems operating in dynamic network environments. Integrated into\na multi-agent reinforcement learning system, the framework is designed to\nenhance decision-making by optimizing the network's collective knowledge\nthrough efficient communication. Key contributions include adapting a static\nnetwork packet-routing scenario to a dynamic setting with node failures,\nincorporating a graph attention network layer in a recurrent message-passing\nframework, and introducing a multi-round communication targeting mechanism.\nThis approach enables an attention-based aggregation mechanism to be\nsuccessfully trained within a sparse-reward, dynamic network packet-routing\nenvironment using only reinforcement learning. Experimental results show\nimprovements in routing performance, including a 9.5 percent increase in\naverage rewards and a 6.4 percent reduction in communication overhead compared\nto a baseline system. The study also examines the ethical and legal\nimplications of deploying such systems in critical infrastructure and military\ncontexts, identifies current limitations, and suggests potential directions for\nfuture research.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00165v1"
    },
    {
        "title": "Agentic Systems: A Guide to Transforming Industries with Vertical AI\n  Agents",
        "authors": [
            "Fouad Bousetouane"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  The evolution of agentic systems represents a significant milestone in\nartificial intelligence and modern software systems, driven by the demand for\nvertical intelligence tailored to diverse industries. These systems enhance\nbusiness outcomes through adaptability, learning, and interaction with dynamic\nenvironments. At the forefront of this revolution are Large Language Model\n(LLM) agents, which serve as the cognitive backbone of these intelligent\nsystems. In response to the need for consistency and scalability, this work\nattempts to define a level of standardization for Vertical AI agent design\npatterns by identifying core building blocks and proposing a \\textbf{Cognitive\nSkills } Module, which incorporates domain-specific, purpose-built inference\ncapabilities. Building on these foundational concepts, this paper offers a\ncomprehensive introduction to agentic systems, detailing their core components,\noperational patterns, and implementation strategies. It further explores\npractical use cases and examples across various industries, highlighting the\ntransformative potential of LLM agents in driving industry-specific\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00881v1"
    },
    {
        "title": "Communicating Unexpectedness for Out-of-Distribution Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Min Whoo Lee",
            "Kibeom Kim",
            "Soo Wung Shin",
            "Minsu Lee",
            "Byoung-Tak Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Applying multi-agent reinforcement learning methods to realistic settings is\nchallenging as it may require the agents to quickly adapt to unexpected\nsituations that are rarely or never encountered in training. Recent methods for\ngeneralization to such out-of-distribution settings are limited to more\nspecific, restricted instances of distribution shifts. To tackle adaptation to\ndistribution shifts, we propose Unexpected Encoding Scheme, a novel\ndecentralized multi-agent reinforcement learning algorithm where agents\ncommunicate \"unexpectedness,\" the aspects of the environment that are\nsurprising. In addition to a message yielded by the original reward-driven\ncommunication, each agent predicts the next observation based on previous\nexperience, measures the discrepancy between the prediction and the actually\nencountered observation, and encodes this discrepancy as a message. Experiments\non multi-robot warehouse environment support that our proposed method adapts\nrobustly to dynamically changing training environments as well as\nout-of-distribution environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.01140v1"
    },
    {
        "title": "TACTIC: Task-Agnostic Contrastive pre-Training for Inter-Agent\n  Communication",
        "authors": [
            "Peihong Yu",
            "Manav Mishra",
            "Syed Zaidi",
            "Pratap Tokekar"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  The \"sight range dilemma\" in cooperative Multi-Agent Reinforcement Learning\n(MARL) presents a significant challenge: limited observability hinders team\ncoordination, while extensive sight ranges lead to distracted attention and\nreduced performance. While communication can potentially address this issue,\nexisting methods often struggle to generalize across different sight ranges,\nlimiting their effectiveness. We propose TACTIC, Task-Agnostic Contrastive\npre-Training strategy Inter-Agent Communication. TACTIC is an adaptive\ncommunication mechanism that enhances agent coordination even when the sight\nrange during execution is vastly different from that during training. The\ncommunication mechanism encodes messages and integrates them with local\nobservations, generating representations grounded in the global state using\ncontrastive learning. By learning to generate and interpret messages that\ncapture important information about the whole environment, TACTIC enables\nagents to effectively \"see\" more through communication, regardless of their\nsight ranges. We comprehensively evaluate TACTIC on the SMACv2 benchmark across\nvarious scenarios with broad sight ranges. The results demonstrate that TACTIC\nconsistently outperforms traditional state-of-the-art MARL techniques with and\nwithout communication, in terms of generalizing to sight ranges different from\nthose seen in training, particularly in cases of extremely limited or extensive\nobservability.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02174v1"
    },
    {
        "title": "A review on reinforcement learning methods for mobility on demand\n  systems",
        "authors": [
            "Tarek Chouaki",
            "Sebastian Hörl",
            "Jakob Puchinger"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Mobility on Demand (MoD) refers to mobility systems that operate on the basis\nof immediate travel demand. Typically, such a system consists of a fleet of\nvehicles that can be booked by customers when needed. The operation of these\nservices consists of two main tasks: deciding how vehicles are assigned to\nrequests (vehicle assignment); and deciding where vehicles move (including\ncharging stations) when they are not serving a request (rebalancing). A field\nof research is emerging around the design of operation strategies for MoD\nservices, and an increasingly popular trend is the use of learning based (most\noften Reinforcement Learning) approaches. We review, in this work, the\nliterature on algorithms for operation strategies of MoD systems that use\napproaches based on Reinforcement Learning with a focus on the types of\nalgorithms being used. The novelty of our review stands in three aspects:\nFirst, the algorithmic details are discussed and the approaches classified in a\nunified framework for sequential decision-making. Second, the use cases on\nwhich approaches are tested and their features are taken into account. Finally,\nvalidation methods that can be found across the literature are discussed. The\nreview aims at advancing the state of the art by identifying similarities and\ndifferences between approaches and highlighting current research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02569v2"
    },
    {
        "title": "Revisiting Communication Efficiency in Multi-Agent Reinforcement\n  Learning from the Dimensional Analysis Perspective",
        "authors": [
            "Chuxiong Sun",
            "Peng He",
            "Rui Wang",
            "Changwen Zheng"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  In this work, we introduce a novel perspective, i.e., dimensional analysis,\nto address the challenge of communication efficiency in Multi-Agent\nReinforcement Learning (MARL). Our findings reveal that simply optimizing the\ncontent and timing of communication at sending end is insufficient to fully\nresolve communication efficiency issues. Even after applying optimized and\ngated messages, dimensional redundancy and confounders still persist in the\nintegrated message embeddings at receiving end, which negatively impact\ncommunication quality and decision-making. To address these challenges, we\npropose Dimensional Rational Multi-Agent Communication (DRMAC), designed to\nmitigate both dimensional redundancy and confounders in MARL. DRMAC\nincorporates a redundancy-reduction regularization term to encourage the\ndecoupling of information across dimensions within the learned representations\nof integrated messages. Additionally, we introduce a dimensional mask that\ndynamically adjusts gradient weights during training to eliminate the influence\nof decision-irrelevant dimensions. We evaluate DRMAC across a diverse set of\nmulti-agent tasks, demonstrating its superior performance over existing\nstate-of-the-art methods in complex scenarios. Furthermore, the plug-and-play\nnature of DRMAC's key modules highlights its generalizable performance, serving\nas a valuable complement rather than a replacement for existing multi-agent\ncommunication strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02888v1"
    },
    {
        "title": "CBS with Continuous-Time Revisit",
        "authors": [
            "Andy Li",
            "Zhe Chen",
            "Danial Harabor"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  In recent years, researchers introduced the Multi-Agent Path Finding in\nContinuous Time (MAPFR) problem. Conflict-based search with Continuous Time\n(CCBS), a variant of CBS for discrete MAPF, aims to solve MAPFR with\ncompleteness and optimality guarantees. However, CCBS overlooked the fact that\nsearch algorithms only guarantee termination and return the optimal solution\nwith a finite amount of search nodes. In this paper, we show that CCBS is\nincomplete, reveal the gaps in the existing implementation, demonstrate that\npatching is non-trivial, and discuss the next steps.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.07744v1"
    },
    {
        "title": "Ensuring Truthfulness in Distributed Aggregative Optimization",
        "authors": [
            "Ziqin Chen",
            "Magnus Egerstedt",
            "Yongqiang Wang"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Distributed aggregative optimization methods are gaining increased traction\ndue to their ability to address cooperative control and optimization problems,\nwhere the objective function of each agent depends not only on its own decision\nvariable but also on the aggregation of other agents' decision variables.\nNevertheless, existing distributed aggregative optimization methods implicitly\nassume all agents to be truthful in information sharing, which can be\nunrealistic in real-world scenarios, where agents may act selfishly or\nstrategically. In fact, an opportunistic agent may deceptively share false\ninformation in its own favor to minimize its own loss, which, however, will\ncompromise the network-level global performance. To solve this issue, we\npropose a new distributed aggregative optimization algorithm that can ensure\ntruthfulness of agents and convergence performance. To the best of our\nknowledge, this is the first algorithm that ensures truthfulness in a fully\ndistributed setting, where no \"centralized\" aggregator exists to collect\nprivate information/decision variables from participating agents. We\nsystematically characterize the convergence rate of our algorithm under\nnonconvex/convex/strongly convex objective functions, which generalizes\nexisting distributed aggregative optimization results that only focus on convex\nobjective functions. We also rigorously quantify the tradeoff between\nconvergence performance and the level of enabled truthfulness under different\nconvexity conditions. Numerical simulations using distributed charging of\nelectric vehicles confirm the efficacy of our algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08512v1"
    },
    {
        "title": "Separation Assurance in Urban Air Mobility Systems using Shared\n  Scheduling Protocols",
        "authors": [
            "Surya Murthy",
            "Tyler Ingebrand",
            "Sophia Smith",
            "Ufuk Topcu",
            "Peng Wei",
            "Natasha Neogi"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Ensuring safe separation between aircraft is a critical challenge in air\ntraffic management, particularly in urban air mobility (UAM) environments where\nhigh traffic density and low altitudes require precise control. In these\nenvironments, conflicts often arise at the intersections of flight corridors,\nposing significant risks. We propose a tactical separation approach leveraging\nshared scheduling protocols, originally designed for Ethernet networks and\noperating systems, to coordinate access to these intersections. Using a\ndecentralized Markov decision process framework, the proposed approach enables\naircraft to autonomously adjust their speed and timing as they navigate these\ncritical areas, maintaining safe separation without a central controller. We\nevaluate the effectiveness of this approach in simulated UAM scenarios,\ndemonstrating its ability to reduce separation violations to zero while\nacknowledging trade-offs in flight times as traffic density increases.\nAdditionally, we explore the impact of non-compliant aircraft, showing that\nwhile shared scheduling protocols can no longer guarantee safe separation, they\nstill provide significant improvements over systems without scheduling\nprotocols.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08933v1"
    },
    {
        "title": "Physical AI Agents: Integrating Cognitive Intelligence with Real-World\n  Action",
        "authors": [
            "Fouad Bousetouane"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Vertical AI Agents are revolutionizing industries by delivering\ndomain-specific intelligence and tailored solutions. However, many sectors,\nsuch as manufacturing, healthcare, and logistics, demand AI systems capable of\nextending their intelligence into the physical world, interacting directly with\nobjects, environments, and dynamic conditions. This need has led to the\nemergence of Physical AI Agents--systems that integrate cognitive reasoning,\npowered by specialized LLMs, with precise physical actions to perform\nreal-world tasks.\n  This work introduces Physical AI Agents as an evolution of shared principles\nwith Vertical AI Agents, tailored for physical interaction. We propose a\nmodular architecture with three core blocks--perception, cognition, and\nactuation--offering a scalable framework for diverse industries. Additionally,\nwe present the Physical Retrieval Augmented Generation (Ph-RAG) design pattern,\nwhich connects physical intelligence to industry-specific LLMs for real-time\ndecision-making and reporting informed by physical context.\n  Through case studies, we demonstrate how Physical AI Agents and the Ph-RAG\nframework are transforming industries like autonomous vehicles, warehouse\nrobotics, healthcare, and manufacturing, offering businesses a pathway to\nintegrate embodied AI for operational efficiency and innovation.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08944v1"
    },
    {
        "title": "Semantics and Conversations for an Agent Communication Language",
        "authors": [
            "Yannis Labrou",
            "Tim Finin"
        ],
        "category": "cs.MA",
        "published_year": "1998",
        "summary": "  We address the issues of semantics and conversations for agent communication\nlanguages and the Knowledge Query Manipulation Language (KQML) in particular.\nBased on ideas from speech act theory, we present a semantic description for\nKQML that associates ``cognitive'' states of the agent with the use of the\nlanguage's primitives (performatives). We have used this approach to describe\nthe semantics for the whole set of reserved KQML performatives. Building on the\nsemantics, we devise the conversation policies, i.e., a formal description of\nhow KQML performatives may be combined into KQML exchanges (conversations),\nusing a Definite Clause Grammar. Our research offers methods for a speech act\ntheory-based semantic description of a language of communication acts and for\nthe specification of the protocols associated with these acts. Languages of\ncommunication acts address the issue of communication among software\napplications at a level of abstraction that is useful to the emerging software\nagents paradigm.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9809034v1"
    },
    {
        "title": "Document Archiving, Replication and Migration Container for Mobile Web\n  Users",
        "authors": [
            "P. Stanski",
            "S. Giles",
            "A. Zaslavsky"
        ],
        "category": "cs.MA",
        "published_year": "1998",
        "summary": "  With the increasing use of mobile workstations for a wide variety of tasks\nand associated information needs, and with many variations of available\nnetworks, access to data becomes a prime consideration. This paper discusses\nissues of workstation mobility and proposes a solution wherein the data\nstructures are accessed in an encapsulated form - through the Portable File\nSystem (PFS) wrapper. The paper discusses an implementation of the Portable\nFile System, highlighting the architecture and commenting upon performance of\nan experimental system. Although investigations have been focused upon mobile\naccess of WWW documents, this technique could be applied to any mobile data\naccess situation.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9809036v1"
    },
    {
        "title": "Learning Nested Agent Models in an Information Economy",
        "authors": [
            "Jose M. Vidal",
            "Edmund H. Durfee"
        ],
        "category": "cs.MA",
        "published_year": "1998",
        "summary": "  We present our approach to the problem of how an agent, within an economic\nMulti-Agent System, can determine when it should behave strategically (i.e.\nlearn and use models of other agents), and when it should act as a simple\nprice-taker. We provide a framework for the incremental implementation of\nmodeling capabilities in agents, and a description of the forms of knowledge\nrequired. The agents were implemented and different populations simulated in\norder to learn more about their behavior and the merits of using and learning\nagent models. Our results show, among other lessons, how savvy buyers can avoid\nbeing ``cheated'' by sellers, how price volatility can be used to\nquantitatively predict the benefits of deeper models, and how specific types of\nagent populations influence system behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9809108v1"
    },
    {
        "title": "Anytime Coalition Structure Generation with Worst Case Guarantees",
        "authors": [
            "Tuomas Sandholm",
            "Kate Larson",
            "Martin Andersson",
            "Onn Shehory",
            "Fernando Tohme"
        ],
        "category": "cs.MA",
        "published_year": "1998",
        "summary": "  Coalition formation is a key topic in multiagent systems. One would prefer a\ncoalition structure that maximizes the sum of the values of the coalitions, but\noften the number of coalition structures is too large to allow exhaustive\nsearch for the optimal one. But then, can the coalition structure found via a\npartial search be guaranteed to be within a bound from optimum? We show that\nnone of the previous coalition structure generation algorithms can establish\nany bound because they search fewer nodes than a threshold that we show\nnecessary for establishing a bound. We present an algorithm that establishes a\ntight bound within this minimal amount of search, and show that any other\nalgorithm would have to search strictly more. The fraction of nodes needed to\nbe searched approaches zero as the number of agents grows. If additional time\nremains, our anytime algorithm searches further, and establishes a\nprogressively lower tight bound. Surprisingly, just searching one more node\ndrops the bound in half. As desired, our algorithm lowers the bound rapidly\nearly on, and exhibits diminishing returns to computation. It also drastically\noutperforms its obvious contenders. Finally, we show how to distribute the\ndesired search across self-interested manipulative agents.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9810005v1"
    },
    {
        "title": "SIMMUNE, a tool for simulating and analyzing immune system behavior",
        "authors": [
            "M. Meier-Schellersheim",
            "G. Mack"
        ],
        "category": "cs.MA",
        "published_year": "1999",
        "summary": "  We present a new approach to the simulation and analysis of immune system\nbehavior. The simulations that can be done with our software package called\nSIMMUNE are based on immunological data that describe the behavior of immune\nsystem agents (cells, molecules) on a microscopial (i.e. agent-agent\ninteraction) scale by defining cellular stimulus-response mechanisms. Since the\nbehavior of the agents in SIMMUNE can be very flexibly configured, its\napplication is not limited to immune system simulations. We outline the\nprinciples of SIMMUNE's multiscale analysis of emergent structure within the\nsimulated immune system that allow the identification of immunological contexts\nusing minimal a priori assumptions about the higher level organization of the\nimmune system.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9903017v1"
    },
    {
        "title": "Collective Choice Theory in Collaborative Computing",
        "authors": [
            "Walter Eaves"
        ],
        "category": "cs.MA",
        "published_year": "1999",
        "summary": "  This paper presents some fundamental collective choice theory for information\nsystem designers, particularly those working in the field of computer-supported\ncooperative work. This paper is focused on a presentation of Arrow's\nPossibility and Impossibility theorems which form the fundamental boundary on\nthe efficacy of collective choice: voting and selection procedures. It restates\nthe conditions that Arrow placed on collective choice functions in more\nrigorous second-order logic, which could be used as a set of test conditions\nfor implementations, and a useful probabilistic result for analyzing votes on\nissue pairs. It also describes some simple collective choice functions. There\nis also some discussion of how enterprises should approach putting their\nresources under collective control: giving an outline of a superstructure of\nperformative agents to carry out this function and what distributing processing\ntechnology would be needed.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9905003v1"
    },
    {
        "title": "Improving Performance of heavily loaded agents",
        "authors": [
            "Fatma Ozcan",
            "VS Subrahmanian",
            "Juergen Dix"
        ],
        "category": "cs.MA",
        "published_year": "2000",
        "summary": "  With the increase in agent-based applications, there are now agent systems\nthat support \\emph{concurrent} client accesses. The ability to process large\nvolumes of simultaneous requests is critical in many such applications. In such\na setting, the traditional approach of serving these requests one at a time via\nqueues (e.g. \\textsf{FIFO} queues, priority queues) is insufficient.\nAlternative models are essential to improve the performance of such\n\\emph{heavily loaded} agents. In this paper, we propose a set of\n\\emph{cost-based algorithms} to \\emph{optimize} and \\emph{merge} multiple\nrequests submitted to an agent. In order to merge a set of requests, one first\nneeds to identify commonalities among such requests. First, we provide an\n\\emph{application independent framework} within which an agent developer may\nspecify relationships (called \\emph{invariants}) between requests. Second, we\nprovide two algorithms (and various accompanying heuristics) which allow an\nagent to automatically rewrite requests so as to avoid redundant work---these\nalgorithms take invariants associated with the agent into account. Our\nalgorithms are independent of any specific agent framework. For an\nimplementation, we implemented both these algorithms on top of the \\impact\nagent development platform, and on top of a (non-\\impact) geographic database\nagent. Based on these implementations, we conducted experiments and show that\nour algorithms are considerably more efficient than methods that use the $A^*$\nalgorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0012004v1"
    },
    {
        "title": "Using Methods of Declarative Logic Programming for Intelligent\n  Information Agents",
        "authors": [
            "T. Eiter",
            "M. Fink",
            "G. Sabbatini",
            "H. Tompits"
        ],
        "category": "cs.MA",
        "published_year": "2001",
        "summary": "  The search for information on the web is faced with several problems, which\narise on the one hand from the vast number of available sources, and on the\nother hand from their heterogeneity. A promising approach is the use of\nmulti-agent systems of information agents, which cooperatively solve advanced\ninformation-retrieval problems. This requires capabilities to address complex\ntasks, such as search and assessment of sources, query planning, information\nmerging and fusion, dealing with incomplete information, and handling of\ninconsistency. In this paper, our interest is in the role which some methods\nfrom the field of declarative logic programming can play in the realization of\nreasoning capabilities for information agents. In particular, we are interested\nin how they can be used and further developed for the specific needs of this\napplication domain. We review some existing systems and current projects, which\naddress information-integration problems. We then focus on declarative\nknowledge-representation methods, and review and evaluate approaches from logic\nprogramming and nonmonotonic reasoning for information agents. We discuss\nadvantages and drawbacks, and point out possible extensions and open issues.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0108008v1"
    },
    {
        "title": "Geometric Aspects of Multiagent Systems",
        "authors": [
            "Timothy Porter"
        ],
        "category": "cs.MA",
        "published_year": "2002",
        "summary": "  Recent advances in Multiagent Systems (MAS) and Epistemic Logic within\nDistributed Systems Theory, have used various combinatorial structures that\nmodel both the geometry of the systems and the Kripke model structure of models\nfor the logic. Examining one of the simpler versions of these models,\ninterpreted systems, and the related Kripke semantics of the logic $S5_n$ (an\nepistemic logic with $n$-agents), the similarities with the geometric /\nhomotopy theoretic structure of groupoid atlases is striking. These latter\nobjects arise in problems within algebraic K-theory, an area of algebra linked\nto the study of decomposition and normal form theorems in linear algebra. They\nhave a natural well structured notion of path and constructions of path\nobjects, etc., that yield a rich homotopy theory.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0210023v1"
    },
    {
        "title": "Modelling intracellular signalling networks using behaviour-based\n  systems and the blackboard architecture",
        "authors": [
            "Pedro Pablo Gonzalez Perez",
            "Carlos Gershenson",
            "Maura Cardenas Garcia",
            "Jaime Lagunez Otero"
        ],
        "category": "cs.MA",
        "published_year": "2002",
        "summary": "  This paper proposes to model the intracellular signalling networks using a\nfusion of behaviour-based systems and the blackboard architecture. In virtue of\nthis fusion, the model developed by us, which has been named Cellulat, allows\nto take account two essential aspects of the intracellular signalling networks:\n(1) the cognitive capabilities of certain types of networks' components and (2)\nthe high level of spatial organization of these networks. A simple example of\nmodelling of Ca2+ signalling pathways using Cellulat is presented here. An\nintracellular signalling virtual laboratory is being developed from Cellulat.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0211029v1"
    },
    {
        "title": "Integration of Computational Techniques for the Modelling of Signal\n  Transduction",
        "authors": [
            "Pedro Pablo Gonzalez Perez",
            "Maura Cardenas Garcia",
            "Carlos Gershenson",
            "Jaime Lagunez-Otero"
        ],
        "category": "cs.MA",
        "published_year": "2002",
        "summary": "  A cell can be seen as an adaptive autonomous agent or as a society of\nadaptive autonomous agents, where each can exhibit a particular behaviour\ndepending on its cognitive capabilities. We present an intracellular signalling\nmodel obtained by integrating several computational techniques into an\nagent-based paradigm. Cellulat, the model, takes into account two essential\naspects of the intracellular signalling networks: cognitive capacities and a\nspatial organization. Exemplifying the functionality of the system by modelling\nthe EGFR signalling pathway, we discuss the methodology as well as the purposes\nof an intracellular signalling virtual laboratory, presently under development.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0211030v1"
    },
    {
        "title": "Learning in Multiagent Systems: An Introduction from a Game-Theoretic\n  Perspective",
        "authors": [
            "Jose M. Vidal"
        ],
        "category": "cs.MA",
        "published_year": "2003",
        "summary": "  We introduce the topic of learning in multiagent systems. We first provide a\nquick introduction to the field of game theory, focusing on the equilibrium\nconcepts of iterated dominance, and Nash equilibrium. We show some of the most\nrelevant findings in the theory of learning in games, including theorems on\nfictitious play, replicator dynamics, and evolutionary stable strategies. The\nCLRI theory and n-level learning agents are introduced as attempts to apply\nsome of these findings to the problem of engineering multiagent systems with\nlearning agents. Finally, we summarize some of the remaining challenges in the\nfield of learning in multiagent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0308030v1"
    },
    {
        "title": "Multi-agent coordination using nearest neighbor rules: revisiting the\n  Vicsek model",
        "authors": [
            "Sanjiang Li",
            "Huaiqing Wang"
        ],
        "category": "cs.MA",
        "published_year": "2004",
        "summary": "  Recently, Jadbabaie, Lin, and Morse (IEEE TAC, 48(6)2003:988-1001) offered a\nmathematical analysis of the discrete time model of groups of mobile autonomous\nagents raised by Vicsek et al. in 1995. In their paper, Jadbabaie et al. showed\nthat all agents shall move in the same heading, provided that these agents are\nperiodically linked together. This paper sharpens this result by showing that\ncoordination will be reached under a very weak condition that requires all\nagents are finally linked together. This condition is also strictly weaker than\nthe one Jadbabaie et al. desired.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0407021v2"
    },
    {
        "title": "An agent-based intelligent environmental monitoring system",
        "authors": [
            "Ioannis N Athanasiadis",
            "Pericles A Mitkas"
        ],
        "category": "cs.MA",
        "published_year": "2004",
        "summary": "  Fairly rapid environmental changes call for continuous surveillance and\non-line decision making. There are two main areas where IT technologies can be\nvaluable. In this paper we present a multi-agent system for monitoring and\nassessing air-quality attributes, which uses data coming from a meteorological\nstation. A community of software agents is assigned to monitor and validate\nmeasurements coming from several sensors, to assess air-quality, and, finally,\nto fire alarms to appropriate recipients, when needed. Data mining techniques\nhave been used for adding data-driven, customized intelligence into agents. The\narchitecture of the developed system, its domain ontology, and typical agent\ninteractions are presented. Finally, the deployment of a real-world test case\nis demonstrated.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0407024v1"
    },
    {
        "title": "Enabling Agents to Dynamically Select Protocols for Interactions",
        "authors": [
            "Jose Ghislain Quenum Samir Aknine"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  in this paper we describe a method which allows agents to dynamically select\nprotocols and roles when they need to execute collaborative tasks\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0501036v2"
    },
    {
        "title": "A T Step Ahead Optimal Target Detection Algorithm for a Multi Sensor\n  Surveillance System",
        "authors": [
            "K Madhava Krishna",
            "Henry Hexmoor",
            "Shravan Sogani"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  This paper presents a methodology for optimal target detection in a multi\nsensor surveillance system. The system consists of mobile sensors that guard a\nrectangular surveillance zone crisscrossed by moving targets. Targets percolate\nthe surveillance zone in a poisson fashion with uniform velocities. Under these\nstatistics this paper computes a motion strategy for a sensor that maximizes\ntarget detections for the next T time steps. A coordination mechanism between\nsensors ensures that overlapping areas between sensors is reduced. This\ncoordination mechanism is interleaved with the motion strategy computation to\nreduce detections of the same target by more than one sensor. To avoid an\nexhaustive search in the joint space of all sensors the coordination mechanism\nconstraints the search by assigning priorities to the sensors. A comparison of\nthis methodology with other multi target tracking schemes verifies its efficacy\nin maximizing detections. A tabulation of these comparisons is reported in\nresults section of the paper\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0505045v1"
    },
    {
        "title": "Traders imprint themselves by adaptively updating their own avatar",
        "authors": [
            "Gilles Daniel",
            "Lev Muchnik",
            "Sorin Solomon"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  Simulations of artificial stock markets were considered as early as 1964 and\nmulti-agent ones were introduced as early as 1989. Starting the early 90's,\ncollaborations of economists and physicists produced increasingly realistic\nsimulation platforms. Currently, the market stylized facts are easily\nreproduced and one has now to address the realistic details of the Market\nMicrostructure and of the Traders Behaviour. This calls for new methods and\ntools capable of bridging smoothly between simulations and experiments in\neconomics.\n  We propose here the following Avatar-Based Method (ABM). The subjects\nimplement and maintain their Avatars (programs encoding their personal decision\nmaking procedures) on NatLab, a market simulation platform. Once these\nprocedures are fed in a computer edible format, they can be operationally used\nas such without the need for belabouring, interpreting or conceptualising them.\nThus ABM short-circuits the usual behavioural economics experiments that search\nfor the psychological mechanisms underlying the subjects behaviour. Finally,\nABM maintains a level of objectivity close to the classical behaviourism while\nextending its scope to subjects' decision making mechanisms.\n  We report on experiments where Avatars designed and maintained by humans from\ndifferent backgrounds (including real traders) compete in a continuous\ndouble-auction market. We hope this unbiased way of capturing the adaptive\nevolution of real subjects behaviour may lead to a new kind of behavioural\neconomics experiments with a high degree of reliability, analysability and\nreproducibility.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0509017v1"
    },
    {
        "title": "Societal Implicit Memory and his Speed on Tracking Extrema over Dynamic\n  Environments using Self-Regulatory Swarms",
        "authors": [
            "Vitorino Ramos",
            "Carlos Fernandes",
            "Agostinho C. Rosa"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  In order to overcome difficult dynamic optimization and environment extrema\ntracking problems, We propose a Self-Regulated Swarm (SRS) algorithm which\nhybridizes the advantageous characteristics of Swarm Intelligence as the\nemergence of a societal environmental memory or cognitive map via collective\npheromone laying in the landscape (properly balancing the\nexploration/exploitation nature of our dynamic search strategy), with a simple\nEvolutionary mechanism that trough a direct reproduction procedure linked to\nlocal environmental features is able to self-regulate the above exploratory\nswarm population, speeding it up globally. In order to test his adaptive\nresponse and robustness, we have recurred to different dynamic multimodal\ncomplex functions as well as to Dynamic Optimization Control problems,\nmeasuring reaction speeds and performance. Final comparisons were made with\nstandard Genetic Algorithms (GAs), Bacterial Foraging strategies (BFOA), as\nwell as with recent Co-Evolutionary approaches. SRS's were able to demonstrate\nquick adaptive responses, while outperforming the results obtained by the other\napproaches. Additionally, some successful behaviors were found. One of the most\ninteresting illustrate that the present SRS collective swarm of bio-inspired\nant-like agents is able to track about 65% of moving peaks traveling up to ten\ntimes faster than the velocity of a single individual composing that precise\nswarm tracking system.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0512003v1"
    },
    {
        "title": "Self-Regulated Artificial Ant Colonies on Digital Image Habitats",
        "authors": [
            "Carlos Fernandes",
            "Vitorino Ramos",
            "Agostinho C. Rosa"
        ],
        "category": "cs.MA",
        "published_year": "2005",
        "summary": "  Artificial life models, swarm intelligent and evolutionary computation\nalgorithms are usually built on fixed size populations. Some studies indicate\nhowever that varying the population size can increase the adaptability of these\nsystems and their capability to react to changing environments. In this paper\nwe present an extended model of an artificial ant colony system designed to\nevolve on digital image habitats. We will show that the present swarm can adapt\nthe size of the population according to the type of image on which it is\nevolving and reacting faster to changing images, thus converging more rapidly\nto the new desired regions, regulating the number of his image foraging agents.\nFinally, we will show evidences that the model can be associated with the\nMathematical Morphology Watershed algorithm to improve the segmentation of\ndigital grey-scale images. KEYWORDS: Swarm Intelligence, Perception and Image\nProcessing, Pattern Recognition, Mathematical Morphology, Social Cognitive\nMaps, Social Foraging, Self-Organization, Distributed Search.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0512004v1"
    },
    {
        "title": "The emergence of knowledge exchange: an agent-based model of a software\n  market",
        "authors": [
            "Maria Chli",
            "Philippe De Wilde"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  We investigate knowledge exchange among commercial organisations, the\nrationale behind it and its effects on the market. Knowledge exchange is known\nto be beneficial for industry, but in order to explain it, authors have used\nhigh level concepts like network effects, reputation and trust. We attempt to\nformalise a plausible and elegant explanation of how and why companies adopt\ninformation exchange and why it benefits the market as a whole when this\nhappens. This explanation is based on a multi-agent model that simulates a\nmarket of software providers. Even though the model does not include any\nhigh-level concepts, information exchange naturally emerges during simulations\nas a successful profitable behaviour. The conclusions reached by this\nagent-based analysis are twofold: (1) A straightforward set of assumptions is\nenough to give rise to exchange in a software market. (2) Knowledge exchange is\nshown to increase the efficiency of the market.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604078v1"
    },
    {
        "title": "Modeling and Mathematical Analysis of Swarms of Microscopic Robots",
        "authors": [
            "Aram Galstyan",
            "Tad Hogg",
            "Kristina Lerman"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  The biologically-inspired swarm paradigm is being used to design\nself-organizing systems of locally interacting artificial agents. A major\ndifficulty in designing swarms with desired characteristics is understanding\nthe causal relation between individual agent and collective behaviors.\nMathematical analysis of swarm dynamics can address this difficulty to gain\ninsight into system design. This paper proposes a framework for mathematical\nmodeling of swarms of microscopic robots that may one day be useful in medical\napplications. While such devices do not yet exist, the modeling approach can be\nhelpful in identifying various design trade-offs for the robots and be a useful\nguide for their eventual fabrication. Specifically, we examine microscopic\nrobots that reside in a fluid, for example, a bloodstream, and are able to\ndetect and respond to different chemicals. We present the general mathematical\nmodel of a scenario in which robots locate a chemical source. We solve the\nscenario in one-dimension and show how results can be used to evaluate certain\ndesign decisions.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604110v1"
    },
    {
        "title": "Self-Replication and Self-Assembly for Manufacturing",
        "authors": [
            "Robert Ewaschuk",
            "Peter D. Turney"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  It has been argued that a central objective of nanotechnology is to make\nproducts inexpensively, and that self-replication is an effective approach to\nvery low-cost manufacturing. The research presented here is intended to be a\nstep towards this vision. We describe a computational simulation of nanoscale\nmachines floating in a virtual liquid. The machines can bond together to form\nstrands (chains) that self-replicate and self-assemble into user-specified\nmeshes. There are four types of machines and the sequence of machine types in a\nstrand determines the shape of the mesh they will build. A strand may be in an\nunfolded state, in which the bonds are straight, or in a folded state, in which\nthe bond angles depend on the types of machines. By choosing the sequence of\nmachine types in a strand, the user can specify a variety of polygonal shapes.\nA simulation typically begins with an initial unfolded seed strand in a soup of\nunbonded machines. The seed strand replicates by bonding with free machines in\nthe soup. The child strands fold into the encoded polygonal shape, and then the\npolygons drift together and bond to form a mesh. We demonstrate that a variety\nof polygonal meshes can be manufactured in the simulation, by simply changing\nthe sequence of machine types in the seed.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0607133v1"
    },
    {
        "title": "CHAC. A MOACO Algorithm for Computation of Bi-Criteria Military Unit\n  Path in the Battlefield",
        "authors": [
            "A. M. Mora",
            "J. J. Merelo",
            "C. Millan",
            "J. Torrecillas",
            "J. L. J. Laredo"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  In this paper we propose a Multi-Objective Ant Colony Optimization (MOACO)\nalgorithm called CHAC, which has been designed to solve the problem of finding\nthe path on a map (corresponding to a simulated battlefield) that minimizes\nresources while maximizing safety. CHAC has been tested with two different\nstate transition rules: an aggregative function that combines the heuristic and\npheromone information of both objectives and a second one that is based on the\ndominance concept of multiobjective optimization problems. These rules have\nbeen evaluated in several different situations (maps with different degree of\ndifficulty), and we have found that they yield better results than a greedy\nalgorithm (taken as baseline) in addition to a military behaviour that is also\nbetter in the tactical sense. The aggregative function, in general, yields\nbetter results than the one based on dominance.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0610113v1"
    },
    {
        "title": "Community Detection in Complex Networks Using Agents",
        "authors": [
            "Ismail Gunes",
            "Haluk Bingol"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  Community structure identification has been one of the most popular research\nareas in recent years due to its applicability to the wide scale of\ndisciplines. To detect communities in varied topics, there have been many\nalgorithms proposed so far. However, most of them still have some drawbacks to\nbe addressed. In this paper, we present an agent-based based community\ndetection algorithm. The algorithm that is a stochastic one makes use of agents\nby forcing them to perform biased moves in a smart way. Using the information\ncollected by the traverses of these agents in the network, the network\nstructure is revealed. Also, the network modularity is used for determining the\nnumber of communities. Our algorithm removes the need for prior knowledge about\nthe network such as number of the communities or any threshold values.\nFurthermore, the definite community structure is provided as a result instead\nof giving some structures requiring further processes. Besides, the\ncomputational and time costs are optimized because of using thread like working\nagents. The algorithm is tested on three network data of different types and\nsizes named Zachary karate club, college football and political books. For all\nthree networks, the real network structures are identified in almost every run.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0610129v1"
    },
    {
        "title": "Asynchronous Distributed Searchlight Scheduling",
        "authors": [
            "Karl J. Obermeyer",
            "Anurag Ganguli",
            "Francesco Bullo"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  This paper develops and compares two simple asynchronous distributed\nsearchlight scheduling algorithms for multiple robotic agents in nonconvex\npolygonal environments. A searchlight is a ray emitted by an agent which cannot\npenetrate the boundary of the environment. A point is detected by a searchlight\nif and only if the point is on the ray at some instant. Targets are points\nwhich can move continuously with unbounded speed. The objective of the proposed\nalgorithms is for the agents to coordinate the slewing (rotation about a point)\nof their searchlights in a distributed manner, i.e., using only local sensing\nand limited communication, such that any target will necessarily be detected in\nfinite time. The first algorithm we develop, called the DOWSS (Distributed One\nWay Sweep Strategy), is a distributed version of a known algorithm described\noriginally in 1990 by Sugihara et al \\cite{KS-IS-MY:90}, but it can be very\nslow in clearing the entire environment because only one searchlight may slew\nat a time. In an effort to reduce the time to clear the environment, we develop\na second algorithm, called the PTSS (Parallel Tree Sweep Strategy), in which\nsearchlights sweep in parallel if guards are placed according to an environment\npartition belonging to a class we call PTSS partitions. Finally, we discuss how\nDOWSS and PTSS could be combined with with deployment, or extended to\nenvironments with holes.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0701077v3"
    },
    {
        "title": "FIPA-based Interoperable Agent Mobility Proposal",
        "authors": [
            "Jordi Cucurull",
            "Ramon Marti",
            "Sergi Robles",
            "Joan Borrell",
            "Guillermo Navarro"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  This paper presents a proposal for a flexible agent mobility architecture\nbased on IEEE-FIPA standards and intended to be one of them. This proposal is a\nfirst step towards interoperable mobility mechanisms, which are needed for\nfuture agent migration between different kinds of platforms. Our proposal is\npresented as a flexible and robust architecture that has been successfully\nimplemented in the JADE and AgentScape platforms. It is based on an open set of\nprotocols, allowing new protocols and future improvements to be accommodated in\nthe architecture. With this proposal we demonstrate that a standard\narchitecture for agent mobility capable of supporting several agent platforms\ncan be defined and implemented.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.1860v2"
    },
    {
        "title": "Distributed Decision Through Self-Synchronizing Sensor Networks in the\n  Presence of Propagation Delays and Asymmetric Channels",
        "authors": [
            "Gesualdo Scutari",
            "Sergio Barbarossa",
            "Loreto Pescosolido"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  In this paper we propose and analyze a distributed algorithm for achieving\nglobally optimal decisions, either estimation or detection, through a\nself-synchronization mechanism among linearly coupled integrators initialized\nwith local measurements. We model the interaction among the nodes as a directed\ngraph with weights (possibly) dependent on the radio channels and we pose\nspecial attention to the effect of the propagation delay occurring in the\nexchange of data among sensors, as a function of the network geometry. We\nderive necessary and sufficient conditions for the proposed system to reach a\nconsensus on globally optimal decision statistics. One of the major results\nproved in this work is that a consensus is reached with exponential convergence\nspeed for any bounded delay condition if and only if the directed graph is\nquasi-strongly connected. We provide a closed form expression for the global\nconsensus, showing that the effect of delays is, in general, the introduction\nof a bias in the final decision. Finally, we exploit our closed form expression\nto devise a double-step consensus mechanism able to provide an unbiased\nestimate with minimum extra complexity, without the need to know or estimate\nthe channel parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.2410v2"
    },
    {
        "title": "Les Agents comme des interpréteurs Scheme : Spécification dynamique\n  par la communication",
        "authors": [
            "Clément Jonquet",
            "Stefano A. Cerri"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  We proposed in previous papers an extension and an implementation of the\nSTROBE model, which regards the Agents as Scheme interpreters. These Agents are\nable to interpret messages in a dedicated environment including an interpreter\nthat learns from the current conversation therefore representing evolving\nmeta-level Agent's knowledge. When the Agent's interpreter is a\nnondeterministic one, the dialogues may consist of subsequent refinements of\nspecifications in the form of constraint sets. The paper presents a worked out\nexample of dynamic service generation - such as necessary on Grids - by\nexploiting STROBE Agents equipped with a nondeterministic interpreter. It shows\nhow enabling dynamic specification of a problem. Then it illustrates how these\nprinciples could be effective for other applications. Details of the\nimplementation are not provided here, but are available.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.1393v1"
    },
    {
        "title": "Moore and more and symmetry",
        "authors": [
            "Tobias Kretz",
            "Michael Schreckenberg"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  In any spatially discrete model of pedestrian motion which uses a regular\nlattice as basis, there is the question of how the symmetry between the\ndifferent directions of motion can be restored as far as possible but with\nlimited computational effort. This question is equivalent to the question ''How\nimportant is the orientation of the axis of discretization for the result of\nthe simulation?'' An optimization in terms of symmetry can be combined with the\nimplementation of higher and heterogeniously distributed walking speeds by\nrepresenting different walking speeds via different amounts of cells an agent\nmay move during one round. Therefore all different possible neighborhoods for\nspeeds up to v = 10 (cells per round) will be examined for the amount of\ndeviation from radial symmetry. Simple criteria will be stated which will allow\nfind an optimal neighborhood for each speed. It will be shown that following\nthese criteria even the best mixture of steps in Moore and von Neumann\nneighborhoods is unable to reproduce the optimal neighborhood for a speed as\nlow as 4.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.0318v1"
    },
    {
        "title": "The F.A.S.T.-Model",
        "authors": [
            "Tobias Kretz",
            "Michael Schreckenberg"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  A discrete model of pedestrian motion is presented that is implemented in the\nFloor field- and Agentbased Simulation Tool (F.A.S.T.) which has already been\napplicated to a variety of real life scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.1893v1"
    },
    {
        "title": "Counterflow Extension for the F.A.S.T.-Model",
        "authors": [
            "Tobias Kretz",
            "Maike Kaufman",
            "Michael Schreckenberg"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  The F.A.S.T. (Floor field and Agent based Simulation Tool) model is a\nmicroscopic model of pedestrian dynamics, which is discrete in space and time.\nIt was developed in a number of more or less consecutive steps from a simple CA\nmodel. This contribution is a summary of a study on an extension of the\nF.A.S.T-model for counterflow situations. The extensions will be explained and\nit will be shown that the extended F.A.S.T.-model is capable of handling\nvarious counterflow situations and to reproduce the well known lane formation\neffect.\n",
        "pdf_link": "http://arxiv.org/pdf/0804.4336v1"
    },
    {
        "title": "Distributed Self Management for Distributed Security Systems",
        "authors": [
            "Michael Hilker"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  Distributed system as e.g. artificial immune systems, complex adaptive\nsystems, or multi-agent systems are widely used in Computer Science, e.g. for\nnetwork security, optimisations, or simulations. In these systems, small\nentities move through the network and perform certain tasks. At some time, the\nentities move to another place and require therefore information where to move\nis most profitable. Common used systems do not provide any information or use a\ncentralised approach where a center delegates the entities. This article\ndiscusses whether small information about the neighbours enhances the\nperformance of the overall system or not. Therefore, two information-protocols\nare introduced and analysed. In addition, the protocols are implemented and\ntested using the artificial immune system SANA that protects a network against\nintrusions.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.1785v1"
    },
    {
        "title": "Next Challenges in Bringing Artificial Immune Systems to Production in\n  Network Security",
        "authors": [
            "Michael Hilker"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  The human immune system protects the human body against various pathogens\nlike e.g. biological viruses and bacteria. Artificial immune systems reuse the\narchitecture, organization, and workflows of the human immune system for\nvarious problems in computer science. In the network security, the artificial\nimmune system is used to secure a network and its nodes against intrusions like\nviruses, worms, and trojans. However, these approaches are far away from\nproduction where they are academic proof-of-concept implementations or use only\na small part to protect against a certain intrusion. This article discusses the\nrequired steps to bring artificial immune systems into production in the\nnetwork security domain. It furthermore figures out the challenges and provides\nthe description and results of the prototype of an artificial immune system,\nwhich is SANA called.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.1786v1"
    },
    {
        "title": "A Network Protection Framework through Artificial Immunity",
        "authors": [
            "Michael Hilker",
            "Christoph Schommer"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  Current network protection systems use a collection of intelligent components\n- e.g. classifiers or rule-based firewall systems to detect intrusions and\nanomalies and to secure a network against viruses, worms, or trojans. However,\nthese network systems rely on individuality and support an architecture with\nless collaborative work of the protection components. They give less\nadministration support for maintenance, but offer a large number of individual\nsingle points of failures - an ideal situation for network attacks to succeed.\nIn this work, we discuss the required features, the performance, and the\nproblems of a distributed protection system called {\\it SANA}. It consists of a\ncooperative architecture, it is motivated by the human immune system, where the\ncomponents correspond to artificial immune cells that are connected for their\ncollaborative work. SANA promises a better protection against intruders than\ncommon known protection systems through an adaptive self-management while\nkeeping the resources efficiently by an intelligent reduction of redundancies.\nWe introduce a library of several novel and common used protection components\nand evaluate the performance of SANA by a proof-of-concept implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.1787v1"
    },
    {
        "title": "Pedestrian Flow at Bottlenecks - Validation and Calibration of Vissim's\n  Social Force Model of Pedestrian Traffic and its Empirical Foundations",
        "authors": [
            "Tobias Kretz",
            "Stefan Hengst",
            "Peter Vortisch"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  In this contribution first results of experiments on pedestrian flow through\nbottlenecks are presented and then compared to simulation results obtained with\nthe Social Force Model in the Vissim simulation framework. Concerning the\nexperiments it is argued that the basic dependence between flow and bottleneck\nwidth is not a step function but that it is linear and modified by the effect\nof a psychological phenomenon. The simulation results as well show a linear\ndependence and the parameters can be calibrated such that the absolute values\nfor flow and time fit to range of experimental results.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.1788v1"
    },
    {
        "title": "Cooperation with Complement is Better",
        "authors": [
            "Ilker Yildirim",
            "Haluk Bingol"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  In a setting where heterogeneous agents interact to accomplish a given set of\ngoals, cooperation is of utmost importance, especially when agents cannot\nachieve their individual goals by exclusive use of their own efforts. Even when\nwe consider friendly environments and benevolent agents, cooperation involves\nseveral issues: with whom to cooperate, reciprocation, how to address credit\nassignment and complex division of gains, etc. We propose a model where\nheterogeneous agents cooperate by forming groups and formation of larger groups\nis promoted. Benefit of agents is proportional to the performance and the size\nof the group. There is a time pressure to form a group. We investigate how\npreferring similar or complement agents in group formation affects an agent's\nsuccess. Preferring complement in group formation is found to be better, yet\nthere is no need to push the strategy to the extreme since the effect of\ncomplementing partners is saturated.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.3938v1"
    },
    {
        "title": "Offloading Cognition onto Cognitive Technology",
        "authors": [
            "Itiel Dror",
            "Stevan Harnad"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  \"Cognizing\" (e.g., thinking, understanding, and knowing) is a mental state.\nSystems without mental states, such as cognitive technology, can sometimes\ncontribute to human cognition, but that does not make them cognizers. Cognizers\ncan offload some of their cognitive functions onto cognitive technology,\nthereby extending their performance capacity beyond the limits of their own\nbrain power. Language itself is a form of cognitive technology that allows\ncognizers to offload some of their cognitive functions onto the brains of other\ncognizers. Language also extends cognizers' individual and joint performance\npowers, distributing the load through interactive and collaborative cognition.\nReading, writing, print, telecommunications and computing further extend\ncognizers' capacities. And now the web, with its network of cognizers, digital\ndatabases and software agents, all accessible anytime, anywhere, has become our\n'Cognitive Commons,' in which distributed cognizers and cognitive technology\ncan interoperate globally with a speed, scope and degree of interactivity\ninconceivable through local individual cognition alone. And as with language,\nthe cognitive tool par excellence, such technological changes are not merely\ninstrumental and quantitative: they can have profound effects on how we think\nand encode information, on how we communicate with one another, on our mental\nstates, and on our very nature.\n",
        "pdf_link": "http://arxiv.org/pdf/0808.3569v3"
    },
    {
        "title": "Mathematical Tool of Discrete Dynamic Modeling of Complex Systems in\n  Control Loop",
        "authors": [
            "Armen Bagdasaryan"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  In this paper we present a method of discrete modeling and analysis of\nmulti-level dynamics of complex large-scale hierarchical dynamic systems\nsubject to external dynamic control mechanism. In a model each state describes\nparallel dynamics and simultaneous trends of changes in system parameters. The\nessence of the approach is in analysis of system state dynamics while it is in\nthe control loop.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.2680v1"
    },
    {
        "title": "A static theory of promises",
        "authors": [
            "Jan A. Bergstra",
            "Mark Burgess"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  We discuss for the concept of promises within a framework that can be applied\nto either humans or technology. We compare promises to the more established\nnotion of obligations and find promises to be both simpler and more effective\nat reducing uncertainty in behavioural outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/0810.3294v5"
    },
    {
        "title": "Complex Agent Networks explaining the HIV epidemic among homosexual men\n  in Amsterdam",
        "authors": [
            "Shan Mei",
            "P. M. A Sloot",
            "Rick Quax",
            "Yifan Zhu",
            "Weiping Wang"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  Simulating the evolution of the Human Immunodeficiency Virus (HIV) epidemic\nrequires a detailed description of the population network, especially for small\npopulations in which individuals can be represented in detail and accuracy. In\nthis paper, we introduce the concept of a Complex Agent Network(CAN) to model\nthe HIV epidemics by combining agent-based modelling and complex networks, in\nwhich agents represent individuals that have sexual interactions. The\napplicability of CANs is demonstrated by constructing and executing a detailed\nHIV epidemic model for men who have sex with men (MSM) in Amsterdam, including\na distinction between steady and casual relationships. We focus on MSM contacts\nbecause they play an important role in HIV epidemics and have been tracked in\nAmsterdam for a long time. Our experiments show good correspondence between the\nhistorical data of the Amsterdam cohort and the simulation results.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.1155v2"
    },
    {
        "title": "Multi-Agent Reinforcement Learning and Genetic Policy Sharing",
        "authors": [
            "Jake Ellowitz"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  The effects of policy sharing between agents in a multi-agent dynamical\nsystem has not been studied extensively. I simulate a system of agents\noptimizing the same task using reinforcement learning, to study the effects of\ndifferent population densities and policy sharing. I demonstrate that sharing\npolicies decreases the time to reach asymptotic behavior, and results in\nimproved asymptotic behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.1599v1"
    },
    {
        "title": "Deaf, Dumb, and Chatting Robots, Enabling Distributed Computation and\n  Fault-Tolerance Among Stigmergic Robot",
        "authors": [
            "Yoann Dieudonné",
            "Shlomi Dolev",
            "Franck Petit",
            "Michael Segal"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  We investigate ways for the exchange of information (explicit communication)\namong deaf and dumb mobile robots scattered in the plane. We introduce the use\nof movement-signals (analogously to flight signals and bees waggle) as a mean\nto transfer messages, enabling the use of distributed algorithms among the\nrobots. We propose one-to-one deterministic movement protocols that implement\nexplicit communication. We first present protocols for synchronous robots. We\nbegin with a very simple coding protocol for two robots. Based on on this\nprotocol, we provide one-to-one communication for any system of n \\geq 2 robots\nequipped with observable IDs that agree on a common direction (sense of\ndirection). We then propose two solutions enabling one-to-one communication\namong anonymous robots. Since the robots are devoid of observable IDs, both\nprotocols build recognition mechanisms using the (weak) capabilities offered to\nthe robots. The first protocol assumes that the robots agree on a common\ndirection and a common handedness (chirality), while the second protocol\nassumes chirality only. Next, we show how the movements of robots can provide\nimplicit acknowledgments in asynchronous systems. We use this result to design\nasynchronous one-to-one communication with two robots only. Finally, we combine\nthis solution with the schemes developed in synchronous settings to fit the\ngeneral case of asynchronous one-to-one communication among any number of\nrobots. Our protocols enable the use of distributing algorithms based on\nmessage exchanges among swarms of Stigmergic robots. Furthermore, they provides\nrobots equipped with means of communication to overcome faults of their\ncommunication device.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.3549v1"
    },
    {
        "title": "The use of dynamic distance potential fields for pedestrian flow around\n  corners",
        "authors": [
            "Tobias Kretz"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  This contribution investigates situations in pedestrian dynamics, where\ntrying to walk the shortest path leads to largely different results than trying\nto walk the quickest path. A heuristic one-shot method to model the influence\nof the will to walk the quickest path is introduced.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.2667v1"
    },
    {
        "title": "On Cyclic and Nearly Cyclic Multiagent Interactions in the Plane",
        "authors": [
            "Frederique Oggier",
            "Alfred Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  We discuss certain types of cyclic and nearly cyclic interactions among N\n\"point\"-agents in the plane, leading to formations of interesting limiting\ngeometric configurations. Cyclic pursuit and local averaging interactions have\nbeen analyzed in the context of multi-agent gathering. In this paper, we\nconsider some nearly cyclic interactions that break symmetry leading to factor\ncirculants rather than circulant interaction matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/0907.2759v1"
    },
    {
        "title": "Digital Ecosystems",
        "authors": [
            "Gerard Briscoe"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  We view Digital Ecosystems to be the digital counterparts of biological\necosystems, which are considered to be robust, self-organising and scalable\narchitectures that can automatically solve complex, dynamic problems. So, this\nwork is concerned with the creation, investigation, and optimisation of Digital\nEcosystems, exploiting the self-organising properties of biological ecosystems.\nFirst, we created the Digital Ecosystem, a novel optimisation technique\ninspired by biological ecosystems, where the optimisation works at two levels:\na first optimisation, migration of agents which are distributed in a\ndecentralised peer-to-peer network, operating continuously in time; this\nprocess feeds a second optimisation based on evolutionary computing that\noperates locally on single peers and is aimed at finding solutions to satisfy\nlocally relevant constraints. We then investigated its self-organising aspects,\nstarting with an extension to the definition of Physical Complexity to include\nevolving agent populations. Next, we established stability of evolving agent\npopulations over time, by extending the Chli-DeWilde definition of agent\nstability to include evolutionary dynamics. Further, we evaluated the diversity\nof the software agents within evolving agent populations. To conclude, we\nconsidered alternative augmentations to optimise and accelerate our Digital\nEcosystem, by studying the accelerating effect of a clustering catalyst on the\nevolutionary dynamics. We also studied the optimising effect of targeted\nmigration on the ecological dynamics, through the indirect and emergent\noptimisation of the agent migration patterns. Overall, we have advanced the\nunderstanding of creating Digital Ecosystems, the self-organisation that occurs\nwithin them, and the optimisation of their Ecosystem-Oriented Architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.3423v2"
    },
    {
        "title": "Computation Speed of the F.A.S.T. Model",
        "authors": [
            "Tobias Kretz"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  The F.A.S.T. model for microscopic simulation of pedestrians was formulated\nwith the idea of parallelizability and small computation times in general in\nmind, but so far it was never demonstrated, if it can in fact be implemented\nefficiently for execution on a multi-core or multi-CPU system. In this\ncontribution results are given on computation times for the F.A.S.T. model on\nan eight-core PC.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.2900v1"
    },
    {
        "title": "An iterative approach for generating statistically realistic populations\n  of households",
        "authors": [
            "Floriana Gargiulo",
            "Sonia Ternes",
            "Sylvie Huet",
            "Guillaume Deffuant"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  Background: Many different simulation frameworks, in different topics, need\nto treat realistic datasets to initialize and calibrate the system. A precise\nreproduction of initial states is extremely important to obtain reliable\nforecast from the model. Methodology/Principal Findings: This paper proposes an\nalgorithm to create an artificial population where individuals are described by\ntheir age, and are gathered in households respecting a variety of statistical\nconstraints (distribution of household types, sizes, age of household head,\ndifference of age between partners and among parents and children). Such a\npopulation is often the initial state of microsimulation or (agent)\nindividual-based models. To get a realistic distribution of households is often\nvery important, because this distribution has an impact on the demographic\nevolution. Usual techniques from microsimulation approach cross different\nsources of aggregated data for generating individuals. In our case the number\nof combinations of different households (types, sizes, age of participants)\nmakes it computationally difficult to use directly such methods. Hence we\ndeveloped a specific algorithm to make the problem more easily tractable.\nConclusions/Significance: We generate the populations of two pilot\nmunicipalities in Auvergne region (France), to illustrate the approach. The\ngenerated populations show a good agreement with the available statistical\ndatasets (not used for the generation) and are obtained in a reasonable\ncomputational time.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.2826v1"
    },
    {
        "title": "Consensus Dynamics in a non-deterministic Naming Game with Shared Memory",
        "authors": [
            "Reginaldo J. da Silva Filho",
            "Matthias R. Brust",
            "Carlos H. C. Ribeiro"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  In the naming game, individuals or agents exchange pairwise local information\nin order to communicate about objects in their common environment. The goal of\nthe game is to reach a consensus about naming these objects. Originally used to\ninvestigate language formation and self-organizing vocabularies, we extend the\nclassical naming game with a globally shared memory accessible by all agents.\nThis shared memory can be interpreted as an external source of knowledge like a\nbook or an Internet site. The extended naming game models an environment\nsimilar to one that can be found in the context of social bookmarking and\ncollaborative tagging sites where users tag sites using appropriate labels, but\nalso mimics an important aspect in the field of human-based image labeling.\nAlthough the extended naming game is non-deterministic in its word selection,\nwe show that consensus towards a common vocabulary is reached. More\nimportantly, we show the qualitative and quantitative influence of the external\nsource of information, i.e. the shared memory, on the consensus dynamics\nbetween the agents.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.4553v1"
    },
    {
        "title": "Distributed Control of the Laplacian Spectral Moments of a Network",
        "authors": [
            "Victor M. Preciado",
            "Michael M. Zavlanos",
            "Ali Jadbabaie",
            "George J. Pappas"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  It is well-known that the eigenvalue spectrum of the Laplacian matrix of a\nnetwork contains valuable information about the network structure and the\nbehavior of many dynamical processes run on it. In this paper, we propose a\nfully decentralized algorithm that iteratively modifies the structure of a\nnetwork of agents in order to control the moments of the Laplacian eigenvalue\nspectrum. Although the individual agents have knowledge of their local network\nstructure only (i.e., myopic information), they are collectively able to\naggregate this local information and decide on what links are most beneficial\nto be added or removed at each time step. Our approach relies on gossip\nalgorithms to distributively compute the spectral moments of the Laplacian\nmatrix, as well as ensure network connectivity in the presence of link\ndeletions. We illustrate our approach in nontrivial computer simulations and\nshow that a good final approximation of the spectral moments of the target\nLaplacian matrix is achieved for many cases of interest.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.4122v1"
    },
    {
        "title": "An Agent-Based Modeling for Pandemic Influenza in Egypt",
        "authors": [
            "Khaled M. Khalil",
            "M. Abdel-Aziz",
            "Taymour T. Nazmy",
            "Abdel-Badeeh M. Salem"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Pandemic influenza has great potential to cause large and rapid increases in\ndeaths and serious illness. The objective of this paper is to develop an\nagent-based model to simulate the spread of pandemic influenza (novel H1N1) in\nEgypt. The proposed multi-agent model is based on the modeling of individuals'\ninteractions in a space time context. The proposed model involves different\ntypes of parameters such as: social agent attributes, distribution of Egypt\npopulation, and patterns of agents' interactions. Analysis of modeling results\nleads to understanding the characteristics of the modeled pandemic,\ntransmission patterns, and the conditions under which an outbreak might occur.\nIn addition, the proposed model is used to measure the effectiveness of\ndifferent control strategies to intervene the pandemic spread.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.5275v1"
    },
    {
        "title": "Agent Based Approaches to Engineering Autonomous Space Software",
        "authors": [
            "Louise A. Dennis",
            "Michael Fisher",
            "Nicholas Lincoln",
            "Alexei Lisitsa",
            "Sandor M. Veres"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Current approaches to the engineering of space software such as satellite\ncontrol systems are based around the development of feedback controllers using\npackages such as MatLab's Simulink toolbox. These provide powerful tools for\nengineering real time systems that adapt to changes in the environment but are\nlimited when the controller itself needs to be adapted.\n  We are investigating ways in which ideas from temporal logics and agent\nprogramming can be integrated with the use of such control systems to provide a\nmore powerful layer of autonomous decision making. This paper will discuss our\ninitial approaches to the engineering of such systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.0617v1"
    },
    {
        "title": "Simulating Customer Experience and Word Of Mouth in Retail - A Case\n  Study",
        "authors": [
            "Peer-Olaf Siebers",
            "Uwe Aickelin",
            "Helen Celia",
            "Chris Clegg"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Agents offer a new and exciting way of understanding the world of work. In\nthis paper we describe the development of agent-based simulation models,\ndesigned to help to understand the relationship between people management\npractices and retail performance. We report on the current development of our\nsimulation models which includes new features concerning the evolution of\ncustomers over time. To test the features we have conducted a series of\nexperiments dealing with customer pool sizes, standard and noise reduction\nmodes, and the spread of customers' word of mouth. To validate and evaluate our\nmodel, we introduce new performance measure specific to retail operations. We\nshow that by varying different parameters in our model we can simulate a range\nof customer experiences leading to significant differences in performance\nmeasures. Ultimately, we are interested in better understanding the impact of\nchanges in staff behavior due to changes in store management practices. Our\nmulti-disciplinary research team draws upon expertise from work psychologists\nand computer scientists. Despite the fact we are working within a relatively\nnovel and complex domain, it is clear that intelligent agents offer potential\nfor fostering sustainable organizational capabilities in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.3784v1"
    },
    {
        "title": "On Asymptotic Consensus Value in Directed Random Networks",
        "authors": [
            "Victor M. Preciado",
            "Alireza Tahbaz-Salehi",
            "Ali Jadbabaie"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  We study the asymptotic properties of distributed consensus algorithms over\nswitching directed random networks. More specifically, we focus on consensus\nalgorithms over independent and identically distributed, directed random\ngraphs, where each agent can communicate with any other agent with some\nexogenously specified probability. While different aspects of consensus\nalgorithms over random switching networks have been widely studied, a complete\ncharacterization of the distribution of the asymptotic value for general\n\\textit{asymmetric} random consensus algorithms remains an open problem. In\nthis paper, we derive closed-form expressions for the mean and an upper bound\nfor the variance of the asymptotic consensus value, when the underlying network\nevolves according to an i.i.d. \\textit{directed} random graph process. We also\nprovide numerical simulations that illustrate our results.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3527v1"
    },
    {
        "title": "Design specifications of the Human Robotic interface for the biomimetic\n  underwater robot \"yellow submarine project\"",
        "authors": [
            "Anil Bheemaiah"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  This paper describes the design of a web based multi agent design for a\ncollision avoidance auto navigation biomimetic submarine for submarine\nhydroelectricity. The paper describes the nature of the map - topology\ninterface for river bodies and the design of interactive agents for the control\nof the robotic submarine. The agents are migratory on the web and are designed\nin XML/html interface with both interactive capabilities and visibility on a\nmap. The paper describes mathematically the user interface and the map\ndefinition languages used for the multi agent description\n",
        "pdf_link": "http://arxiv.org/pdf/1006.5263v1"
    },
    {
        "title": "A Hybrid Model for Disease Spread and an Application to the SARS\n  Pandemic",
        "authors": [
            "Teruhiko Yoneyama",
            "Sanmay Das",
            "Mukkai Krishnamoorthy"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Pandemics can cause immense disruption and damage to communities and\nsocieties. Thus far, modeling of pandemics has focused on either large-scale\ndifference equation models like the SIR and the SEIR models, or detailed\nmicro-level simulations, which are harder to apply at a global scale. This\npaper introduces a hybrid model for pandemics considering both global and local\nspread of infections. We hypothesize that the spread of an infectious disease\nbetween regions is significantly influenced by global traffic patterns and the\nspread within a region is influenced by local conditions. Thus we model the\nspread of pandemics considering the connections between regions for the global\nspread of infection and population density based on the SEIR model for the\nlocal spread of infection. We validate our hybrid model by carrying out a\nsimulation study for the spread of SARS pandemic of 2002-2003 using available\ndata on population, population density, and traffic networks between different\nregions. While it is well-known that international relationships and global\ntraffic patterns significantly influence the spread of pandemics, our results\nshow that integrating these factors into relatively simple models can greatly\nimprove the results of modeling disease spread.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.4523v1"
    },
    {
        "title": "Noise in Naming Games, partial synchronization and community detection\n  in social networks",
        "authors": [
            "Weituo Zhang",
            "Chjan C. Lim"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  The Naming Games (NG) are agent-based models for agreement dynamics, peer\npressure and herding in social networks, and protocol selection in autonomous\nad-hoc sensor networks. By introducing a small noise term to the NG, the\nresulting Markov Chain model called Noisy Naming Games (NNG) are ergodic, in\nwhich all partial consensus states are recurrent. By using Gibbs-Markov\nequivalence we show how to get the NNG's stationary distribution in terms of\nthe local specification of a related Markov Random Field (MRF). By ordering the\npartially-synchronized states according to their Gibbs energy, taken here to be\na good measure of social tension, this method offers an enhanced method for\ncommunity-detection in social interaction data. We show how the lowest Gibbs\nenergy multi-name states separate and display the hidden community structures\nwithin a social network.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.4115v1"
    },
    {
        "title": "A Novel Approach for Cardiac Disease Prediction and Classification Using\n  Intelligent Agents",
        "authors": [
            "Murugesan Kuttikrishnan"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  The goal is to develop a novel approach for cardiac disease prediction and\ndiagnosis using intelligent agents. Initially the symptoms are preprocessed\nusing filter and wrapper based agents. The filter removes the missing or\nirrelevant symptoms. Wrapper is used to extract the data in the data set\naccording to the threshold limits. Dependency of each symptom is identified\nusing dependency checker agent. The classification is based on the prior and\nposterior probability of the symptoms with the evidence value. Finally the\nsymptoms are classified in to five classes namely absence, starting, mild,\nmoderate and serious. Using the cooperative approach the cardiac problem is\nsolved and verified.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.5346v1"
    },
    {
        "title": "A simulation of the Neolithic transition in Western Eurasia",
        "authors": [
            "Carsten Lemmen",
            "Detlef Gronenborn",
            "Kai W. Wirtz"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Farming and herding were introduced to Europe from the Near East and\nAnatolia; there are, however, considerable arguments about the mechanisms of\nthis transition. Were it people who moved and outplaced the indigenous hunter-\ngatherer groups or admixed with them? Or was it just material and information\nthat moved-the Neolithic Package-consisting of domesticated plants and animals\nand the knowledge of its use? The latter process is commonly referred to as\ncultural diffusion and the former as demic diffusion. Despite continuous and\npartly combined efforts by archaeologists, anthropologists, linguists,\npaleontologists and geneticists a final resolution of the debate has not yet\nbeen reached. In the present contribution we interpret results from the Global\nLand Use and technological Evolution Simulator (GLUES), a mathematical model\nfor regional sociocultural development embedded in the western Eurasian\ngeoenvironmental context during the Holocene. We demonstrate that the model is\nable to realistically hindcast the expansion speed and the inhomogeneous\nspace-time evolution of the transition to agropastoralism in Europe. GLUES, in\ncontrast to models that do not resolve endogenous sociocultural dynamics, also\ndescribes and explains how and why the Neolithic advanced in stages. In the\nmodel analysis, we uncouple the mechanisms of migration and information\nexchange. We find that (1) an indigenous form of agropastoralism could well\nhave arisen in certain Mediterranean landscapes, but not in Northern and\nCentral Europe, where it depended on imported technology and material, (2) both\ndemic diffusion by migration or cultural diffusion by trade may explain the\nwestern European transition equally well, (3) [...]\n",
        "pdf_link": "http://arxiv.org/pdf/1104.1905v2"
    },
    {
        "title": "Decentralized Markets versus Central Control: A Comparative Study",
        "authors": [
            "H. Akkermans",
            "F. Ygge"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Multi-Agent Systems (MAS) promise to offer solutions to problems where\nestablished, older paradigms fall short. In order to validate such claims that\nare repeatedly made in software agent publications, empirical in-depth studies\nof advantages and weaknesses of multi-agent solutions versus conventional ones\nin practical applications are needed. Climate control in large buildings is one\napplication area where multi-agent systems, and market-oriented programming in\nparticular, have been reported to be very successful, although central control\nsolutions are still the standard practice. We have therefore constructed and\nimplemented a variety of market designs for this problem, as well as different\nstandard control engineering solutions. This article gives a detailed analysis\nand comparison, so as to learn about differences between standard versus agent\napproaches, and yielding new insights about benefits and limitations of\ncomputational markets. An important outcome is that \"local information plus\nmarket communication produces global control\".\n",
        "pdf_link": "http://arxiv.org/pdf/1106.0223v1"
    },
    {
        "title": "Robust Agent Teams via Socially-Attentive Monitoring",
        "authors": [
            "G. A. Kaminka",
            "M. Tambe"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Agents in dynamic multi-agent environments must monitor their peers to\nexecute individual and group plans. A key open question is how much monitoring\nof other agents' states is required to be effective: The Monitoring Selectivity\nProblem. We investigate this question in the context of detecting failures in\nteams of cooperating agents, via Socially-Attentive Monitoring, which focuses\non monitoring for failures in the social relationships between the agents. We\nempirically and analytically explore a family of socially-attentive teamwork\nmonitoring algorithms in two dynamic, complex, multi-agent domains, under\nvarying conditions of task distribution and uncertainty. We show that a\ncentralized scheme using a complex algorithm trades correctness for\ncompleteness and requires monitoring all teammates. In contrast, a simple\ndistributed teamwork monitoring algorithm results in correct and complete\ndetection of teamwork failures, despite relying on limited, uncertain\nknowledge, and monitoring only key agents in a team. In addition, we report on\nthe design of a socially-attentive monitoring system and demonstrate its\ngenerality in monitoring several coordination relationships, diagnosing\ndetected failures, and both on-line and off-line applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.0235v1"
    },
    {
        "title": "Interactive Execution Monitoring of Agent Teams",
        "authors": [
            "P. Berry",
            "T. J. Lee",
            "D. E. Wilkins"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  There is an increasing need for automated support for humans monitoring the\nactivity of distributed teams of cooperating agents, both human and machine. We\ncharacterize the domain-independent challenges posed by this problem, and\ndescribe how properties of domains influence the challenges and their\nsolutions. We will concentrate on dynamic, data-rich domains where humans are\nultimately responsible for team behavior. Thus, the automated aid should\ninteractively support effective and timely decision making by the human. We\npresent a domain-independent categorization of the types of alerts a plan-based\nmonitoring system might issue to a user, where each type generally requires\ndifferent monitoring techniques. We describe a monitoring framework for\nintegrating many domain-specific and task-specific monitoring techniques and\nthen using the concept of value of an alert to avoid operator overload. We use\nthis framework to describe an execution monitoring approach we have used to\nimplement Execution Assistants (EAs) in two different dynamic, data-rich,\nreal-world domains to assist a human in monitoring team behavior. One domain\n(Army small unit operations) has hundreds of mobile, geographically distributed\nagents, a combination of humans, robots, and vehicles. The other domain (teams\nof unmanned ground and air vehicles) has a handful of cooperating robots. Both\ndomains involve unpredictable adversaries in the vicinity. Our approach\ncustomizes monitoring behavior for each specific task, plan, and situation, as\nwell as for user preferences. Our EAs alert the human controller when reported\nevents threaten plan execution or physically threaten team members. Alerts were\ngenerated in a timely manner without inundating the user with too many alerts\n(less than 10 percent of alerts are unwanted, as judged by domain experts).\n",
        "pdf_link": "http://arxiv.org/pdf/1106.4577v1"
    },
    {
        "title": "A Multiagent Simulation for Traffic Flow Management with Evolutionary\n  Optimization",
        "authors": [
            "Patryk Filipiak"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  A traffic flow is one of the main transportation issues in nowadays\nindustrialized agglomerations. Configuration of traffic lights is among the key\naspects in traffic flow management. This paper proposes an evolutionary\noptimization tool that utilizes multiagent simulator in order to obtain\naccurate model. Even though more detailed studies are still necessary, a\npreliminary research gives an expectation for promising results.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.3462v1"
    },
    {
        "title": "Multi-Issue Negotiation with Deadlines",
        "authors": [
            "S. S. Fatima",
            "N. R. Jennings",
            "M. J. Wooldridge"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  This paper studies bilateral multi-issue negotiation between self-interested\nautonomous agents. Now, there are a number of different procedures that can be\nused for this process; the three main ones being the package deal procedure in\nwhich all the issues are bundled and discussed together, the simultaneous\nprocedure in which the issues are discussed simultaneously but independently of\neach other, and the sequential procedure in which the issues are discussed one\nafter another. Since each of them yields a different outcome, a key problem is\nto decide which one to use in which circumstances. Specifically, we consider\nthis question for a model in which the agents have time constraints (in the\nform of both deadlines and discount factors) and information uncertainty (in\nthat the agents do not know the opponents utility function). For this model, we\nconsider issues that are both independent and those that are interdependent and\ndetermine equilibria for each case for each procedure. In so doing, we show\nthat the package deal is in fact the optimal procedure for each party. We then\ngo on to show that, although the package deal may be computationally more\ncomplex than the other two procedures, it generates Pareto optimal outcomes\n(unlike the other two), it has similar earliest and latest possible times of\nagreement to the simultaneous procedure (which is better than the sequential\nprocedure), and that it (like the other two procedures) generates a unique\noutcome only under certain conditions (which we define).\n",
        "pdf_link": "http://arxiv.org/pdf/1110.2765v1"
    },
    {
        "title": "Resource Allocation Among Agents with MDP-Induced Preferences",
        "authors": [
            "D. A. Dolgov",
            "E. H. Durfee"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Allocating scarce resources among agents to maximize global utility is, in\ngeneral, computationally challenging. We focus on problems where resources\nenable agents to execute actions in stochastic environments, modeled as Markov\ndecision processes (MDPs), such that the value of a resource bundle is defined\nas the expected value of the optimal MDP policy realizable given these\nresources. We present an algorithm that simultaneously solves the\nresource-allocation and the policy-optimization problems. This allows us to\navoid explicitly representing utilities over exponentially many resource\nbundles, leading to drastic (often exponential) reductions in computational\ncomplexity. We then use this algorithm in the context of self-interested agents\nto design a combinatorial auction for allocating resources. We empirically\ndemonstrate the effectiveness of our approach by showing that it can, in\nminutes, optimally solve problems for which a straightforward combinatorial\nresource-allocation technique would require the agents to enumerate up to 2^100\nresource bundles and the auctioneer to solve an NP-complete problem with an\ninput of that size.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.2767v1"
    },
    {
        "title": "Stability of Evolving Multi-Agent Systems",
        "authors": [
            "Philippe De Wilde",
            "Gerard Briscoe"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  A Multi-Agent System is a distributed system where the agents or nodes\nperform complex functions that cannot be written down in analytic form.\nMulti-Agent Systems are highly connected, and the information they contain is\nmostly stored in the connections. When agents update their state, they take\ninto account the state of the other agents, and they have access to those\nstates via the connections. There is also external, user-generated input into\nthe Multi-Agent System. As so much information is stored in the connections,\nagents are often memory-less. This memory-less property, together with the\nrandomness of the external input, has allowed us to model Multi-Agent Systems\nusing Markov chains. In this paper, we look at Multi-Agent Systems that evolve,\ni.e. the number of agents varies according to the fitness of the individual\nagents. We extend our Markov chain model, and define stability. This is the\nstart of a methodology to control Multi-Agent Systems. We then build upon this\nto construct an entropy-based definition for the degree of instability (entropy\nof the limit probabilities), which we used to perform a stability analysis. We\nthen investigated the stability of evolving agent populations through\nsimulation, and show that the results are consistent with the original\ndefinition of stability in non-evolving Multi-Agent Systems, proposed by Chli\nand De Wilde. This paper forms the theoretical basis for the construction of\nDigital Business Ecosystems, and applications have been reported elsewhere.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.7033v1"
    },
    {
        "title": "Modeling multistage decision processes with Reflexive Game Theory",
        "authors": [
            "Sergey Tarasenko"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This paper introduces application of Reflexive Game Theory to the matter of\nmultistage decision making processes. The idea behind is that each decision\nmaking session has certain parameters like \"when the session is taking place\",\n\"who are the group members to make decision\", \"how group members influence on\neach other\", etc. This study illustrates the consecutive or sequential decision\nmaking process, which consist of two stages. During the stage 1 decisions about\nthe parameters of the ultimate decision making are made. Then stage 2 is\nimplementation of Ultimate decision making itself. Since during stage 1 there\ncan be multiple decision sessions. In such a case it takes more than two\nsessions to make ultimate (final) decision. Therefore the overall process of\nultimate decision making becomes multistage decision making process consisting\nof consecutive decision making sessions.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2315v1"
    },
    {
        "title": "Graph-Theoretic Characterizations of Structural Controllability for\n  Multi-Agent System with Switching Topology",
        "authors": [
            "Xiaomeng Liu",
            "Hai Lin",
            "Ben M. Chen"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This paper considers the controllability problem for multi-agent systems. In\nparticular, the structural controllability of multi-agent systems under\nswitching topologies is investigated. The structural controllability of\nmulti-agent systems is a generalization of the traditional controllability\nconcept for dynamical systems, and purely based on the communication topologies\namong agents. The main contributions of the paper are graph-theoretic\ncharacterizations of the structural controllability for multi-agent systems. It\nturns out that the multi-agent system with switching topology is structurally\ncontrollable if and only if the union graph G of the underlying communication\ntopologies is connected (single leader) or leader-follower connected\n(multi-leader). Finally, the paper concludes with several illustrative examples\nand discussions of the results and future work.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.5583v1"
    },
    {
        "title": "A new approach of designing Multi-Agent Systems",
        "authors": [
            "Sara Maalal",
            "Malika Addou"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Agent technology is a software paradigm that permits to implement large and\ncomplex distributed applications. In order to assist analyzing, conception and\ndevelopment or implementation phases of multi-agent systems, we've tried to\npresent a practical application of a generic and scalable method of a MAS with\na component-oriented architecture and agent-based approach that allows MDA to\ngenerate source code from a given model. We've designed on AUML the class\ndiagrams as a class meta-model of different agents of a MAS. Then we generated\nthe source code of the models developed using an open source tool called\nAndroMDA. This agent-based and evolutive approach enhances the modularity and\ngenericity developments and promotes their reusability in future developments.\nThis property distinguishes our design methodology of existing methodologies in\nthat it is constrained by any particular agent-based model while providing a\nlibrary of generic models\n",
        "pdf_link": "http://arxiv.org/pdf/1204.1581v1"
    },
    {
        "title": "Towards a Formal Model of Privacy-Sensitive Dynamic Coalitions",
        "authors": [
            "Sebastian Bab",
            "Nadim Sarrouh"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  The concept of dynamic coalitions (also virtual organizations) describes the\ntemporary interconnection of autonomous agents, who share information or\nresources in order to achieve a common goal. Through modern technologies these\ncoalitions may form across company, organization and system borders. Therefor\nquestions of access control and security are of vital significance for the\narchitectures supporting these coalitions.\n  In this paper, we present our first steps to reach a formal framework for\nmodeling and verifying the design of privacy-sensitive dynamic coalition\ninfrastructures and their processes. In order to do so we extend existing\ndynamic coalition modeling approaches with an access-control-concept, which\nmanages access to information through policies. Furthermore we regard the\nprocesses underlying these coalitions and present first works in formalizing\nthese processes. As a result of the present paper we illustrate the usefulness\nof the Abstract State Machine (ASM) method for this task. We demonstrate a\nformal treatment of privacy-sensitive dynamic coalitions by two example ASMs\nwhich model certain access control situations. A logical consideration of these\nASMs can lead to a better understanding and a verification of the ASMs\naccording to the aspired specification.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.6090v1"
    },
    {
        "title": "A structured approach to VO reconfigurations through Policies",
        "authors": [
            "Stephan Reiff-Marganiec"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  One of the strength of Virtual Organisations is their ability to dynamically\nand rapidly adapt in response to changing environmental conditions. Dynamic\nadaptability has been studied in other system areas as well and system\nmanagement through policies has crystallized itself as a very prominent\nsolution in system and network administration. However, these areas are often\nconcerned with very low-level technical aspects. Previous work on the APPEL\npolicy language has been aimed at dynamically adapting system behaviour to\nsatisfy end-user demands and - as part of STPOWLA - APPEL was used to adapt\nworkflow instances at runtime. In this paper we explore how the ideas of APPEL\nand STPOWLA can be extended from workflows to the wider scope of Virtual\nOrganisations. We will use a Travel Booking VO as example.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.6091v1"
    },
    {
        "title": "Ring Exploration with Oblivious Myopic Robots",
        "authors": [
            "Ajoy K. Datta",
            "Anissa Lamani",
            "Lawrence L. Larmore",
            "Franck Petit"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  The exploration problem in the discrete universe, using identical oblivious\nasynchronous robots without direct communication, has been well investigated.\nThese robots have sensors that allow them to see their environment and move\naccordingly. However, the previous work on this problem assume that robots have\nan unlimited visibility, that is, they can see the position of all the other\nrobots. In this paper, we consider deterministic exploration in an anonymous,\nunoriented ring using asynchronous, oblivious, and myopic robots. By myopic, we\nmean that the robots have only a limited visibility. We study the computational\nlimits imposed by such robots and we show that under some conditions the\nexploration problem can still be solved. We study the cases where the robots\nvisibility is limited to 1, 2, and 3 neighboring nodes, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.5003v1"
    },
    {
        "title": "Distributed team formation in multi-agent systems: stability and\n  approximation",
        "authors": [
            "Lorenzo Coviello",
            "Massimo Franceschetti"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  We consider a scenario in which leaders are required to recruit teams of\nfollowers. Each leader cannot recruit all followers, but interaction is\nconstrained according to a bipartite network. The objective for each leader is\nto reach a state of local stability in which it controls a team whose size is\nequal to a given constraint. We focus on distributed strategies, in which\nagents have only local information of the network topology and propose a\ndistributed algorithm in which leaders and followers act according to simple\nlocal rules. The performance of the algorithm is analyzed with respect to the\nconvergence to a stable solution.\n  Our results are as follows. For any network, the proposed algorithm is shown\nto converge to an approximate stable solution in polynomial time, namely the\nleaders quickly form teams in which the total number of additional followers\nrequired to satisfy all team size constraints is an arbitrarily small fraction\nof the entire population. In contrast, for general graphs there can be an\nexponential time gap between convergence to an approximate solution and to a\nstable solution.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.6475v2"
    },
    {
        "title": "Distributed Pareto Optimization via Diffusion Strategies",
        "authors": [
            "Jianshu Chen",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  We consider solving multi-objective optimization problems in a distributed\nmanner by a network of cooperating and learning agents. The problem is\nequivalent to optimizing a global cost that is the sum of individual\ncomponents. The optimizers of the individual components do not necessarily\ncoincide and the network therefore needs to seek Pareto optimal solutions. We\ndevelop a distributed solution that relies on a general class of adaptive\ndiffusion strategies. We show how the diffusion process can be represented as\nthe cascade composition of three operators: two combination operators and a\ngradient descent operator. Using the Banach fixed-point theorem, we establish\nthe existence of a unique fixed point for the composite cascade. We then study\nhow close each agent converges towards this fixed point, and also examine how\nclose the Pareto solution is to the fixed point. We perform a detailed\nmean-square error analysis and establish that all agents are able to converge\nto the same Pareto optimal solution within a sufficiently small\nmean-square-error (MSE) bound even for constant step-sizes. We illustrate one\napplication of the theory to collaborative decision making in finance by a\nnetwork of agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.2503v1"
    },
    {
        "title": "A Novel Service Oriented Model for Query Identification and Solution\n  Development using Semantic Web and Multi Agent System",
        "authors": [
            "Muneendra Ojha"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  In this paper, we propose to develop service model architecture by merging\nmulti-agentsystems and semantic web technology. The proposed architecture works\nin two stages namely, Query Identification and Solution Development. A person\nreferred to as customer will submit the problem details or requirements which\nwill be referred to as a query. Anyone who can provide a service will need to\nregister with the registrar module of the architecture. Services can be\nanything ranging from expert consultancy in the field of agriculture to\nacademic research, from selling products to manufacturing goods, from medical\nhelp to legal issues or even providing logistics. Query submitted by customer\nis first parsed and then iteratively understood with the help of domain experts\nand the customer to get a precise set of properties. Query thus identified will\nbe solved again with the help of intelligent agent systems which will search\nthe semantic web for all those who can find or provide a solution. A workable\nsolution workflow is created and then depending on the requirements, using the\ntechniques of negotiation or auctioning, solution is implemented to complete\nthe service for customer. This part is termed as solution development. In this\nservice oriented architecture, we first try to analyze the complex set of user\nrequirements then try to provide best possible solution in an optimized way by\ncombining better information searches through semantic web and better workflow\nprovisioning using multi agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.6421v1"
    },
    {
        "title": "Average Consensus in the Presence of Delays and Dynamically Changing\n  Directed Graph Topologies",
        "authors": [
            "Christoforos N. Hadjicostis",
            "Themistoklis Charalambous"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Classical approaches for asymptotic convergence to the global average in a\ndistributed fashion typically assume timely and reliable exchange of\ninformation between neighboring components of a given multi-component system.\nThese assumptions are not necessarily valid in practical settings due to\nvarying delays that might affect transmissions at different times, as well as\npossible changes in the underlying interconnection topology (e.g., due to\ncomponent mobility). In this work, we propose protocols to overcome these\nlimitations. We first consider a fixed interconnection topology (captured by a\n- possibly directed - graph) and propose a discrete-time protocol that can\nreach asymptotic average consensus in a distributed fashion, despite the\npresence of arbitrary (but bounded) delays in the communication links. The\nprotocol requires that each component has knowledge of the number of its\noutgoing links (i.e., the number of components to which it sends information).\nWe subsequently extend the protocol to also handle changes in the underlying\ninterconnection topology and describe a variety of rather loose conditions\nunder which the modified protocol allows the components to reach asymptotic\naverage consensus. The proposed algorithms are illustrated via examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.4778v2"
    },
    {
        "title": "Study on the Availability Prediction of the Reconfigurable Networked\n  Software System",
        "authors": [
            "Lingzhong Meng"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This paper describes multi-agent based availability prediction approach for\nthe reconfigurable networked software system.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.7600v1"
    },
    {
        "title": "Emergence of Self-Organized Amoeboid Movement in a Multi-Agent\n  Approximation of Physarum polycephalum",
        "authors": [
            "Jeff Jones",
            "Andrew Adamatzky"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  The giant single-celled slime mould Physarum polycephalum exhibits complex\nmorphological adaptation and amoeboid movement as it forages for food and may\nbe seen as a minimal example of complex robotic behaviour. Swarm computation\nhas previously been used to explore how spatiotemporal complexity can emerge\nfrom, and be distributed within, simple component parts and their interactions.\nUsing a particle based swarm approach we explore the question of how to\ngenerate collective amoeboid movement from simple non-oscillatory component\nparts in a model of P. polycephalum. The model collective behaves as a cohesive\nand deformable virtual material, approximating the local coupling within the\nplasmodium matrix. The collective generates de-novo and complex oscillatory\npatterns from simple local interactions. The origin of this motor behaviour is\ndistributed within the collective rendering is morphologically adaptive,\namenable to external influence, and robust to simulated environmental insult.\nWe show how to gain external influence over the collective movement by\nsimulated chemo-attraction (pulling towards nutrient stimuli) and simulated\nlight irradiation hazards (pushing from stimuli). The amorphous and distributed\nproperties of the collective are demonstrated by cleaving it into two\nindependent entities and fusing two separate entities to form a single device,\nthus enabling it to traverse narrow, separate or tortuous paths. We conclude by\nsummarising the contribution of the model to swarm based robotics and\nsoft-bodied modular robotics and discuss the future potential of such material\napproaches to the field.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0023v1"
    },
    {
        "title": "Onboard Dynamic Rail Track Safety Monitoring System",
        "authors": [
            "Abhisekh Jain",
            "Arvind Seshadri",
            "Balaji B. S",
            "Ramviyas Parasuraman"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  This proposal aims at solving one of the long prevailing problems in the\nIndian Railways. This simple method of continuous monitoring and assessment of\nthe condition of the rail tracks can prevent major disasters and save precious\nhuman lives. Our method is capable of alerting the train in case of any\ndislocations in the track or change in strength of the soil. Also it can avert\nthe collisions of the train with other or with the vehicles trying to move\nacross the unmanned level crossings.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0240v2"
    },
    {
        "title": "Design of Intelligent Agents Based System for Commodity Market\n  Simulation with JADE",
        "authors": [
            "R. Refianti",
            "A. B. Mutiara",
            "H. Gunawan"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  A market of potato commodity for industry scale usage is engaging several\ntypes of actors. They are farmers, middlemen, and industries. A multi-agent\nsystem has been built to simulate these actors into agent entities, based on\nmanually given parameters within a simulation scenario file. Each type of\nagents has its own fuzzy logic representing actual actors' knowledge, to be\nused to interpreting values and take appropriated decision of it while on\nsimulation. The system will simulate market activities with programmed\nbehaviors then produce the results as spreadsheet and chart graph files. These\nresults consist of each agent's yearly finance and commodity data. The system\nwill also predict each of next value from these outputs.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6298v1"
    },
    {
        "title": "A multi-lane traffic simulation model via continuous cellular automata",
        "authors": [
            "Emanuele Rodaro",
            "Öznur Yeldan"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Traffic models based on cellular automata have high computational efficiency\nbecause of their simplicity in describing unrealistic vehicular behavior and\nthe versatility of cellular automata to be implemented on parallel processing.\nOn the other hand, the other microscopic traffic models such as car-following\nmodels are computationally more expensive, but they have more realistic driver\nbehaviors and detailed vehicle characteristics. We propose a new class between\nthese two categories, defining a traffic model based on continuous cellular\nautomata where we combine the efficiency of cellular automata models with the\naccuracy of the other microscopic models. More precisely, we introduce a\nstochastic cellular automata traffic model in which the space is not\ncoarse-grain but continuous. The continuity also allows us to embed a\nmulti-agent fuzzy system proposed to handle uncertainties in decision making on\nroad traffic. Therefore, we simulate different driver behaviors and study the\neffect of various compositions of vehicles within the traffic stream from the\nmacroscopic point of view. The experimental results show that our model is able\nto reproduce the typical traffic flow phenomena showing a variety of effects\ndue to the heterogeneity of traffic.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.0488v1"
    },
    {
        "title": "A tournament of order 24 with two disjoint TEQ-retentive sets",
        "authors": [
            "Felix Brandt",
            "Hans Georg Seedig"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Brandt et al. (2013) have recently disproved a conjecture by Schwartz (1990)\nby non-constructively showing the existence of a counterexample with about\n10^136 alternatives. We provide a concrete counterexample for Schwartz's\nconjecture with only 24 alternatives.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.5592v2"
    },
    {
        "title": "Finite-time consensus using stochastic matrices with positive diagonals",
        "authors": [
            "Julien M. Hendrickx",
            "Guodong Shi",
            "Karl H. Johansson"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  We discuss the possibility of reaching consensus in finite time using only\nlinear iterations, with the additional restrictions that the update matrices\nmust be stochastic with positive diagonals and consistent with a given graph\nstructure. We show that finite-time average consensus can always be achieved\nfor connected undirected graphs. For directed graphs, we show some necessary\nconditions for finite-time consensus, including strong connectivity and the\npresence of a simple cycle of even length.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.6668v3"
    },
    {
        "title": "Models of Consensus for Multiple Agent Systems",
        "authors": [
            "Daniel E. O'Leary"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Models of consensus are used to manage multiple agent systems in order to\nchoose between different recommendations provided by the system. It is assumed\nthat there is a central agent that solicits recommendations or plans from other\nagents. That agent the n determines the consensus of the other agents, and\nchooses the resultant consensus recommendation or plan. Voting schemes such as\nthis have been used in a variety of domains, including air traffic control.\nThis paper uses an analytic model to study the use of consensus in multiple\nagent systems. The binomial model is used to study the probability that the\nconsensus judgment is correct or incorrect. That basic model is extended to\naccount for both different levels of agent competence and unequal prior odds.\nThe analysis of that model is critical in the investigation of multiple agent\nsystems, since the model leads us to conclude that in some cases consensus\njudgment is not appropriate. In addition, the results allow us to determine how\nmany agents should be used to develop consensus decisions, which agents should\nbe used to develop consensus decisions and under which conditions the consensus\nmodel should be used.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.6834v1"
    },
    {
        "title": "Towards a serious games evacuation simulator",
        "authors": [
            "João Ribeiro",
            "João Emílio Almeida",
            "Rosaldo J. F. Rossetti",
            "António Coelho",
            "António Leça Coelho"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  The evacuation of complex buildings is a challenge under any circumstances.\nFire drills are a way of training and validating evacuation plans. However,\nsometimes these plans are not taken seriously by their participants. It is also\ndifficult to have the financial and time resources required. In this scenario,\nserious games can be used as a tool for training, planning and evaluating\nemergency plans. In this paper a prototype of a serious games evacuation\nsimulator is presented. To make the environment as realistic as possible, 3D\nmodels were made using Blender and loaded onto Unity3D, a popular game engine.\nThis framework provided us with the appropriate simulation environment. Some\nexperiences were made and results show that this tool has potential for\npractitioners and planners to use it for training building occupants.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.3827v1"
    },
    {
        "title": "Towards an Integrated Approach to Crowd Analysis and Crowd Synthesis: a\n  Case Study and First Results",
        "authors": [
            "Stefania Bandini",
            "Andrea Gorrini",
            "Giuseppe Vizzari"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Studies related to crowds of pedestrians, both those of theoretical nature\nand application oriented ones, have generally focused on either the analysis or\nthe synthesis of the phenomena related to the interplay between individual\npedestrians, each characterised by goals, preferences and potentially relevant\nrelationships with others, and the environment in which they are situated. The\ncases in which these activities have been systematically integrated for a\nmutual benefit are still very few compared to the corpus of crowd related\nliterature. This paper presents a case study of an integrated approach to the\ndefinition of an innovative model for pedestrian and crowd simulation (on the\nside of synthesis) that was actually motivated and supported by the analyses of\nempirical data acquired from both experimental settings and observations in\nreal world scenarios. In particular, we will introduce a model for the adaptive\nbehaviour of pedestrians that are also members of groups, that strive to\nmaintain their cohesion even in difficult (e.g. high density) situations. The\npaper will show how the synthesis phase also provided inputs to the analysis of\nempirical data, in a virtuous circle.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.5029v1"
    },
    {
        "title": "Coordinating metaheuristic agents with swarm intelligence",
        "authors": [
            "Mehmet Emin Aydin"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Coordination of multi agent systems remains as a problem since there is no\nprominent method to completely solve this problem. Metaheuristic agents are\nspecific implementations of multi-agent systems, which imposes working together\nto solve optimisation problems with metaheuristic algorithms. The idea borrowed\nfrom swarm intelligence seems working much better than those implementations\nsuggested before. This paper reports the performance of swarms of simulated\nannealing agents collaborating with particle swarm optimization algorithm. The\nproposed approach is implemented for multidimensional knapsack problem and has\nresulted much better than some other works published before.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.4051v1"
    },
    {
        "title": "History Based Coalition Formation in Hedonic Context Using Trust",
        "authors": [
            "Ahmadreza Ghaffarizadeh",
            "Vicki H. Allan"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  In this paper we address the problem of coalition formation in hedonic\ncontext. Our modelling tries to be as realistic as possible. In previous\nmodels, once an agent joins a coalition it would not be able to leave the\ncoalition and join the new one; in this research we made it possible to leave a\ncoalition but put some restrictions to control the behavior of agents. Leaving\nor staying of an agent in a coalition will affect on the trust of the other\nagents included in this coalition. Agents will use the trust values in\ncomputing the expected utility of coalitions. Three different risk behaviors\nare introduced for agents that want to initiate a coalition. Using these risk\nbehaviors, some simulations are made and results are analyzed.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.3324v1"
    },
    {
        "title": "Distributed Business Processes - A Framework for Modeling and Execution",
        "authors": [
            "J. Kotremba",
            "S. Raß",
            "R. Singer"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Commercially available business process management systems (BPMS) still\nsuffer to support organizations to enact their business processes in an\neffective and efficient way. Current BPMS, in general, are based on BPMN 2.0\nand/or BPEL. It is well known, that these approaches have some restrictions\naccording modeling and immediate transfer of the model into executable code.\nRecently, a method for modeling and execution of business processes, named\nsubject-oriented business process management (S-BPM), gained attention. This\nmethodology facilitates modeling of any business process using only five\nsymbols and allows direct execution based on such models. Further on, this\nmethodology has a strong theoretical and formal basis realizing distributed\nsystems; any process is defined as a network of independent and distributed\nagents - i.e. instances of subjects - which coordinate work through the\nexchange of messages. In this work, we present a framework and a prototype\nbased on off-the-shelf technologies as a possible realization of the S-BPM\nmethodology. We can prove and demonstrate the principal architecture concept;\nthese results should also stimulate a discussion about actual BPMS and its\nunderlying concepts.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.3126v2"
    },
    {
        "title": "Meme and Variations: A Computer Model of Cultural Evolution",
        "authors": [
            "Liane Gabora"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Holland's (1975) genetic algorithm is a minimal computer model of natural\nselection that made it possible to investigate the effect of manipulating\nspecific parameters on the evolutionary process. If culture is, like biology, a\nform of evolution, it should be possible to similarly abstract the underlying\nskeleton of the process and develop a minimal model of it. Meme and Variations,\nor MAV, is a computational model, inspired by the genetic algorithm, of how\nideas evolve in a society of interacting individuals (Gabora 1995). The name is\na pun on the classical music form 'theme and variations', because it is based\non the premise that novel ideas are variations of old ones; they result from\ntweaking or combining existing ideas in new ways (Holland et al. 1981). MAV\nexplores the impact of biological phenomena such as over-dominance and\nepistasis as well as cognitive and social phenomena such as the ability to\nlearn generalizations or imitate others on the fitness and diversity of\ncultural transmissible actions.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.7524v3"
    },
    {
        "title": "EVOC: A Computer Model of the Evolution of Culture",
        "authors": [
            "Liane Gabora"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  EVOC is a computer model of the EVOlution of Culture. It consists of neural\nnetwork based agents that invent ideas for actions, and imitate neighbors'\nactions. EVOC replicates using a different fitness function the results\nobtained with an earlier model (MAV), including (1) an increase in mean fitness\nof actions, and (2) an increase and then decrease in the diversity of actions.\nDiversity of actions is positively correlated with number of needs, population\nsize and density, and with the erosion of borders between populations. Slowly\neroding borders maximize diversity, fostering specialization followed by\nsharing of fit actions. Square (as opposed to toroidal) worlds also exhibit\nhigher diversity. Introducing a leader that broadcasts its actions throughout\nthe population increases the fitness of actions but reduces diversity; these\neffects diminish the more leaders there are. Low density populations have less\nfit ideas but broadcasting diminishes this effect.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.0522v2"
    },
    {
        "title": "An Agent-based Model of the Cognitive Mechanisms Underlying the Origins\n  of Creative Cultural Evolution",
        "authors": [
            "Liane Gabora",
            "Maryam Saberi"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Human culture is uniquely cumulative and open-ended. Using a computational\nmodel of cultural evolution in which neural network based agents evolve ideas\nfor actions through invention and imitation, we tested the hypothesis that this\nis due to the capacity for recursive recall. We compared runs in which agents\nwere limited to single-step actions to runs in which they used recursive recall\nto chain simple actions into complex ones. Chaining resulted in higher cultural\ndiversity, open-ended generation of novelty, and no ceiling on the mean fitness\nof actions. Both chaining and no-chaining runs exhibited convergence on optimal\nactions, but without chaining this set was static while with chaining it was\never-changing. Chaining increased the ability to capitalize on the capacity for\nlearning. These findings show that the recursive recall hypothesis provides a\ncomputationally plausible explanation of why humans alone have evolved the\ncultural means to transform this planet.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3781v2"
    },
    {
        "title": "Society Functions Best with an Intermediate Level of Creativity",
        "authors": [
            "Liane Gabora",
            "Hadi Firouzi"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  In a society, a proportion of the individuals can benefit from creativity\nwithout being creative themselves by copying the creators. This paper uses an\nagent-based model of cultural evolution to investigate how society is affected\nby different levels of individual creativity. We performed a time series\nanalysis of the mean fitness of ideas across the artificial society varying\nboth the percentage of creators, C, and how creative they are, p using two\ndiscounting methods. Both analyses revealed a valley in the adaptive landscape,\nindicating a tradeoff between C and p. The results suggest that excess\ncreativity at the individual level can be detrimental at the level of the\nsociety because creators invest in unproven ideas at the expense of propagating\nproven ideas.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.4753v2"
    },
    {
        "title": "Cultural Evolution as Distributed Computation",
        "authors": [
            "Liane Gabora"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  The speed and transformative power of human cultural evolution is evident\nfrom the change it has wrought on our planet. This chapter proposes a human\ncomputation program aimed at (1) distinguishing algorithmic from\nnon-algorithmic components of cultural evolution, (2) computationally modeling\nthe algorithmic components, and amassing human solutions to the non-algorithmic\n(generally, creative) components, and (3) combining them to develop\nhuman-machine hybrids with previously unforeseen computational power that can\nbe used to solve real problems. Drawing on recent insights into the origins of\nevolutionary processes from biology and complexity theory, human minds are\nmodeled as self-organizing, interacting, autopoietic networks that evolve\nthrough a Lamarckian (non-Darwinian) process of communal exchange. Existing\ncomputational models as well as directions for future research are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.6342v1"
    },
    {
        "title": "Modeling Oligarchs' Campaign Donations and Ideological Preferences with\n  Simulated Agent-Based Spatial Elections",
        "authors": [
            "Mason Wright",
            "Pratim Sengupta"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  In this paper, we investigate the interactions among oligarchs, political\nparties, and voters using an agent-based modeling approach. We introduce the\nOLIGO model, which is based on the spatial model of democracy, where voters\nhave positions in a policy space and vote for the party that appears closest to\nthem, and parties move in policy space to seek more votes. We extend the\nexisting literature on agent-based models of political economy in the following\nmanner: (1) by introducing a new class of agents- oligarchs - that represent\nleaders of firms in a common industry who lobby for beneficial subsidies\nthrough campaign donations; and (2) by investigating the effects of ideological\npreferences of the oligarchs on legislative action. We test hypotheses from the\nliterature in political economics on the behavior of oligarchs and political\nparties as they interact, under conditions of imperfect information and bounded\nrationality. Our key results indicate that (1) oligarchs tend to donate less to\npolitical campaigns when the parties are more resistant to changing their\npolicies, or when voters are more informed; and (2) if Oligarchs donate to\nparties based on a combination of ideological and profit motivations, Oligarchs\nwill tend to donate at a lower equilibrium level, due to the influence of lost\nprofits. We validate these outcomes via comparisons to real world polling data\non changes in party support over time.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.7134v2"
    },
    {
        "title": "Multitask Diffusion Adaptation over Networks",
        "authors": [
            "Jie Chen",
            "Cédric Richard",
            "Ali. H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Adaptive networks are suitable for decentralized inference tasks, e.g., to\nmonitor complex natural phenomena. Recent research works have intensively\nstudied distributed optimization problems in the case where the nodes have to\nestimate a single optimum parameter vector collaboratively. However, there are\nmany important applications that are multitask-oriented in the sense that there\nare multiple optimum parameter vectors to be inferred simultaneously, in a\ncollaborative manner, over the area covered by the network. In this paper, we\nemploy diffusion strategies to develop distributed algorithms that address\nmultitask problems by minimizing an appropriate mean-square error criterion\nwith $\\ell_2$-regularization. The stability and convergence of the algorithm in\nthe mean and in the mean-square sense is analyzed. Simulations are conducted to\nverify the theoretical findings, and to illustrate how the distributed strategy\ncan be used in several useful applications related to spectral sensing, target\nlocalization, and hyperspectral data unmixing.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.4894v1"
    },
    {
        "title": "Cellular Automata based Feedback Mechanism in Strengthening biological\n  Sequence Analysis Approach to Robotic Soccer",
        "authors": [
            "P. Kiran Sree",
            "G. V. S. Raju",
            "S. Viswandha Raju",
            "N. S. S. S. N Usha Devi"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This paper reports on the application of sequence analysis algorithms for\nagents in robotic soccer and a suitable representation is proposed to achieve\nthis mapping. The objective of this research is to generate novel better\nin-game strategies with the aim of faster adaptation to the changing\nenvironment. A homogeneous non-communicating multi-agent architecture using the\nrepresentation is presented. To achieve real-time learning during a game, a\nbucket brigade algorithm is used to reinforce Cellular Automata Based\nClassifier. A technique for selecting strategies based on sequence analysis is\nadopted.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.2642v1"
    },
    {
        "title": "Hierarchical organization versus self-organization",
        "authors": [
            "Evo Busseniers"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In this paper we try to define the difference between hierarchical\norganization and self-organization. Organization is defined as a structure with\na function. So we can define the difference between hierarchical organization\nand self-organization both on the structure as on the function. In the next two\nchapters these two definitions are given. For the structure we will use some\nexisting definitions in graph theory, for the function we will use existing\ntheory on (self-)organization. In the third chapter we will look how these two\ndefinitions agree. Finally we give a conclusion.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.1670v1"
    },
    {
        "title": "Frequency-Based Patrolling with Heterogeneous Agents and Limited\n  Communication",
        "authors": [
            "Tao Mao",
            "Laura Ray"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper investigates multi-agent frequencybased patrolling of\nintersecting, circle graphs under conditions where graph nodes have non-uniform\nvisitation requirements and agents have limited ability to communicate. The\ntask is modeled as a partially observable Markov decision process, and a\nreinforcement learning solution is developed. Each agent generates its own\npolicy from Markov chains, and policies are exchanged only when agents occupy\nthe same or adjacent nodes. This constraint on policy exchange models sparse\ncommunication conditions over large, unstructured environments. Empirical\nresults provide perspectives on convergence properties, agent cooperation, and\ngeneralization of learned patrolling policies to new instances of the task. The\nemergent behavior indicates learned coordination strategies between\nheterogeneous agents for patrolling large, unstructured regions as well as the\nability to generalize to dynamic variation in node visitation requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.1757v1"
    },
    {
        "title": "Simulating Congestion Dynamics of Train Rapid Transit using Smart Card\n  Data",
        "authors": [
            "Nasri Bin Othman",
            "Erika Fille Legara",
            "Vicknesh Selvam",
            "Christopher Monterola"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Investigating congestion in train rapid transit systems (RTS) in today's\nurban cities is a challenge compounded by limited data availability and\ndifficulties in model validation. Here, we integrate information from travel\nsmart card data, a mathematical model of route choice, and a full-scale\nagent-based model of the Singapore RTS to provide a more comprehensive\nunderstanding of the congestion dynamics than can be obtained through\nanalytical modelling alone. Our model is empirically validated, and allows for\nclose inspection of the dynamics including station crowdedness, average travel\nduration, and frequency of missed trains---all highly pertinent factors in\nservice quality. Using current data, the crowdedness in all 121 stations\nappears to be distributed log-normally. In our preliminary scenarios, we\ninvestigate the effect of population growth on service quality. We find that\nthe current population (2 million) lies below a critical point; and increasing\nit beyond a factor of $\\sim10\\%$ leads to an exponential deterioration in\nservice quality. We also predict that incentivizing commuters to avoid the most\ncongested hours can bring modest improvements to the service quality provided\nthe population remains under the critical point. Finally, our model can be used\nto generate simulated data for analytical modelling when such data are not\nempirically available, as is often the case.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3892v1"
    },
    {
        "title": "Software Agents Interaction Algorithms in Virtual Learning Environment",
        "authors": [
            "Zahi A. M. Abu Sarhan"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper highlights the multi-agent learning virtual environment and agents\ncommunication algorithms. The researcher proposed three algorithms required\nsoftware agents interaction in virtual learning information system environment.\nThe first proposed algorithm is agents interaction localization algorithm, the\nsecond one is the dynamic agents distribution algorithm (load distribution\nalgorithm), and the third model is Agent communication algorithm based on using\nagents intermediaries. The main objectives of these algorithms are to reduce\nthe response time for any agents changes in virtual learning environment (VLE)\nby increasing the information exchange intensity between software agents and\nreduce the overall network load, and to improve the communication between\nmobile agents in distributed information system to support effectiveness.\nFinally the paper describe the algorithms of information exchange between\nmobile agents in VLE based on the expansion of the address structure and the\nuse of an agent, intermediary agents, matchmaking agents, brokers and their\nentrepreneurial functions\n",
        "pdf_link": "http://arxiv.org/pdf/1403.5734v2"
    },
    {
        "title": "Experimental Study of Phase Transition in Pedestrian Flow",
        "authors": [
            "Marek Bukáček",
            "Pavel Hrabák",
            "Milan Krbálek"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The transition between low and high density phases is a typical feature of\nsystems with social interactions. This contribution focuses on simple\nevacuation design of one room with one entrance and one exit; four\npassing-through experiments were organized and evaluated by means of automatic\nimage processing. The phase of the system, determined by travel time and\noccupancy, is evaluated with respect to the inflow, a controlled boundary\ncondition. Critical values of inflow and outflow were described with respect to\nthe transition from low density to congested state. Moreover, microscopic\nanalysis of travel time is provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.6108v1"
    },
    {
        "title": "Definition and properties to assess multi-agent environments as social\n  intelligence tests",
        "authors": [
            "Javier Insa-Cabrera",
            "José Hernández-Orallo"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Social intelligence in natural and artificial systems is usually measured by\nthe evaluation of associated traits or tasks that are deemed to represent some\nfacets of social behaviour. The amalgamation of these traits is then used to\nconfigure the intuitive notion of social intelligence. Instead, in this paper\nwe start from a parametrised definition of social intelligence as the expected\nperformance in a set of environments with several agents, and we assess and\nderive tests from it. This definition makes several dependencies explicit: (1)\nthe definition depends on the choice (and weight) of environments and agents,\n(2) the definition may include both competitive and cooperative behaviours\ndepending on how agents and rewards are arranged into teams, (3) the definition\nmostly depends on the abilities of other agents, and (4) the actual difference\nbetween social intelligence and general intelligence (or other abilities)\ndepends on these choices. As a result, we address the problem of converting\nthis definition into a more precise one where some fundamental properties\nensuring social behaviour (such as action and reward dependency and\nanticipation on competitive/cooperative behaviours) are met as well as some\nother more instrumental properties (such as secernment, boundedness, symmetry,\nvalidity, reliability, efficiency), which are convenient to convert the\ndefinition into a practical test. From the definition and the formalised\nproperties, we take a look at several representative multi-agent environments,\ntests and games to see whether they meet these properties.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.6350v1"
    },
    {
        "title": "Visualizing the Invisible Hand of Markets: Simulating complex dynamic\n  economic interactions",
        "authors": [
            "Klaus Jaffe"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In complex systems, many different parts interact in non-obvious ways.\nTraditional research focuses on a few or a single aspect of the problem so as\nto analyze it with the tools available. To get a better insight of phenomena\nthat emerge from complex interactions, we need instruments that can analyze\nsimultaneously complex interactions between many parts. Here, a simulator\nmodeling different types of economies, is used to visualize complex\nquantitative aspects that affect economic dynamics. The main conclusions are:\n1- Relatively simple economic settings produce complex non-linear dynamics and\ntherefore linear regressions are often unsuitable to capture complex economic\ndynamics; 2- Flexible pricing of goods by individual agents according to their\nmicro-environment increases the health and wealth of the society, but\nasymmetries in price sensitivity between buyers and sellers increase price\ninflation; 3- Prices for goods conferring risky long term benefits are not\ntracked efficiently by simple market forces. 4- Division of labor creates\nsynergies that improve enormously the health and wealth of the society by\nincreasing the efficiency of economic activity. 5- Stochastic modeling improves\nour understanding of real economies, and didactic games based on them might\nhelp policy makers and non specialists in grasping the complex dynamics\nunderlying even simple economic settings.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.6924v2"
    },
    {
        "title": "Safe Sequential Path Planning of Multi-Vehicle Systems via\n  Double-Obstacle Hamilton-Jacobi-Isaacs Variational Inequality",
        "authors": [
            "Mo Chen",
            "Jaime F. Fisac",
            "Shankar Sastry",
            "Claire J. Tomlin"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We consider the problem of planning trajectories for a group of $N$ vehicles,\neach aiming to reach its own target set while avoiding danger zones of other\nvehicles. The analysis of problems like this is extremely important\npractically, especially given the growing interest in utilizing unmanned\naircraft systems for civil purposes. The direct solution of this problem by\nsolving a single-obstacle Hamilton-Jacobi-Isaacs (HJI) variational inequality\n(VI) is numerically intractable due to the exponential scaling of computation\ncomplexity with problem dimensionality. Furthermore, the single-obstacle HJI VI\ncannot directly handle situations in which vehicles do not have a common\nscheduled arrival time. Instead, we perform sequential path planning by\nconsidering vehicles in order of priority, modeling higher-priority vehicles as\ntime-varying obstacles for lower-priority vehicles. To do this, we solve a\ndouble-obstacle HJI VI which allows us to obtain the reach-avoid set, defined\nas the set of states from which a vehicle can reach its target while staying\nwithin a time-varying state constraint set. From the solution of the\ndouble-obstacle HJI VI, we can also extract the latest start time and the\noptimal control for each vehicle. This is a first application of the\ndouble-obstacle HJI VI which can handle systems with time-varying dynamics,\ntarget sets, and state constraint sets, and results in computation complexity\nthat scales linearly, as opposed to exponentially, with the number of vehicles\nin consideration.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.7223v2"
    },
    {
        "title": "Exploiting Near Time Forecasting From Social Network To Decongest\n  Traffic",
        "authors": [
            "Deepika Pathania",
            "Kamalakar Karlapalem"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Preventing traffic congestion by forecasting near time traffic flows is an\nimportant problem as it leads to effective use of transport resources. Social\nnetwork provides information about activities of humans and social events.\nThus, with the help of social network, we can extract which humans will attend\na particular event (in near time) and can estimate flow of traffic based on it.\nThis opens up a wide area of research which poses need to have a framework for\ntraffic management that can capture essential parameters of real-life behaviour\nand provide a way to iterate upon and evaluate new ideas. In this paper, we\npresent building blocks of a framework and a system to simulate a city with its\ntransport system, humans and their social network. We emphasize on relevant\nparameters selected and modular design of the framework. Our framework defines\nmetrics to evaluate congestion avoidance strategies. To show utility of the\nframework, we present experimental studies of few strategies on a public\ntransport system.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.03767v1"
    },
    {
        "title": "Exploring NK Fitness Landscapes Using Imitative Learning",
        "authors": [
            "José F. Fontanari"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  The idea that a group of cooperating agents can solve problems more\nefficiently than when those agents work independently is hardly controversial,\ndespite our obliviousness of the conditions that make cooperation a successful\nproblem solving strategy. Here we investigate the performance of a group of\nagents in locating the global maxima of NK fitness landscapes with varying\ndegrees of ruggedness. Cooperation is taken into account through imitative\nlearning and the broadcasting of messages informing on the fitness of each\nagent. We find a trade-off between the group size and the frequency of\nimitation: for rugged landscapes, too much imitation or too large a group yield\na performance poorer than that of independent agents. By decreasing the\ndiversity of the group, imitative learning may lead to duplication of work and\nhence to a decrease of its effective size. However, when the parameters are set\nto optimal values the cooperative group substantially outperforms the\nindependent agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06419v3"
    },
    {
        "title": "Multi-Agent Distributed Coordination Control: Developments and\n  Directions",
        "authors": [
            "Xiangke Wang",
            "Xun Li",
            "Yirui Cong",
            "Zhiwen Zeng",
            "Zhiqiang Zheng"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  In this paper, the recent developments on distributed coordination control,\nespecially the consensus and formation control, are summarized with the graph\ntheory playing a central role, in order to present a cohesive overview of the\nmulti-agent distributed coordination control, together with brief reviews of\nsome closely related issues including rendezvous/alignment, swarming/flocking\nand containment control.In terms of the consensus problem, the recent results\non consensus for the agents with different dynamics from first-order,\nsecond-order to high-order linear and nonlinear dynamics, under different\ncommunication conditions, such as cases with/without switching communication\ntopology and varying time-delays, are reviewed, in which the algebraic graph\ntheory is very useful in the protocol designs, stability proofs and converging\nanalysis. In terms of the formation control problem, after reviewing the\nresults of the algebraic graph theory employed in the formation control, we\nmainly pay attention to the developments of the rigid and persistent graphs.\nWith the notions of rigidity and persistence, the formation transformation,\nsplitting and reconstruction can be completed, and consequently the range-based\nformation control laws are designed with the least required information in\norder to maintain a formation rigid/persistent. Afterwards, the recent results\non rendezvous/alignment, swarming/flocking and containment control, which are\nvery closely related to consensus and formation control, are briefly\nintroduced, in order to present an integrated view of the graph theory used in\nthe coordination control problem. Finally, towards the practical applications,\nsome directions possibly deserving investigation in coordination control are\nraised as well.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.02595v1"
    },
    {
        "title": "Norm Monitoring under Partial Action Observability",
        "authors": [
            "Natalia Criado",
            "Jose M. Such"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  In the context of using norms for controlling multi-agent systems, a vitally\nimportant question that has not yet been addressed in the literature is the\ndevelopment of mechanisms for monitoring norm compliance under partial action\nobservability. This paper proposes the reconstruction of unobserved actions to\ntackle this problem. In particular, we formalise the problem of reconstructing\nunobserved actions, and propose an information model and algorithms for\nmonitoring norms under partial action observability using two different\nprocesses for reconstructing unobserved actions. Our evaluation shows that\nreconstructing unobserved actions increases significantly the number of norm\nviolations and fulfilments detected.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.03996v2"
    },
    {
        "title": "Work Capacity of Freelance Markets: Fundamental Limits and Decentralized\n  Schemes",
        "authors": [
            "Avhishek Chatterjee",
            "Lav R. Varshney",
            "Sriram Vishwanath"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Crowdsourcing of jobs to online freelance markets is rapidly gaining\npopularity. Most crowdsourcing platforms are uncontrolled and offer freedom to\ncustomers and freelancers to choose each other. This works well for unskilled\njobs (e.g., image classification) with no specific quality requirement since\nfreelancers are functionally identical. For skilled jobs (e.g., software\ndevelopment) with specific quality requirements, however, this does not ensure\nthat the maximum number of job requests is satisfied. In this work we determine\nthe capacity of freelance markets, in terms of maximum satisfied job requests,\nand propose centralized schemes that achieve capacity. To ensure decentralized\noperation and freedom of choice for customers and freelancers, we propose\nsimple schemes compatible with the operation of current crowdsourcing platforms\nthat approximately achieve capacity. Further, for settings where the number of\njob requests exceeds capacity, we propose a scheme that is agnostic of that\ninformation, but is optimal and fair in declining jobs without wait.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.00023v2"
    },
    {
        "title": "Space-Time Diagram Generation for Profiling Multi Agent Systems",
        "authors": [
            "Dinh Doan Van Bien",
            "David Lillis",
            "Rem W. Collier"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Advances in Agent Oriented Software Engineering have focused on the provision\nof frameworks and toolkits to aid in the creation of Multi Agent Systems\n(MASs). However, despite the need to address the inherent complexity of such\nsystems, little progress has been made in the development of tools to allow for\nthe debugging and understanding of their inner workings.\n  This paper introduces a novel performance analysis system, named\nAgentSpotter, which facilitates such analysis. AgentSpotter was developed by\nmapping conventional profiling concepts to the domain of MASs. We outline its\nintegration into the Agent Factory multi agent framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.02674v1"
    },
    {
        "title": "Call Graph Profiling for Multi Agent Systems",
        "authors": [
            "Dinh Doan Van Bien",
            "David Lillis",
            "Rem W. Collier"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  The design, implementation and testing of Multi Agent Systems is typically a\nvery complex task. While a number of specialist agent programming languages and\ntoolkits have been created to aid in the development of such systems, the\nprovision of associated development tools still lags behind those available for\nother programming paradigms. This includes tools such as debuggers and\nprofilers to help analyse system behaviour, performance and efficiency.\nAgentSpotter is a profiling tool designed specifically to operate on the\nconcepts of agent-oriented programming. This paper extends previous work on\nAgentSpotter by discussing its Call Graph View, which presents system\nperformance information, with reference to the communication between the agents\nin the system. This is aimed at aiding developers in examining the effect that\nagent communication has on the processing requirements of the system.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.02677v1"
    },
    {
        "title": "Multi-agent Reinforcement Learning with Sparse Interactions by\n  Negotiation and Knowledge Transfer",
        "authors": [
            "Luowei Zhou",
            "Pei Yang",
            "Chunlin Chen",
            "Yang Gao"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Reinforcement learning has significant applications for multi-agent systems,\nespecially in unknown dynamic environments. However, most multi-agent\nreinforcement learning (MARL) algorithms suffer from such problems as\nexponential computation complexity in the joint state-action space, which makes\nit difficult to scale up to realistic multi-agent problems. In this paper, a\nnovel algorithm named negotiation-based MARL with sparse interactions (NegoSI)\nis presented. In contrast to traditional sparse-interaction based MARL\nalgorithms, NegoSI adopts the equilibrium concept and makes it possible for\nagents to select the non-strict Equilibrium Dominating Strategy Profile\n(non-strict EDSP) or Meta equilibrium for their joint actions. The presented\nNegoSI algorithm consists of four parts: the equilibrium-based framework for\nsparse interactions, the negotiation for the equilibrium set, the minimum\nvariance method for selecting one joint action and the knowledge transfer of\nlocal Q-values. In this integrated algorithm, three techniques, i.e., unshared\nvalue functions, equilibrium solutions and sparse interactions are adopted to\nachieve privacy protection, better coordination and lower computational\ncomplexity, respectively. To evaluate the performance of the presented NegoSI\nalgorithm, two groups of experiments are carried out regarding three criteria:\nsteps of each episode (SEE), rewards of each episode (REE) and average runtime\n(AR). The first group of experiments is conducted using six grid world games\nand shows fast convergence and high scalability of the presented algorithm.\nThen in the second group of experiments NegoSI is applied to an intelligent\nwarehouse problem and simulated results demonstrate the effectiveness of the\npresented NegoSI algorithm compared with other state-of-the-art MARL\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.05328v2"
    },
    {
        "title": "Approximation and Heuristic Algorithms for Probabilistic Physical Search\n  on General Graphs",
        "authors": [
            "Noam Hazon",
            "Mira Gonen",
            "Max Kleb"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  We consider an agent seeking to obtain an item, potentially available at\ndifferent locations in a physical environment. The traveling costs between\nlocations are known in advance, but there is only probabilistic knowledge\nregarding the possible prices of the item at any given location. Given such a\nsetting, the problem is to find a plan that maximizes the probability of\nacquiring the good while minimizing both travel and purchase costs. Sample\napplications include agents in search-and-rescue or exploration missions, e.g.,\na rover on Mars seeking to mine a specific mineral. These probabilistic\nphysical search problems have been previously studied, but we present the first\napproximation and heuristic algorithms for solving such problems on general\ngraphs. We establish an interesting connection between these problems and\nclassical graph-search problems, which led us to provide the approximation\nalgorithms and hardness of approximation results for our settings. We further\nsuggest several heuristics for practical use, and demonstrate their\neffectiveness with simulation on real graph structure and synthetic graphs.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.08088v1"
    },
    {
        "title": "A simple agent-based spatial model of the economy: tools for policy",
        "authors": [
            "Bernardo Alves Furtado",
            "Isaque Daniel Rocha Eberhardt"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This study simulates the evolution of artificial economies in order to\nunderstand the tax relevance of administrative boundaries in the quality of\nlife of its citizens. The modeling involves the construction of a computational\nalgorithm, which includes citizens, bounded into families; firms and\ngovernments; all of them interacting in markets for goods, labor and real\nestate. The real estate market allows families to move to dwellings with higher\nquality or lower price when the families capitalize property values. The goods\nmarket allows consumers to search on a flexible number of firms choosing by\nprice and proximity. The labor market entails a matching process between firms\n(location) and candidates (qualification). The government may be configured\ninto one, four or seven distinct sub-national governments. The role of\ngovernment is to collect taxes on the value added of firms in its territory and\ninvest the taxes into higher levels of quality of life for residents. The model\ndoes not have a credit market. The results suggest that the configuration of\nadministrative boundaries is relevant to the levels of quality of life arising\nfrom the reversal of taxes. The model with seven regions is more dynamic, with\nhigher GDP values, but more unequal and heterogeneous across regions. The\nsimulation with only one region is more homogeneously poor. The study seeks to\ncontribute to a theoretical and methodological framework as well as to\ndescribe, operationalize and test computer models of public finance analysis,\nwith explicitly spatial and dynamic emphasis. Several alternatives of expansion\nof the model for future research are described. Moreover, this study adds to\nthe existing literature in the realm of simple microeconomic computational\nmodels, specifying structural relationships between local governments and\nfirms, consumers and dwellings mediated by distance.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.04967v4"
    },
    {
        "title": "Continuous Time Gathering of Agents with Limited Visibility and\n  Bearing-Only Sensing",
        "authors": [
            "Levi-Itzhak Bellaiche",
            "Alfred Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  A group of mobile agents, identical, anonymous, and oblivious (memoryless),\nhaving the capability to sense only the relative direction (bearing) to\nneighborhing agents within a finite visibility range, are shown to gather to a\nmeeting point in finite time by applying a very simple rule of motion. The\nagents' rule of motion is : set your velocity vector to be the sum of the two\nunit vectors in R^2 pointing to your \"extremal\" neighbours determining the\nsmallest visibility disc sector in which all your visible neighbors reside,\nprovided it spans an angle smaller than pi, otherwise, since you are\n\"surrounded\" by visible neighbors, simply stay put (set your velocity to 0). Of\ncourse, the initial constellation of agents must have a visibility graph that\nis connected, and provided this we prove that the agents gather to a common\nmeeting point in finite time, while the distances between agents that initially\nsee each other monotically decreases. We will also prove a geometrical result,\na tight lower bound on the sum of cosines of the interior angles of a convex\npolygon, that we will use to prove the gathering of our dynamical system.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.09115v1"
    },
    {
        "title": "Reachability-Based Safety and Goal Satisfaction of Unmanned Aerial\n  Platoons on Air Highways",
        "authors": [
            "Mo Chen",
            "Qie Hu",
            "Jaime Fisac",
            "Kene Akametalu",
            "Casey Mackin",
            "Claire Tomlin"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Recently, there has been immense interest in using unmanned aerial vehicles\n(UAVs) for civilian operations. As a result, unmanned aerial systems traffic\nmanagement is needed to ensure the safety and goal satisfaction of potentially\nthousands of UAVs flying simultaneously. Currently, the analysis of large\nmulti-agent systems cannot tractably provide these guarantees if the agents'\nset of maneuvers is unrestricted. In this paper, platoons of UAVs flying on air\nhighways is proposed to impose an airspace structure that allows for tractable\nanalysis. For the air highway placement problem, the fast marching method is\nused to produce a sequence of air highways that minimizes the cost of flying\nfrom an origin to any destination. The placement of air highways can be updated\nin real-time to accommodate sudden airspace changes. Within platoons traveling\non air highways, each vehicle is modeled as a hybrid system. Using\nHamilton-Jacobi reachability, safety and goal satisfaction are guaranteed for\nall mode transitions. For a single altitude range, the proposed approach\nguarantees safety for one safety breach per vehicle, in the unlikely event of\nmultiple safety breaches, safety can be guaranteed over multiple altitude\nranges. We demonstrate the platooning concept through simulations of three\nrepresentative scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.08150v4"
    },
    {
        "title": "Job Selection in a Network of Autonomous UAVs for Delivery of Goods",
        "authors": [
            "Pasquale Grippa",
            "Doris A. Behrens",
            "Christian Bettstetter",
            "Friederike Wall"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This article analyzes two classes of job selection policies that control how\na network of autonomous aerial vehicles delivers goods from depots to\ncustomers. Customer requests (jobs) occur according to a spatio-temporal\nstochastic process not known by the system. If job selection uses a policy in\nwhich the first job (FJ) is served first, the system may collapse to\ninstability by removing just one vehicle. Policies that serve the nearest job\n(NJ) first show such threshold behavior only in some settings and can be\nimplemented in a distributed manner. The timing of job selection has\nsignificant impact on delivery time and stability for NJ while it has no impact\nfor FJ. Based on these findings we introduce a methodological approach for\ndecision-making support to set up and operate such a system, taking into\naccount the trade-off between monetary cost and service quality. In particular,\nwe compute a lower bound for the infrastructure expenditure required to achieve\na certain expected delivery time. The approach includes three time horizons:\nlong-term decisions on the number of depots to deploy in the service area,\nmid-term decisions on the number of vehicles to use, and short-term decisions\non the policy to operate the vehicles.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.04180v2"
    },
    {
        "title": "Tasks for agent-based negotiation teams: Analysis, review, and\n  challenges",
        "authors": [
            "Victor Sanchez-Anguix",
            "Vicente Julian",
            "Vicente Botti",
            "Ana Garcia-Fornes"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  An agent-based negotiation team is a group of interdependent agents that join\ntogether as a single negotiation party due to their shared interests in the\nnegotiation at hand. The reasons to employ an agent-based negotiation team may\nvary: (i) more computation and parallelization capabilities, (ii) unite agents\nwith different expertise and skills whose joint work makes it possible to\ntackle complex negotiation domains, (iii) the necessity to represent different\nstakeholders or different preferences in the same party (e.g., organizations,\ncountries, and married couple). The topic of agent-based negotiation teams has\nbeen recently introduced in multi-agent research. Therefore, it is necessary to\nidentify good practices, challenges, and related research that may help in\nadvancing the state-of-the-art in agent-based negotiation teams. For that\nreason, in this article we review the tasks to be carried out by agent-based\nnegotiation teams. Each task is analyzed and related with current advances in\ndifferent research areas. The analysis aims to identify special challenges that\nmay arise due to the particularities of agent-based negotiation teams.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.04727v1"
    },
    {
        "title": "Studying the impact of negotiation environments on negotiation teams'\n  performance",
        "authors": [
            "Victor Sanchez-Anguix",
            "Vicente Julian",
            "Vicente Botti",
            "Ana Garcia-Fornes"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  In this article we study the impact of the negotiation environment on the\nperformance of several intra-team strategies (team dynamics) for agent-based\nnegotiation teams that negotiate with an opponent. An agent-based negotiation\nteam is a group of agents that joins together as a party because they share\ncommon interests in the negotiation at hand. It is experimentally shown how\nnegotiation environment conditions like the deadline of both parties, the\nconcession speed of the opponent, similarity among team members, and team size\naffect performance metrics like the minimum utility of team members, the\naverage utility of team members, and the number of negotiation rounds. Our goal\nis identifying which intra-team strategies work better in different\nenvironmental conditions in order to provide useful knowledge for team members\nto select appropriate intra-team strategies according to environmental\nconditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.04737v1"
    },
    {
        "title": "Multi-Agent Modeling of Dynamical Systems: A Self-organized, Emergent,\n  Homeostatic and Autopoietic Approach",
        "authors": [
            "Nelson Fernandez"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This thesis presents the theoretical, conceptual and methodological aspects\nthat support the modeling of dynamical systems (DS) by using several agents.\nThe modeling approach permits the assessment of properties representing order,\nchange, equilibrium, adaptability, and autonomy, in DS. The modeling processes\nwere supported by a conceptual corpus regarding systems dynamics, multi-agent\nsystems, graph theory, and, particularly, the information theory. Besides to\nthe specification of the dynamical systems as a computational network of\nagents, metrics that allow characterizing and assessing the inherent complexity\nof such systems were defined. As a result, properties associated with\nemergence, self-organization, complexity, homeostasis and autopoiesis were\ndefined, formalized and measured. The validation of the underlying DS model was\ncarried out on discrete systems (boolean networks and cellular automata) and\necological systems. The central contribution of this thesis was the development\nof a methodological approach for DS modeling. This approach includes a larger\nset of properties than in traditional studies, what allows us to deepen in\nquestioning essential issues associated with the DS field. All this was\nachieved from a simple base of calculation and interpretation, which does not\nrequire advanced mathematical knowledge, and facilitates their application in\ndifferent fields of science.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.00799v1"
    },
    {
        "title": "Modelling movement for collective adaptive systems with CARMA",
        "authors": [
            "Natalia Zoń",
            "Vashti Galpin",
            "Stephen Gilmore"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Space and movement through space play an important role in many collective\nadaptive systems (CAS). CAS consist of multiple components interacting to\nachieve some goal in a system or environment that can change over time. When\nthese components operate in space, then their behaviour can be affected by\nwhere they are located in that space. Examples include the possibility of\ncommunication between two components located at different points, and rates of\nmovement of a component that may be affected by location. The CARMA language\nand its associated software tools can be used to model such systems. In\nparticular, a graphical editor for CARMA allows for the specification of\nspatial structure and generation of templates that can be used in a CARMA model\nwith space. We demonstrate the use of this tool to experiment with a model of\npedestrian movement over a network of paths.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.02963v1"
    },
    {
        "title": "Modelling resource contention in multi-robot task allocation problems\n  with uncertain timing",
        "authors": [
            "Andrew W. Palmer",
            "Andrew J. Hill",
            "Steven J. Scheding"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This paper proposes an analytical framework for modelling resource contention\nin multi-robot systems, where the travel times and task durations are\nuncertain. It uses several approximation methods to quickly and accurately\ncalculate the probability distributions describing the times at which the tasks\nstart and finish. Specific contributions include exact and fast approximation\nmethods for calculating the probability of a set of independent normally\ndistributed random events occurring in a given order, a method for calculating\nthe most likely and n-th most likely orders of occurrence for a set of\nindependent normally distributed random events that have equal standard\ndeviations, and a method for approximating the conditional probability\ndistributions of the events given a specific order of the events. The complete\nframework is shown to be faster than a Monte Carlo approach for the same\naccuracy in two multi-robot task allocation problems. In addition, the\nimportance of incorporating uncertainty is demonstrated through a comparison\nwith a deterministic method. This is a general framework that is agnostic to\nthe optimisation method and objective function used, and is applicable to a\nwide range of problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.04358v3"
    },
    {
        "title": "Exploiting Vagueness for Multi-Agent Consensus",
        "authors": [
            "Michael Crosscombe",
            "Jonathan Lawry"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  A framework for consensus modelling is introduced using Kleene's three valued\nlogic as a means to express vagueness in agents' beliefs. Explicitly borderline\ncases are inherent to propositions involving vague concepts where sentences of\na propositional language may be absolutely true, absolutely false or\nborderline. By exploiting these intermediate truth values, we can allow agents\nto adopt a more vague interpretation of underlying concepts in order to weaken\ntheir beliefs and reduce the levels of inconsistency, so as to achieve\nconsensus. We consider a consensus combination operation which results in\nagents adopting the borderline truth value as a shared viewpoint if they are in\ndirect conflict. Simulation experiments are presented which show that applying\nthis operator to agents chosen at random (subject to a consistency threshold)\nfrom a population, with initially diverse opinions, results in convergence to a\nsmaller set of more precise shared beliefs. Furthermore, if the choice of\nagents for combination is dependent on the payoff of their beliefs, this acting\nas a proxy for performance or usefulness, then the system converges to beliefs\nwhich, on average, have higher payoff.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.05540v2"
    },
    {
        "title": "SEAL's operating manual: a Spatially-bounded Economic Agent-based Lab",
        "authors": [
            "Bernardo Alves Furtado",
            "Isaque Daniel Rocha Eberhardt",
            "Alexandre Messa"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This text reports in detail how SEAL, a modeling framework for the economy\nbased on individual agents and firms, works. Thus, it aims to be an usage\nmanual for those wishing to use SEAL or SEAL's results. As a reference work,\ntheoretical and research studies are only cited. SEAL is thought as a Lab that\nenables the simulation of the economy with spatially bounded\nmicroeconomic-based computational agents. Part of the novelty of SEAL comes\nfrom the possibility of simulating the economy in space and the instantiation\nof different public offices, i.e. government institutions, with embedded\nmarkets and actual data. SEAL is designed for Public Policy analysis,\nspecifically those related to Public Finance, Taxes and Real Estate.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.03996v1"
    },
    {
        "title": "Location Aggregation of Spatial Population CTMC Models",
        "authors": [
            "Luca Bortolussi",
            "Cheng Feng"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  In this paper we focus on spatial Markov population models, describing the\nstochastic evolution of populations of agents, explicitly modelling their\nspatial distribution, representing space as a discrete, finite graph. More\nspecifically, we present a heuristic approach to aggregating spatial locations,\nwhich is designed to preserve the dynamical behaviour of the model whilst\nreducing the computational cost of analysis. Our approach combines stochastic\napproximation ideas (moment closure, linear noise), with computational\nstatistics (spectral clustering) to obtain an efficient aggregation, which is\nexperimentally shown to be reasonably accurate on two case studies: an instance\nof epidemic spreading and a London bike sharing scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.08168v1"
    },
    {
        "title": "Social Groups and Pedestrian Crowds: Experiment on Dyads in a Counter\n  Flow Scenario",
        "authors": [
            "Andrea Gorrini",
            "Luca Crociani",
            "Claudio Feliciani",
            "Pengfei Zhao",
            "Katsuhiro Nishinari",
            "Stefania Bandini"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  The calibration and validation of pedestrian simulations require the\nacquisition of empirical evidences of human behaviour. The current work\npresents the results of an experiment focused on the potentially combined\neffect of counter flow and grouping on pedestrian dynamics. In particular, we\nfocused on: (i) four different configurations of flow ratio (the rate between\nthe minor flow and the total flow in bidirectional scenarios); (ii) dyads, as\nthe most frequently observed and basic social groups of crowds. Results showed\nthat the increase of flow ratio negatively impacted the speed of pedestrians.\nDyads walked significantly slower than singletons, due to the difficulty in\nmovement coordination among group members (proxemics) in case of counter flow.\nThe collected results represent an useful contribution towards the validation\nof pedestrian simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.08325v1"
    },
    {
        "title": "Humans of Simulated New York (HOSNY): an exploratory comprehensive model\n  of city life",
        "authors": [
            "Francis Tseng",
            "Fei Liu",
            "Bernardo Alves Furtado"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The model presented in this paper experiments with a comprehensive simulant\nagent in order to provide an exploratory platform in which simulation modelers\nmay try alternative scenarios and participation in policy decision-making. The\nframework is built in a computationally distributed online format in which\nusers can join in and visually explore the results. Modeled activity involves\ndaily routine errands, such as shopping, visiting the doctor or engaging in the\nlabor market. Further, agents make everyday decisions based on individual\nbehavioral attributes and minimal requirements, according to social and\ncontagion networks. Fully developed firms and governments are also included in\nthe model allowing for taxes collection, production decisions, bankruptcy and\nchange in ownership. The contributions to the literature are multifold. They\ninclude (a) a comprehensive model with detailing of the agents and firms'\nactivities and processes and original use of simultaneously (b) reinforcement\nlearning for firm pricing and demand allocation; (c) social contagion for\ndisease spreading and social network for hiring opportunities; and (d) Bayesian\nnetworks for demographic-like generation of agents. All of that within a (e)\nvisually rich environment and multiple use of databases. Hence, the model\nprovides a comprehensive framework from where interactions among citizens,\nfirms and governments can be easily explored allowing for learning and\nvisualization of policies and scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.05240v2"
    },
    {
        "title": "Semantic-level Decentralized Multi-Robot Decision-Making using\n  Probabilistic Macro-Observations",
        "authors": [
            "Shayegan Omidshafiei",
            "Shih-Yuan Liu",
            "Michael Everett",
            "Brett T. Lopez",
            "Christopher Amato",
            "Miao Liu",
            "Jonathan P. How",
            "John Vian"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Robust environment perception is essential for decision-making on robots\noperating in complex domains. Intelligent task execution requires principled\ntreatment of uncertainty sources in a robot's observation model. This is\nimportant not only for low-level observations (e.g., accelerometer data), but\nalso for high-level observations such as semantic object labels. This paper\nformalizes the concept of macro-observations in Decentralized Partially\nObservable Semi-Markov Decision Processes (Dec-POSMDPs), allowing scalable\nsemantic-level multi-robot decision making. A hierarchical Bayesian approach is\nused to model noise statistics of low-level classifier outputs, while\nsimultaneously allowing sharing of domain noise characteristics between\nclasses. Classification accuracy of the proposed macro-observation scheme,\ncalled Hierarchical Bayesian Noise Inference (HBNI), is shown to exceed\nexisting methods. The macro-observation scheme is then integrated into a\nDec-POSMDP planner, with hardware experiments running onboard a team of dynamic\nquadrotors in a challenging domain where noise-agnostic filtering fails. To the\nbest of our knowledge, this is the first demonstration of a real-time,\nconvolutional neural net-based classification framework running fully onboard a\nteam of quadrotors in a multi-robot decision-making domain.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.05623v1"
    },
    {
        "title": "Scalable Accelerated Decentralized Multi-Robot Policy Search in\n  Continuous Observation Spaces",
        "authors": [
            "Shayegan Omidshafiei",
            "Christopher Amato",
            "Miao Liu",
            "Michael Everett",
            "Jonathan P. How",
            "John Vian"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper presents the first ever approach for solving\n\\emph{continuous-observation} Decentralized Partially Observable Markov\nDecision Processes (Dec-POMDPs) and their semi-Markovian counterparts,\nDec-POSMDPs. This contribution is especially important in robotics, where a\nvast number of sensors provide continuous observation data. A\ncontinuous-observation policy representation is introduced using Stochastic\nKernel-based Finite State Automata (SK-FSAs). An SK-FSA search algorithm titled\nEntropy-based Policy Search using Continuous Kernel Observations (EPSCKO) is\nintroduced and applied to the first ever continuous-observation\nDec-POMDP/Dec-POSMDP domain, where it significantly outperforms\nstate-of-the-art discrete approaches. This methodology is equally applicable to\nDec-POMDPs and Dec-POSMDPs, though the empirical analysis presented focuses on\nDec-POSMDPs due to their higher scalability. To improve convergence, an entropy\ninjection policy search acceleration approach for both continuous and discrete\nobservation cases is also developed and shown to improve convergence rates\nwithout degrading policy quality.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.05626v1"
    },
    {
        "title": "A Coalition Formation Algorithm for Multi-Robot Task Allocation in\n  Large-Scale Natural Disasters",
        "authors": [
            "Carla Mouradian",
            "Jagruti Sahoo",
            "Roch H. Glitho",
            "Monique J. Morrow",
            "Paul A. Polakos"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In large-scale natural disasters, humans are likely to fail when they attempt\nto reach high-risk sites or act in search and rescue operations. Robots,\nhowever, outdo their counterparts in surviving the hazards and handling the\nsearch and rescue missions due to their multiple and diverse sensing and\nactuation capabilities. The dynamic formation of optimal coalition of these\nheterogeneous robots for cost efficiency is very challenging and research in\nthe area is gaining more and more attention. In this paper, we propose a novel\nheuristic. Since the population of robots in large-scale disaster settings is\nvery large, we rely on Quantum Multi-Objective Particle Swarm Optimization\n(QMOPSO). The problem is modeled as a multi-objective optimization problem.\nSimulations with different test cases and metrics, and comparison with other\nalgorithms such as NSGA-II and SPEA-II are carried out. The experimental\nresults show that the proposed algorithm outperforms the existing algorithms\nnot only in terms of convergence but also in terms of diversity and processing\ntime.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.05905v1"
    },
    {
        "title": "Solving Distributed Constraint Optimization Problems Using Logic\n  Programming",
        "authors": [
            "Tiep Le",
            "Tran Cao Son",
            "Enrico Pontelli",
            "William Yeoh"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper explores the use of Answer Set Programming (ASP) in solving\nDistributed Constraint Optimization Problems (DCOPs). The paper provides the\nfollowing novel contributions: (1) It shows how one can formulate DCOPs as\nlogic programs; (2) It introduces ASP-DPOP, the first DCOP algorithm that is\nbased on logic programming; (3) It experimentally shows that ASP-DPOP can be up\nto two orders of magnitude faster than DPOP (its imperative programming\ncounterpart) as well as solve some problems that DPOP fails to solve, due to\nmemory limitations; and (4) It demonstrates the applicability of ASP in a wide\narray of multi-agent problems currently modeled as DCOPs. Under consideration\nin Theory and Practice of Logic Programming (TPLP).\n",
        "pdf_link": "http://arxiv.org/pdf/1705.03916v1"
    },
    {
        "title": "Reinforcement Mechanism Design for e-commerce",
        "authors": [
            "Qingpeng Cai",
            "Aris Filos-Ratsikas",
            "Pingzhong Tang",
            "Yiwei Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We study the problem of allocating impressions to sellers in e-commerce\nwebsites, such as Amazon, eBay or Taobao, aiming to maximize the total revenue\ngenerated by the platform. We employ a general framework of reinforcement\nmechanism design, which uses deep reinforcement learning to design efficient\nalgorithms, taking the strategic behaviour of the sellers into account.\nSpecifically, we model the impression allocation problem as a Markov decision\nprocess, where the states encode the history of impressions, prices,\ntransactions and generated revenue and the actions are the possible impression\nallocations in each round. To tackle the problem of continuity and\nhigh-dimensionality of states and actions, we adopt the ideas of the DDPG\nalgorithm to design an actor-critic policy gradient algorithm which takes\nadvantage of the problem domain in order to achieve convergence and stability.\nWe evaluate our proposed algorithm, coined IA(GRU), by comparing it against\nDDPG, as well as several natural heuristics, under different rationality models\nfor the sellers - we assume that sellers follow well-known no-regret type\nstrategies which may vary in their degree of sophistication. We find that\nIA(GRU) outperforms all algorithms in terms of the total revenue.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.07607v3"
    },
    {
        "title": "Maintaining Ad-Hoc Communication Network in Area Protection Scenarios\n  with Adversarial Agents",
        "authors": [
            "Marika Ivanová",
            "Pavel Surynek",
            "Diep Thi Ngoc Nguyen"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We address a problem of area protection in graph-based scenarios with\nmultiple mobile agents where connectivity is maintained among agents to ensure\nthey can communicate. The problem consists of two adversarial teams of agents\nthat move in an undirected graph shared by both teams. Agents are placed in\nvertices of the graph; at most one agent can occupy a vertex; and they can move\ninto adjacent vertices in a conflict free way. Teams have asymmetric goals: the\naim of one team - attackers - is to invade into given area while the aim of the\nopponent team - defenders - is to protect the area from being entered by\nattackers by occupying selected vertices. The team of defenders need to\nmaintain connectivity of vertices occupied by its own agents in a visibility\ngraph. The visibility graph models possibility of communication between pairs\nof vertices.\n  We study strategies for allocating vertices to be occupied by the team of\ndefenders to block attacking agents where connectivity is maintained at the\nsame time. To do this we reserve a subset of defending agents that do not try\nto block the attackers but instead are placed to support connectivity of the\nteam. The performance of strategies is tested in multiple benchmarks. The\nsuccess of a strategy is heavily dependent on the type of the instance, and so\none of the contributions of this work is that we identify suitable strategies\nfor diverse instance types.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.01070v1"
    },
    {
        "title": "Cellular Automaton Based Simulation of Large Pedestrian Facilities - A\n  Case Study on the Staten Island Ferry Terminals",
        "authors": [
            "Luca Crociani",
            "Gregor Lämmel",
            "H. Joon Park",
            "Giuseppe Vizzari"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Current metropolises largely depend on a functioning transport infrastructure\nand the increasing demand can only be satisfied by a well organized mass\ntransit. One example for a crucial mass transit system is New York City's\nStaten Island Ferry, connecting the two boroughs of Staten Island and Manhattan\nwith a regular passenger service. Today's demand already exceeds 2500\npassengers for a single cycle during peek hours, and future projections suggest\nthat it will further increase. One way to appraise how the system will cope\nwith future demand is by simulation. This contribution proposes an integrated\nsimulation approach to evaluate the system performance with respect to future\ndemand. The simulation relies on a multiscale modeling approach where the\nterminal buildings are simulated by a microscopic and quantitatively valid\ncellular automata (CA) and the journeys of the ferries themselves are modeled\nby a mesoscopic queue simulation approach. Based on the simulation results\nrecommendations with respect to the future demand are given.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.03297v1"
    },
    {
        "title": "An Agent-based Modelling Framework for Driving Policy Learning in\n  Connected and Autonomous Vehicles",
        "authors": [
            "Varuna De Silva",
            "Xiongzhao Wang",
            "Deniz Aladagli",
            "Ahmet Kondoz",
            "Erhan Ekmekcioglu"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Due to the complexity of the natural world, a programmer cannot foresee all\npossible situations, a connected and autonomous vehicle (CAV) will face during\nits operation, and hence, CAVs will need to learn to make decisions\nautonomously. Due to the sensing of its surroundings and information exchanged\nwith other vehicles and road infrastructure, a CAV will have access to large\namounts of useful data. While different control algorithms have been proposed\nfor CAVs, the benefits brought about by connectedness of autonomous vehicles to\nother vehicles and to the infrastructure, and its implications on policy\nlearning has not been investigated in literature. This paper investigates a\ndata driven driving policy learning framework through an agent-based modelling\napproaches. The contributions of the paper are two-fold. A dynamic programming\nframework is proposed for in-vehicle policy learning with and without\nconnectivity to neighboring vehicles. The simulation results indicate that\nwhile a CAV can learn to make autonomous decisions, vehicle-to-vehicle (V2V)\ncommunication of information improves this capability. Furthermore, to overcome\nthe limitations of sensing in a CAV, the paper proposes a novel concept for\ninfrastructure-led policy learning and communication with autonomous vehicles.\nIn infrastructure-led policy learning, road-side infrastructure senses and\ncaptures successful vehicle maneuvers and learns an optimal policy from those\ntemporal sequences, and when a vehicle approaches the road-side unit, the\npolicy is communicated to the CAV. Deep-imitation learning methodology is\nproposed to develop such an infrastructure-led policy learning framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.04622v4"
    },
    {
        "title": "Open Multi-Agent Systems: Gossiping with Random Arrivals and Departures",
        "authors": [
            "Julien M. Hendrickx",
            "Samuel Martin"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We consider open multi-agent systems. Unlike the systems usually studied in\nthe literature, here agents may join or leave while the process studied takes\nplace. The system composition and size evolve thus with time. We focus here on\nsystems where the interactions between agents lead to pairwise gossip averages,\nand where agents either arrive or are replaced at random times. These events\nprevent any convergence of the system. Instead, we describe the expected system\nbehavior by showing that the evolution of scaled moments of the state can be\ncharacterized by a 2-dimensional (possibly time-varying) linear dynamical\nsystem. We apply this technique to two cases : (i) systems with fixed size\nwhere leaving agents are immediately replaced, and (ii) systems where new\nagents keep arriving without ever leaving, and whose size grows thus unbounded.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.05142v1"
    },
    {
        "title": "MAX-consensus in open multi-agent systems with gossip interactions",
        "authors": [
            "Mahmoud Abdelrahim",
            "Julien M. Hendrickx",
            "W. P. M. H. Heemels"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We study the problem of distributed maximum computation in an open\nmulti-agent system, where agents can leave and arrive during the execution of\nthe algorithm. The main challenge comes from the possibility that the agent\nholding the largest value leaves the system, which changes the value to be\ncomputed. The algorithms must as a result be endowed with mechanisms allowing\nto forget outdated information. The focus is on systems in which interactions\nare pairwise gossips between randomly selected agents. We consider situations\nwhere leaving agents can send a last message, and situations where they cannot.\nFor both cases, we provide algorithms able to eventually compute the maximum of\nthe values held by agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.05793v1"
    },
    {
        "title": "SEAR: A Polynomial-Time Multi-Robot Path Planning Algorithm with\n  Expected Constant-Factor Optimality Guarantee",
        "authors": [
            "Shuai D. Han",
            "Edgar J. Rodriguez",
            "Jingjin Yu"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We study the labeled multi-robot path planning problem in continuous 2D and\n3D domains in the absence of obstacles where robots must not collide with each\nother. For an arbitrary number of robots in arbitrary initial and goal\narrangements, we derive a polynomial time, complete algorithm that produces\nsolutions with constant-factor optimality guarantees on both makespan and\ndistance optimality, in expectation, under the assumption that the robot labels\nare uniformly randomly distributed. Our algorithm only requires a small\nconstant factor expansion of the initial and goal configuration footprints for\nsolving the problem, i.e., the problem can be solved in a fairly small bounded\nregion. Beside theoretical guarantees, we present a thorough computational\nevaluation of the proposed solution. In addition to the baseline\nimplementation, adapting an effective (but non-polynomial time) routing\nsubroutine, we also provide a highly efficient implementation that quickly\ncomputes near-optimal solutions. Hardware experiments on the microMVP platform\ncomposed of non-holonomic robots confirms the practical applicability of our\nalgorithmic pipeline.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.08215v2"
    },
    {
        "title": "Key Management and Learning based Two Level Data Security for Metering\n  Infrastructure of Smart Grid",
        "authors": [
            "Imtiaz Parvez",
            "Maryamossadat Aghili",
            "Arif Sarwat"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In the smart grid, smart meters, and numerous control and monitoring\napplications employ bidirectional wireless communication, where security is a\ncritical issue. In key management based encryption method for the smart grid,\nthe Trusted Third Party (TTP), and links between the smart meter and the third\nparty are assumed to be fully trusted and reliable. However, in wired/wireless\nmedium, a man-in-middle may want to interfere, monitor and control the network,\nthus exposing its vulnerability. Acknowledging this, in this paper, we propose\na novel two level encryption method based on two partially trusted simple\nservers (constitutes the TTP) which implement this method without increasing\npacket overhead. One server is responsible for data encryption between the\nmeter and control center/central database, and the other server manages the\nrandom sequence of data transmission. Numerical calculation shows that the\nnumber of iterations required to decode a message is large which is quite\nimpractical. Furthermore, we introduce One-class support vector machine\n(machine learning) algorithm for node-to-node authentication utilizing the\nlocation information and the data transmission history (node identity, packet\nsize and frequency of transmission). This secures data communication privacy\nwithout increasing the complexity of the conventional key management scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.08505v1"
    },
    {
        "title": "Traffic Optimization For a Mixture of Self-interested and Compliant\n  Agents",
        "authors": [
            "Guni Sharon",
            "Michael Albert",
            "Tarun Rambha",
            "Stephen Boyles",
            "Peter Stone"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper focuses on two commonly used path assignment policies for agents\ntraversing a congested network: self-interested routing, and system-optimum\nrouting. In the self-interested routing policy each agent selects a path that\noptimizes its own utility, while the system-optimum routing agents are assigned\npaths with the goal of maximizing system performance. This paper considers a\nscenario where a centralized network manager wishes to optimize utilities over\nall agents, i.e., implement a system-optimum routing policy. In many real-life\nscenarios, however, the system manager is unable to influence the route\nassignment of all agents due to limited influence on route choice decisions.\nMotivated by such scenarios, a computationally tractable method is presented\nthat computes the minimal amount of agents that the system manager needs to\ninfluence (compliant agents) in order to achieve system optimal performance.\nMoreover, this methodology can also determine whether a given set of compliant\nagents is sufficient to achieve system optimum and compute the optimal route\nassignment for the compliant agents to do so. Experimental results are\npresented showing that in several large-scale, realistic traffic networks\noptimal flow can be achieved with as low as 13% of the agent being compliant\nand up to 54%.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.09569v1"
    },
    {
        "title": "Crossing Behaviour of Social Groups: Insights from Observations at\n  Non-signalized Intersection",
        "authors": [
            "Andrea Gorrini",
            "Luca Crociani",
            "Giuseppe Vizzari",
            "Stefania Bandini"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Environmental, demographical and psychological factors have a demonstrated\nimpact on risky crossing behaviour. In this work we focus on the potential\ninfluence of social factors on the considered phenomenon (i.e. group crossing\ndecision). We present the results of a video-recorded observation about the\ncrossing behaviour of singles and dyads at non-signalized intersections.\nResults showed that crossing behaviour is characterized by three distinct\nphases: (i) approaching, (ii) appraising (decision making) and (iii) crossing.\nDyads walk slower than single pedestrians in all phases. The crossing behaviour\nof dyads is characterized by the emergence of a leader who takes the decision\nto cross first, followed by the companion. However, there is no difference\nbetween the accepted safety gap of singles and dyads. Understanding factors\ninfluencing the crossing decision of social groups represents an important\nresult supporting the development of agent-based simulations of\npedestrian-vehicle interactions.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.00728v1"
    },
    {
        "title": "Multiagent Simple Temporal Problem: The Arc-Consistency Approach",
        "authors": [
            "Shufeng Kong",
            "Jae Hee Lee",
            "Sanjiang Li"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The Simple Temporal Problem (STP) is a fundamental temporal reasoning problem\nand has recently been extended to the Multiagent Simple Temporal Problem\n(MaSTP). In this paper we present a novel approach that is based on enforcing\narc-consistency (AC) on the input (multiagent) simple temporal network. We show\nthat the AC-based approach is sufficient for solving both the STP and MaSTP and\nprovide efficient algorithms for them. As our AC-based approach does not impose\nnew constraints between agents, it does not violate the privacy of the agents\nand is superior to the state-of-the-art approach to MaSTP. Empirical\nevaluations on diverse benchmark datasets also show that our AC-based\nalgorithms for STP and MaSTP are significantly more efficient than existing\napproaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.08151v1"
    },
    {
        "title": "Micro and Macro Pedestrian Dynamics in Counterflow: the Impact of Social\n  Groups",
        "authors": [
            "Luca Crociani",
            "Andrea Gorrini",
            "Claudio Feliciani",
            "Giuseppe Vizzari",
            "Katsuhiro Nishinari",
            "Stefania Bandini"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Although it is widely recognised that the presence of groups influences\nmicroscopic and aggregated pedestrian dynamics, a precise characterisation of\nthe phenomenon still calls for evidences and insights. The present paper\ndescribes micro and macro level original analyses on data characterising\npedestrian behaviour in presence of counter-flows and grouping, in particular\ndyads, acquired through controlled experiments. Results suggest that the\npresence of dyads and their tendency to walk in a line-abreast formation\ninfluences the formation of lanes and, in turn, aggregated observables, such as\noverall specific flow.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.08225v1"
    },
    {
        "title": "Systems, Actors and Agents: Operation in a multicomponent environment",
        "authors": [
            "Mark Burgin"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Multi-agent approach has become popular in computer science and technology.\nHowever, the conventional models of multi-agent and multicomponent systems\nimplicitly or explicitly assume existence of absolute time or even do not\ninclude time in the set of defining parameters. At the same time, it is proved\ntheoretically and validated experimentally that there are different times and\ntime scales in a variety of real systems - physical, chemical, biological,\nsocial, informational, etc. Thus, the goal of this work is construction of a\nmulti-agent multicomponent system models with concurrency of processes and\ndiversity of actions. To achieve this goal, a mathematical system actor model\nis elaborated and its properties are studied.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.08319v1"
    },
    {
        "title": "Controlling Elections through Social Influence",
        "authors": [
            "Bryan Wilder",
            "Yevgeniy Vorobeychik"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.08615v1"
    },
    {
        "title": "Happiness Pursuit: Personality Learning in a Society of Agents",
        "authors": [
            "Rafał Muszyński",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Modeling personality is a challenging problem with applications spanning\ncomputer games, virtual assistants, online shopping and education. Many\ntechniques have been tried, ranging from neural networks to computational\ncognitive architectures. However, most approaches rely on examples with\nhand-crafted features and scenarios. Here, we approach learning a personality\nby training agents using a Deep Q-Network (DQN) model on rewards based on\npsychoanalysis, against hand-coded AI in the game of Pong. As a result, we\nobtain 4 agents, each with its own personality. Then, we define happiness of an\nagent, which can be seen as a measure of alignment with agent's objective\nfunction, and study it when agents play both against hand-coded AI, and against\neach other. We find that the agents that achieve higher happiness during\ntesting against hand-coded AI, have lower happiness when competing against each\nother. This suggests that higher happiness in testing is a sign of overfitting\nin learning to interact with hand-coded AI, and leads to worse performance\nagainst agents with different personalities.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.11068v2"
    },
    {
        "title": "Strategic Topology Switching for Security-Part II: Detection & Switching\n  Topologies",
        "authors": [
            "Yanbing Mao",
            "Emrah Akyol",
            "Ziang Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This two-part paper considers strategic topology switching for security in\nthe second-order multi-agent system. In Part II, we propose a strategy on\nswitching topologies to detect zero-dynamics attack (ZDA), whose\nattack-starting time is allowed to be not the initial time. We first\ncharacterize the sufficient and necessary condition for detectability of ZDA,\nin terms of the network topologies to be switched to and the set of agents to\nbe monitored. We then propose an attack detection algorithm based on the\nLuenberger observer, using the characterized detectability condition. Employing\nthe strategy on switching times proposed in Part I and the strategy on\nswitching topologies proposed here, a strategic topology-switching algorithm is\nderived. Its primary advantages are threefold: (i) in achieving consensus in\nthe absence of attacks, the control protocol does not need velocity\nmeasurements and the algorithm has no constraint on the magnitudes of coupling\nweights; (ii) in tracking system in the absence of attacks, the Luenberger\nobserver has no constraint on the magnitudes of observer gains and the number\nof monitored agents, i.e., only one monitored agent's output is sufficient;\n(iii) in detecting ZDA, the algorithm allows the defender to have no knowledge\nof the attack-starting time and the number of misbehaving agents (i.e., agents\nunder attack). Simulations are provided to verify the effectiveness of the\nstrategic topology-switching algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.11181v4"
    },
    {
        "title": "Multiagent-based Participatory Urban Simulation through Inverse\n  Reinforcement Learning",
        "authors": [
            "Soma Suzuki"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The multiagent-based participatory simulation features prominently in urban\nplanning as the acquired model is considered as the hybrid system of the domain\nand the local knowledge. However, the key problem of generating realistic\nagents for particular social phenomena invariably remains. The existing models\nhave attempted to dictate the factors involving human behavior, which appeared\nto be intractable. In this paper, Inverse Reinforcement Learning (IRL) is\nintroduced to address this problem. IRL is developed for computational modeling\nof human behavior and has achieved great successes in robotics, psychology and\nmachine learning. The possibilities presented by this new style of modeling are\ndrawn out as conclusions, and the relative challenges with this modeling are\nhighlighted.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.07887v1"
    },
    {
        "title": "Limits for Rumor Spreading in stochastic populations",
        "authors": [
            "Lucas Boczkowski",
            "Ofer Feinerman",
            "Amos Korman",
            "Emanuele Natale"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Biological systems can share and collectively process information to yield\nemergent effects, despite inherent noise in communication. While man-made\nsystems often employ intricate structural solutions to overcome noise, the\nstructure of many biological systems is more amorphous. It is not well\nunderstood how communication noise may affect the computational repertoire of\nsuch groups. To approach this question we consider the basic collective task of\nrumor spreading, in which information from few knowledgeable sources must\nreliably flow into the rest of the population.\n  In order to study the effect of communication noise on the ability of groups\nthat lack stable structures to efficiently solve this task, we consider a noisy\nversion of the uniform PULL model. We prove a lower bound which implies that,\nin the presence of even moderate levels of noise that affect all facets of the\ncommunication, no scheme can significantly outperform the trivial one in which\nagents have to wait until directly interacting with the sources. Our results\nthus show an exponential separation between the uniform PUSH and PULL\ncommunication models in the presence of noise. Such separation may be\ninterpreted as suggesting that, in order to achieve efficient rumor spreading,\na system must exhibit either some degree of structural stability or,\nalternatively, some facet of the communication which is immune to noise.\n  We corroborate our theoretical findings with a new analysis of experimental\ndata regarding recruitment in Cataglyphis niger desert ants.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.08507v1"
    },
    {
        "title": "Um Sistema Multiagente no Combate ao Braqueamento de Capitais",
        "authors": [
            "Claudio Alexandre",
            "João Balsa"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Money laundering is a crime that makes it possible to finance other crimes,\nfor this reason, it is important for criminal organizations and their combat is\nprioritized by nations around the world. The anti-money laundering process has\nnot evolved as expected because it has prioritized only the signaling of\nsuspicious transactions. The constant increasing in the volume of transactions\nhas overloaded the indispensable human work of final evaluation of the\nsuspicions. This article presents a multiagent system that aims to go beyond\nthe capture of suspicious transactions, seeking to assist the human expert in\nthe analysis of suspicions. The agents created use data mining techniques to\ncreate transactional behavioral profiles; apply rules generated in learning\nprocess in conjunction with specific rules based on legal aspects and profiles\ncreated to capture suspicious transactions; and analyze these suspicious\ntransactions indicating to the human expert those that require more detailed\nanalysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.00743v1"
    },
    {
        "title": "Utilitarian Welfare and Representation Guarantees of Approval-Based\n  Multiwinner Rules",
        "authors": [
            "Martin Lackner",
            "Piotr Skowron"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  To choose a suitable multiwinner voting rule is a hard and ambiguous task.\nDepending on the context, it varies widely what constitutes the choice of an\n``optimal'' subset of alternatives. In this paper, we provide a quantitative\nanalysis of multiwinner voting rules using methods from the theory of\napproximation algorithms---we estimate how well multiwinner rules approximate\ntwo extreme objectives: a representation criterion defined via the Approval\nChamberlin--Courant rule and a utilitarian criterion defined via Multiwinner\nApproval Voting. With both theoretical and experimental methods, we classify\nmultiwinner rules in terms of their quantitative alignment with these two\nopposing objectives. Our results provide fundamental information about the\nnature of multiwinner rules and, in particular, about the necessary tradeoffs\nwhen choosing such a rule.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.01527v4"
    },
    {
        "title": "Belief Control Strategies for Interactions over Weakly-Connected Graphs",
        "authors": [
            "Hawraa Salami",
            "Bicheng Ying",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In diffusion social learning over weakly-connected graphs, it has been shown\nrecently that influential agents shape the beliefs of non-influential agents.\nThis paper analyzes this mechanism more closely and addresses two main\nquestions. First, the article examines how much freedom influential agents have\nin controlling the beliefs of the receiving agents, namely, whether receiving\nagents can be driven to arbitrary beliefs and whether the network structure\nlimits the scope of control by the influential agents. Second, even if there is\na limit to what influential agents can accomplish, this article develops\nmechanisms by which they can lead receiving agents to adopt certain beliefs.\nThese questions raise interesting possibilities about belief control over\nnetworked agents. Once addressed, one ends up with design procedures that allow\ninfluential agents to drive other agents to endorse particular beliefs\nregardless of their local observations or convictions. The theoretical findings\nare illustrated by means of examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05479v2"
    },
    {
        "title": "Knowledge Representation for High-Level Norms and Violation Inference in\n  Logic Programming",
        "authors": [
            "Babatunde Opeoluwa Akinkunmi",
            "Moyin Florence Babalola"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Most of the knowledge Representation formalisms developed for representing\nprescriptive norms can be categorized as either suitable for representing\neither low level or high level norms.We argue that low level norm\nrepresentations do not advance the cause of autonomy in agents in the sense\nthat it is not the agent itself that determines the normative position it\nshould be at a particular time, on the account of a more general rule. In other\nwords an agent on some external system for a nitty gritty prescriptions of its\nobligations and prohibitions. On the other hand, high level norms which have an\nexplicit description of a norm's precondition and have some form of\nimplication, do not as they exist in the literature do not support generalized\ninferences about violation like low level norm representations do. This paper\npresents a logical formalism for the representation of high level norms in open\nsocieties that enable violation inferences that detail the situation in which\nthe norm violation took place and the identity of the norm violation. Norms are\nformalized as logic programs whose heads specify what an agent is obliged or\npermitted to do when a situation arises and within what time constraint of the\nsituation.Each norm is also assigned an identity using some reification scheme.\nThe body of each logic program describes the nature of the situation in which\nthe agent is expected to act or desist from acting. This kind of violation is\nnovel in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.06740v1"
    },
    {
        "title": "A Work Zone Simulation Model for Travel Time Prediction in a Connected\n  Vehicle Environment",
        "authors": [
            "Xuejin Wen"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  A work zone bottleneck in a roadway network can cause traffic delays,\nemissions and safety issues. Accurate measurement and prediction of work zone\ntravel time can help travelers make better routing decisions and therefore\nmitigate its impact. Historically, data used for travel time analyses comes\nfrom fixed loop detectors, which are expensive to install and maintain. With\nconnected vehicle technology, such as Vehicle-to-Infrastructure, portable\nroadside unit (RSU) can be located in and around a work zone segment to\ncommunicate with the vehicles and collect traffic data. A PARAMICS simulation\nmodel for a prototypical freeway work zone in a connected vehicle environment\nwas built to test this idea using traffic demand data from NY State Route 104.\nFor the simulation, twelve RSUs were placed along the work zone segment and\nsixteen variables were extracted from the simulation results to explore travel\ntime estimation and prediction. For the travel time analysis, four types of\nmodels were constructed, including linear regression, multivariate adaptive\nregression splines (MARS), stepwise regression and elastic net. The results\nshow that the modeling approaches under consideration have similar performance\nin terms of the Root of Mean Square Error (RMSE), which provides an opportunity\nfor model selection based on additional factors including the number and\nlocations of the RSUs according to the significant variables identified in the\nvarious models. Among the four approaches, the stepwise regression model only\nneeds variables from two RSUs: one placed sufficiently upstream of the work\nzone and one at the end of the work zone.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07579v1"
    },
    {
        "title": "Quantified Degrees of Group Responsibility (Extended Abstract)",
        "authors": [
            "Vahid Yazdanpanah",
            "Mehdi Dastani"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper builds on an existing notion of group responsibility and proposes\ntwo ways to define the degree of group responsibility: structural and\nfunctional degrees of responsibility. These notions measure the potential\nresponsibilities of (agent) groups for avoiding a state of affairs. According\nto these notions, a degree of responsibility for a state of affairs can be\nassigned to a group of agents if, and to the extent that, the group has the\npotential to preclude the state of affairs.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07747v1"
    },
    {
        "title": "Adversarial Classification on Social Networks",
        "authors": [
            "Sixie Yu",
            "Yevgeniy Vorobeychik",
            "Scott Alfeld"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The spread of unwanted or malicious content through social media has become a\nmajor challenge. Traditional examples of this include social network spam, but\nan important new concern is the propagation of fake news through social media.\nA common approach for mitigating this problem is by using standard statistical\nclassification to distinguish malicious (e.g., fake news) instances from benign\n(e.g., actual news stories). However, such an approach ignores the fact that\nmalicious instances propagate through the network, which is consequential both\nin quantifying consequences (e.g., fake news diffusing through the network),\nand capturing detection redundancy (bad content can be detected at different\nnodes). An additional concern is evasion attacks, whereby the generators of\nmalicious instances modify the nature of these to escape detection. We model\nthis problem as a Stackelberg game between the defender who is choosing\nparameters of the detection model, and an attacker, who is choosing both the\nnode at which to initiate malicious spread, and the nature of malicious\nentities. We develop a novel bi-level programming approach for this problem, as\nwell as a novel solution approach based on implicit function gradients, and\nexperimentally demonstrate the advantage of our approach over alternatives\nwhich ignore network structure.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.08159v1"
    },
    {
        "title": "Anatomy of Leadership in Collective Behaviour",
        "authors": [
            "Joshua Garland",
            "Andrew M. Berdahl",
            "Jie Sun",
            "Erik Bollt"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Understanding the mechanics behind the coordinated movement of mobile animal\ngroups (collective motion) provides key insights into their biology and\necology, while also yielding algorithms for bio-inspired technologies and\nautonomous systems. It is becoming increasingly clear that many mobile animal\ngroups are composed of heterogeneous individuals with differential levels and\ntypes of influence over group behaviors. The ability to infer this differential\ninfluence, or leadership, is critical to understanding group functioning in\nthese collective animal systems. Due to the broad interpretation of leadership,\nmany different measures and mathematical tools are used to describe and infer\n\"leadership\", e.g., position, causality, influence, information flow. But a key\nquestion remains: which, if any, of these concepts actually describes\nleadership? We argue that instead of asserting a single definition or notion of\nleadership, the complex interaction rules and dynamics typical of a group\nimplies that leadership itself is not merely a binary classification (leader or\nfollower), but rather, a complex combination of many different components. In\nthis paper we develop an anatomy of leadership, identify several principle\ncomponents and provide a general mathematical framework for discussing\nleadership. With the intricacies of this taxonomy in mind we present a set of\nleadership-oriented toy models that should be used as a proving ground for\nleadership inference methods going forward. We believe this multifaceted\napproach to leadership will enable a broader understanding of leadership and\nits inference from data in mobile animal groups and beyond.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01194v2"
    },
    {
        "title": "A Sharp Bound on the $s$-Energy and Its Applications to Averaging\n  Systems",
        "authors": [
            "Bernard Chazelle"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The {\\em $s$-energy} is a generating function of wide applicability in\nnetwork-based dynamics. We derive an (essentially) optimal bound of $(3/\\rho\ns)^{n-1}$ on the $s$-energy of an $n$-agent symmetric averaging system, for any\npositive real $s\\leq 1$, where~$\\rho$ is a lower bound on the nonzero weights.\nThis is done by introducing the new dynamics of {\\em twist systems}. We show\nhow to use the new bound on the $s$-energy to tighten the convergence rate of\nsystems in opinion dynamics, flocking, and synchronization.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01207v2"
    },
    {
        "title": "Machine Learning-based Variability Handling in IoT Agents",
        "authors": [
            "Nathalia Nascimento",
            "Paulo Alencar",
            "Carlos Lucena",
            "Donald Cowan"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Agent-based IoT applications have recently been proposed in several domains,\nsuch as health care, smart cities and agriculture. Deploying these applications\nin specific settings has been very challenging for many reasons including the\ncomplex static and dynamic variability of the physical devices such as sensors\nand actuators, the software application behavior and the environment in which\nthe application is embedded. In this paper, we propose a self-configurable IoT\nagent approach based on feedback-evaluative machine-learning. The approach\ninvolves: i) a variability model of IoT agents; ii) generation of sets of\ncustomized agents; iii) feedback evaluative machine learning; iv) modeling and\ncomposition of a group of IoT agents; and v) a feature-selection method based\non manual and automatic feedback.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03858v1"
    },
    {
        "title": "Efficient Collaborative Multi-Agent Deep Reinforcement Learning for\n  Large-Scale Fleet Management",
        "authors": [
            "Kaixiang Lin",
            "Renyu Zhao",
            "Zhe Xu",
            "Jiayu Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Large-scale online ride-sharing platforms have substantially transformed our\nlives by reallocating transportation resources to alleviate traffic congestion\nand promote transportation efficiency. An efficient fleet management strategy\nnot only can significantly improve the utilization of transportation resources\nbut also increase the revenue and customer satisfaction. It is a challenging\ntask to design an effective fleet management strategy that can adapt to an\nenvironment involving complex dynamics between demand and supply. Existing\nstudies usually work on a simplified problem setting that can hardly capture\nthe complicated stochastic demand-supply variations in high-dimensional space.\nIn this paper we propose to tackle the large-scale fleet management problem\nusing reinforcement learning, and propose a contextual multi-agent\nreinforcement learning framework including three concrete algorithms to achieve\ncoordination among a large number of agents adaptive to different contexts. We\nshow significant improvements of the proposed framework over state-of-the-art\napproaches through extensive empirical studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.06444v3"
    },
    {
        "title": "Simulating the Ridesharing Economy: The Individual Agent\n  Metro-Washington Area Ridesharing Model",
        "authors": [
            "Joseph A. E. Shaheen"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The ridesharing economy is experiencing rapid growth and innovation.\nCompanies such as Uber and Lyft are continuing to grow at a considerable pace\nwhile providing their platform as an organizing medium for ridesharing\nservices, increasing consumer utility as well as employing thousands in\npart-time positions. However, many challenges remain in the modeling of\nridesharing services, many of which are not currently under wide consideration.\nIn this paper, an agent-based model is developed to simulate a ridesharing\nservice in the Washington D.C. metropolitan region. The model is used to\nexamine levels of utility gained for both riders (customers) and drivers\n(service providers) of a generic ridesharing service. A description of the\nIndividual Agent Metro-Washington Area Ridesharing Model (IAMWARM) is provided,\nas well as a description of a typical simulation run. We investigate the\nfinancial gains of drivers for a 24-hour period under two scenarios and two\nspatial movement behaviors. The two spatial behaviors were random movement and\nVoronoi movement, which we describe. Both movement behaviors were tested under\na stationary run conditions scenario and a variable run conditions scenario. We\nfind that Voronoi movement increased drivers' utility gained but that emergence\nof this system property was only viable under variable scenario conditions.\nThis result provides two important insights: The first is that driver movement\ndecisions prior to passenger pickup can impact financial gain for the service\nand drivers, and consequently, rate of successful pickup for riders. The second\nis that this phenomenon is only evident under experimentation conditions where\nvariability in passenger and driver arrival rates are administered.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.07280v1"
    },
    {
        "title": "A Model of Free Will for Artificial Entities",
        "authors": [
            "Eric Sanchis"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The impression of free will is the feeling according to which our choices are\nneither imposed from our inside nor from outside. It is the sense we are the\nultimate cause of our acts. In direct opposition with the universal\ndeterminism, the existence of free will continues to be discussed. In this\npaper, free will is linked to a decisional mechanism: an agent is provided with\nfree will if having performed a predictable choice Cp, it can immediately\nperform another choice Cr in a random way. The intangible feeling of free will\nis replaced by a decision-making process including a predictable\ndecision-making process immediately followed by an unpredictable decisional\none.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.09317v1"
    },
    {
        "title": "Identifying Sources and Sinks in the Presence of Multiple Agents with\n  Gaussian Process Vector Calculus",
        "authors": [
            "Adam D. Cobb",
            "Richard Everett",
            "Andrew Markham",
            "Stephen J. Roberts"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In systems of multiple agents, identifying the cause of observed agent\ndynamics is challenging. Often, these agents operate in diverse, non-stationary\nenvironments, where models rely on hand-crafted environment-specific features\nto infer influential regions in the system's surroundings. To overcome the\nlimitations of these inflexible models, we present GP-LAPLACE, a technique for\nlocating sources and sinks from trajectories in time-varying fields. Using\nGaussian processes, we jointly infer a spatio-temporal vector field, as well as\ncanonical vector calculus operations on that field. Notably, we do this from\nonly agent trajectories without requiring knowledge of the environment, and\nalso obtain a metric for denoting the significance of inferred causal features\nin the environment by exploiting our probabilistic method. To evaluate our\napproach, we apply it to both synthetic and real-world GPS data, demonstrating\nthe applicability of our technique in the presence of multiple agents, as well\nas its superiority over existing methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.10446v2"
    },
    {
        "title": "Simon's Anthill: Mapping and Navigating Belief Spaces",
        "authors": [
            "Philip Feldman",
            "Aaron Dant",
            "Wayne Lutters"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In the parable of Simon's Ant, an ant follows a complex path along a beach on\nto reach its goal. The story shows how the interaction of simple rules and a\ncomplex environment result in complex behavior. But this relationship can be\nlooked at in another way - given path and rules, we can infer the environment.\nWith a large population of agents - human or animal - it should be possible to\nbuild a detailed map of a population's social and physical environment. In this\nabstract, we describe the development of a framework to create such maps of\nhuman belief space. These maps are built from the combined trajectories of a\nlarge number of agents. Currently, these maps are built using multidimensional\nagent-based simulation, but the framework is designed to work using data from\ncomputer-mediated human communication. Maps incorporating human data should\nsupport visualization and navigation of the \"plains of research\", \"fashionable\nfoothills\" and \"conspiracy cliffs\" of human belief spaces.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.05409v1"
    },
    {
        "title": "Vehicle Communication Strategies for Simulated Highway Driving",
        "authors": [
            "Cinjon Resnick",
            "Ilya Kulikov",
            "Kyunghyun Cho",
            "Jason Weston"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Interest in emergent communication has recently surged in Machine Learning.\nThe focus of this interest has largely been either on investigating the\nproperties of the learned protocol or on utilizing emergent communication to\nbetter solve problems that already have a viable solution. Here, we consider\nself-driving cars coordinating with each other and focus on how communication\ninfluences the agents' collective behavior. Our main result is that\ncommunication helps (most) with adverse conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.07178v2"
    },
    {
        "title": "Influencing Flock Formation in Low-Density Settings",
        "authors": [
            "Daniel Y. Fu",
            "Emily S. Wang",
            "Peter M. Krafft",
            "Barbara J. Grosz"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Flocking is a coordinated collective behavior that results from local sensing\nbetween individual agents that have a tendency to orient towards each other.\nFlocking is common among animal groups and might also be useful in robotic\nswarms. In the interest of learning how to control flocking behavior, recent\nwork in the multiagent systems literature has explored the use of influencing\nagents for guiding flocking agents to face a target direction. The existing\nwork in this domain has focused on simulation settings of small areas with\ntoroidal shapes. In such settings, agent density is high, so interactions are\ncommon, and flock formation occurs easily. In our work, we study new\nenvironments with lower agent density, wherein interactions are more rare. We\nstudy the efficacy of placement strategies and influencing agent behaviors\ndrawn from the literature, and find that the behaviors that have been shown to\nwork well in high-density conditions tend to be much less effective in lower\ndensity environments. The source of this ineffectiveness is that the\ninfluencing agents explored in prior work tended to face directions optimized\nfor maximal influence, but which actually separate the influencing agents from\nthe flock. We find that in low-density conditions maintaining a connection to\nthe flock is more important than rushing to orient towards the desired\ndirection. We use these insights to propose new influencing agent behaviors,\nwhich we dub \"follow-then-influence\"; agents act like normal members of the\nflock to achieve positions that allow for control and then exert their\ninfluence. This strategy overcomes the difficulties posed by low density\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.08667v1"
    },
    {
        "title": "Self-Stabilizing Task Allocation In Spite of Noise",
        "authors": [
            "Anna Dornhaus",
            "Nancy Lynch",
            "Frederik Mallmann-Trenn",
            "Dominik Pajak",
            "Tsvetomira Radeva"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We study the problem of distributed task allocation inspired by the behavior\nof social insects, which perform task allocation in a setting of limited\ncapabilities and noisy environment feedback. We assume that each task has a\ndemand that should be satisfied but not exceeded, i.e., there is an optimal\nnumber of ants that should be working on this task at a given time. The goal is\nto assign a near-optimal number of workers to each task in a distributed manner\nand without explicit access to the values of the demands nor the number of ants\nworking on the task.\n  We seek to answer the question of how the quality of task allocation depends\non the accuracy of assessing whether too many (overload) or not enough (lack)\nants are currently working on a given task. Concretely, we address the open\nquestion of solving task allocation in the model where each ant receives\nfeedback that depends on the deficit defined as the (possibly negative)\ndifference between the optimal demand and the current number of workers in the\ntask. The feedback is modeled as a random variable that takes value lack or\noverload with probability given by a sigmoid of the deficit. Each ants receives\nthe feedback independently, but the higher the overload or lack of workers for\na task, the more likely it is that all the ants will receive the same, correct\nfeedback from this task; the closer the deficit is to zero, the less reliable\nthe feedback becomes. We measure the performance of task allocation algorithms\nusing the notion of regret, defined as the absolute value of the deficit summed\nover all tasks and summed over time.\n  We propose a simple, constant-memory, self-stabilizing, distributed algorithm\nthat quickly converges from any initial distribution to a near-optimal\nassignment. We also show that our algorithm works not only under stochastic\nnoise but also in an adversarial noise setting.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03691v2"
    },
    {
        "title": "Agent Based Rumor Spreading in a scale-free network",
        "authors": [
            "Mattia Mazzoli",
            "Tullio Re",
            "Roberto Bertilone",
            "Marco Maggiora",
            "Jacopo Pellegrino"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In the last years, the study of rumor spreading on social networks produced a\nlot of interest among the scientific community, expecially due to the role of\nsocial networks in the last political events. The goal of this work is to\nreproduce real-like diffusions of information and misinformation in a\nscale-free network using a multi-agent-based model. The data concerning the\nvirtual spreading are easily obtainable, in particular the diffusion of\ninformation during the announcement for the discovery of the Higgs Boson on\nTwitter was recorded and investigated in detail. We made some assumptions on\nthe micro behavior of our agents and registered the effects in a statistical\nanalysis replying the real data diffusion. Then, we studied an hypotetical\nresponse to a misinformation diffusion adding debunking agents and trying to\nmodel a critic response from the agents using real data from a hoax regarding\nthe Occupy Wall Street movement. After tuning our model to reproduce these\nresults, we measured some network properties and proved the emergence of\nsubstantially separated structures like echochambers, independently from the\nnetwork size scale, i.e. with one hundred, one thousand and ten thousand\nagents.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.05999v2"
    },
    {
        "title": "Learning to Teach in Cooperative Multiagent Reinforcement Learning",
        "authors": [
            "Shayegan Omidshafiei",
            "Dong-Ki Kim",
            "Miao Liu",
            "Gerald Tesauro",
            "Matthew Riemer",
            "Christopher Amato",
            "Murray Campbell",
            "Jonathan P. How"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Collective human knowledge has clearly benefited from the fact that\ninnovations by individuals are taught to others through communication. Similar\nto human social groups, agents in distributed learning systems would likely\nbenefit from communication to share knowledge and teach skills. The problem of\nteaching to improve agent learning has been investigated by prior works, but\nthese approaches make assumptions that prevent application of teaching to\ngeneral multiagent problems, or require domain expertise for problems they can\napply to. This learning to teach problem has inherent complexities related to\nmeasuring long-term impacts of teaching that compound the standard multiagent\ncoordination challenges. In contrast to existing works, this paper presents the\nfirst general framework and algorithm for intelligent agents to learn to teach\nin a multiagent environment. Our algorithm, Learning to Coordinate and Teach\nReinforcement (LeCTR), addresses peer-to-peer teaching in cooperative\nmultiagent reinforcement learning. Each agent in our approach learns both when\nand what to advise, then uses the received advice to improve local learning.\nImportantly, these roles are not fixed; these agents learn to assume the role\nof student and/or teacher at the appropriate moments, requesting and providing\nadvice in order to improve teamwide performance and learning. Empirical\ncomparisons against state-of-the-art teaching methods show that our teaching\nagents not only learn significantly faster, but also learn to coordinate in\ntasks where existing methods fail.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.07830v4"
    },
    {
        "title": "The Swarmathon: An Autonomous Swarm Robotics Competition",
        "authors": [
            "Sarah M. Ackerman",
            "G. Matthew Fricke",
            "Joshua P. Hecker",
            "Kastro M. Hamed",
            "Samantha R. Fowler",
            "Antonio D. Griego",
            "Jarett C. Jones",
            "J. Jake Nichol",
            "Kurt W. Leucht",
            "Melanie E. Moses"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The Swarmathon is a swarm robotics programming challenge that engages college\nstudents from minority-serving institutions in NASA's Journey to Mars. Teams\ncompete by programming a group of robots to search for, pick up, and drop off\nresources in a collection zone. The Swarmathon produces prototypes for robot\nswarms that would collect resources on the surface of Mars. Robots operate\ncompletely autonomously with no global map, and each team's algorithm must be\nsufficiently flexible to effectively find resources from a variety of unknown\ndistributions. The Swarmathon includes Physical and Virtual Competitions.\nPhysical competitors test their algorithms on robots they build at their\nschools; they then upload their code to run autonomously on identical robots\nduring the three day competition in an outdoor arena at Kennedy Space Center.\nVirtual competitors complete an identical challenge in simulation. Participants\nmentor local teams to compete in a separate High School Division. In the first\n2 years, over 1,100 students participated. 63% of students were from\nunderrepresented ethnic and racial groups. Participants had significant gains\nin both interest and core robotic competencies that were equivalent across\ngender and racial groups, suggesting that the Swarmathon is effectively\neducating a diverse population of future roboticists.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.08320v1"
    },
    {
        "title": "Correlation Clustering Based Coalition Formation For Multi-Robot Task\n  Allocation",
        "authors": [
            "Ayan Dutta",
            "Vladimir Ufimtsev",
            "Asai Asaithambi"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In this paper, we study the multi-robot task allocation problem where a group\nof robots needs to be allocated to a set of tasks so that the tasks can be\nfinished optimally. One task may need more than one robot to finish it.\nTherefore the robots need to form coalitions to complete these tasks.\nMulti-robot coalition formation for task allocation is a well-known NP-hard\nproblem. To solve this problem, we use a linear-programming based graph\npartitioning approach along with a region growing strategy which allocates\n(near) optimal robot coalitions to tasks in a negligible amount of time. Our\nproposed algorithm is fast (only taking 230 secs. for 100 robots and 10 tasks)\nand it also finds a near-optimal solution (up to 97.66% of the optimal). We\nhave empirically demonstrated that the proposed approach in this paper always\nfinds a solution which is closer (up to 9.1 times) to the optimal solution than\na theoretical worst-case bound proved in an earlier work.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.08629v1"
    },
    {
        "title": "Dynamic Connected Cooperative Coverage Problem",
        "authors": [
            "Tristan Charrier",
            "François Schwarzentruber",
            "Eva Soulier"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We study the so-called dynamic coverage problem by agents located in some\ntopological graph. The agents must visit all regions of interest but they also\nshould stay connected to the base via multi-hop. We prove that the algorithmic\ncomplexity of this planning problem is PSPACE-complete. Furthermore we prove\nthat the problem becomes NP-complete for bounded plans. We also prove the same\ncomplexities for the reachability problem of some positions. We also prove that\ncomplexities are maintained for a subclass of topological graphs.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.06213v1"
    },
    {
        "title": "Multi-Agent Actor-Critic with Generative Cooperative Policy Network",
        "authors": [
            "Heechang Ryu",
            "Hayong Shin",
            "Jinkyoo Park"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We propose an efficient multi-agent reinforcement learning approach to derive\nequilibrium strategies for multi-agents who are participating in a Markov game.\nMainly, we are focused on obtaining decentralized policies for agents to\nmaximize the performance of a collaborative task by all the agents, which is\nsimilar to solving a decentralized Markov decision process. We propose to use\ntwo different policy networks: (1) decentralized greedy policy network used to\ngenerate greedy action during training and execution period and (2) generative\ncooperative policy network (GCPN) used to generate action samples to make other\nagents improve their objectives during training period. We show that the\nsamples generated by GCPN enable other agents to explore the policy space more\neffectively and favorably to reach a better policy in terms of achieving the\ncollaborative tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.09206v1"
    },
    {
        "title": "Multiparty Dynamics and Failure Modes for Machine Learning and\n  Artificial Intelligence",
        "authors": [
            "David Manheim"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  An important challenge for safety in machine learning and artificial\nintelligence systems is a~set of related failures involving specification\ngaming, reward hacking, fragility to distributional shifts, and Goodhart's or\nCampbell's law. This paper presents additional failure modes for interactions\nwithin multi-agent systems that are closely related. These multi-agent failure\nmodes are more complex, more problematic, and less well understood than the\nsingle-agent case, and are also already occurring, largely unnoticed. After\nmotivating the discussion with examples from poker-playing artificial\nintelligence (AI), the paper explains why these failure modes are in some\nsenses unavoidable. Following this, the paper categorizes failure modes,\nprovides definitions, and cites examples for each of the modes: accidental\nsteering, coordination failures, adversarial misalignment, input spoofing and\nfiltering, and goal co-option or direct hacking. The paper then discusses how\nextant literature on multi-agent AI fails to address these failure modes, and\nidentifies work which may be useful for the mitigation of these failure modes.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.10862v4"
    },
    {
        "title": "The Impact of Position Errors on Crowd Simulation",
        "authors": [
            "Lei Zhang",
            "Diego Lai",
            "Andriy V. Miranskyy"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In large crowd events, there is always a potential possibility that a\nstampede accident will occur. The accident may cause injuries or even death.\nApproaches for controlling crowd flows and predicting dangerous congestion\nspots would be a boon to on-site authorities to manage the crowd and to prevent\nfatal accidents. One of the most popular approaches is real-time crowd\nsimulation based on position data from personal Global Positioning System (GPS)\ndevices. However, the accuracy of spatial data varies for different GPS\ndevices, and it is also affected by an environment in which an event takes\nplace. In this paper, we would like to assess the effect of position errors on\nstampede prediction. We propose an Automatic Real-time dEtection of Stampedes\n(ARES) method to predict stampedes for large events. We implement three\ndifferent stampede assessment methods in Menge framework and incorporate\nposition errors. Our analysis suggests that the probability of simulated\nstampede changes significantly with the increase of the magnitude of position\nerrors, which cannot be eliminated entirely with the help of classic\ntechniques, such as the Kalman filter. Thus, it is our position that novel\nstampede assessment methods should be developed, focusing on the detection of\nposition noise and the elimination of its effect.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.11131v1"
    },
    {
        "title": "A Unified Approach to Dynamic Decision Problems with Asymmetric\n  Information - Part I: Non-Strategic Agents",
        "authors": [
            "Hamidreza Tavafoghi",
            "Yi Ouyang",
            "Demosthenis Teneketzis"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We study a general class of dynamic multi-agent decision problems with\nasymmetric information and non-strategic agents, which includes dynamic teams\nas a special case. When agents are non-strategic, an agent's strategy is known\nto the other agents. Nevertheless, the agents' strategy choices and beliefs are\ninterdependent over times, a phenomenon known as signaling. We introduce the\nnotions of private information that effectively compresses the agents'\ninformation in a mutually consistent manner. Based on the notions of sufficient\ninformation, we propose an information state for each agent that is sufficient\nfor decision making purposes. We present instances of dynamic multi-agent\ndecision problems where we can determine an information state with a\ntime-invariant domain for each agent. Furthermore, we present a generalization\nof the policy-independence property of belief in Partially Observed Markov\nDecision Processes (POMDP) to dynamic multi-agent decision problems. Within the\ncontext of dynamic teams with asymmetric information, the proposed set of\ninformation states leads to a sequential decomposition that decouples the\ninterdependence between the agents' strategies and beliefs over time, and\nenables us to formulate a dynamic program to determine a globally optimal\npolicy via backward induction.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.01130v1"
    },
    {
        "title": "On the Positive Effect of Delay on the Rate of Convergence of a Class of\n  Linear Time-Delayed Systems",
        "authors": [
            "Hossein Moradian",
            "Solmaz S. Kia"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper is a comprehensive study of a long observed phenomenon of increase\nin the stability margin and so the rate of convergence of a class of linear\nsystems due to time delay. We use Lambert W function to determine (a) in what\nsystems the delay can lead to increase in the rate of convergence, (b) the\nexact range of time delay for which the rate of convergence is greater than\nthat of the delay free system, and (c) an estimate on the value of the delay\nthat leads to the maximum rate of convergence. For the special case when the\nsystem matrix eigenvalues are all negative real numbers, we expand our results\nto show that the rate of convergence in the presence of delay depends only on\nthe eigenvalues with minimum and maximum real parts. Moreover, we determine the\nexact value of the maximum rate of convergence and the corresponding maximizing\ntime delay. We demonstrate our results through a numerical example on the\npractical application in accelerating an agreement algorithm for\nnetworked~systems by use of a delayed feedback.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.04030v2"
    },
    {
        "title": "Hierarchical Macro Strategy Model for MOBA Game AI",
        "authors": [
            "Bin Wu",
            "Qiang Fu",
            "Jing Liang",
            "Peng Qu",
            "Xiaoqian Li",
            "Liang Wang",
            "Wei Liu",
            "Wei Yang",
            "Yongsheng Liu"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The next challenge of game AI lies in Real Time Strategy (RTS) games. RTS\ngames provide partially observable gaming environments, where agents interact\nwith one another in an action space much larger than that of GO. Mastering RTS\ngames requires both strong macro strategies and delicate micro level execution.\nRecently, great progress has been made in micro level execution, while complete\nsolutions for macro strategies are still lacking. In this paper, we propose a\nnovel learning-based Hierarchical Macro Strategy model for mastering MOBA\ngames, a sub-genre of RTS games. Trained by the Hierarchical Macro Strategy\nmodel, agents explicitly make macro strategy decisions and further guide their\nmicro level execution. Moreover, each of the agents makes independent strategy\ndecisions, while simultaneously communicating with the allies through\nleveraging a novel imitated cross-agent communication mechanism. We perform\ncomprehensive evaluations on a popular 5v5 Multiplayer Online Battle Arena\n(MOBA) game. Our 5-AI team achieves a 48% winning rate against human player\nteams which are ranked top 1% in the player ranking system.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.07887v1"
    },
    {
        "title": "A Cooperative Multi-Agent Reinforcement Learning Framework for Resource\n  Balancing in Complex Logistics Network",
        "authors": [
            "Xihan Li",
            "Jia Zhang",
            "Jiang Bian",
            "Yunhai Tong",
            "Tie-Yan Liu"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Resource balancing within complex transportation networks is one of the most\nimportant problems in real logistics domain. Traditional solutions on these\nproblems leverage combinatorial optimization with demand and supply\nforecasting. However, the high complexity of transportation routes, severe\nuncertainty of future demand and supply, together with non-convex business\nconstraints make it extremely challenging in the traditional resource\nmanagement field. In this paper, we propose a novel sophisticated multi-agent\nreinforcement learning approach to address these challenges. In particular,\ninspired by the externalities especially the interactions among resource\nagents, we introduce an innovative cooperative mechanism for state and reward\ndesign resulting in more effective and efficient transportation. Extensive\nexperiments on a simulated ocean transportation service demonstrate that our\nnew approach can stimulate cooperation among agents and lead to much better\nperformance. Compared with traditional solutions based on combinatorial\noptimization, our approach can give rise to a significant improvement in terms\nof both performance and stability.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.00714v1"
    },
    {
        "title": "Convergence of Multi-Agent Learning with a Finite Step Size in\n  General-Sum Games",
        "authors": [
            "Xinliang Song",
            "Tonghan Wang",
            "Chongjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Learning in a multi-agent system is challenging because agents are\nsimultaneously learning and the environment is not stationary, undermining\nconvergence guarantees. To address this challenge, this paper presents a new\ngradient-based learning algorithm, called Gradient Ascent with Shrinking Policy\nPrediction (GA-SPP), which augments the basic gradient ascent approach with the\nconcept of shrinking policy prediction. The key idea behind this algorithm is\nthat an agent adjusts its strategy in response to the forecasted strategy of\nthe other agent, instead of its current one. GA-SPP is shown formally to have\nNash convergence in larger settings than existing gradient-based multi-agent\nlearning methods. Furthermore, unlike existing gradient-based methods, GA-SPP's\ntheoretical guarantees do not assume the learning rate to be infinitesimal.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.02868v1"
    },
    {
        "title": "A Privacy-preserving Disaggregation Algorithm for Non-intrusive\n  Management of Flexible Energy",
        "authors": [
            "Paulin Jacquot",
            "Olivier Beaude",
            "Pascal Benchimol",
            "Stéphane Gaubert",
            "Nadia Oudjane"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We consider a resource allocation problem involving a large number of agents\nwith individual constraints subject to privacy, and a central operator whose\nobjective is to optimizing a global, possibly non-convex, cost while satisfying\nthe agents'c onstraints. We focus on the practical case of the management of\nenergy consumption flexibilities by the operator of a microgrid. This paper\nprovides a privacy-preserving algorithm that does compute the optimal\nallocation of resources, avoiding each agent to reveal her private information\n(constraints and individual solution profile) neither to the central operator\nnor to a third party. Our method relies on an aggregation procedure: we\nmaintain a global allocation of resources, and gradually disaggregate this\nallocation to enforce the satisfaction of private contraints, by a protocol\ninvolving the generation of polyhedral cuts and secure multiparty computations\n(SMC). To obtain these cuts, we use an alternate projections method \\`a la Von\nNeumann, which is implemented locally by each agent, preserving her privacy\nneeds. Our theoretical and numerical results show that the method scales well\nas the number of agents gets large, and thus can be used to solve the\nallocation problem in high dimension, while addressing privacy issues.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.03053v1"
    },
    {
        "title": "Incorporating social practices in BDI agent systems",
        "authors": [
            "Stephen Cranefield",
            "Frank Dignum"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  When agents interact with humans, either through embodied agents or because\nthey are embedded in a robot, it would be easy if they could use fixed\ninteraction protocols as they do with other agents. However, people do not keep\nfixed protocols in their day-to-day interactions and the environments are often\ndynamic, making it impossible to use fixed protocols. Deliberating about\ninteractions from fundamentals is not very scalable either, because in that\ncase all possible reactions of a user have to be considered in the plans. In\nthis paper we argue that social practices can be used as an inspiration for\ndesigning flexible and scalable interaction mechanisms that are also robust.\nHowever, using social practices requires extending the traditional BDI\ndeliberation cycle to monitor landmark states and perform expected actions by\nleveraging existing plans. We define and implement this mechanism in Jason\nusing a periodically run meta-deliberation plan, supported by a\nmetainterpreter, and illustrate its use in a realistic scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.03189v1"
    },
    {
        "title": "Self-triggered distributed k-order coverage control",
        "authors": [
            "Daniel Tabatabai",
            "Mohanad Ajina",
            "Cameron Nowzari"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  A k-order coverage control problem is studied where a network of agents must\ndeploy over a desired area. The objective is to deploy all the agents in a\ndecentralized manner such that a certain coverage performance metric of the\nnetwork is maximized. Unlike many prior works that consider multi-agent\ndeployment, we explicitly consider applications where more than one agent may\nbe required to service an event that randomly occurs anywhere in the domain.\nThe proposed method ensures the distributed agents autonomously cover the area\nwhile simultaneously relaxing the requirement of constant communication among\nthe agents. In order to achieve the stated goals, a self-triggered coordination\nmethod is developed that both determines how agents should move without having\nto continuously acquire information from other agents, as well as exactly when\nto communicate and acquire new information. Through analysis, the proposed\nstrategy is shown to provide asymptotic convergence similar to that of\ncontinuous or periodic methods. Simulation results demonstrate that the\nproposed method can reduce the number of messages exchanged as well as the\namount of communication power necessary to accomplish the deployment task.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.04726v1"
    },
    {
        "title": "Resource Abstraction for Reinforcement Learning in Multiagent Congestion\n  Problems",
        "authors": [
            "Kleanthis Malialis",
            "Sam Devlin",
            "Daniel Kudenko"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Real-world congestion problems (e.g. traffic congestion) are typically very\ncomplex and large-scale. Multiagent reinforcement learning (MARL) is a\npromising candidate for dealing with this emerging complexity by providing an\nautonomous and distributed solution to these problems. However, there are three\nlimiting factors that affect the deployability of MARL approaches to congestion\nproblems. These are learning time, scalability and decentralised coordination\ni.e. no communication between the learning agents. In this paper we introduce\nResource Abstraction, an approach that addresses these challenges by allocating\nthe available resources into abstract groups. This abstraction creates new\nreward functions that provide a more informative signal to the learning agents\nand aid the coordination amongst them. Experimental work is conducted on two\nbenchmark domains from the literature, an abstract congestion problem and a\nrealistic traffic congestion problem. The current state-of-the-art for solving\nmultiagent congestion problems is a form of reward shaping called difference\nrewards. We show that the system using Resource Abstraction significantly\nimproves the learning speed and scalability, and achieves the highest possible\nor near-highest joint performance/social welfare for both congestion problems\nin large-scale scenarios involving up to 1000 reinforcement learning agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.05431v1"
    },
    {
        "title": "Learning Multi-agent Communication under Limited-bandwidth Restriction\n  for Internet Packet Routing",
        "authors": [
            "Hangyu Mao",
            "Zhibo Gong",
            "Zhengchao Zhang",
            "Zhen Xiao",
            "Yan Ni"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Communication is an important factor for the big multi-agent world to stay\norganized and productive. Recently, the AI community has applied the Deep\nReinforcement Learning (DRL) to learn the communication strategy and the\ncontrol policy for multiple agents. However, when implementing the\ncommunication for real-world multi-agent applications, there is a more\npractical limited-bandwidth restriction, which has been largely ignored by the\nexisting DRL-based methods. Specifically, agents trained by most previous\nmethods keep sending messages incessantly in every control cycle; due to\nemitting too many messages, these methods are unsuitable to be applied to the\nreal-world systems that have a limited bandwidth to transmit the messages. To\nhandle this problem, we propose a gating mechanism to adaptively prune\nunprofitable messages. Results show that the gating mechanism can prune more\nthan 80% messages with little damage to the performance. Moreover, our method\noutperforms several state-of-the-art DRL-based and rule-based methods by a\nlarge margin in both the real-world packet routing tasks and four benchmark\ntasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.05561v1"
    },
    {
        "title": "Learning Reciprocity in Complex Sequential Social Dilemmas",
        "authors": [
            "Tom Eccles",
            "Edward Hughes",
            "János Kramár",
            "Steven Wheelwright",
            "Joel Z. Leibo"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Reciprocity is an important feature of human social interaction and underpins\nour cooperative nature. What is more, simple forms of reciprocity have proved\nremarkably resilient in matrix game social dilemmas. Most famously, the\ntit-for-tat strategy performs very well in tournaments of Prisoner's Dilemma.\nUnfortunately this strategy is not readily applicable to the real world, in\nwhich options to cooperate or defect are temporally and spatially extended.\nHere, we present a general online reinforcement learning algorithm that\ndisplays reciprocal behavior towards its co-players. We show that it can induce\npro-social outcomes for the wider group when learning alongside selfish agents,\nboth in a $2$-player Markov game, and in $5$-player intertemporal social\ndilemmas. We analyse the resulting policies to show that the reciprocating\nagents are strongly influenced by their co-players' behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.08082v1"
    },
    {
        "title": "A Combination of Theta*, ORCA and Push and Rotate for Multi-agent\n  Navigation",
        "authors": [
            "Stepan Dergachev",
            "Konstantin Yakovlev",
            "Ryhor Prakapovich"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We study the problem of multi-agent navigation in static environments when no\ncentralized controller is present. Each agent is controlled individually and\nrelies on three algorithmic components to achieve its goal while avoiding\ncollisions with the other agents and the obstacles: i) individual path planning\nwhich is done by Theta* algorithm; ii) collision avoidance while path following\nwhich is performed by ORCA* algorithm; iii) locally-confined multi-agent path\nplanning done by Push and Rotate algorithm. The latter component is crucial to\navoid deadlocks in confined areas, such as narrow passages or doors. We\ndescribe how the suggested components interact and form a coherent navigation\npipeline. We carry out an extensive empirical evaluation of this pipeline in\nsimulation. The obtained results clearly demonstrate that the number of\noccurring deadlocks significantly decreases enabling more agents to reach their\ngoals compared to techniques that rely on collision-avoidance only and do not\ninclude multi-agent path planning component\n",
        "pdf_link": "http://arxiv.org/pdf/2008.01227v1"
    },
    {
        "title": "The paradox of productivity during quarantine: an agent-based simulation",
        "authors": [
            "Peter Hardy",
            "Leandro Soriano Marcolino",
            "José F. Fontanari"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Economies across the globe were brought to their knees due to lockdowns and\nsocial restriction measures to contain the spread of the SARS-CoV-2, despite\nthe quick switch to remote working. This downfall may be partially explained by\nthe \"water cooler effect\", which holds that higher levels of social interaction\nlead to higher productivity due to a boost in people's mood. Somewhat\nparadoxically, however, there are reports of increased productivity in the\nremote working scenario. Here we address quantitatively this issue using a\nvariety of experimental findings of social psychology that address the\ninterplay between mood, social interaction and productivity to set forth an\nagent-based model for a workplace composed of extrovert and introvert agent\nstereotypes that differ solely on their propensities to initiate a social\ninteraction. We find that the effects of curtailing social interactions depend\non the proportion of the stereotypes in the working group: while the social\nrestriction measures always have a negative impact on the productivity of\ngroups composed predominantly of introverts, they may actually improve the\nproductivity of groups composed predominantly of extroverts. Our results offer\na proof of concept that the paradox of productivity during quarantine can be\nexplained by taking into account the distinct effects of the social distancing\nmeasures on extroverts and introverts.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.09461v2"
    },
    {
        "title": "Integrated Self-Organized Traffic Light Controllers for Signalized\n  Intersections",
        "authors": [
            "Maythem K. Abbas",
            "Mohd Noh Karsiti",
            "Madzlan Napiah",
            "Samir Brahim"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Detecting emergency vehicles arrival on roads has been the focus for many\nresearchers. It is quite important to detect the emergency vehicles (e.g;\nambulance) arrival to traffic light to give the green light for it to pass\nthrough. Many researchers have suggested and patented emergency vehicles\ndetection systems however, according to our knowledge, none of them considered\nsolving the effect of giving extra green time to a road while the queues are\nbeing built on others. This paper considers the problem of finding a better\ntraffic light phase plan to stabilize/recover the situation at an effected\nintersection after solving an emergency vehicle existence. A hardware setup and\na novel messaging protocol have been suggested to be set on roads and vehicles\nto collect roads real time data. In addition, a novel decision making protocol\nhas been created to make the use of the collected data for making a better\ntraffic light phase plan for an intersection. The phase plan has two main\ndecisions to be made; which light has a higher priority to be green in the next\nphase, and how long the green phase should be. After simulating the proposed\nsystem using our customized simulator written in Matlab programing language and\ncomparing its performance with other related works, significant enhancements\nhave been observed in terms of stabilizing the queue lengths at an intersection\nafter solving an emergency case.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.11350v1"
    },
    {
        "title": "Algorithmic Approaches to Reconfigurable Assembly Systems",
        "authors": [
            "Allan Costa",
            "Benjamin Jenett",
            "Irina Kostitsyna",
            "Amira Abdel-Rahman",
            "Neil Gershenfeld",
            "Kenneth Cheung"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Assembly of large scale structural systems in space is understood as critical\nto serving applications that cannot be deployed from a single launch. Recent\nliterature proposes the use of discrete modular structures for in-space\nassembly and relatively small scale robotics that are able to modify and\ntraverse the structure. This paper addresses the algorithmic problems in\nscaling reconfigurable space structures built through robotic construction,\nwhere reconfiguration is defined as the problem of transforming an initial\nstructure into a different goal configuration. We analyze different algorithmic\nparadigms and present corresponding abstractions and graph formulations,\nexamining specialized algorithms that consider discretized space and time\nsteps. We then discuss fundamental design trades for different computational\narchitectures, such as centralized versus distributed, and present two\nrepresentative algorithms as concrete examples for comparison. We analyze how\nthose algorithms achieve different objective functions and goals, such as\nminimization of total distance traveled, maximization of fault-tolerance, or\nminimization of total time spent in assembly. This is meant to offer an\nimpression of algorithmic constraints on scalability of corresponding\nstructural and robotic design. From this study, a set of recommendations is\ndeveloped on where and when to use each paradigm, as well as implications for\nphysical robotic and structural system design.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.11925v1"
    },
    {
        "title": "Disturbances in Influence of a Shepherding Agent is More Impactful than\n  Sensorial Noise During Swarm Guidance",
        "authors": [
            "Hung The Nguyen",
            "Matthew Garratt",
            "Lam Thu Bui",
            "Hussein Abbass"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The guidance of a large swarm is a challenging control problem. Shepherding\noffers one approach to guide a large swarm using a few shepherding agents\n(sheepdogs). While noise is an inherent characteristic in many real-world\nproblems, the impact of noise on shepherding is not a well-studied problem. We\nstudy two forms of noise. First, we evaluate noise in the sensorial information\nreceived by the shepherd about the location of sheep. Second, we evaluate noise\nin the ability of the sheepdog to influence sheep due to disturbance forces\noccurring during actuation. We study both types of noise in this paper, and\ninvestigate the performance of Str\\\"{o}mbom's approach under these actuation\nand perception noises. To ensure that the parameterisation of the algorithm\ncreates a stable performance, we need to run a large number of simulations,\nwhile increasing the number of random episodes until stability is achieved. We\nthen systematically study the impact of sensorial and actuation noise on\nperformance. Str\\\"{o}mbom's approach is found to be more sensitive to actuation\nnoise than perception noise. This implies that it is more important for the\nshepherding agent to influence the sheep more accurately by reducing actuation\nnoise than attempting to reduce noise in its sensors. Moreover, different\nlevels of noise required different parameterisation for the shepherding agent,\nwhere the threshold needed by an agent to decide whether or not to collect\nastray sheep is different for different noise levels.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.12708v2"
    },
    {
        "title": "Biased Opinion Dynamics: When the Devil Is in the Details",
        "authors": [
            "Aris Anagnostopoulos",
            "Luca Becchetti",
            "Emilio Cruciani",
            "Francesco Pasquale",
            "Sara Rizzo"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We investigate opinion dynamics in multi-agent networks when a bias toward\none of two possible opinions exists; for example, reflecting a status quo vs a\nsuperior alternative. Starting with all agents sharing an initial opinion\nrepresenting the status quo, the system evolves in steps. In each step, one\nagent selected uniformly at random adopts the superior opinion with some\nprobability $\\alpha$, and with probability $1 - \\alpha$ it follows an\nunderlying update rule to revise its opinion on the basis of those held by its\nneighbors. We analyze convergence of the resulting process under two well-known\nupdate rules, namely majority and voter. The framework we propose exhibits a\nrich structure, with a non-obvious interplay between topology and underlying\nupdate rule. For example, for the voter rule we show that the speed of\nconvergence bears no significant dependence on the underlying topology, whereas\nthe picture changes completely under the majority rule, where network density\nnegatively affects convergence. We believe that the model we propose is at the\nsame time simple, rich, and modular, affording mathematical characterization of\nthe interplay between bias, underlying opinion dynamics, and social structure\nin a unified setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.13589v2"
    },
    {
        "title": "Team Behavior in Interactive Dynamic Influence Diagrams with\n  Applications to Ad Hoc Teams",
        "authors": [
            "Muthukumaran Chandrasekaran",
            "Prashant Doshi",
            "Yifeng Zeng",
            "Yingke Chen"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Planning for ad hoc teamwork is challenging because it involves agents\ncollaborating without any prior coordination or communication. The focus is on\nprincipled methods for a single agent to cooperate with others. This motivates\ninvestigating the ad hoc teamwork problem in the context of individual decision\nmaking frameworks. However, individual decision making in multiagent settings\nfaces the task of having to reason about other agents' actions, which in turn\ninvolves reasoning about others. An established approximation that\noperationalizes this approach is to bound the infinite nesting from below by\nintroducing level 0 models. We show that a consequence of the finitely-nested\nmodeling is that we may not obtain optimal team solutions in cooperative\nsettings. We address this limitation by including models at level 0 whose\nsolutions involve learning. We demonstrate that the learning integrated into\nplanning in the context of interactive dynamic influence diagrams facilitates\noptimal team behavior, and is applicable to ad hoc teamwork.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.0302v1"
    },
    {
        "title": "Modelling Electrical Car Diffusion Based on Agents",
        "authors": [
            "Lei Yu",
            "Tao Zhang",
            "Peer-Olaf Siebers",
            "Uwe Aickelin"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Replacing traditional fossil fuel vehicles with innovative zero-emission\nvehicles for the transport in ci ties is one of the major tactics to achieve\nthe UK government 2020 target of cutting emission. We are developing an\nagent-based simulation model to study the possible impact of different\ngovernmental interventions on the diffusion of such vehicles. Options that\ncould be studied with our what-if analysis to include things like car parking\ncharges, price of electrical car, energy awareness and word of mouth. In this\npaper we present a first case study related to the introduction of a new car\npark charging scheme at the University of Nottingham. We have developed an\nagent based model to simulate theimpact of different car parking rates and\nother incentives on the uptake of electrical cars. The goal of this case study\nis to demonstrate the usefulness of agent-based modelling and simulation for\nsuch investigations.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.0657v1"
    },
    {
        "title": "Comparing Stochastic Differential Equations and Agent-Based Modelling\n  and Simulation for Early-stage Cancer",
        "authors": [
            "Grazziela P Figueredo",
            "Peer-Olaf Siebers",
            "Markus R Owen",
            "Jenna Reps",
            "Uwe Aickelin"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  There is great potential to be explored regarding the use of agent-based\nmodelling and simulation as an alternative paradigm to investigate early-stage\ncancer interactions with the immune system. It does not suffer from some\nlimitations of ordinary differential equation models, such as the lack of\nstochasticity, representation of individual behaviours rather than aggregates\nand individual memory. In this paper we investigate the potential contribution\nof agent-based modelling and simulation when contrasted with stochastic\nversions of ODE models using early-stage cancer examples. We seek answers to\nthe following questions: (1) Does this new stochastic formulation produce\nsimilar results to the agent-based version? (2) Can these methods be used\ninterchangeably? (3) Do agent-based models outcomes reveal any benefit when\ncompared to the Gillespie results? To answer these research questions we\ninvestigate three well-established mathematical models describing interactions\nbetween tumour cells and immune elements. These case studies were\nre-conceptualised under an agent-based perspective and also converted to the\nGillespie algorithm formulation. Our interest in this work, therefore, is to\nestablish a methodological discussion regarding the usability of different\nsimulation approaches, rather than provide further biological insights into the\ninvestigated case studies. Our results show that it is possible to obtain\nequivalent models that implement the same mechanisms; however, the incapacity\nof the Gillespie algorithm to retain individual memory of past events affects\nthe similarity of some results. Furthermore, the emergent behaviour of ABMS\nproduces extra patters of behaviour in the system, which was not obtained by\nthe Gillespie algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.0758v1"
    },
    {
        "title": "Probabilistic Selection in AgentSpeak(L)",
        "authors": [
            "Francisco Coelho",
            "Vitor Nogueira"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Agent programming is mostly a symbolic discipline and, as such, draws little\nbenefits from probabilistic areas as machine learning and graphical models.\nHowever, the greatest objective of agent research is the achievement of\nautonomy in dynamical and complex environments --- a goal that implies\nembracing uncertainty and therefore the entailed representations, algorithms\nand techniques. This paper proposes an innovative and conflict free two layer\napproach to agent programming that uses already established methods and tools\nfrom both symbolic and probabilistic artificial intelligence. Moreover, this\nframework is illustrated by means of a widely used agent programming example,\nGoldMiners.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.3717v1"
    },
    {
        "title": "On the fundamental limitations of performance for distributed\n  decision-making in robotic networks",
        "authors": [
            "Federico Rossi",
            "Marco Pavone"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper studies fundamental limitations of performance for distributed\ndecision-making in robotic networks. The class of decision-making problems we\nconsider encompasses a number of prototypical problems such as average-based\nconsensus as well as distributed optimization, leader election, majority\nvoting, MAX, MIN, and logical formulas. We first propose a formal model for\ndistributed computation on robotic networks that is based on the concept of I/O\nautomata and is inspired by the Computer Science literature on distributed\ncomputing clusters. Then, we present a number of bounds on time, message, and\nbyte complexity, which we use to discuss the relative performance of a number\nof approaches for distributed decision-making. From a methodological\nstandpoint, our work sheds light on the relation between the tools developed by\nthe Computer Science and Controls communities on the topic of distributed\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.4863v1"
    },
    {
        "title": "Agent based simulation of the evolution of society as an alternate\n  maximization problem",
        "authors": [
            "Amartya Sanyal",
            "Sanjana Garg",
            "Asim Unmesh"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Understanding the evolution of human society, as a complex adaptive system,\nis a task that has been looked upon from various angles. In this paper, we\nsimulate an agent-based model with a high enough population tractably. To do\nthis, we characterize an entity called \\textit{society}, which helps us reduce\nthe complexity of each step from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n)$. We\npropose a very realistic setting, where we design a joint alternate\nmaximization step algorithm to maximize a certain \\textit{fitness} function,\nwhich we believe simulates the way societies develop. Our key contributions\ninclude (i) proposing a novel protocol for simulating the evolution of a\nsociety with cheap, non-optimal joint alternate maximization steps (ii)\nproviding a framework for carrying out experiments that adhere to this\njoint-optimization simulation framework (iii) carrying out experiments to show\nthat it makes sense empirically (iv) providing an alternate justification for\nthe use of \\textit{society} in the simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.01546v1"
    },
    {
        "title": "Effects of Network Structure on the Performance of a Modeled Traffic\n  Network under Drivers' Bounded Rationality",
        "authors": [
            "Toru Fujino",
            "Yu Chen"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We propose a minority route choice game to investigate the effect of the\nnetwork structure on traffic network performance under the assumption of\ndrivers' bounded rationality. We investigate ring-and-hub topologies to capture\nthe nature of traffic networks in cities, and employ a minority game-based\ninductive learning process to model the characteristic behavior under the route\nchoice scenario. Through numerical experiments, we find that topological\nchanges in traffic networks induce a phase transition from an uncongested phase\nto a congested phase. Understanding this phase transition is helpful in\nplanning new traffic networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.06492v1"
    },
    {
        "title": "A Survey of Learning in Multiagent Environments: Dealing with\n  Non-Stationarity",
        "authors": [
            "Pablo Hernandez-Leal",
            "Michael Kaisers",
            "Tim Baarslag",
            "Enrique Munoz de Cote"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The key challenge in multiagent learning is learning a best response to the\nbehaviour of other agents, which may be non-stationary: if the other agents\nadapt their strategy as well, the learning target moves. Disparate streams of\nresearch have approached non-stationarity from several angles, which make a\nvariety of implicit assumptions that make it hard to keep an overview of the\nstate of the art and to validate the innovation and significance of new works.\nThis survey presents a coherent overview of work that addresses\nopponent-induced non-stationarity with tools from game theory, reinforcement\nlearning and multi-armed bandits. Further, we reflect on the principle\napproaches how algorithms model and cope with this non-stationarity, arriving\nat a new framework and five categories (in increasing order of sophistication):\nignore, forget, respond to target models, learn models, and theory of mind. A\nwide range of state-of-the-art algorithms is classified into a taxonomy, using\nthese categories and key characteristics of the environment (e.g.,\nobservability) and adaptation behaviour of the opponents (e.g., smooth,\nabrupt). To clarify even further we present illustrative variations of one\ndomain, contrasting the strengths and limitations of each category. Finally, we\ndiscuss in which environments the different approaches yield most merit, and\npoint to promising avenues of future research.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.09183v2"
    },
    {
        "title": "A Self-Integration Testbed for Decentralized Socio-technical Systems",
        "authors": [
            "Farzam Fanitabasi",
            "Edward Gaere",
            "Evangelos Pournaras"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The Internet of Things comes along with new challenges for experimenting,\ntesting, and operating decentralized socio-technical systems at large-scale. In\nsuch systems, autonomous agents interact locally with their users, and remotely\nwith other agents to make intelligent collective choices. Via these\ninteractions they self-regulate the consumption and production of distributed\nresources. While such complex systems are often deployed and operated using\ncentralized computing infrastructures, the socio-technical nature of these\ndecentralized systems requires new value-sensitive design paradigms; empowering\ntrust, transparency, and alignment with citizens' social values, such as\nprivacy preservation, autonomy, and fairness among citizens' choices.\nCurrently, instruments and tools to study such systems and guide the\nprototyping process from simulation to live deployment are missing, or not\npractical in this distributed socio-technical context. This paper bridges this\ngap by introducing a novel testbed architecture for decentralized\nsocio-technical systems running on IoT. This new architecture is designed for a\nseamless reusability of (i) application-independent decentralized services by\nan IoT application, and (ii) different IoT applications by the same\ndecentralized service. This dual self-integration promises IoT applications\nthat are simpler to prototype, and can interoperate with decentralized services\nduring runtime to self-integrate more complex functionality. Such integration\nprovides stronger validation of IoT applications, and improves resource\nutilization. Pressure and crash tests during continuous operations of several\nweeks, with more than 80K network joining and leaving of agents, 2.4M parameter\nchanges, and 100M communicated messages, confirm the robustness and\npracticality of the testbed architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.02219v2"
    },
    {
        "title": "Social diversity and social preferences in mixed-motive reinforcement\n  learning",
        "authors": [
            "Kevin R. McKee",
            "Ian Gemp",
            "Brian McWilliams",
            "Edgar A. Duéñez-Guzmán",
            "Edward Hughes",
            "Joel Z. Leibo"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Recent research on reinforcement learning in pure-conflict and pure-common\ninterest games has emphasized the importance of population heterogeneity. In\ncontrast, studies of reinforcement learning in mixed-motive games have\nprimarily leveraged homogeneous approaches. Given the defining characteristic\nof mixed-motive games--the imperfect correlation of incentives between group\nmembers--we study the effect of population heterogeneity on mixed-motive\nreinforcement learning. We draw on interdependence theory from social\npsychology and imbue reinforcement learning agents with Social Value\nOrientation (SVO), a flexible formalization of preferences over group outcome\ndistributions. We subsequently explore the effects of diversity in SVO on\npopulations of reinforcement learning agents in two mixed-motive Markov games.\nWe demonstrate that heterogeneity in SVO generates meaningful and complex\nbehavioral variation among agents similar to that suggested by interdependence\ntheory. Empirical results in these mixed-motive dilemmas suggest agents trained\nin heterogeneous populations develop particularly generalized, high-performing\npolicies relative to those trained in homogeneous populations.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.02325v2"
    },
    {
        "title": "SPA: Verbal Interactions between Agents and Avatars in Shared Virtual\n  Environments using Propositional Planning",
        "authors": [
            "Andrew Best",
            "Sahil Narang",
            "Dinesh Manocha"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We present a novel approach for generating plausible verbal interactions\nbetween virtual human-like agents and user avatars in shared virtual\nenvironments. Sense-Plan-Ask, or SPA, extends prior work in propositional\nplanning and natural language processing to enable agents to plan with\nuncertain information, and leverage question and answer dialogue with other\nagents and avatars to obtain the needed information and complete their goals.\nThe agents are additionally able to respond to questions from the avatars and\nother agents using natural-language enabling real-time multi-agent multi-avatar\ncommunication environments.\n  Our algorithm can simulate tens of virtual agents at interactive rates\ninteracting, moving, communicating, planning, and replanning. We find that our\nalgorithm creates a small runtime cost and enables agents to complete their\ngoals more effectively than agents without the ability to leverage\nnatural-language communication. We demonstrate quantitative results on a set of\nsimulated benchmarks and detail the results of a preliminary user-study\nconducted to evaluate the plausibility of the virtual interactions generated by\nSPA. Overall, we find that participants prefer SPA to prior techniques in 84\\%\nof responses including significant benefits in terms of the plausibility of\nnatural-language interactions and the positive impact of those interactions.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03246v1"
    },
    {
        "title": "A Versatile Multi-Robot Monte Carlo Tree Search Planner for On-Line\n  Coverage Path Planning",
        "authors": [
            "Phillip Hyatt",
            "Zachary Brock",
            "Marc D. Killpack"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Mobile robots hold great promise in reducing the need for humans to perform\njobs such as vacuuming, seeding,harvesting, painting, search and rescue, and\ninspection. In practice, these tasks must often be done without an exact map of\nthe area and could be completed more quickly through the use of multiple robots\nworking together. The task of simultaneously covering and mapping an area with\nmultiple robots is known as multi-robot on-line coverage and is a growing area\nof research. Many multi-robot on-line coverage path planning algorithms have\nbeen developed as extensions of well established off-line coverage algorithms.\nIn this work we introduce a novel approach to multi-robot on-line coverage path\nplanning based on a method borrowed from game theory and machine learning-\nMonte Carlo Tree Search. We implement a Monte Carlo Tree Search planner and\ncompare completion times against a Boustrophedon-based on-line multi-robot\nplanner. The MCTS planner is shown to perform on par with the conventional\nBoustrophedon algorithm in simulations varying the number of robots and the\ndensity of obstacles in the map. The versatility of the MCTS planner is\ndemonstrated by incorporating secondary objectives such as turn minimization\nwhile performing the same coverage task. The versatility of the MCTS planner\nsuggests it is well suited to many multi-objective tasks that arise in mobile\nrobotics.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.04517v1"
    },
    {
        "title": "Learning Graph Influence from Social Interactions",
        "authors": [
            "Vincenzo Matta",
            "Virginia Bordignon",
            "Augusto Santos",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In social learning, agents form their opinions or beliefs about certain\nhypotheses by exchanging local information. This work considers the recent\nparadigm of weak graphs, where the network is partitioned into sending and\nreceiving components, with the former having the possibility of exerting a\ndomineering effect on the latter. Such graph structures are prevalent over\nsocial platforms. We will not be focusing on the direct social learning problem\n(which examines what agents learn), but rather on the dual or reverse learning\nproblem (which examines how agents learned). Specifically, from observations of\nthe stream of beliefs at certain agents, we would like to examine whether it is\npossible to learn the strength of the connections (influences) from sending\ncomponents in the network to these receiving agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.04946v1"
    },
    {
        "title": "R-MADDPG for Partially Observable Environments and Limited Communication",
        "authors": [
            "Rose E. Wang",
            "Michael Everett",
            "Jonathan P. How"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  There are several real-world tasks that would benefit from applying\nmultiagent reinforcement learning (MARL) algorithms, including the coordination\namong self-driving cars. The real world has challenging conditions for\nmultiagent learning systems, such as its partial observable and nonstationary\nnature. Moreover, if agents must share a limited resource (e.g. network\nbandwidth) they must all learn how to coordinate resource use. This paper\nintroduces a deep recurrent multiagent actor-critic framework (R-MADDPG) for\nhandling multiagent coordination under partial observable set-tings and limited\ncommunication. We investigate recurrency effects on performance and\ncommunication use of a team of agents. We demonstrate that the resulting\nframework learns time dependencies for sharing missing observations, handling\nresource limitations, and developing different communication patterns among\nagents.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.06684v2"
    },
    {
        "title": "Scalable Multi-Agent Inverse Reinforcement Learning via\n  Actor-Attention-Critic",
        "authors": [
            "Wonseok Jeon",
            "Paul Barde",
            "Derek Nowrouzezahrai",
            "Joelle Pineau"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Multi-agent adversarial inverse reinforcement learning (MA-AIRL) is a recent\napproach that applies single-agent AIRL to multi-agent problems where we seek\nto recover both policies for our agents and reward functions that promote\nexpert-like behavior. While MA-AIRL has promising results on cooperative and\ncompetitive tasks, it is sample-inefficient and has only been validated\nempirically for small numbers of agents -- its ability to scale to many agents\nremains an open question. We propose a multi-agent inverse RL algorithm that is\nmore sample-efficient and scalable than previous works. Specifically, we employ\nmulti-agent actor-attention-critic (MAAC) -- an off-policy multi-agent RL\n(MARL) method -- for the RL inner loop of the inverse RL procedure. In doing\nso, we are able to increase sample efficiency compared to state-of-the-art\nbaselines, across both small- and large-scale tasks. Moreover, the RL agents\ntrained on the rewards recovered by our method better match the experts than\nthose trained on the rewards derived from the baselines. Finally, our method\nrequires far fewer agent-environment interactions, particularly as the number\nof agents increases.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.10525v1"
    },
    {
        "title": "RMB-DPOP: Refining MB-DPOP by Reducing Redundant Inferences",
        "authors": [
            "Ziyu Chen",
            "Wenxin Zhang",
            "Yanchen Deng",
            "Dingding Chen",
            "Qing Li"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  MB-DPOP is an important complete algorithm for solving Distributed Constraint\nOptimization Problems (DCOPs) by exploiting a cycle-cut idea to implement\nmemory-bounded inference. However, each cluster root in the algorithm is\nresponsible for enumerating all the instantiations of its cycle-cut nodes,\nwhich would cause redundant inferences when its branches do not have the same\ncycle-cut nodes. Additionally, a large number of cycle-cut nodes and the\niterative nature of MB-DPOP further exacerbate the pathology. As a result,\nMB-DPOP could suffer from huge coordination overheads and cannot scale up well.\nTherefore, we present RMB-DPOP which incorporates several novel mechanisms to\nreduce redundant inferences and improve the scalability of MB-DPOP. First,\nusing the independence among the cycle-cut nodes in different branches, we\ndistribute the enumeration of instantiations into different branches whereby\nthe number of nonconcurrent instantiations reduces significantly and each\nbranch can perform memory bounded inference asynchronously. Then, taking the\ntopology into the consideration, we propose an iterative allocation mechanism\nto choose the cycle-cut nodes that cover a maximum of active nodes in a cluster\nand break ties according to their relative positions in a pseudo-tree. Finally,\na caching mechanism is proposed to further reduce unnecessary inferences when\nthe historical results are compatible with the current instantiations. We\ntheoretically show that with the same number of cycle-cut nodes RMB-DPOP\nrequires as many messages as MB-DPOP in the worst case and the experimental\nresults show our superiorities over the state-of-the-art.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.10641v1"
    },
    {
        "title": "Simulation of Real-time Routing for UAS traffic Management with\n  Communication and Airspace Safety Considerations",
        "authors": [
            "Zhao Jin",
            "Ziyi Zhao",
            "Chen Luo",
            "Franco Basti",
            "Adrian Solomon",
            "M. Cenk Gursoy",
            "Carlos Caicedo",
            "Qinru Qiu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Small Unmanned Aircraft Systems (sUAS) will be an important component of the\nsmart city and intelligent transportation environments of the near future. The\ndemand for sUAS related applications, such as commercial delivery and land\nsurveying, is expected to grow rapidly in next few years. In general, sUAS\ntraffic routing and management functions are needed to coordinate the launching\nof sUAS from different launch sites and determine their trajectories to avoid\nconflict while considering several other constraints such as expected arrival\ntime, minimum flight energy, and availability of communication resources.\nHowever, as the airborne sUAS density grows in a certain area, it is difficult\nto foresee the potential airspace and communications resource conflicts and\nmake immediate decisions to avoid them. To address this challenge, we present a\ntemporal and spatial routing algorithm and simulation platform for sUAS\ntrajectory management in a high density urban area that plans sUAS movements in\na spatial and temporal maze taking into account obstacles that are either\nstatic or dynamic in time. The routing allows the sUAS to avoid static no-fly\nareas (i.e. static obstacles) or other in-flight sUAS and areas that have\ncongested communication resources (i.e. dynamic obstacles). The algorithm is\nevaluated using an agent-based simulation platform. The simulation results show\nthat the proposed algorithm outperforms other route management algorithms in\nmany areas, especially in processing speed and memory efficiency. Detailed\ncomparisons are provided for the sUAS flight time, the overall throughput,\nconflict rate and communication resource utilization. The results demonstrate\nthat our proposed algorithm can be used to address the airspace and\ncommunication resource utilization needs for a next generation smart city and\nsmart transportation.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.11861v1"
    },
    {
        "title": "Learning Optimal Temperature Region for Solving Mixed Integer Functional\n  DCOPs",
        "authors": [
            "Saaduddin Mahmud",
            "Md. Mosaddek Khan",
            "Moumita Choudhury",
            "Long Tran-Thanh",
            "Nicholas R. Jennings"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Distributed Constraint Optimization Problems (DCOPs) are an important\nframework for modeling coordinated decision-making problems in multi-agent\nsystems with a set of discrete variables. Later works have extended DCOPs to\nmodel problems with a set of continuous variables, named Functional DCOPs\n(F-DCOPs). In this paper, we combine both of these frameworks into the Mixed\nInteger Functional DCOP (MIF-DCOP) framework that can deal with problems\nregardless of their variables' type. We then propose a novel algorithm $-$\nDistributed Parallel Simulated Annealing (DPSA), where agents cooperatively\nlearn the optimal parameter configuration for the algorithm while also solving\nthe given problem using the learned knowledge. Finally, we empirically evaluate\nour approach in DCOP, F-DCOP, and MIF-DCOP settings and show that DPSA produces\nsolutions of significantly better quality than the state-of-the-art non-exact\nalgorithms in their corresponding settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.12001v2"
    },
    {
        "title": "Distributed Local Linear Parameter Estimation using Gaussian SPAWN",
        "authors": [
            "Mei Leng",
            "Wee Peng Tay",
            "Tony Q. S. Quek",
            "Hyundong Shin"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We consider the problem of estimating local sensor parameters, where the\nlocal parameters and sensor observations are related through linear stochastic\nmodels. Sensors exchange messages and cooperate with each other to estimate\ntheir own local parameters iteratively. We study the Gaussian Sum-Product\nAlgorithm over a Wireless Network (gSPAWN) procedure, which is based on belief\npropagation, but uses fixed size broadcast messages at each sensor instead.\nCompared with the popular diffusion strategies for performing network parameter\nestimation, whose communication cost at each sensor increases with increasing\nnetwork density, the gSPAWN algorithm allows sensors to broadcast a message\nwhose size does not depend on the network size or density, making it more\nsuitable for applications in wireless sensor networks. We show that the gSPAWN\nalgorithm converges in mean and has mean-square stability under some technical\nsufficient conditions, and we describe an application of the gSPAWN algorithm\nto a network localization problem in non-line-of-sight environments. Numerical\nresults suggest that gSPAWN converges much faster in general than the diffusion\nmethod, and has lower communication costs, with comparable root mean square\nerrors.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3145v1"
    },
    {
        "title": "Adaptive event sensing in networks of autonomous mobile agents",
        "authors": [
            "Rodrigo R. Esch",
            "Fábio Protti",
            "Valmir C. Barbosa"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Given a connected region in two-dimensional space where events of a certain\nkind occur according to a certain time-varying density, we consider the problem\nof setting up a network of autonomous mobile agents to detect the occurrence of\nthose events and possibly record them in as effective a manner as possible. We\nassume that agents can communicate with one another wirelessly within a fixed\ncommunication radius, and moreover that initially no agent has any information\nregarding the event density. We introduce a new distributed algorithm for agent\ncontrol based on the notion of an execution mode, which essentially lets each\nagent roam the target region either at random or following its local view of a\ndensity-dependent gradient. Agents can switch back and forth between the two\nmodes, and the precise manner of such changes depends on the setting of various\nparameters that can be adjusted as a function of the application at hand. We\nprovide simulation results on some synthetic applications especially designed\nto highlight the algorithm's behavior relative to the possible execution modes.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.01310v1"
    },
    {
        "title": "Agent-Based Product Configuration: towards Generalized Consensus Seeking",
        "authors": [
            "Benoît Beroule",
            "Alain-Jérôme Fougères",
            "Egon Ostrosi"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper will present an evolution of a fuzzy agent based platform which\nperformed products configuration. As a first step, we used the notion of\nconsensus to establish robust results at the end of the configuration process.\nWe implemented the concept of generalized consensus which implied the\nconsideration of consensuses from the beginning, in this way robust data are\ntreated during the entire process and the final result enables the designer to\ndistinguish the robust components and flexible ones in a set of configurations.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.02796v1"
    },
    {
        "title": "Microsimulations of Arching, Clogging, and Bursty Exit Phenomena in\n  Crowd Dynamics",
        "authors": [
            "Francisco Enrique Vicente G. Castro",
            "Jaderick P. Pabico"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  We present in this paper the behavior of an artificial agent who is a member\nof a crowd. The behavior is based on the social comparison theory, as well as\nthe trajectory mapping towards an agent's goal considering the agent's field of\nvision. The crowd of artificial agents were able to exhibit arching, clogging,\nand bursty exit rates. We were also able to observe a new phenomenon we called\ndouble arching, which happens towards the end of the simulation, and whose\nonset is exhibited by a \"calm\" density graph within the exit passage. The\ndensity graph is usually bursty at this area. Because of these exhibited\nphenomena, we can use these agents with high confidence to perform\nmicrosimulation studies for modeling the behavior of humans and objects in very\nrealistic ways.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.07781v1"
    },
    {
        "title": "A Study on the Effect of Exit Widths and Crowd Sizes in the Formation of\n  Arch in Clogged Crowds",
        "authors": [
            "Francisco Enrique Vicente G. Castro",
            "Jaderick P. Pabico"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  The arching phenomenon is an emergent pattern formed by a $c$-sized crowd of\nintelligent, goal-oriented, autonomous, heterogeneous individuals moving\ntowards a $w$-wide exit along a long $W$-wide corridor, where $W>w$. We\ncollected empirical data from microsimulations to identify the combination\neffects of~$c$ and~$w$ to the time~$T$ of the onset of and the size~$S$ of the\nformation of the arch. The arch takes on the form of the perimeter of a half\nellipse halved along the minor axis. We measured the~$S$ with respect to the\nlengths of the major~$M$ and minor~$m$ axes of the ellipse, respectively. The\nmathematical description of the formation of this phenomenon will be an\nimportant information in the design of walkways to control and easily direct\nthe flow of large crowds, especially during panic egress conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.08133v1"
    },
    {
        "title": "Organic Computing in the Spotlight",
        "authors": [
            "Sven Tomforde",
            "Bernhard Sick",
            "Christian Müller-Schloer"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Organic Computing is an initiative in the field of systems engineering that\nproposed to make use of concepts such as self-adaptation and self-organisation\nto increase the robustness of technical systems. Based on the observation that\ntraditional design and operation concepts reach their limits, transferring more\nautonomy to the systems themselves should result in a reduction of complexity\nfor users, administrators, and developers. However, there seems to be a need\nfor an updated definition of the term \"Organic Computing\", of desired\nproperties of technical, organic systems, and the objectives of the Organic\nComputing initiative. With this article, we will address these points.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.08125v1"
    },
    {
        "title": "An applied spatial agent-based model of administrative boundaries using\n  SEAL",
        "authors": [
            "Bernardo Alves Furtado",
            "Isaque Daniel Eberhardt Rocha"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper extends and adapts an existing abstract model into an empirical\nmetropolitan region in Brazil. The model - named SEAL: a Spatial Economic\nAgent-based Lab - comprehends a framework to enable public policy ex-ante\nanalysis. The aim of the model is to use official data and municipalities\nspatial boundaries to allow for policy experimentation. The current version\nconsiders three markets: housing, labor and goods. Families' members age,\nconsume, join the labor market and trade houses. A single consumption tax is\ncollected by municipalities that invest back into quality of life improvements.\nWe test whether a single metropolitan government - which is an aggregation of\nmunicipalities - would be in the best interest of its citizens. Preliminary\nresults for 20 simulation runs indicate that it may be the case. Future\ndevelopments include improving performance to enable running of higher\npercentage of the population and a number of runs that make the model more\nrobust.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.03226v2"
    },
    {
        "title": "Safe Open-Loop Strategies for Handling Intermittent Communications in\n  Multi-Robot Systems",
        "authors": [
            "Siddharth Mayya",
            "Magnus Egerstedt"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In multi-robot systems where a central decision maker is specifying the\nmovement of each individual robot, a communication failure can severely impair\nthe performance of the system. This paper develops a motion strategy that\nallows robots to safely handle critical communication failures for such\nmulti-robot architectures. For each robot, the proposed algorithm computes a\ntime horizon over which collisions with other robots are guaranteed not to\noccur. These safe time horizons are included in the commands being transmitted\nto the individual robots. In the event of a communication failure, the robots\nexecute the last received velocity commands for the corresponding safe time\nhorizons leading to a provably safe open-loop motion strategy. The resulting\nalgorithm is computationally effective and is agnostic to the task that the\nrobots are performing. The efficacy of the strategy is verified in simulation\nas well as on a team of differential-drive mobile robots.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.03466v1"
    },
    {
        "title": "Multitask diffusion adaptation over networks with common latent\n  representations",
        "authors": [
            "Jie Chen",
            "Cédric Richard",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Online learning with streaming data in a distributed and collaborative manner\ncan be useful in a wide range of applications. This topic has been receiving\nconsiderable attention in recent years with emphasis on both single-task and\nmultitask scenarios. In single-task adaptation, agents cooperate to track an\nobjective of common interest, while in multitask adaptation agents track\nmultiple objectives simultaneously. Regularization is one useful technique to\npromote and exploit similarity among tasks in the latter scenario. This work\nexamines an alternative way to model relations among tasks by assuming that\nthey all share a common latent feature representation. As a result, a new\nmultitask learning formulation is presented and algorithms are developed for\nits solution in a distributed online manner. We present a unified framework to\nanalyze the mean-square-error performance of the adaptive strategies, and\nconduct simulations to illustrate the theoretical findings and potential\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.03614v1"
    },
    {
        "title": "Scalable Multiagent Coordination with Distributed Online Open Loop\n  Planning",
        "authors": [
            "Lenz Belzner",
            "Thomas Gabor"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We propose distributed online open loop planning (DOOLP), a general framework\nfor online multiagent coordination and decision making under uncertainty. DOOLP\nis based on online heuristic search in the space defined by a generative model\nof the domain dynamics, which is exploited by agents to simulate and evaluate\nthe consequences of their potential choices.\n  We also propose distributed online Thompson sampling (DOTS) as an effective\ninstantiation of the DOOLP framework. DOTS models sequences of agent choices by\nconcatenating a number of multiarmed bandits for each agent and uses Thompson\nsampling for dealing with action value uncertainty. The Bayesian approach\nunderlying Thompson sampling allows to effectively model and estimate\nuncertainty about (a) own action values and (b) other agents' behavior. This\napproach yields a principled and statistically sound solution to the\nexploration-exploitation dilemma when exploring large search spaces with\nlimited resources.\n  We implemented DOTS in a smart factory case study with positive empirical\nresults. We observed effective, robust and scalable planning and coordination\ncapabilities even when only searching a fraction of the potential search space.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07544v1"
    },
    {
        "title": "A decentralized algorithm for control of autonomous agents coupled by\n  feasibility constraints",
        "authors": [
            "Ugo Rosolia",
            "Francesco Braghin",
            "Andrew G. Alleyne",
            "Stijn De Bruyne",
            "Edoardo Sabbioni"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In this paper a decentralized control algorithm for systems composed of $N$\ndynamically decoupled agents, coupled by feasibility constraints, is presented.\nThe control problem is divided into $N$ optimal control sub-problems and a\ncommunication scheme is proposed to decouple computations. The derivative of\nthe solution of each sub-problem is used to approximate the evolution of the\nsystem allowing the algorithm to decentralize and parallelize computations. The\neffectiveness of the proposed algorithm is shown through simulations in a\ncooperative driving scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07934v1"
    },
    {
        "title": "Analysing Congestion Problems in Multi-agent Reinforcement Learning",
        "authors": [
            "Roxana Rădulescu",
            "Peter Vrancx",
            "Ann Nowé"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Congestion problems are omnipresent in today's complex networks and represent\na challenge in many research domains. In the context of Multi-agent\nReinforcement Learning (MARL), approaches like difference rewards and resource\nabstraction have shown promising results in tackling such problems. Resource\nabstraction was shown to be an ideal candidate for solving large-scale resource\nallocation problems in a fully decentralized manner. However, its performance\nand applicability strongly depends on some, until now, undocumented\nassumptions. Two of the main congestion benchmark problems considered in the\nliterature are: the Beach Problem Domain and the Traffic Lane Domain. In both\nsettings the highest system utility is achieved when overcrowding one resource\nand keeping the rest at optimum capacity. We analyse how abstract grouping can\npromote this behaviour and how feasible it is to apply this approach in a\nreal-world domain (i.e., what assumptions need to be satisfied and what\nknowledge is necessary). We introduce a new test problem, the Road Network\nDomain (RND), where the resources are no longer independent, but rather part of\na network (e.g., road network), thus choosing one path will also impact the\nload on other paths having common road segments. We demonstrate the application\nof state-of-the-art MARL methods for this new congestion model and analyse\ntheir performance. RND allows us to highlight an important limitation of\nresource abstraction and show that the difference rewards approach manages to\nbetter capture and inform the agents about the dynamics of the environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.08736v2"
    },
    {
        "title": "ALAN: Adaptive Learning for Multi-Agent Navigation",
        "authors": [
            "Julio Godoy",
            "Tiannan Chen",
            "Stephen J. Guy",
            "Ioannis Karamouzas",
            "Maria Gini"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In multi-agent navigation, agents need to move towards their goal locations\nwhile avoiding collisions with other agents and static obstacles, often without\ncommunication with each other. Existing methods compute motions that are\noptimal locally but do not account for the aggregated motions of all agents,\nproducing inefficient global behavior especially when agents move in a crowded\nspace. In this work, we develop methods to allow agents to dynamically adapt\ntheir behavior to their local conditions. We accomplish this by formulating the\nmulti-agent navigation problem as an action-selection problem, and propose an\napproach, ALAN, that allows agents to compute time-efficient and collision-free\nmotions. ALAN is highly scalable because each agent makes its own decisions on\nhow to move using a set of velocities optimized for a variety of navigation\ntasks. Experimental results show that the agents using ALAN, in general, reach\ntheir destinations faster than using ORCA, a state-of-the-art collision\navoidance framework, the Social Forces model for pedestrian navigation, and a\nPredictive collision avoidance model.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.04296v1"
    },
    {
        "title": "RAWSim-O: A Simulation Framework for Robotic Mobile Fulfillment Systems",
        "authors": [
            "Marius Merschformann",
            "Lin Xie",
            "Hanyi Li"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper deals with a new type of warehousing system, Robotic Mobile\nFulfillment Systems (RMFS). In such systems, robots are sent to carry storage\nunits, so-called \"pods\", from the inventory and bring them to human operators\nworking at stations. At the stations, the items are picked according to\ncustomers' orders. There exist new decision problems in such systems, for\nexample, the reallocation of pods after their visits at work stations or the\nselection of pods to fulfill orders. In order to analyze decision strategies\nfor these decision problems and relations between them, we develop a simulation\nframework called \"RAWSim-O\" in this paper. Moreover, we show a real-world\napplication of our simulation framework by integrating simple robot prototypes\nbased on vacuum cleaning robots.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.04726v2"
    },
    {
        "title": "Declarative vs Rule-based Control for Flocking Dynamics",
        "authors": [
            "Usama Mehmood",
            "Nicola Paoletti",
            "Dung Phan",
            "Radu Grosu",
            "Shan Lin",
            "Scott D. Stoller",
            "Ashish Tiwari",
            "Junxing Yang",
            "Scott A. Smolka"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The popularity of rule-based flocking models, such as Reynolds' classic\nflocking model, raises the question of whether more declarative flocking models\nare possible. This question is motivated by the observation that declarative\nmodels are generally simpler and easier to design, understand, and analyze than\noperational models. We introduce a very simple control law for flocking based\non a cost function capturing cohesion (agents want to stay together) and\nseparation (agents do not want to get too close). We refer to it as {\\textit\ndeclarative flocking} (DF). We use model-predictive control (MPC) to define\ncontrollers for DF in centralized and distributed settings. A thorough\nperformance comparison of our declarative flocking with Reynolds' model, and\nwith more recent flocking models that use MPC with a cost function based on\nlattice structures, demonstrate that DF-MPC yields the best cohesion and least\nfragmentation, and maintains a surprisingly good level of geometric regularity\nwhile still producing natural flock shapes similar to those produced by\nReynolds' model. We also show that DF-MPC has high resilience to sensor noise.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.10013v1"
    },
    {
        "title": "Investigating the effect of social groups in uni-directional pedestrian\n  flow",
        "authors": [
            "Luca Crociani",
            "Yiping Zeng",
            "Andrea Gorrini",
            "Giuseppe Vizzari",
            "Weiguo Song"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The influence of cohesion among members of dyads is investigated in scenarios\ncharacterized by uni-directional flow by means of a discrete model: a corridor\nand the egress from a room with a bottleneck of varying width are simulated.\nThe model manages the dynamics of simulated group members with an adaptive\nmechanism, balancing the probability of movement according to the dispersion of\nthe group; the cohesion mechanism is calibrated through the parameters\n$\\kappa_c$ and $\\delta$. All scenarios are simulated with two procedures:\n(Proc. 1) population composed of individual pedestrians, in order to validate\nthe simulation model and to provide baseline data; (Proc. 2) population\nincluding dyads (50% of the simulated pedestrians), in order to verify their\nimpact. In the corridor scenario, the presence of dyads causes a reduction of\nthe velocities and specific flow at medium-high densities. Egress from a square\nroom with a unique central exit produces results in line with recent studies in\nthe literature, but also shows that the dyads negatively affect the dynamics,\nleading generally to a slower walking speed and a lower pedestrian flow.\nIgnoring the presence of dyads would lead to an overestimation of egress flows.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.11460v1"
    },
    {
        "title": "Multiple Drones driven Hexagonally Partitioned Area Exploration:\n  Simulation and Evaluation",
        "authors": [
            "Ayush Datta",
            "Rahul Tallamraju",
            "Kamalakar Karlapalem"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we simulated a distributed, cooperative path planning\ntechnique for multiple drones (~200) to explore an unknown region (~10,000\nconnected units) in the presence of obstacles. The map of an unknown region is\ndynamically created based on the information obtained from sensors and other\ndrones. The unknown area is considered a connected region made up of hexagonal\nunit cells. These cells are grouped to form larger cells called sub-areas. We\nuse long range and short range communication. The short-range communication\nwithin drones in smaller proximity helps avoid re-exploration of cells already\nexplored by companion drones located in the same subarea. The long-range\ncommunication helps drones identify next subarea to be targeted based on\nweighted RNN (Reverse nearest neighbor). Simulation results show that weighted\nRNN in a hexagonal representation makes exploration more efficient, scalable\nand resilient to communication failures.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.00401v2"
    },
    {
        "title": "Maximizing Energy Battery Efficiency in Swarm Robotics",
        "authors": [
            "Anthony Chen",
            "John Harwell",
            "Maria Gini"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Miniaturization and cost, two of the main attractive factors of swarm\nrobotics, have motivated its use as a solution in object collecting tasks,\nsearch & rescue missions, and other applications. However, in the current\nliterature only a few papers consider energy allocation efficiency within a\nswarm. Generally, robots recharge to their maximum level every time\nunconditionally, and do not incorporate estimates of the energy needed for\ntheir next task. In this paper we present an energy efficiency maximization\nmethod that minimizes the overall energy cost within a swarm while\nsimultaneously maximizing swarm performance on an object gathering task. The\nmethod utilizes dynamic thresholds for upper and lower battery limits. This\nmethod has also shown to improve the efficiency of existing energy management\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.01957v1"
    },
    {
        "title": "Deep learning control of artificial avatars in group coordination tasks",
        "authors": [
            "Maria Lombardi",
            "Davide Liuzza",
            "Mario di Bernardo"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In many joint-action scenarios, humans and robots have to coordinate their\nmovements to accomplish a given shared task. Lifting an object together, sawing\na wood log, transferring objects from a point to another are all examples where\nmotor coordination between humans and machines is a crucial requirement. While\nthe dyadic coordination between a human and a robot has been studied in\nprevious investigations, the multi-agent scenario in which a robot has to be\nintegrated into a human group still remains a less explored field of research.\nIn this paper we discuss how to synthesise an artificial agent able to\ncoordinate its motion in human ensembles. Driven by a control architecture\nbased on deep reinforcement learning, such an artificial agent will be able to\nautonomously move itself in order to synchronise its motion with that of the\ngroup while exhibiting human-like kinematic features. As a paradigmatic\ncoordination task we take a group version of the so-called mirror-game which is\nhighlighted as a good benchmark in the human movement literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.04656v1"
    },
    {
        "title": "Extending Eigentrust with the Max-Plus Algebra",
        "authors": [
            "Juan Afanador",
            "Maria Araujo",
            "Murilo Baptista",
            "Nir Oren"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Eigentrust is a simple and widely used algorithm, which quantifies trust\nbased on the repeated application of an update matrix to a vector of initial\ntrust values. In some cases, however, this procedure is rendered uninformative.\nHere, we characterise such situations and trace their origin to the algebraic\nconditions guaranteeing the convergence of the Power Method. We overcome the\nidentified limitations by extending Eigentrust's core ideas into the Max-Plus\nAlgebra. The empirical evaluation of our max-plus approach demonstrates\nimprovements over Eigentrust.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.05793v1"
    },
    {
        "title": "Traffic Management Strategies for Multi-Robotic Rigid Payload Transport\n  Systems",
        "authors": [
            "Yahnit Sirineni",
            "Pulkit Verma",
            "Kamalakar Karlapalem"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this work, we address traffic management of multiple payload transport\nsystems comprising of non-holonomic robots. We consider loosely coupled rigid\nrobot formations carrying a payload from one place to another. Each payload\ntransport system (PTS) moves in various kinds of environments with obstacles.\nWe ensure each PTS completes its given task by avoiding collisions with other\npayload systems and obstacles as well. Each PTS has one leader and multiple\nfollowers and the followers maintain a desired distance and angle with respect\nto the leader using a decentralized leader-follower control architecture while\nmoving in the traffic. We showcase, through simulations the time taken by each\nPTS to traverse its respective trajectory with and without other PTS and\nobstacles. We show that our strategies help manage the traffic for a large\nnumber of PTS moving from one place to another.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.11452v1"
    },
    {
        "title": "Adaptation and learning over networks under subspace constraints -- Part\n  II: Performance Analysis",
        "authors": [
            "Roula Nassif",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Part I of this paper considered optimization problems over networks where\nagents have individual objectives to meet, or individual parameter vectors to\nestimate, subject to subspace constraints that require the objectives across\nthe network to lie in low-dimensional subspaces. Starting from the centralized\nprojected gradient descent, an iterative and distributed solution was proposed\nthat responds to streaming data and employs stochastic approximations in place\nof actual gradient vectors, which are generally unavailable. We examined the\nsecond-order stability of the learning algorithm and we showed that, for small\nstep-sizes $\\mu$, the proposed strategy leads to small estimation errors on the\norder of $\\mu$. This Part II examines steady-state performance. The results\nreveal explicitly the influence of the gradient noise, data characteristics,\nand subspace constraints, on the network performance. The results also show\nthat in the small step-size regime, the iterates generated by the distributed\nalgorithm achieve the centralized steady-state performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.12250v1"
    },
    {
        "title": "Needs-driven Heterogeneous Multi-Robot Cooperation in Rescue Missions",
        "authors": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper focuses on the teaming aspects and the role of heterogeneity in a\nmulti-robot system applied to robot-aided urban search and rescue (USAR)\nmissions. We propose a needs-driven multi-robot cooperation mechanism\nrepresented through a Behavior Tree structure and evaluate the system's\nperformance in terms of the group utility and energy cost to achieve the rescue\nmission in a limited time. From the theoretical analysis, we prove that the\nneeds-driven cooperation in a heterogeneous robot system enables higher group\nutility than a homogeneous robot system. We also perform simulation experiments\nto verify the proposed needs-driven collaboration and show that the\nheterogeneous multi-robot cooperation can achieve better performance and\nincrease system robustness by reducing uncertainty in task execution. Finally,\nwe discuss the application to human-robot teaming.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.00288v2"
    },
    {
        "title": "Resilient Task Allocation in Heterogeneous Multi-Robot Systems",
        "authors": [
            "Siddharth Mayya",
            "Diego S. D'antonio",
            "David Saldaña",
            "Vijay Kumar"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  For a multi-robot system equipped with heterogeneous capabilities, this paper\npresents a mechanism to allocate robots to tasks in a resilient manner when\nanomalous environmental conditions such as weather events or adversarial\nattacks affect the performance of robots within the tasks. Our primary\nobjective is to ensure that each task is assigned the requisite level of\nresources, measured as the aggregated capabilities of the robots allocated to\nthe task. By keeping track of task performance deviations under external\nperturbations, our framework quantifies the extent to which robot capabilities\n(e.g., visual sensing or aerial mobility) are affected by environmental\nconditions. This enables an optimization-based framework to flexibly reallocate\nrobots to tasks based on the most degraded capabilities within each task. In\nthe face of resource limitations and adverse environmental conditions, our\nalgorithm minimally relaxes the resource constraints corresponding to some\ntasks, thus exhibiting a graceful degradation of performance. Simulated\nexperiments in a multi-robot coverage and target tracking scenario demonstrate\nthe efficacy of the proposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.04593v2"
    },
    {
        "title": "SkyTrakx: A Toolkit for Simulation and Verification of Unmanned\n  Air-Traffic Management Systems (Extended Version)",
        "authors": [
            "Chiao Hsieh",
            "Hussein Sibai",
            "Hebron Taylor",
            "Yifeng Ni",
            "Sayan Mitra"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The key concept for safe and efficient traffic management for Unmanned\nAircraft Systems (UAS) is the notion of operation volume (OV). An OV is a\n4-dimensional block of airspace and time, which can express an aircraft's\nintent, and can be used for planning, de-confliction, and traffic management.\nWhile there are several high-level simulators for UAS Traffic Management (UTM),\nwe are lacking a framework for creating, manipulating, and reasoning about OVs\nfor heterogeneous air vehicles. In this paper, we address this and present\nSkyTrakx -- a software toolkit for simulation and verification of UTM scenarios\nbased on OVs. First, we illustrate a use case of SkyTrakx by presenting a\nspecific air traffic coordination protocol. This protocol communicates OVs\nbetween participating aircraft and an airspace manager for traffic routing. We\nshow how existing formal verification tools, Dafny and Dione, can assist in\nautomatically checking key properties of the protocol. Second, we show how the\nOVs can be computed for heterogeneous air vehicles like quadcopters and\nfixed-wing aircraft using another verification technique, namely reachability\nanalysis. Finally, we show that SkyTrakx can be used to simulate complex\nscenarios involving heterogeneous vehicles, for testing and performance\nevaluation in terms of workload and response delays analysis. Our experiments\ndelineate the trade-off between performance and workload across different\nstrategies for generating OVs.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.04655v3"
    },
    {
        "title": "Learnable Strategies for Bilateral Agent Negotiation over Multiple\n  Issues",
        "authors": [
            "Pallavi Bagga",
            "Nicola Paoletti",
            "Kostas Stathis"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We present a novel bilateral negotiation model that allows a self-interested\nagent to learn how to negotiate over multiple issues in the presence of user\npreference uncertainty. The model relies upon interpretable strategy templates\nrepresenting the tactics the agent should employ during the negotiation and\nlearns template parameters to maximize the average utility received over\nmultiple negotiations, thus resulting in optimal bid acceptance and generation.\nOur model also uses deep reinforcement learning to evaluate threshold utility\nvalues, for those tactics that require them, thereby deriving optimal utilities\nfor every environment state. To handle user preference uncertainty, the model\nrelies on a stochastic search to find user model that best agrees with a given\npartial preference profile. Multi-objective optimization and multi-criteria\ndecision-making methods are applied at negotiation time to generate\nPareto-optimal outcomes thereby increasing the number of successful (win-win)\nnegotiations. Rigorous experimental evaluations show that the agent employing\nour model outperforms the winning agents of the 10th Automated Negotiating\nAgents Competition (ANAC'19) in terms of individual as well as social-welfare\nutilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.08302v2"
    },
    {
        "title": "Sense-Deliberate-Act Cognitive Agents for Sense-Compute-Control\n  Applications in the Internet of Things & Services",
        "authors": [
            "Armin Moin"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, we advocate Agent-Oriented Software Engi-neering (AOSE)\nthrough employing Belief-Desire-Intention (BDI) intel-ligent agents for\ndeveloping Sense-Compute-Control (SCC) applications in the Internet of Things\nand Services (IoTS). We argue that not only the agent paradigm, in general, but\nalso cognitive BDI agents with sense-deliberate-act cycle, in particular, fit\nvery well to the nature of SCC applications in the IoTS. However, considering\nthe highly constrained heterogeneous devices that are prevalent in the IoTS,\nexisting BDI agent frameworks, even those especially created for Wireless\nSensor Networks (WSNs), do not work. We elaborate on the challenges and propose\npos-sible approaches to address them.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.10638v1"
    },
    {
        "title": "An Overview on Optimal Flocking",
        "authors": [
            "Logan E. Beaver",
            "Andreas A. Malikopoulos"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The study of robotic flocking has received considerable attention in the past\ntwenty years. As we begin to deploy flocking control algorithms on physical\nmulti-agent and swarm systems, there is an increasing necessity for rigorous\npromises on safety and performance. In this paper, we present an overview the\nliterature focusing on optimization approaches to achieve flocking behavior\nthat provide strong safety guarantees. We separate the literature into cluster\nand line flocking, and categorize cluster flocking with respect to the\nsystem-level objective, which may be realized by a reactive or planning control\nalgorithm. We also categorize the line flocking literature by the energy-saving\nmechanism that is exploited by the agents. We present several approaches aimed\nat minimizing the communication and computational requirements in real systems\nvia neighbor filtering and event-driven planning, and conclude with our\nperspective on the outlook and future research direction of optimal flocking as\na field.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.14279v2"
    },
    {
        "title": "On Location Hiding in Distributed Systems",
        "authors": [
            "Karol Gotfryd",
            "Marek Klonowski",
            "Dominik Pająk"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We consider the following problem - a group of mobile agents perform some\ntask on a terrain modeled as a graph. In a given moment of time an adversary\ngets an access to the graph and positions of the agents. Shortly before\nadversary's observation the mobile agents have a chance to relocate themselves\nin order to hide their initial configuration. We assume that the initial\nconfiguration may possibly reveal to the adversary some information about the\ntask they performed. Clearly agents have to change their location in possibly\nshort time using minimal energy. In our paper we introduce a definition of a\n\\emph{well hiding} algorithm in which the starting and final configurations of\nthe agents have small mutual information. Then we discuss the influence of\nvarious features of the model on the running time of the optimal well-hiding\nalgorithm. We show that if the topology of the graph is known to the agents,\nthen the number of steps proportional to the diameter of the graph is\nsufficient and necessary. In the unknown topology scenario we only consider a\nsingle agent case. We first show that the task is impossible in the\ndeterministic case if the agent has no memory. Then we present a polynomial\nrandomized algorithm. Finally in the model with memory we show that the number\nof steps proportional to the number of edges of the graph is sufficient and\nnecessary. In some sense we investigate how complex is the problem of \"losing\"\ninformation about location (both physical and logical) for different settings.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.04211v1"
    },
    {
        "title": "A Scalable and Adaptable Multiple-Place Foraging Algorithm for\n  Ant-Inspired Robot Swarms",
        "authors": [
            "Qi Lu",
            "Melanie E. Moses",
            "Joshua P. Hecker"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Individual robots are not effective at exploring large unmapped areas. An\nalternate approach is to use a swarm of simple robots that work together,\nrather than a single highly capable robot. The central-place foraging algorithm\n(CPFA) is effective for coordinating robot swarm search and collection tasks.\nRobots start at a centrally placed location (nest), explore potential targets\nin the area without global localization or central control, and return the\ntargets to the nest. The scalability of the CPFA is limited because large\nnumbers of robots produce more inter-robot collisions and large search areas\nresult in substantial travel costs. We address these problems with the\nmultiple-place foraging algorithm (MPFA), which uses multiple nests distributed\nthroughout the search area. Robots start from a randomly assigned home nest but\nreturn to the closest nest with found targets. We simulate the foraging\nbehavior of robot swarms in the robot simulator ARGoS and employ a genetic\nalgorithm to discover different optimized foraging strategies as swarm sizes\nand the number of targets are scaled up. In our experiments, the MPFA always\nproduces higher foraging rates, fewer collisions, and lower travel and search\ntime compared to the CPFA for the partially clustered targets distribution. The\nmain contribution of this paper is that we systematically quantify the\nadvantages of the MPFA (reduced travel time and collisions), the potential\ndisadvantages (less communication among robots), and the ability of a genetic\nalgorithm to tune MPFA parameters to mitigate search inefficiency due to less\ncommunication.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.00480v1"
    },
    {
        "title": "A Model of Multi-Agent Consensus for Vague and Uncertain Beliefs",
        "authors": [
            "Michael Crosscombe",
            "Jonathan Lawry"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Consensus formation is investigated for multi-agent systems in which agents'\nbeliefs are both vague and uncertain. Vagueness is represented by a third truth\nstate meaning \\emph{borderline}. This is combined with a probabilistic model of\nuncertainty. A belief combination operator is then proposed which exploits\nborderline truth values to enable agents with conflicting beliefs to reach a\ncompromise. A number of simulation experiments are carried out in which agents\napply this operator in pairwise interactions, under the bounded confidence\nrestriction that the two agents' beliefs must be sufficiently consistent with\neach other before agreement can be reached. As well as studying the consensus\noperator in isolation we also investigate scenarios in which agents are\ninfluenced either directly or indirectly by the state of the world. For the\nformer we conduct simulations which combine consensus formation with belief\nupdating based on evidence. For the latter we investigate the effect of\nassuming that the closer an agent's beliefs are to the truth the more visible\nthey are in the consensus building process. In all cases applying the consensus\noperators results in the population converging to a single shared belief which\nis both crisp and certain. Furthermore, simulations which combine consensus\nformation with evidential updating converge faster to a shared opinion which is\ncloser to the actual state of the world than those in which beliefs are only\nchanged as a result of directly receiving new evidence. Finally, if agent\ninteractions are guided by belief quality measured as similarity to the true\nstate of the world, then applying the consensus operator alone results in the\npopulation converging to a high quality shared belief.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.03433v2"
    },
    {
        "title": "Algorithms for Graph-Constrained Coalition Formation in the Real World",
        "authors": [
            "Filippo Bistaffa",
            "Alessandro Farinelli",
            "Jesús Cerquides",
            "Juan A. Rodríguez-Aguilar",
            "Sarvapali D. Ramchurn"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Coalition formation typically involves the coming together of multiple,\nheterogeneous, agents to achieve both their individual and collective goals. In\nthis paper, we focus on a special case of coalition formation known as\nGraph-Constrained Coalition Formation (GCCF) whereby a network connecting the\nagents constrains the formation of coalitions. We focus on this type of problem\ngiven that in many real-world applications, agents may be connected by a\ncommunication network or only trust certain peers in their social network. We\npropose a novel representation of this problem based on the concept of edge\ncontraction, which allows us to model the search space induced by the GCCF\nproblem as a rooted tree. Then, we propose an anytime solution algorithm\n(CFSS), which is particularly efficient when applied to a general class of\ncharacteristic functions called $m+a$ functions. Moreover, we show how CFSS can\nbe efficiently parallelised to solve GCCF using a non-redundant partition of\nthe search space. We benchmark CFSS on both synthetic and realistic scenarios,\nusing a real-world dataset consisting of the energy consumption of a large\nnumber of households in the UK. Our results show that, in the best case, the\nserial version of CFSS is 4 orders of magnitude faster than the state of the\nart, while the parallel version is 9.44 times faster than the serial version on\na 12-core machine. Moreover, CFSS is the first approach to provide anytime\napproximate solutions with quality guarantees for very large systems of agents\n(i.e., with more than 2700 agents).\n",
        "pdf_link": "http://arxiv.org/pdf/1612.04299v1"
    },
    {
        "title": "Agent-based Model for Spot and Balancing Electricity Markets",
        "authors": [
            "Florian Kühnlenz",
            "Pedro H. J. Nardelli"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We present a simple, yet realistic, agent-based model of an electricity\nmarket. The proposed model combines the spot and balancing markets with a\nresolution of one minute, which enables a more accurate depiction of the\nphysical properties of the power grid. As a test, we compare the results\nobtained from our simulation to data from Nord Pool.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.04512v1"
    },
    {
        "title": "A Hybrid Network/Grid Model of Urban Morphogenesis and Optimization",
        "authors": [
            "Juste Raimbault",
            "Arnaud Banos",
            "René Doursat"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We describe a hybrid agent-based model and simulation of urban morphogenesis.\nIt consists of a cellular automata grid coupled to a dynamic network topology.\nThe inherently heterogeneous properties of urban structure and function are\ntaken into account in the dynamics of the system. We propose various layout and\nperformance measures to categorize and explore the generated configurations. An\neconomic evaluation metric was also designed using the sensitivity of\nsegregation models to spatial configuration. Our model is applied to a\nreal-world case, offering a means to optimize the distribution of activities in\na zoning context.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.08552v1"
    },
    {
        "title": "An Ontology to Support Collective Intelligence in Decentralised\n  Multi-Robot Systems",
        "authors": [
            "Pragna Das",
            "Vincent Hilaire",
            "Lluis Ribas-Xirgo"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In most multi-robot systems, conditions of the floor, battery and mechanical\nparts are important and impact cost-efficiency. The costs are generally\ninterpreted through performance times. The relation between performance times\nandthese factors are not directly derivable, though, performance time has a\ndirect correlation with discharge of batteries. Inroute planning, travel time\nof an edge is the performance time and may be required to be estimated for\nmultiple times.These estimated travel times are different than heuristics costs\nas they depict the real states which are impossible toknow from heuristics.\nThis facilitates path planning algorithms to choose the edges with least real\ntravel times or coststo form the path. Nevertheless, a good estimation is\ndependent on historical data which are close in time. But, there aresituations\nwhen all the travel times for one or more edge(s) are not available for the\nentire duration of operation of theMRS to an individual robot. Then, it is\nimperative for that robot to gather the necessary travel times from others\ninthe system as a reference observation. The mechanism of information sharing\nbetween one robot to others in the systemhas been devised in a form of a common\nontology-based knowledge. This ontology helps to fetch and share\ninformationforming a collective knowledge base facilitating a comprehensive\ncontrol and planning for the system. This greatly helpsthe MR to estimate\ntravel times more accurately and precisely. Also, accurate estimation affects\nroute planning to bemore precise with reduced cost. The total cost of paths\ngenerated through the travel times estimated through sharingis 40% less on\naverage than that of paths generated through travel times without sharing.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.00367v1"
    },
    {
        "title": "Accuracy Analysis for Distributed Weighted Least-Squares Estimation in\n  Finite Steps and Loopy Networks",
        "authors": [
            "Tianju Sui",
            "Damián Marelli",
            "Minyue Fu",
            "Renquan Lu"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Distributed parameter estimation for large-scale systems is an active\nresearch problem. The goal is to derive a distributed algorithm in which each\nagent obtains a local estimate of its own subset of the global parameter\nvector, based on local measurements as well as information received from its\nneighbours. A recent algorithm has been proposed, which yields the optimal\nsolution (i.e., the one that would be obtained using a centralized method) in\nfinite time, provided the communication network forms an acyclic graph. If\ninstead, the graph is cyclic, the only available alternative algorithm, which\nis based on iterative matrix inversion, achieving the optimal solution, does so\nasymptotically. However, it is also known that, in the cyclic case, the\nalgorithm designed for acyclic graphs produces a solution which, although non\noptimal, is highly accurate. In this paper we do a theoretical study of the\naccuracy of this algorithm, in communication networks forming cyclic graphs. To\nthis end, we provide bounds for the sub-optimality of the estimation error and\nthe estimation error covariance, for a class of systems whose topological\nsparsity and signal-to-noise ratio satisfy certain condition. Our results show\nthat, at each node, the accuracy improves exponentially with the so-called\nloop-free depth. Also, although the algorithm no longer converges in finite\ntime in the case of cyclic graphs, simulation results show that the convergence\nis significantly faster than that of methods based on iterative matrix\ninversion. Our results suggest that, depending on the loop-free depth, the\nstudied algorithm may be the preferred option even in applications with cyclic\ncommunication graphs.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.09104v1"
    },
    {
        "title": "ACSEE: Antagonistic Crowd Simulation Model with Emotional Contagion and\n  Evolutionary Game Theory",
        "authors": [
            "Chaochao Li",
            "Pei Lv",
            "Dinesh Manocha",
            "Hua Wang",
            "Yafei Li",
            "Bing Zhou",
            "Mingliang Xu"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Antagonistic crowd behaviors are often observed in cases of serious conflict.\nAntagonistic emotions, which is the typical psychological state of agents in\ndifferent roles (i.e. cops, activists, and civilians) in crowd violent scenes,\nand the way they spread through contagion in a crowd are important causes of\ncrowd antagonistic behaviors. Moreover, games, which refers to the interaction\nbetween opposing groups adopting different strategies to obtain higher benefits\nand less casualties, determine the level of crowd violence. We present an\nantagonistic crowd simulation model, ACSEE, which is integrated with\nantagonistic emotional contagion and evolutionary game theories. Our approach\nmodels the antagonistic emotions between agents in different roles using two\ncomponents: mental emotion and external emotion. We combine enhanced\nsusceptible-infectious-susceptible (SIS) and game approaches to evaluate the\nrole of antagonistic emotional contagion in crowd violence. Our evolutionary\ngame theoretic approach incorporates antagonistic emotional contagion through\ndeterrent force, which is modelled by a mixture of emotional forces and\nphysical forces defeating the opponents. Antagonistic emotional contagion and\nevolutionary game theories influence each other to determine antagonistic crowd\nbehaviors. We evaluate our approach on real-world scenarios consisting of\ndifferent kinds of agents. We also compare the simulated crowd behaviors with\nreal-world crowd videos and use our approach to predict the trends of crowd\nmovements in violence incidents. We investigate the impact of various factors\n(number of agents, emotion, strategy, etc.) on the outcome of crowd violence.\nWe present results from user studies suggesting that our model can simulate\nantagonistic crowd behaviors similar to those seen in real-world scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.00380v3"
    },
    {
        "title": "Agent-Based Simulation Modelling for Reflecting on Consequences of\n  Digital Mental Health",
        "authors": [
            "Daniel Stroud",
            "Christian Wagner",
            "Peer-Olaf Siebers"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The premise of this working paper is based around agent-based simulation\nmodels and how to go about creating them from given incomplete information.\nAgent-based simulations are stochastic simulations that revolve around groups\nof agents that each have their own characteristics and can make decisions. Such\nsimulations can be used to emulate real life situations and to create\nhypothetical situations without the need for real-world testing prior. Here we\ndescribe the development of an agent-based simulation model for studying future\ndigital mental health scenarios. An incomplete conceptual model has been used\nas the basis for this development. To define differences in responses to\nstimuli we employed fuzzy decision making logic. The model has been implemented\nbut not been used for structured experimentation yet. This is planned as our\nnext step.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.01642v1"
    },
    {
        "title": "Partner Selection for the Emergence of Cooperation in Multi-Agent\n  Systems Using Reinforcement Learning",
        "authors": [
            "Nicolas Anastassacos",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Social dilemmas have been widely studied to explain how humans are able to\ncooperate in society. Considerable effort has been invested in designing\nartificial agents for social dilemmas that incorporate explicit agent\nmotivations that are chosen to favor coordinated or cooperative responses. The\nprevalence of this general approach points towards the importance of achieving\nan understanding of both an agent's internal design and external environment\ndynamics that facilitate cooperative behavior. In this paper, we investigate\nhow partner selection can promote cooperative behavior between agents who are\ntrained to maximize a purely selfish objective function. Our experiments reveal\nthat agents trained with this dynamic learn a strategy that retaliates against\ndefectors while promoting cooperation with other agents resulting in a\nprosocial society.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.03185v4"
    },
    {
        "title": "Anytime Heuristic for Weighted Matching Through Altruism-Inspired\n  Behavior",
        "authors": [
            "Panayiotis Danassis",
            "Aris Filos-Ratsikas",
            "Boi Faltings"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We present a novel anytime heuristic (ALMA), inspired by the human principle\nof altruism, for solving the assignment problem. ALMA is decentralized,\ncompletely uncoupled, and requires no communication between the participants.\nWe prove an upper bound on the convergence speed that is polynomial in the\ndesired number of resources and competing agents per resource; crucially, in\nthe realistic case where the aforementioned quantities are bounded\nindependently of the total number of agents/resources, the convergence time\nremains constant as the total problem size increases.\n  We have evaluated ALMA under three test cases: (i) an anti-coordination\nscenario where agents with similar preferences compete over the same set of\nactions, (ii) a resource allocation scenario in an urban environment, under a\nconstant-time constraint, and finally, (iii) an on-line matching scenario using\nreal passenger-taxi data. In all of the cases, ALMA was able to reach high\nsocial welfare, while being orders of magnitude faster than the centralized,\noptimal algorithm. The latter allows our algorithm to scale to realistic\nscenarios with hundreds of thousands of agents, e.g., vehicle coordination in\nurban environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.09359v1"
    },
    {
        "title": "An Elo-based rating system for TopCoder SRM",
        "authors": [
            "Fred Batty",
            "Dmitry Kamenetsky"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We present an Elo-based rating system for programming contests. We justify a\ndefinition of performance using the logarithm of a player's rank. We apply the\ndefinition to rating TopCoder SRM. We improve the accuracy, guided by\nexperimental results. We compare results with SRM ratings.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.00961v6"
    },
    {
        "title": "Teaching on a Budget in Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Ercüment İlhan",
            "Jeremy Gow",
            "Diego Perez-Liebana"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Deep Reinforcement Learning (RL) algorithms can solve complex sequential\ndecision tasks successfully. However, they have a major drawback of having poor\nsample efficiency which can often be tackled by knowledge reuse. In Multi-Agent\nReinforcement Learning (MARL) this drawback becomes worse, but at the same\ntime, a new set of opportunities to leverage knowledge are also presented\nthrough agent interactions. One promising approach among these is peer-to-peer\naction advising through a teacher-student framework. Despite being introduced\nfor single-agent RL originally, recent studies show that it can also be applied\nto multi-agent scenarios with promising empirical results. However, studies in\nthis line of research are currently very limited. In this paper, we propose\nheuristics-based action advising techniques in cooperative decentralised MARL,\nusing a nonlinear function approximation based task-level policy. By adopting\nRandom Network Distillation technique, we devise a measurement for agents to\nassess their knowledge in any given state and be able to initiate the\nteacher-student dynamics with no prior role assumptions. Experimental results\nin a gridworld environment show that such an approach may indeed be useful and\nneeds to be further investigated.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.01357v2"
    },
    {
        "title": "Fuzzy Q-Learning Based Multi-Agent System for Intelligent Traffic\n  Control by a Game Theory Approach",
        "authors": [
            "Abolghasem Daeichian",
            "Amir Haghani"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper introduces a multi-agent approach to adjust traffic lights based\non traffic situation in order to reduce average delay time. In the traffic\nmodel, lights of each intersection are controlled by an autonomous agent. Since\ndecision of each agent affects neighbor agents, this approach creates a\nclassical non-stationary environment. Thus, each agent not only needs to learn\nfrom the past experience but also has to consider decision of neighbors to\novercome dynamic changes of the traffic network. Fuzzy Q-learning and Game\ntheory are employed to make policy based on previous experiences and decision\nof neighbor agents. Simulation results illustrate the advantage of the proposed\nmethod over fixed time, fuzzy, Q-learning and fuzzy Q-learning control methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.01361v1"
    },
    {
        "title": "A multi-agent system approach in evaluating human spatio-temporal\n  vulnerability to seismic risk using social attachment",
        "authors": [
            "Julius Bañgate",
            "Julie Dugdale",
            "Elise Beck",
            "Carole Adam"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Social attachment theory states that individuals seek the proximity of\nattachment figures (e.g. family members, friends, colleagues, familiar places\nor objects) when faced with threat. During disasters, this means that family\nmembers may seek each other before evacuating, gather personal property before\nheading to familiar exits and places, or follow groups/crowds, etc. This\nhard-wired human tendency should be considered in the assessment of risk and\nthe creation of disaster management plans. Doing so may result in more\nrealistic evacuation procedures and may minimise the number of casualties and\ninjuries. In this context, a dynamic spatio-temporal analysis of seismic risk\nis presented using SOLACE, a multi-agent model of pedestrian behaviour based on\nsocial attachment theory implemented using the Belief-Desire-Intention\napproach. The model focuses on the influence of human, social, physical and\ntemporal factors on successful evacuation. Human factors considered include\nperception and mobility defined by age. Social factors are defined by\nattachment bonds, social groups, population distribution, and cultural norms.\nPhysical factors refer to the location of the epicentre of the earthquake,\nspatial distribution/layout and attributes of environmental objects such as\nbuildings, roads, barriers (cars), placement of safe areas, evacuation routes,\nand the resulting debris/damage from the earthquake. Experiments tested the\ninfluence of time of the day, presence of disabled persons and earthquake\nintensity. Initial results show that factors that influence arrivals in safe\nareas include (a) human factors (age, disability, speed), (b) pre-evacuation\nbehaviours, (c) perception distance (social attachment, time of day), (d)\nsocial interaction during evacuation, and (e) physical and spatial aspects,\nsuch as limitations imposed by debris (damage), and the distance to safe areas.\nTo validate the results, scenarios will be designed with stakeholders, who will\nalso take part in the definition of a serious game. The recommendation of this\nresearch is that both social and physical aspects should be considered when\ndefining vulnerability in the analysis of risk.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.01365v1"
    },
    {
        "title": "Emergent Escape-based Flocking Behavior using Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Carsten Hahn",
            "Thomy Phan",
            "Thomas Gabor",
            "Lenz Belzner",
            "Claudia Linnhoff-Popien"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In nature, flocking or swarm behavior is observed in many species as it has\nbeneficial properties like reducing the probability of being caught by a\npredator. In this paper, we propose SELFish (Swarm Emergent Learning Fish), an\napproach with multiple autonomous agents which can freely move in a continuous\nspace with the objective to avoid being caught by a present predator. The\npredator has the property that it might get distracted by multiple possible\npreys in its vicinity. We show that this property in interaction with\nself-interested agents which are trained with reinforcement learning to solely\nsurvive as long as possible leads to flocking behavior similar to Boids, a\ncommon simulation for flocking behavior. Furthermore we present interesting\ninsights in the swarming behavior and in the process of agents being caught in\nour modeled environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04077v1"
    },
    {
        "title": "Evidence Propagation and Consensus Formation in Noisy Environments",
        "authors": [
            "Michael Crosscombe",
            "Jonathan Lawry",
            "Palina Bartashevich"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We study the effectiveness of consensus formation in multi-agent systems\nwhere there is both belief updating based on direct evidence and also belief\ncombination between agents. In particular, we consider the scenario in which a\npopulation of agents collaborate on the best-of-n problem where the aim is to\nreach a consensus about which is the best (alternatively, true) state from\namongst a set of states, each with a different quality value (or level of\nevidence). Agents' beliefs are represented within Dempster-Shafer theory by\nmass functions and we investigate the macro-level properties of four well-known\nbelief combination operators for this multi-agent consensus formation problem:\nDempster's rule, Yager's rule, Dubois & Prade's operator and the averaging\noperator. The convergence properties of the operators are considered and\nsimulation experiments are conducted for different evidence rates and noise\nlevels. Results show that a combination of updating on direct evidence and\nbelief combination between agents results in better consensus to the best state\nthan does evidence updating alone. We also find that in this framework the\noperators are robust to noise. Broadly, Yager's rule is shown to be the better\noperator under various parameter values, i.e. convergence to the best state,\nrobustness to noise, and scalability.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04840v2"
    },
    {
        "title": "CityFlow: A Multi-Agent Reinforcement Learning Environment for Large\n  Scale City Traffic Scenario",
        "authors": [
            "Huichu Zhang",
            "Siyuan Feng",
            "Chang Liu",
            "Yaoyao Ding",
            "Yichen Zhu",
            "Zihan Zhou",
            "Weinan Zhang",
            "Yong Yu",
            "Haiming Jin",
            "Zhenhui Li"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Traffic signal control is an emerging application scenario for reinforcement\nlearning. Besides being as an important problem that affects people's daily\nlife in commuting, traffic signal control poses its unique challenges for\nreinforcement learning in terms of adapting to dynamic traffic environment and\ncoordinating thousands of agents including vehicles and pedestrians. A key\nfactor in the success of modern reinforcement learning relies on a good\nsimulator to generate a large number of data samples for learning. The most\ncommonly used open-source traffic simulator SUMO is, however, not scalable to\nlarge road network and large traffic flow, which hinders the study of\nreinforcement learning on traffic scenarios. This motivates us to create a new\ntraffic simulator CityFlow with fundamentally optimized data structures and\nefficient algorithms. CityFlow can support flexible definitions for road\nnetwork and traffic flow based on synthetic and real-world data. It also\nprovides user-friendly interface for reinforcement learning. Most importantly,\nCityFlow is more than twenty times faster than SUMO and is capable of\nsupporting city-wide traffic simulation with an interactive render for\nmonitoring. Besides traffic signal control, CityFlow could serve as the base\nfor other transportation studies and can create new possibilities to test\nmachine learning methods in the intelligent transportation domain.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.05217v1"
    },
    {
        "title": "An Online Pricing Mechanism for Electric Vehicle Parking Assignment and\n  Charge Scheduling",
        "authors": [
            "Nathaniel Tucker",
            "Bryce Ferguson",
            "Mahnoosh Alizadeh"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we design a pricing framework for online electric vehicle (EV)\nparking assignment and charge scheduling. Here, users with electric vehicles\nwant to park and charge at electric-vehicle-supply-equipment (EVSEs) at\ndifferent locations and arrive/depart throughout the day. The goal is to assign\nand schedule users to the available EVSEs while maximizing user utility and\nminimizing operational costs. Our formulation can accommodate multiple\nlocations, limited resources, operational costs, as well as variable arrival\npatterns. With this formulation, the parking facility management can optimize\nfor behind-the-meter solar integration and reduce costs due to procuring\nelectricity from the grid. We use an online pricing mechanism to approximate\nthe EVSE reservation problem's solution and we analyze the performance compared\nto the offline solution. Our numerical simulation validates the performance of\nthe EVSE reservation system in a downtown area with multiple parking locations\nequipped with EVSEs.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.06449v1"
    },
    {
        "title": "A Reputation System for Multi-Agent Marketplaces",
        "authors": [
            "Anton Kolonin",
            "Ben Goertzel",
            "Cassio Pennachin",
            "Deborah Duong",
            "Matt Ikle",
            "Nejc Znidar",
            "Marco Argentieri"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We present an exploration of a reputation system based on explicit ratings\nweighted by the values of corresponding financial transactions from the\nperspective of its ability to grant \"security\" to market participants by\nprotecting them from scam and \"equity\" in terms of having real qualities of the\nparticipants correctly assessed. We present a simulation modeling approach\nbased on the selected reputation system and discuss the results of the\nsimulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.08036v1"
    },
    {
        "title": "Arena: A General Evaluation Platform and Building Toolkit for\n  Multi-Agent Intelligence",
        "authors": [
            "Yuhang Song",
            "Andrzej Wojcicki",
            "Thomas Lukasiewicz",
            "Jianyi Wang",
            "Abi Aryan",
            "Zhenghua Xu",
            "Mai Xu",
            "Zihan Ding",
            "Lianlong Wu"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Learning agents that are not only capable of taking tests, but also\ninnovating is becoming a hot topic in AI. One of the most promising paths\ntowards this vision is multi-agent learning, where agents act as the\nenvironment for each other, and improving each agent means proposing new\nproblems for others. However, existing evaluation platforms are either not\ncompatible with multi-agent settings, or limited to a specific game. That is,\nthere is not yet a general evaluation platform for research on multi-agent\nintelligence. To this end, we introduce Arena, a general evaluation platform\nfor multi-agent intelligence with 35 games of diverse logics and\nrepresentations. Furthermore, multi-agent intelligence is still at the stage\nwhere many problems remain unexplored. Therefore, we provide a building toolkit\nfor researchers to easily invent and build novel multi-agent problems from the\nprovided game set based on a GUI-configurable social tree and five basic\nmulti-agent reward schemes. Finally, we provide Python implementations of five\nstate-of-the-art deep multi-agent reinforcement learning baselines. Along with\nthe baseline implementations, we release a set of 100 best agents/teams that we\ncan train with different training schemes for each game, as the base for\nevaluating agents with population performance. As such, the research community\ncan perform comparisons under a stable and uniform standard. All the\nimplementations and accompanied tutorials have been open-sourced for the\ncommunity at https://sites.google.com/view/arena-unity/.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.08085v5"
    },
    {
        "title": "Adaptation and learning over networks under subspace constraints -- Part\n  I: Stability Analysis",
        "authors": [
            "Roula Nassif",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper considers optimization problems over networks where agents have\nindividual objectives to meet, or individual parameter vectors to estimate,\nsubject to subspace constraints that require the objectives across the network\nto lie in low-dimensional subspaces. This constrained formulation includes\nconsensus optimization as a special case, and allows for more general task\nrelatedness models such as smoothness. While such formulations can be solved\nvia projected gradient descent, the resulting algorithm is not distributed.\nStarting from the centralized solution, we propose an iterative and distributed\nimplementation of the projection step, which runs in parallel with the\nstochastic gradient descent update. We establish in this Part I of the work\nthat, for small step-sizes $\\mu$, the proposed distributed adaptive strategy\nleads to small estimation errors on the order of $\\mu$. We examine in the\naccompanying Part II [2] the steady-state performance. The results will reveal\nexplicitly the influence of the gradient noise, data characteristics, and\nsubspace constraints, on the network performance. The results will also show\nthat in the small step-size regime, the iterates generated by the distributed\nalgorithm achieve the centralized steady-state performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.08750v2"
    },
    {
        "title": "Asynchronous Scattering",
        "authors": [
            "Ulysse Léchine",
            "Sébastien Tixeuil"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we consider the problem of scattering a swarm of mobile\noblivious robots in a continuous space. We consider the fully asynchronous\nsetting where robots may base their computation on past observations, or may be\nobserved by other robots while moving.\n  It turns out that asynchronous scattering is solvable in the most general\ncase when both vision (the ability to see others robots positions) and weak\nlocal multiplicity detection are available. In the case of a bidimensional\nEuclidean space, ASYNC scattering is also solvable with blind robots if moves\nare rigid. Our approach is constructive and modular, as we present a proof\ntechnique for probabilistic robot protocols that is of independent interest and\ncan be reused for other purposes.\n  On the negative side, we show that when robots are both blind and have no\nmultiplicity detection, the problem is unsolvable, and when only one of those\nis available, the problem remains unsolvable on the line.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.09177v1"
    },
    {
        "title": "Nature-Inspired Computational Model of Population Desegregation under\n  Group Leaders Influence",
        "authors": [
            "Kashif Zia",
            "Dinesh Kumar Saini",
            "Arshad Muhammad",
            "Alois Ferscha"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper presents an agent-based model of population desegregation and\nprovides a thorough analysis of the social behavior leading to it, namely, the\ncontact hypothesis. Based on the parameters of frequency and intensity of\ninfluence of group leaders on the population, the proposed model is constituted\nby two layers: 1) a physical layer of the population that is influenced by and\n2) a virtual layer of group leaders. The model of negotiation and survival of\ngroup leaders are governed by the nature-inspired evolutionary process of queen\nants, also known as Foundress Dilemma. The motivation of using a virtual\ngrouping concept (instead of taking a subset of population as the group\nleaders) is to stay focused on finding the conditions leading individuals in a\nsociety tolerating a significantly diversified (desegregated) neighborhood,\nrather than, indulging into complex details, which would be more relevant to\nstudies targeting the evolution of societal group and leaders. A geographic\ninformation system-driven simulation is performed, which reveals that: 1)\ndesegregation is directly proportional to the frequency of group leaders'\ncontact with the population and 2) mostly, it remains ineffective with an\nincrease in the intensity of group leaders' contact with the population. The\nmechanism of group selection (the conflict resolution model resolving the\nFoundress Dilemma) reveals an exciting result concerning negative influence of\ncooperative group leaders. Most of the time, desegregation decreases with\nincrease in cooperative leaders (the leaders enforcing desegregation) when\ncompared with fierce leaders (the leaders enforcing segregation).\n",
        "pdf_link": "http://arxiv.org/pdf/1905.09795v1"
    },
    {
        "title": "Decentralized Informative Path Planning with Exploration-Exploitation\n  Balance for Swarm Robotic Search",
        "authors": [
            "Payam Ghassemi",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Swarm robotic search is concerned with searching targets in unknown\nenvironments (e.g., for search and rescue or hazard localization), using a\nlarge number of collaborating simple mobile robots. In such applications,\ndecentralized swarm systems are touted for their task/coverage scalability,\ntime efficiency, and fault tolerance. To guide the behavior of such swarm\nsystems, two broad classes of approaches are available, namely nature-inspired\nswarm heuristics and multi-robotic search methods. However, simultaneously\noffering computationally-efficient scalability and fundamental insights into\nthe exhibited behavior (instead of a black-box behavior model), remains\nchallenging under either of these two class of approaches. In this paper, we\ndevelop an important extension of the batch Bayesian search method for\napplication to embodied swarm systems, searching in a physical 2D space. Key\ncontributions lie in: 1) designing an acquisition function that not only\nbalances exploration and exploitation across the swarm, but also allows\nmodeling knowledge extraction over trajectories; and 2) developing its\ndistributed implementation to allow asynchronous task inference and path\nplanning by the swarm robots. The resulting collective informative path\nplanning approach is tested on target search case studies of varying\ncomplexity, where the target produces a spatially varying (measurable) signal.\nSignificantly superior performance, in terms of mission completion efficiency,\nis observed compared to exhaustive search and random walk baselines, along with\nfavorable performance scalability with increasing swarm size.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.09988v2"
    },
    {
        "title": "Finding new routes for integrating Multi-Agent Systems using Apache\n  Camel",
        "authors": [
            "Cleber Jorge Amaral",
            "Sérgio Pereira Bernardes",
            "Mateus Conceição",
            "Jomi Fred Hübner",
            "Luis Pedro Arenhart Lampert",
            "Otávio Arruda Matoso",
            "Maicon Rafael Zatelli"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In Multi-Agent Systems (MAS) there are two main models of interaction: among\nagents, and between agents and the environment. Although there are studies\nconsidering these models, there is no practical tool to afford the interaction\nwith external entities with both models. This paper presents a proposal for\nsuch a tool based on the Apache Camel framework by designing two new\ncomponents, namely camel-jason and camel-artifact. By means of these\ncomponents, an external entity is modelled according to its nature, i.e.,\nwhether it is autonomous or non-autonomous, interacting with the MAS\nrespectively as an agent or an artifact. It models coherently external entities\nwhereas Camel provides interoperability with several communication protocols.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.10490v1"
    },
    {
        "title": "Shared Autonomous Electric Vehicle Service Performance: Assessing the\n  Impact of Charging Infrastructure and Battery Capacity",
        "authors": [
            "Reza Vosooghi",
            "Jakob Puchinger",
            "Joschka Bischoff",
            "Marija Jankovic",
            "Anthony Vouillon"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Shared autonomous vehicles (SAVs) are the next major evolution in urban\nmobility. This technology has attracted much interest of car manufacturers\naiming at playing a role as transportation network companies (TNCs) in order to\ngain benefits per kilometer and per ride. The majority of future SAVs will most\nprobably be electric. It is therefore important to understand how limited\nvehicle range and the configuration of charging infrastructure will affect the\nperformance of shared autonomous electric vehicle (SAEV) services. We aim to\nexplore the impacts of charging station placement, charging type (rapid\ncharging, battery swapping) as well as vehicle range onto service efficiency\nand customer experience in terms of service availability and response time. We\nperform an agent-based simulation of SAEVs across the Rouen Normandie\nmetropolitan area in France. The simulation process features impact assessment\nby considering dynamic demand responsive to the network and traffic. Research\nresults suggest that the performance of SAEVs is strongly correlated to the\ncharging infrastructure. Importantly, faster charging infrastructure and\noptimized placement of charging locations in order to minimize distances\nbetween demand hubs and charging stations result in a higher performance.\nFurther analysis indicates the importance of dispersing charging stations\nacross the service area and how this affects service effectiveness. The results\nalso underline that SAEV battery capacity has to be carefully selected to avoid\nthe overlaps between demand and charging peak times. Finally, the simulation\nresults show that by providing battery swapping infrastructure the performance\nindicators of SAEV service are significantly improved.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.12160v1"
    },
    {
        "title": "Robo-Taxi service fleet sizing: assessing the impact of user trust and\n  willingness-to-use",
        "authors": [
            "Reza Vosooghi",
            "Joseph Kamel",
            "Jakob Puchinger",
            "Vincent Leblond",
            "Marija Jankovic"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The first commercial fleets of Robo-Taxis will be on the road soon. Today\nimportant efforts are made to anticipate future Robo-Taxi services. Fleet size\nis one of the key parameters considered in the planning phase of service design\nand configuration. Based on multi-agent approaches, the fleet size can be\nexplored using dynamic demand response simulations. Time and cost are the most\ncommon variables considered in such simulation approaches. However, personal\ntaste variation can affect the demand and consequently the required fleet size.\nIn this paper, we explore the impact of user trust and willingness-to-use on\nthe Robo-Taxi fleet size. This research is based upon simulating the\ntransportation system of the Rouen-Normandie metropolitan area in France using\nMATSim, a multi-agent activity-based simulator. A local survey is made in order\nto explore the variation of user trust and their willingness-to-use future\nRobo-Taxis according to the sociodemographic attributes. Integrating survey\ndata in the model shows the significant importance of traveler trust and\nwillingness-to-use varying the Robo-Taxi use and the required fleet size.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.12267v1"
    },
    {
        "title": "Guiding the Self-organization of Cyber-Physical Systems",
        "authors": [
            "Carlos Gershenson"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Self-organization offers a promising approach for designing adaptive systems.\nGiven the inherent complexity of most cyber-physical systems, adaptivity is\ndesired, as predictability is limited. Here I summarize different concepts and\napproaches that can facilitate self-organization in cyber-physical systems, and\nthus be exploited for design. Then I mention real-world examples of systems\nwhere self-organization has managed to provide solutions that outperform\nclassical approaches, in particular related to urban mobility. Finally, I\nidentify when a centralized, distributed, or self-organizing control is more\nappropriate.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.00758v1"
    },
    {
        "title": "A Study on Accelerating Average Consensus Algorithms Using Delayed\n  Feedback",
        "authors": [
            "Hossein Moradian",
            "Solmaz S. Kia"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we study accelerating a Laplacian-based dynamic average\nconsensus algorithm by splitting the conventional delay-free disagreement\nfeedback into weighted summation of a current and an outdated term. We\ndetermine for what weighted sum there exists a range of time delay that results\nin the higher rate of convergence for the algorithm. For such weights, using\nthe Lambert W function, we obtain the rate increasing range of the time delay,\nthe maximum reachable rate and comment on the value of the corresponding\nmaximizer delay. We also study the effect of use of outdated feedback on the\ncontrol effort of the agents and show that only for some specific affine\ncombination of the immediate and outdated feedback the control effort of the\nagents does not go beyond that of the delay-free algorithm. Additionally, we\ndemonstrate that using outdated feedback does not increase the steady state\ntracking error of the average consensus algorithm. Lastly, we determine the\noptimum combination of the current and the outdated feedback weights to achieve\nthe maximum increase in the rate of convergence without increasing the control\neffort of the agents. We demonstrate our results through a numerical example.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.04442v1"
    },
    {
        "title": "Jason-RS, a Collaboration between Agents and an IoT Platform",
        "authors": [
            "Hantanirina Felixie",
            "Jean Razafindramintsa",
            "Sylvain Cherrier",
            "Thomas Mahatody",
            "Laurent George",
            "Victor Manantsoa"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this article we start from the observation that REST services are the most\nused as tools of interoperability and orchestration in the Internet of Things\n(IoT). But REST does not make it possible to inject artificial intelligence\ninto connected objects, ie it cannot allow autonomy and decision-making by the\nobjects themselves. To define an intelligence to a connected object, one can\nuse a Beleive Desire Intention agent (BDI an intelligent agent that adopts\nhuman behavior) such as Jason Agentspeak. But Jason AgentSpeak does not\nguarantee orchestration or choreography between connected objects. There are\nplatforms for service orchestration and choreography in IoT, still the\ninterconnection with artificial intelligence needs to be built. In this\narticle, we propose a new approach called Jason-RS. It is a result of pairing\nJason BDI agent with the web service technologies to exploit the agent capacity\nas a service, Jason-RS turn in Java SE and it does not need any middleware. The\narchitecture that we propose allows to create the link between Artificial\nIntelligence and Services choreography to reduce human intervention in the\nservice choreography. In order to validate the proposed approach, we have\ninterconnected the Iot BeC 3 platform and the REST agent (Jason-RS). The\ndecision-making faculty offered by Jason-RS is derived from the information\nsent by the objects according to the different methods of REST (GET, POST, PUT,\nand DELETE) that Jason-RS offers. As a result, the objects feed the inter-agent\ncollaborations and decision-making inside the agent. Finally, we show that\nJason-RS allows the Web of Objects to power complex systems such as an\nartificial intelligence responsible for processing data. This performance is\npromising.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05362v1"
    },
    {
        "title": "Leader Selection in Multi-Agent Networks with Switching Topologies via\n  Submodular Optimization",
        "authors": [
            "Kaile Chen",
            "Wangli He",
            "Yang Tang",
            "Wenle Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In leader-follower multi-agent networks with switching topologies, choosing a\nsubset of agents as leaders is a critical step to achieve desired performances.\nIn this paper, we concentrate on the problem of selecting a minimum-size set of\nleaders that ensure the tracking of a reference signal in a highorder linear\nmulti-agent network with a set of given topology dependent dwell time (TDDT).\nFirst, we derive a sufficient condition that guarantees the states of all\nagents converging to an expected state trajectory. Second, by exploiting\nsubmodular optimization method, we formulate the problem of identifying a\nminimal leader set which satisfies the proposed sufficient condition. Third, we\npresent an algorithm with the provable optimality bound to solve the formulated\nproblem. Finally, several numerical examples are provided to verify the\neffectiveness of the designed selection scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.06019v1"
    },
    {
        "title": "Mission Oriented Miniature Fixed-wing UAV Swarms: A Multi-layered and\n  Distributed Architecture",
        "authors": [
            "Zhihong Liu",
            "Xiangke Wang",
            "Lincheng Shen",
            "Shulong Zhao",
            "Yirui Cong",
            "Jie Li",
            "Dong Yin",
            "Shengde Jia",
            "Xiaojia Xiang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  UAV swarms have triggered wide concern due to their potential application\nvalues in recent years. While there are studies proposed in terms of the\narchitecture design for UAV swarms, two main challenges still exist: (1)\nScalability, supporting a large scale of vehicles; (2) Versatility, integrating\ndiversified missions. To this end, a multi-layered and distributed architecture\nfor mission oriented miniature fixed-wing UAV swarms is presented in this\npaper. The proposed architecture is built on the concept of modularity. It\ndivides the overall system to five layers: low-level control, high-level\ncontrol, coordination, communication and human interaction layers, and many\nmodules that can be viewed as black boxes with interfaces of inputs and\noutputs. In this way, not only the complexity of developing a large system can\nbe reduced, but also the versatility of supporting diversified missions can be\nensured. Furthermore, the proposed architecture is fully distributed that each\nUAV performs the decision-making procedure autonomously so as to achieve better\nscalability. Moreover, different kinds of aerial platforms can be feasibly\nextended by using the control allocation matrices and the integrated hardware\nbox. A prototype swarm system based on the proposed architecture is built and\nthe proposed architecture is evaluated through field experiments with a scale\nof 21 fixed-wing UAVs. Particularly, to the best of our knowledge, this paper\nis the first work which successfully demonstrates formation flight, target\nrecognition and tracking missions within an integrated architecture for\nfixed-wing UAV swarms through field experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.06285v1"
    },
    {
        "title": "Resolving Congestions in the Air Traffic Management Domain via\n  Multiagent Reinforcement Learning Methods",
        "authors": [
            "Theocharis Kravaris",
            "Christos Spatharis",
            "Alevizos Bastas",
            "George A. Vouros",
            "Konstantinos Blekas",
            "Gennady Andrienko",
            "Natalia Andrienko",
            "Jose Manuel Cordero Garcia"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this article, we report on the efficiency and effectiveness of multiagent\nreinforcement learning methods (MARL) for the computation of flight delays to\nresolve congestion problems in the Air Traffic Management (ATM) domain.\nSpecifically, we aim to resolve cases where demand of airspace use exceeds\ncapacity (demand-capacity problems), via imposing ground delays to flights at\nthe pre-tactical stage of operations (i.e. few days to few hours before\noperation). Casting this into the multiagent domain, agents, representing\nflights, need to decide on own delays w.r.t. own preferences, having no\ninformation about others' payoffs, preferences and constraints, while they plan\nto execute their trajectories jointly with others, adhering to operational\nconstraints. Specifically, we formalize the problem as a multiagent Markov\nDecision Process (MA-MDP) and we show that it can be considered as a Markov\ngame in which interacting agents need to reach an equilibrium: What makes the\nproblem more interesting is the dynamic setting in which agents operate, which\nis also due to the unforeseen, emergent effects of their decisions in the whole\nsystem. We propose collaborative multiagent reinforcement learning methods to\nresolve demand-capacity imbalances: Extensive experimental study on real-world\ncases, shows the potential of the proposed approaches in resolving problems,\nwhile advanced visualizations provide detailed views towards understanding the\nquality of solutions provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.06860v1"
    },
    {
        "title": "COBRA: Context-aware Bernoulli Neural Networks for Reputation Assessment",
        "authors": [
            "Leonit Zeynalvand",
            "Tie Luo",
            "Jie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Trust and reputation management (TRM) plays an increasingly important role in\nlarge-scale online environments such as multi-agent systems (MAS) and the\nInternet of Things (IoT). One main objective of TRM is to achieve accurate\ntrust assessment of entities such as agents or IoT service providers. However,\nthis encounters an accuracy-privacy dilemma as we identify in this paper, and\nwe propose a framework called Context-aware Bernoulli Neural Network based\nReputation Assessment (COBRA) to address this challenge. COBRA encapsulates\nagent interactions or transactions, which are prone to privacy leak, in machine\nlearning models, and aggregates multiple such models using a Bernoulli neural\nnetwork to predict a trust score for an agent. COBRA preserves agent privacy\nand retains interaction contexts via the machine learning models, and achieves\nmore accurate trust prediction than a fully-connected neural network\nalternative. COBRA is also robust to security attacks by agents who inject fake\nmachine learning models; notably, it is resistant to the 51-percent attack. The\nperformance of COBRA is validated by our experiments using a real dataset, and\nby our simulations, where we also show that COBRA outperforms other\nstate-of-the-art TRM systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.08446v2"
    },
    {
        "title": "PFaRA: a Platoon Forming and Routing Algorithm for Same-Day Deliveries",
        "authors": [
            "Sînziana-Maria Sebe",
            "Jörg P. Müller"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Platoons, vehicles that travel very close together acting as one, promise to\nimprove road usage on freeways and city roads alike. We study platoon formation\nin the context of same-day delivery in urban environments. Multiple\nself-interested logistic service providers (LSP) carry out same-day deliveries\nby deploying autonomous electric vehicles that are capable of forming and\ntraveling in platoons. The novel aspect that we consider in our research is\nheterogeneity of platoons in the sense that vehicles are equipped with\ndifferent capabilities and constraints, and belong to different providers. Our\naim is to examine how these platoons can form and their potential properties\nand benefits. We present a platoon forming and routing algorithm, called PFaRA,\nthat finds longest common routes for multiple vehicles, while also respecting\nvehicle preferences and constraints. PFaRA consists of two parts, a speed\nclustering step and a linear optimisation step. To test the approach, a\nsimulation was used, working with realistic urban network data and background\ntraffic models. Our results showed that the performance of our approach is\ncomparable to a simple route-matching one, but it leads to better utility\nvalues for vehicles and by extension the LSPs. We show that the grouping\nprovided is viable and provides benefits to all vehicles participating in the\nplatoon.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.08929v1"
    },
    {
        "title": "A Bi-Level Cooperative Driving Strategy Allowing Lane Changes",
        "authors": [
            "Huile Xu",
            "Yi Zhang",
            "Christos G. Cassandras",
            "Li Li",
            "Shuo Feng"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper studies the cooperative driving of connected and automated\nvehicles (CAVs) at conflict areas (e.g., non-signalized intersections and\nramping regions). Due to safety concerns, most existing studies prohibit lane\nchange since this may cause lateral collisions when coordination is not\nappropriately performed. However, in many traffic scenarios (e.g., work zones),\nvehicles must change lanes. To solve this problem, we categorize the potential\ncollision into two kinds and thus establish a bi-level planning problem. The\nright-of-way of vehicles for the critical conflict zone is considered in the\nupper-level, and the right-of-way of vehicles during lane changes is then\nresolved in the lower-level. The solutions of the upper-level problem are\nrepresented in tree space, and a near-optimal solution is searched for by\ncombining Monte Carlo Tree Search (MCTS) with some heuristic rules within a\nvery short planning time. The proposed strategy is suitable for not only the\nshortest delay objective but also other objectives (e.g., energy-saving and\npassenger comfort). Numerical examples show that the proposed strategy leads to\ngood traffic performance in real-time.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.11495v1"
    },
    {
        "title": "Multirobot Coverage of Linear Modular Environments",
        "authors": [
            "Mirko Salaris",
            "Alessandro Riva",
            "Francesco Amigoni"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Multirobot systems for covering environments are increasingly used in\napplications like cleaning, industrial inspection, patrolling, and precision\nagriculture. The problem of covering a given environment using multiple robots\ncan be naturally formulated and studied as a multi-Traveling Salesperson\nProblem (mTSP). In a mTSP, the environment is represented as a graph and the\ngoal is to find tours (starting and ending at the same depot) for the robots in\norder to visit all the vertices with minimum global cost, namely the length of\nthe longest tour. The mTSP is an NP-hard problem for which several\napproximation algorithms have been proposed. These algorithms usually assume\ngeneric environments, but tighter approximation bounds can be reached focusing\non specific environments. In this paper, we address the case of environments\ncomposed of sub-parts, called modules, that can be reached from each other only\nthrough some linking structures. Examples are multi-floor buildings, in which\nthe modules are the floors and the linking structures are the staircases or the\nelevators, and floors of large hotels or hospitals, in which the modules are\nthe rooms and the linking structures are the corridors. We focus on linear\nmodular environments, with the modules organized sequentially, presenting an\nefficient (with polynomial worst-case time complexity) algorithm that finds a\nsolution for the mTSP whose cost is within a bounded distance from the cost of\nthe optimal solution. The main idea of our algorithm is to allocate disjoint\n\"blocks\" of adjacent modules to the robots, in such a way that each module is\ncovered by only one robot. We experimentally compare our algorithm against some\nstate-of-the-art algorithms for solving mTSPs in generic environments and show\nthat it is able to provide solutions with lower makespan and spending a\ncomputing time several orders of magnitude shorter.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.02906v1"
    },
    {
        "title": "Multi-Agent Interactions Modeling with Correlated Policies",
        "authors": [
            "Minghuan Liu",
            "Ming Zhou",
            "Weinan Zhang",
            "Yuzheng Zhuang",
            "Jun Wang",
            "Wulong Liu",
            "Yong Yu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In multi-agent systems, complex interacting behaviors arise due to the high\ncorrelations among agents. However, previous work on modeling multi-agent\ninteractions from demonstrations is primarily constrained by assuming the\nindependence among policies and their reward structures. In this paper, we cast\nthe multi-agent interactions modeling problem into a multi-agent imitation\nlearning framework with explicit modeling of correlated policies by\napproximating opponents' policies, which can recover agents' policies that can\nregenerate similar interactions. Consequently, we develop a Decentralized\nAdversarial Imitation Learning algorithm with Correlated policies (CoDAIL),\nwhich allows for decentralized training and execution. Various experiments\ndemonstrate that CoDAIL can better regenerate complex interactions close to the\ndemonstrators and outperforms state-of-the-art multi-agent imitation learning\nmethods. Our code is available at \\url{https://github.com/apexrl/CoDAIL}.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03415v3"
    },
    {
        "title": "Safe Voting: Resilience to Abstention and Sybils",
        "authors": [
            "Reshef Meir",
            "Gal Shahaf",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Voting rules may implement the will of the society when all eligible voters\nvote, and only them. However, they may fail to do so when sybil (fake or\nduplicate) votes are present and when only some honest (non sybil) voters\nactively participate. As, unfortunately, sometimes this is the case, our aim\nhere is to address social choice in the presence of sybils and voter\nabstention. To do so we build upon the framework of Reality-aware Social\nChoice: we assume the status-quo as an ever-present distinguished alternative,\nand study Status-Quo Enforcing voting rules, which add virtual votes in support\nof the status-quo. We characterize the tradeoff between safety and liveness\n(the ability of active honest voters to maintain/change the status-quo,\nrespectively) in several domains, and show that the Status-Quo Enforcing voting\nrules are often optimal. We comment on the applicability of our methods and\nanalyses to the governance of digital communities.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.05271v3"
    },
    {
        "title": "Subjective Knowledge and Reasoning about Agents in Multi-Agent Systems",
        "authors": [
            "Shikha Singh",
            "Deepak Khemani"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Though a lot of work in multi-agent systems is focused on reasoning about\nknowledge and beliefs of artificial agents, an explicit representation and\nreasoning about the presence/absence of agents, especially in the scenarios\nwhere agents may be unaware of other agents joining in or going offline in a\nmulti-agent system, leading to partial knowledge/asymmetric knowledge of the\nagents is mostly overlooked by the MAS community. Such scenarios lay the\nfoundations of cases where an agent can influence other agents' mental states\nby (mis)informing them about the presence/absence of collaborators or\nadversaries. In this paper, we investigate how Kripke structure-based epistemic\nmodels can be extended to express the above notion based on an agent's\nsubjective knowledge and we discuss the challenges that come along.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.08016v1"
    },
    {
        "title": "Silly rules improve the capacity of agents to learn stable enforcement\n  and compliance behaviors",
        "authors": [
            "Raphael Köster",
            "Dylan Hadfield-Menell",
            "Gillian K. Hadfield",
            "Joel Z. Leibo"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  How can societies learn to enforce and comply with social norms? Here we\ninvestigate the learning dynamics and emergence of compliance and enforcement\nof social norms in a foraging game, implemented in a multi-agent reinforcement\nlearning setting. In this spatiotemporally extended game, individuals are\nincentivized to implement complex berry-foraging policies and punish\ntransgressions against social taboos covering specific berry types. We show\nthat agents benefit when eating poisonous berries is taboo, meaning the\nbehavior is punished by other agents, as this helps overcome a\ncredit-assignment problem in discovering delayed health effects. Critically,\nhowever, we also show that introducing an additional taboo, which results in\npunishment for eating a harmless berry, improves the rate and stability with\nwhich agents learn to punish taboo violations and comply with taboos.\nCounterintuitively, our results show that an arbitrary taboo (a \"silly rule\")\ncan enhance social learning dynamics and achieve better outcomes in the middle\nstages of learning. We discuss the results in the context of studying\nnormativity as a group-level emergent phenomenon.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.09318v1"
    },
    {
        "title": "Parameter Calibration in Crowd Simulation Models using Approximate\n  Bayesian Computation",
        "authors": [
            "Nikolai Bode"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Simulation models for pedestrian crowds are a ubiquitous tool in research and\nindustry. It is crucial that the parameters of these models are calibrated\ncarefully and ultimately it will be of interest to compare competing models to\ndecide which model is best suited for a particular purpose. In this\ncontribution, I demonstrate how Approximate Bayesian Computation (ABC), which\nis already a popular tool in other areas of science, can be used for model\nfitting and model selection in a pedestrian dynamics context. I fit two\ndifferent models for pedestrian dynamics to data on a crowd passing in one\ndirection through a bottleneck. One model describes movement in\ncontinuous-space, the other model is a cellular automaton and thus describes\nmovement in discrete-space. In addition, I compare models to data using two\nmetrics. The first is based on egress times and the second on the velocity of\npedestrians in front of the bottleneck. My results show that while model\nfitting is successful, a substantial degree of uncertainty about the value of\nsome model parameters remains after model fitting. Importantly, the choice of\nmetric in model fitting can influence parameter estimates. Model selection is\ninconclusive for the egress time metric but supports the continuous-space model\nfor the velocity-based metric. These findings show that ABC is a flexible\napproach and highlight the difficulties associated with model fitting and model\nselection for pedestrian dynamics. ABC requires many simulation runs and\nchoosing appropriate metrics for comparing data to simulations requires careful\nattention. Despite this, I suggest ABC is a promising tool, because it is\nversatile and easily implemented for the growing number of openly available\ncrowd simulators and data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.10330v1"
    },
    {
        "title": "A Deep Reinforcement Learning Approach to Concurrent Bilateral\n  Negotiation",
        "authors": [
            "Pallavi Bagga",
            "Nicola Paoletti",
            "Bedour Alrayes",
            "Kostas Stathis"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We present a novel negotiation model that allows an agent to learn how to\nnegotiate during concurrent bilateral negotiations in unknown and dynamic\ne-markets. The agent uses an actor-critic architecture with model-free\nreinforcement learning to learn a strategy expressed as a deep neural network.\nWe pre-train the strategy by supervision from synthetic market data, thereby\ndecreasing the exploration time required for learning during negotiation. As a\nresult, we can build automated agents for concurrent negotiations that can\nadapt to different e-market settings without the need to be pre-programmed. Our\nexperimental evaluation shows that our deep reinforcement learning-based agents\noutperform two existing well-known negotiation strategies in one-to-many\nconcurrent bilateral negotiations for a range of e-market settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.11785v2"
    },
    {
        "title": "Using Machine Learning to Emulate Agent-Based Simulations",
        "authors": [
            "Claudio Angione",
            "Eric Silverman",
            "Elisabeth Yaneske"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this proof-of-concept work, we evaluate the performance of multiple\nmachine-learning methods as statistical emulators for use in the analysis of\nagent-based models (ABMs). Analysing ABM outputs can be challenging, as the\nrelationships between input parameters can be non-linear or even chaotic even\nin relatively simple models, and each model run can require significant CPU\ntime. Statistical emulation, in which a statistical model of the ABM is\nconstructed to facilitate detailed model analyses, has been proposed as an\nalternative to computationally costly Monte Carlo methods. Here we compare\nmultiple machine-learning methods for ABM emulation in order to determine the\napproaches best suited to emulating the complex behaviour of ABMs. Our results\nsuggest that, in most scenarios, artificial neural networks (ANNs) and\ngradient-boosted trees outperform Gaussian process emulators, currently the\nmost commonly used method for the emulation of complex computational models.\nANNs produced the most accurate model replications in scenarios with high\nnumbers of model runs, although training times were longer than the other\nmethods. We propose that agent-based modelling would benefit from using\nmachine-learning methods for emulation, as this can facilitate more robust\nsensitivity analyses for the models while also reducing CPU time consumption\nwhen calibrating and analysing the simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02077v2"
    },
    {
        "title": "Long-term electricity market agent based model validation using genetic\n  algorithm based optimization",
        "authors": [
            "Alexander J. M. Kell",
            "Matthew Forshaw",
            "A. Stephen McGough"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Electricity market modelling is often used by governments, industry and\nagencies to explore the development of scenarios over differing timeframes. For\nexample, how would the reduction in cost of renewable energy impact investments\nin gas power plants or what would be an optimum strategy for carbon tax or\nsubsidies? Cost optimization based solutions are the dominant approach for\nunderstanding different long-term energy scenarios. However, these types of\nmodels have certain limitations such as the need to be interpreted in a\nnormative manner, and the assumption that the electricity market remains in\nequilibrium throughout. Through this work, we show that agent-based models are\na viable technique to simulate decentralised electricity markets. The aim of\nthis paper is to validate an agent-based modelling framework to increase\nconfidence in its ability to be used in policy and decision making. Our\nframework can model heterogeneous agents with imperfect information. The model\nuses a rules-based approach to approximate the underlying dynamics of a real\nworld, decentralised electricity market. We use the UK as a case study,\nhowever, our framework is generalisable to other countries. We increase the\ntemporal granularity of the model by selecting representative days of\nelectricity demand and weather using a $k$-means clustering approach. We show\nthat our framework can model the transition from coal to gas observed in the UK\nbetween 2013 and 2018. We are also able to simulate a future scenario to 2035\nwhich is similar to the UK Government, Department for Business and Industrial\nStrategy (BEIS) projections. We show a more realistic increase in nuclear power\nover this time period. This is due to the fact that with current nuclear\ntechnology, electricity is generated almost instantaneously and has a low\nshort-run marginal cost \\cite{Department2016}.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.10346v1"
    },
    {
        "title": "Agent-Based Simulation of Collective Cooperation: From Experiment to\n  Model",
        "authors": [
            "Benedikt Kleinmeier",
            "Gerta Köster",
            "John Drury"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Simulation models of pedestrian dynamics have become an invaluable tool for\nevacuation planning. Typically crowds are assumed to stream unidirectionally\ntowards a safe area. Simulated agents avoid collisions through mechanisms that\nbelong to each individual, such as being repelled from each other by imaginary\nforces. But classic locomotion models fail when collective cooperation is\ncalled for, notably when an agent, say a first-aid attendant, needs to forge a\npath through a densely packed group. We present a controlled experiment to\nobserve what happens when humans pass through a dense static crowd. We\nformulate and test hypothesis on salient phenomena. We discuss our observations\nin a psychological framework. We derive a model that incorporates: agents'\nperception and cognitive processing of a situation that needs cooperation;\nselection from a portfolio of behaviours, such as being cooperative; and a\nsuitable action, such as swapping places. Agents' ability to successfully get\nthrough a dense crowd emerges as an effect of the psychological model.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.12712v2"
    },
    {
        "title": "Time-Independent Planning for Multiple Moving Agents",
        "authors": [
            "Keisuke Okumura",
            "Yasumasa Tamura",
            "Xavier Défago"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Typical Multi-agent Path Finding (MAPF) solvers assume that agents move\nsynchronously, thus neglecting the reality gap in timing assumptions, e.g.,\ndelays caused by an imperfect execution of asynchronous moves. So far, two\npolicies enforce a robust execution of MAPF plans taken as input: either by\nforcing agents to synchronize or by executing plans while preserving temporal\ndependencies. This paper proposes an alternative approach, called\ntime-independent planning, which is both online and distributed. We represent\nreality as a transition system that changes configurations according to atomic\nactions of agents, and use it to generate a time-independent schedule.\nEmpirical results in a simulated environment with stochastic delays of agents'\nmoves support the validity of our proposal.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.13187v3"
    },
    {
        "title": "A Real-time Localization System Using RFID for Visually Impaired",
        "authors": [
            "Tae Qinghui",
            "Muhammad Yasir Malik",
            "Youngjee Hong",
            "Jinwoo Park"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Gadgets helping the disabled, especially blind that are in least\naccessibility of information, use acoustic methods that can cause stress to ear\nand infringe user's privacy. Even if some project uses embedded Radio Frequency\nIdentification (RFID) into the sidewalk for blind's free walking, the tag\nmemory design is not specified for buildings and road conditions. This paper\nsuggested allocation scheme of RFID tag referring to EPCglobal SGLN, tactile\nmethod for conveying information, and use of lithium battery as power source\nwith solar cells as an alternative. Results have shown independent mobility,\naccidents prevention, stress relief and satisfied factors in terms of cost and\nhuman usability.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.1879v1"
    },
    {
        "title": "Distributed Air Traffic Control : A Human Safety Perspective",
        "authors": [
            "Sarvesh Nikumbh",
            "Joeprakash Nathaman",
            "Rahul Vartak"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  The issues in air traffic control have so far been addressed with the intent\nto improve resource utilization and achieve an optimized solution with respect\nto fuel comsumption of aircrafts, efficient usage of the available airspace\nwith minimal congestion related losses under various dynamic constraints. So\nthe focus has almost always been more on smarter management of traffic to\nincrease profits while human safety, though achieved in the process, we\nbelieve, has remained less seriously attended. This has become all the more\nimportant given that we have overburdened and overstressed air traffic\ncontrollers managing hundreds of airports and thousands of aircrafts per day.\n  We propose a multiagent system based distributed approach to handle air\ntraffic ensuring complete human (passenger) safety without removing any humans\n(ground controllers) from the loop thereby also retaining the earlier\nadvantages in the new solution. The detailed design of the agent system, which\nwill be easily interfacable with the existing environment, is described. Based\non our initial findings from simulations, we strongly believe the system to be\ncapable of handling the nuances involved, to be extendable and customizable at\nany later point in time.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.6838v1"
    },
    {
        "title": "Optimizing Supply Chain Management using Gravitational Search Algorithm\n  and Multi Agent System",
        "authors": [
            "Muneendra Ojha"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Supply chain management is a very dynamic operation research problem where\none has to quickly adapt according to the changes perceived in environment in\norder to maximize the benefit or minimize the loss. Therefore we require a\nsystem which changes as per the changing requirements. Multi agent system\ntechnology in recent times has emerged as a possible way of efficient solution\nimplementation for many such complex problems. Our research here focuses on\nbuilding a Multi Agent System (MAS), which implements a modified version of\nGravitational Search swarm intelligence Algorithm (GSA) to find out an optimal\nstrategy in managing the demand supply chain. We target the grains distribution\nsystem among various centers of Food Corporation of India (FCI) as application\ndomain. We assume centers with larger stocks as objects of greater mass and\nvice versa. Applying Newtonian law of gravity as suggested in GSA, larger\nobjects attract objects of smaller mass towards itself, creating a virtual\ngrain supply source. As heavier object sheds its mass by supplying some to the\none in demand, it loses its gravitational pull and thus keeps the whole system\nof supply chain per-fectly in balance. The multi agent system helps in\ncontinuous updation of the whole system with the help of autonomous agents\nwhich react to the change in environment and act accordingly. This model also\nreduces the communication bottleneck to greater extents.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.0308v1"
    },
    {
        "title": "Challenges and Directions for Engineering Multi-agent Systems",
        "authors": [
            "Michael Winikoff"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  In this talk I review where we stand regarding the engineering of multi-agent\nsystems. There is both good news and bad news. The good news is that over the\npast decade we've made considerable progress on techniques for engineering\nmulti-agent systems: we have good, usable methodologies, and mature tools.\nFurthermore, we've seen a wide range of demonstrated applications, and have\neven begun to quantify the advantages of agent technology. However, industry\ninvolvement in AAMAS appears to be declining (as measured by industry\nsponsorship of the conference), and industry affiliated attendants at AAMAS\n2012 were few (1-2%). Furthermore, looking at the applications of agents being\nreported at recent AAMAS, usage of Agent Oriented Software Engineering (AOSE)\nand of Agent Oriented Programming Languages (AOPLs) is quite limited. This\nobservation is corroborated by the results of a 2008 survey by Frank and\nVirginia Dignum. Based on these observations, I make five recommendations: (1)\nRe-engage with industry; (2) Stop designing AOPLs and AOSE methodologies ...\nand instead ... (3) Move to the \"macro\" level: develop techniques for designing\nand implementing interaction, integrate micro (single cognitive agent) and\nmacro (MAS) design and implementation; (4) Develop techniques for the Assurance\nof MAS; and (5) Re-engage with the US.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.1428v1"
    },
    {
        "title": "Testing demand responsive shared transport services via agent-based\n  simulations",
        "authors": [
            "Giuseppe Inturri",
            "Nadia Giuffrida",
            "Matteo Ignaccolo",
            "Michela Le Pira",
            "Alessandro Pluchino",
            "Andrea Rapisarda"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Demand Responsive Shared Transport DRST services take advantage of\nInformation and Communication Technologies ICT, to provide on demand transport\nservices booking in real time a ride on a shared vehicle. In this paper, an\nagent-based model ABM is presented to test different the feasibility of\ndifferent service configurations in a real context. First results show the\nimpact of route choice strategy on the system performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.08867v1"
    },
    {
        "title": "Co-evolution and morphogenetic systems",
        "authors": [
            "Juste Raimbault"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The emerging field of morphogenetic engineering proposes to design complex\nheterogeneous system focused on the paradigm of emergence. Necessarily at the\ninterface of disciplines, its concepts can be defined through multiple\nviewpoints. This contribution aims at linking a co-evolutionary perspective on\nsuch systems with morphogenesis, and therein at bringing a novel conceptual\napproach to the bottom-up design of complex systems which allows to fully\nconsider co-evolutive processes. We first situate systems of interest at the\ninterface between biological and social systems, and introduce a\nmultidisciplinary perspective on co-evolution. Building on Holland's signals\nand boundaries theory of complex adaptive systems, we finally suggest that\nmorphogenetic systems are equivalent to combinations of co-evolutionary niches.\nThis introduces an entry to morphogenetic engineering focused on co-evolution\nbetween components of a system. Applications can be found in a broad range of\nsubjects, which we illustrate with the example of planning in territorial\nsystems, suggesting an extended scope for the relevance of morphogenetic\nengineering concepts.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.11457v1"
    },
    {
        "title": "Ontology-based multi-agent system to support business users and\n  management",
        "authors": [
            "Dejan Lavbič",
            "Olegas Vasilecas",
            "Rok Rupnik"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  For some decision processes a significant added value is achieved when\nenterprises' internal Data Warehouse (DW) can be integrated and combined with\nexternal data gained from web sites of competitors and other relevant Web\nsources. In this paper we discuss the agent-based integration approach using\nontologies (DSS-MAS). In this approach data from internal DW and external\nsources are scanned by coordinated group of agents, while semantically\nintegrated and relevant data is reported to business users according to\nbusiness rules. After data from internal DW, Web sources and business rules are\nacquired, agents using these data and rules can infer new knowledge and\ntherefore facilitate decision making process. Knowledge represented in\nenterprises' ontologies is acquired from business users without extensive\ntechnical knowledge using user friendly user interface based on constraints and\npredefined templates. The approach presented in the paper was verified using\nthe case study from the domain of mobile communications with the emphasis on\nsupply and demand of mobile phones.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.03646v1"
    },
    {
        "title": "Multi-agents features on Android platforms",
        "authors": [
            "Camelia-M. Pintea",
            "Andreea Camelia Tripon",
            "Anca Avram",
            "Gloria-Cerasela Crisan"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The current paper shows the multi-agents capabilities to make a valid and\nflexible application when using a framework. Agent-based functions were used\nwithin JADE framework to make an Android messenger application with all\nrequirements included. In the paper are described the architecture, the main\nfunctions and the databases integration of the user friendly agent-based\napplication. There are included existing and possible multi-agents\ncharacteristics to provide integration with mobile platforms and storage\nchallenges to improve the user experience through data mining.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.05826v1"
    },
    {
        "title": "Sybil-Resilient Reality-Aware Social Choice",
        "authors": [
            "Gal Shahaf",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Sybil attacks, in which fake or duplicate identities (\\emph{sybils})\ninfiltrate an online community, pose a serious threat to such communities, as\nthey might tilt community-wide decisions in their favor. While the extensive\nresearch on sybil identification may help keep the fraction of sybils in such\ncommunities low, it cannot however ensure their complete eradication. Thus, our\ngoal is to enhance social choice theory with effective group decision\nmechanisms for communities with bounded sybil penetration. Inspired by\nReality-Aware Social Choice, we use the status quo as the anchor of \\emph{sybil\nresilience}, characterized by \\emph{sybil safety} -- the inability of sybils to\nchange the status quo against the will of the genuine agents, and \\emph{sybil\nliveness} -- the ability of the genuine agents to change the status quo against\nthe will of the sybils.\n  We consider the social choice settings of deciding on a single proposal, on\nmultiple proposals, and on updating a parameter. For each, we present social\nchoice rules that are sybil-safe and, under certain conditions, satisfy\nsybil-liveness.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.11105v5"
    },
    {
        "title": "A Game-Theoretic Framework for Resource Sharing in Clouds",
        "authors": [
            "Faheem Zafari",
            "Kin K. Leung",
            "Don Towsley",
            "Prithwish Basu",
            "Ananthram Swami"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Providing resources to different users or applications is fundamental to\ncloud computing. This is a challenging problem as a cloud service provider may\nhave insufficient resources to satisfy all user requests. Furthermore,\nallocating available resources optimally to different applications is also\nchallenging. Resource sharing among different cloud service providers can\nimprove resource availability and resource utilization as certain cloud service\nproviders may have free resources available that can be ``rented'' by other\nservice providers. However, different cloud service providers can have\ndifferent objectives or \\emph{utilities}. Therefore, there is a need for a\nframework that can share and allocate resources in an efficient and effective\nway, while taking into account the objectives of various service providers that\nresults in a \\emph{multi-objective optimization} problem. In this paper, we\npresent a \\emph{Cooperative Game Theory} (CGT) based framework for resource\nsharing and allocation among different service providers with varying\nobjectives that form a coalition. We show that the resource sharing problem can\nbe modeled as an $N-$player \\emph{canonical} cooperative game with\n\\emph{non-transferable utility} (NTU) and prove that the game is convex for\nmonotonic non-decreasing utilities. We propose an $\\mathcal{O}({N})$ algorithm\nthat provides an allocation from the \\emph{core}, hence guaranteeing\n\\emph{Pareto optimality}. We evaluate the performance of our proposed resource\nsharing framework in a number of simulation settings and show that our proposed\nframework improves user satisfaction and utility of service providers.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.00820v2"
    },
    {
        "title": "Modelling Social Care Provision in An Agent-Based Framework with Kinship\n  Networks",
        "authors": [
            "Umberto Gostoli",
            "Eric Silverman"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Current demographic trends in the UK include a fast-growing elderly\npopulation and dropping birth rates, and demand for social care amongst the\naged is rising. The UK depends on informal social care -- family members or\nfriends providing care -- for some 50\\% of care provision. However, lower birth\nrates and a graying population mean that care availability is becoming a\nsignificant problem, causing concern amongst policy-makers that substantial\npublic investment in formal care will be required in decades to come. In this\npaper we present an agent-based simulation of care provision in the UK, in\nwhich individual agents can decide to provide informal care, or pay for private\ncare, for their loved ones. Agents base these decisions on factors including\ntheir own health, employment status, financial resources, relationship to the\nindividual in need, and geographical location. Results demonstrate that the\nmodel can produce similar patterns of care need and availability as is observed\nin the real world, despite the model containing minimal empirical data. We\npropose that our model better captures the complexities of social care\nprovision than other methods, due to the socioeconomic details present and the\nuse of kinship networks to distribute care amongst family members.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.05267v1"
    },
    {
        "title": "LegenDary 2012 Soccer 2D Simulation Team Description Paper",
        "authors": [
            "Pourya Saljoughi",
            "Reza Ma'anijou",
            "Ehsan Fouladi",
            "Narges Majidi",
            "Saber Yaghoobi",
            "Houman Fallah",
            "Saeideh Zahedi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In LegenDary project, we started a new research based on Agent2D in RoboCup\n2D soccer simulation. In this paper, we mainly present the team algorithms and\nstructures which we used to develop our team in separated section. We have\nfocused on passing, dribbling and blocking skills. We improved them and made\nthe team ready for this competition. Through pass is the most important part of\nour team that we work a lot on it.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.08310v1"
    },
    {
        "title": "Genuine Personal Identifiers and Mutual Sureties for Sybil-Resilient\n  Community Formation",
        "authors": [
            "Gal Shahaf",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  While most of humanity is suddenly on the net, the value of this singularity\nis hampered by the lack of credible digital identities: Social networking,\nperson-to-person transactions, democratic conduct, cooperation and philanthropy\nare all hampered by the profound presence of fake identities, as illustrated by\nFacebook's removal of 5.4Bn fake accounts since the beginning of 2019.\n  Here, we introduce the fundamental notion of a \\emph{genuine personal\nidentifier}---a globally unique and singular identifier of a person---and\npresent a foundation for a decentralized, grassroots, bottom-up process in\nwhich every human being may create, own, and protect the privacy of a genuine\npersonal identifier. The solution employs mutual sureties among owners of\npersonal identifiers, resulting in a mutual-surety graph reminiscent of a\nweb-of-trust. Importantly, this approach is designed for a distributed\nrealization, possibly using distributed ledger technology, and does not depend\non the use or storage of biometric properties. For the solution to be complete,\nadditional components are needed, notably a mechanism that encourages honest\nbehavior and a sybil-resilient governance system.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.09630v5"
    },
    {
        "title": "Consensus Control for Leader-follower Multi-agent Systems under\n  Prescribed Performance Guarantees",
        "authors": [
            "Fei Chen",
            "Dimos V. Dimarogonas"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper addresses the problem of distributed control for leader-follower\nmulti-agent systems under prescribed performance guarantees. Leader-follower is\nmeant in the sense that a group of agents with external inputs are selected as\nleaders in order to drive the group of followers in a way that the entire\nsystem can achieve consensus within certain prescribed performance transient\nbounds. Under the assumption of tree graphs, a distributed control law is\nproposed when the decay rate of the performance functions is within a\nsufficient bound. Then, two classes of tree graphs that can have additional\nfollowers are investigated. Finally, several simulation examples are given to\nillustrate the results.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12771v1"
    },
    {
        "title": "A sub-modular receding horizon solution for mobile multi-agent\n  persistent monitoring",
        "authors": [
            "Navid Rezazadeh",
            "Solmaz S. Kia"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We study the problem of persistent monitoring of a finite number of\ninter-connected geographical nodes by a group of heterogeneous mobile agents.\nWe assign to each geographical node a concave and increasing reward function\nthat resets to zero after an agent's visit. Then, we design the optimal\ndispatch policy of which nodes to visit at what time and by what agent by\nfinding a policy set that maximizes a utility that is defined as the total\nreward collected at visit times. We show that this optimization problem is\nNP-hard and its computational complexity increases exponentially with the\nnumber of the agents and the length of the mission horizon. By showing that the\nutility function is a monotone increasing and submodular set function of\nagents' policy, we proceed to propose a suboptimal dispatch policy design with\na known optimality gap. To reduce the time complexity of constructing the\nfeasible search set and also to induce robustness to changes in the operational\nfactors, we perform our suboptimal policy design in a receding horizon fashion.\nThen, to compensate for the shortsightedness of the receding horizon approach\nfor reward distribution beyond the feasible policies of the agents over the\nreceding horizon, we add a new term to our utility, which provides a measure of\nnodal importance beyond the receding horizon's sight. This term gives the\npolicy design an intuition to steer the agents towards the nodes with higher\nrewards on the patrolling graph. Finally, we discuss how our proposed algorithm\ncan be implemented in a decentralized manner. A simulation study demonstrates\nour results.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.04425v3"
    },
    {
        "title": "Massive Multi-Agent Data-Driven Simulations of the GitHub Ecosystem",
        "authors": [
            "Jim Blythe",
            "John Bollenbacher",
            "Di Huang",
            "Pik-Mai Hui",
            "Rachel Krohn",
            "Diogo Pacheco",
            "Goran Muric",
            "Anna Sapienza",
            "Alexey Tregubov",
            "Yong-Yeol Ahn",
            "Alessandro Flammini",
            "Kristina Lerman",
            "Filippo Menczer",
            "Tim Weninger",
            "Emilio Ferrara"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Simulating and predicting planetary-scale techno-social systems poses heavy\ncomputational and modeling challenges. The DARPA SocialSim program set the\nchallenge to model the evolution of GitHub, a large collaborative\nsoftware-development ecosystem, using massive multi-agent simulations. We\ndescribe our best performing models and our agent-based simulation framework,\nwhich we are currently extending to allow simulating other planetary-scale\ntechno-social systems. The challenge problem measured participant's ability,\ngiven 30 months of meta-data on user activity on GitHub, to predict the next\nmonths' activity as measured by a broad range of metrics applied to ground\ntruth, using agent-based simulation. The challenge required scaling to a\nsimulation of roughly 3 million agents producing a combined 30 million actions,\nacting on 6 million repositories with commodity hardware. It was also important\nto use the data optimally to predict the agent's next moves. We describe the\nagent framework and the data analysis employed by one of the winning teams in\nthe challenge. Six different agent models were tested based on a variety of\nmachine learning and statistical methods. While no single method proved the\nmost accurate on every metric, the broadly most successful sampled from a\nstationary probability distribution of actions and repositories for each agent.\nTwo reasons for the success of these agents were their use of a distinct\ncharacterization of each agent, and that GitHub users change their behavior\nrelatively slowly.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.05437v1"
    },
    {
        "title": "Cluster-based Distributed Augmented Lagrangian Algorithm for a Class of\n  Constrained Convex Optimization Problems",
        "authors": [
            "Hossein Moradian",
            "Solmaz S. Kia"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We propose a distributed solution for a constrained convex optimization\nproblem over a network of clustered agents each consisted of a set of\nsubagents. The communication range of the clustered agents is such that they\ncan form a connected undirected graph topology. The total cost in this\noptimization problem is the sum of the local convex costs of the subagents of\neach cluster. We seek a minimizer of this cost subject to a set of affine\nequality constraints, and a set of affine inequality constraints specifying the\nbounds on the decision variables if such bounds exist. We design our\ndistributed algorithm in a cluster-based framework which results in a\nsignificant reduction in communication and computation costs. Our proposed\ndistributed solution is a novel continuous-time algorithm that is linked to the\naugmented Lagrangian approach. It converges asymptotically when the local cost\nfunctions are convex and exponentially when they are strongly convex and have\nLipschitz gradients. Moreover, we use an $\\epsilon$-exact penalty function to\naddress the inequality constraints and derive an explicit lower bound on the\npenalty function weight to guarantee convergence to $\\epsilon$-neighborhood of\nthe global minimum value of the cost. A numerical example demonstrates our\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.06634v4"
    },
    {
        "title": "Immediate Observation in Mediated Population Protocols",
        "authors": [
            "Tobias Prehn",
            "Myron Rotter"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper we analyze the computational power of variants of population\nprotocols (PP), a formalism for distributed systems with anonymous agents\nhaving very limited capabilities. The capabilities of agents are enhanced in\nmediated population protocols (MPP) by recording the states in the edges of the\ninteraction graph. Restricting the interactions to the communication model of\nimmediate observation (IO) reduces the computational power of the resulting\nformalism. We show that this enhancement and restriction, when combined, yield\na model (IOMPP) at least as powerful as the basic PP. The proof requires a\nnovel notion of configurations in the MPP model allowing differentiation of\nagents and uses techniques similar to methods of analyzing encoding criteria,\nnamely operational correspondence. The constructional part of the proof is\ngeneric in a way that all protocols can be translated into the new model\nwithout losing the desirable properties they might have besides a stable\noutput. Furthermore, we illustrate how this approach could be utilized to prove\nour conjecture of IOMPP model being even as expressive as the MPP model. If our\nconjecture holds, this would result in a sharp characterization of the\ncomputational power and reveal the nonnecessity of two-way communication in the\ncontext of mediated population protocols.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.08637v1"
    },
    {
        "title": "Universal Policies to Learn Them All",
        "authors": [
            "Hassam Ullah Sheikh",
            "Ladislau Bölöni"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We explore a collaborative and cooperative multi-agent reinforcement learning\nsetting where a team of reinforcement learning agents attempt to solve a single\ncooperative task in a multi-scenario setting. We propose a novel multi-agent\nreinforcement learning algorithm inspired by universal value function\napproximators that not only generalizes over state space but also over a set of\ndifferent scenarios. Additionally, to prove our claim, we are introducing a\nchallenging 2D multi-agent urban security environment where the learning agents\nare trying to protect a person from nearby bystanders in a variety of\nscenarios. Our study shows that state-of-the-art multi-agent reinforcement\nlearning algorithms fail to generalize a single task over multiple scenarios\nwhile our proposed solution works equally well as scenario-dependent policies.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.09184v1"
    },
    {
        "title": "The Effectiveness of Managed Lane Strategies for the Near-term\n  Deployment of Cooperative Adaptive Cruise Control",
        "authors": [
            "Zijia Zhong",
            "Joyoung Lee"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Traffic simulation is a cost-effective way to test the deployment of\nCooperative Adaptive Cruise Control (CACC) vehicles in a large-scale\ntransportation network. By using a previously developed microscopic simulation\ntestbed, this paper examines the impacts of four managed lane strategies for\nthe near-term deployment of CACC vehicles under mixed traffic conditions.\nNetwork-wide performance measures are investigated from the perspectives of\nmobility, safety, equity, and environmental impacts. In addition, the platoon\nformation performance of CACC vehicles is evaluated with platoon-orientated\nmeasures, such as the percentage of platooned CACC vehicles, average platoon\ndepth, and vehicle-hour-platooned that is proposed in this paper under the\nimperfect DSRC communication environment. Moreover, managed lane score matrices\nare developed to incorporate heterogeneous categories of performance measures,\naiming to provide a more comprehensive picture for stakeholders. The results\nshow that mixing CACC traffic along with non-CACC traffic across all travel\nlanes is an acceptable option when the market penetration (MP) is lower than\n30% for roadways where a managed lane is absent. Providing CACC with priority\naccess to an existing managed lane, if available, is also a good strategy for\nimproving the overall traffic performance when the MP is lower than 40%. When\nthe MP reaches above 40%, a dedicated lane for CACC vehicles is recommended, as\nit provides greater opportunity for CACC vehicles to form platoons. The\nfacilitation of homogeneous CACC traffic flow could make further improvements\npossible in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.10404v2"
    },
    {
        "title": "Modelling Bushfire Evacuation Behaviours",
        "authors": [
            "Joel Robertson"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Bushfires pose a significant threat to Australia's regional areas. To\nminimise risk and increase resilience, communities need robust evacuation\nstrategies that account for people's likely behaviour both before and during a\nbushfire. Agent-based modelling (ABM) offers a practical way to simulate a\nrange of bushfire evacuation scenarios. However, the ABM should reflect the\ndiversity of possible human responses in a given community. The\nBelief-Desire-Intention (BDI) cognitive model captures behaviour in a compact\nrepresentation that is understandable by domain experts. Within a BDI-ABM\nsimulation, individual BDI agents can be assigned profiles that determine their\nlikely behaviour. Over a population of agents their collective behaviour will\ncharacterise the community response. These profiles are drawn from existing\nhuman behaviour research and consultation with emergency services personnel and\ncapture the expected behaviours of identified groups in the population, both\nprior to and during an evacuation. A realistic representation of each community\ncan then be formed, and evacuation scenarios within the simulation can be used\nto explore the possible impact of population structure on outcomes. It is hoped\nthat this will give an improved understanding of the risks associated with\nevacuation, and lead to tailored evacuation plans for each community to help\nthem prepare for and respond to bushfire.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.00991v1"
    },
    {
        "title": "Simulation and computational analysis of multiscale graph agent-based\n  tumor model",
        "authors": [
            "Ghazal Tashakor",
            "Remo Suppi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper deals with the cellular biological network analysis of the\ntumor-growth model, consisting of multiple spaces and time scales. In this\npaper, we present a model in graph simulation using ABM for tumor growth. In\nparticular, we propose a graph agent-based modeling and simulation system in\nthe format of tumor growth scenario for evolving analysis. To manage cellular\nbiological network analysis, we developed a workflow that allows us to estimate\nthe tumor model and the complexity of the evolving behavior in a principled\nmanner. By developing the model using Python, which has enabled us to run the\nmodel multiple times (more than what is possible by conventional means) to\ngenerate a large amount of data, we have succeeded in getting deep in to the\nmicro-environment of the tumor, employing network analysis. Combining\nagent-based modeling with graph-based modeling to simulate the structure,\ndynamics, and functions of complex networks is exclusively important for\nbiological systems with a large number of open parameters, e.g., epidemic\nmodels of disease spreading or cancer. Extracting data from evolutionary\ndirected graphs and a set of centrality algorithms helps us to tackle the\nproblems of pathway analysis and to develop the ability to predict, control,\nand design the function of metabolisms. Reproducing and performing complex\nparametric simulations a known phenomenon at a sufficient level of detail for\ncomputational biology could be an impressive achievement for fast analysis\npurposes in clinics, both on the predictive diagnostic and therapeutic side.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.01711v1"
    },
    {
        "title": "Agent-based model for tumour-analysis using Python+Mesa",
        "authors": [
            "Ghazal Tashakor",
            "Remo Suppi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The potential power provided and possibilities presented by computation\ngraphs has steered most of the available modeling techniques to\nre-implementing, utilization and including the complex nature of System Biology\n(SB). To model the dynamics of cellular population, we need to study a plethora\nof scenarios ranging from cell differentiation to tumor growth and etcetera.\nTest and verification of a model in research means running the model multiple\ntimes with different or in some cases identical parameters, to see how the\nmodel interacts and if some of the outputs would change regarding different\nparameters. In this paper, we will describe the development and implementation\nof a new agent-based model using Python. The model can be executed using a\ndevelopment environment (based on Mesa, and extremely simplified for\nconvenience) with different parameters. The result is collecting large sets of\ndata, which will allow an in-depth analysis in the microenvironment of the\ntumor by the means of network analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.01885v1"
    },
    {
        "title": "Lower bound performances for average consensus in open multi-agent\n  systems (extended version)",
        "authors": [
            "Charles Monnoyer de Galland",
            "Julien M. Hendrickx"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We derive fundamental limitations on the performances of intrinsic averaging\nalgorithms in open multi-agent systems, which are systems subject to random\narrivals and departures of agents. Each agent holds a value, and their goal is\nto estimate the average of the values of the agents presently in the system. We\nprovide a lower bound on the expected Mean Square Error for any estimation\nalgorithm, assuming that the number of agents remains constant and that\ncommunications are random and pairwise. Our derivation is based on the expected\nerror obtained with an optimal algorithm under conditions more favorable than\nthose the actual problem allows, and relies on an analysis of the constraints\non the information spreading mechanisms in the system, and relaxations of\nthese.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.02475v2"
    },
    {
        "title": "An Architectural Style for Self-Adaptive Multi-Agent Systems",
        "authors": [
            "Danny Weyns",
            "Flavio Oquendo"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Modern distributed software systems often operate in dynamic environments in\nwhich operation conditions change continuously and subsystems may come and go\nat will, e.g. intelligent traffic management and multi-robot systems. To manage\nthese dynamics, these systems have to self-adapt their structures and behaviors\ndynamically. While we have witnessed significant progress over the past decade\nin the manner in which such systems are designed, persistent challenges remain.\nIn particular, dealing with distribution and decentralized control remains one\nof the major challenges in self-adaptive systems. This report presents an\narchitecture style that supports software architects with designing\narchitectures for a family of decentralized self-adaptive systems. The\narchitecture style structures the software in a number of interacting\nautonomous entities (agents) that cooperatively realize the system tasks.\nMulti-agent systems derived from the architectural style realize flexibility\n(agents adapt their behavior and interactions to variable operating conditions)\nand openness (agents cope autonomously with other agents that enter and leave\nthe system). The architectural style consists of five related patterns that\ndistill domain-specific architectural knowledge derived from extensive\nexperiences with developing various multi-agent systems. The architectural\npatterns are specified using pi-ADL, a formal architectural description\nlanguage supporting specification of dynamic architectures. This specification\nprovides architects with a rigorous description of the architecture elements of\nthe patterns, their interactions and behavior. We illustrate how we have\napplied the architectural style with excerpts of two cases from our practice:\nan experimental system for anticipatory traffic routing and an industrial\nlogistic system for automated transportation in warehouse environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.03475v1"
    },
    {
        "title": "Signal Instructed Coordination in Cooperative Multi-agent Reinforcement\n  Learning",
        "authors": [
            "Liheng Chen",
            "Hongyi Guo",
            "Yali Du",
            "Fei Fang",
            "Haifeng Zhang",
            "Yaoming Zhu",
            "Ming Zhou",
            "Weinan Zhang",
            "Qing Wang",
            "Yong Yu"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In many real-world problems, a team of agents need to collaborate to maximize\nthe common reward. Although existing works formulate this problem into a\ncentralized learning with decentralized execution framework, which avoids the\nnon-stationary problem in training, their decentralized execution paradigm\nlimits the agents' capability to coordinate. Inspired by the concept of\ncorrelated equilibrium, we propose to introduce a coordination signal to\naddress this limitation, and theoretically show that following mild conditions,\ndecentralized agents with the coordination signal can coordinate their\nindividual policies as manipulated by a centralized controller. The idea of\nintroducing coordination signal is to encapsulate coordinated strategies into\nthe signals, and use the signals to instruct the collaboration in decentralized\nexecution. To encourage agents to learn to exploit the coordination signal, we\npropose Signal Instructed Coordination (SIC), a novel coordination module that\ncan be integrated with most existing MARL frameworks. SIC casts a common signal\nsampled from a pre-defined distribution to all agents, and introduces an\ninformation-theoretic regularization to facilitate the consistency between the\nobserved signal and agents' policies. Our experiments show that SIC\nconsistently improves performance over well-recognized MARL models in both\nmatrix games and a predator-prey game with high-dimensional strategy space.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.04224v2"
    },
    {
        "title": "On Re-Balancing Self-Interested Agents in Ride-Sourcing Transportation\n  Networks",
        "authors": [
            "Armin Sadeghi",
            "Stephen L. Smith"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper focuses on the problem of controlling self-interested drivers in\nride-sourcing applications. Each driver has the objective of maximizing its\nprofit, while the ride-sourcing company focuses on customer experience by\nseeking to minimizing the expected wait time for pick-up. These objectives are\nnot usually aligned, and the company has no direct control on the waiting\nlocations of the drivers. In this paper, we provide two indirect control\nmethods to optimize the set of waiting locations of the drivers, thereby\nminimizing the expected wait time of the customers: 1) sharing the location of\nall drivers with a subset of drivers, and 2) paying the drivers to relocate. We\nshow that finding the optimal control for each method is NP-hard and we provide\nalgorithms to find near-optimal control in each case. We evaluate the\nperformance of the proposed control methods on real-world data and show that we\ncan achieve between 20% to 80% improvement in the expected response.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.04615v1"
    },
    {
        "title": "On Memory Mechanism in Multi-Agent Reinforcement Learning",
        "authors": [
            "Yilun Zhou",
            "Derrik E. Asher",
            "Nicholas R. Waytowich",
            "Julie A. Shah"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Multi-agent reinforcement learning (MARL) extends (single-agent)\nreinforcement learning (RL) by introducing additional agents and (potentially)\npartial observability of the environment. Consequently, algorithms for solving\nMARL problems incorporate various extensions beyond traditional RL methods,\nsuch as a learned communication protocol between cooperative agents that\nenables exchange of private information or adaptive modeling of opponents in\ncompetitive settings. One popular algorithmic construct is a memory mechanism\nsuch that an agent's decisions can depend not only upon the current state but\nalso upon the history of observed states and actions. In this paper, we study\nhow a memory mechanism can be useful in environments with different properties,\nsuch as observability, internality and presence of a communication channel.\nUsing both prior work and new experiments, we show that a memory mechanism is\nhelpful when learning agents need to model other agents and/or when\ncommunication is constrained in some way; however we must to be cautious of\nagents achieving effective memoryfulness through other means.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.05232v1"
    },
    {
        "title": "Modeling Sensorimotor Coordination as Multi-Agent Reinforcement Learning\n  with Differentiable Communication",
        "authors": [
            "Bowen Jing",
            "William Yin"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Multi-agent reinforcement learning has shown promise on a variety of\ncooperative tasks as a consequence of recent developments in differentiable\ninter-agent communication. However, most architectures are limited to pools of\nhomogeneous agents, limiting their applicability. Here we propose a modular\nframework for learning complex tasks in which a traditional monolithic agent is\nframed as a collection of cooperating heterogeneous agents. We apply this\napproach to model sensorimotor coordination in the neocortex as a multi-agent\nreinforcement learning problem. Our results demonstrate proof-of-concept of the\nproposed architecture and open new avenues for learning complex tasks and for\nunderstanding functional localization in the brain and future intelligent\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.05815v1"
    },
    {
        "title": "AED: An Anytime Evolutionary DCOP Algorithm",
        "authors": [
            "Saaduddin Mahmud",
            "Moumita Choudhury",
            "Md. Mosaddek Khan",
            "Long Tran-Thanh",
            "Nicholas R. Jennings"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Evolutionary optimization is a generic population-based metaheuristic that\ncan be adapted to solve a wide variety of optimization problems and has proven\nvery effective for combinatorial optimization problems. However, the potential\nof this metaheuristic has not been utilized in Distributed Constraint\nOptimization Problems (DCOPs), a well-known class of combinatorial optimization\nproblems prevalent in Multi-Agent Systems. In this paper, we present a novel\npopulation-based algorithm, Anytime Evolutionary DCOP (AED), that uses\nevolutionary optimization to solve DCOPs. In AED, the agents cooperatively\nconstruct an initial set of random solutions and gradually improve them through\na new mechanism that considers an optimistic approximation of local benefits.\nMoreover, we present a new anytime update mechanism for AED that identifies the\nbest among a distributed set of candidate solutions and notifies all the agents\nwhen a new best is found. In our theoretical analysis, we prove that AED is\nanytime. Finally, we present empirical results indicating AED outperforms the\nstate-of-the-art DCOP algorithms in terms of solution quality.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.06254v4"
    },
    {
        "title": "Speeding Up Distributed Pseudo-tree Optimization Procedure with Cross\n  Edge Consistency to Solve DCOPs",
        "authors": [
            "Mashrur Rashik",
            "Md. Musfiqur Rahman",
            "Md. Mamun-or-Rashid",
            "Md. Mosaddek Khan"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Distributed Pseudo-tree Optimization Procedure (DPOP) is a well-known message\npassing algorithm that has been used to provide optimal solutions of\nDistributed Constraint Optimization Problems (DCOPs) -- a framework that is\ndesigned to optimize constraints in cooperative multi-agent systems. The\ntraditional DCOP formulation does not consider those constraints that must be\nsatisfied (also known as hard constraints), rather it concentrates only on soft\nconstraints. However, the presence of both types of constraints are observed in\na number of applications, such as Distributed Radio Link Frequency Assignment\nand Distributed Event Scheduling, etc. Although the combination of these types\nof constraints is recently incorporated in DPOP to solve DCOPs, scalability\nremains an issue for them as finding an optimal solution is NP-hard.\nAdditionally, in DPOP, the agents are arranged as a DFS pseudo-tree. Recently\nit has been observed that the constructed pseudo-trees in this way often come\nto be chain-like and greatly impair the algorithm's performance. To address\nthese issues, we develop an algorithm that speeds up the DPOP algorithm by\nreducing the size of the messages exchanged and increasing parallelism in the\npseudo tree. Our empirical evidence suggests that our approach outperforms the\nstate-of-the-art algorithms by a significant margin.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.06537v1"
    },
    {
        "title": "SPSC: a new execution policy for exploring discrete-time stochastic\n  simulations",
        "authors": [
            "Yu-Lin Huang",
            "Gildas Morvan",
            "Frédéric Pichon",
            "David Mercier"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we introduce a new method called SPSC (Simulation,\nPartitioning, Selection, Cloning) to estimate efficiently the probability of\npossible solutions in stochastic simulations. This method can be applied to any\ntype of simulation, however it is particularly suitable for multi-agent-based\nsimulations (MABS). Therefore, its performance is evaluated on a well-known\nMABS and compared to the classical approach, i.e., Monte Carlo.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.09390v1"
    },
    {
        "title": "MCTS-based Automated Negotiation Agent",
        "authors": [
            "Cédric Buron",
            "Zahia Guessoum",
            "Sylvain Ductor"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper introduces a new negotiating agent model for automated\nnegotiation. We focus on applications without time pressure with\nmultidi-mensional negotiation on both continuous and discrete domains. The\nagent bidding strategy relies on Monte Carlo Tree Search, which is a trendy\nmethod since it has been used with success on games with high branching factor\nsuch as Go. It also exploits opponent modeling techniques thanks to Gaussian\nprocess regression and Bayesian learning. Evaluation is done by confronting the\nexisting agents that are able to negotiate in such context: Random Walker,\nTit-for-tat and Nice Tit-for-Tat. None of those agents succeeds in beating our\nagent. Also, the modular and adaptive nature of our approach is a huge\nadvantage when it comes to optimize it in specific applicative contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.09461v1"
    },
    {
        "title": "$α^α$-Rank: Practically Scaling $α$-Rank through\n  Stochastic Optimisation",
        "authors": [
            "Yaodong Yang",
            "Rasul Tutunov",
            "Phu Sakulwongtana",
            "Haitham Bou Ammar"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Recently, $\\alpha$-Rank, a graph-based algorithm, has been proposed as a\nsolution to ranking joint policy profiles in large scale multi-agent systems.\n$\\alpha$-Rank claimed tractability through a polynomial time implementation\nwith respect to the total number of pure strategy profiles. Here, we note that\ninputs to the algorithm were not clearly specified in the original\npresentation; as such, we deem complexity claims as not grounded, and\nconjecture solving $\\alpha$-Rank is NP-hard. The authors of $\\alpha$-Rank\nsuggested that the input to $\\alpha$-Rank can be an exponentially-sized payoff\nmatrix; a claim promised to be clarified in subsequent manuscripts. Even though\n$\\alpha$-Rank exhibits a polynomial-time solution with respect to such an\ninput, we further reflect additional critical problems. We demonstrate that due\nto the need of constructing an exponentially large Markov chain, $\\alpha$-Rank\nis infeasible beyond a small finite number of agents. We ground these claims by\nadopting amount of dollars spent as a non-refutable evaluation metric.\nRealising such scalability issue, we present a stochastic implementation of\n$\\alpha$-Rank with a double oracle mechanism allowing for reductions in joint\nstrategy spaces. Our method, $\\alpha^\\alpha$-Rank, does not need to save\nexponentially-large transition matrix, and can terminate early under required\nprecision. Although theoretically our method exhibits similar worst-case\ncomplexity guarantees compared to $\\alpha$-Rank, it allows us, for the first\ntime, to practically conduct large-scale multi-agent evaluations. On $10^4\n\\times 10^4$ random matrices, we achieve $1000x$ speed reduction. Furthermore,\nwe also show successful results on large joint strategy profiles with a maximum\nsize in the order of $\\mathcal{O}(2^{25})$ ($\\approx 33$ million joint\nstrategies) -- a setting not evaluable using $\\alpha$-Rank with reasonable\ncomputational budget.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.11628v6"
    },
    {
        "title": "Explaining Agent-Based Financial Market Simulation",
        "authors": [
            "David Byrd"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper is intended to explain, in simple terms, some of the mechanisms\nand agents common to multiagent financial market simulations. We first discuss\nthe necessity to include an exogenous price time series (\"the fundamental\nvalue\") for each asset and three methods for generating that series. We then\nillustrate one process by which a Bayesian agent may receive limited\nobservations of the fundamental series and estimate its current and future\nvalues. Finally, we present two such agents widely examined in the literature,\nthe Zero Intelligence agent and the Heuristic Belief Learning agent, which\nimplement different approaches to order placement.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.11650v1"
    },
    {
        "title": "A Comprehensive Study on Pedestrians' Evacuation",
        "authors": [
            "Danial A. Muhammed",
            "Soran Saeed",
            "Tarik A. Rashid"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Human beings face threats because of unexpected happenings, which can be\navoided through an adequate crisis evacuation plan, which is vital to stop\nwound and demise as its negative results. Consequently, different typical\nevacuation pedestrians have been created. Moreover, through applied research,\nthese models for various applications, reproductions, and conditions have been\nexamined to present an operational model. Furthermore, new models have been\ndeveloped to cooperate with system evacuation in residential places in case of\nunexpected events. This research has taken into account an inclusive and a\n'systematic survey of pedestrian evacuation' to demonstrate models methods by\nfocusing on the applications' features, techniques, implications, and after\nthat gather them under various types, for example, classical models, hybridized\nmodels, and generic model. The current analysis assists scholars in this field\nof study to write their forthcoming papers about it, which can suggest a novel\nstructure to recent typical intelligent reproduction with novel features.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.01165v1"
    },
    {
        "title": "ElecSim: Monte-Carlo Open-Source Agent-Based Model to Inform Policy for\n  Long-Term Electricity Planning",
        "authors": [
            "Alexander J. M. Kell",
            "Matthew Forshaw",
            "A. Stephen McGough"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Due to the threat of climate change, a transition from a fossil-fuel based\nsystem to one based on zero-carbon is required. However, this is not as simple\nas instantaneously closing down all fossil fuel energy generation and replacing\nthem with renewable sources -- careful decisions need to be taken to ensure\nrapid but stable progress. To aid decision makers, we present a new tool,\nElecSim, which is an open-sourced agent-based modelling framework used to\nexamine the effect of policy on long-term investment decisions in electricity\ngeneration. ElecSim allows non-experts to rapidly prototype new ideas.\n  Different techniques to model long-term electricity decisions are reviewed\nand used to motivate why agent-based models will become an important strategic\ntool for policy. We motivate why an open-source toolkit is required for\nlong-term electricity planning.\n  Actual electricity prices are compared with our model and we demonstrate that\nthe use of a Monte-Carlo simulation in the system improves performance by\n$52.5\\%$. Further, using ElecSim we demonstrate the effect of a carbon tax to\nencourage a low-carbon electricity supply. We show how a {\\pounds}40 ($\\$50$)\nper tonne of CO2 emitted would lead to 70% renewable electricity by 2050.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.01203v1"
    },
    {
        "title": "Cooperative Pathfinding based on memory-efficient Multi-agent RRT*",
        "authors": [
            "Jinmingwu Jiang",
            "Kaigui Wu"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In cooperative pathfinding problems, no-conflicts paths that bring several\nagents from their start location to their destination need to be planned. This\nproblem can be efficiently solved by Multi-agent RRT*(MA-RRT*) algorithm, which\nis still state-of-the-art in the field of coupled methods. However, the\nimplementation of this algorithm is hindered in systems with limited memory\nbecause the number of nodes in the tree grows indefinitely as the paths get\noptimized. This paper proposes an improved version of MA-RRT*, called\nMulti-agent RRT* Fixed Node(MA-RRT*FN), which limits the number of nodes stored\nin the tree by removing the weak nodes on the path which are not likely to\nreach the goal. The results show that MA-RRT*FN performs close to MA-RRT* in\nterms of scalability and solution quality while the memory required is much\nlower and fixed.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.03927v3"
    },
    {
        "title": "SMIX($λ$): Enhancing Centralized Value Functions for Cooperative\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Xinghu Yao",
            "Chao Wen",
            "Yuhui Wang",
            "Xiaoyang Tan"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Learning a stable and generalizable centralized value function (CVF) is a\ncrucial but challenging task in multi-agent reinforcement learning (MARL), as\nit has to deal with the issue that the joint action space increases\nexponentially with the number of agents in such scenarios. This paper proposes\nan approach, named SMIX(${\\lambda}$), to address the issue using an efficient\noff-policy centralized training method within a flexible learner search space.\nAs importance sampling for such off-policy training is both computationally\ncostly and numerically unstable, we proposed to use the ${\\lambda}$-return as a\nproxy to compute the TD error. With this new loss function objective, we adopt\na modified QMIX network structure as the base to train our model. By further\nconnecting it with the ${Q(\\lambda)}$ approach from an unified expectation\ncorrection viewpoint, we show that the proposed SMIX(${\\lambda}$) is equivalent\nto ${Q(\\lambda)}$ and hence shares its convergence properties, while without\nbeing suffered from the aforementioned curse of dimensionality problem inherent\nin MARL. Experiments on the StarCraft Multi-Agent Challenge (SMAC) benchmark\ndemonstrate that our approach not only outperforms several state-of-the-art\nMARL methods by a large margin, but also can be used as a general tool to\nimprove the overall performance of other CTDE-type algorithms by enhancing\ntheir CVFs.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.04094v5"
    },
    {
        "title": "LAC-Nav: Collision-Free Mutiagent Navigation Based on The Local Action\n  Cells",
        "authors": [
            "Li Ning",
            "Yong Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Collision avoidance is one of the most primary requirement in the\ndecentralized multiagent navigations: while the agents are moving towards their\nown targets, attentions should be paid to avoid the collisions with the others.\nIn this paper, we introduce the concept of local action cell, which provides\nfor each agent a set of velocities that are safe to perform. Based on the\nrealtime updated local action cells, we propose the LAC-Nav approach to\nnavigate the agent with the properly selected velocity; and furthermore, we\ncoupled the local action cell with an adaptive learning framework, in which the\neffect of selections are evaluated and used as the references for making\ndecisions in the following updates. Through the experiments for three commonly\nconsidered scenarios, we demonstrated the efficiency of the proposed\napproaches, with the comparison to several widely studied strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.04646v1"
    },
    {
        "title": "Leadership emergence in walking groups",
        "authors": [
            "Maria Lombardi",
            "William H. Warren",
            "M. di Bernardo"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Understanding the mechanisms underlying the emergence of leadership in\nmulti-agent systems is still under investigation in many areas of research\nwhere group coordination is involved. While leadership has been mostly\ninvestigated in the case of animal groups, only a few works address the problem\nof leadership emergence in human ensembles, e.g. pedestrian walking, group\ndance. In this paper we study the emergence of leadership in the specific\nscenario of a small walking group. Our aim is to unveil the main mechanisms\nemerging in a human group when leader or follower roles are not designated a\npriori. Two groups of participants were asked to walk together and turn or\nchange speed at self-selected times. Data were analysed using time-dependent\ncross correlation to infer leader-follower interactions between each pair of\ngroup members. The results indicate that leadership emergence is due both to\ncontextual factors, such as an individual's position in the group, and to\npersonal factors, such as an individual's characteristic locomotor behaviour.\nOur approach can easily be extended to larger groups and other scenarios such\nas team sports and emergency evacuations.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.03700v1"
    },
    {
        "title": "Skill Discovery of Coordination in Multi-agent Reinforcement Learning",
        "authors": [
            "Shuncheng He",
            "Jianzhun Shao",
            "Xiangyang Ji"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Unsupervised skill discovery drives intelligent agents to explore the unknown\nenvironment without task-specific reward signal, and the agents acquire various\nskills which may be useful when the agents adapt to new tasks. In this paper,\nwe propose \"Multi-agent Skill Discovery\"(MASD), a method for discovering skills\nfor coordination patterns of multiple agents. The proposed method aims to\nmaximize the mutual information between a latent code Z representing skills and\nthe combination of the states of all agents. Meanwhile it suppresses the\nempowerment of Z on the state of any single agent by adversarial training. In\nanother word, it sets an information bottleneck to avoid empowerment\ndegeneracy. First we show the emergence of various skills on the level of\ncoordination in a general particle multi-agent environment. Second, we reveal\nthat the \"bottleneck\" prevents skills from collapsing to a single agent and\nenhances the diversity of learned skills. Finally, we show the pretrained\npolicies have better performance on supervised RL tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.04021v1"
    },
    {
        "title": "Polarization in Attraction-Repulsion Models",
        "authors": [
            "Elisabetta Cornacchia",
            "Neta Singer",
            "Emmanuel Abbe"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper introduces a model for opinion dynamics, where at each time step,\nrandomly selected agents see their opinions - modeled as scalars in [0,1] -\nevolve depending on a local interaction function. In the classical Bounded\nConfidence Model, agents opinions get attracted when they are close enough. The\nproposed model extends this by adding a repulsion component, which models the\neffect of opinions getting further pushed away when dissimilar enough. With\nthis repulsion component added, and under a repulsion-attraction cleavage\nassumption, it is shown that a new stable configuration emerges beyond the\nclassical consensus configuration, namely the polarization configuration. More\nspecifically, it is shown that total consensus and total polarization are the\nonly two possible limiting configurations. The paper further provides an\nanalysis of the infinite population regime in dimension 1 and higher, with a\nphase transition phenomenon conjectured and backed heuristically.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.05251v1"
    },
    {
        "title": "Towards Jacamo-rest: A Resource-Oriented Abstraction for Managing\n  Multi-Agent Systems",
        "authors": [
            "Cleber Jorge Amaral",
            "Jomi Fred Hübner",
            "Timotheus Kampik"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The Multi-Agent Oriented Programming (MAOP) paradigm provides abstractions to\nmodel and implements entities of agents, as well as of their organisations and\nenvironments. In recent years, researchers have started to explore the\nintegration of MAOP and the resource-oriented web architecture (REST). This\npaper further advances this line of research by presenting an ongoing work on\njacamo-rest, a resource-oriented web-based abstraction for the multi-agent\nprogramming platform JaCaMo. Jacamo-rest takes Multi-Agent System (MAS)\ninteroperability to a new level, enabling MAS to not only interact with\nservices or applications of the World Wide Web but also to be managed and\nupdated in their specifications by other applications. To add a developer\ninterface to JaCaMo that is suitable for the Web, we provide a novel conceptual\nperspective on the management of MAOP specification entities as web resources.\nWe tested jacamo-rest using it as a middleware of a programming interface\napplication that provides modern software engineering facilities such as\ncontinuous deployments and iterative software development for MAS.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.05619v1"
    },
    {
        "title": "Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning",
        "authors": [
            "Filippos Christianos",
            "Lukas Schäfer",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Exploration in multi-agent reinforcement learning is a challenging problem,\nespecially in environments with sparse rewards. We propose a general method for\nefficient exploration by sharing experience amongst agents. Our proposed\nalgorithm, called Shared Experience Actor-Critic (SEAC), applies experience\nsharing in an actor-critic framework. We evaluate SEAC in a collection of\nsparse-reward multi-agent environments and find that it consistently\noutperforms two baselines and two state-of-the-art algorithms by learning in\nfewer steps and converging to higher returns. In some harder environments,\nexperience sharing makes the difference between learning to solve the task and\nnot learning at all.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.07169v4"
    },
    {
        "title": "Towards Auditability Requirements Specification Using an Agent-Based\n  Approach",
        "authors": [
            "Denis J. S. de Albuquerque",
            "Vanessa Tavares Nunes",
            "Claudia Cappelli",
            "Celia Ghedini Ralha"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Transparency is an important factor in democratic societies composed of\ncharacteristics such as accessibility, usability, informativeness,\nunderstandability and auditability. In this research we focus on auditability\nsince it plays an important role for citizens that need to understand and audit\npublic information. Although auditability has been a subject of discussion when\ndesigning systems, there is a lack of systematization in its specification. We\npropose an approach to systematically add auditability requirements\nspecification during the goal-oriented agent-based Tropos methodology. We used\nthe Transparency Softgoal Interdependency Graph that captures the different\nfacets of transparency while considering their operationalization. An empirical\nevaluation was conducted through the design and implementation of LawDisTrA\nsystem that distributes lawsuits among judges in an appellate court.\nExperiments included the distribution of over 300,000 lawsuits at the Brazilian\nSuperior Labor Court. We theorize that the presented approach for auditability\nprovides adequate techniques to address the cross-organizational nature of\ntransparency.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.10232v1"
    },
    {
        "title": "Calibration of Shared Equilibria in General Sum Partially Observable\n  Markov Games",
        "authors": [
            "Nelson Vadori",
            "Sumitra Ganesh",
            "Prashant Reddy",
            "Manuela Veloso"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Training multi-agent systems (MAS) to achieve realistic equilibria gives us a\nuseful tool to understand and model real-world systems. We consider a general\nsum partially observable Markov game where agents of different types share a\nsingle policy network, conditioned on agent-specific information. This paper\naims at i) formally understanding equilibria reached by such agents, and ii)\nmatching emergent phenomena of such equilibria to real-world targets. Parameter\nsharing with decentralized execution has been introduced as an efficient way to\ntrain multiple agents using a single policy network. However, the nature of\nresulting equilibria reached by such agents has not been yet studied: we\nintroduce the novel concept of Shared equilibrium as a symmetric pure Nash\nequilibrium of a certain Functional Form Game (FFG) and prove convergence to\nthe latter for a certain class of games using self-play. In addition, it is\nimportant that such equilibria satisfy certain constraints so that MAS are\ncalibrated to real world data for practical use: we solve this problem by\nintroducing a novel dual-Reinforcement Learning based approach that fits\nemergent behaviors of agents in a Shared equilibrium to externally-specified\ntargets, and apply our methods to a n-player market example. We do so by\ncalibrating parameters governing distributions of agent types rather than\nindividual agents, which allows both behavior differentiation among agents and\ncoherent scaling of the shared policy network to multiple agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.13085v5"
    },
    {
        "title": "Multi Agent Team Learning in Disaggregated Virtualized Open Radio Access\n  Networks (O-RAN)",
        "authors": [
            "Pedro Enrique Iturria Rivera",
            "Shahram Mollahasani",
            "Melike Erol-Kantarci"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Starting from the Cloud Radio Access Network (C-RAN), continuing with the\nvirtual Radio Access Network (vRAN) and most recently with Open RAN (O-RAN)\ninitiative, Radio Access Network (RAN) architectures have significantly evolved\nin the past decade. In the last few years, the wireless industry has witnessed\na strong trend towards disaggregated, virtualized and open RANs, with numerous\ntests and deployments world wide. One unique aspect that motivates this paper\nis the availability of new opportunities that arise from using machine learning\nto optimize the RAN in closed-loop, i.e. without human intervention, where the\ncomplexity of disaggregation and virtualization makes well-known Self-Organized\nNetworking (SON) solutions inadequate. In our view, Multi-Agent Systems (MASs)\nwith team learning, can play an essential role in the control and coordination\nof controllers of O-RAN, i.e. near-real-time and non-real-time RAN Intelligent\nController (RIC). In this article, we first present the state-of-the-art\nresearch in multi-agent systems and team learning, then we provide an overview\nof the landscape in RAN disaggregation and virtualization, as well as O-RAN\nwhich emphasizes the open interfaces introduced by the O-RAN Alliance. We\npresent a case study for agent placement and the AI feedback required in O-RAN,\nand finally, we identify challenges and open issues to provide a roadmap for\nresearchers.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.04861v2"
    },
    {
        "title": "A generic and density-sensitive method for multi-scale pedestrian\n  dynamics",
        "authors": [
            "Daniel H. Biedermann",
            "Jan Clever",
            "Andre Borrmann"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Microscopic approaches to the simulation of pedestrian dynamics rely on\nmodelling the behaviour of individual agents and their mutual interactions.\nRegarding the spatial resolution, microscopic simulators are either based on\ncontinuous (SpaceCont) or discrete (SpaceDisc) approaches. To combine the\nadvantages of both approaches, we propose to integrate SpaceCont and SpaceDisc\ninto a hybrid simulation model. Such a hybrid approach allows simulating\ncritical regions with a continuous spatial resolution and uncritical ones with\ndiscrete spatial resolution while enabling consistent information exchange\nbetween the two simulation models. We introduce a generic approach that\nprovides consistent solutions for the challenges resulting from coupling\ndiverging time steps and spatial resolutions. Furthermore, we present a dynamic\nand density-sensitive approach to detect dense areas during the simulation run.\nIf a critical region is detected, the simulation model used in this area is\ndynamically switched to a space-continuous one. The correctness of the hybrid\nmodel is evaluated by comparison with a established simulator. Its superior\ncomputational efficiency is shown by runtime comparison with a standard\nmicroscopic simulation.on with the simulation results of other,\nwell-established simulation models.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.07623v1"
    },
    {
        "title": "An Improved Simulation Model for Pedestrian Crowd Evacuation",
        "authors": [
            "Danial A. Muhammed",
            "Tarik A. Rashid",
            "Abeer Alsadoon",
            "Nebojsa Bacanin",
            "Polla Fattah",
            "Mokhtar Mohammadi",
            "Indradip Banerjee"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper works on one of the most recent pedestrian crowd evacuation\nmodels, i.e., \"a simulation model for pedestrian crowd evacuation based on\nvarious AI techniques\", developed in late 2019. This study adds a new feature\nto the developed model by proposing a new method and integrating it with the\nmodel. This method enables the developed model to find a more appropriate\nevacuation area design, among others regarding safety due to selecting the best\nexit door location among many suggested locations. This method is completely\ndependent on the selected model's output, i.e., the evacuation time for each\nindividual within the evacuation process. The new method finds an average of\nthe evacuees' evacuation times of each exit door location; then, based on the\naverage evacuation time, it decides which exit door location would be the best\nexit door to be used for evacuation by the evacuees. To validate the method,\nvarious designs for the evacuation area with various written scenarios were\nused. The results showed that the model with this new method could predict a\nproper exit door location among many suggested locations. Lastly, from the\nresults of this research using the integration of this newly proposed method, a\nnew capability for the selected model in terms of safety allowed the right\ndecision in selecting the finest design for the evacuation area among other\ndesigns.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.09135v1"
    },
    {
        "title": "Resolving Implicit Coordination in Multi-Agent Deep Reinforcement\n  Learning with Deep Q-Networks & Game Theory",
        "authors": [
            "Griffin Adams",
            "Sarguna Janani Padmanabhan",
            "Shivang Shekhar"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We address two major challenges of implicit coordination in multi-agent deep\nreinforcement learning: non-stationarity and exponential growth of state-action\nspace, by combining Deep-Q Networks for policy learning with Nash equilibrium\nfor action selection. Q-values proxy as payoffs in Nash settings, and mutual\nbest responses define joint action selection. Coordination is implicit because\nmultiple/no Nash equilibria are resolved deterministically. We demonstrate that\nknowledge of game type leads to an assumption of mirrored best responses and\nfaster convergence than Nash-Q. Specifically, the Friend-or-Foe algorithm\ndemonstrates signs of convergence to a Set Controller which jointly chooses\nactions for two agents. This encouraging given the highly unstable nature of\ndecentralized coordination over joint actions. Inspired by the dueling network\narchitecture, which decouples the Q-function into state and advantage streams,\nas well as residual networks, we learn both a single and joint agent\nrepresentation, and merge them via element-wise addition. This simplifies\ncoordination by recasting it is as learning a residual function. We also draw\nhigh level comparative insights on key MADRL and game theoretic variables:\ncompetitive vs. cooperative, asynchronous vs. parallel learning, greedy versus\nsocially optimal Nash equilibria tie breaking, and strategies for the no Nash\nequilibrium case. We evaluate on 3 custom environments written in Python using\nOpenAI Gym: a Predator Prey environment, an alternating Warehouse environment,\nand a Synchronization environment. Each environment requires successively more\ncoordination to achieve positive rewards.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.09136v1"
    },
    {
        "title": "Difference Rewards Policy Gradients",
        "authors": [
            "Jacopo Castellini",
            "Sam Devlin",
            "Frans A. Oliehoek",
            "Rahul Savani"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Policy gradient methods have become one of the most popular classes of\nalgorithms for multi-agent reinforcement learning. A key challenge, however,\nthat is not addressed by many of these methods is multi-agent credit\nassignment: assessing an agent's contribution to the overall performance, which\nis crucial for learning good policies. We propose a novel algorithm called\nDr.Reinforce that explicitly tackles this by combining difference rewards with\npolicy gradients to allow for learning decentralized policies when the reward\nfunction is known. By differencing the reward function directly, Dr.Reinforce\navoids difficulties associated with learning the Q-function as done by\nCounterfactual Multiagent Policy Gradients (COMA), a state-of-the-art\ndifference rewards method. For applications where the reward function is\nunknown, we show the effectiveness of a version of Dr.Reinforce that learns an\nadditional reward network that is used to estimate the difference rewards.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.11258v2"
    },
    {
        "title": "Modelling Human Routines: Conceptualising Social Practice Theory for\n  Agent-Based Simulation",
        "authors": [
            "Rijk Mercuur",
            "Virginia Dignum",
            "Catholijn M. Jonker"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Our routines play an important role in a wide range of social challenges such\nas climate change, disease outbreaks and coordinating staff and patients in a\nhospital. To use agent-based simulations (ABS) to understand the role of\nroutines in social challenges we need an agent framework that integrates\nroutines. This paper provides the domain-independent Social Practice Agent\n(SoPrA) framework that satisfies requirements from the literature to simulate\nour routines. By choosing the appropriate concepts from the literature on agent\ntheory, social psychology and social practice theory we ensure SoPrA correctly\ndepicts current evidence on routines. By creating a consistent, modular and\nparsimonious framework suitable for multiple domains we enhance the usability\nof SoPrA. SoPrA provides ABS researchers with a conceptual, formal and\ncomputational framework to simulate routines and gain new insights into social\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.11903v1"
    },
    {
        "title": "Distributed Q-Learning with State Tracking for Multi-agent Networked\n  Control",
        "authors": [
            "Hang Wang",
            "Sen Lin",
            "Hamid Jafarkhani",
            "Junshan Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper studies distributed Q-learning for Linear Quadratic Regulator\n(LQR) in a multi-agent network. The existing results often assume that agents\ncan observe the global system state, which may be infeasible in large-scale\nsystems due to privacy concerns or communication constraints. In this work, we\nconsider a setting with unknown system models and no centralized coordinator.\nWe devise a state tracking (ST) based Q-learning algorithm to design optimal\ncontrollers for agents. Specifically, we assume that agents maintain local\nestimates of the global state based on their local information and\ncommunications with neighbors. At each step, every agent updates its local\nglobal state estimation, based on which it solves an approximate Q-factor\nlocally through policy iteration. Assuming decaying injected excitation noise\nduring the policy evaluation, we prove that the local estimation converges to\nthe true global state, and establish the convergence of the proposed\ndistributed ST-based Q-learning algorithm. The experimental studies corroborate\nour theoretical results by showing that our proposed method achieves comparable\nperformance with the centralized case.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.12383v1"
    },
    {
        "title": "Distributed Multi-object Tracking under Limited Field of View Sensors",
        "authors": [
            "Hoa Van Nguyen",
            "Hamid Rezatofighi",
            "Ba-Ngu Vo",
            "Damith C. Ranasinghe"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We consider the challenging problem of tracking multiple objects using a\ndistributed network of sensors. In the practical setting of nodes with limited\nfield of views (FoVs), computing power and communication resources, we develop\na novel distributed multi-object tracking algorithm. To accomplish this, we\nfirst formalise the concept of label consistency, determine a sufficient\ncondition to achieve it and develop a novel \\textit{label consensus approach}\nthat reduces label inconsistency caused by objects' movements from one node's\nlimited FoV to another. Second, we develop a distributed multi-object fusion\nalgorithm that fuses local multi-object state estimates instead of local\nmulti-object densities. This algorithm: i) requires significantly less\nprocessing time than multi-object density fusion methods; ii) achieves better\ntracking accuracy by considering Optimal Sub-Pattern Assignment (OSPA) tracking\nerrors over several scans rather than a single scan; iii) is agnostic to local\nmulti-object tracking techniques, and only requires each node to provide a set\nof estimated tracks. Thus, it is not necessary to assume that the nodes\nmaintain multi-object densities, and hence the fusion outcomes do not modify\nlocal multi-object densities. Numerical experiments demonstrate our proposed\nsolution's real-time computational efficiency and accuracy compared to\nstate-of-the-art solutions in challenging scenarios. We also release source\ncode at https://github.com/AdelaideAuto-IDLab/Distributed-limitedFoV-MOT for\nour fusion method to foster developments in DMOT algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.12990v2"
    },
    {
        "title": "Prosocial Norm Emergence in Multiagent Systems",
        "authors": [
            "Mehdi Mashayekhi",
            "Nirav Ajmeri",
            "George F. List",
            "Munindar P. Singh"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Multiagent systems provide a basis for developing systems of autonomous\nentities and thus find application in a variety of domains. We consider a\nsetting where not only the member agents are adaptive but also the multiagent\nsystem viewed as an entity in its own right is adaptive. Specifically, the\nsocial structure of a multiagent system can be reflected in the social norms\namong its members. It is well recognized that the norms that arise in society\nare not always beneficial to its members. We focus on prosocial norms, which\nhelp achieve positive outcomes for society and often provide guidance to agents\nto act in a manner that takes into account the welfare of others.\n  Specifically, we propose Cha, a framework for the emergence of prosocial\nnorms. Unlike previous norm emergence approaches, Cha supports continual change\nto a system (agents may enter and leave) and dynamism (norms may change when\nthe environment changes). Importantly, Cha agents incorporate prosocial\ndecision making based on inequity aversion theory, reflecting an intuition of\nguilt arising from being antisocial. In this manner, Cha brings together two\nimportant themes in prosociality: decision making by individuals and fairness\nof system-level outcomes. We demonstrate via simulation that Cha can improve\naggregate societal gains and fairness of outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.14581v2"
    },
    {
        "title": "Multi-UAV Mobile Edge Computing and Path Planning Platform based on\n  Reinforcement Learning",
        "authors": [
            "Huan Chang",
            "Yicheng Chen",
            "Baochang Zhang",
            "David Doermann"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Unmanned Aerial vehicles (UAVs) are widely used as network processors in\nmobile networks, but more recently, UAVs have been used in Mobile Edge\nComputing as mobile servers. However, there are significant challenges to use\nUAVs in complex environments with obstacles and cooperation between UAVs. We\nintroduce a new multi-UAV Mobile Edge Computing platform, which aims to provide\nbetter Quality-of-Service and path planning based on reinforcement learning to\naddress these issues. The contributions of our work include: 1) optimizing the\nquality of service for mobile edge computing and path planning in the same\nreinforcement learning framework; 2) using a sigmoid-like function to depict\nthe terminal users' demand to ensure a higher quality of service; 3) applying\nsynthetic considerations of the terminal users' demand, risk and geometric\ndistance in reinforcement learning reward matrix to ensure the quality of\nservice, risk avoidance, and the cost-savings. Simulations have shown the\neffectiveness and feasibility of our platform, which can help advance related\nresearches.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.02078v3"
    },
    {
        "title": "Improved Cooperation by Exploiting a Common Signal",
        "authors": [
            "Panayiotis Danassis",
            "Zeki Doruk Erden",
            "Boi Faltings"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Can artificial agents benefit from human conventions? Human societies manage\nto successfully self-organize and resolve the tragedy of the commons in\ncommon-pool resources, in spite of the bleak prediction of non-cooperative game\ntheory. On top of that, real-world problems are inherently large-scale and of\nlow observability. One key concept that facilitates human coordination in such\nsettings is the use of conventions. Inspired by human behavior, we investigate\nthe learning dynamics and emergence of temporal conventions, focusing on\ncommon-pool resources. Extra emphasis was given in designing a realistic\nevaluation setting: (a) environment dynamics are modeled on real-world\nfisheries, (b) we assume decentralized learning, where agents can observe only\ntheir own history, and (c) we run large-scale simulations (up to 64 agents).\n  Uncoupled policies and low observability make cooperation hard to achieve; as\nthe number of agents grow, the probability of taking a correct gradient\ndirection decreases exponentially. By introducing an arbitrary common signal\n(e.g., date, time, or any periodic set of numbers) as a means to couple the\nlearning process, we show that temporal conventions can emerge and agents reach\nsustainable harvesting strategies. The introduction of the signal consistently\nimproves the social welfare (by 258% on average, up to 3306%), the range of\nenvironmental parameters where sustainability can be achieved (by 46% on\naverage, up to 300%), and the convergence speed in low abundance settings (by\n13% on average, up to 53%).\n",
        "pdf_link": "http://arxiv.org/pdf/2102.02304v1"
    },
    {
        "title": "Modelling Cooperation in Network Games with Spatio-Temporal Complexity",
        "authors": [
            "Michiel A. Bakker",
            "Richard Everett",
            "Laura Weidinger",
            "Iason Gabriel",
            "William S. Isaac",
            "Joel Z. Leibo",
            "Edward Hughes"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The real world is awash with multi-agent problems that require collective\naction by self-interested agents, from the routing of packets across a computer\nnetwork to the management of irrigation systems. Such systems have local\nincentives for individuals, whose behavior has an impact on the global outcome\nfor the group. Given appropriate mechanisms describing agent interaction,\ngroups may achieve socially beneficial outcomes, even in the face of short-term\nselfish incentives. In many cases, collective action problems possess an\nunderlying graph structure, whose topology crucially determines the\nrelationship between local decisions and emergent global effects. Such\nscenarios have received great attention through the lens of network games.\nHowever, this abstraction typically collapses important dimensions, such as\ngeometry and time, relevant to the design of mechanisms promoting cooperation.\nIn parallel work, multi-agent deep reinforcement learning has shown great\npromise in modelling the emergence of self-organized cooperation in complex\ngridworld domains. Here we apply this paradigm in graph-structured collective\naction problems. Using multi-agent deep reinforcement learning, we simulate an\nagent society for a variety of plausible mechanisms, finding clear transitions\nbetween different equilibria over time. We define analytic tools inspired by\nrelated literatures to measure the social outcomes, and use these to draw\nconclusions about the efficacy of different environmental interventions. Our\nmethods have implications for mechanism design in both human and artificial\nagent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.06911v1"
    },
    {
        "title": "An Efficient QOS Based Multimedia Content Distribution Mechanism in P2P\n  Network",
        "authors": [
            "M Anandaraj",
            "P Ganeshkumar",
            "K. P. Vijayakumar"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Peer-to-peer network is one in which each node in the network can act as a\nclient or server for the other nodes in the network. It allows shared access to\nvarious resources such as files, peripherals, and sensors without the need for\na central server. Content distribution in the P2P network from server is done\nby multicasting. Multicasting is the process of sending the data to the\nmultiple designations. This technology is highly efficient for the large scale\nmultimedia content delivery in P2P network where the end peer have identical\nset of system components. But in reality, the peers have heterogeneous set of\nrequirements for different service levels as well as different service\ncomponents. The ability to provide differentiated services to each peer with\nwidely varying requirements is becoming important. We need to provide\ndifferentiated Services above the existing shared network infrastructure. The\nsolution proposed to solve the above said problem is to provide individualized\nservice to each peer. It focuses on constructing and maintaining an efficient\nmultiple overlay multicast tree structure in the P2P network. The tree\nmaintenance process is governed by two mechanisms called as dynamic\nreconfiguration driven by peer and less frequent tree maintenance by network\nstatus change observation. In this paper new scalable architecture is\nconstructed and analysed based on the above strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.06954v2"
    },
    {
        "title": "Partial Disclosure of Private Dependencies in Privacy Preserving\n  Planning",
        "authors": [
            "Rotem Lev Lehman",
            "Guy Shani",
            "Roni Stern"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In collaborative privacy preserving planning (CPPP), a group of agents\njointly creates a plan to achieve a set of goals while preserving each others'\nprivacy. During planning, agents often reveal the private dependencies between\ntheir public actions to other agents, that is, which public action facilitates\nthe preconditions of another public action. Previous work in CPPP does not\nlimit the disclosure of such dependencies. In this paper, we explicitly limit\nthe amount of disclosed dependencies, allowing agents to publish only a part of\ntheir private dependencies. We investigate different strategies for deciding\nwhich dependencies to publish, and how they affect the ability to find\nsolutions. We evaluate the ability of two solvers -- distribute forward search\nand centralized planning based on a single-agent projection -- to produce plans\nunder this constraint. Experiments over standard CPPP domains show that the\nproposed dependency-sharing strategies enable generating plans while sharing\nonly a small fraction of all private dependencies.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07185v1"
    },
    {
        "title": "Scaling Multi-Agent Reinforcement Learning with Selective Parameter\n  Sharing",
        "authors": [
            "Filippos Christianos",
            "Georgios Papoudakis",
            "Arrasy Rahman",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Sharing parameters in multi-agent deep reinforcement learning has played an\nessential role in allowing algorithms to scale to a large number of agents.\nParameter sharing between agents significantly decreases the number of\ntrainable parameters, shortening training times to tractable levels, and has\nbeen linked to more efficient learning. However, having all agents share the\nsame parameters can also have a detrimental effect on learning. We demonstrate\nthe impact of parameter sharing methods on training speed and converged\nreturns, establishing that when applied indiscriminately, their effectiveness\nis highly dependent on the environment. We propose a novel method to\nautomatically identify agents which may benefit from sharing parameters by\npartitioning them based on their abilities and goals. Our approach combines the\nincreased sample efficiency of parameter sharing with the representational\ncapacity of multiple independent networks to reduce training time and increase\nfinal returns.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07475v2"
    },
    {
        "title": "Cooperation and Reputation Dynamics with Reinforcement Learning",
        "authors": [
            "Nicolas Anastassacos",
            "Julian García",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Creating incentives for cooperation is a challenge in natural and artificial\nsystems. One potential answer is reputation, whereby agents trade the immediate\ncost of cooperation for the future benefits of having a good reputation. Game\ntheoretical models have shown that specific social norms can make cooperation\nstable, but how agents can independently learn to establish effective\nreputation mechanisms on their own is less understood. We use a simple model of\nreinforcement learning to show that reputation mechanisms generate two\ncoordination problems: agents need to learn how to coordinate on the meaning of\nexisting reputations and collectively agree on a social norm to assign\nreputations to others based on their behavior. These coordination problems\nexhibit multiple equilibria, some of which effectively establish cooperation.\nWhen we train agents with a standard Q-learning algorithm in an environment\nwith the presence of reputation mechanisms, convergence to undesirable\nequilibria is widespread. We propose two mechanisms to alleviate this: (i)\nseeding a proportion of the system with fixed agents that steer others towards\ngood equilibria; and (ii), intrinsic rewards based on the idea of\nintrospection, i.e., augmenting agents' rewards by an amount proportionate to\nthe performance of their own strategy against themselves. A combination of\nthese simple mechanisms is successful in stabilizing cooperation, even in a\nfully decentralized version of the problem where agents learn to use and assign\nreputations simultaneously. We show how our results relate to the literature in\nEvolutionary Game Theory, and discuss implications for artificial, human and\nhybrid systems, where reputations can be used as a way to establish trust and\ncooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07523v1"
    },
    {
        "title": "DFAC Framework: Factorizing the Value Function via Quantile Mixture for\n  Multi-Agent Distributional Q-Learning",
        "authors": [
            "Wei-Fang Sun",
            "Cheng-Kuang Lee",
            "Chun-Yi Lee"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In fully cooperative multi-agent reinforcement learning (MARL) settings, the\nenvironments are highly stochastic due to the partial observability of each\nagent and the continuously changing policies of the other agents. To address\nthe above issues, we integrate distributional RL and value function\nfactorization methods by proposing a Distributional Value Function\nFactorization (DFAC) framework to generalize expected value function\nfactorization methods to their DFAC variants. DFAC extends the individual\nutility functions from deterministic variables to random variables, and models\nthe quantile function of the total return as a quantile mixture. To validate\nDFAC, we demonstrate DFAC's ability to factorize a simple two-step matrix game\nwith stochastic rewards and perform experiments on all Super Hard tasks of\nStarCraft Multi-Agent Challenge, showing that DFAC is able to outperform\nexpected value function factorization baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07936v2"
    },
    {
        "title": "Quantifying the effects of environment and population diversity in\n  multi-agent reinforcement learning",
        "authors": [
            "Kevin R. McKee",
            "Joel Z. Leibo",
            "Charlie Beattie",
            "Richard Everett"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Generalization is a major challenge for multi-agent reinforcement learning.\nHow well does an agent perform when placed in novel environments and in\ninteractions with new co-players? In this paper, we investigate and quantify\nthe relationship between generalization and diversity in the multi-agent\ndomain. Across the range of multi-agent environments considered here,\nprocedurally generating training levels significantly improves agent\nperformance on held-out levels. However, agent performance on the specific\nlevels used in training sometimes declines as a result. To better understand\nthe effects of co-player variation, our experiments introduce a new\nenvironment-agnostic measure of behavioral diversity. Results demonstrate that\npopulation size and intrinsic motivation are both effective methods of\ngenerating greater population diversity. In turn, training with a diverse set\nof co-players strengthens agent performance in some (but not all) cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.08370v2"
    },
    {
        "title": "Models we Can Trust: Toward a Systematic Discipline of (Agent-Based)\n  Model Interpretation and Validation",
        "authors": [
            "Gabriel Istrate"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We advocate the development of a discipline of interacting with and\nextracting information from models, both mathematical (e.g. game-theoretic\nones) and computational (e.g. agent-based models). We outline some directions\nfor the development of a such a discipline:\n  - the development of logical frameworks for the systematic formal\nspecification of stylized facts and social mechanisms in (mathematical and\ncomputational) social science. Such frameworks would bring to attention new\nissues, such as phase transitions, i.e. dramatical changes in the validity of\nthe stylized facts beyond some critical values in parameter space. We argue\nthat such statements are useful for those logical frameworks describing\nproperties of ABM.\n  - the adaptation of tools from the theory of reactive systems (such as\nbisimulation) to obtain practically relevant notions of two systems \"having the\nsame behavior\".\n  - the systematic development of an adversarial theory of model perturbations,\nthat investigates the robustness of conclusions derived from models of social\nbehavior to variations in several features of the social dynamics. These may\ninclude: activation order, the underlying social network, individual agent\nbehavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.11615v1"
    },
    {
        "title": "MAPFAST: A Deep Algorithm Selector for Multi Agent Path Finding using\n  Shortest Path Embeddings",
        "authors": [
            "Jingyao Ren",
            "Vikraman Sathiyanarayanan",
            "Eric Ewing",
            "Baskin Senbaslar",
            "Nora Ayanian"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Solving the Multi-Agent Path Finding (MAPF) problem optimally is known to be\nNP-Hard for both make-span and total arrival time minimization. While many\nalgorithms have been developed to solve MAPF problems, there is no dominating\noptimal MAPF algorithm that works well in all types of problems and no standard\nguidelines for when to use which algorithm. In this work, we develop the deep\nconvolutional network MAPFAST (Multi-Agent Path Finding Algorithm SelecTor),\nwhich takes a MAPF problem instance and attempts to select the fastest\nalgorithm to use from a portfolio of algorithms. We improve the performance of\nour model by including single-agent shortest paths in the instance embedding\ngiven to our model and by utilizing supplemental loss functions in addition to\na classification loss. We evaluate our model on a large and diverse dataset of\nMAPF instances, showing that it outperforms all individual algorithms in its\nportfolio as well as the state-of-the-art optimal MAPF algorithm selector. We\nalso provide an analysis of algorithm behavior in our dataset to gain a deeper\nunderstanding of optimal MAPF algorithms' strengths and weaknesses to help\nother researchers leverage different heuristics in algorithm designs.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.12461v2"
    },
    {
        "title": "Inference-Based Deterministic Messaging For Multi-Agent Communication",
        "authors": [
            "Varun Bhatt",
            "Michael Buro"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Communication is essential for coordination among humans and animals.\nTherefore, with the introduction of intelligent agents into the world,\nagent-to-agent and agent-to-human communication becomes necessary. In this\npaper, we first study learning in matrix-based signaling games to empirically\nshow that decentralized methods can converge to a suboptimal policy. We then\npropose a modification to the messaging policy, in which the sender\ndeterministically chooses the best message that helps the receiver to infer the\nsender's observation. Using this modification, we see, empirically, that the\nagents converge to the optimal policy in nearly all the runs. We then apply\nthis method to a partially observable gridworld environment which requires\ncooperation between two agents and show that, with appropriate approximation\nmethods, the proposed sender modification can enhance existing decentralized\ntraining methods for more complex domains as well.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.02150v1"
    },
    {
        "title": "Quasi-Equivalence Discovery for Zero-Shot Emergent Communication",
        "authors": [
            "Kalesha Bullard",
            "Douwe Kiela",
            "Franziska Meier",
            "Joelle Pineau",
            "Jakob Foerster"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Effective communication is an important skill for enabling information\nexchange in multi-agent settings and emergent communication is now a vibrant\nfield of research, with common settings involving discrete cheap-talk channels.\nSince, by definition, these settings involve arbitrary encoding of information,\ntypically they do not allow for the learned protocols to generalize beyond\ntraining partners. In contrast, in this work, we present a novel problem\nsetting and the Quasi-Equivalence Discovery (QED) algorithm that allows for\nzero-shot coordination (ZSC), i.e., discovering protocols that can generalize\nto independently trained agents. Real world problem settings often contain\ncostly communication channels, e.g., robots have to physically move their\nlimbs, and a non-uniform distribution over intents. We show that these two\nfactors lead to unique optimal ZSC policies in referential games, where agents\nuse the energy cost of the messages to communicate intent. Other-Play was\nrecently introduced for learning optimal ZSC policies, but requires prior\naccess to the symmetries of the problem. Instead, QED can iteratively discovers\nthe symmetries in this setting and converges to the optimal ZSC policy.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.08067v2"
    },
    {
        "title": "Multi-Agent Algorithms for Collective Behavior: A structural and\n  application-focused atlas",
        "authors": [
            "Federico Rossi",
            "Saptarshi Bandyopadhyay",
            "Michael T. Wolf",
            "Marco Pavone"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The goal of this paper is to provide a survey and application-focused atlas\nof collective behavior coordination algorithms for multi-agent systems.\n  We survey the general family of collective behavior algorithms for\nmulti-agent systems and classify them according to their underlying\nmathematical structure. In doing so, we aim to capture fundamental mathematical\nproperties of algorithms (e.g., scalability with respect to the number of\nagents and bandwidth use) and to show how the same algorithm or family of\nalgorithms can be used for multiple tasks and applications.\n  Collectively, this paper provides an application-focused atlas of algorithms\nfor collective behavior of multi-agent systems, with three objectives:\n  1. to act as a tutorial guide to practitioners in the selection of\ncoordination algorithms for a given application;\n  2. to highlight how mathematically similar algorithms can be used for a\nvariety of tasks, ranging from low-level control to high-level coordination;\n  3. to explore the state-of-the-art in the field of control of multi-agent\nsystems and identify areas for future research.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.11067v1"
    },
    {
        "title": "Safe Multi-Agent Reinforcement Learning through Decentralized Multiple\n  Control Barrier Functions",
        "authors": [
            "Zhiyuan Cai",
            "Huanhui Cao",
            "Wenjie Lu",
            "Lin Zhang",
            "Hao Xiong"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) algorithms show amazing performance\nin simulation in recent years, but placing MARL in real-world applications may\nsuffer safety problems. MARL with centralized shields was proposed and verified\nin safety games recently. However, centralized shielding approaches can be\ninfeasible in several real-world multi-agent applications that involve\nnon-cooperative agents or communication delay. Thus, we propose to combine MARL\nwith decentralized Control Barrier Function (CBF) shields based on available\nlocal information. We establish a safe MARL framework with decentralized\nmultiple CBFs and develop Multi-Agent Deep Deterministic Policy Gradient\n(MADDPG) to Multi-Agent Deep Deterministic Policy Gradient with decentralized\nmultiple Control Barrier Functions (MADDPG-CBF). Based on a collision-avoidance\nproblem that includes not only cooperative agents but obstacles, we demonstrate\nthe construction of multiple CBFs with safety guarantees in theory. Experiments\nare conducted and experiment results verify that the proposed safe MARL\nframework can guarantee the safety of agents included in MARL.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.12553v1"
    },
    {
        "title": "Hastily Formed Knowledge Networks and Distributed Situation Awareness\n  for Collaborative Robotics",
        "authors": [
            "Cyrille Berger",
            "Patrick Doherty",
            "Piotr Rudol",
            "Mariusz Wzorek"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In the context of collaborative robotics, distributed situation awareness is\nessential for supporting collective intelligence in teams of robots and human\nagents where it can be used for both individual and collective decision\nsupport. This is particularly important in applications pertaining to emergency\nrescue and crisis management. During operational missions, data and knowledge\nis gathered incrementally and in different ways by heterogeneous robots and\nhumans. We describe this as the creation of \\emph{Hastily Formed Knowledge\nNetworks} (HFKNs). The focus of this paper is the specification and prototyping\nof a general distributed system architecture that supports the creation of\nHFKNs by teams of robots and humans. The information collected ranges from\nlow-level sensor data to high-level semantic knowledge, the latter represented\nin part as RDF Graphs. The framework includes a synchronization protocol and\nassociated algorithms that allow for the automatic distribution and sharing of\ndata and knowledge between agents. This is done through the distributed\nsynchronization of RDF Graphs shared between agents. High-level semantic\nqueries specified in SPARQL can be used by robots and humans alike to acquire\nboth knowledge and data content from team members. The system is empirically\nvalidated and complexity results of the proposed algorithms are provided.\nAdditionally, a field robotics case study is described, where a 3D mapping\nmission has been executed using several UAVs in a collaborative emergency\nrescue scenario while using the full HFKN Framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.14078v1"
    },
    {
        "title": "Learning to Participate through Trading of Reward Shares",
        "authors": [
            "Michael Kölle",
            "Tim Matheis",
            "Philipp Altmann",
            "Kyrill Schmid"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Enabling autonomous agents to act cooperatively is an important step to\nintegrate artificial intelligence in our daily lives. While some methods seek\nto stimulate cooperation by letting agents give rewards to others, in this\npaper we propose a method inspired by the stock market, where agents have the\nopportunity to participate in other agents' returns by acquiring reward shares.\nIntuitively, an agent may learn to act according to the common interest when\nbeing directly affected by the other agents' rewards. The empirical results of\nthe tested general-sum Markov games show that this mechanism promotes\ncooperative policies among independently trained agents in social dilemma\nsituations. Moreover, as demonstrated in a temporally and spatially extended\ndomain, participation can lead to the development of roles and the division of\nsubtasks between the agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.07416v1"
    },
    {
        "title": "Decentralized Multi-agent Filtering",
        "authors": [
            "Dom Huh",
            "Prasant Mohapatra"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper addresses the considerations that comes along with adopting\ndecentralized communication for multi-agent localization applications in\ndiscrete state spaces. In this framework, we extend the original formulation of\nthe Bayes filter, a foundational probabilistic tool for discrete state\nestimation, by appending a step of greedy belief sharing as a method to\npropagate information and improve local estimates' posteriors. We apply our\nwork in a model-based multi-agent grid-world setting, where each agent\nmaintains a belief distribution for every agents' state. Our results affirm the\nutility of our proposed extensions for decentralized collaborative tasks. The\ncode base for this work is available in the following repo\n",
        "pdf_link": "http://arxiv.org/pdf/2301.08864v1"
    },
    {
        "title": "Graph Neural Networks for Decentralized Multi-Agent Perimeter Defense",
        "authors": [
            "Elijah S. Lee",
            "Lifeng Zhou",
            "Alejandro Ribeiro",
            "Vijay Kumar"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this work, we study the problem of decentralized multi-agent perimeter\ndefense that asks for computing actions for defenders with local perceptions\nand communications to maximize the capture of intruders. One major challenge\nfor practical implementations is to make perimeter defense strategies scalable\nfor large-scale problem instances. To this end, we leverage graph neural\nnetworks (GNNs) to develop an imitation learning framework that learns a\nmapping from defenders' local perceptions and their communication graph to\ntheir actions. The proposed GNN-based learning network is trained by imitating\na centralized expert algorithm such that the learned actions are close to that\ngenerated by the expert algorithm. We demonstrate that our proposed network\nperforms closer to the expert algorithm and is superior to other baseline\nalgorithms by capturing more intruders. Our GNN-based network is trained at a\nsmall scale and can be generalized to large-scale cases. We run perimeter\ndefense games in scenarios with different team sizes and configurations to\ndemonstrate the performance of the learned network.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.09689v1"
    },
    {
        "title": "Design of a GIS-based Assistant Software Agent for the Incident\n  Commander to Coordinate Emergency Response Operations",
        "authors": [
            "Reza Nourjou",
            "Michinori Hatayama",
            "Stephen F. Smith",
            "Atabak Sadeghi",
            "Pedro Szekely"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Problem: This paper addresses the design of an intelligent software system\nfor the IC (incident commander) of a team in order to coordinate actions of\nagents (field units or robots) in the domain of emergency/crisis response\noperations. Objective: This paper proposes GICoordinator. It is a GIS-based\nassistant software agent that assists and collaborates with the human planner\nin strategic planning and macro tasks assignment for centralized multi-agent\ncoordination. Method: Our approach to design GICoordinator was to: analyze the\nproblem, design a complete data model, design an architecture of GICoordinator,\nspecify required capabilities of human and system in coordination problem\nsolving, specify development tools, and deploy. Result: The result was an\narchitecture/design of GICoordinator that contains system requirements.\nFindings: GICoordinator efficiently integrates geoinformatics with artifice\nintelligent techniques in order to provide a spatial intelligent coordinator\nsystem for an IC to efficiently coordinate and control agents by making\nmacro/strategic decisions. Results define a framework for future works to\ndevelop this system.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.0282v1"
    },
    {
        "title": "Quantitative Comparison Between Crowd Models for Evacuation Planning and\n  Evaluation",
        "authors": [
            "Vaisagh Viswanathan",
            "Chong Eu Lee",
            "Michael Harold Lees",
            "Siew Ann Cheong",
            "Peter M. A. Sloot"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Crowd simulation is rapidly becoming a standard tool for evacuation planning\nand evaluation. However, the many crowd models in the literature are\nstructurally different, and few have been rigorously calibrated against\nreal-world egress data, especially in emergency situations. In this paper we\ndescribe a procedure to quantitatively compare different crowd models or\nbetween models and real-world data. We simulated three models: (1) the lattice\ngas model, (2) the social force model, and (3) the RVO2 model, and obtained the\ndistributions of six observables: (1) evacuation time, (2) zoned evacuation\ntime, (3) passage density, (4) total distance traveled, (5) inconvenience, and\n(6) flow rate. We then used the DISTATIS procedure to compute the compromise\nmatrix of statistical distances between the three models. Projecting the three\nmodels onto the first two principal components of the compromise matrix, we\nfind the lattice gas and RVO2 models are similar in terms of the evacuation\ntime, passage density, and flow rates, whereas the social force and RVO2 models\nare similar in terms of the total distance traveled. Most importantly, we find\nthat the zoned evacuation times of the three models to be very different from\neach other. Thus we propose to use this variable, if it can be measured, as the\nkey test between different models, and also between models and the real world.\nFinally, we compared the model flow rates against the flow rate of an emergency\nevacuation during the May 2008 Sichuan earthquake, and found the social force\nmodel agrees best with this real data.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.0366v2"
    },
    {
        "title": "An Anytime Algorithm for Optimal Coalition Structure Generation",
        "authors": [
            "Talal Rahwan",
            "Sarvapali Dyanand Ramchurn",
            "Nicholas Robert Jennings",
            "Andrea Giovannucci"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Coalition formation is a fundamental type of interaction that involves the\ncreation of coherent groupings of distinct, autonomous, agents in order to\nefficiently achieve their individual or collective goals. Forming effective\ncoalitions is a major research challenge in the field of multi-agent systems.\nCentral to this endeavour is the problem of determining which of the many\npossible coalitions to form in order to achieve some goal. This usually\nrequires calculating a value for every possible coalition, known as the\ncoalition value, which indicates how beneficial that coalition would be if it\nwas formed. Once these values are calculated, the agents usually need to find a\ncombination of coalitions, in which every agent belongs to exactly one\ncoalition, and by which the overall outcome of the system is maximized.\nHowever, this coalition structure generation problem is extremely challenging\ndue to the number of possible solutions that need to be examined, which grows\nexponentially with the number of agents involved. To date, therefore, many\nalgorithms have been proposed to solve this problem using different techniques\nranging from dynamic programming, to integer programming, to stochastic search\nall of which suffer from major limitations relating to execution time, solution\nquality, and memory requirements.\n  With this in mind, we develop an anytime algorithm to solve the coalition\nstructure generation problem. Specifically, the algorithm uses a novel\nrepresentation of the search space, which partitions the space of possible\nsolutions into sub-spaces such that it is possible to compute upper and lower\nbounds on the values of the best coalition structures in them. These bounds are\nthen used to identify the sub-spaces that have no potential of containing the\noptimal solution so that they can be pruned. The algorithm, then, searches\nthrough the remaining sub-spaces very efficiently using a branch-and-bound\ntechnique to avoid examining all the solutions within the searched subspace(s).\nIn this setting, we prove that our algorithm enumerates all coalition\nstructures efficiently by avoiding redundant and invalid solutions\nautomatically. Moreover, in order to effectively test our algorithm we develop\na new type of input distribution which allows us to generate more reliable\nbenchmarks compared to the input distributions previously used in the field.\nGiven this new distribution, we show that for 27 agents our algorithm is able\nto find solutions that are optimal in 0.175% of the time required by the\nfastest available algorithm in the literature. The algorithm is anytime, and if\ninterrupted before it would have normally terminated, it can still provide a\nsolution that is guaranteed to be within a bound from the optimal one.\nMoreover, the guarantees we provide on the quality of the solution are\nsignificantly better than those provided by the previous state of the art\nalgorithms designed for this purpose. For example, for the worst case\ndistribution given 25 agents, our algorithm is able to find a 90% efficient\nsolution in around 10% of time it takes to find the optimal solution.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3466v1"
    },
    {
        "title": "Resource-Driven Mission-Phasing Techniques for Constrained Agents in\n  Stochastic Environments",
        "authors": [
            "Jianhui Wu",
            "Edmund H. Durfee"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Because an agents resources dictate what actions it can possibly take, it\nshould plan which resources it holds over time carefully, considering its\ninherent limitations (such as power or payload restrictions), the competing\nneeds of other agents for the same resources, and the stochastic nature of the\nenvironment. Such agents can, in general, achieve more of their objectives if\nthey can use --- and even create --- opportunities to change which resources\nthey hold at various times. Driven by resource constraints, the agents could\nbreak their overall missions into an optimal series of phases, optimally\nreconfiguring their resources at each phase, and optimally using their assigned\nresources in each phase, given their knowledge of the stochastic environment.\nIn this paper, we formally define and analyze this constrained, sequential\noptimization problem in both the single-agent and multi-agent contexts. We\npresent a family of mixed integer linear programming (MILP) formulations of\nthis problem that can optimally create phases (when phases are not predefined)\naccounting for costs and limitations in phase creation. Because our\nformulations multaneously also find the optimal allocations of resources at\neach phase and the optimal policies for using the allocated resources at each\nphase, they exploit structure across these coupled problems. This allows them\nto find solutions significantly faster(orders of magnitude faster in larger\nproblems) than alternative solution techniques, as we demonstrate empirically.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3845v1"
    },
    {
        "title": "Multi-Robot Adversarial Patrolling: Facing a Full-Knowledge Opponent",
        "authors": [
            "Noa Agmon",
            "Gal A. Kaminka",
            "Sarit Kraus"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The problem of adversarial multi-robot patrol has gained interest in recent\nyears, mainly due to its immediate relevance to various security applications.\nIn this problem, robots are required to repeatedly visit a target area in a way\nthat maximizes their chances of detecting an adversary trying to penetrate\nthrough the patrol path. When facing a strong adversary that knows the patrol\nstrategy of the robots, if the robots use a deterministic patrol algorithm,\nthen in many cases it is easy for the adversary to penetrate undetected (in\nfact, in some of those cases the adversary can guarantee penetration).\nTherefore this paper presents a non-deterministic patrol framework for the\nrobots. Assuming that the strong adversary will take advantage of its knowledge\nand try to penetrate through the patrols weakest spot, hence an optimal\nalgorithm is one that maximizes the chances of detection in that point. We\ntherefore present a polynomial-time algorithm for determining an optimal patrol\nunder the Markovian strategy assumption for the robots, such that the\nprobability of detecting the adversary in the patrols weakest spot is\nmaximized. We build upon this framework and describe an optimal patrol strategy\nfor several robotic models based on their movement abilities (directed or\nundirected) and sensing abilities (perfect or imperfect), and in different\nenvironment models - either patrol around a perimeter (closed polygon) or an\nopen fence (open polyline).\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3903v1"
    },
    {
        "title": "Location-Based Reasoning about Complex Multi-Agent Behavior",
        "authors": [
            "Adam Sadilek",
            "Henry Kautz"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Recent research has shown that surprisingly rich models of human activity can\nbe learned from GPS (positional) data. However, most effort to date has\nconcentrated on modeling single individuals or statistical properties of groups\nof people. Moreover, prior work focused solely on modeling actual successful\nexecutions (and not failed or attempted executions) of the activities of\ninterest. We, in contrast, take on the task of understanding human\ninteractions, attempted interactions, and intentions from noisy sensor data in\na fully relational multi-agent setting. We use a real-world game of capture the\nflag to illustrate our approach in a well-defined domain that involves many\ndistinct cooperative and competitive joint activities. We model the domain\nusing Markov logic, a statistical-relational language, and learn a theory that\njointly denoises the data and infers occurrences of high-level activities, such\nas a player capturing an enemy. Our unified model combines constraints imposed\nby the geometry of the game area, the motion model of the players, and by the\nrules and dynamics of the game in a probabilistically and logically sound\nfashion. We show that while it may be impossible to directly detect a\nmulti-agent activity due to sensor noise or malfunction, the occurrence of the\nactivity can still be inferred by considering both its impact on the future\nbehaviors of the people involved as well as the events that could have preceded\nit. Further, we show that given a model of successfully performed multi-agent\nactivities, along with a set of examples of failed attempts at the same\nactivities, our system automatically learns an augmented model that is capable\nof recognizing success and failure, as well as goals of peoples actions with\nhigh accuracy. We compare our approach with other alternatives and show that\nour unified model, which takes into account not only relationships among\nindividual players, but also relationships among activities over the entire\nlength of a game, although more computationally costly, is significantly more\naccurate. Finally, we demonstrate that explicitly modeling unsuccessful\nattempts boosts performance on other important recognition tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4593v1"
    },
    {
        "title": "Logic and Constraint Logic Programming for Distributed Constraint\n  Optimization",
        "authors": [
            "Tiep Le",
            "Enrico Pontelli",
            "Tran Cao Son",
            "William Yeoh"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The field of Distributed Constraint Optimization Problems (DCOPs) has gained\nmomentum, thanks to its suitability in capturing complex problems (e.g.,\nmulti-agent coordination and resource allocation problems) that are naturally\ndistributed and cannot be realistically addressed in a centralized manner. The\nstate of the art in solving DCOPs relies on the use of ad-hoc infrastructures\nand ad-hoc constraint solving procedures. This paper investigates an\ninfrastructure for solving DCOPs that is completely built on logic programming\ntechnologies. In particular, the paper explores the use of a general constraint\nsolver (a constraint logic programming system in this context) to handle the\nagent-level constraint solving. The preliminary experiments show that logic\nprogramming provides benefits over a state-of-the-art DCOP system, in terms of\nperformance and scalability, opening the doors to the use of more advanced\ntechnology (e.g., search strategies and complex constraints) for solving DCOPs.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.1734v2"
    },
    {
        "title": "Réseaux de radio cognitive : Allocation des ressources radio et\n  accès dynamique au spectre",
        "authors": [
            "Badr Benmammar",
            "Asma Amraoui"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In the first chapter of this report, we provide an overview on mobile and\nwireless networks, with special focus on the IEEE 802.22 norm, which is a norm\ndedicated to cognitive radio (CR). Chapter 2 goes into detail about CR and\nChapter 3 is devoted to the presentation of the concept of agents and in\nparticular the concept of multi-agent systems (MAS). Finally, Chapter 4\nprovides a state of the art on the use of artificial intelligence techniques,\nparticularly MAS for radio resource allocation and dynamic spectrum access in\nthe field of CR.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2705v1"
    },
    {
        "title": "An Agent-Based Approach to Component Management",
        "authors": [
            "David Lillis",
            "Rem Collier",
            "Mauro Dragone",
            "G. M. P. O'Hare"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper details the implementation of a software framework that aids the\ndevelopment of distributed and self-configurable software systems. This\nframework is an instance of a novel integration strategy called SoSAA (SOcially\nSituated Agent Architecture), which combines Component-Based Software\nEngineering and Agent-Oriented Software Engineering, drawing its inspiration\nfrom hybrid agent control architectures. The framework defines a complete\nconstruction process by enhancing a simple component-based framework with\nreasoning and self-awareness capabilities through a standardized interface.\n  The capabilities of the resulting framework are demonstrated through its\napplication to a non-trivial Multi Agent System (MAS). The system in question\nis a pre-existing Information Retrieval (IR) system that has not previously\ntaken advantage of CBSE principles. In this paper we contrast these two systems\nso as to highlight the benefits of using this new hybrid approach. We also\noutline how component-based elements may be integrated into the Agent Factory\nagent-oriented application framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.0176v1"
    },
    {
        "title": "Parallel and Distributed Methods for Nonconvex Optimization-Part I:\n  Theory",
        "authors": [
            "Gesualdo Scutari",
            "Francisco Facchinei",
            "Lorenzo Lampariello",
            "Peiran Song"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In this two-part paper, we propose a general algorithmic framework for the\nminimization of a nonconvex smooth function subject to nonconvex smooth\nconstraints. The algorithm solves a sequence of (separable) strongly convex\nproblems and mantains feasibility at each iteration. Convergence to a\nstationary solution of the original nonconvex optimization is established. Our\nframework is very general and flexible; it unifies several existing Successive\nConvex Approximation (SCA)-based algorithms such as (proximal) gradient or\nNewton type methods, block coordinate (parallel) descent schemes, difference of\nconvex functions methods, and improves on their convergence properties. More\nimportantly, and differently from current SCA approaches, it naturally leads to\ndistributed and parallelizable implementations for a large class of nonconvex\nproblems.\n  This Part I is devoted to the description of the framework in its generality.\nIn Part II we customize our general methods to several multi-agent optimization\nproblems, mainly in communications and networking; the result is a new class of\n(distributed) algorithms that compare favorably to existing ad-hoc\n(centralized) schemes (when they exist).\n",
        "pdf_link": "http://arxiv.org/pdf/1410.4754v2"
    },
    {
        "title": "A Parallel Stochastic Approximation Method for Nonconvex Multi-Agent\n  Optimization Problems",
        "authors": [
            "Yang Yang",
            "Gesualdo Scutari",
            "Daniel P. Palomar",
            "Marius Pesavento"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Consider the problem of minimizing the expected value of a (possibly\nnonconvex) cost function parameterized by a random (vector) variable, when the\nexpectation cannot be computed accurately (e.g., because the statistics of the\nrandom variables are unknown and/or the computational complexity is\nprohibitive). Classical sample stochastic gradient methods for solving this\nproblem may empirically suffer from slow convergence. In this paper, we propose\nfor the first time a stochastic parallel Successive Convex Approximation-based\n(best-response) algorithmic framework for general nonconvex stochastic\nsum-utility optimization problems, which arise naturally in the design of\nmulti-agent systems. The proposed novel decomposition enables all users to\nupdate their optimization variables in parallel by solving a sequence of\nstrongly convex subproblems, one for each user. Almost surely convergence to\nstationary points is proved. We then customize our algorithmic framework to\nsolve the stochastic sum rate maximization problem over\nSingle-Input-Single-Output (SISO) frequency-selective interference channels,\nmultiple-input-multiple-output (MIMO) interference channels, and MIMO\nmultiple-access channels. Numerical results show that our algorithms are much\nfaster than state-of-the-art stochastic gradient schemes while achieving the\nsame (or better) sum-rates.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.5076v2"
    },
    {
        "title": "Massively-concurrent Agent-based Evolutionary Computing",
        "authors": [
            "D. Krzywicki",
            "W. Turek",
            "A. Byrski",
            "M. Kisiel-Dorohinicki"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  The fusion of the multi-agent paradigm with evolutionary computation yielded\npromising results in many optimization problems. Evolutionary multi-agent\nsystem (EMAS) are more similar to biological evolution than classical\nevolutionary algorithms. However, technological limitations prevented the use\nof fully asynchronous agents in previous EMAS implementations. In this paper we\npresent a new algorithm for agent-based evolutionary computations. The\nindividuals are represented as fully autonomous and asynchronous agents. An\nefficient implementation of this algorithm was possible through the use of\nmodern technologies based on functional languages (namely Erlang and Scala),\nwhich natively support lightweight processes and asynchronous communication.\nOur experiments show that such an asynchronous approach is both faster and more\nefficient in solving common optimization problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.06721v2"
    },
    {
        "title": "When more of the same is better",
        "authors": [
            "José F. Fontanari"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Problem solving (e.g., drug design, traffic engineering, software\ndevelopment) by task forces represents a substantial portion of the economy of\ndeveloped countries. Here we use an agent-based model of cooperative problem\nsolving systems to study the influence of diversity on the performance of a\ntask force. We assume that agents cooperate by exchanging information on their\npartial success and use that information to imitate the more successful agent\nin the system -- the model. The agents differ only in their propensities to\ncopy the model. We find that, for easy tasks, the optimal organization is a\nhomogeneous system composed of agents with the highest possible copy\npropensities. For difficult tasks, we find that diversity can prevent the\nsystem from being trapped in sub-optimal solutions. However, when the system\nsize is adjusted to maximize performance the homogeneous systems outperform the\nheterogeneous systems, i.e., for optimal performance, sameness should be\npreferred to diversity.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.00313v2"
    },
    {
        "title": "Densifying the sparse cloud SimSaaS: The need of a synergy among\n  agent-directed simulation, SimSaaS and HLA",
        "authors": [
            "Tiago Azevedo",
            "Rosaldo J. F. Rossetti",
            "Jorge G. Barbosa"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Modelling & Simulation (M&S) is broadly used in real scenarios where making\nphysical modifications could be highly expensive. With the so-called Simulation\nSoftware-as-a-Service (SimSaaS), researchers could take advantage of the huge\namount of resource that cloud computing provides. Even so, studying and\nanalysing a problem through simulation may need several simulation tools, hence\nraising interoperability issues. Having this in mind, IEEE developed a standard\nfor interoperability among simulators named High Level Architecture (HLA).\nMoreover, the multi-agent system approach has become recognised as a convenient\napproach for modelling and simulating complex systems. Despite all the recent\nworks and acceptance of these technologies, there is still a great lack of work\nregarding synergies among them. This paper shows by means of a literature\nreview this lack of work or, in other words, the sparse Cloud SimSaaS. The\nliterature review and the resulting taxonomy are the main contributions of this\npaper, as they provide a research agenda illustrating future research\nopportunities and trends.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.08116v1"
    },
    {
        "title": "A State-of-the-art Integrated Transportation Simulation Platform",
        "authors": [
            "Tiago Azevedo",
            "Rosaldo J. F. Rossetti",
            "Jorge G. Barbosa"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Nowadays, universities and companies have a huge need for simulation and\nmodelling methodologies. In the particular case of traffic and transportation,\nmaking physical modifications to the real traffic networks could be highly\nexpensive, dependent on political decisions and could be highly disruptive to\nthe environment. However, while studying a specific domain or problem,\nanalysing a problem through simulation may not be trivial and may need several\nsimulation tools, hence raising interoperability issues. To overcome these\nproblems, we propose an agent-directed transportation simulation platform,\nthrough the cloud, by means of services. We intend to use the IEEE standard HLA\n(High Level Architecture) for simulators interoperability and agents for\ncontrolling and coordination. Our motivations are to allow multiresolution\nanalysis of complex domains, to allow experts to collaborate on the analysis of\na common problem and to allow co-simulation and synergy of different\napplication domains. This paper will start by presenting some preliminary\nbackground concepts to help better understand the scope of this work. After\nthat, the results of a literature review is shown. Finally, the general\narchitecture of a transportation simulation platform is proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.08162v1"
    },
    {
        "title": "Safe Sequential Path Planning Under Disturbances and Imperfect\n  Information",
        "authors": [
            "Somil Bansal",
            "Mo Chen",
            "Jaime F. Fisac",
            "Claire J. Tomlin"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Multi-UAV systems are safety-critical, and guarantees must be made to ensure\nno unsafe configurations occur. Hamilton-Jacobi (HJ) reachability is ideal for\nanalyzing such safety-critical systems; however, its direct application is\nlimited to small-scale systems of no more than two vehicles due to an\nexponentially-scaling computational complexity. Previously, the sequential path\nplanning (SPP) method, which assigns strict priorities to vehicles, was\nproposed; SPP allows multi-vehicle path planning to be done with a\nlinearly-scaling computational complexity. However, the previous formulation\nassumed that there are no disturbances, and that every vehicle has perfect\nknowledge of higher-priority vehicles' positions. In this paper, we make SPP\nmore practical by providing three different methods to account for disturbances\nin dynamics and imperfect knowledge of higher-priority vehicles' states. Each\nmethod has different assumptions about information sharing. We demonstrate our\nproposed methods in simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.05208v3"
    },
    {
        "title": "User-based solutions for increasing level of service in bike-sharing\n  transportation systems",
        "authors": [
            "Juste Raimbault"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Bike-sharing transportation systems have been well studied from a top-down\nviewpoint, either for an optimal conception of the system, or for a better\nstatistical understanding of their working mechanisms in the aim of the\noptimization of the management strategy. Yet bottom-up approaches that could\ninclude behavior of users have not been well studied so far. We propose an\nagent-based model for the short time evolution of a bike-sharing system, with a\nfocus on two strategical parameters that are the role of the quantity of\ninformation users have on the all system and the propensity of user to walk\nafter having dropped their bike. We implement the model in a general way so it\nis applicable to every system as soon as data are available in a certain\nformat. The model of simulation is parametrized and calibrated on processed\nreal time-series of bike movements for the system of Paris. After showing the\nrobustness of the simulations by validating internally and externally the\nmodel, we are able to test different user-based strategies for an increase of\nthe level of service. In particular, we show that an increase of user\ninformation can have significant impact on the homogeneity of repartition of\nbikes in docking stations, and, what is important for a future implementation\nof the strategy, that an action on only 30% of regular users is enough to\nobtain most of the possible amelioration.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.08883v1"
    },
    {
        "title": "Improving Max-Sum through Decimation to Solve Loopy Distributed\n  Constraint Optimization Problems",
        "authors": [
            "Jesús Cerquides",
            "Rémi Emonet",
            "Gauthier Picard",
            "Juan A. Rodríguez-Aguilar"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In the context of solving large distributed constraint optimization problems\n(DCOP), belief-propagation and approximate inference algorithms are candidates\nof choice. However, in general, when the factor graph is very loopy (i.e.\ncyclic), these solution methods suffer from bad performance, due to\nnon-convergence and many exchanged messages. As to improve performances of the\nMax-Sum inference algorithm when solving loopy constraint optimization\nproblems, we propose here to take inspiration from the\nbelief-propagation-guided dec-imation used to solve sparse random graphs\n(k-satisfiability). We propose the novel DeciMaxSum method, which is\nparameterized in terms of policies to decide when to trigger decimation, which\nvariables to decimate, and which values to assign to decimated variables. Based\non an empirical evaluation on a classical BP benchmark (the Ising model), some\nof these combinations of policies exhibit better performance than\nstate-of-the-art competitors.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.02209v1"
    },
    {
        "title": "An Algorithm for Supervised Driving of Cooperative Semi-Autonomous\n  Vehicles (Extended)",
        "authors": [
            "Florent Altche",
            "Xiangjun Qian",
            "Arnaud de La Fortelle"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Before reaching full autonomy, vehicles will gradually be equipped with more\nand more advanced driver assistance systems (ADAS), effectively rendering them\nsemi-autonomous. However, current ADAS technologies seem unable to handle\ncomplex traffic situations, notably when dealing with vehicles arriving from\nthe sides, either at intersections or when merging on highways. The high rate\nof accidents in these settings prove that they constitute difficult driving\nsituations. Moreover, intersections and merging lanes are often the source of\nimportant traffic congestion and, sometimes, deadlocks. In this article, we\npropose a cooperative framework to safely coordinate semi-autonomous vehicles\nin such settings, removing the risk of collision or deadlocks while remaining\ncompatible with human driving. More specifically, we present a supervised\ncoordination scheme that overrides control inputs from human drivers when they\nwould result in an unsafe or blocked situation. To avoid unnecessary\nintervention and remain compatible with human driving, overriding only occurs\nwhen collisions or deadlocks are imminent. In this case, safe overriding\ncontrols are chosen while ensuring they deviate minimally from those originally\nrequested by the drivers. Simulation results based on a realistic physics\nsimulator show that our approach is scalable to real-world scenarios, and\ncomputations can be performed in real-time on a standard computer for up to a\ndozen simultaneous vehicles.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.08046v1"
    },
    {
        "title": "A Simulator for Hedonic Games",
        "authors": [
            "Luke Harold Miles"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Hedonic games are meant to model how coalitions of people form and break\napart in the real world. However, it is difficult to run simulations when\neverything must be done by hand on paper. We present an online software that\nallows fast and visual simulation of several types of hedonic games.\nhttp://lukemiles.org/hedonic-games/\n",
        "pdf_link": "http://arxiv.org/pdf/1706.08501v2"
    },
    {
        "title": "Scalable Asymptotically-Optimal Multi-Robot Motion Planning",
        "authors": [
            "Andrew Dobson",
            "Kiril Solovey",
            "Rahul Shome",
            "Dan Halperin",
            "Kostas E. Bekris"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Finding asymptotically-optimal paths in multi-robot motion planning problems\ncould be achieved, in principle, using sampling-based planners in the composite\nconfiguration space of all of the robots in the space. The dimensionality of\nthis space increases with the number of robots, rendering this approach\nimpractical. This work focuses on a scalable sampling-based planner for coupled\nmulti-robot problems that provides asymptotic optimality. It extends the dRRT\napproach, which proposed building roadmaps for each robot and searching an\nimplicit roadmap in the composite configuration space. This work presents a new\nmethod, dRRT* , and develops theory for scalable convergence to optimal paths\nin multi-robot problems. Simulated experiments indicate dRRT* converges to\nhigh-quality paths while scaling to higher numbers of robots where the naive\napproach fails. Furthermore, dRRT* is applicable to high-dimensional problems,\nsuch as planning for robot manipulators\n",
        "pdf_link": "http://arxiv.org/pdf/1706.09932v2"
    },
    {
        "title": "Cities of the Future: Employing Wireless Sensor Networks for Efficient\n  Decision Making in Complex Environments",
        "authors": [
            "Alex Doboli",
            "Daniel Curiac",
            "Dan Pescaru",
            "Simona Doboli",
            "Wendy Tang",
            "Costantin Volosencu",
            "Michael Gilberti",
            "Ovidiu Banias",
            "Codruta Istin"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Decision making in large scale urban environments is critical for many\napplications involving continuous distribution of resources and utilization of\ninfrastructure, such as ambient lighting control and traffic management.\nTraditional decision making methods involve extensive human participation, are\nexpensive, and inefficient and unreliable for hard-to-predict situations.\nModern technology, including ubiquitous data collection though sensors,\nautomated analysis and prognosis, and online optimization, offers new\ncapabilities for developing flexible, autonomous, scalable, efficient, and\npredictable control methods. This paper presents a new decision making concept\nin which a hierarchy of semantically more abstract models are utilized to\nperform online scalable and predictable control. The lower semantic levels\nperform localized decisions based on sampled data from the environment, while\nthe higher semantic levels provide more global, time invariant results based on\naggregated data from the lower levels. There is a continuous feedback between\nthe levels of the semantic hierarchy, in which the upper levels set performance\nguaranteeing constraints for the lower levels, while the lower levels indicate\nwhether these constraints are feasible or not. Even though the semantic\nhierarchy is not tied to a particular set of description models, the paper\nillustrates a hierarchy used for traffic management applications and composed\nof Finite State Machines, Conditional Task Graphs, Markov Decision Processes,\nand functional graphs. The paper also summarizes some of the main research\nproblems that must be addressed as part of the proposed concept\n",
        "pdf_link": "http://arxiv.org/pdf/1808.01169v1"
    },
    {
        "title": "Coordination-driven learning in multi-agent problem spaces",
        "authors": [
            "Sean L. Barton",
            "Nicholas R. Waytowich",
            "Derrik E. Asher"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We discuss the role of coordination as a direct learning objective in\nmulti-agent reinforcement learning (MARL) domains. To this end, we present a\nnovel means of quantifying coordination in multi-agent systems, and discuss the\nimplications of using such a measure to optimize coordinated agent policies.\nThis concept has important implications for adversary-aware RL, which we take\nto be a sub-domain of multi-agent learning.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.04918v1"
    },
    {
        "title": "IntelligentCrowd: Mobile Crowdsensing via Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Yize Chen",
            "Hao Wang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The prosperity of smart mobile devices has made mobile crowdsensing (MCS) a\npromising paradigm for completing complex sensing and computation tasks. In the\npast, great efforts have been made on the design of incentive mechanisms and\ntask allocation strategies from MCS platform's perspective to motivate mobile\nusers' participation. However, in practice, MCS participants face many\nuncertainties coming from their sensing environment as well as other\nparticipants' strategies, and how do they interact with each other and make\nsensing decisions is not well understood. In this paper, we take MCS\nparticipants' perspective to derive an online sensing policy to maximize their\npayoffs via MCS participation. Specifically, we model the interactions of\nmobile users and sensing environments as a multi-agent Markov decision process.\nEach participant cannot observe others' decisions, but needs to decide her\neffort level in sensing tasks only based on local information, e.g., its own\nrecord of sensed signals' quality. To cope with the stochastic sensing\nenvironment, we develop an intelligent crowdsensing algorithm IntelligentCrowd\nby leveraging the power of multi-agent reinforcement learning (MARL). Our\nalgorithm leads to the optimal sensing policy for each user to maximize the\nexpected payoff against stochastic sensing environments, and can be implemented\nat individual participant's level in a distributed fashion. Numerical\nsimulations demonstrate that IntelligentCrowd significantly improves users'\npayoffs in sequential MCS tasks under various sensing dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07830v3"
    },
    {
        "title": "The Price of Governance: A Middle Ground Solution to Coordination in\n  Organizational Control",
        "authors": [
            "Chao Yu"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Achieving coordination is crucial in organizational control. This paper\ninvestigates a middle ground solution between decentralized interactions and\ncentralized administrations for coordinating agents beyond inefficient\nbehavior. We first propose the price of governance (PoG) to evaluate how such a\nmiddle ground solution performs in terms of effectiveness and cost. We then\npropose a hierarchical supervision framework to explicitly model the PoG, and\ndefine step by step how to realize the core principle of the framework and\ncompute the optimal PoG for a control problem. Two illustrative case studies\nare carried out to exemplify the applications of the proposed framework and its\nmethodology. Results show that by properly formulating and implementing each\nstep, the hierarchical supervision framework is capable of promoting\ncoordination among agents while bounding administrative cost to a minimum in\ndifferent kinds of organizational control problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.03819v1"
    },
    {
        "title": "Distributed Obstacle and Multi-Robot Collision Avoidance in Uncertain\n  Environments",
        "authors": [
            "Vu Phi Tran",
            "Matthew Garratt",
            "Ian R. Petersen"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper tackles the distributed leader-follower (L-F) control problem for\nheterogeneous mobile robots in unknown environments requiring obstacle\navoidance, inter-robot collision avoidance, and reliable robot communications.\nTo prevent an inter-robot collision, we employ a virtual propulsive force\nbetween robots. For obstacle avoidance, we present a novel distributed\nNegative-Imaginary (NI) variant formation tracking control approach and a\ndynamic network topology methodology which allows the formation to change its\nshape and the robot to switch their roles. In the case of communication or\nsensor loss, a UAV, controlled by a Strictly-Negative-Imaginary (SNI)\ncontroller with good wind resistance characteristics, is utilized to track the\nposition of the UGV formation using its camera. Simulations and indoor\nexperiments have been conducted to validate the proposed methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06196v1"
    },
    {
        "title": "Time-Varying Formation Control of a Collaborative Multi-Agent System\n  Using Negative-Imaginary Systems Theory",
        "authors": [
            "Vu Phi Tran",
            "Matthew Garratt",
            "Ian R. Petersen"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The movement of cooperative robots in a densely cluttered environment may not\nbe possible if the formation type is invariant. Hence, we investigate a new\nmethod for time-varying formation control for a group of heterogeneous\nautonomous vehicles, which may include Unmanned Ground Vehicles (UGV) and\nUnmanned Aerial Vehicles (UAV). We have extended a Negative-Imaginary (NI)\nconsensus control approach to switch the formation shape of the robots whilst\nonly using the relative distance between agents and between agents and\nobstacles. All agents can automatically create a new safe formation to overcome\nobstacles based on a novel geometric method, then restore the prototype\nformation once the obstacles are cleared. Furthermore, we improve the position\nconsensus at sharp corners by achieving yaw consensus between robots.\nSimulation and experimental results are then analyzed to validate the\nfeasibility of our proposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06206v1"
    },
    {
        "title": "Tetris",
        "authors": [
            "Jiajun Xu",
            "Sam Huang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Tetris is an Asynchronous Byzantine Fault Tolerance consensus algorithm\ndesigned for next generation high-throughput permission and permissionless\nblockchain. The core concept of Tetris is derived from Reasoning About\nKnowledge, which we believe to be the most appropriate tools for revealing and\nanalyzing the fundamental complexity of distributed systems. By analyzing the\nstates of knowledge that each participant attained in an unreliable system, we\ncan capture some of the basis underlying structure of the system, then help us\ndesigning effective & efficient protocols. Plus the adoption of Full\nInformation Protocol (FIP) with the optimized message traffic model, Tetris has\nfinally got high performance, with proved safety. Tetris achieve consensus\nfinality in seconds, means transactions can be confirmed greatly faster than\nother scheme like Pow/Dpos. Tetris also achieve fairness, which is critically\nimportant in some areas such as stock market etc.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08614v2"
    },
    {
        "title": "Deep Multi-Agent Reinforcement Learning with Relevance Graphs",
        "authors": [
            "Aleksandra Malysheva",
            "Tegg Taekyong Sung",
            "Chae-Bong Sohn",
            "Daniel Kudenko",
            "Aleksei Shpilman"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Over recent years, deep reinforcement learning has shown strong successes in\ncomplex single-agent tasks, and more recently this approach has also been\napplied to multi-agent domains. In this paper, we propose a novel approach,\ncalled MAGnet, to multi-agent reinforcement learning (MARL) that utilizes a\nrelevance graph representation of the environment obtained by a self-attention\nmechanism, and a message-generation technique inspired by the NerveNet\narchitecture. We applied our MAGnet approach to the Pommerman game and the\nresults show that it significantly outperforms state-of-the-art MARL solutions,\nincluding DQN, MADDPG, and MCTS.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.12557v1"
    },
    {
        "title": "Sample Greedy Based Task Allocation for Multiple Robot Systems",
        "authors": [
            "Hyo-Sang Shin",
            "Teng Li",
            "Pau Segui-Gasco"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper addresses the task allocation problem for multi-robot systems. The\nmain issue with the task allocation problem is inherent complexity that makes\nfinding an optimal solution within a reasonable time almost impossible. To hand\nthe issue, this paper develops a task allocation algorithm that can be\ndecentralised by leveraging the submodularity concepts and sampling process.\nThe theoretical analysis reveals that the proposed algorithm can provide\napproximation guarantee of $1/2$ for the monotone submodular case and $1/4$ for\nthe non-monotone submodular case in average sense with polynomial time\ncomplexity. To examine the performance of the proposed algorithm and validate\nthe theoretical analysis results, we design a task allocation problem and\nperform numerical simulations. The simulation results confirm that the proposed\nalgorithm achieves solution quality, which is comparable to a state-of-the-art\nalgorithm in the monotone case, and much better quality in the non-monotone\ncase with significantly less computational complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.03258v1"
    },
    {
        "title": "Inferring Causality in Agent-Based Simulations - Literature Review",
        "authors": [
            "George Hassan-Coring"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Complex systems have interested researchers across a broad range of fields\nfor many years and as computing has become more accesible and feasible, it is\nnow possible to simulate aspects of these systems. A major point of research is\nhow emergent behaviour arises and the underlying causes of it. This paper aims\nto discuss and compare different methods of identifying causal links between\nagents in such systems in order to gain further understanding of the structure.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.04836v1"
    },
    {
        "title": "Designing a Multi-Objective Reward Function for Creating Teams of\n  Robotic Bodyguards Using Deep Reinforcement Learning",
        "authors": [
            "Hassam Ullah Sheikh",
            "Ladislau Bölöni"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We are considering a scenario where a team of bodyguard robots provides\nphysical protection to a VIP in a crowded public space. We use deep\nreinforcement learning to learn the policy to be followed by the robots. As the\nrobot bodyguards need to follow several difficult-to-reconcile goals, we study\nseveral primitive and composite reward functions and their impact on the\noverall behavior of the robotic bodyguards.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.09837v1"
    },
    {
        "title": "Are You Doing What I Think You Are Doing? Criticising Uncertain Agent\n  Models",
        "authors": [
            "Stefano V. Albrecht",
            "S. Ramamoorthy"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The key for effective interaction in many multiagent applications is to\nreason explicitly about the behaviour of other agents, in the form of a\nhypothesised behaviour. While there exist several methods for the construction\nof a behavioural hypothesis, there is currently no universal theory which would\nallow an agent to contemplate the correctness of a hypothesis. In this work, we\npresent a novel algorithm which decides this question in the form of a\nfrequentist hypothesis test. The algorithm allows for multiple metrics in the\nconstruction of the test statistic and learns its distribution during the\ninteraction process, with asymptotic correctness guarantees. We present results\nfrom a comprehensive set of experiments, demonstrating that the algorithm\nachieves high accuracy and scalability at low computational costs.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.01912v1"
    },
    {
        "title": "Learning Truthful, Efficient, and Welfare Maximizing Auction Rules",
        "authors": [
            "Andrea Tacchetti",
            "DJ Strouse",
            "Marta Garnelo",
            "Thore Graepel",
            "Yoram Bachrach"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  From social networks to supply chains, more and more aspects of how humans,\nfirms and organizations interact is mediated by artificial learning agents. As\nthe influence of machine learning systems grows, it is paramount that we study\nhow to imbue our modern institutions with our own values and principles. Here\nwe consider the problem of allocating goods to buyers who have preferences over\nthem in settings where the seller's aim is not to maximize their monetary\ngains, but rather to advance some notion of social welfare (e.g. the government\ntrying to award construction licenses for hospitals or schools). This problem\nhas a long history in economics, and solutions take the form of auction rules.\nResearchers have proposed reliable auction rules that work in extremely general\nsettings, and in the presence of information asymmetry and strategic buyers.\nHowever, these protocols require significant payments from participants\nresulting in low aggregate welfare. Here we address this shortcoming by casting\nauction rule design as a statistical learning problem, and trade generality for\nparticipant welfare effectively and automatically with a novel deep learning\nnetwork architecture and auction representation. Our analysis shows that our\nauction rules outperform state-of-the art approaches in terms of participants\nwelfare, applicability, robustness.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.05181v2"
    },
    {
        "title": "Broadcast Distributed Voting Algorithm in Population Protocols",
        "authors": [
            "Hamidreza Bandealinaeini",
            "Saber Salehkaleybar"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We consider the problem of multi-choice majority voting in a network of $n$\nagents where each agent initially selects a choice from a set of $K$ possible\nchoices. The agents try to infer the choice in majority merely by performing\nlocal interactions. Population protocols provide a framework for designing\npairwise interactions between agents in order to perform tasks in a coordinated\nmanner. In this paper, we propose ``Broadcasting Population Protocol\" model as\na counterpart model of conventional population protocols for the networks that\neach agent can send a message to all its neighbors simultaneously. We design\ntwo distributed algorithms for solving the multi-choice majority voting problem\nin the model of broadcasting population protocols. We prove the correctness of\nthese algorithms and analyze their performance in terms of time and message\ncomplexities. Experiments show that the proposed algorithm improves both time\nand message complexities significantly with respect to previous algorithms\nproposed in conventional population protocols and they can be utilized in\nnetworks where messages can be transmitted to a subset of agents simultaneously\nsuch as wireless networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.06855v1"
    },
    {
        "title": "Comparative Evaluation of Multiagent Learning Algorithms in a Diverse\n  Set of Ad Hoc Team Problems",
        "authors": [
            "Stefano V. Albrecht",
            "Subramanian Ramamoorthy"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper is concerned with evaluating different multiagent learning (MAL)\nalgorithms in problems where individual agents may be heterogenous, in the\nsense of utilizing different learning strategies, without the opportunity for\nprior agreements or information regarding coordination. Such a situation arises\nin ad hoc team problems, a model of many practical multiagent systems\napplications. Prior work in multiagent learning has often been focussed on\nhomogeneous groups of agents, meaning that all agents were identical and a\npriori aware of this fact. Also, those algorithms that are specifically\ndesigned for ad hoc team problems are typically evaluated in teams of agents\nwith fixed behaviours, as opposed to agents which are adapting their\nbehaviours. In this work, we empirically evaluate five MAL algorithms,\nrepresenting major approaches to multiagent learning but originally developed\nwith the homogeneous setting in mind, to understand their behaviour in a set of\nad hoc team problems. All teams consist of agents which are continuously\nadapting their behaviours. The algorithms are evaluated with respect to a\ncomprehensive characterisation of repeated matrix games, using performance\ncriteria that include considerations such as attainment of equilibrium, social\nwelfare and fairness. Our main conclusion is that there is no clear winner.\nHowever, the comparative evaluation also highlights the relative strengths of\ndifferent algorithms with respect to the type of performance criteria, e.g.,\nsocial welfare vs. attainment of equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.09189v1"
    },
    {
        "title": "Agent Modeling as Auxiliary Task for Deep Reinforcement Learning",
        "authors": [
            "Pablo Hernandez-Leal",
            "Bilal Kartal",
            "Matthew E. Taylor"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper we explore how actor-critic methods in deep reinforcement\nlearning, in particular Asynchronous Advantage Actor-Critic (A3C), can be\nextended with agent modeling. Inspired by recent works on representation\nlearning and multiagent deep reinforcement learning, we propose two\narchitectures to perform agent modeling: the first one based on parameter\nsharing, and the second one based on agent policy features. Both architectures\naim to learn other agents' policies as auxiliary tasks, besides the standard\nactor (policy) and critic (values). We performed experiments in both\ncooperative and competitive domains. The former is a problem of coordinated\nmultiagent object transportation and the latter is a two-player mini version of\nthe Pommerman game. Our results show that the proposed architectures stabilize\nlearning and outperform the standard A3C architecture when learning a best\nresponse in terms of expected rewards.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.09597v1"
    },
    {
        "title": "Alternative Intersection Designs with Connected and Automated Vehicle",
        "authors": [
            "Zijia Zhong",
            "Earl E. Lee"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Alternative intersection designs (AIDs) can improve the performance of an\nintersection by not only reducing the number of signal phases but also change\nthe configuration of the conflicting points by re-routing traffic. However the\nAID studies have rarely been extended to Connected and Automated Vehicle (CAV)\nwhich is expected to revolutionize our transportation system. In this study, we\ninvestigate the potential benefits of CAV to two AIDs: the diverging diamond\ninterchange (DDI) and the restricted crossing U-turn intersection. The\npotential enhancements of AID, CAV, and the combination of both are quantified\nvia microscopic traffic simulation. We found that CAV is able to positively\ncontribute to the performance of an intersection. However, converting an\nexisting conventional diamond interchange (CDI) to a diverging one is a more\neffective way according to the simulation results. DDI improves the throughput\nof a CDI by 950 vehicles per hour, a near 20% improvement; whereas with full\npenetration of CAV, the throughput of a CDI is increased only by 300 vehicles\nper hour. A similar trend is observed in the average delay per vehicle as well.\nFurthermore, we assess the impact for the driver's confusion, a concern for\ndeploying AIDs, on the traffic flow. According to the ANOVA test, the negative\nimpacts of driver's confusion are of statistical significance.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10491v1"
    },
    {
        "title": "A Framework for Monitoring Human Physiological Response during Human\n  Robot Collaborative Task",
        "authors": [
            "Celal Savur",
            "Shitij Kumar",
            "Ferat Sahin"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, a framework for monitoring human physiological response during\nHuman-Robot Collaborative (HRC) task is presented. The framework highlights the\nimportance of generation of event markers related to both human and robot, and\nalso synchronization of data collected. This framework enables continuous data\ncollection during an HRC task when changing robot movements as a form of\nstimuli to invoke a human physiological response. It also presents two case\nstudies based on this framework and a data visualization tool for\nrepresentation and easy analysis of the collected data during an HRC\nexperiment.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10782v2"
    },
    {
        "title": "Action Semantics Network: Considering the Effects of Actions in\n  Multiagent Systems",
        "authors": [
            "Weixun Wang",
            "Tianpei Yang",
            "Yong Liu",
            "Jianye Hao",
            "Xiaotian Hao",
            "Yujing Hu",
            "Yingfeng Chen",
            "Changjie Fan",
            "Yang Gao"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In multiagent systems (MASs), each agent makes individual decisions but all\nof them contribute globally to the system evolution. Learning in MASs is\ndifficult since each agent's selection of actions must take place in the\npresence of other co-learning agents. Moreover, the environmental stochasticity\nand uncertainties increase exponentially with the increase in the number of\nagents. Previous works borrow various multiagent coordination mechanisms into\ndeep learning architecture to facilitate multiagent coordination. However, none\nof them explicitly consider action semantics between agents that different\nactions have different influences on other agents. In this paper, we propose a\nnovel network architecture, named Action Semantics Network (ASN), that\nexplicitly represents such action semantics between agents. ASN characterizes\ndifferent actions' influence on other agents using neural networks based on the\naction semantics between them. ASN can be easily combined with existing deep\nreinforcement learning (DRL) algorithms to boost their performance.\nExperimental results on StarCraft II micromanagement and Neural MMO show ASN\nsignificantly improves the performance of state-of-the-art DRL approaches\ncompared with several network architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.11461v3"
    },
    {
        "title": "G-flocking: Flocking Model Optimization based on Genetic Framework",
        "authors": [
            "Li Ma",
            "Weidong Bao",
            "Xiaomin Zhu",
            "Meng Wu",
            "Yuan Wang",
            "Yunxiang Ling",
            "Wen Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Flocking model has been widely used to control robotic swarm. However, with\nthe increasing scalability, there exist complex conflicts for robotic swarm in\nautonomous navigation, brought by internal pattern maintenance, external\nenvironment changes, and target area orientation, which results in poor\nstability and adaptability. Hence, optimizing the flocking model for robotic\nswarm in autonomous navigation is an important and meaningful research domain.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.11852v1"
    },
    {
        "title": "Multi-Agent Path Finding with Capacity Constraints",
        "authors": [
            "Pavel Surynek",
            "T. K. Satish Kumar",
            "Sven Koenig"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In multi-agent path finding (MAPF) the task is to navigate agents from their\nstarting positions to given individual goals. The problem takes place in an\nundirected graph whose vertices represent positions and edges define the\ntopology. Agents can move to neighbor vertices across edges. In the standard\nMAPF, space occupation by agents is modeled by a capacity constraint that\npermits at most one agent per vertex. We suggest an extension of MAPF in this\npaper that permits more than one agent per vertex. Propositional satisfiability\n(SAT) models for these extensions of MAPF are studied. We focus on modeling\ncapacity constraints in SAT-based formulations of MAPF and evaluation of\nperformance of these models. We extend two existing SAT-based formulations with\nvertex capacity constraints: MDD-SAT and SMT-CBS where the former is an\napproach that builds the model in an eager way while the latter relies on lazy\nconstruction of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12648v1"
    },
    {
        "title": "Cognitive Agent Based Simulation Model For Improving Disaster Response\n  Procedures",
        "authors": [
            "Rohit K. Dubey",
            "Samuel S. Sohn",
            "Christoph Hoelscher",
            "Mubbasir Kapadia"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In the event of a disaster, saving human lives is of utmost importance. For\ndeveloping proper evacuation procedures and guidance systems, behavioural data\non how people respond during panic and stress is crucial. In the absence of\nreal human data on building evacuation, there is a need for a crowd simulator\nto model egress and decision-making under uncertainty. In this paper, we\npropose an agent-based simulation tool, which is grounded in human cognition\nand decision-making, for evaluating and improving the effectiveness of building\nevacuation procedures and guidance systems during a disaster. Specifically, we\npropose a predictive agent-wayfinding framework based on information theory\nthat is applied at intersections with variable route choices where it fuses N\ndynamic information sources. The proposed framework can be used to visualize\ntrajectories and prediction results (i.e., total evacuation time, number of\npeople evacuated) for different combinations of reinforcing or contradicting\ninformation sources (i.e., signage, crowd flow, familiarity, and spatial\nlayout). This tool can enable designers to recreate various disaster scenarios\nand generate simulation data for improving the evacuation procedures and\nexisting guidance systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.00767v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Order-dispatching via\n  Order-Vehicle Distribution Matching",
        "authors": [
            "Ming Zhou",
            "Jiarui Jin",
            "Weinan Zhang",
            "Zhiwei Qin",
            "Yan Jiao",
            "Chenxi Wang",
            "Guobin Wu",
            "Yong Yu",
            "Jieping Ye"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Improving the efficiency of dispatching orders to vehicles is a research\nhotspot in online ride-hailing systems. Most of the existing solutions for\norder-dispatching are centralized controlling, which require to consider all\npossible matches between available orders and vehicles. For large-scale\nride-sharing platforms, there are thousands of vehicles and orders to be\nmatched at every second which is of very high computational cost. In this\npaper, we propose a decentralized execution order-dispatching method based on\nmulti-agent reinforcement learning to address the large-scale order-dispatching\nproblem. Different from the previous cooperative multi-agent reinforcement\nlearning algorithms, in our method, all agents work independently with the\nguidance from an evaluation of the joint policy since there is no need for\ncommunication or explicit cooperation between agents. Furthermore, we use\nKL-divergence optimization at each time step to speed up the learning process\nand to balance the vehicles (supply) and orders (demand). Experiments on both\nthe explanatory environment and real-world simulator show that the proposed\nmethod outperforms the baselines in terms of accumulated driver income (ADI)\nand Order Response Rate (ORR) in various traffic environments. Besides, with\nthe support of the online platform of Didi Chuxing, we designed a hybrid system\nto deploy our model.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.02591v1"
    },
    {
        "title": "Decentralized Multi-Agent Actor-Critic with Generative Inference",
        "authors": [
            "Kevin Corder",
            "Manuel M. Vindiola",
            "Keith Decker"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Recent multi-agent actor-critic methods have utilized centralized training\nwith decentralized execution to address the non-stationarity of co-adapting\nagents. This training paradigm constrains learning to the centralized phase\nsuch that only pre-learned policies may be used during the decentralized phase,\nwhich performs poorly when agent communications are delayed, noisy, or\ndisrupted. In this work, we propose a new system that can gracefully handle\npartially-observable information due to communication disruptions during\ndecentralized execution. Our approach augments the multi-agent actor-critic\nmethod's centralized training phase with generative modeling so that agents may\ninfer other agents' observations when provided with locally available context.\nOur method is evaluated on three tasks that require agents to combine local and\nremote observations communicated by other agents. We evaluate our approach by\nintroducing both partial observability during decentralized execution, and show\nthat decentralized training on inferred observations performs as well or better\nthan existing actor-critic methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.03058v1"
    },
    {
        "title": "Multi-Robot Coordinated Planning in Confined Environments under\n  Kinematic Constraints",
        "authors": [
            "Clayton Mangette",
            "Pratap Tokekar"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We investigate the problem of multi-robot coordinated planning in\nenvironments where the robots may have to operate in close proximity to each\nother. We seek computationally efficient planners that ensure safe paths and\nadherence to kinematic constraints. We extend the central planner dRRT* with\nour variant, fast-dRRT (fdRRT), with the intention being to use in tight\nenvironments that lead to a high degree of coupling between robots. Our\nalgorithm is empirically shown to achieve the trade-off between computational\ntime and solution quality, especially in tight environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.03101v1"
    },
    {
        "title": "Modeling Cyber-Physical Human Systems via an Interplay Between\n  Reinforcement Learning and Game Theory",
        "authors": [
            "Mert Albaba",
            "Yildiray Yildiz"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Predicting the outcomes of cyber-physical systems with multiple human\ninteractions is a challenging problem. This article reviews a game theoretical\napproach to address this issue, where reinforcement learning is employed to\npredict the time-extended interaction dynamics. We explain that the most\nattractive feature of the method is proposing a computationally feasible\napproach to simultaneously model multiple humans as decision makers, instead of\ndetermining the decision dynamics of the intelligent agent of interest and\nforcing the others to obey certain kinematic and dynamic constraints imposed by\nthe environment. We present two recent exploitations of the method to model 1)\nunmanned aircraft integration into the National Airspace System and 2) highway\ntraffic. We conclude the article by providing ongoing and future work about\nemploying, improving and validating the method. We also provide related open\nproblems and research opportunities.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.05092v1"
    },
    {
        "title": "Anticipating Illegal Maritime Activities from Anomalous Multiscale Fleet\n  Behaviors",
        "authors": [
            "James R. Watson",
            "A. John Woodill"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Illegal fishing is prevalent throughout the world and heavily impacts the\nhealth of our oceans, the sustainability and profitability of fisheries, and\neven acts to destabilize geopolitical relations. To achieve the United Nations'\nSustainable Development Goal of \"Life Below Water\", our ability to detect and\npredict illegal fishing must improve. Recent advances have been made through\nthe use of vessel location data, however, most analyses to date focus on\nanomalous spatial behaviors of vessels one at a time. To improve predictions,\nwe develop a method inspired by complex systems theory to monitor the anomalous\nmulti-scale behavior of whole fleets as they respond to nearby illegal\nactivities. Specifically, we analyze changes in the multiscale geospatial\norganization of fishing fleets operating on the Patagonia Shelf, an important\nfishing region with chronic exposure to illegal fishing. We show that legally\noperating (and visible) vessels respond anomalously to nearby illegal\nactivities (by vessels that are difficult to detect). Indeed, precursor\nbehaviors are identified, suggesting a path towards pre-empting illegal\nactivities. This approach offers a promising step towards a global system for\ndetecting, predicting and deterring illegal activities at sea in near\nreal-time. Doing so will be a big step forward to achieving sustainable life\nunderwater.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.05424v1"
    },
    {
        "title": "Autonomous Industrial Management via Reinforcement Learning:\n  Self-Learning Agents for Decision-Making -- A Review",
        "authors": [
            "Leonardo A. Espinosa Leal",
            "Magnus Westerlund",
            "Anthony Chapman"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Industry has always been in the pursuit of becoming more economically\nefficient and the current focus has been to reduce human labour using modern\ntechnologies. Even with cutting edge technologies, which range from packaging\nrobots to AI for fault detection, there is still some ambiguity on the aims of\nsome new systems, namely, whether they are automated or autonomous. In this\npaper we indicate the distinctions between automated and autonomous system as\nwell as review the current literature and identify the core challenges for\ncreating learning mechanisms of autonomous agents. We discuss using different\ntypes of extended realities, such as digital twins, to train reinforcement\nlearning agents to learn specific tasks through generalization. Once\ngeneralization is achieved, we discuss how these can be used to develop\nself-learning agents. We then introduce self-play scenarios and how they can be\nused to teach self-learning agents through a supportive environment which\nfocuses on how the agents can adapt to different real-world environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.08942v1"
    },
    {
        "title": "Data assimilation in Agent-based models using creation and annihilation\n  operators",
        "authors": [
            "Daniel Tang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Agent-based models are a powerful tool for studying the behaviour of complex\nsystems that can be described in terms of multiple, interacting ``agents''.\nHowever, because of their inherently discrete and often highly non-linear\nnature, it is very difficult to reason about the relationship between the state\nof the model, on the one hand, and our observations of the real world on the\nother. In this paper we consider agents that have a discrete set of states\nthat, at any instant, act with a probability that may depend on the environment\nor the state of other agents. Given this, we show how the mathematical\napparatus of quantum field theory can be used to reason probabilistically about\nthe state and dynamics the model, and describe an algorithm to update our\nbelief in the state of the model in the light of new, real-world observations.\nUsing a simple predator-prey model on a 2-dimensional spatial grid as an\nexample, we demonstrate the assimilation of incomplete, noisy observations and\nshow that this leads to an increase in the mutual information between the\nactual state of the observed system and the posterior distribution given the\nobservations, when compared to a null model.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.09442v1"
    },
    {
        "title": "Interplay between Topology and Social Learning over Weak Graphs",
        "authors": [
            "Vincenzo Matta",
            "Virginia Bordignon",
            "Augusto Santos",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We consider a social learning problem, where a network of agents is\ninterested in selecting one among a finite number of hypotheses. We focus on\nweakly-connected graphs where the network is partitioned into a sending part\nand a receiving part. The data collected by the agents might be heterogeneous.\nFor example, some sub-networks might intentionally generate data from a fake\nhypothesis in order to influence other agents. The social learning task is\naccomplished via a diffusion strategy where each agent: i) updates individually\nits belief using its private data; ii) computes a new belief by exponentiating\na linear combination of the log-beliefs of its neighbors. First, we examine\nwhat agents learn over weak graphs (social learning problem). We obtain\nanalytical formulas for the beliefs at the different agents, which reveal how\nthe agents' detection capability and the network topology interact to influence\nthe beliefs. In particular, the formulas allow us to predict when a\nleader-follower behavior is possible, where some sending agents can control the\nmind of the receiving agents by forcing them to choose a particular hypothesis.\nSecond, we consider the dual or reverse learning problem that reveals how\nagents learned: given a stream of beliefs collected at a receiving agent, we\nwould like to discover the global influence that any sending component exerts\non this receiving agent (topology learning problem). A remarkable and perhaps\nunexpected interplay between social and topology learning is observed: given\n$H$ hypotheses and $S$ sending components, topology learning can be feasible\nwhen $H\\geq S$. The latter being only a necessary condition, we examine the\nfeasibility of topology learning for two useful classes of problems. The\nanalysis reveals that a critical element to enable faithful topology learning\nis the diversity in the statistical models of the sending sub-networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13905v1"
    },
    {
        "title": "Scaling Up Multiagent Reinforcement Learning for Robotic Systems: Learn\n  an Adaptive Sparse Communication Graph",
        "authors": [
            "Chuangchuang Sun",
            "Macheng Shen",
            "Jonathan P. How"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The complexity of multiagent reinforcement learning (MARL) in multiagent\nsystems increases exponentially with respect to the agent number. This\nscalability issue prevents MARL from being applied in large-scale multiagent\nsystems. However, one critical feature in MARL that is often neglected is that\nthe interactions between agents are quite sparse. Without exploiting this\nsparsity structure, existing works aggregate information from all of the agents\nand thus have a high sample complexity. To address this issue, we propose an\nadaptive sparse attention mechanism by generalizing a sparsity-inducing\nactivation function. Then a sparse communication graph in MARL is learned by\ngraph neural networks based on this new attention mechanism. Through this\nsparsity structure, the agents can communicate in an effective as well as\nefficient way via only selectively attending to agents that matter the most and\nthus the scale of the MARL problem is reduced with little optimality\ncompromised. Comparative results show that our algorithm can learn an\ninterpretable sparse structure and outperforms previous works by a significant\nmargin on applications involving a large-scale multiagent system.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.01040v2"
    },
    {
        "title": "Adaptive Online Distributed Optimal Control of Very-Large-Scale Robotic\n  Systems",
        "authors": [
            "Pingping Zhu",
            "Chang Liu",
            "Silvia Ferrari"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper presents an adaptive online distributed optimal control approach\nthat is applicable to optimal planning for very-large-scale robotics systems in\nhighly uncertain environments. This approach is developed based on the optimal\nmass transport theory. It is also viewed as an online reinforcement learning\nand approximate dynamic programming approach in the Wasserstein-GMM space,\nwhere a novel value functional is defined based on the probability density\nfunctions of robots and the time-varying obstacle map functions describing the\nchanging environmental information. The proposed approach is demonstrated on\nthe path planning problem of very-largescale robotic systems where the\napproximated layout of obstacles in the workspace is incrementally updated by\nthe observations of robots, and compared with some existing state-of-the-art\napproaches. The numerical simulation results show that the proposed approach\noutperforms these approaches in aspects of the average traveling distance and\nthe energy cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.01891v2"
    },
    {
        "title": "The Application of Market-based Multi-Robot Task Allocation to Ambulance\n  Dispatch",
        "authors": [
            "Eric Schneider",
            "Marcus Poulton",
            "Archie Drake",
            "Leanne Smith",
            "George Roussos",
            "Simon Parsons",
            "Elizabeth I Sklar"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Multi-Robot Task Allocation (MRTA) is the problem of distributing a set of\ntasks to a team of robots with the objective of optimising some criteria, such\nas minimising the amount of time or energy spent to complete all the tasks or\nmaximising the efficiency of the team's joint activity. The exploration of MRTA\nmethods is typically restricted to laboratory and field experimentation. There\nare few existing real-world models in which teams of autonomous mobile robots\nare deployed \"in the wild\", e.g., in industrial settings. In the work presented\nhere, a market-based MRTA approach is applied to the problem of ambulance\ndispatch, where ambulances are allocated in respond to patients' calls for\nhelp. Ambulances and robots are limited (and perhaps scarce), specialised\nmobile resources; incidents and tasks represent time-sensitive, specific,\npotentially unlimited, precisely-located demands for the services which the\nresources provide. Historical data from the London Ambulance Service describing\na set of more than 1 million (anonymised) incidents are used as the basis for\nevaluating the predicted performance of the market-based approach versus the\ncurrent, largely manual, method of allocating ambulances to incidents.\nExperimental results show statistically significant improvement in response\ntimes when using the market-based approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.05550v1"
    },
    {
        "title": "Driver Modeling through Deep Reinforcement Learning and Behavioral Game\n  Theory",
        "authors": [
            "Berat Mert Albaba",
            "Yildiray Yildiz"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, a synergistic combination of deep reinforcement learning and\nhierarchical game theory is proposed as a modeling framework for behavioral\npredictions of drivers in highway driving scenarios. The need for a modeling\nframework that can address multiple human-human and human-automation\ninteractions, where all the agents can be modeled as decision makers\nsimultaneously, is the main motivation behind this work. Such a modeling\nframework may be utilized for the validation and verification of autonomous\nvehicles: It is estimated that for an autonomous vehicle to reach the same\nsafety level of cars with drivers, millions of miles of driving tests are\nrequired. The modeling framework presented in this paper may be used in a\nhigh-fidelity traffic simulator consisting of multiple human decision makers to\nreduce the time and effort spent for testing by allowing safe and quick\nassessment of self-driving algorithms. To demonstrate the fidelity of the\nproposed modeling framework, game theoretical driver models are compared with\nreal human driver behavior patterns extracted from traffic data.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.11071v1"
    },
    {
        "title": "Norms and Sanctions as a Basis for Promoting Cybersecurity Practices",
        "authors": [
            "Nirav Ajmeri",
            "Shubham Goyal",
            "Munindar P. Singh"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Many cybersecurity breaches occur due to users not following good\ncybersecurity practices, chief among them being regulations for applying\nsoftware patches to operating systems, updating applications, and maintaining\nstrong passwords.\n  We capture cybersecurity expectations on users as norms. We empirically\ninvestigate sanctioning mechanisms in promoting compliance with those norms as\nwell as the detrimental effect of sanctions on the ability of users to complete\ntheir work. We realize these ideas in a game that emulates the decision making\nof workers in a research lab.\n  Through a human-subject study, we find that whereas individual sanctions are\nmore effective than group sanctions in achieving compliance and less\ndetrimental on the ability of users to complete their work, individual\nsanctions offer significantly lower resilience especially for organizations\ncomprising risk seekers. Our findings have implications for workforce training\nin cybersecurity.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.11170v1"
    },
    {
        "title": "Anytime and Efficient Coalition Formation with Spatial and Temporal\n  Constraints",
        "authors": [
            "Luca Capezzuto",
            "Danesh Tarapore",
            "Sarvapali D. Ramchurn"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP)\nis a multi-agent task scheduling problem where the tasks are spatially\ndistributed, with deadlines and workloads, and the number of agents is\ntypically much smaller than the number of tasks, thus the agents have to form\ncoalitions in order to maximise the number of completed tasks. The current\nstate-of-the-art CFSTP solver, the Coalition Formation with Look-Ahead (CFLA)\nalgorithm, has two main limitations. First, its time complexity is exponential\nwith the number of agents. Second, as we show, its look-ahead technique is not\neffective in real-world scenarios, such as open multi-agent systems, where new\ntasks can appear at any time. In this work, we study its design and define an\nextension, called Coalition Formation with Improved Look-Ahead (CFLA2), which\nachieves better performance. Since we cannot eliminate the limitations of CFLA\nin CFLA2, we also develop a novel algorithm to solve the CFSTP, the first to be\nanytime, efficient and with provable guarantees, called Cluster-based Coalition\nFormation (CCF). We empirically show that, in settings where the look-ahead\ntechnique is highly effective, CCF completes up to 30% (resp. 10%) more tasks\nthan CFLA (resp. CFLA2) while being up to four orders of magnitude faster. Our\nresults affirm CCF as the new state-of-the-art algorithm to solve the CFSTP.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.13806v3"
    },
    {
        "title": "A Norm Emergence Framework for Normative MAS -- Position Paper",
        "authors": [
            "Andreasa Morris-Martin",
            "Marina De Vos",
            "Julian Padget"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Norm emergence is typically studied in the context of multiagent systems\n(MAS) where norms are implicit, and participating agents use simplistic\ndecision-making mechanisms. These implicit norms are usually unconsciously\nshared and adopted through agent interaction. A norm is deemed to have emerged\nwhen a threshold or predetermined percentage of agents follow the \"norm\".\nConversely, in normative MAS, norms are typically explicit and agents\ndeliberately share norms through communication or are informed about norms by\nan authority, following which an agent decides whether to adopt the norm or\nnot. The decision to adopt a norm by the agent can happen immediately after\nrecognition or when an applicable situation arises. In this paper, we make the\ncase that, similarly, a norm has emerged in a normative MAS when a percentage\nof agents adopt the norm. Furthermore, we posit that agents themselves can and\nshould be involved in norm synthesis, and hence influence the norms governing\nthe MAS, in line with Ostrom's eight principles. Consequently, we put forward a\nframework for the emergence of norms within a normative MAS, that allows\nparticipating agents to propose/request changes to the normative system, while\nspecial-purpose synthesizer agents formulate new norms or revisions in response\nto these requests. Synthesizers must collectively agree that the new norm or\nnorm revision should proceed, and then finally be approved by an \"Oracle\". The\nnormative system is then modified to incorporate the norm.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.02575v1"
    },
    {
        "title": "Networked Multi-Agent Reinforcement Learning with Emergent Communication",
        "authors": [
            "Shubham Gupta",
            "Rishi Hazra",
            "Ambedkar Dukkipati"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) methods find optimal policies for\nagents that operate in the presence of other learning agents. Central to\nachieving this is how the agents coordinate. One way to coordinate is by\nlearning to communicate with each other. Can the agents develop a language\nwhile learning to perform a common task? In this paper, we formulate and study\na MARL problem where cooperative agents are connected to each other via a fixed\nunderlying network. These agents can communicate along the edges of this\nnetwork by exchanging discrete symbols. However, the semantics of these symbols\nare not predefined and, during training, the agents are required to develop a\nlanguage that helps them in accomplishing their goals. We propose a method for\ntraining these agents using emergent communication. We demonstrate the\napplicability of the proposed framework by applying it to the problem of\nmanaging traffic controllers, where we achieve state-of-the-art performance as\ncompared to a number of strong baselines. More importantly, we perform a\ndetailed analysis of the emergent communication to show, for instance, that the\ndeveloped language is grounded and demonstrate its relationship with the\nunderlying network topology. To the best of our knowledge, this is the only\nwork that performs an in depth analysis of emergent communication in a\nnetworked MARL setting while being applicable to a broad class of problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.02780v2"
    },
    {
        "title": "Fundamental Performance Limitations for Average Consensus in Open\n  Multi-Agent Systems",
        "authors": [
            "Charles Monnoyer de Galland",
            "Julien M. Hendrickx"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We derive fundamental performance limitations for intrinsic average consensus\nproblems in open multi-agent systems, which are systems subject to frequent\narrivals and departures of agents. Each agent holds a value, and the objective\nof the agents is to collaboratively estimate the average of the values of the\nagents presently in the system. Algorithms solving such problems in open\nsystems are poised to never converge because of the permanent variations in the\ncomposition, size and objective pursued by the agents of the system. We provide\nlower bounds on the expected Mean Squared Error achievable by any averaging\nalgorithms in open systems of fixed size. Our derivation is based on the\nanalysis of a conceptual algorithm that would achieve optimal performance for a\ngiven model of replacements. We obtain a general bound that depends on the\nproperties of the model defining the interactions between the agents, and\ninstantiate that result for all-to-one and one-to-one interaction models. A\ncomparison between those bounds and algorithms implementable with those models\nis then provided to highlight their validity.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.06533v4"
    },
    {
        "title": "Cyber-Physical Mobility Lab: An Open-Source Platform for Networked and\n  Autonomous Vehicles",
        "authors": [
            "Maximilian Kloock",
            "Patrick Scheffe",
            "Janis Maczijewski",
            "Alexandru Kampmann",
            "Armin Mokhtarian",
            "Stefan Kowalewski",
            "Bassam Alrifaee"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper introduces our Cyber-Physical Mobility Lab (CPM Lab). It is an\nopen-source development environment for networked and autonomous vehicles with\nfocus on networked decision-making, trajectory planning, and control. The CPM\nLab hosts 20 physical model-scale vehicles ({\\mu}Cars) which we can seamlessly\nextend by unlimited simulated vehicles. The code and construction plans are\npublicly available to enable rebuilding the CPM Lab.\n  Our four-layered architecture enables the seamless use of the same software\nin simulations and in experiments without any further adaptions. A Data\nDistribution Service (DDS) based middleware allows adapting the number of\nvehicles during experiments in a seamless manner. The middleware is also\nresponsible for synchronizing all entities following a logical execution time\napproach to achieve determinism and reproducibility of experiments. This\napproach makes the CPM Lab a unique platform for rapid functional prototyping\nof networked decision-making algorithms.\n  The CPM Lab allows researchers as well as students from different disciplines\nto see their ideas developing into reality. We demonstrate its capabilities\nusing two example experiments. We are working on a remote access to the CPM Lab\nvia a webinterface.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.10063v4"
    },
    {
        "title": "Inferring Degrees from Incomplete Networks and Nonlinear Dynamics",
        "authors": [
            "Chunheng Jiang",
            "Jianxi Gao",
            "Malik Magdon-Ismail"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Inferring topological characteristics of complex networks from observed data\nis critical to understand the dynamical behavior of networked systems, ranging\nfrom the Internet and the World Wide Web to biological networks and social\nnetworks. Prior studies usually focus on the structure-based estimation to\ninfer network sizes, degree distributions, average degrees, and more. Little\neffort attempted to estimate the specific degree of each vertex from a sampled\ninduced graph, which prevents us from measuring the lethality of nodes in\nprotein networks and influencers in social networks. The current approaches\ndramatically fail for a tiny sampled induced graph and require a specific\nsampling method and a large sample size. These approaches neglect information\nof the vertex state, representing the dynamical behavior of the networked\nsystem, such as the biomass of species or expression of a gene, which is useful\nfor degree estimation. We fill this gap by developing a framework to infer\nindividual vertex degrees using both information of the sampled topology and\nvertex state. We combine the mean-field theory with combinatorial optimization\nto learn vertex degrees. Experimental results on real networks with a variety\nof dynamics demonstrate that our framework can produce reliable degree\nestimates and dramatically improve existing link prediction methods by\nreplacing the sampled degrees with our estimated degrees.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.10546v2"
    },
    {
        "title": "Information and Causality in Promise Theory",
        "authors": [
            "Mark Burgess"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The explicit link between Promise Theory and Information Theory, while\nperhaps obvious, is laid out explicitly here. It's shown how causally related\nobservations of promised behaviours relate to the probabilistic formulation of\ncausal information in Shannon's theory, and thus clarify the meaning of\nautonomy or causal independence, and further the connection between information\nand causal sets. Promise Theory helps to make clear a number of assumptions\nwhich are commonly taken for granted in causal descriptions. The concept of a\npromise is hard to escape. It serves as proxy for intent, whether a priori or\nby inference, and it is intrinsic to the interpretations of observations in the\nlatter.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.12661v1"
    },
    {
        "title": "Social rules for agent systems",
        "authors": [
            "René Mellema",
            "Maarten Jensen",
            "Frank Dignum"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  When creating (open) agent systems it has become common practice to use\nsocial concepts such as social practices, norms and conventions to model the\nway the interactions between the agents are regulated. However, in the\nliterature most papers concentrate on only one of these aspects at the time.\nTherefore there is hardly any research on how these social concepts relate and\nwhen each of them emerges or evolves from another concept. In this paper we\nwill investigate some of the relations between these concepts and also whether\nthey are fundamentally stemming from a single social object or should be seen\nas different types of objects altogether.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.12797v2"
    },
    {
        "title": "Social distancing with the Optimal Steps Model",
        "authors": [
            "Christina Maria Mayr",
            "Gerta Köster"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  With the Covid-19 pandemic an urgent need to simulate social distancing\narises. The Optimal Steps Model (OSM) is a pedestrian locomotion model that\noperationalizes an individual's need for personal space. We present new\nparameter values for personal space in the Optimal Steps Model to simulate\nsocial distancing in the pedestrian dynamics simulator Vadere. Our approach is\npragmatic. We consider two use cases: in the first we demand that a set social\ndistance must never be violated. In the second the social distance must be kept\nonly on average. For each use case we conduct simulation studies in a typical\nbottleneck scenario and measure contact times, that is, violations of the\nsocial distance rule. We derive rules of thumb for suitable parameter choices\nin dependency of the desired social distance. We test the rules of thumb for\nthe social distances 1.5m and 2.0m and observe that the new parameter values\nindeed lead to the desired social distancing. Thus, the rules of thumb will\nquickly enable Vadere users to conduct their own studies without understanding\nthe intricacies of the OSM implementation and without extensive parameter\nadjustment.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.01634v2"
    },
    {
        "title": "Reward Machines for Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Cyrus Neary",
            "Zhe Xu",
            "Bo Wu",
            "Ufuk Topcu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In cooperative multi-agent reinforcement learning, a collection of agents\nlearns to interact in a shared environment to achieve a common goal. We propose\nthe use of reward machines (RM) -- Mealy machines used as structured\nrepresentations of reward functions -- to encode the team's task. The proposed\nnovel interpretation of RMs in the multi-agent setting explicitly encodes\nrequired teammate interdependencies, allowing the team-level task to be\ndecomposed into sub-tasks for individual agents. We define such a notion of RM\ndecomposition and present algorithmically verifiable conditions guaranteeing\nthat distributed completion of the sub-tasks leads to team behavior\naccomplishing the original task. This framework for task decomposition provides\na natural approach to decentralized learning: agents may learn to accomplish\ntheir sub-tasks while observing only their local state and abstracted\nrepresentations of their teammates. We accordingly propose a decentralized\nq-learning algorithm. Furthermore, in the case of undiscounted rewards, we use\nlocal value functions to derive lower and upper bounds for the global value\nfunction corresponding to the team task. Experimental results in three discrete\nsettings exemplify the effectiveness of the proposed RM decomposition approach,\nwhich converges to a successful team policy an order of magnitude faster than a\ncentralized learner and significantly outperforms hierarchical and independent\nq-learning approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.01962v2"
    },
    {
        "title": "Agent-Based Modelling: An Overview with Application to Disease Dynamics",
        "authors": [
            "Affan Shoukat",
            "Seyed M. Moghadas"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Modelling and computational methods have been essential in advancing\nquantitative science, especially in the past two decades with the availability\nof vast amount of complex, voluminous, and heterogeneous data. In particular,\nthere has been a surge of interest in agent-based modelling, largely due to its\ncapabilities to exploit such data and make significant projections. However,\nany well-established quantitative method relies on theoretical frameworks for\nboth construction and analysis. While the computational aspects of agent-based\nmodelling have been detailed in existing literature, the underlying theoretical\nbasis has rarely been used in its construction. In this exposition, we provide\nan overview of the theoretical foundation of agent-based modelling and\nestablish a relationship with its computational implementation. In addition to\ndetailing the main characteristics of this computational methodology, we\nillustrate its application to simulating the spread of an infectious disease in\na simple, dynamical process. As the use of agent-based models expands to\nvarious disciplines, our review highlights the need for directed research\nefforts to develop theoretical methods and analytical tools for the analysis of\nsuch models.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.04192v1"
    },
    {
        "title": "Urban Mobility Swarms: A Scalable Implementation",
        "authors": [
            "Alex Berke",
            "Jason Nawyn",
            "Thomas Sanchez Lengeling",
            "Kent Larson"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We present a system to coordinate 'urban mobility swarms' in order to promote\nthe use and safety of lightweight, sustainable transit, while enhancing the\nvibrancy and community fabric of cities. This work draws from behavior\nexhibited by swarms of nocturnal insects, such as crickets and fireflies,\nwhereby synchrony unifies individuals in a decentralized network. Coordination\nnaturally emerges in these cases and provides a compelling demonstration of\n'strength in numbers'. Our work is applied to coordinating lightweight\nvehicles, such as bicycles, which are automatically inducted into ad-hoc\n'swarms', united by the synchronous pulsation of light. We model individual\nriders as nodes in a decentralized network and synchronize their behavior via a\npeer-to-peer message protocol and algorithm, which preserves individual\nprivacy. Nodes broadcast over radio with a transmission range tuned to localize\nswarm membership. Nodes then join or disconnect from others based on proximity,\naccommodating the dynamically changing topology of urban mobility networks.\nThis paper provides a technical description of our system, including the\nprotocol and algorithm to coordinate the swarming behavior that emerges from\nit. We also demonstrate its implementation in code, circuity, and hardware,\nwith a system prototype tested on a city bike-share. In doing so, we evince the\nscalability of our system. Our prototype uses low-cost components, and\nbike-share programs, which manage bicycle fleets distributed across cities,\ncould deploy the system at city-scale. Our flexible, decentralized design\nallows additional bikes to then connect with the network, enhancing its scale\nand impact.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.06653v1"
    },
    {
        "title": "Active Deception using Factored Interactive POMDPs to Recognize Cyber\n  Attacker's Intent",
        "authors": [
            "Aditya Shinde",
            "Prashant Doshi",
            "Omid Setayeshfar"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper presents an intelligent and adaptive agent that employs deception\nto recognize a cyber adversary's intent. Unlike previous approaches to cyber\ndeception, which mainly focus on delaying or confusing the attackers, we focus\non engaging with them to learn their intent. We model cyber deception as a\nsequential decision-making problem in a two-agent context. We introduce\nfactored finitely nested interactive POMDPs (I-POMDPx) and use this framework\nto model the problem with multiple attacker types. Our approach models cyber\nattacks on a single honeypot host across multiple phases from the attacker's\ninitial entry to reaching its adversarial objective. The defending\nI-POMDPx-based agent uses decoys to engage with the attacker at multiple phases\nto form increasingly accurate predictions of the attacker's behavior and\nintent. The use of I-POMDPs also enables us to model the adversary's mental\nstate and investigate how deception affects their beliefs. Our experiments in\nboth simulation and on a real host show that the I-POMDPx-based agent performs\nsignificantly better at intent recognition than commonly used deception\nstrategies on honeypots.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.09512v1"
    },
    {
        "title": "Design and Analysis of a Multi-Agent E-Learning System Using Prometheus\n  Design Tool",
        "authors": [
            "Kennedy E. Ehimwenma",
            "Sujatha Krishnamoorthy"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Agent unified modeling languages (AUML) are agent-oriented approaches that\nsupports the specification, design, visualization and documentation of an\nagent-based system. This paper presents the use of Prometheus AUML approach for\nthe modeling of a Pre-assessment System of five interactive agents. The\nPre-assessment System, as previously reported, is a multi-agent based\ne-learning system that is developed to support the assessment of prior learning\nskills in students so as to classify their skills and make recommendation for\ntheir learning. This paper discusses the detailed design approach of the system\nin a step-by-step manner; and domain knowledge abstraction and organization in\nthe system. In addition, the analysis of the data collated and models of\nprediction for future pre-assessment results are also presented.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.09645v3"
    },
    {
        "title": "Adaptive Workload Allocation for Multi-human Multi-robot Teams for\n  Independent and Homogeneous Tasks",
        "authors": [
            "Tamzidul Mina",
            "Shyam Sundar Kannan",
            "Wonse Jo",
            "Byung-Cheol Min"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Multi-human multi-robot (MH-MR) systems have the ability to combine the\npotential advantages of robotic systems with those of having humans in the\nloop. Robotic systems contribute precision performance and long operation on\nrepetitive tasks without tiring, while humans in the loop improve situational\nawareness and enhance decision-making abilities. A system's ability to adapt\nallocated workload to changing conditions and the performance of each\nindividual (human and robot) during the mission is vital to maintaining overall\nsystem performance. Previous works from literature including market-based and\noptimization approaches have attempted to address the task/workload allocation\nproblem with focus on maximizing the system output without regarding individual\nagent conditions, lacking in real-time processing and have mostly focused\nexclusively on multi-robot systems. Given the variety of possible combination\nof teams (autonomous robots and human-operated robots: any number of human\noperators operating any number of robots at a time) and the operational scale\nof MH-MR systems, development of a generalized framework of workload allocation\nhas been a particularly challenging task. In this paper, we present such a\nframework for independent homogeneous missions, capable of adaptively\nallocating the system workload in relation to health conditions and work\nperformances of human-operated and autonomous robots in real-time. The\nframework consists of removable modular function blocks ensuring its\napplicability to different MH-MR scenarios. A new workload transition function\nblock ensures smooth transition without the workload change having adverse\neffects on individual agents. The effectiveness and scalability of the system's\nworkload adaptability is validated by experiments applying the proposed\nframework in a MH-MR patrolling scenario with changing human and robot\ncondition, and failing robots.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.13897v1"
    },
    {
        "title": "Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment\n  Mapping",
        "authors": [
            "Ceyer Wakilpoor",
            "Patrick J. Martin",
            "Carrie Rebhuhn",
            "Amanda Vu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Reinforcement learning in heterogeneous multi-agent scenarios is important\nfor real-world applications but presents challenges beyond those seen in\nhomogeneous settings and simple benchmarks. In this work, we present an\nactor-critic algorithm that allows a team of heterogeneous agents to learn\ndecentralized control policies for covering an unknown environment. This task\nis of interest to national security and emergency response organizations that\nwould like to enhance situational awareness in hazardous areas by deploying\nteams of unmanned aerial vehicles. To solve this multi-agent coverage path\nplanning problem in unknown environments, we augment a multi-agent actor-critic\narchitecture with a new state encoding structure and triplet learning loss to\nsupport heterogeneous agent learning. We developed a simulation environment\nthat includes real-world environmental factors such as turbulence, delayed\ncommunication, and agent loss, to train teams of agents as well as probe their\nrobustness and flexibility to such disturbances.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.02663v1"
    },
    {
        "title": "A Particle Swarm Inspired Approach for Continuous Distributed Constraint\n  Optimization Problems",
        "authors": [
            "Moumita Choudhury",
            "Amit Sarker",
            "Md. Mosaddek Khan",
            "William Yeoh"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Distributed Constraint Optimization Problems (DCOPs) are a widely studied\nframework for coordinating interactions in cooperative multi-agent systems. In\nclassical DCOPs, variables owned by agents are assumed to be discrete. However,\nin many applications, such as target tracking or sleep scheduling in sensor\nnetworks, continuous-valued variables are more suitable than discrete ones. To\nbetter model such applications, researchers have proposed Continuous DCOPs\n(C-DCOPs), an extension of DCOPs, that can explicitly model problems with\ncontinuous variables. The state-of-the-art approaches for solving C-DCOPs\nexperience either onerous memory or computation overhead and unsuitable for\nnon-differentiable optimization problems. To address this issue, we propose a\nnew C-DCOP algorithm, namely Particle Swarm Optimization Based C-DCOP (PCD),\nwhich is inspired by Particle Swarm Optimization (PSO), a well-known\ncentralized population-based approach for solving continuous optimization\nproblems. In recent years, population-based algorithms have gained significant\nattention in classical DCOPs due to their ability in producing high-quality\nsolutions. Nonetheless, to the best of our knowledge, this class of algorithms\nhas not been utilized to solve C-DCOPs and there has been no work evaluating\nthe potential of PSO in solving classical DCOPs or C-DCOPs. In light of this\nobservation, we adapted PSO, a centralized algorithm, to solve C-DCOPs in a\ndecentralized manner. The resulting PCD algorithm not only produces\ngood-quality solutions but also finds solutions without any requirement for\nderivative calculations. Moreover, we design a crossover operator that can be\nused by PCD to further improve the quality of solutions found. Finally, we\ntheoretically prove that PCD is an anytime algorithm and empirically evaluate\nPCD against the state-of-the-art C-DCOP algorithms in a wide variety of\nbenchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.10192v1"
    },
    {
        "title": "A Decentralised Self-Healing Approach for Network Topology Maintenance",
        "authors": [
            "Arles Rodríguez",
            "Jonatan Gómez",
            "Ada Diaconescu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In many distributed systems, from cloud to sensor networks, different\nconfigurations impact system performance, while strongly depending on the\nnetwork topology. Hence, topological changes may entail costly reconfiguration\nand optimisation processes. This paper proposes a multi-agent solution for\nrecovering networks from node failures. To preserve the network topology, the\nproposed approach relies on local information about the network's structure,\nwhich is collected and disseminated at runtime. The paper studies two\nstrategies for distributing topological data: one based on Mobile Agents (our\nproposal) and the other based on Trickle (a reference gossiping protocol from\nthe literature). These two strategies were adapted for our self-healing\napproach to collect topological information for recovering the network; and\nwere evaluated in terms of resource overheads. Experimental results show that\nboth variants can recover the network topology, up to a certain node failure\nrate, which depends on the network topology. At the same time, Mobile Agents\ncollect less information, focusing on local dissemination, which suffices for\nnetwork recovery. This entails less bandwidth overheads than when Trickle is\nused. Still, Mobile Agents utilise more memory and exchange more messages,\nduring data-collection, than Trickle does. These results validate the viability\nof the proposed self-healing solution, offering two variant implementations\nwith diverse performance characteristics, which may suit different application\ndomains.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.11146v1"
    },
    {
        "title": "Towards human-agent knowledge fusion (HAKF) in support of distributed\n  coalition teams",
        "authors": [
            "Dave Braines",
            "Federico Cerutti",
            "Marc Roig Vilamala",
            "Mani Srivastava",
            "Lance Kaplan Alun Preece",
            "Gavin Pearson"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Future coalition operations can be substantially augmented through agile\nteaming between human and machine agents, but in a coalition context these\nagents may be unfamiliar to the human users and expected to operate in a broad\nset of scenarios rather than being narrowly defined for particular purposes. In\nsuch a setting it is essential that the human agents can rapidly build trust in\nthe machine agents through appropriate transparency of their behaviour, e.g.,\nthrough explanations. The human agents are also able to bring their local\nknowledge to the team, observing the situation unfolding and deciding which key\ninformation should be communicated to the machine agents to enable them to\nbetter account for the particular environment. In this paper we describe the\ninitial steps towards this human-agent knowledge fusion (HAKF) environment\nthrough a recap of the key requirements, and an explanation of how these can be\nfulfilled for an example situation. We show how HAKF has the potential to bring\nvalue to both human and machine agents working as part of a distributed\ncoalition team in a complex event processing setting with uncertain sources.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.12327v1"
    },
    {
        "title": "Optimizing Multi-UAV Deployment in 3D Space to Minimize Task Completion\n  Time in UAV-Enabled Mobile Edge Computing Systems",
        "authors": [
            "Sujunjie Sun",
            "Guopeng Zhang",
            "Haibo Mei",
            "Kezhi Wang",
            "Kun Yang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In Unmanned Aerial Vehicle (UAV)-enabled mobile edge computing (MEC) systems,\nUAVs can carry edge servers to help ground user equipment (UEs) offloading\ntheir computing tasks to the UAVs for execution. This paper aims to minimize\nthe total time required for the UAVs to complete the offloaded tasks, while\noptimizing the three-dimensional (3D) deployment of UAVs, including their\nflying height and horizontal positions. Although the formulated optimization is\na mixed integer nonlinear programmming, we convert it to a convex problem and\ndevelop a successive convex approximation (SCA) based algorithm to effectively\nsolve it. The simulation results show that the joint optimization of the\nhorizontal and the vertical position of a group of UAVs can achieve better\nperformance than the traditional algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.12894v1"
    },
    {
        "title": "Exploring Zero-Shot Emergent Communication in Embodied Multi-Agent\n  Populations",
        "authors": [
            "Kalesha Bullard",
            "Franziska Meier",
            "Douwe Kiela",
            "Joelle Pineau",
            "Jakob Foerster"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Effective communication is an important skill for enabling information\nexchange and cooperation in multi-agent settings. Indeed, emergent\ncommunication is now a vibrant field of research, with common settings\ninvolving discrete cheap-talk channels. One limitation of this setting is that\nit does not allow for the emergent protocols to generalize beyond the training\npartners. Furthermore, so far emergent communication has primarily focused on\nthe use of symbolic channels. In this work, we extend this line of work to a\nnew modality, by studying agents that learn to communicate via actuating their\njoints in a 3D environment. We show that under realistic assumptions, a\nnon-uniform distribution of intents and a common-knowledge energy cost, these\nagents can find protocols that generalize to novel partners. We also explore\nand analyze specific difficulties associated with finding these solutions in\npractice. Finally, we propose and evaluate initial training improvements to\naddress these challenges, involving both specific training curricula and\nproviding the latent feature that can be coordinated on during training.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.15896v2"
    },
    {
        "title": "An Overview of Multi-Agent Reinforcement Learning from Game Theoretical\n  Perspective",
        "authors": [
            "Yaodong Yang",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Following the remarkable success of the AlphaGO series, 2019 was a booming\nyear that witnessed significant advances in multi-agent reinforcement learning\n(MARL) techniques. MARL corresponds to the learning problem in a multi-agent\nsystem in which multiple agents learn simultaneously. It is an\ninterdisciplinary domain with a long history that includes game theory, machine\nlearning, stochastic control, psychology, and optimisation. Although MARL has\nachieved considerable empirical success in solving real-world games, there is a\nlack of a self-contained overview in the literature that elaborates the game\ntheoretical foundations of modern MARL methods and summarises the recent\nadvances. In fact, the majority of existing surveys are outdated and do not\nfully cover the recent developments since 2010. In this work, we provide a\nmonograph on MARL that covers both the fundamentals and the latest developments\nin the research frontier. The goal of our monograph is to provide a\nself-contained assessment of the current state-of-the-art MARL techniques from\na game theoretical perspective. We expect this work to serve as a stepping\nstone for both new researchers who are about to enter this fast-growing domain\nand existing domain experts who want to obtain a panoramic view and identify\nnew directions based on recent advances.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.00583v3"
    },
    {
        "title": "The Persistence of False Memory: Brain in a Vat Despite Perfect Clocks",
        "authors": [
            "Thomas Schlögl",
            "Ulrich Schmid",
            "Roman Kuznets"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Recently, a detailed epistemic reasoning framework for multi-agent systems\nwith byzantine faulty asynchronous agents and possibly unreliable communication\nwas introduced. We have developed a modular extension framework implemented on\ntop of it, which allows to encode and safely combine additional system\nassumptions commonly used in the modeling and analysis of fault-tolerant\ndistributed systems, like reliable communication, time-bounded communication,\nmulticasting, synchronous and lock-step synchronous agents and even agents with\ncoordinated actions. We use this extension framework for analyzing basic\nproperties of synchronous and lock-step synchronous agents, such as the agents'\nlocal and global fault detection abilities. Moreover, we show that even the\nperfectly synchronized clocks available in lock-step synchronous systems cannot\nbe used to avoid \"brain-in-a-vat\" scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.01057v1"
    },
    {
        "title": "Social Choice with Changing Preferences: Representation Theorems and\n  Long-Run Policies",
        "authors": [
            "Kshitij Kulkarni",
            "Sven Neth"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We study group decision making with changing preferences as a Markov Decision\nProcess. We are motivated by the increasing prevalence of automated\ndecision-making systems when making choices for groups of people over time. Our\nmain contribution is to show how classic representation theorems from social\nchoice theory can be adapted to characterize optimal policies in this dynamic\nsetting. We provide an axiomatic characterization of MDP reward functions that\nagree with the Utilitarianism social welfare functionals of social choice\ntheory. We also provide discussion of cases when the implementation of social\nchoice-theoretic axioms may fail to lead to long-run optimal outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.02544v1"
    },
    {
        "title": "Scalable Reinforcement Learning Policies for Multi-Agent Control",
        "authors": [
            "Christopher D. Hsu",
            "Heejin Jeong",
            "George J. Pappas",
            "Pratik Chaudhari"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We develop a Multi-Agent Reinforcement Learning (MARL) method to learn\nscalable control policies for target tracking. Our method can handle an\narbitrary number of pursuers and targets; we show results for tasks consisting\nup to 1000 pursuers tracking 1000 targets. We use a decentralized,\npartially-observable Markov Decision Process framework to model pursuers as\nagents receiving partial observations (range and bearing) about targets which\nmove using fixed, unknown policies. An attention mechanism is used to\nparameterize the value function of the agents; this mechanism allows us to\nhandle an arbitrary number of targets. Entropy-regularized off-policy RL\nmethods are used to train a stochastic policy, and we discuss how it enables a\nhedging behavior between pursuers that leads to a weak form of cooperation in\nspite of completely decentralized control execution. We further develop a\nmasking heuristic that allows training on smaller problems with few\npursuers-targets and execution on much larger problems. Thorough simulation\nexperiments, ablation studies, and comparisons to state of the art algorithms\nare performed to study the scalability of the approach and robustness of\nperformance to varying numbers of agents and targets.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.08055v4"
    },
    {
        "title": "MaaSSim -- agent-based two-sided mobility platform simulator",
        "authors": [
            "Rafał Kucharski",
            "Oded Cats"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Two-sided mobility platforms, such as Uber and Lyft, widely emerged in the\nurban mobility landscape, bringing disruptive changes to transportation systems\nworldwide. This calls for a simulation framework where researchers from various\nand across disciplines may introduce models aimed at representing the dynamics\nof platform-driven urban mobility systems. In this work, we present MaaSSim, an\nagent-based simulator reproducing the transport system used by two kind of\nagents: (i) travellers, requesting to travel from their origin to destination\nat a given time, and (ii) drivers supplying their travel needs by offering them\nrides. An intermediate agent, the platform, allows demand to be matched with\nsupply. Agents are decision makers, specifically, travellers may decide which\nmode they use or reject an incoming offer. Similarly, drivers may opt-out from\nthe system or reject incoming requests. All of the above behaviours are\nmodelled through user-defined modules, representing agents' taste variations\n(heterogeneity), their previous experiences (learning) and available\ninformation (system control). MaaSSim is an open-source library available at a\npublic repository github.com/RafalKucharskiPK/MaaSSim, along with a set of\ntutorials and reproducible use-case scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.12827v1"
    },
    {
        "title": "Estimating $α$-Rank by Maximizing Information Gain",
        "authors": [
            "Tabish Rashid",
            "Cheng Zhang",
            "Kamil Ciosek"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Game theory has been increasingly applied in settings where the game is not\nknown outright, but has to be estimated by sampling. For example, meta-games\nthat arise in multi-agent evaluation can only be accessed by running a\nsuccession of expensive experiments that may involve simultaneous deployment of\nseveral agents. In this paper, we focus on $\\alpha$-rank, a popular\ngame-theoretic solution concept designed to perform well in such scenarios. We\naim to estimate the $\\alpha$-rank of the game using as few samples as possible.\nOur algorithm maximizes information gain between an epistemic belief over the\n$\\alpha$-ranks and the observed payoff. This approach has two main benefits.\nFirst, it allows us to focus our sampling on the entries that matter the most\nfor identifying the $\\alpha$-rank. Second, the Bayesian formulation provides a\nfacility to build in modeling assumptions by using a prior over game payoffs.\nWe show the benefits of using information gain as compared to the confidence\ninterval criterion of ResponseGraphUCB (Rowland et al. 2019), and provide\ntheoretical results justifying our method.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.09178v1"
    },
    {
        "title": "Agents.jl: A performant and feature-full agent based modelling software\n  of minimal code complexity",
        "authors": [
            "George Datseris",
            "Ali R. Vahdati",
            "Timothy C. DuBois"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Agent based modelling is a simulation method in which autonomous agents\ninteract with their environment and one another, given a predefined set of\nrules. It is an integral method for modelling and simulating complex systems,\nsuch as socio-economic problems. Since agent based models are not described by\nsimple and concise mathematical equations, code that generates them is\ntypically complicated, large, and slow. Here we present Agents.jl, a\nJulia-based software that provides an ABM analysis platform with minimal code\ncomplexity. We compare our software with some of the most popular ABM software\nin other programming languages. We find that Agents.jl is not only the most\nperformant, but also the least complicated software, providing the same (and\nsometimes more) features as the competitors with less input required from the\nuser. Agents.jl also integrates excellently with the entire Julia ecosystem,\nincluding interactive applications, differential equations, parameter\noptimization, and more. This removes any ``extensions library'' requirement\nfrom Agents.jl, which is paramount in many other tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.10072v3"
    },
    {
        "title": "Accumulating Risk Capital Through Investing in Cooperation",
        "authors": [
            "Charlotte Roman",
            "Michael Dennis",
            "Andrew Critch",
            "Stuart Russell"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Recent work on promoting cooperation in multi-agent learning has resulted in\nmany methods which successfully promote cooperation at the cost of becoming\nmore vulnerable to exploitation by malicious actors. We show that this is an\nunavoidable trade-off and propose an objective which balances these concerns,\npromoting both safety and long-term cooperation. Moreover, the trade-off\nbetween safety and cooperation is not severe, and you can receive exponentially\nlarge returns through cooperation from a small amount of risk. We study both an\nexact solution method and propose a method for training policies that targets\nthis objective, Accumulating Risk Capital Through Investing in Cooperation\n(ARCTIC), and evaluate them in iterated Prisoner's Dilemma and Stag Hunt.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.10305v2"
    },
    {
        "title": "Exploring the Impact of Tunable Agents in Sequential Social Dilemmas",
        "authors": [
            "David O'Callaghan",
            "Patrick Mannion"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  When developing reinforcement learning agents, the standard approach is to\ntrain an agent to converge to a fixed policy that is as close to optimal as\npossible for a single fixed reward function. If different agent behaviour is\nrequired in the future, an agent trained in this way must normally be either\nfully or partially retrained, wasting valuable time and resources. In this\nstudy, we leverage multi-objective reinforcement learning to create tunable\nagents, i.e. agents that can adopt a range of different behaviours according to\nthe designer's preferences, without the need for retraining. We apply this\ntechnique to sequential social dilemmas, settings where there is inherent\ntension between individual and collective rationality. Learning a single fixed\npolicy in such settings leaves one at a significant disadvantage if the\nopponents' strategies change after learning is complete. In our work, we\ndemonstrate empirically that the tunable agents framework allows easy adaption\nbetween cooperative and competitive behaviours in sequential social dilemmas\nwithout the need for retraining, allowing a single trained agent model to be\nadjusted to cater for a wide range of behaviours and opponent strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.11967v1"
    },
    {
        "title": "City-scale Simulation of Covid-19 Pandemic and Intervention Policies\n  using Agent-based Modelling",
        "authors": [
            "Gaurav Suryawanshi",
            "Varun Madhavan",
            "Adway Mitra",
            "Partha Pratim Chakrabarti"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  During the Covid-19 pandemic, most governments across the world imposed\npolicies like lock-down of public spaces and restrictions on people's movements\nto minimize the spread of the virus through physical contact. However, such\npolicies have grave social and economic costs, and so it is important to\npre-assess their impacts. In this work we aim to visualize the dynamics of the\npandemic in a city under different intervention policies, by simulating the\nbehavior of the residents. We develop a very detailed agent-based model for a\ncity, including its residents, physical and social spaces like homes,\nmarketplaces, workplaces, schools/colleges etc. We parameterize our model for\nKolkata city in India using ward-level demographic and civic data. We\ndemonstrate that under appropriate choice of parameters, our model is able to\nreproduce the observed dynamics of the Covid-19 pandemic in Kolkata, and also\nindicate the counter-factual outcomes of alternative intervention policies.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.01650v2"
    },
    {
        "title": "A Framework for Automatic Monitoring of Norms that regulate Time\n  Constrained Actions",
        "authors": [
            "Nicoletta Fornara",
            "Soheil Roshankish",
            "Marco Colombetti"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper addresses the problem of proposing a model of norms and a\nframework for automatically computing their violation or fulfilment. The\nproposed T-NORM model can be used to express abstract norms able to regulate\nclasses of actions that should or should not be performed in a temporal\ninterval. We show how the model can be used to formalize obligations and\nprohibitions and for inhibiting them by introducing permissions and exemptions.\nThe basic building blocks for norm specification consists of rules with\nsuitably nested components. The activation condition, the regulated actions,\nand the temporal constrains of norms are specified using the W3C Web Ontology\nLanguage (OWL 2). Thanks to this choice, it is possible to use OWL reasoning\nfor computing the effects that the logical implication between actions has on\nnorms fulfilment or violation. The operational semantics of the T-NORM model is\nspecified by providing an unambiguous procedure for translating every norm and\nevery exception into production rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.00200v1"
    },
    {
        "title": "Lecture Notes on Voting Theory",
        "authors": [
            "Davide Grossi"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  These lecture notes have been developed for the course Computational Social\nChoice of the Artificial Intelligence MSc programme at the University of\nGroningen. They cover mathematical and algorithmic aspects of voting theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.00216v1"
    },
    {
        "title": "Multi-Agent Routing and Scheduling Through Coalition Formation",
        "authors": [
            "Luca Capezzuto",
            "Danesh Tarapore",
            "Sarvapali D. Ramchurn"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In task allocation for real-time domains, such as disaster response, a\nlimited number of agents is deployed across a large area to carry out numerous\ntasks, each with its prerequisites, profit, time window and workload. To\nmaximize profits while minimizing time penalties, agents need to cooperate by\nforming, disbanding and reforming coalitions. In this paper, we name this\nproblem Multi-Agent Routing and Scheduling through Coalition formation (MARSC)\nand show that it generalizes the important Team Orienteering Problem with Time\nWindows. We propose a binary integer program and an anytime and scalable\nheuristic to solve it. Using public London Fire Brigade records, we create a\ndataset with 347588 tasks and a test framework that simulates the mobilization\nof firefighters. In problems with up to 150 agents and 3000 tasks, our\nheuristic finds solutions up to 3.25 times better than the Earliest Deadline\nFirst approach commonly used in real-time systems. Our results constitute the\nfirst large-scale benchmark for the MARSC problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.00451v2"
    },
    {
        "title": "Density-Aware Federated Imitation Learning for Connected and Automated\n  Vehicles with Unsignalized Intersection",
        "authors": [
            "Tianhao Wu",
            "Mingzhi Jiang",
            "Yinhui Han",
            "Zheng Yuan",
            "Lin Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Intelligent Transportation System (ITS) has become one of the essential\ncomponents in Industry 4.0. As one of the critical indicators of ITS,\nefficiency has attracted wide attention from researchers. However, the next\ngeneration of urban traffic carried by multiple transport service providers may\nprohibit the raw data interaction among multiple regions for privacy reasons,\neasily ignored in the existing research. This paper puts forward a federated\nlearning-based vehicle control framework to solve the above problem, including\ninteractors, trainers, and an aggregator. In addition, the density-aware model\naggregation method is utilized in this framework to improve vehicle control.\nWhat is more, to promote the performance of the end-to-end learning algorithm\nin the safety aspect, this paper proposes an imitation learning algorithm,\nwhich can obtain collision avoidance capabilities from a set of collision\navoidance rules. Furthermore, a loss-aware experience selection strategy is\nalso explored, reducing the communication overhead between the interactors and\nthe trainers via extra computing. Finally, the experiment results demonstrate\nthat the proposed imitation learning algorithm obtains the ability to avoid\ncollisions and reduces discomfort by 55.71%. Besides, density-aware model\naggregation can further reduce discomfort by 41.37%, and the experience\nselection scheme can reduce the communication overhead by 12.80% while ensuring\nmodel convergence.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.01889v1"
    },
    {
        "title": "Informational Design of Dynamic Multi-Agent System",
        "authors": [
            "Tao Zhang",
            "Quanyan Zhu"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This work considers a novel information design problem and studies how the\ncraft of payoff-relevant environmental signals solely can influence the\nbehaviors of intelligent agents. The agents' strategic interactions are\ncaptured by a Markov game, in which each agent first selects one external\nsignal from multiple signal sources as additional payoff-relevant information\nand then takes an action. There is a rational information designer (principal)\nwho possesses one signal source and aims to influence the equilibrium behaviors\nof the agents by designing the information structure of her signals sent to the\nagents. We propose a direct information design approach that incentivizes each\nagent to select the signal sent by the principal, such that the design process\navoids the predictions of the agents' strategic selection behaviors. We then\nintroduce the design protocol given a goal of the designer which we refer to as\nobedient implementability (OIL) and characterize the OIL in a class of obedient\nsequential Markov perfect equilibria (O-SMPE). A design regime is proposed\nbased on an approach which we refer to as the fixed-point alignment that\nincentivizes the agents to choose the signal sent by the principal, guarantees\nthat the agents' policy profile of taking actions is the policy component of an\nO-SMPE and the principal's goal is achieved. We then formulate the principal's\noptimal goal selection problem in terms of information design and characterize\nthe optimization problem by minimizing the fixed-point misalignments. The\nproposed approach can be applied to elicit desired behaviors of multi-agent\nsystems in competing as well as cooperating settings and be extended to\nheterogeneous stochastic games in the complete- and the incomplete-information\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03052v2"
    },
    {
        "title": "Improving Multi-agent Coordination by Learning to Estimate Contention",
        "authors": [
            "Panayiotis Danassis",
            "Florian Wiedemair",
            "Boi Faltings"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We present a multi-agent learning algorithm, ALMA-Learning, for efficient and\nfair allocations in large-scale systems. We circumvent the traditional pitfalls\nof multi-agent learning (e.g., the moving target problem, the curse of\ndimensionality, or the need for mutually consistent actions) by relying on the\nALMA heuristic as a coordination mechanism for each stage game. ALMA-Learning\nis decentralized, observes only own action/reward pairs, requires no\ninter-agent communication, and achieves near-optimal (<5% loss) and fair\ncoordination in a variety of synthetic scenarios and a real-world meeting\nscheduling problem. The lightweight nature and fast learning constitute\nALMA-Learning ideal for on-device deployment.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.04027v2"
    },
    {
        "title": "Offline Time-Independent Multi-Agent Path Planning",
        "authors": [
            "Keisuke Okumura",
            "François Bonnet",
            "Yasumasa Tamura",
            "Xavier Défago"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper studies a novel planning problem for multiple agents that cannot\nshare holding resources, named OTIMAPP (Offline Time-Independent Multi-Agent\nPath Planning). Given a graph and a set of start-goal pairs, the problem\nconsists in assigning a path to each agent such that every agent eventually\nreaches their goal without blocking each other, regardless of how the agents\nare being scheduled at runtime. The motivation stems from the nature of\ndistributed environments that agents take actions fully asynchronous and have\nno knowledge about those exact timings of other actors. We present solution\nconditions, computational complexity, solvers, and robotic applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07132v3"
    },
    {
        "title": "Mean Field Games Flock! The Reinforcement Learning Way",
        "authors": [
            "Sarah Perrin",
            "Mathieu Laurière",
            "Julien Pérolat",
            "Matthieu Geist",
            "Romuald Élie",
            "Olivier Pietquin"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We present a method enabling a large number of agents to learn how to flock,\nwhich is a natural behavior observed in large populations of animals. This\nproblem has drawn a lot of interest but requires many structural assumptions\nand is tractable only in small dimensions. We phrase this problem as a Mean\nField Game (MFG), where each individual chooses its acceleration depending on\nthe population behavior. Combining Deep Reinforcement Learning (RL) and\nNormalizing Flows (NF), we obtain a tractable solution requiring only very weak\nassumptions. Our algorithm finds a Nash Equilibrium and the agents adapt their\nvelocity to match the neighboring flock's average one. We use Fictitious Play\nand alternate: (1) computing an approximate best response with Deep RL, and (2)\nestimating the next population distribution with NF. We show numerically that\nour algorithm learn multi-group or high-dimensional flocking with obstacles.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07933v1"
    },
    {
        "title": "Programming and Deployment of Autonomous Swarms using Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Jayson Boubin",
            "Codi Burley",
            "Peida Han",
            "Bowen Li",
            "Barry Porter",
            "Christopher Stewart"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Autonomous systems (AS) carry out complex missions by continuously observing\nthe state of their surroundings and taking actions toward a goal. Swarms of AS\nworking together can complete missions faster and more effectively than single\nAS alone. To build swarms today, developers handcraft their own software for\nstoring, aggregating, and learning from observations. We present the Fleet\nComputer, a platform for developing and managing swarms. The Fleet Computer\nprovides a programming paradigm that simplifies multi-agent reinforcement\nlearning (MARL) -- an emerging class of algorithms that coordinate swarms of\nagents. Using just two programmer-provided functions Map() and Eval(), the\nFleet Computer compiles and deploys swarms and continuously updates the\nreinforcement learning models that govern actions. To conserve compute\nresources, the Fleet Computer gives priority scheduling to models that\ncontribute to effective actions, drawing a novel link between online learning\nand resource management. We developed swarms for unmanned aerial vehicles (UAV)\nin agriculture and for video analytics on urban traffic. Compared to individual\nAS, our swarms achieved speedup of 4.4X using 4 UAV and 62X using 130 video\ncameras. Compared to a competing approach for building swarms that is widely\nused in practice, our swarms were 3X more effective, using 3.9X less energy.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10605v1"
    },
    {
        "title": "Large-scale, Dynamic and Distributed Coalition Formation with Spatial\n  and Temporal Constraints",
        "authors": [
            "Luca Capezzuto",
            "Danesh Tarapore",
            "Sarvapali D. Ramchurn"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The Coalition Formation with Spatial and Temporal constraints Problem (CFSTP)\nis a multi-agent task allocation problem in which few agents have to perform\nmany tasks, each with its deadline and workload. To maximize the number of\ncompleted tasks, the agents need to cooperate by forming, disbanding and\nreforming coalitions. The original mathematical programming formulation of the\nCFSTP is difficult to implement, since it is lengthy and based on the\nproblematic Big-M method. In this paper, we propose a compact and\neasy-to-implement formulation. Moreover, we design D-CTS, a distributed version\nof the state-of-the-art CFSTP algorithm. Using public London Fire Brigade\nrecords, we create a dataset with $347588$ tasks and a test framework that\nsimulates the mobilization of firefighters in dynamic environments. In problems\nwith up to $150$ agents and $3000$ tasks, compared to DSA-SDP, a\nstate-of-the-art distributed algorithm, D-CTS completes $3.79\\% \\pm [42.22\\%,\n1.96\\%]$ more tasks, and is one order of magnitude more efficient in terms of\ncommunication overhead and time complexity. D-CTS sets the first large-scale,\ndynamic and distributed CFSTP benchmark.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.00379v1"
    },
    {
        "title": "The Impact of Network Connectivity on Collective Learning",
        "authors": [
            "Michael Crosscombe",
            "Jonathan Lawry"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In decentralised autonomous systems it is the interactions between individual\nagents which govern the collective behaviours of the system. These local-level\ninteractions are themselves often governed by an underlying network structure.\nThese networks are particularly important for collective learning and\ndecision-making whereby agents must gather evidence from their environment and\npropagate this information to other agents in the system. Models for collective\nbehaviours may often rely upon the assumption of total connectivity between\nagents to provide effective information sharing within the system, but this\nassumption may be ill-advised. In this paper we investigate the impact that the\nunderlying network has on performance in the context of collective learning.\nThrough simulations we study small-world networks with varying levels of\nconnectivity and randomness and conclude that totally-connected networks result\nin higher average error when compared to networks with less connectivity.\nFurthermore, we show that networks of high regularity outperform networks with\nincreasing levels of random connectivity.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.00655v2"
    },
    {
        "title": "SURPRISE! and When to Schedule It",
        "authors": [
            "Zhihuan Huang",
            "Shengwei Xu",
            "You Shan",
            "Yuxuan Lu",
            "Yuqing Kong",
            "Tracy Xiao Liu",
            "Grant Schoenebeck"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Information flow measures, over the duration of a game, the audience's belief\nof who will win, and thus can reflect the amount of surprise in a game. To\nquantify the relationship between information flow and audiences' perceived\nquality, we conduct a case study where subjects watch one of the world's\nbiggest esports events, LOL S10. In addition to eliciting information flow, we\nalso ask subjects to report their rating for each game. We find that the amount\nof surprise in the end of the game plays a dominant role in predicting the\nrating. This suggests the importance of incorporating when the surprise occurs,\nin addition to the amount of surprise, in perceived quality models. For content\nproviders, it implies that everything else being equal, it is better for twists\nto be more likely to happen toward the end of a show rather than uniformly\nthroughout.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.02851v1"
    },
    {
        "title": "Decentralised Approach for Multi Agent Path Finding",
        "authors": [
            "Shyni Thomas",
            "M. Narasimha Murty"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi Agent Path Finding (MAPF) requires identification of conflict free\npaths for agents which could be point-sized or with dimensions. In this paper,\nwe propose an approach for MAPF for spatially-extended agents. These find\napplication in real world problems like Convoy Movement Problem, Train\nScheduling etc. Our proposed approach, Decentralised Multi Agent Path Finding\n(DeMAPF), handles MAPF as a sequence of pathplanning and allocation problems\nwhich are solved by two sets of agents Travellers and Routers respectively,\nover multiple iterations. The approach being decentralised allows an agent to\nsolve the problem pertinent to itself, without being aware of other agents in\nthe same set. This allows the agents to be executed on independent machines,\nthereby leading to scalability to handle large sized problems. We prove, by\ncomparison with other distributed approaches, that the approach leads to a\nfaster convergence to a conflict-free solution, which may be suboptimal, with\nlesser memory requirement.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.05188v1"
    },
    {
        "title": "MALib: A Parallel Framework for Population-based Multi-agent\n  Reinforcement Learning",
        "authors": [
            "Ming Zhou",
            "Ziyu Wan",
            "Hanjing Wang",
            "Muning Wen",
            "Runzhe Wu",
            "Ying Wen",
            "Yaodong Yang",
            "Weinan Zhang",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Population-based multi-agent reinforcement learning (PB-MARL) refers to the\nseries of methods nested with reinforcement learning (RL) algorithms, which\nproduces a self-generated sequence of tasks arising from the coupled population\ndynamics. By leveraging auto-curricula to induce a population of distinct\nemergent strategies, PB-MARL has achieved impressive success in tackling\nmulti-agent tasks. Despite remarkable prior arts of distributed RL frameworks,\nPB-MARL poses new challenges for parallelizing the training frameworks due to\nthe additional complexity of multiple nested workloads between sampling,\ntraining and evaluation involved with heterogeneous policy interactions. To\nsolve these problems, we present MALib, a scalable and efficient computing\nframework for PB-MARL. Our framework is comprised of three key components: (1)\na centralized task dispatching model, which supports the self-generated tasks\nand scalable training with heterogeneous policy combinations; (2) a programming\narchitecture named Actor-Evaluator-Learner, which achieves high parallelism for\nboth training and sampling, and meets the evaluation requirement of\nauto-curriculum learning; (3) a higher-level abstraction of MARL training\nparadigms, which enables efficient code reuse and flexible deployments on\ndifferent distributed computing paradigms. Experiments on a series of complex\ntasks such as multi-agent Atari Games show that MALib achieves throughput\nhigher than 40K FPS on a single machine with $32$ CPU cores; 5x speedup than\nRLlib and at least 3x speedup than OpenSpiel in multi-agent training tasks.\nMALib is publicly available at https://github.com/sjtu-marl/malib.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.07551v1"
    },
    {
        "title": "Dynamic Urban Planning: an Agent-Based Model Coupling Mobility Mode and\n  Housing Choice. Use case Kendall Square",
        "authors": [
            "Mireia Yurrita",
            "Arnaud Grignard",
            "Luis Alonso",
            "Yan Zhang",
            "Cristian Jara-Figueroa",
            "Markus Elkatsha",
            "Kent Larson"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  As cities become increasingly populated, urban planning plays a key role in\nensuring the equitable and inclusive development of metropolitan areas. MIT\nCity Science group created a data-driven tangible platform, CityScope, to help\ndifferent stakeholders, such as government representatives, urban planners,\ndevelopers, and citizens, collaboratively shape the urban scenario through the\nreal-time impact analysis of different urban interventions. This paper presents\nan agent-based model that characterizes citizens' behavioural patterns with\nrespect to housing and mobility choice that will constitute the first step in\nthe development of a dynamic incentive system for an open interactive\ngovernance process. The realistic identification and representation of the\ncriteria that affect this decision-making process will help understand and\nevaluate the impacts of potential housing incentives that aim to promote urban\ncharacteristics such as equality, diversity, walkability, and efficiency. The\ncalibration and validation of the model have been performed in a well-known\ngeographic area for the Group: Kendall Square in Cambridge, MA.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.14572v1"
    },
    {
        "title": "SA-MATD3:Self-attention-based multi-agent continuous control method in\n  cooperative environments",
        "authors": [
            "Kai Liu",
            "Yuyang Zhao",
            "Gang Wang",
            "Bei Peng"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Cooperative problems under continuous control have always been the focus of\nmulti-agent reinforcement learning. Existing algorithms suffer from the problem\nof uneven learning degree with the increase of the number of agents. In this\npaper, a new structure for a multi-agent actor critic is proposed, and the\nself-attention mechanism is applied in the critic network and the value\ndecomposition method used to solve the uneven problem. The proposed algorithm\nmakes full use of the samples in the replay memory buffer to learn the behavior\nof a class of agents. First, a new update method is proposed for policy\nnetworks that promotes learning efficiency. Second, the utilization of samples\nis improved, at the same time reflecting the ability of perspective-taking\namong groups. Finally, the \"deceptive signal\" in training is eliminated and the\nlearning degree among agents is more uniform than in the existing methods.\nMultiple experiments were conducted in two typical scenarios of a multi-agent\nparticle environment. Experimental results show that the proposed algorithm can\nperform better than the state-of-the-art ones, and that it exhibits higher\nlearning efficiency with an increasing number of agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00284v1"
    },
    {
        "title": "Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting\n  Pot",
        "authors": [
            "Joel Z. Leibo",
            "Edgar Duéñez-Guzmán",
            "Alexander Sasha Vezhnevets",
            "John P. Agapiou",
            "Peter Sunehag",
            "Raphael Koster",
            "Jayd Matyas",
            "Charles Beattie",
            "Igor Mordatch",
            "Thore Graepel"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Existing evaluation suites for multi-agent reinforcement learning (MARL) do\nnot assess generalization to novel situations as their primary objective\n(unlike supervised-learning benchmarks). Our contribution, Melting Pot, is a\nMARL evaluation suite that fills this gap, and uses reinforcement learning to\nreduce the human labor required to create novel test scenarios. This works\nbecause one agent's behavior constitutes (part of) another agent's environment.\nTo demonstrate scalability, we have created over 80 unique test scenarios\ncovering a broad range of research topics such as social dilemmas, reciprocity,\nresource sharing, and task partitioning. We apply these test scenarios to\nstandard MARL training algorithms, and demonstrate how Melting Pot reveals\nweaknesses not apparent from training performance alone.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.06857v1"
    },
    {
        "title": "Multi Agent System for Machine Learning Under Uncertainty in Cyber\n  Physical Manufacturing System",
        "authors": [
            "Bang Xiang Yong",
            "Alexandra Brintrup"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Recent advancements in predictive machine learning has led to its application\nin various use cases in manufacturing. Most research focused on maximising\npredictive accuracy without addressing the uncertainty associated with it.\nWhile accuracy is important, focusing primarily on it poses an overfitting\ndanger, exposing manufacturers to risk, ultimately hindering the adoption of\nthese techniques. In this paper, we determine the sources of uncertainty in\nmachine learning and establish the success criteria of a machine learning\nsystem to function well under uncertainty in a cyber-physical manufacturing\nsystem (CPMS) scenario. Then, we propose a multi-agent system architecture\nwhich leverages probabilistic machine learning as a means of achieving such\ncriteria. We propose possible scenarios for which our proposed architecture is\nuseful and discuss future work. Experimentally, we implement Bayesian Neural\nNetworks for multi-tasks classification on a public dataset for the real-time\ncondition monitoring of a hydraulic system and demonstrate the usefulness of\nthe system by evaluating the probability of a prediction being accurate given\nits uncertainty. We deploy these models using our proposed agent-based\nframework and integrate web visualisation to demonstrate its real-time\nfeasibility.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.13252v1"
    },
    {
        "title": "Dynamic communication topologies for distributed heuristics in energy\n  system optimization algorithms",
        "authors": [
            "Stefanie Holly",
            "Astrid Nieße"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The communication topology is an essential aspect in designing distributed\noptimization heuristics. It can influence the exploration and exploitation of\nthe search space and thus the optimization performance in terms of solution\nquality, convergence speed and collaboration costs, all relevant aspects for\napplications operating critical infrastructure in energy systems. In this work,\nwe present an approach for adapting the communication topology during runtime,\nbased on the principles of simulated annealing. We compare the approach to\ncommon static topologies regarding the performance of an exemplary distributed\noptimization heuristic. Finally, we investigate the correlations between\nfitness landscape properties and defined performance metrics.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.01380v1"
    },
    {
        "title": "Tracking Multiple Fast Targets With Swarms: Interplay Between Social\n  Interaction and Agent Memory",
        "authors": [
            "Hian Lee Kwa",
            "Jabez Leong Kit",
            "Roland Bouffanais"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The task of searching for and tracking of multiple targets is a challenging\none. However, most works in this area do not consider evasive targets that move\nfaster than the agents comprising the multi-robot system. This is due to the\nassumption that the movement patterns of such targets, combined with their\nexcessive speed, would make the task nearly impossible to accomplish. In this\nwork, we show that this is not the case and we propose a decentralized search\nand tracking strategy in which the level of exploration and exploitation\ncarried out by the swarm is adjustable. By tuning a swarm's exploration and\nexploitation dynamics, we demonstrate that there exists an optimal balance\nbetween the level of exploration and exploitation performed. This optimum\nmaximizes its tracking performance and changes depending on the number of\ntargets and the targets' movement profiles. We also show that the use of\nagent-based memory is critical in enabling the tracking of an evasive target.\nThe obtained simulation results are validated through experimental tests with a\ndecentralized swarm of six robots tracking a virtual fast-moving target.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.07122v1"
    },
    {
        "title": "Encirclement Guaranteed Cooperative Pursuit with Robust Model Predictive\n  Control",
        "authors": [
            "Chen Wang",
            "Hua Chen",
            "Jia Pan",
            "Wei Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper studies a novel encirclement guaranteed cooperative pursuit\nproblem involving $N$ pursuers and a single evader in an unbounded\ntwo-dimensional game domain. Throughout the game, the pursuers are required to\nmaintain encirclement of the evader, i.e., the evader should always stay inside\nthe convex hull generated by all the pursuers, in addition to achieving the\nclassical capture condition. To tackle this challenging cooperative pursuit\nproblem, a robust model predictive control (RMPC) based formulation framework\nis first introduced, which simultaneously accounts for the encirclement and\ncapture requirements under the assumption that the evader's action is\nunavailable to all pursuers. Despite the reformulation, the resulting RMPC\nproblem involves a bilinear constraint due to the encirclement requirement. To\nfurther handle such a bilinear constraint, a novel encirclement guaranteed\npartitioning scheme is devised that simplifies the original bilinear RMPC\nproblem to a number of linear tube MPC (TMPC) problems solvable in a\ndecentralized manner. Simulation experiments demonstrate the effectiveness of\nthe proposed solution framework. Furthermore, comparisons with existing\napproaches show that the explicit consideration of the encirclement condition\nsignificantly improves the chance of successful capture of the evader in\nvarious scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.07445v1"
    },
    {
        "title": "An Agent-Based Model of COVID-19 Diffusion to Plan and Evaluate\n  Intervention Policies",
        "authors": [
            "Gianpiero Pescarmona",
            "Pietro Terna",
            "Alberto Acquadro",
            "Paolo Pescarmona",
            "Giuseppe Russo",
            "Emilio Sulis",
            "Stefano Terna"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  A model of interacting agents, following plausible behavioral rules into a\nworld where the Covid-19 epidemic is affecting the actions of everyone. The\nmodel works with (i) infected agents categorized as symptomatic or asymptomatic\nand (ii) the places of contagion specified in a detailed way. The infection\ntransmission is related to three factors: the characteristics of both the\ninfected person and the susceptible one, plus those of the space in which\ncontact occurs. The model includes the structural data of Piedmont, an Italian\nregion, but we can easily calibrate it for other areas. The micro-based\nstructure of the model allows factual, counterfactual, and conditional\nsimulations to investigate both the spontaneous or controlled development of\nthe epidemic. The model is generative of complex epidemic dynamics emerging\nfrom the consequences of agents' actions and interactions, with high\nvariability in outcomes and stunning realistic reproduction of the successive\ncontagion waves in the reference region. There is also an inverse generative\nside of the model, coming from the idea of using genetic algorithms to\nconstruct a meta-agent to optimize the vaccine distribution. This agent takes\ninto account groups' characteristics -- by age, fragility, work conditions --\nto minimize the number of symptomatic people.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.08885v1"
    },
    {
        "title": "Commutative Monoid Formalism for Weighted Coupled Cell Networks and\n  Invariant Synchrony Patterns",
        "authors": [
            "Pedro M. Sequeira",
            "António P. Aguiar",
            "João Hespanha"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper presents a framework based on matrices of monoids for the study of\ncoupled cell networks. We formally prove within the proposed framework, that\nthe set of results about invariant synchrony patterns for unweighted networks\nalso holds for the weighted case. Moreover, the approach described allows us to\nreason about any multiedge and multiedge-type network as if it was single edge\nand single-edge-type. Several examples illustrate the concepts described.\nAdditionally, an improvement of the coarsest invariant refinement algorithm to\nfind balanced partitions is presented that exhibits a worst-case complexity of\n$ \\mathbf{O}(\\vert\\mathcal{C}\\vert^3) $, where $\\mathcal{C}$ denotes the set of\ncells.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.11991v1"
    },
    {
        "title": "Multi-Agent Simulation for AI Behaviour Discovery in Operations Research",
        "authors": [
            "Michael Papasimeon",
            "Lyndon Benke"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We describe ACE0, a lightweight platform for evaluating the suitability and\nviability of AI methods for behaviour discovery in multiagent simulations.\nSpecifically, ACE0 was designed to explore AI methods for multi-agent\nsimulations used in operations research studies related to new technologies\nsuch as autonomous aircraft. Simulation environments used in production are\noften high-fidelity, complex, require significant domain knowledge and as a\nresult have high R&D costs. Minimal and lightweight simulation environments can\nhelp researchers and engineers evaluate the viability of new AI technologies\nfor behaviour discovery in a more agile and potentially cost effective manner.\nIn this paper we describe the motivation for the development of ACE0.We provide\na technical overview of the system architecture, describe a case study of\nbehaviour discovery in the aerospace domain, and provide a qualitative\nevaluation of the system. The evaluation includes a brief description of\ncollaborative research projects with academic partners, exploring different AI\nbehaviour discovery methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.13296v1"
    },
    {
        "title": "Learning Robot Swarm Tactics over Complex Adversarial Environments",
        "authors": [
            "Amir Behjat",
            "Hemanth Manjunatha",
            "Prajit KrisshnaKumar",
            "Apurv Jani",
            "Leighton Collins",
            "Payam Ghassemi",
            "Joseph Distefano",
            "David Doermann",
            "Karthik Dantu",
            "Ehsan Esfahani",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  To accomplish complex swarm robotic missions in the real world, one needs to\nplan and execute a combination of single robot behaviors, group primitives such\nas task allocation, path planning, and formation control, and mission-specific\nobjectives such as target search and group coverage. Most such missions are\ndesigned manually by teams of robotics experts. Recent work in automated\napproaches to learning swarm behavior has been limited to individual primitives\nwith sparse work on learning complete missions. This paper presents a\nsystematic approach to learn tactical mission-specific policies that compose\nprimitives in a swarm to accomplish the mission efficiently using neural\nnetworks with special input and output encoding. To learn swarm tactics in an\nadversarial environment, we employ a combination of 1) map-to-graph\nabstraction, 2) input/output encoding via Pareto filtering of points of\ninterest and clustering of robots, and 3) learning via neuroevolution and\npolicy gradient approaches. We illustrate this combination as critical to\nproviding tractable learning, especially given the computational cost of\nsimulating swarm missions of this scale and complexity. Successful mission\ncompletion outcomes are demonstrated with up to 60 robots. In addition, a close\nmatch in the performance statistics in training and testing scenarios shows the\npotential generalizability of the proposed framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.05663v1"
    },
    {
        "title": "Comprehensive Multi-Agent Epistemic Planning",
        "authors": [
            "Francesco Fabiano"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Over the last few years, the concept of Artificial Intelligence has become\ncentral in different tasks concerning both our daily life and several working\nscenarios. Among these tasks automated planning has always been central in the\nAI research community. In particular, this manuscript is focused on a\nspecialized kind of planning known as Multi-agent Epistemic Planning (MEP).\nEpistemic Planning (EP) refers to an automated planning setting where the agent\nreasons in the space of knowledge/beliefs states and tries to find a plan to\nreach a desirable state from a starting one. Its general form, the MEP problem,\ninvolves multiple agents who need to reason about both the state of the world\nand the information flows between agents. To tackle the MEP problem several\ntools have been developed and, while the diversity of approaches has led to a\ndeeper understanding of the problem space, each proposed tool lacks some\nabilities and does not allow for a comprehensive investigation of the\ninformation flows. That is why, the objective of our work is to formalize an\nenvironment where a complete characterization of the agents' knowledge/beliefs\ninteraction and update is possible. In particular, we aim to achieve such goal\nby defining a new action-based language for multi-agent epistemic planning and\nto implement an epistemic planner based on it. This solver should provide a\ntool flexible enough to reason on different domains, e.g., economy, security,\njustice and politics, where considering others' knowledge/beliefs could lead to\nwinning strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.08301v1"
    },
    {
        "title": "Random coordinate descent algorithm for open multi-agent systems with\n  complete topology and homogeneous agents",
        "authors": [
            "Charles Monnoyer de Galland",
            "Renato Vizuete",
            "Julien M. Hendrickx",
            "Paolo Frasca",
            "Elena Panteley"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We study the convergence in expectation of the Random Coordinate Descent\nalgorithm (RCD) for solving optimal resource allocations problems in open\nmulti-agent systems, i.e., multi-agent systems that are subject to arrivals and\ndepartures of agents. Assuming all local functions are strongly-convex and\nsmooth, and their minimizers lie in a given ball, we analyse the evolution of\nthe distance to the minimizer in expectation when the system is occasionally\nsubject to replacements in addition to the usual iterations of the RCD\nalgorithm. We focus on complete graphs where all agents interact with each\nother with the same probability, and provide conditions to guarantee\nconvergence in open system. Finally, a discussion around the tightness of our\nresults is provided.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.14510v1"
    },
    {
        "title": "Decentralized Role Assignment in Multi-Agent Teams via Empirical\n  Game-Theoretic Analysis",
        "authors": [
            "Fengjun Yang",
            "Negar Mehr",
            "Mac Schwager"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We propose a method, based on empirical game theory, for a robot operating as\npart of a team to choose its role within the team without explicitly\ncommunicating with team members, by leveraging its knowledge about the team\nstructure. To do this, we formulate the role assignment problem as a dynamic\ngame, and borrow tools from empirical game-theoretic analysis to analyze such\ngames. Based on this game-theoretic formulation, we propose a distributed\ncontroller for each robot to dynamically decide on the best role to take. We\ndemonstrate our method in simulations of a collaborative planar manipulation\nscenario in which each agent chooses from a set of feedback control policies at\neach instant. The agents can effectively collaborate without communication to\nmanipulate the object while also avoiding collisions using our method.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.14755v1"
    },
    {
        "title": "Decentralized Graph-Based Multi-Agent Reinforcement Learning Using\n  Reward Machines",
        "authors": [
            "Jueming Hu",
            "Zhe Xu",
            "Weichang Wang",
            "Guannan Qu",
            "Yutian Pang",
            "Yongming Liu"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In multi-agent reinforcement learning (MARL), it is challenging for a\ncollection of agents to learn complex temporally extended tasks. The\ndifficulties lie in computational complexity and how to learn the high-level\nideas behind reward functions. We study the graph-based Markov Decision Process\n(MDP) where the dynamics of neighboring agents are coupled. We use a reward\nmachine (RM) to encode each agent's task and expose reward function internal\nstructures. RM has the capacity to describe high-level knowledge and encode\nnon-Markovian reward functions. We propose a decentralized learning algorithm\nto tackle computational complexity, called decentralized graph-based\nreinforcement learning using reward machines (DGRM), that equips each agent\nwith a localized policy, allowing agents to make decisions independently, based\non the information available to the agents. DGRM uses the actor-critic\nstructure, and we introduce the tabular Q-function for discrete state problems.\nWe show that the dependency of Q-function on other agents decreases\nexponentially as the distance between them increases. Furthermore, the\ncomplexity of DGRM is related to the local information size of the largest\n$\\kappa$-hop neighborhood, and DGRM can find an\n$O(\\rho^{\\kappa+1})$-approximation of a stationary point of the objective\nfunction. To further improve efficiency, we also propose the deep DGRM\nalgorithm, using deep neural networks to approximate the Q-function and policy\nfunction to solve large-scale or continuous state problems. The effectiveness\nof the proposed DGRM algorithm is evaluated by two case studies, UAV package\ndelivery and COVID-19 pandemic mitigation. Experimental results show that local\ninformation is sufficient for DGRM and agents can accomplish complex tasks with\nthe help of RM. DGRM improves the global accumulated reward by 119% compared to\nthe baseline in the case of COVID-19 pandemic mitigation.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.00096v1"
    },
    {
        "title": "Temporal Graphs and Temporal Network Characteristics for Bio-Inspired\n  Networks During Optimization",
        "authors": [
            "N. DiBrita",
            "K. Eledlebi",
            "H. Hildmann",
            "L. Culley",
            "A. F. Isakovic"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Temporal network analysis and time evolution of network characteristics are\npowerful tools in describing the changing topology of dynamic networks. This\npaper uses such approaches to better visualize and provide analytical measures\nfor the changes in performance that we observed in Voronoi-type spatial\ncoverage, particularly for the example of time evolving networks with a\nchanging number of wireless sensors being deployed. Specifically, our analysis\nfocuses on the role different combinations of impenetrable obstacles and\nenvironmental noise play in connectivity and overall network structure. It is\nshown how the use of (i) temporal network graphs, and (ii) network centrality\nand regularity measures illustrate the differences between various options\ndeveloped for the balancing act of energy and time efficiency in network\ncoverage. Lastly, we compare the outcome of these measures with the less\nabstract classification variables, such as percent area covered, and cumulative\ndistance travelled.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.00506v1"
    },
    {
        "title": "School Virus Infection Simulator for Customizing School Schedules During\n  COVID-19",
        "authors": [
            "Satoshi Takahashi",
            "Masaki Kitazawa",
            "Atsushi Yoshikawa"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  During the Coronavirus 2019 (the covid-19) pandemic, schools continuously\nstrive to provide consistent education to their students. Teachers and\neducation policymakers are seeking ways to re-open schools, as it is necessary\nfor community and economic development. However, in light of the pandemic,\nschools require customized schedules that can address the health concerns and\nsafety of the students considering classroom sizes, air conditioning equipment,\nclassroom systems, e.g., self-contained or compartmentalized. To solve this\nissue, we developed the School-Virus-Infection-Simulator (SVIS) for teachers\nand education policymakers. SVIS simulates the spread of infection at a school\nconsidering the students' lesson schedules, classroom volume, air circulation\nrates in classrooms, and infectability of the students. Thus, teachers and\neducation policymakers can simulate how their school schedules can impact\ncurrent health concerns. We then demonstrate the impact of several school\nschedules in self-contained and departmentalized classrooms and evaluate them\nin terms of the maximum number of students infected simultaneously and the\npercentage of face-to-face lessons. The results show that increasing classroom\nventilation rate is effective, however, the impact is not stable compared to\ncustomizing school schedules, in addition, school schedules can differently\nimpact the maximum number of students infected depending on whether classrooms\nare self-contained or compartmentalized. It was found that one of school\nschedules had a higher maximum number of students infected, compared to\nschedules with a higher percentage of face-to-face lessons. SVIS and the\nsimulation results can help teachers and education policymakers plan school\nschedules appropriately in order to reduce the maximum number of students\ninfected, while also maintaining a certain percentage of face-to-face lessons.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.03615v2"
    },
    {
        "title": "DeepABM: Scalable, efficient and differentiable agent-based simulations\n  via graph neural networks",
        "authors": [
            "Ayush Chopra",
            "Esma Gel",
            "Jayakumar Subramanian",
            "Balaji Krishnamurthy",
            "Santiago Romero-Brufau",
            "Kalyan S. Pasupathy",
            "Thomas C. Kingsley",
            "Ramesh Raskar"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We introduce DeepABM, a framework for agent-based modeling that leverages\ngeometric message passing of graph neural networks for simulating action and\ninteractions over large agent populations. Using DeepABM allows scaling\nsimulations to large agent populations in real-time and running them\nefficiently on GPU architectures. To demonstrate the effectiveness of DeepABM,\nwe build DeepABM-COVID simulator to provide support for various\nnon-pharmaceutical interventions (quarantine, exposure notification,\nvaccination, testing) for the COVID-19 pandemic, and can scale to populations\nof representative size in real-time on a GPU. Specifically, DeepABM-COVID can\nmodel 200 million interactions (over 100,000 agents across 180 time-steps) in\n90 seconds, and is made available online to help researchers with modeling and\nanalysis of various interventions. We explain various components of the\nframework and discuss results from one research study to evaluate the impact of\ndelaying the second dose of the COVID-19 vaccine in collaboration with clinical\nand public health experts. While we simulate COVID-19 spread, the ideas\nintroduced in the paper are generic and can be easily extend to other forms of\nagent-based simulations. Furthermore, while beyond scope of this document,\nDeepABM enables inverse agent-based simulations which can be used to learn\nphysical parameters in the (micro) simulations using gradient-based\noptimization with large-scale real-world (macro) data. We are optimistic that\nthe current work can have interesting implications for bringing ABM and AI\ncommunities closer.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.04421v1"
    },
    {
        "title": "Decentralized sliding-mode control laws for the bearing-based formation\n  tracking problem",
        "authors": [
            "Dung Van Vu",
            "Minh Hoang Trinh"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper studies the time-varying bearing-based tracking of leader-follower\nformations. The desired constraints between agents are specified by bearing\nvectors, and several leaders are moving with a bounded reference velocity. Each\nfollowers can measure the relative positions of its neighbors, its own\nvelocities, and receive information from their neighbors. Under the assumptions\nthat the desired formation is infinitesimally bearing rigid and the local\nreference frames of followers are aligned with each other, two control laws are\npresented in this paper based on sliding mode control approach. Stability\nanalyses are given based on Lyapunov stability theory and supported by\nnumerical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.05153v1"
    },
    {
        "title": "GridLearn: Multiagent Reinforcement Learning for Grid-Aware Building\n  Energy Management",
        "authors": [
            "Aisling Pigott",
            "Constance Crozier",
            "Kyri Baker",
            "Zoltan Nagy"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Increasing amounts of distributed generation in distribution networks can\nprovide both challenges and opportunities for voltage regulation across the\nnetwork. Intelligent control of smart inverters and other smart building energy\nmanagement systems can be leveraged to alleviate these issues. GridLearn is a\nmultiagent reinforcement learning platform that incorporates both building\nenergy models and power flow models to achieve grid level goals, by controlling\nbehind-the-meter resources. This study demonstrates how multi-agent\nreinforcement learning can preserve building owner privacy and comfort while\npursuing grid-level objectives. Building upon the CityLearn framework which\nconsiders RL for building-level goals, this work expands the framework to a\nnetwork setting where grid-level goals are additionally considered. As a case\nstudy, we consider voltage regulation on the IEEE-33 bus network using\ncontrollable building loads, energy storage, and smart inverters. The results\nshow that the RL agents nominally reduce instances of undervoltages and reduce\ninstances of overvoltages by 34%.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.06396v1"
    },
    {
        "title": "Decentralized Cooperative Lane Changing at Freeway Weaving Areas Using\n  Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Yi Hou",
            "Peter Graf"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Frequent lane changes during congestion at freeway bottlenecks such as merge\nand weaving areas further reduce roadway capacity. The emergence of deep\nreinforcement learning (RL) and connected and automated vehicle technology\nprovides a possible solution to improve mobility and energy efficiency at\nfreeway bottlenecks through cooperative lane changing. Deep RL is a collection\nof machine-learning methods that enables an agent to improve its performance by\nlearning from the environment. In this study, a decentralized cooperative\nlane-changing controller was developed using proximal policy optimization by\nadopting a multi-agent deep RL paradigm. In the decentralized control strategy,\npolicy learning and action reward are evaluated locally, with each agent\n(vehicle) getting access to global state information. Multi-agent deep RL\nrequires lower computational resources and is more scalable than single-agent\ndeep RL, making it a powerful tool for time-sensitive applications such as\ncooperative lane changing. The results of this study show that cooperative lane\nchanging enabled by multi-agent deep RL yields superior performance to human\ndrivers in term of traffic throughput, vehicle speed, number of stops per\nvehicle, vehicle fuel efficiency, and emissions. The trained RL policy is\ntransferable and can be generalized to uncongested, moderately congested, and\nextremely congested traffic conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08124v1"
    },
    {
        "title": "Towards a Multi-Agent System Architecture for Supply Chain Management",
        "authors": [
            "Carlos R. Jaimez-González",
            "Wulfrano A. Luna-Ramírez"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Individual business processes have been changing since the Internet was\ncreated, and they are now oriented towards a more distributed and collaborative\nbusiness model, in an e-commerce environment that adapts itself to the\ncompetitive and changing market conditions. This paper presents a multi-agent\nsystem architecture for supply chain management, which explores different\nstrategies and offers solutions in a distributed e-commerce environment. The\nsystem is designed to support different types of interfaces, which allow\ninteroperating with other business models already developed. In order to show\nhow the entire multi-agent system is being developed, the implementation of a\ncollaborative agent is presented and explained.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08125v1"
    },
    {
        "title": "Deep Structured Teams in Arbitrary-Size Linear Networks: Decentralized\n  Estimation, Optimal Control and Separation Principle",
        "authors": [
            "Jalal Arabneydi",
            "Amir G. Aghdam"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this article, we introduce decentralized Kalman filters for linear\nquadratic deep structured teams. The agents in deep structured teams are\ncoupled in dynamics, costs and measurements through a set of linear regressions\nof the states and actions (also called deep states and deep actions). The\ninformation structure is decentralized, where every agent observes a noisy\nmeasurement of its local state and the global deep state. Since the number of\nagents is often very large in deep structured teams, any naive approach to\nfinding an optimal Kalman filter suffers from the curse of dimensionality.\nMoreover, due to the decentralized nature of information structure, the\nresultant optimization problem is non-convex, in general, where non-linear\nstrategies can outperform linear ones. However, we prove that the optimal\nstrategy is linear in the local state estimate as well as the deep state\nestimate and can be efficiently computed by two scale-free Riccati equations\nand Kalman filters. We propose a bi-level orthogonal approach across both space\nand time levels based on a gauge transformation technique to achieve the above\nresult.\n  We also establish a separation principle between optimal control and optimal\nestimation. Furthermore, we show that as the number of agents goes to infinity,\nthe Kalman gain associated with the deep state estimate converges to zero at a\nrate inversely proportional to the number of agents. This leads to a fully\ndecentralized approximate strategy where every agent predicts the deep state by\nits conditional and unconditional expected value, also known as the certainty\nequivalence approximation and (weighted) mean-field approximation,\nrespectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.12217v1"
    },
    {
        "title": "Integrated Task Assignment and Path Planning for Capacitated Multi-Agent\n  Pickup and Delivery",
        "authors": [
            "Zhe Chen",
            "Javier Alonso-Mora",
            "Xiaoshan Bai",
            "Daniel D. Harabor",
            "Peter J. Stuckey"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi-agent Pickup and Delivery (MAPD) is a challenging industrial problem\nwhere a team of robots is tasked with transporting a set of tasks, each from an\ninitial location and each to a specified target location. Appearing in the\ncontext of automated warehouse logistics and automated mail sortation, MAPD\nrequires first deciding which robot is assigned what task (i.e., Task\nAssignment or TA) followed by a subsequent coordination problem where each\nrobot must be assigned collision-free paths so as to successfully complete its\nassignment (i.e., Multi-Agent Path Finding or MAPF). Leading methods in this\narea solve MAPD sequentially: first assigning tasks, then assigning paths. In\nthis work we propose a new coupled method where task assignment choices are\ninformed by actual delivery costs instead of by lower-bound estimates. The main\ningredients of our approach are a marginal-cost assignment heuristic and a\nmeta-heuristic improvement strategy based on Large Neighbourhood Search. As a\nfurther contribution, we also consider a variant of the MAPD problem where each\nrobot can carry multiple tasks instead of just one. Numerical simulations show\nthat our approach yields efficient and timely solutions and we report\nsignificant improvement compared with other recent methods from the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.14891v1"
    },
    {
        "title": "Decentralized Multi-Agent Reinforcement Learning: An Off-Policy Method",
        "authors": [
            "Kuo Li",
            "Qing-Shan Jia"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We discuss the problem of decentralized multi-agent reinforcement learning\n(MARL) in this work. In our setting, the global state, action, and reward are\nassumed to be fully observable, while the local policy is protected as privacy\nby each agent, and thus cannot be shared with others. There is a communication\ngraph, among which the agents can exchange information with their neighbors.\nThe agents make individual decisions and cooperate to reach a higher\naccumulated reward.\n  Towards this end, we first propose a decentralized actor-critic (AC) setting.\nThen, the policy evaluation and policy improvement algorithms are designed for\ndiscrete and continuous state-action-space Markov Decision Process (MDP)\nrespectively. Furthermore, convergence analysis is given under the\ndiscrete-space case, which guarantees that the policy will be reinforced by\nalternating between the processes of policy evaluation and policy improvement.\nIn order to validate the effectiveness of algorithms, we design experiments and\ncompare them with previous algorithms, e.g., Q-learning \\cite{watkins1992q} and\nMADDPG \\cite{lowe2017multi}. The results show that our algorithms perform\nbetter from the aspects of both learning speed and final performance. Moreover,\nthe algorithms can be executed in an off-policy manner, which greatly improves\nthe data efficiency compared with on-policy algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.00438v1"
    },
    {
        "title": "Search and Rescue in a Maze-like Environment with Ant and Dijkstra\n  Algorithms",
        "authors": [
            "Z. Husain",
            "A. Al Zaabi",
            "H. Hildmann",
            "F. Saffre",
            "D. Ruta",
            "A. F. Isakovic"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  With the growing reliability of modern Ad Hoc Networks, it is encouraging to\nanalyze potential involvement of autonomous Ad Hoc agents in critical\nsituations where human involvement could be perilous. One such critical\nscenario is the Search and Rescue effort in the event of a disaster where\ntimely discovery and help deployment is of utmost importance. This paper\ndemonstrates the applicability of a bio-inspired technique, namely Ant\nAlgorithms (AA), in optimizing the search time for a near optimal path to a\ntrapped victim, followed by the application of Dijkstra's algorithm in the\nrescue phase. The inherent exploratory nature of AA is put to use for a faster\nmapping and coverage of the unknown search space. Four different AA are\nimplemented, with different effects of the pheromone in play. An inverted AA,\nwith repulsive pheromones, was found to be the best fit for this particular\napplication. After considerable exploration, upon discovery of the victim, the\nautonomous agents further facilitate the rescue process by forming a relay\nnetwork, using the already deployed resources. Hence, the paper discusses a\ndetailed decision making model of the swarm, segmented into two primary phases,\nresponsible for the search and rescue respectively. Different aspects of the\nperformance of the agent swarm are analyzed, as a function of the spatial\ndimensions, the complexity of the search space, the deployed search group size,\nand the signal permeability of the obstacles in the area.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.08882v1"
    },
    {
        "title": "Top-k Dynamic Service Composition in Skyway Networks",
        "authors": [
            "Babar Shahzaad",
            "Athman Bouguettaya"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We propose a novel top-k service composition framework for drone services\nunder a dynamic environment. We develop a system model for formal modelling of\ndrone services in a skyway network. The composition process is accomplished in\ntwo phases, i.e., computing top-k compositions and extending and ranking top-k\ncompositions using probabilistic wait and recharge times under congestion\nconditions. We propose a top-k composition algorithm to compute the best\nservice composition plan meeting user's requirements. A set of experiments with\na real dataset is conducted to demonstrate the effectiveness of the proposed\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.09153v1"
    },
    {
        "title": "Resonating Minds -- Emergent Collaboration Through Hierarchical Active\n  Inference",
        "authors": [
            "Jan Pöppel",
            "Sebastian Kahl",
            "Stefan Kopp"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Working together on complex collaborative tasks requires agents to coordinate\ntheir actions. Doing this explicitly or completely prior to the actual\ninteraction is not always possible nor sufficient. Agents also need to\ncontinuously understand the current actions of others and quickly adapt their\nown behavior appropriately. Here we investigate how efficient, automatic\ncoordination processes at the level of mental states (intentions, goals), which\nwe call belief resonance, can lead to collaborative situated problem-solving.\nWe present a model of hierarchical active inference for collaborative agents\n(HAICA). It combines efficient Bayesian Theory of Mind processes with a\nperception-action system based on predictive processing and active inference.\nBelief resonance is realized by letting the inferred mental states of one agent\ninfluence another agent's predictive beliefs about its own goals and\nintentions. This way, the inferred mental states influence the agent's own task\nbehavior without explicit collaborative reasoning. We implement and evaluate\nthis model in the Overcooked domain, in which two agents with varying degrees\nof belief resonance team up to fulfill meal orders. Our results demonstrate\nthat agents based on HAICA achieve a team performance comparable to recent\nstate of the art approaches, while incurring much lower computational costs. We\nalso show that belief resonance is especially beneficial in settings were the\nagents have asymmetric knowledge about the environment. The results indicate\nthat belief resonance and active inference allow for quick and efficient agent\ncoordination, and thus can serve as a building block for collaborative\ncognitive agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.01210v1"
    },
    {
        "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
        "authors": [
            "Samuele Bolotta",
            "Guillaume Dumas"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This article introduces a three-axis framework indicating how AI can be\ninformed by biological examples of social learning mechanisms. We argue that\nthe complex human cognitive architecture owes a large portion of its expressive\npower to its ability to engage in social and cultural learning. However, the\nfield of AI has mostly embraced a solipsistic perspective on intelligence. We\nthus argue that social interactions not only are largely unexplored in this\nfield but also are an essential element of advanced cognitive ability, and\ntherefore constitute metaphorically the dark matter of AI. In the first\nsection, we discuss how social learning plays a key role in the development of\nintelligence. We do so by discussing social and cultural learning theories and\nempirical findings from social neuroscience. Then, we discuss three lines of\nresearch that fall under the umbrella of Social NeuroAI and can contribute to\ndeveloping socially intelligent embodied agents in complex environments. First,\nneuroscientific theories of cognitive architecture, such as the global\nworkspace theory and the attention schema theory, can enhance biological\nplausibility and help us understand how we could bridge individual and social\ntheories of intelligence. Second, intelligence occurs in time as opposed to\nover time, and this is naturally incorporated by dynamical systems. Third,\nembodiment has been demonstrated to provide more sophisticated array of\ncommunicative signals. To conclude, we discuss the example of active inference,\nwhich offers powerful insights for developing agents that possess biological\nrealism, can self-organize in time, and are socially embodied.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.15459v3"
    },
    {
        "title": "Learning Complex Spatial Behaviours in ABM: An Experimental\n  Observational Study",
        "authors": [
            "Sedar Olmez",
            "Dan Birks",
            "Alison Heppenstall"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Capturing and simulating intelligent adaptive behaviours within spatially\nexplicit individual-based models remains an ongoing challenge for researchers.\nWhile an ever-increasing abundance of real-world behavioural data are\ncollected, few approaches exist that can quantify and formalise key individual\nbehaviours and how they change over space and time. Consequently, commonly used\nagent decision-making frameworks, such as event-condition-action rules, are\noften required to focus only on a narrow range of behaviours. We argue that\nthese behavioural frameworks often do not reflect real-world scenarios and fail\nto capture how behaviours can develop in response to stimuli. There has been an\nincreased interest in Machine Learning methods and their potential to simulate\nintelligent adaptive behaviours in recent years. One method that is beginning\nto gain traction in this area is Reinforcement Learning (RL). This paper\nexplores how RL can be applied to create emergent agent behaviours using a\nsimple predator-prey Agent-Based Model (ABM). Running a series of simulations,\nwe demonstrate that agents trained using the novel Proximal Policy Optimisation\n(PPO) algorithm behave in ways that exhibit properties of real-world\nintelligent adaptive behaviours, such as hiding, evading and foraging.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.01099v1"
    },
    {
        "title": "Value Functions Factorization with Latent State Information Sharing in\n  Decentralized Multi-Agent Policy Gradients",
        "authors": [
            "Hanhan Zhou",
            "Tian Lan",
            "Vaneet Aggarwal"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Value function factorization via centralized training and decentralized\nexecution is promising for solving cooperative multi-agent reinforcement tasks.\nOne of the approaches in this area, QMIX, has become state-of-the-art and\nachieved the best performance on the StarCraft II micromanagement benchmark.\nHowever, the monotonic-mixing of per agent estimates in QMIX is known to\nrestrict the joint action Q-values it can represent, as well as the\ninsufficient global state information for single agent value function\nestimation, often resulting in suboptimality. To this end, we present LSF-SAC,\na novel framework that features a variational inference-based\ninformation-sharing mechanism as extra state information to assist individual\nagents in the value function factorization. We demonstrate that such latent\nindividual state information sharing can significantly expand the power of\nvalue function factorization, while fully decentralized execution can still be\nmaintained in LSF-SAC through a soft-actor-critic design. We evaluate LSF-SAC\non the StarCraft II micromanagement challenge and demonstrate that it\noutperforms several state-of-the-art methods in challenging collaborative\ntasks. We further set extensive ablation studies for locating the key factors\naccounting for its performance improvements. We believe that this new insight\ncan lead to new local value estimation methods and variational deep learning\nalgorithms. A demo video and code of implementation can be found at\nhttps://sites.google.com/view/sacmm.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.01247v3"
    },
    {
        "title": "Planning Not to Talk: Multiagent Systems that are Robust to\n  Communication Loss",
        "authors": [
            "Mustafa O. Karabag",
            "Cyrus Neary",
            "Ufuk Topcu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In a cooperative multiagent system, a collection of agents executes a joint\npolicy in order to achieve some common objective. The successful deployment of\nsuch systems hinges on the availability of reliable inter-agent communication.\nHowever, many sources of potential disruption to communication exist in\npractice, such as radio interference, hardware failure, and adversarial\nattacks. In this work, we develop joint policies for cooperative multiagent\nsystems that are robust to potential losses in communication. More\nspecifically, we develop joint policies for cooperative Markov games with\nreach-avoid objectives. First, we propose an algorithm for the decentralized\nexecution of joint policies during periods of communication loss. Next, we use\nthe total correlation of the state-action process induced by a joint policy as\na measure of the intrinsic dependencies between the agents. We then use this\nmeasure to lower-bound the performance of a joint policy when communication is\nlost. Finally, we present an algorithm that maximizes a proxy to this lower\nbound in order to synthesize minimum-dependency joint policies that are robust\nto communication loss. Numerical experiments show that the proposed\nminimum-dependency policies require minimal coordination between the agents\nwhile incurring little to no loss in performance; the total correlation value\nof the synthesized policy is one fifth of the total correlation value of the\nbaseline policy which does not take potential communication losses into\naccount. As a result, the performance of the minimum-dependency policies\nremains consistently high regardless of whether or not communication is\navailable. By contrast, the performance of the baseline policy decreases by\ntwenty percent when communication is lost.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06619v1"
    },
    {
        "title": "Solving Dynamic Principal-Agent Problems with a Rationally Inattentive\n  Principal",
        "authors": [
            "Tong Mu",
            "Stephan Zheng",
            "Alexander Trott"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Principal-Agent (PA) problems describe a broad class of economic\nrelationships characterized by misaligned incentives and asymmetric\ninformation. The Principal's problem is to find optimal incentives given the\navailable information, e.g., a manager setting optimal wages for its employees.\nWhereas the Principal is often assumed rational, comparatively little is known\nabout solutions when the Principal is boundedly rational, especially in the\nsequential setting, with multiple Agents, and with multiple information\nchannels. Here, we develop RIRL, a deep reinforcement learning framework that\nsolves such complex PA problems with a rationally inattentive Principal. Such a\nPrincipal incurs a cost for paying attention to information, which can model\nforms of bounded rationality. We use RIRL to analyze rich economic phenomena in\nmanager-employee relationships. In the single-step setting, 1) RIRL yields\nwages that are consistent with theoretical predictions; and 2) non-zero\nattention costs lead to simpler but less profitable wage structures, and\nincreased Agent welfare. In a sequential setting with multiple Agents, RIRL\nshows opposing consequences of the Principal's inattention to different\ninformation channels: 1) inattention to Agents' outputs closes wage gaps based\non ability differences; and 2) inattention to Agents' efforts induces a social\ndilemma dynamic in which Agents work harder, but essentially for free.\nMoreover, RIRL reveals non-trivial relationships between the Principal's\ninattention and Agent types, e.g., if Agents are prone to sub-optimal effort\nchoices, payment schedules are more sensitive to the Principal's attention\ncost. As such, RIRL can reveal novel economic relationships and enables\nprogress towards understanding the effects of bounded rationality in dynamic\nsettings.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.01691v2"
    },
    {
        "title": "Governance of Autonomous Agents on the Web: Challenges and Opportunities",
        "authors": [
            "Timotheus Kampik",
            "Adnane Mansour",
            "Olivier Boissier",
            "Sabrina Kirrane",
            "Julian Padget",
            "Terry R. Payne",
            "Munindar P. Singh",
            "Valentina Tamma",
            "Antoine Zimmermann"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The study of autonomous agents has a long tradition in the Multiagent Systems\nand the Semantic Web communities, with applications ranging from automating\nbusiness processes to personal assistants. More recently, the Web of Things\n(WoT), which is an extension of the Internet of Things (IoT) with metadata\nexpressed in Web standards, and its community provide further motivation for\npushing the autonomous agents research agenda forward. Although representing\nand reasoning about norms, policies and preferences is crucial to ensuring that\nautonomous agents act in a manner that satisfies stakeholder requirements,\nnormative concepts, policies and preferences have yet to be considered as\nfirst-class abstractions in Web-based multiagent systems. Towards this end,\nthis paper motivates the need for alignment and joint research across the\nMultiagent Systems, Semantic Web, and WoT communities, introduces a conceptual\nframework for governance of autonomous agents on the Web, and identifies\nseveral research challenges and opportunities.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.02574v1"
    },
    {
        "title": "Intelligent Autonomous Intersection Management",
        "authors": [
            "Udesh Gunarathna",
            "Shanika Karunasekara",
            "Renata Borovica-Gajic",
            "Egemen Tanin"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Connected Autonomous Vehicles will make autonomous intersection management a\nreality replacing traditional traffic signal control. Autonomous intersection\nmanagement requires time and speed adjustment of vehicles arriving at an\nintersection for collision-free passing through the intersection. Due to its\ncomputational complexity, this problem has been studied only when vehicle\narrival times towards the vicinity of the intersection are known beforehand,\nwhich limits the applicability of these solutions for real-time deployment. To\nsolve the real-time autonomous traffic intersection management problem, we\npropose a reinforcement learning (RL) based multiagent architecture and a novel\nRL algorithm coined multi-discount Q-learning. In multi-discount Q-learning, we\nintroduce a simple yet effective way to solve a Markov Decision Process by\npreserving both short-term and long-term goals, which is crucial for\ncollision-free speed control. Our empirical results show that our RL-based\nmultiagent solution can achieve near-optimal performance efficiently when\nminimizing the travel time through an intersection.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04224v1"
    },
    {
        "title": "Cooperative Solutions to Exploration Tasks Under Speed and Budget\n  Constraints",
        "authors": [
            " Karishma",
            "Shrisha Rao"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We present a multi-agent system where agents can cooperate to solve a system\nof dependent tasks, with agents having the capability to explore a solution\nspace, make inferences, as well as query for information under a limited\nbudget. Re-exploration of the solution space takes place by an agent when an\nolder solution expires and is thus able to adapt to dynamic changes in the\nenvironment. We investigate the effects of task dependencies, with\nhighly-dependent graph $G_{40}$ (a well-known program graph that contains $40$\nhighly interlinked nodes, each representing a task) and less-dependent graphs\n$G_{18}$ (a program graph that contains $18$ tasks with fewer links),\nincreasing the speed of the agents and the complexity of the problem space and\nthe query budgets available to agents. Specifically, we evaluate trade-offs\nbetween the agent's speed and query budget. During the experiments, we observed\nthat increasing the speed of a single agent improves the system performance to\na certain point only, and increasing the number of faster agents may not\nimprove the system performance due to task dependencies. Favoring faster agents\nduring budget allocation enhances the system performance, in line with the\n\"Matthew effect.\" We also observe that allocating more budget to a faster agent\ngives better performance for a less-dependent system, but increasing the number\nof faster agents gives a better performance for a highly-dependent system.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.05891v1"
    },
    {
        "title": "Learning to Mitigate AI Collusion on Economic Platforms",
        "authors": [
            "Gianluca Brero",
            "Nicolas Lepore",
            "Eric Mibuari",
            "David C. Parkes"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Algorithmic pricing on online e-commerce platforms raises the concern of\ntacit collusion, where reinforcement learning algorithms learn to set collusive\nprices in a decentralized manner and through nothing more than profit feedback.\nThis raises the question as to whether collusive pricing can be prevented\nthrough the design of suitable \"buy boxes,\" i.e., through the design of the\nrules that govern the elements of e-commerce sites that promote particular\nproducts and prices to consumers. In this paper, we demonstrate that\nreinforcement learning (RL) can also be used by platforms to learn buy box\nrules that are effective in preventing collusion by RL sellers. For this, we\nadopt the methodology of Stackelberg POMDPs, and demonstrate success in\nlearning robust rules that continue to provide high consumer welfare together\nwith sellers employing different behavior models or having out-of-distribution\ncosts for goods.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07106v2"
    },
    {
        "title": "Distributed Multi-Agent Reinforcement Learning with One-hop Neighbors\n  and Compute Straggler Mitigation",
        "authors": [
            "Baoqian Wang",
            "Junfei Xie",
            "Nikolay Atanasov"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Most multi-agent reinforcement learning (MARL) methods are limited in the\nscale of problems they can handle. With increasing numbers of agents, the\nnumber of training iterations required to find the optimal behaviors increases\nexponentially due to the exponentially growing joint state and action spaces.\nThis paper tackles this limitation by introducing a scalable MARL method called\nDistributed multi-Agent Reinforcement Learning with One-hop Neighbors (DARL1N).\nDARL1N is an off-policy actor-critic method that addresses the curse of\ndimensionality by restricting information exchanges among the agents to one-hop\nneighbors when representing value and policy functions. Each agent optimizes\nits value and policy functions over a one-hop neighborhood, significantly\nreducing the learning complexity, yet maintaining expressiveness by training\nwith varying neighbor numbers and states. This structure allows us to formulate\na distributed learning framework to further speed up the training procedure.\nDistributed computing systems, however, contain straggler compute nodes, which\nare slow or unresponsive due to communication bottlenecks, software or hardware\nproblems. To mitigate the detrimental straggler effect, we introduce a novel\ncoded distributed learning architecture, which leverages coding theory to\nimprove the resilience of the learning system to stragglers. Comprehensive\nexperiments show that DARL1N significantly reduces training time without\nsacrificing policy quality and is scalable as the number of agents increases.\nMoreover, the coded distributed learning architecture improves training\nefficiency in the presence of stragglers.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09019v3"
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Network Selection and Resource\n  Allocation in Heterogeneous multi-RAT Networks",
        "authors": [
            "Mhd Saria Allahham",
            "Alaa Awad Abdellatif",
            "Naram Mhaisen",
            "Amr Mohamed",
            "Aiman Erbad",
            "Mohsen Guizani"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The rapid production of mobile devices along with the wireless applications\nboom is continuing to evolve daily. This motivates the exploitation of wireless\nspectrum using multiple Radio Access Technologies (multi-RAT) and developing\ninnovative network selection techniques to cope with such intensive demand\nwhile improving Quality of Service (QoS). Thus, we propose a distributed\nframework for dynamic network selection at the edge level, and resource\nallocation at the Radio Access Network (RAN) level, while taking into\nconsideration diverse applications' characteristics. In particular, our\nframework employs a deep Multi-Agent Reinforcement Learning (DMARL) algorithm,\nthat aims to maximize the edge nodes' quality of experience while extending the\nbattery lifetime of the nodes and leveraging adaptive compression schemes.\nIndeed, our framework enables data transfer from the network's edge nodes, with\nmulti-RAT capabilities, to the cloud in a cost and energy-efficient manner,\nwhile maintaining QoS requirements of different supported applications. Our\nresults depict that our solution outperforms state-of-the-art techniques of\nnetwork selection in terms of energy consumption, latency, and cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10308v1"
    },
    {
        "title": "Optimal Multi-Agent Path Finding for Precedence Constrained Planning\n  Tasks",
        "authors": [
            "Kushal Kedia",
            "Rajat Kumar Jenamani",
            "Aritra Hazra",
            "Partha Pratim Chakrabarti"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-Agent Path Finding (MAPF) is the problem of finding collision-free\npaths for multiple agents from their start locations to end locations. We\nconsider an extension to this problem, Precedence Constrained Multi-Agent Path\nFinding (PC-MAPF), wherein agents are assigned a sequence of planning tasks\nthat contain precedence constraints between them. PC-MAPF has various\napplications, for example in multi-agent pickup and delivery problems where\nsome objects might require multiple agents to collaboratively pickup and move\nthem in unison. Precedence constraints also arise in warehouse assembly\nproblems where before a manufacturing task can begin, its input resources must\nbe manufactured and delivered. We propose a novel algorithm, Precedence\nConstrained Conflict Based Search (PC-CBS), which finds makespan-optimal\nsolutions for this class of problems. PC-CBS utilizes a Precedence-Constrained\nTask-Graph to define valid intervals for each planning task and updates them\nwhen precedence conflicts are encountered. We benchmark the performance of this\nalgorithm over various warehouse assembly, and multi-agent pickup and delivery\ntasks, and use it to evaluate the sub-optimality of a recently proposed\nefficient baseline.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10449v1"
    },
    {
        "title": "A Survey of Ad Hoc Teamwork Research",
        "authors": [
            "Reuth Mirsky",
            "Ignacio Carlucho",
            "Arrasy Rahman",
            "Elliot Fosong",
            "William Macke",
            "Mohan Sridharan",
            "Peter Stone",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Ad hoc teamwork is the research problem of designing agents that can\ncollaborate with new teammates without prior coordination. This survey makes a\ntwo-fold contribution: First, it provides a structured description of the\ndifferent facets of the ad hoc teamwork problem. Second, it discusses the\nprogress that has been made in the field so far, and identifies the immediate\nand long-term open problems that need to be addressed in ad hoc teamwork.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10450v3"
    },
    {
        "title": "A Decentralized Communication Framework based on Dual-Level Recurrence\n  for Multi-Agent Reinforcement Learning",
        "authors": [
            "Jingchen Li",
            "Haobin Shi",
            "Kao-Shing Hwang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We propose a model enabling decentralized multiple agents to share their\nperception of environment in a fair and adaptive way. In our model, both the\ncurrent message and historical observation are taken into account, and they are\nhandled in the same recurrent model but in different forms. We present a\ndual-level recurrent communication framework for multi-agent systems, in which\nthe first recurrence occurs in the communication sequence and is used to\ntransmit communication data among agents, while the second recurrence is based\non the time sequence and combines the historical observations for each agent.\nThe developed communication flow separates communication messages from memories\nbut allows agents to share their historical observations by the dual-level\nrecurrence. This design makes agents adapt to changeable communication objects,\nwhile the communication results are fair to these agents. We provide a\nsufficient discussion about our method in both partially observable and fully\nobservable environments. The results of several experiments suggest our method\noutperforms the existing decentralized communication frameworks and the\ncorresponding centralized training method.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10612v1"
    },
    {
        "title": "Incorporating social norms into a configurable agent-based model of the\n  decision to perform commuting behaviour",
        "authors": [
            "Robert Greener",
            "Daniel Lewis",
            "Jon Reades",
            "Simon Miles",
            "Steven Cummins"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Interventions to increase active commuting have been recommended as a method\nto increase population physical activity, but evidence is mixed. Social norms\nrelated to travel behaviour may influence the uptake of active commuting\ninterventions but are rarely considered in their design and evaluation. In this\nstudy we develop an agent-based model that incorporates social norms related to\ntravel behaviour and demonstrate the utility of this through implementing\ncar-free Wednesdays. A synthetic population of Waltham Forest, London, UK was\ngenerated using a microsimulation approach with data from the UK Census 2011\nand UK HLS datasets. An agent-based model was created using this synthetic\npopulation which modelled how the actions of peers and neighbours, subculture,\nhabit, weather, bicycle ownership, car ownership, environmental supportiveness,\nand congestion affect the decision to trave. The developed model (MOTIVATE) is\na configurable agent-based model where social norms related to travel behaviour\nare used to provide a more realistic representation of the socio-ecological\nsystems in which active commuting interventions may be deployed. The utility of\nthis model is demonstrated using car-free days as a hypothetical intervention.\nIn the control scenario, the odds of active travel were plausible at 0.091 (89%\nHPDI: [0.091, 0.091]). Compared to the control scenario, the odds of active\ntravel were increased by 70.3% (89% HPDI: [70.3%, 70.3%]), in the intervention\nscenario, on non-car-free days; the effect is sustained to non-car-free days.\nThe model is a useful tool for investigating the effect of how social networks\nand social norms influence the effectiveness of various interventions. If\nconfigured using real-world built environment data, it may be useful for\ninvestigating how social norms interact with the built environment to cause the\nemergence of commuting conventions.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.11149v3"
    },
    {
        "title": "Evacuation trials from a double-deck electric train unit: Experimental\n  data and sensitivity analysis",
        "authors": [
            "Hana Najmanová",
            "Veronika Pešková",
            "Lukáš Kuklík",
            "Marek Bukáček",
            "Pavel Hrabák",
            "Daniel Vašata"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Passenger trains represent a challenging environment in emergencies, with\nspecific evacuation conditions resulting from the typical layout and interior\ndesign inherent to public transportation vehicles. This paper describes a\ndataset obtained in a full-scale controlled experiment emulating the emergency\nevacuation of a double-deck electric unit railcar carried out in Prague in\n2018. 15 evacuation trials involving 91 participants were conducted under\nvarious evacuation scenarios considering different compositions of passenger\ncrowd, exit widths, and exit types (e.g. egress to a high platform, to an open\nrail line using stairs, and a 750 mm jump without any supporting equipment).\nThe study's main goals were to collect experimental data on the movement\nconditions in the railcar and to study the impact of various boundary\nconditions on evacuation process and total evacuation time. Movement\ncharacteristics (exit flows, speeds) and human behaviour (pre-movement\nactivities, exiting behaviours) were also analysed.\n  The data obtained was used to validate and adjust a Pathfinder model to\ncapture important aspects of evacuation from the railcar. Furthermore, a series\nof simulations using this model was performed to provide sensitivity analysis\nof the influence of crowd composition, exit width, and exit type on total\nevacuation time. As a key finding, we can conclude that for the case of a\nstandard exit path (platform or stairs) the width of the main exit had the\ngreatest impact on total evacuation time, however, crowd composition played the\nprevailing role in evacuation scenarios involving a jump.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.11460v1"
    },
    {
        "title": "CTDS: Centralized Teacher with Decentralized Student for Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Jian Zhao",
            "Xunhan Hu",
            "Mingyu Yang",
            "Wengang Zhou",
            "Jiangcheng Zhu",
            "Houqiang Li"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Due to the partial observability and communication constraints in many\nmulti-agent reinforcement learning (MARL) tasks, centralized training with\ndecentralized execution (CTDE) has become one of the most widely used MARL\nparadigms. In CTDE, centralized information is dedicated to learning the\nallocation of the team reward with a mixing network, while the learning of\nindividual Q-values is usually based on local observations. The insufficient\nutility of global observation will degrade performance in challenging\nenvironments. To this end, this work proposes a novel Centralized Teacher with\nDecentralized Student (CTDS) framework, which consists of a teacher model and a\nstudent model. Specifically, the teacher model allocates the team reward by\nlearning individual Q-values conditioned on global observation, while the\nstudent model utilizes the partial observations to approximate the Q-values\nestimated by the teacher model. In this way, CTDS balances the full utilization\nof global observation during training and the feasibility of decentralized\nexecution for online inference. Our CTDS framework is generic which is ready to\nbe applied upon existing CTDE methods to boost their performance. We conduct\nexperiments on a challenging set of StarCraft II micromanagement tasks to test\nthe effectiveness of our method and the results show that CTDS outperforms the\nexisting value-based MARL methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.08412v1"
    },
    {
        "title": "PMIC: Improving Multi-Agent Reinforcement Learning with Progressive\n  Mutual Information Collaboration",
        "authors": [
            "Pengyi Li",
            "Hongyao Tang",
            "Tianpei Yang",
            "Xiaotian Hao",
            "Tong Sang",
            "Yan Zheng",
            "Jianye Hao",
            "Matthew E. Taylor",
            "Wenyuan Tao",
            "Zhen Wang",
            "Fazl Barez"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Learning to collaborate is critical in Multi-Agent Reinforcement Learning\n(MARL). Previous works promote collaboration by maximizing the correlation of\nagents' behaviors, which is typically characterized by Mutual Information (MI)\nin different forms. However, we reveal sub-optimal collaborative behaviors also\nemerge with strong correlations, and simply maximizing the MI can,\nsurprisingly, hinder the learning towards better collaboration. To address this\nissue, we propose a novel MARL framework, called Progressive Mutual Information\nCollaboration (PMIC), for more effective MI-driven collaboration. PMIC uses a\nnew collaboration criterion measured by the MI between global states and joint\nactions. Based on this criterion, the key idea of PMIC is maximizing the MI\nassociated with superior collaborative behaviors and minimizing the MI\nassociated with inferior ones. The two MI objectives play complementary roles\nby facilitating better collaborations while avoiding falling into sub-optimal\nones. Experiments on a wide range of MARL benchmarks show the superior\nperformance of PMIC compared with other algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.08553v4"
    },
    {
        "title": "A Survey of Multi-Agent Deep Reinforcement Learning with Communication",
        "authors": [
            "Changxi Zhu",
            "Mehdi Dastani",
            "Shihan Wang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Communication is an effective mechanism for coordinating the behaviors of\nmultiple agents, broadening their views of the environment, and to support\ntheir collaborations. In the field of multi-agent deep reinforcement learning\n(MADRL), agents can improve the overall learning performance and achieve their\nobjectives by communication. Agents can communicate various types of messages,\neither to all agents or to specific agent groups, or conditioned on specific\nconstraints. With the growing body of research work in MADRL with communication\n(Comm-MADRL), there is a lack of a systematic and structural approach to\ndistinguish and classify existing Comm-MADRL approaches. In this paper, we\nsurvey recent works in the Comm-MADRL field and consider various aspects of\ncommunication that can play a role in designing and developing multi-agent\nreinforcement learning systems. With these aspects in mind, we propose 9\ndimensions along which Comm-MADRL approaches can be analyzed, developed, and\ncompared. By projecting existing works into the multi-dimensional space, we\ndiscover interesting trends. We also propose some novel directions for\ndesigning future Comm-MADRL systems through exploring possible combinations of\nthe dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.08975v2"
    },
    {
        "title": "Strategic Maneuver and Disruption with Reinforcement Learning Approaches\n  for Multi-Agent Coordination",
        "authors": [
            "Derrik E. Asher",
            "Anjon Basak",
            "Rolando Fernandez",
            "Piyush K. Sharma",
            "Erin G. Zaroukian",
            "Christopher D. Hsu",
            "Michael R. Dorothy",
            "Thomas Mahre",
            "Gerardo Galindo",
            "Luke Frerichs",
            "John Rogers",
            "John Fossaceca"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Reinforcement learning (RL) approaches can illuminate emergent behaviors that\nfacilitate coordination across teams of agents as part of a multi-agent system\n(MAS), which can provide windows of opportunity in various military tasks.\nTechnologically advancing adversaries pose substantial risks to a friendly\nnation's interests and resources. Superior resources alone are not enough to\ndefeat adversaries in modern complex environments because adversaries create\nstandoff in multiple domains against predictable military doctrine-based\nmaneuvers. Therefore, as part of a defense strategy, friendly forces must use\nstrategic maneuvers and disruption to gain superiority in complex multi-faceted\ndomains such as multi-domain operations (MDO). One promising avenue for\nimplementing strategic maneuver and disruption to gain superiority over\nadversaries is through coordination of MAS in future military operations. In\nthis paper, we present overviews of prominent works in the RL domain with their\nstrengths and weaknesses for overcoming the challenges associated with\nperforming autonomous strategic maneuver and disruption in military contexts.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.09565v1"
    },
    {
        "title": "Decentralizing Permissioned Blockchain with Delay Towers",
        "authors": [
            "Shashank Motepalli",
            "Hans-Arno Jacobsen"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Growing excitement around permissionless blockchains is uncovering its latent\nscalability concerns. Permissioned blockchains offer high transactional\nthroughput and low latencies while compromising decentralization. In the quest\nfor a decentralized, scalable blockchain fabric, i.e., to offer the scalability\nof permissioned blockchain in a permissionless setting, we present L4L to\nencourage decentralization over the permissioned Libra network without\ncompromising its sustainability. L4L employs delay towers, -- puzzle towers\nthat leverage verifiable delay functions -- for establishing identity in a\npermissionless setting. Delay towers cannot be parallelized due to their\nsequential execution, making them an eco-friendly alternative. We also discuss\nmethodologies to replace validators participating in consensus to promote\ncompliant behavior. Our evaluations found that the cost of enabling\ndecentralization over permissioned networks is almost negligible. Furthermore,\ndelay towers offer an alternative to existing permissionless consensus\nmechanisms without requiring airdrops or pre-sale of tokens.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.09714v1"
    },
    {
        "title": "Continuous Flow Model of a Historical Battle: A Fresh Look at Pickett's\n  charge",
        "authors": [
            "Jonathan Poggie",
            "Sorin A. Matei",
            "Robert Kirchubel"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  A continuous flow model of infantry behavior, based on conservation of\nindividuals and tracking of subunit identity, has been developed in sufficient\ndetail that it can now be applied to a realistic simulation of a historical\nbattle. Pickett's charge during the 1863 Battle of Gettysburg, Pennsylvania in\nthe U.S. Civil War was chosen as an initial application of the model. This\nscenario is a good test of the current mathematical model because many modern\nmilitary tactics were employed, in a context where the action took place on\nfoot or horseback, and the historical map and troop numbers are available.\nCompared to a discrete agent model, the flow model was found to better capture\nthe interaction of the forces with the terrain and each other. A brigade-level\nsimulation, faithful to the details of the historical events, was performed.\nThe main source of asymmetry in the numbers of casualties was found to be the\ninability of the Confederate forces to use effective ranged fire while they\nwere moving. Comparison of simulations with and without terrain effects showed\nthat they slow the pace of battle and favor the defenders, exposing the\nattackers to heavy ranged fire for an extended period. A statistical analysis\nof possible outcomes for an ensemble of 1000 randomized perturbations of the\nbaseline brigade-level scenario was carried out. Consistent with historical\nevents, it was found that only 6 percent of the scenarios resulted in an\noutcome that could be considered a Confederate victory.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.11035v1"
    },
    {
        "title": "BESSIE: A Behavior and Epidemic Simulator for Use With Synthetic\n  Populations",
        "authors": [
            "Henning S Mortveit",
            "Stephen Adams",
            "Faraz Dadgostari",
            "Samarth Swarup",
            "Peter Beling"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we present BESSIE (Behavior and Epidemic Simulator for\nSynthetic Information Environments), an open source, agent-based simulator for\nCOVID-type epidemics. BESSIE uses a synthetic population where each person has\ndemographic attributes, belong to a household, and has a base activity- and\nvisit schedule covering seven days. The simulated disease spreads through\ncontacts that arise from joint visits to the locations where activities take\nplace. The simulation model has a plugin-type programmable behavioral model\nwhere, based on the dynamics and observables tracked by the simulator, agents\ndecide on actions such as wearing a mask, engaging in social distancing, or\nrefraining from certain activity types by staying at home instead. The plugins\nare supplied as Python code. To the best of our knowledge, BESSIE is a unique\nsimulator supporting this feature set, and most certainly as open software.\n  To illustrate the use of BESSIE, we provide a COVID-relevant example\ndemonstrating some of its capabilities. The example uses a synthetic population\nfor the City of Charlottesville, Virginia. Both this population and the Python\nplugin modules used in the example are made available. The Python\nimplementation, which can run on anything from a laptop to a cluster, is made\navailable under the Apache 2.0 license\n(https://www.apache.org/licenses/LICENSE-2.0.html). The example population\naccompanying this publication is made available under the CC BY 4.0 license\n(https://creativecommons.org/licenses/by/4.0/).\n",
        "pdf_link": "http://arxiv.org/pdf/2203.11414v1"
    },
    {
        "title": "Heterogeneous Ground-Air Autonomous Vehicle Networking in Austere\n  Environments: Practical Implementation of a Mesh Network in the DARPA\n  Subterranean Challenge",
        "authors": [
            "Harel Biggie",
            "Steve McGuire"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Implementing a wireless mesh network in a real-life scenario requires a\nsignificant systems engineering effort to turn a network concept into a\ncomplete system. This paper presents an evaluation of a fielded system within\nthe DARPA Subterranean (SubT) Challenge Final Event that contributed to a 3rd\nplace finish. Our system included a team of air and ground robots, deployable\nmesh extender nodes, and a human operator base station. This paper presents a\nreal-world evaluation of a stack optimized for air and ground robotic\nexploration in a RF-limited environment under practical system design\nlimitations. Our highly customizable solution utilizes a minimum of non-free\ncomponents with form factor options suited for UAV operations and provides\ninsight into network operations at all levels. We present performance metrics\nbased on our performance in the Final Event of the DARPA Subterranean\nChallenge, demonstrating the practical successes and limitations of our\napproach, as well as a set of lessons learned and suggestions for future\nimprovements.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.12832v1"
    },
    {
        "title": "Multi-Agent Spatial Predictive Control with Application to Drone\n  Flocking (Extended Version)",
        "authors": [
            "Andreas Brandstätter",
            "Scott A. Smolka",
            "Scott D. Stoller",
            "Ashish Tiwari",
            "Radu Grosu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We introduce the novel concept of Spatial Predictive Control (SPC) to solve\nthe following problem: given a collection of agents (e.g., drones) with\npositional low-level controllers (LLCs) and a mission-specific distributed cost\nfunction, how can a distributed controller achieve and maintain cost-function\nminimization without a plant model and only positional observations of the\nenvironment? Our fully distributed SPC controller is based strictly on the\nposition of the agent itself and on those of its neighboring agents. This\ninformation is used in every time-step to compute the gradient of the cost\nfunction and to perform a spatial look-ahead to predict the best next target\nposition for the LLC. Using a high-fidelity simulation environment, we show\nthat SPC outperforms the most closely related class of controllers, Potential\nField Controllers, on the drone flocking problem. We also show that SPC is able\nto cope with a potential sim-to-real transfer gap by demonstrating its\nperformance on real hardware, namely our implementation of flocking using nine\nCrazyflie 2.1 drones.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.16960v1"
    },
    {
        "title": "Diffusion of Information on Networked Lattices by Gossip",
        "authors": [
            "Hans Riess",
            "Robert Ghrist"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We study time-dependent dynamics on a network of order lattices, where\nstructure-preserving lattice maps are used to fuse lattice-valued data over\nvertices and edges. The principal contribution is a novel asynchronous\nLaplacian, generalizing the usual graph Laplacian, adapted to a network of\nheterogeneous lattices. The resulting gossip algorithm is shown to converge\nasymptotically to stable \"harmonic\" distributions of lattice data. This general\ntheorem is applicable to several general problems, including lattice-valued\nconsensus, Kripke semantics, and threat detection, all using asynchronous local\nupdate rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.00167v2"
    },
    {
        "title": "Automated generalisation of buildings using CartAGen platform",
        "authors": [
            "Jagadish Boodala",
            "Onkar Dikshit",
            "Nagarajan Balasubramanian"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we present a methodology to automatically derive the\ngeneralised representations of buildings at scales 1:25K, 1:50K, and to\ndelineate the urban area for 1:250K scale representation. These generalised\nrepresentations are derived from 1:10K scale. The automatic generalisation\nprocesses are realised using the specific algorithms and the generalisation\nmodels available in the CartAGen (CARTographic Agent GENeralisation) platform.\nThe CartAGen is an open source map generalisation platform developed by IGN\nFrance. The proposed methodology in this paper is evaluated using the data\nproducts available from the Ordnance Survey, UK, and the Survey of India,\nIndia. This study investigates the applicability of the CartAGen platform for\ngeneralising the data products which have been excluded from the investigations\nby IGN France. This paper discusses the modifications required for such data\nproducts.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.01544v1"
    },
    {
        "title": "Deep Graphic FBSDEs for Opinion Dynamics Stochastic Control",
        "authors": [
            "Tianrong Chen",
            "Ziyi Wang",
            "Evangelos A. Theodorou"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we present a scalable deep learning approach to solve opinion\ndynamics stochastic optimal control problems with mean field term coupling in\nthe dynamics and cost function. Our approach relies on the probabilistic\nrepresentation of the solution of the Hamilton-Jacobi-Bellman partial\ndifferential equation. Grounded on the nonlinear version of the Feynman-Kac\nlemma, the solutions of the Hamilton-Jacobi-Bellman partial differential\nequation are linked to the solution of Forward-Backward Stochastic Differential\nEquations. These equations can be solved numerically using a novel deep neural\nnetwork with architecture tailored to the problem in consideration. The\nresulting algorithm is tested on a polarized opinion consensus experiment. The\nlarge-scale (10K) agents experiment validates the scalability and\ngeneralizability of our algorithm. The proposed framework opens up the\npossibility for future applications on extremely large-scale problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.02506v3"
    },
    {
        "title": "Massive Twinning to Enhance Emergent Intelligence",
        "authors": [
            "Siyu Yuan",
            "Bin Han",
            "Dennis Krummacker",
            "Hans D. Schotten"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  As a complement to conventional AI solutions, emergent intelligence (EI)\nexhibits competitiveness in 6G IIoT scenario for its various outstanding\nfeatures including robustness, protection to privacy, and scalability. However,\ndespite the low computational complexity, EI is challenged by its high demand\nof data traffic in massive deployment. We propose to leverage massive twinning,\nwhich 6G is envisaged to support, to reduce the data traffic in EI and\ntherewith enhance its performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.09316v2"
    },
    {
        "title": "Embracing AWKWARD! Real-time Adjustment of Reactive Plans Using Social\n  Norms",
        "authors": [
            "Leila Methnani",
            "Andreas Antoniades",
            "Andreas Theodorou"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper presents the AWKWARD architecture for the development of hybrid\nagents in Multi-Agent Systems. AWKWARD agents can have their plans\nre-configured in real time to align with social role requirements under\nchanging environmental and social circumstances. The proposed hybrid\narchitecture makes use of Behaviour Oriented Design (BOD) to develop agents\nwith reactive planning and of the well-established OperA framework to provide\norganisational, social, and interaction definitions in order to validate and\nadjust agents' behaviours. Together, OperA and BOD can achieve real-time\nadjustment of agent plans for evolving social roles, while providing the\nadditional benefit of transparency into the interactions that drive this\nbehavioural change in individual agents. We present this architecture to\nmotivate the bridging between traditional symbolic- and behaviour-based AI\ncommunities, where such combined solutions can help MAS researchers in their\npursuit of building stronger, more robust intelligent agent teams. We use\nDOTA2, a game where success is heavily dependent on social interactions, as a\nmedium to demonstrate a sample implementation of our proposed hybrid\narchitecture.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.10740v3"
    },
    {
        "title": "Extracting Symbolic Models of Collective Behaviors with Graph Neural\n  Networks and Macro-Micro Evolution",
        "authors": [
            "Stephen Powers",
            "Carlo Pinciroli"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Collective behaviors are typically hard to model. The scale of the swarm, the\nlarge number of interactions, and the richness and complexity of the behaviors\nare factors that make it difficult to distill a collective behavior into simple\nsymbolic expressions. In this paper, we propose a novel approach to symbolic\nregression designed to facilitate such modeling. Using raw and post-processed\ndata as an input, our approach produces viable symbolic expressions that\nclosely model the target behavior. Our approach is composed of two phases. In\nthe first, a graph neural network (GNN) is trained to extract an approximation\nof the target behavior. In the second phase, the GNN is used to produce data\nfor a nested evolutionary algorithm called macro-micro evolution (MME). The\nmacro layer of this algorithm selects candidate symbolic expressions, while the\nmicro layer tunes its parameters. Experimental evaluation shows that our\napproach outperforms competing solutions for symbolic regression, making it\npossible to extract compact expressions for complex swarm behaviors.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.00614v1"
    },
    {
        "title": "Real-Time BDI Agents: a model and its implementation",
        "authors": [
            "Andrea Traldi",
            "Francesco Bruschetti",
            "Marco Robol",
            "Marco Roveri",
            "Paolo Giorgini"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The BDI model proved to be effective for developing applications requiring\nhigh-levels of autonomy and to deal with the complexity and unpredictability of\nreal-world scenarios. The model, however, has significant limitations in\nreacting and handling contingencies within the given real-time constraints.\nWithout an explicit representation of time, existing real-time BDI\nimplementations overlook the temporal implications during the agent's decision\nprocess that may result in delays or unresponsiveness of the system when it\ngets overloaded. In this paper, we redefine the BDI agent control loop inspired\nby well established algorithms for real-time systems to ensure a proper\nreaction of agents and their effective application in typical real-time\ndomains. Our model proposes an effective real-time management of goals, plans,\nand actions with respect to time constraints and resources availability. We\npropose an implementation of the model for a resource-collection video-game and\nwe validate the approach against a set of significant scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.00979v1"
    },
    {
        "title": "Creating Teams of Simple Agents for Specified Tasks: A Computational\n  Complexity Perspective",
        "authors": [
            "T. Wareham"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Teams of interacting and co-operating agents have been proposed as an\nefficient and robust alternative to monolithic centralized control for carrying\nout specified tasks in a variety of applications. A number of different team\nand agent architectures have been investigated, e.g., teams based on single vs\nmultiple behaviorally-distinct types of agents (homogeneous vs heterogeneous\nteams), simple vs complex agents, direct vs indirect agent-to-agent\ncommunication. A consensus is emerging that (1) heterogeneous teams composed of\nsimple agents that communicate indirectly are preferable and (2) automated\nmethods for verifying and designing such teams are necessary. In this paper, we\nuse computational complexity analysis to assess viable algorithmic options for\nsuch automated methods for various types of teams. Building on recent\ncomplexity analyses addressing related questions in swarm robotics, we prove\nthat automated team verification and design are by large both exact and\napproximate polynomial-time intractable in general for the most basic types of\nhomogeneous and heterogeneous teams consisting of simple agents that\ncommunicate indirectly. Our results suggest that tractability for these\nproblems must be sought relative to additional restrictions on teams, agents,\noperating environments, and tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.02061v1"
    },
    {
        "title": "HARL: A Novel Hierachical Adversary Reinforcement Learning for\n  Automoumous Intersection Management",
        "authors": [
            "Guanzhou Li",
            "Jianping Wu",
            "Yujing He"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  As an emerging technology, Connected Autonomous Vehicles (CAVs) are believed\nto have the ability to move through intersections in a faster and safer manner,\nthrough effective Vehicle-to-Everything (V2X) communication and global\nobservation. Autonomous intersection management is a key path to efficient\ncrossing at intersections, which reduces unnecessary slowdowns and stops\nthrough adaptive decision process of each CAV, enabling fuller utilization of\nthe intersection space. Distributed reinforcement learning (DRL) offers a\nflexible, end-to-end model for AIM, adapting for many intersection scenarios.\nWhile DRL is prone to collisions as the actions of multiple sides in the\ncomplicated interactions are sampled from a generic policy, restricting the\napplication of DRL in realistic scenario. To address this, we propose a\nhierarchical RL framework where models at different levels vary in receptive\nscope, action step length, and feedback period of reward. The upper layer model\naccelerate CAVs to prevent them from being clashed, while the lower layer model\nadjust the trends from upper layer model to avoid the change of mobile state\ncausing new conflicts. And the real action of CAV at each step is co-determined\nby the trends from both levels, forming a real-time balance in the adversarial\nprocess. The proposed model is proven effective in the experiment undertaken in\na complicated intersection with 4 branches and 4 lanes each branch, and show\nbetter performance compared with baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.02428v4"
    },
    {
        "title": "Learning Scalable Policies over Graphs for Multi-Robot Task Allocation\n  using Capsule Attention Networks",
        "authors": [
            "Steve Paul",
            "Payam Ghassemi",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper presents a novel graph reinforcement learning (RL) architecture to\nsolve multi-robot task allocation (MRTA) problems that involve tasks with\ndeadlines and workload, and robot constraints such as work capacity. While\ndrawing motivation from recent graph learning methods that learn to solve\ncombinatorial optimization (CO) problems such as multi-Traveling Salesman and\nVehicle Routing Problems using RL, this paper seeks to provide better\nperformance (compared to non-learning methods) and important scalability\n(compared to existing learning architectures) for the stated class of MRTA\nproblems. The proposed neural architecture, called Capsule Attention-based\nMechanism or CapAM acts as the policy network, and includes three main\ncomponents: 1) an encoder: a Capsule Network based node embedding model to\nrepresent each task as a learnable feature vector; 2) a decoder: an\nattention-based model to facilitate a sequential output; and 3) context: that\nencodes the states of the mission and the robots. To train the CapAM model, the\npolicy-gradient method based on REINFORCE is used. When evaluated over unseen\nscenarios, CapAM demonstrates better task completion performance and $>$10\ntimes faster decision-making compared to standard non-learning based online\nMRTA methods. CapAM's advantage in generalizability, and scalability to test\nproblems of size larger than those used in training, are also successfully\ndemonstrated in comparison to a popular approach for learning to solve CO\nproblems, namely the purely attention mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.03321v1"
    },
    {
        "title": "Concepts and Algorithms for Agent-based Decentralized and Integrated\n  Scheduling of Production and Auxiliary Processes",
        "authors": [
            "Felix Gehlhoff",
            "Alexander Fay"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Individualized products and shorter product life cycles have driven companies\nto rethink traditional mass production. New concepts like Industry 4.0 foster\nthe advent of decentralized production control and distribution of information.\nA promising technology for realizing such scenarios are Multi-agent systems.\nThis contribution analyses the requirements for an agent-based decentralized\nand integrated scheduling approach. Part of the requirements is to develop a\nlinearly scaling communication architecture, as the communication between the\nagents is a major driver of the scheduling execution time. The approach\nschedules production, transportation, buffering and shared resource operations\nsuch as tools in an integrated manner to account for interdependencies between\nthem. Part of the logistics requirements reflect constraints for large\nworkpieces such as buffer scarcity. The approach aims at providing a general\nsolution that is also applicable to large system sizes that, for example, can\nbe found in production networks with multiple companies. Further, it is\napplicable for different kinds of factory organization (flow shop, job shop\netc.). The approach is explained using an example based on industrial\nrequirements. Experiments have been conducted to evaluate the scheduling\nexecution time. The results show the approach's linear scaling behavior. Also,\nanalyses of the concurrent negotiation ability are conducted.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04461v2"
    },
    {
        "title": "MOPaC: The Multiple Offers Protocol for Multilateral Negotiations with\n  Partial Consensus",
        "authors": [
            "Pradeep K. Murukannaiah",
            "Catholijn M. Jonker"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Existing protocols for multilateral negotiation require a full consensus\namong the negotiating parties. In contrast, we propose a protocol for\nmultilateral negotiation that allows partial consensus, wherein only a subset\nof the negotiating parties can reach an agreement. We motivate problems that\nrequire such a protocol and describe the protocol formally.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.06678v1"
    },
    {
        "title": "Random Coordinate Descent for Resource Allocation in Open Multi-Agent\n  Systems",
        "authors": [
            "Charles Monnoyer de Galland",
            "Renato Vizuete",
            "Julien M. Hendrickx",
            "Elena Panteley",
            "Paolo Frasca"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We propose a method for analyzing the distributed random coordinate descent\nalgorithm for solving separable resource allocation problems in the context of\nan open multiagent system, where agents can be replaced during the process. In\nparticular, we characterize the evolution of the distance to the minimizer in\nexpectation by following a time-varying optimization approach which builds on\ntwo components. First, we establish the linear convergence of the algorithm in\nclosed systems, in terms of the estimate towards the minimizer, for general\ngraphs and appropriate step-size. Second, we estimate the change of the optimal\nsolution after a replacement, in order to evaluate its effect on the distance\nbetween the current estimate and the minimizer. From these two elements, we\nderive stability conditions in open systems and establish the linear\nconvergence of the algorithm towards a steady-state expected error. Our results\nenable to characterize the trade-off between speed of convergence and\nrobustness to agent replacements, under the assumptions that local functions\nare smooth, strongly convex, and have their minimizers located in a given ball.\nThe approach proposed in this paper can moreover be extended to other\nalgorithms guaranteeing linear convergence in closed system.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10259v2"
    },
    {
        "title": "Learning to Advise and Learning from Advice in Cooperative Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Yue Jin",
            "Shuangqing Wei",
            "Jian Yuan",
            "Xudong Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Learning to coordinate is a daunting problem in multi-agent reinforcement\nlearning (MARL). Previous works have explored it from many facets, including\ncognition between agents, credit assignment, communication, expert\ndemonstration, etc. However, less attention were paid to agents' decision\nstructure and the hierarchy of coordination. In this paper, we explore the\nspatiotemporal structure of agents' decisions and consider the hierarchy of\ncoordination from the perspective of multilevel emergence dynamics, based on\nwhich a novel approach, Learning to Advise and Learning from Advice (LALA), is\nproposed to improve MARL. Specifically, by distinguishing the hierarchy of\ncoordination, we propose to enhance decision coordination at meso level with an\nadvisor and leverage a policy discriminator to advise agents' learning at micro\nlevel. The advisor learns to aggregate decision information in both spatial and\ntemporal domains and generates coordinated decisions by employing a\nspatiotemporal dual graph convolutional neural network with a task-oriented\nobjective function. Each agent learns from the advice via a policy generative\nadversarial learning method where a discriminator distinguishes between the\npolicies of the agent and the advisor and boosts both of them based on its\njudgement. Experimental results indicate the advantage of LALA over baseline\napproaches in terms of both learning efficiency and coordination capability.\nCoordination mechanism is investigated from the perspective of multilevel\nemergence dynamics and mutual information point of view, which provides a novel\nperspective and method to analyze and improve MARL algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.11163v1"
    },
    {
        "title": "Maximising the Influence of Temporary Participants in Opinion Formation",
        "authors": [
            "Zhiqiang Zhuang",
            "Kewen Wang",
            "Zhe Wang",
            "Junhu Wang",
            "Yinong Yang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  DeGroot-style opinion formation presumes a continuous interaction among\nagents of a social network. Hence, it cannot handle agents external to the\nsocial network that interact only temporarily with the permanent ones. Many\nreal-world organisations and individuals fall into such a category. For\ninstance, a company tries to persuade as many as possible to buy its products\nand, due to various constraints, can only exert its influence for a limited\namount of time. We propose a variant of the DeGroot model that allows an\nexternal agent to interact with the permanent ones for a preset period of time.\nWe obtain several insights on maximising an external agent's influence in\nopinion formation by analysing and simulating the variant.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.12503v2"
    },
    {
        "title": "Deadlock-Free Method for Multi-Agent Pickup and Delivery Problem Using\n  Priority Inheritance with Temporary Priority",
        "authors": [
            "Yukita Fujitani",
            "Tomoki Yamauchi",
            "Yuki Miyashita",
            "Toshiharu Sugawara"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper proposes a control method for the multi-agent pickup and delivery\nproblem (MAPD problem) by extending the priority inheritance with backtracking\n(PIBT) method to make it applicable to more general environments. PIBT is an\neffective algorithm that introduces a priority to each agent, and at each\ntimestep, the agents, in descending order of priority, decide their next\nneighboring locations in the next timestep through communications only with the\nlocal agents. Unfortunately, PIBT is only applicable to environments that are\nmodeled as a bi-connected area, and if it contains dead-ends, such as\ntree-shaped paths, PIBT may cause deadlocks. However, in the real-world\nenvironment, there are many dead-end paths to locations such as the shelves\nwhere materials are stored as well as loading/unloading locations to\ntransportation trucks. Our proposed method enables MAPD tasks to be performed\nin environments with some tree-shaped paths without deadlock while preserving\nthe PIBT feature; it does this by allowing the agents to have temporary\npriorities and restricting agents' movements in the trees. First, we\ndemonstrate that agents can always reach their delivery without deadlock. Our\nexperiments indicate that the proposed method is very efficient, even in\nenvironments where PIBT is not applicable, by comparing them with those\nobtained using the well-known token passing method as a baseline.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.12504v1"
    },
    {
        "title": "Feudal Multi-Agent Reinforcement Learning with Adaptive Network\n  Partition for Traffic Signal Control",
        "authors": [
            "Jinming Ma",
            "Feng Wu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent reinforcement learning (MARL) has been applied and shown great\npotential in multi-intersections traffic signal control, where multiple agents,\none for each intersection, must cooperate together to optimize traffic flow. To\nencourage global cooperation, previous work partitions the traffic network into\nseveral regions and learns policies for agents in a feudal structure. However,\nstatic network partition fails to adapt to dynamic traffic flow, which will\nchanges frequently over time. To address this, we propose a novel feudal MARL\napproach with adaptive network partition. Specifically, we first partition the\nnetwork into several regions according to the traffic flow. To do this, we\npropose two approaches: one is directly to use graph neural network (GNN) to\ngenerate the network partition, and the other is to use Monte-Carlo tree search\n(MCTS) to find the best partition with criteria computed by GNN. Then, we\ndesign a variant of Qmix using GNN to handle various dimensions of input, given\nby the dynamic network partition. Finally, we use a feudal hierarchy to manage\nagents in each partition and promote global cooperation. By doing so, agents\nare able to adapt to the traffic flow as required in practice. We empirically\nevaluate our method both in a synthetic traffic grid and real-world traffic\nnetworks of three cities, widely used in the literature. Our experimental\nresults confirm that our method can achieve better performance, in terms of\naverage travel time and queue length, than several leading methods for traffic\nsignal control.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.13836v1"
    },
    {
        "title": "Agent-based Simulation of District-based Elections",
        "authors": [
            "Adway Mitra"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In district-based elections, electors cast votes in their respective\ndistricts. In each district, the party with maximum votes wins the\ncorresponding seat in the governing body. The election result is based on the\nnumber of seats won by different parties. In this system, locations of electors\nacross the districts may severely affect the election result even if the total\nnumber of votes obtained by different parties remains unchanged. A less popular\nparty may end up winning more seats if their supporters are suitably\ndistributed spatially. This happens due to various regional and social\ninfluences on individual voters which modulate their voting choice. In this\npaper, we explore agent-based models for district-based elections, where we\nconsider each elector as an agent, and try to represent their social and\ngeographical attributes and political inclinations using probability\ndistributions. This model can be used to simulate election results by Monte\nCarlo sampling. The models allow us to explore the full space of possible\noutcomes of an electoral setting, though they can also be calibrated to actual\nelection results for suitable values of parameters. We use Approximate Bayesian\nComputation (ABC) framework to estimate model parameters. We show that our\nmodel can reproduce the results of elections held in India and USA, and can\nalso produce counterfactual scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.14400v2"
    },
    {
        "title": "Multi-Agent Reinforcement Learning is a Sequence Modeling Problem",
        "authors": [
            "Muning Wen",
            "Jakub Grudzien Kuba",
            "Runji Lin",
            "Weinan Zhang",
            "Ying Wen",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Large sequence model (SM) such as GPT series and BERT has displayed\noutstanding performance and generalization capabilities on vision, language,\nand recently reinforcement learning tasks. A natural follow-up question is how\nto abstract multi-agent decision making into an SM problem and benefit from the\nprosperous development of SMs. In this paper, we introduce a novel architecture\nnamed Multi-Agent Transformer (MAT) that effectively casts cooperative\nmulti-agent reinforcement learning (MARL) into SM problems wherein the task is\nto map agents' observation sequence to agents' optimal action sequence. Our\ngoal is to build the bridge between MARL and SMs so that the modeling power of\nmodern sequence models can be unleashed for MARL. Central to our MAT is an\nencoder-decoder architecture which leverages the multi-agent advantage\ndecomposition theorem to transform the joint policy search problem into a\nsequential decision making process; this renders only linear time complexity\nfor multi-agent problems and, most importantly, endows MAT with monotonic\nperformance improvement guarantee. Unlike prior arts such as Decision\nTransformer fit only pre-collected offline data, MAT is trained by online\ntrials and errors from the environment in an on-policy fashion. To validate\nMAT, we conduct extensive experiments on StarCraftII, Multi-Agent MuJoCo,\nDexterous Hands Manipulation, and Google Research Football benchmarks. Results\ndemonstrate that MAT achieves superior performance and data efficiency compared\nto strong baselines including MAPPO and HAPPO. Furthermore, we demonstrate that\nMAT is an excellent few-short learner on unseen tasks regardless of changes in\nthe number of agents. See our project page at\nhttps://sites.google.com/view/multi-agent-transformer.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.14953v3"
    },
    {
        "title": "CBS-Budget (CBSB): A Complete and Bounded Suboptimal Search for\n  Multi-Agent Path Finding",
        "authors": [
            "Jaein Lim",
            "Panagiotis Tsiotras"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-Agent Path Finding (MAPF) is the problem of finding a collection of\ncollision-free paths for a team of multiple agents while minimizing some global\ncost, such as the sum of the time travelled by all agents, or the time\ntravelled by the last agent. Conflict Based Search (CBS) is a leading complete\nand optimal MAPF solver which lazily explores the joint agent state space,\nusing an admissible heuristic joint plan. Such an admissible heuristic joint\nplan is computed by combining individual shortest paths found without\nconsidering inter-agent conflicts, and which becomes gradually more informed as\nconstraints are added to individual agents' path planning problems to avoid\ndiscovered conflicts. In this paper, we seek to speedup CBS by finding a more\ninformed heuristic joint plan which is bounded from above. We first propose the\nbudgeted Class-Ordered A* (bCOA*), a novel algorithm that finds the shortest\npath with minimal number of conflicts that is upper bounded in terms of length.\nThen, we propose a novel bounded-cost variant of CBS, called CBS-Budget (CBSB)\nby using a bCOA* search at the low-level search of the CBS and by using a\nmodified focal search at the high-level search of the CBS. We prove that CBSB\nis complete and bounded-suboptimal. In our numerical experiments, CBSB finds a\nnear optimal solution for hundreds of agents within a fraction of a second.\nCBSB shows state-of-the-art performance, comparable to Explicit Estimation CBS\n(EECBS), an enhanced recent version of CBS. On the other hand, CBSB is easier\nto implement than EECBS, since only two priority queues at the high-level\nsearch are needed as in Enhanced CBS (ECBS).\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00130v1"
    },
    {
        "title": "Machine learning applications for electricity market agent-based models:\n  A systematic literature review",
        "authors": [
            "Alexander J. M. Kell",
            "Stephen McGough",
            "Matthew Forshaw"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The electricity market has a vital role to play in the decarbonisation of the\nenergy system. However, the electricity market is made up of many different\nvariables and data inputs. These variables and data inputs behave in sometimes\nunpredictable ways which can not be predicted a-priori. It has therefore been\nsuggested that agent-based simulations are used to better understand the\ndynamics of the electricity market. Agent-based models provide the opportunity\nto integrate machine learning and artificial intelligence to add intelligence,\nmake better forecasts and control the power market in better and more efficient\nways. In this systematic literature review, we review 55 papers published\nbetween 2016 and 2021 which focus on machine learning applied to agent-based\nelectricity market models. We find that research clusters around popular\ntopics, such as bidding strategies. However, there exists a long-tail of\ndifferent research applications that could benefit from the high intensity\nresearch from the more investigated applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.02196v1"
    },
    {
        "title": "ACHORD: Communication-Aware Multi-Robot Coordination with Intermittent\n  Connectivity",
        "authors": [
            "Maira Saboia",
            "Lillian Clark",
            "Vivek Thangavelu",
            "Jeffrey A. Edlund",
            "Kyohei Otsu",
            "Gustavo J. Correa",
            "Vivek Shankar Varadharajan",
            "Angel Santamaria-Navarro",
            "Thomas Touma",
            "Amanda Bouman",
            "Hovhannes Melikyan",
            "Torkom Pailevanian",
            "Sung-Kyun Kim",
            "Avak Archanian",
            "Tiago Stegun Vaquero",
            "Giovanni Beltrame",
            "Nils Napp",
            "Gustavo Pessin",
            "Ali-akbar Agha-mohammadi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Communication is an important capability for multi-robot exploration because\n(1) inter-robot communication (comms) improves coverage efficiency and (2)\nrobot-to-base comms improves situational awareness. Exploring comms-restricted\n(e.g., subterranean) environments requires a multi-robot system to tolerate and\nanticipate intermittent connectivity, and to carefully consider comms\nrequirements, otherwise mission-critical data may be lost. In this paper, we\ndescribe and analyze ACHORD (Autonomous & Collaborative High-Bandwidth\nOperations with Radio Droppables), a multi-layer networking solution which\ntightly co-designs the network architecture and high-level decision-making for\nimproved comms. ACHORD provides bandwidth prioritization and timely and\nreliable data transfer despite intermittent connectivity. Furthermore, it\nexposes low-layer networking metrics to the application layer to enable robots\nto autonomously monitor, map, and extend the network via droppable radios, as\nwell as restore connectivity to improve collaborative exploration. We evaluate\nour solution with respect to the comms performance in several challenging\nunderground environments including the DARPA SubT Finals competition\nenvironment. Our findings support the use of data stratification and flow\ncontrol to improve bandwidth-usage.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.02245v1"
    },
    {
        "title": "Consensus Learning for Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Bin Zhang",
            "Dapeng Li",
            "Zeren Zhang",
            "Guangchong Zhou",
            "Hao Chen",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Almost all multi-agent reinforcement learning algorithms without\ncommunication follow the principle of centralized training with decentralized\nexecution. During centralized training, agents can be guided by the same\nsignals, such as the global state. During decentralized execution, however,\nagents lack the shared signal. Inspired by viewpoint invariance and contrastive\nlearning, we propose consensus learning for cooperative multi-agent\nreinforcement learning in this paper. Although based on local observations,\ndifferent agents can infer the same consensus in discrete space. During\ndecentralized execution, we feed the inferred consensus as an explicit input to\nthe network of agents, thereby developing their spirit of cooperation. Our\nproposed method can be extended to various multi-agent reinforcement learning\nalgorithms with small model changes. Moreover, we carry out them on some fully\ncooperative tasks and get convincing results.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.02583v3"
    },
    {
        "title": "Towards Explainable Social Agent Authoring tools: A case study on\n  FAtiMA-Toolkit",
        "authors": [
            "Manuel Guimarães",
            "Joana Campos",
            "Pedro A. Santos",
            "João Dias",
            "Rui Prada"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The deployment of Socially Intelligent Agents (SIAs) in learning environments\nhas proven to have several advantages in different areas of application. Social\nAgent Authoring Tools allow scenario designers to create tailored experiences\nwith high control over SIAs behaviour, however, on the flip side, this comes at\na cost as the complexity of the scenarios and its authoring can become\noverbearing. In this paper we introduce the concept of Explainable Social Agent\nAuthoring Tools with the goal of analysing if authoring tools for social agents\nare understandable and interpretable. To this end we examine whether an\nauthoring tool, FAtiMA-Toolkit, is understandable and its authoring steps\ninterpretable, from the point-of-view of the author. We conducted two user\nstudies to quantitatively assess the Interpretability, Comprehensibility and\nTransparency of FAtiMA-Toolkit from the perspective of a scenario designer. One\nof the key findings is the fact that FAtiMA-Toolkit's conceptual model is, in\ngeneral, understandable, however the emotional-based concepts were not as\neasily understood and used by the authors. Although there are some positive\naspects regarding the explainability of FAtiMA-Toolkit, there is still progress\nto be made to achieve a fully explainable social agent authoring tool. We\nprovide a set of key concepts and possible solutions that can guide developers\nto build such tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.03360v1"
    },
    {
        "title": "Stabilizing Voltage in Power Distribution Networks via Multi-Agent\n  Reinforcement Learning with Transformer",
        "authors": [
            "Minrui Wang",
            "Mingxiao Feng",
            "Wengang Zhou",
            "Houqiang Li"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The increased integration of renewable energy poses a slew of technical\nchallenges for the operation of power distribution networks. Among them,\nvoltage fluctuations caused by the instability of renewable energy are\nreceiving increasing attention. Utilizing MARL algorithms to coordinate\nmultiple control units in the grid, which is able to handle rapid changes of\npower systems, has been widely studied in active voltage control task recently.\nHowever, existing approaches based on MARL ignore the unique nature of the grid\nand achieve limited performance. In this paper, we introduce the transformer\narchitecture to extract representations adapting to power network problems and\npropose a Transformer-based Multi-Agent Actor-Critic framework (T-MAAC) to\nstabilize voltage in power distribution networks. In addition, we adopt a novel\nauxiliary-task training process tailored to the voltage control task, which\nimproves the sample efficiency and facilitating the representation learning of\nthe transformer-based model. We couple T-MAAC with different multi-agent\nactor-critic algorithms, and the consistent improvements on the active voltage\ncontrol task demonstrate the effectiveness of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.03721v1"
    },
    {
        "title": "Resource-Mediated Consensus Formation",
        "authors": [
            "Omar Malik",
            "James Flamino",
            "Boleslaw K. Szymanski"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In social sciences, simulating opinion dynamics to study the interplay\nbetween homophily and influence, and the subsequent formation of echo chambers,\nis of great importance. As such, in this paper we investigate echo chambers by\nimplementing a unique social game in which we spawn in a large number of\nagents, each assigned one of the two opinions on an issue and a finite amount\nof influence in the form of a game currency. Agents attempt to have an opinion\nthat is a majority at the end of the game, to obtain a reward also paid in the\ngame currency. At the beginning of each round, a randomly selected agent is\nselected, referred to as a speaker. The second agent is selected in the radius\nof speaker influence (which is a set subset of the speaker's neighbors) to\ninteract with the speaker as a listener. In this interaction, the speaker\nproposes a payoff in the game currency from their personal influence budget to\npersuade the listener to hold the speaker's opinion in future rounds until\nchosen listener again. The listener can either choose to accept or reject this\npayoff to hold the speaker's opinion for future rounds. The listener's choice\nis informed only by their estimate of global majority opinion through a limited\nview of the opinions of their neighboring agents. We show that the influence\ngame leads to the formation of \"echo chambers,\" or homogeneous clusters of\nopinions. We also investigate various scenarios to disrupt the creation of such\necho chambers, including the introduction of resource disparity between agents\nwith different opinions, initially preferentially assigning opinions to agents,\nand the introduction of committed agents, who never change their initial\nopinion.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.07099v1"
    },
    {
        "title": "Automating the resolution of flight conflicts: Deep reinforcement\n  learning in service of air traffic controllers",
        "authors": [
            "George Vouros",
            "George Papadopoulos",
            "Alevizos Bastas",
            "Jose Manuel Cordero",
            "Ruben Rodrigez Rodrigez"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Dense and complex air traffic scenarios require higher levels of automation\nthan those exhibited by tactical conflict detection and resolution (CD\\&R)\ntools that air traffic controllers (ATCO) use today. However, the air traffic\ncontrol (ATC) domain, being safety critical, requires AI systems to which\noperators are comfortable to relinquishing control, guaranteeing operational\nintegrity and automation adoption. Two major factors towards this goal are\nquality of solutions, and transparency in decision making. This paper proposes\nusing a graph convolutional reinforcement learning method operating in a\nmultiagent setting where each agent (flight) performs a CD\\&R task, jointly\nwith other agents. We show that this method can provide high-quality solutions\nwith respect to stakeholders interests (air traffic controllers and airspace\nusers), addressing operational transparency issues.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.07403v1"
    },
    {
        "title": "Responsibility-associated Multi-agent Collision Avoidance with Social\n  Preferences",
        "authors": [
            "Yiwei Lyu",
            "Wenhao Luo",
            "John M. Dolan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper introduces a novel social preference-aware decentralized safe\ncontrol framework to address the responsibility allocation problem in\nmulti-agent collision avoidance. Considering that agents do not necessarily\ncooperate in symmetric ways, this paper focuses on semi-cooperative behavior\namong heterogeneous agents with varying cooperation levels. Drawing upon the\nidea of Social Value Orientation (SVO) for quantifying the individual\nselfishness, we propose a novel concept of Responsibility-associated Social\nValue Orientation (R-SVO) to express the intended relative social implications\nbetween pairwise agents. This is used to redefine each agent's social\npreferences or personalities in terms of corresponding responsibility shares in\ncontributing to the coordination scenario, such as semi-cooperative collision\navoidance where all agents interact in an asymmetric way. By incorporating such\nrelative social implications through proposed Local Pairwise Responsibility\nWeights, we develop a Responsibility-associated Control Barrier Function-based\nsafe control framework for individual agents, and multi-agent collision\navoidance is achieved with formally provable safety guarantees. Simulations are\nprovided to demonstrate the effectiveness and efficiency of the proposed\nframework in several multi-agent navigation tasks, such as a position-swapping\ngame, a self-driving car highway ramp merging scenario, and a circular position\nswapping game.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09030v1"
    },
    {
        "title": "Recommendations for Systematic Research on Emergent Language",
        "authors": [
            "Brendon Boldt",
            "David Mortensen"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Emergent language is unique among fields within the discipline of machine\nlearning for its open-endedness, not obviously presenting well-defined problems\nto be solved. As a result, the current research in the field has largely been\nexploratory: focusing on establishing new problems, techniques, and phenomena.\nYet after these problems have been established, subsequent progress requires\nresearch which can measurably demonstrate how it improves on prior approaches.\nThis type of research is what we call systematic research; in this paper, we\nillustrate this mode of research specifically for emergent language. We first\nidentify the overarching goals of emergent language research, categorizing them\nas either science or engineering. Using this distinction, we present core\nmethodological elements of science and engineering, analyze their role in\ncurrent emergent language research, and recommend how to apply these elements.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.11302v1"
    },
    {
        "title": "PAC: Assisted Value Factorisation with Counterfactual Predictions in\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Hanhan Zhou",
            "Tian Lan",
            "Vaneet Aggarwal"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent reinforcement learning (MARL) has witnessed significant progress\nwith the development of value function factorization methods. It allows\noptimizing a joint action-value function through the maximization of factorized\nper-agent utilities due to monotonicity. In this paper, we show that in\npartially observable MARL problems, an agent's ordering over its own actions\ncould impose concurrent constraints (across different states) on the\nrepresentable function class, causing significant estimation error during\ntraining. We tackle this limitation and propose PAC, a new framework leveraging\nAssistive information generated from Counterfactual Predictions of optimal\njoint action selection, which enable explicit assistance to value function\nfactorization through a novel counterfactual loss. A variational\ninference-based information encoding method is developed to collect and encode\nthe counterfactual predictions from an estimated baseline. To enable\ndecentralized execution, we also derive factorized per-agent policies inspired\nby a maximum-entropy MARL framework. We evaluate the proposed PAC on\nmulti-agent predator-prey and a set of StarCraft II micromanagement tasks.\nEmpirical results demonstrate improved results of PAC over state-of-the-art\nvalue-based and policy-based multi-agent reinforcement learning algorithms on\nall benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.11420v3"
    },
    {
        "title": "Toward multi-target self-organizing pursuit in a partially observable\n  Markov game",
        "authors": [
            "Lijun Sun",
            "Yu-Cheng Chang",
            "Chao Lyu",
            "Ye Shi",
            "Yuhui Shi",
            "Chin-Teng Lin"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The multiple-target self-organizing pursuit (SOP) problem has wide\napplications and has been considered a challenging self-organization game for\ndistributed systems, in which intelligent agents cooperatively pursue multiple\ndynamic targets with partial observations. This work proposes a framework for\ndecentralized multi-agent systems to improve the implicit coordination\ncapabilities in search and pursuit. We model a self-organizing system as a\npartially observable Markov game (POMG) featured by large-scale,\ndecentralization, partial observation, and noncommunication. The proposed\ndistributed algorithm: fuzzy self-organizing cooperative coevolution (FSC2) is\nthen leveraged to resolve the three challenges in multi-target SOP: distributed\nself-organizing search (SOS), distributed task allocation, and distributed\nsingle-target pursuit. FSC2 includes a coordinated multi-agent deep\nreinforcement learning (MARL) method that enables homogeneous agents to learn\nnatural SOS patterns. Additionally, we propose a fuzzy-based distributed task\nallocation method, which locally decomposes multi-target SOP into several\nsingle-target pursuit problems. The cooperative coevolution principle is\nemployed to coordinate distributed pursuers for each single-target pursuit\nproblem. Therefore, the uncertainties of inherent partial observation and\ndistributed decision-making in the POMG can be alleviated. The experimental\nresults demonstrate that by decomposing the SOP task, FSC2 achieves superior\nperformance compared with other implicit coordination policies fully trained by\ngeneral MARL algorithms. The scalability of FSC2 is proved that up to 2048 FSC2\nagents perform efficient multi-target SOP with almost 100 percent capture\nrates. Empirical analyses and ablation studies verify the interpretability,\nrationality, and effectiveness of component algorithms in FSC2.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.12330v3"
    },
    {
        "title": "AGENT: An Adaptive Grouping Entrapping Method of Flocking Systems",
        "authors": [
            "Chen Wang",
            "Minqiang Gu",
            "Wenxi Kuang",
            "Dongliang Wang",
            "Weicheng Luo",
            "Zhaohui Shi",
            "Zhun Fan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This study proposes a distributed algorithm that makes agents' adaptive\ngrouping entrap multiple targets via automatic decision making, smooth\nflocking, and well-distributed entrapping. Agents make their own decisions\nabout which targets to surround based on environmental information. An improved\nartificial potential field method is proposed to enable agents to smoothly and\nnaturally change the formation to adapt to the environment. The proposed\nstrategies guarantee that the coordination of swarm agents develops the\nphenomenon of multiple targets entrapping at the swarm level. We validate the\nperformance of the proposed method using simulation experiments and design\nindicators for the analysis of these simulation and physical experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.14614v1"
    },
    {
        "title": "\"Y'all are just too sensitive\": A computational ethics approach to\n  understanding how prejudice against marginalized communities becomes\n  epistemic belief",
        "authors": [
            "Johannah Sprinz"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Members of marginalized communities are often accused of being \"too\nsensitive\" when subjected to supposedly harmless acts of microaggression. This\npaper explores a simulated society consisting of marginalized and\nnon-marginalized agents who interact and may, based on their individually held\nconvictions, commit acts of microaggressions. Agents witnessing a\nmicroaggression might condone, ignore or condemn such microaggressions, thus\npotentially influencing a perpetrator's conviction. A prototype model has been\nimplemented in NetLogo, and possible applications are briefly discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.01017v1"
    },
    {
        "title": "Stochastic Market Games",
        "authors": [
            "Kyrill Schmid",
            "Lenz Belzner",
            "Robert Müller",
            "Johannes Tochtermann",
            "Claudia Linnhoff-Popien"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Some of the most relevant future applications of multi-agent systems like\nautonomous driving or factories as a service display mixed-motive scenarios,\nwhere agents might have conflicting goals. In these settings agents are likely\nto learn undesirable outcomes in terms of cooperation under independent\nlearning, such as overly greedy behavior. Motivated from real world societies,\nin this work we propose to utilize market forces to provide incentives for\nagents to become cooperative. As demonstrated in an iterated version of the\nPrisoner's Dilemma, the proposed market formulation can change the dynamics of\nthe game to consistently learn cooperative policies. Further we evaluate our\napproach in spatially and temporally extended settings for varying numbers of\nagents. We empirically find that the presence of markets can improve both the\noverall result and agent individual returns via their trading activities.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.07388v3"
    },
    {
        "title": "Ballot Length in Instant Runoff Voting",
        "authors": [
            "Kiran Tomlinson",
            "Johan Ugander",
            "Jon Kleinberg"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Instant runoff voting (IRV) is an increasingly-popular alternative to\ntraditional plurality voting in which voters submit rankings over the\ncandidates rather than single votes. In practice, elections using IRV often\nrestrict the ballot length, the number of candidates a voter is allowed to rank\non their ballot. We theoretically and empirically analyze how ballot length can\ninfluence the outcome of an election, given fixed voter preferences. We show\nthat there exist preference profiles over $k$ candidates such that up to $k-1$\ndifferent candidates win at different ballot lengths. We derive exact lower\nbounds on the number of voters required for such profiles and provide a\nconstruction matching the lower bound for unrestricted voter preferences.\nAdditionally, we characterize which sequences of winners are possible over\nballot lengths and provide explicit profile constructions achieving any\nfeasible winner sequence. We also examine how classic preference restrictions\ninfluence our results--for instance, single-peakedness makes $k-1$ different\nwinners impossible but still allows at least $\\Omega(\\sqrt k)$. Finally, we\nanalyze a collection of 168 real-world elections, where we truncate rankings to\nsimulate shorter ballots. We find that shorter ballots could have changed the\noutcome in one quarter of these elections. Our results highlight ballot length\nas a consequential degree of freedom in the design of IRV elections.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.08958v3"
    },
    {
        "title": "Few-Shot Teamwork",
        "authors": [
            "Elliot Fosong",
            "Arrasy Rahman",
            "Ignacio Carlucho",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We propose the novel few-shot teamwork (FST) problem, where skilled agents\ntrained in a team to complete one task are combined with skilled agents from\ndifferent tasks, and together must learn to adapt to an unseen but related\ntask. We discuss how the FST problem can be seen as addressing two separate\nproblems: one of reducing the experience required to train a team of agents to\ncomplete a complex task; and one of collaborating with unfamiliar teammates to\ncomplete a new task. Progress towards solving FST could lead to progress in\nboth multi-agent reinforcement learning and ad hoc teamwork.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.09300v1"
    },
    {
        "title": "Resource allocation in open multi-agent systems: an online optimization\n  analysis",
        "authors": [
            "Renato Vizuete",
            "Charles Monnoyer de Galland",
            "Julien M. Hendrickx",
            "Paolo Frasca",
            "Elena Panteley"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The resource allocation problem consists of the optimal distribution of a\nbudget between agents in a group. We consider such a problem in the context of\nopen systems, where agents can be replaced at some time instances. These\nreplacements lead to variations in both the budget and the total cost function\nthat hinder the overall network's performance. For a simple setting, we analyze\nthe performance of the Random Coordinate Descent algorithm (RCD) using tools\nsimilar to those commonly used in online optimization. In particular, we study\nthe accumulated errors that compare solutions issued from the RCD algorithm and\nthe optimal solution or the non-collaborating selfish strategy and we derive\nsome bounds in expectation for these accumulated errors.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.09316v1"
    },
    {
        "title": "Heterogeneous-Agent Mirror Learning: A Continuum of Solutions to\n  Cooperative MARL",
        "authors": [
            "Jakub Grudzien Kuba",
            "Xidong Feng",
            "Shiyao Ding",
            "Hao Dong",
            "Jun Wang",
            "Yaodong Yang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The necessity for cooperation among intelligent machines has popularised\ncooperative multi-agent reinforcement learning (MARL) in the artificial\nintelligence (AI) research community. However, many research endeavors have\nbeen focused on developing practical MARL algorithms whose effectiveness has\nbeen studied only empirically, thereby lacking theoretical guarantees. As\nrecent studies have revealed, MARL methods often achieve performance that is\nunstable in terms of reward monotonicity or suboptimal at convergence. To\nresolve these issues, in this paper, we introduce a novel framework named\nHeterogeneous-Agent Mirror Learning (HAML) that provides a general template for\nMARL algorithmic designs. We prove that algorithms derived from the HAML\ntemplate satisfy the desired properties of the monotonic improvement of the\njoint reward and the convergence to Nash equilibrium. We verify the\npracticality of HAML by proving that the current state-of-the-art cooperative\nMARL algorithms, HATRPO and HAPPO, are in fact HAML instances. Next, as a\nnatural outcome of our theory, we propose HAML extensions of two well-known RL\nalgorithms, HAA2C (for A2C) and HADDPG (for DDPG), and demonstrate their\neffectiveness against strong baselines on StarCraftII and Multi-Agent MuJoCo\ntasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.01682v1"
    },
    {
        "title": "Nonstationary Continuum-Armed Bandit Strategies for Automated Trading in\n  a Simulated Financial Market",
        "authors": [
            "Bingde Liu",
            "John Cartlidge"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We approach the problem of designing an automated trading strategy that can\nconsistently profit by adapting to changing market conditions. This challenge\ncan be framed as a Nonstationary Continuum-Armed Bandit (NCAB) problem. To\nsolve the NCAB problem, we propose PRBO, a novel trading algorithm that uses\nBayesian optimization and a ``bandit-over-bandit'' framework to dynamically\nadjust strategy parameters in response to market conditions. We use Bristol\nStock Exchange (BSE) to simulate financial markets containing heterogeneous\npopulations of automated trading agents and compare PRBO with PRSH, a reference\ntrading strategy that adapts strategy parameters through stochastic\nhill-climbing. Results show that PRBO generates significantly more profit than\nPRSH, despite having fewer hyperparameters to tune. The code for PRBO and\nperforming experiments is available online open-source\n(https://github.com/HarmoniaLeo/PRZI-Bayesian-Optimisation).\n",
        "pdf_link": "http://arxiv.org/pdf/2208.02901v3"
    },
    {
        "title": "Maximum Correntropy Value Decomposition for Multi-agent Deep\n  Reinforcemen Learning",
        "authors": [
            "Kai Liu",
            "Tianxian Zhang",
            "Lingjiang Kong"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We explore value decomposition solutions for multi-agent deep reinforcement\nlearning in the popular paradigm of centralized training with decentralized\nexecution(CTDE). As the recognized best solution to CTDE, Weighted QMIX is\ncutting-edge on StarCraft Multi-agent Challenge (SMAC), with a weighting scheme\nimplemented on QMIX to place more emphasis on the optimal joint actions.\nHowever, the fixed weight requires manual tuning according to the application\nscenarios, which painfully prevents Weighted QMIX from being used in broader\nengineering applications. In this paper, we first demonstrate the flaw of\nWeighted QMIX using an ordinary One-Step Matrix Game (OMG), that no matter how\nthe weight is chosen, Weighted QMIX struggles to deal with non-monotonic value\ndecomposition problems with a large variance of reward distributions. Then we\ncharacterize the problem of value decomposition as an Underfitting One-edged\nRobust Regression problem and make the first attempt to give a solution to the\nvalue decomposition problem from the perspective of information-theoretical\nlearning. We introduce the Maximum Correntropy Criterion (MCC) as a cost\nfunction to dynamically adapt the weight to eliminate the effects of minimum in\nreward distributions. We simplify the implementation and propose a new\nalgorithm called MCVD. A preliminary experiment conducted on OMG shows that\nMCVD could deal with non-monotonic value decomposition problems with a large\ntolerance of kernel bandwidth selection. Further experiments are carried out on\nCooperative-Navigation and multiple SMAC scenarios, where MCVD exhibits\nunprecedented ease of implementation, broad applicability, and stability.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03663v1"
    },
    {
        "title": "Emerging cooperation on the road by myopic local interactions",
        "authors": [
            "Dmitry Rabinovich",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We study a combinatorial problem inspired by the following scenario: fully\nautonomous vehicles drive on a multi-lane ($m \\geq 2$) road. Each vehicle heads\nto its own destination and is allowed to exit the road only through a single\ndesignated off-ramp lane. However, an individual vehicle has a severely limited\nmemory and sensing capabilities, and, moreover, does not communicate with its\npeers. In this work we present a distributed algorithm that, nonetheless,\nallows vehicles to get to the desired lane without collisions and in timely\nmanner.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03760v3"
    },
    {
        "title": "Ad Hoc Teamwork in the Presence of Adversaries",
        "authors": [
            "Ted Fujimoto",
            "Samrat Chatterjee",
            "Auroop Ganguly"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Advances in ad hoc teamwork have the potential to create agents that\ncollaborate robustly in real-world applications. Agents deployed in the real\nworld, however, are vulnerable to adversaries with the intent to subvert them.\nThere has been little research in ad hoc teamwork that assumes the presence of\nadversaries. We explain the importance of extending ad hoc teamwork to include\nthe presence of adversaries and clarify why this problem is difficult. We then\npropose some directions for new research opportunities in ad hoc teamwork that\nleads to more robust multi-agent cyber-physical infrastructure systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.05071v1"
    },
    {
        "title": "Transformer-based Value Function Decomposition for Cooperative\n  Multi-agent Reinforcement Learning in StarCraft",
        "authors": [
            "Muhammad Junaid Khan",
            "Syed Hammad Ahmed",
            "Gita Sukthankar"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The StarCraft II Multi-Agent Challenge (SMAC) was created to be a challenging\nbenchmark problem for cooperative multi-agent reinforcement learning (MARL).\nSMAC focuses exclusively on the problem of StarCraft micromanagement and\nassumes that each unit is controlled individually by a learning agent that acts\nindependently and only possesses local information; centralized training is\nassumed to occur with decentralized execution (CTDE). To perform well in SMAC,\nMARL algorithms must handle the dual problems of multi-agent credit assignment\nand joint action evaluation.\n  This paper introduces a new architecture TransMix, a transformer-based joint\naction-value mixing network which we show to be efficient and scalable as\ncompared to the other state-of-the-art cooperative MARL solutions. TransMix\nleverages the ability of transformers to learn a richer mixing function for\ncombining the agents' individual value functions. It achieves comparable\nperformance to previous work on easy SMAC scenarios and outperforms other\ntechniques on hard scenarios, as well as scenarios that are corrupted with\nGaussian noise to simulate fog of war.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.07298v1"
    },
    {
        "title": "Taming Multi-Agent Reinforcement Learning with Estimator Variance\n  Reduction",
        "authors": [
            "Taher Jafferjee",
            "Juliusz Ziomek",
            "Tianpei Yang",
            "Zipeng Dai",
            "Jianhong Wang",
            "Matthew Taylor",
            "Kun Shao",
            "Jun Wang",
            "David Mguni"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Centralised training with decentralised execution (CT-DE) serves as the\nfoundation of many leading multi-agent reinforcement learning (MARL)\nalgorithms. Despite its popularity, it suffers from a critical drawback due to\nits reliance on learning from a single sample of the joint-action at a given\nstate. As agents explore and update their policies during training, these\nsingle samples may poorly represent the actual joint-policy of the system of\nagents leading to high variance gradient estimates that hinder learning. To\naddress this problem, we propose an enhancement tool that accommodates any\nactor-critic MARL method. Our framework, Performance Enhancing Reinforcement\nLearning Apparatus (PERLA), introduces a sampling technique of the agents'\njoint-policy into the critics while the agents train. This leads to TD updates\nthat closely approximate the true expected value under the current joint-policy\nrather than estimates from a single sample of the joint-action at a given\nstate. This produces low variance and precise estimates of expected returns,\nminimising the variance in the critic estimators which typically hinders\nlearning. Moreover, as we demonstrate, by eliminating much of the critic\nvariance from the single sampling of the joint policy, PERLA enables CT-DE\nmethods to scale more efficiently with the number of agents. Theoretically, we\nprove that PERLA reduces variance in value estimates similar to that of\ndecentralised training while maintaining the benefits of centralised training.\nEmpirically, we demonstrate PERLA's superior performance and ability to reduce\nestimator variance in a range of benchmarks including Multi-agent Mujoco, and\nStarCraft II Multi-agent Challenge.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01054v2"
    },
    {
        "title": "Joint Caching and Transmission in the Mobile Edge Network: A Multi-Agent\n  Learning Approach",
        "authors": [
            "Qirui Mi",
            "Ning Yang",
            "Haifeng Zhang",
            "Haijun Zhang",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Joint caching and transmission optimization problem is challenging due to the\ndeep coupling between decisions. This paper proposes an iterative distributed\nmulti-agent learning approach to jointly optimize caching and transmission. The\ngoal of this approach is to minimize the total transmission delay of all users.\nIn this iterative approach, each iteration includes caching optimization and\ntransmission optimization. A multi-agent reinforcement learning (MARL)-based\ncaching network is developed to cache popular tasks, such as answering which\nfiles to evict from the cache and which files to storage. Based on the cached\nfiles of the caching network, the transmission network transmits cached files\nfor users by single transmission (ST) or joint transmission (JT) with\nmulti-agent Bayesian learning automaton (MABLA) method. And then users access\nthe edge servers with the minimum transmission delay. The experimental results\ndemonstrate the performance of the proposed multi-agent learning approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04164v1"
    },
    {
        "title": "Multi-Agent Path Finding on Strongly Connected Digraphs: feasibility and\n  solution algorithms",
        "authors": [
            "Stefano Ardizzoni",
            "Irene Saccani",
            "Luca Consolini",
            "Marco Locatelli"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  On an assigned graph, the problem of Multi-Agent Pathfinding (MAPF) consists\nin finding paths for multiple agents, avoiding collisions. Finding the\nminimum-length solution is known to be NP-hard, and computation times grows\nexponentially with the number of agents. However, in industrial applications,\nit is important to find feasible, suboptimal solutions, in a time that grows\npolynomially with the number of agents. Such algorithms exist for undirected\nand biconnected directed graphs. Our main contribution is to generalize these\nalgorithms to the more general case of strongly connected directed graphs. In\nparticular, given a MAPF problem with at least two holes, we present an\nalgorithm that checks the problem feasibility in linear time with respect to\nthe number of nodes, and provides a feasible solution in polynomial time.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04286v1"
    },
    {
        "title": "Graphon Mean-Field Control for Cooperative Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Yuanquan Hu",
            "Xiaoli Wei",
            "Junji Yan",
            "Hengxi Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The marriage between mean-field theory and reinforcement learning has shown a\ngreat capacity to solve large-scale control problems with homogeneous agents.\nTo break the homogeneity restriction of mean-field theory, a recent interest is\nto introduce graphon theory to the mean-field paradigm. In this paper, we\npropose a graphon mean-field control (GMFC) framework to approximate\ncooperative multi-agent reinforcement learning (MARL) with nonuniform\ninteractions and show that the approximate order is of\n$\\mathcal{O}(\\frac{1}{\\sqrt{N}})$, with $N$ the number of agents. By\ndiscretizing the graphon index of GMFC, we further introduce a smaller class of\nGMFC called block GMFC, which is shown to well approximate cooperative MARL.\nOur empirical studies on several examples demonstrate that our GMFC approach is\ncomparable with the state-of-art MARL algorithms while enjoying better\nscalability.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04808v1"
    },
    {
        "title": "Solving the Job Shop Scheduling Problem with Ant Colony Optimization",
        "authors": [
            "Alysson Ribeiro da Silva"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The Job Shop Schedule Problem (JSSP) refers to the ability of an agent to\nallocate tasks that should be executed in a specified time in a machine from a\ncluster. The task allocation can be achieved from several methods, however,\nthis report it is explored the ability of the Ant Colony Optimization to\ngenerate feasible solutions for several JSSP instances. This proposal models\nthe JSSP as a complete graph since disjunct models can prevent the ACO from\nexploring all the search space. Several instances of the JSSP were used to\nevaluate the proposal. Results suggest that the algorithm can reach optimum\nsolutions for easy and harder instances with a selection of parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.05284v1"
    },
    {
        "title": "Developing, Evaluating and Scaling Learning Agents in Multi-Agent\n  Environments",
        "authors": [
            "Ian Gemp",
            "Thomas Anthony",
            "Yoram Bachrach",
            "Avishkar Bhoopchand",
            "Kalesha Bullard",
            "Jerome Connor",
            "Vibhavari Dasagi",
            "Bart De Vylder",
            "Edgar Duenez-Guzman",
            "Romuald Elie",
            "Richard Everett",
            "Daniel Hennes",
            "Edward Hughes",
            "Mina Khan",
            "Marc Lanctot",
            "Kate Larson",
            "Guy Lever",
            "Siqi Liu",
            "Luke Marris",
            "Kevin R. McKee",
            "Paul Muller",
            "Julien Perolat",
            "Florian Strub",
            "Andrea Tacchetti",
            "Eugene Tarassov",
            "Zhe Wang",
            "Karl Tuyls"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The Game Theory & Multi-Agent team at DeepMind studies several aspects of\nmulti-agent learning ranging from computing approximations to fundamental\nconcepts in game theory to simulating social dilemmas in rich spatial\nenvironments and training 3-d humanoids in difficult team coordination tasks. A\nsignature aim of our group is to use the resources and expertise made available\nto us at DeepMind in deep reinforcement learning to explore multi-agent systems\nin complex environments and use these benchmarks to advance our understanding.\nHere, we summarise the recent work of our team and present a taxonomy that we\nfeel highlights many important open challenges in multi-agent research.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.10958v1"
    },
    {
        "title": "Multi-Agent Coordination via Multi-Level Communication",
        "authors": [
            "Ziluo Ding",
            "Zeyuan Liu",
            "Zhirui Fang",
            "Kefan Su",
            "Liwen Zhu",
            "Zongqing Lu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The partial observability and stochasticity in multi-agent settings can be\nmitigated by accessing more information about others via communication.\nHowever, the coordination problem still exists since agents cannot communicate\nactual actions with each other at the same time due to the circular\ndependencies. In this paper, we propose a novel multi-level communication\nscheme, Sequential Communication (SeqComm). SeqComm treats agents\nasynchronously (the upper-level agents make decisions before the lower-level\nones) and has two communication phases. In the negotiation phase, agents\ndetermine the priority of decision-making by communicating hidden states of\nobservations and comparing the value of intention, obtained by modeling the\nenvironment dynamics. In the launching phase, the upper-level agents take the\nlead in making decisions and then communicate their actions with the\nlower-level agents. Theoretically, we prove the policies learned by SeqComm are\nguaranteed to improve monotonically and converge. Empirically, we show that\nSeqComm outperforms existing methods in various cooperative multi-agent tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12713v2"
    },
    {
        "title": "From Intelligent Agents to Trustworthy Human-Centred Multiagent Systems",
        "authors": [
            "Mohammad Divband Soorati",
            "Enrico H. Gerding",
            "Enrico Marchioni",
            "Pavel Naumov",
            "Timothy J. Norman",
            "Sarvapali D. Ramchurn",
            "Bahar Rastegari",
            "Adam Sobey",
            "Sebastian Stein",
            "Danesh Tarpore",
            "Vahid Yazdanpanah",
            "Jie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The Agents, Interaction and Complexity research group at the University of\nSouthampton has a long track record of research in multiagent systems (MAS). We\nhave made substantial scientific contributions across learning in MAS,\ngame-theoretic techniques for coordinating agent systems, and formal methods\nfor representation and reasoning. We highlight key results achieved by the\ngroup and elaborate on recent work and open research challenges in developing\ntrustworthy autonomous systems and deploying human-centred AI systems that aim\nto support societal good.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.02260v1"
    },
    {
        "title": "A General Learning Framework for Open Ad Hoc Teamwork Using Graph-based\n  Policy Learning",
        "authors": [
            "Arrasy Rahman",
            "Ignacio Carlucho",
            "Niklas Höpner",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Open ad hoc teamwork is the problem of training a single agent to efficiently\ncollaborate with an unknown group of teammates whose composition may change\nover time. A variable team composition creates challenges for the agent, such\nas the requirement to adapt to new team dynamics and dealing with changing\nstate vector sizes. These challenges are aggravated in real-world applications\nin which the controlled agent only has a partial view of the environment. In\nthis work, we develop a class of solutions for open ad hoc teamwork under full\nand partial observability. We start by developing a solution for the fully\nobservable case that leverages graph neural network architectures to obtain an\noptimal policy based on reinforcement learning. We then extend this solution to\npartially observable scenarios by proposing different methodologies that\nmaintain belief estimates over the latent environment states and team\ncomposition. These belief estimates are combined with our solution for the\nfully observable case to compute an agent's optimal policy under partial\nobservability in open ad hoc teamwork. Empirical results demonstrate that our\nsolution can learn efficient policies in open ad hoc teamwork in fully and\npartially observable cases. Further analysis demonstrates that our methods'\nsuccess is a result of effectively learning the effects of teammates' actions\nwhile also inferring the inherent state of the environment under partial\nobservability.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.05448v2"
    },
    {
        "title": "Multi-Agent Distributed and Decentralized Geometric Task Allocation",
        "authors": [
            "Michael Amir",
            "Yigal Koifman",
            "Yakov Bloch",
            "Ariel Barel",
            "Alfred M. Bruckstein"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We consider the general problem of geometric task allocation, wherein a\nlarge, decentralised swarm of simple mobile agents must detect the locations of\ntasks in the plane and position themselves nearby. The tasks are represented by\nan a priori unknown demand profile $\\Phi(x,y)$ that determines how many agents\nare needed in each location. The agents are autonomous, oblivious and\nindistinguishable, and have finite sensing range. They must configure\nthemselves according to $\\Phi$ using only local information about $\\Phi$ and\nabout the positions of nearby agents. All agents act according to the same\nlocal sensing-based rule of motion, and cannot explicitly communicate nor share\ninformation.\n  We propose an optimization-based approach to the problem which results in\nattraction-repulsion dynamics. Repulsion encourages agents to spread out and\nexplore the region so as to find the tasks, and attraction causes them to\naccumulate at task locations. We derive this approach via gradient descent over\nan appropriate ``error'' functional, and test it extensively through numerical\nsimulations.\n  The figures in this work are snapshots of simulations that can be viewed\nonline at https://youtu.be/kyUiGYSaaoQ.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.05552v2"
    },
    {
        "title": "Towards Evology: a Market Ecology Agent-Based Model of US Equity Mutual\n  Funds",
        "authors": [
            "Aymeric Vie",
            "Maarten Scholl",
            "Alissa M. Kleinnijenhuis",
            "J. Doyne Farmer"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The profitability of various investment styles in investment funds depends on\nmacroeconomic conditions. Market ecology, which views financial markets as\necosystems of diverse, interacting and evolving trading strategies, has shown\nthat endogenous interactions between strategies determine market behaviour and\nstyles' performance. We present Evology: a heterogeneous, empirically\ncalibrated multi-agent market ecology agent-based model to quantify endogenous\ninteractions between US equity mutual funds, particularly Value and Growth\ninvestment styles. We outline the model design, validation and calibration\napproach and its potential for optimising investment strategies using machine\nlearning algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.11344v2"
    },
    {
        "title": "An agent-based epidemics simulation to compare and explain screening and\n  vaccination prioritisation strategies",
        "authors": [
            "Carole Adam",
            "Helene Arduin"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper describes an agent-based model of epidemics dynamics. This model\nis willingly simplified, as its goal is not to predict the evolution of the\nepidemics, but to explain the underlying mechanisms in an interactive way. This\nmodel allows to compare screening prioritisation strategies, as well as\nvaccination priority strategies, on a virtual population. The model is\nimplemented in Netlogo in different simulators, published online to let people\nexperiment with them. This paper reports on the model design, implementation,\nand experimentations. In particular we have compared screening strategies to\nevaluate the epidemics vs control it by quarantining infectious people; and we\nhave compared vaccinating older people with more risk factors, vs younger\npeople with more social contacts.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.13089v1"
    },
    {
        "title": "Counting and Computing Join-Endomorphisms in Lattices (Revisited)",
        "authors": [
            "Carlos Pinzón",
            "Santiago Quintero",
            "Sergio Ramírez",
            "Camilo Rueda",
            "Frank Valencia"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Structures involving a lattice and join-endomorphisms on it are ubiquitous in\ncomputer science. We study the cardinality of the set $\\mathcal{E}(L)$ of all\njoin-endomorphisms of a given finite lattice $L$. In particular, we show for\n$\\mathbf{M}_n$, the discrete order of $n$ elements extended with top and\nbottom, $| \\mathcal{E}(\\mathbf{M}_n) | =n!\\mathcal{L}_n(-1)+(n+1)^2$ where\n$\\mathcal{L}_n(x)$ is the Laguerre polynomial of degree $n$. We also study the\nfollowing problem: Given a lattice $L$ of size $n$ and a set $S\\subseteq\n\\mathcal{E}(L)$ of size $m$, find the greatest lower bound\n${\\large\\sqcap}_{\\mathcal{E}(L)} S$. The join-endomorphism\n${\\large\\sqcap}_{\\mathcal{E}(L)} S$ has meaningful interpretations in epistemic\nlogic, distributed systems, and Aumann structures. We show that this problem\ncan be solved with worst-case time complexity in $O(mn)$ for distributive\nlattices and $O(mn + n^3)$ for arbitrary lattices. In the particular case of\nmodular lattices, we present an adaptation of the latter algorithm that reduces\nits average time complexity. We provide theoretical and experimental results to\nsupport this enhancement. The complexity is expressed in terms of the basic\nbinary lattice operations performed by the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.00781v1"
    },
    {
        "title": "Learning Decentralized Strategies for a Perimeter Defense Game with\n  Graph Neural Networks",
        "authors": [
            "Elijah S. Lee",
            "Lifeng Zhou",
            "Alejandro Ribeiro",
            "Vijay Kumar"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We consider the problem of finding decentralized strategies for multi-agent\nperimeter defense games. In this work, we design a graph neural network-based\nlearning framework to learn a mapping from defenders' local perceptions and the\ncommunication graph to defenders' actions such that the learned actions are\nclose to that generated by a centralized expert algorithm. We demonstrate that\nour proposed networks stay closer to the expert policy and are superior to\nother baseline algorithms by capturing more intruders. Our GNN-based networks\nare trained at a small scale and can generalize to large scales. To validate\nour results, we run perimeter defense games in scenarios with different team\nsizes and initial configurations to evaluate the performance of the learned\nnetworks.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.01757v1"
    },
    {
        "title": "An agent-based approach to procedural city generation incorporating Land\n  Use and Transport Interaction models",
        "authors": [
            "Luiz Fernando Silva Eugênio dos Santos",
            "Claus Aranha",
            "André Ponce de Leon F de Carvalho"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We apply the knowledge of urban settings established with the study of Land\nUse and Transport Interaction (LUTI) models to develop reward functions for an\nagent-based system capable of planning realistic artificial cities. The system\naims to replicate in the micro scale the main components of real settlements,\nsuch as zoning and accessibility in a road network. Moreover, we propose a\nnovel representation for the agent's environment that efficiently combines the\nroad graph with a discrete model for the land. Our system starts from an empty\nmap consisting only of the road network graph, and the agent incrementally\nexpands it by building new sites while distinguishing land uses between\nresidential, commercial, industrial, and recreational.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.01959v1"
    },
    {
        "title": "Group Cohesion in Multi-Agent Scenarios as an Emergent Behavior",
        "authors": [
            "Gianluca Georg Alois Volkmer",
            "Nabil Alsabah"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we elaborate on the design and discuss the results of a\nmulti-agent simulation that we have developed using the PSI cognitive\narchitecture. We demonstrate that imbuing agents with intrinsic needs for group\naffiliation, certainty and competence will lead to the emergence of social\nbehavior among agents. This behavior expresses itself in altruism toward\nin-group agents and adversarial tendencies toward out-group agents. Our\nsimulation also shows how parameterization can have dramatic effects on agent\nbehavior. Introducing an out-group bias, for example, not only made agents\nbehave aggressively toward members of the other group, but it also increased\nin-group cohesion. Similarly, environmental and situational factors facilitated\nthe emergence of outliers: agents from adversarial groups becoming close\nfriends.\n  Overall, this simulation showcases the power of psychological frameworks, in\ngeneral, and the PSI paradigm, in particular, to bring about human-like\nbehavioral patterns in an emergent fashion.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.02089v1"
    },
    {
        "title": "Developing Decentralised Resilience to Malicious Influence in Collective\n  Perception Problem",
        "authors": [
            "Chris Wise",
            "Aya Hussein",
            "Heba El-Fiqi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In collective decision-making, designing algorithms that use only local\ninformation to effect swarm-level behaviour is a non-trivial problem. We used\nmachine learning techniques to teach swarm members to map their local\nperceptions of the environment to an optimal action. A curriculum inspired by\nMachine Education approaches was designed to facilitate this learning process\nand teach the members the skills required for optimal performance in the\ncollective perception problem. We extended upon previous approaches by creating\na curriculum that taught agents resilience to malicious influence. The\nexperimental results show that well-designed rules-based algorithms can produce\neffective agents. When performing opinion fusion, we implemented decentralised\nresilience by having agents dynamically weight received opinion. We found a\nnon-significant difference between constant and dynamic weights, suggesting\nthat momentum-based opinion fusion is perhaps already a resilience mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.03063v1"
    },
    {
        "title": "A study on the ephemeral nature of knowledge shared within multiagent\n  systems",
        "authors": [
            "Sanjay Sarma Oruganti Venkata",
            "Ramviyas Parasuraman",
            "Ramana Pidaparti"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Achieving knowledge sharing within an artificial swarm system could lead to\nsignificant development in autonomous multiagent and robotic systems research\nand realize collective intelligence. However, this is difficult to achieve\nsince there is no generic framework to transfer skills between agents other\nthan a query-response-based approach. Moreover, natural living systems have a\n\"forgetfulness\" property for everything they learn. Analyzing such ephemeral\nnature (temporal memory properties of new knowledge gained) in artificial\nsystems has never been studied in the literature. We propose a behavior\ntree-based framework to realize a query-response mechanism for transferring\nskills encoded as the condition-action control sub-flow of that portion of the\nknowledge between agents to fill this gap. We simulate a multiagent group with\ndifferent initial knowledge on a foraging mission. While performing basic\noperations, each robot queries other robots to respond to an unknown condition.\nThe responding robot shares the control actions by sharing a portion of the\nbehavior tree that addresses the queries. Specifically, we investigate the\nephemeral nature of the new knowledge gained through such a framework, where\nthe knowledge gained by the agent is either limited due to memory or is\nforgotten over time. Our investigations show that knowledge grows\nproportionally with the duration of remembrance, which is trivial. However, we\nfound minimal impact on knowledge growth due to memory. We compare these cases\nagainst a baseline that involved full knowledge pre-coded on all agents. We\nfound that knowledge-sharing strived to match the baseline condition by sharing\nand achieving knowledge growth as a collective system.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.04433v1"
    },
    {
        "title": "Deterministic Random Walk Model in NetLogo and the Identification of\n  Asymmetric Saturation Time in Random Graph",
        "authors": [
            "Ayan Chatterjee",
            "Qingtao Cao",
            "Amirhossein Sajadi",
            "Babak Ravandi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Interactive programming environments are powerful tools for promoting\ninnovative network thinking, teaching science of complexity, and exploring\nemergent phenomena. This paper reports on our recent development of the\ndeterministic random walk model in NetLogo, a leading platform for\ncomputational thinking, eco-system thinking, and multi-agent cross-platform\nprogramming environment. The deterministic random walk is foundational to\nmodeling dynamical processes on complex networks. Inspired by the temporal\nvisualizations offered in NetLogo, we investigated the relationship between\nnetwork topology and diffusion saturation time for the deterministic random\nwalk model. Our analysis uncovers that in Erd\\H{o}s-R\\'{e}nyi graphs, the\nsaturation time exhibits an asymmetric pattern with a considerable probability\nof occurrence. This behavior occurs when the hubs, defined as nodes with\nrelatively higher number of connections, emerge in Erd\\H{o}s-R\\'{e}nyi graphs.\nYet, our analysis yields that the hubs in Barab\\'{a}si-Albert model stabilize\nthe the convergence time of the deterministic random walk model. These findings\nstrongly suggest that depending on the dynamical process running on complex\nnetworks, complementing characteristics other than the degree need to be taken\ninto account for considering a node as a hub. We have made our development\nopen-source, available to the public at no cost at\nhttps://github.com/bravandi/NetLogo-Dynamical-Processes.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.05189v2"
    },
    {
        "title": "Multi-Agent Deep Reinforcement Learning for Efficient Passenger Delivery\n  in Urban Air Mobility",
        "authors": [
            "Chanyoung Park",
            "Soohyun Park",
            "Gyu Seon Kim",
            "Soyi Jung",
            "Jae-Hyun Kim",
            "Joongheon Kim"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  It has been considered that urban air mobility (UAM), also known as\ndrone-taxi or electrical vertical takeoff and landing (eVTOL), will play a key\nrole in future transportation. By putting UAM into practical future\ntransportation, several benefits can be realized, i.e., (i) the total travel\ntime of passengers can be reduced compared to traditional transportation and\n(ii) there is no environmental pollution and no special labor costs to operate\nthe system because electric batteries will be used in UAM system. However,\nthere are various dynamic and uncertain factors in the flight environment,\ni.e., passenger sudden service requests, battery discharge, and collision among\nUAMs. Therefore, this paper proposes a novel cooperative MADRL algorithm based\non centralized training and distributed execution (CTDE) concepts for reliable\nand efficient passenger delivery in UAM networks. According to the performance\nevaluation results, we confirm that the proposed algorithm outperforms other\nexisting algorithms in terms of the number of serviced passengers increase\n(30%) and the waiting time per serviced passenger decrease (26%).\n",
        "pdf_link": "http://arxiv.org/pdf/2211.06890v2"
    },
    {
        "title": "Greedy based Value Representation for Optimal Coordination in\n  Multi-agent Reinforcement Learning",
        "authors": [
            "Lipeng Wan",
            "Zeyang Liu",
            "Xingyu Chen",
            "Xuguang Lan",
            "Nanning Zheng"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Due to the representation limitation of the joint Q value function,\nmulti-agent reinforcement learning methods with linear value decomposition\n(LVD) or monotonic value decomposition (MVD) suffer from relative\novergeneralization. As a result, they can not ensure optimal consistency (i.e.,\nthe correspondence between individual greedy actions and the maximal true Q\nvalue). In this paper, we derive the expression of the joint Q value function\nof LVD and MVD. According to the expression, we draw a transition diagram,\nwhere each self-transition node (STN) is a possible convergence. To ensure\noptimal consistency, the optimal node is required to be the unique STN.\nTherefore, we propose the greedy-based value representation (GVR), which turns\nthe optimal node into an STN via inferior target shaping and further eliminates\nthe non-optimal STNs via superior experience replay. In addition, GVR achieves\nan adaptive trade-off between optimality and stability. Our method outperforms\nstate-of-the-art baselines in experiments on various benchmarks. Theoretical\nproofs and empirical results on matrix games demonstrate that GVR ensures\noptimal consistency under sufficient exploration.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.12075v1"
    },
    {
        "title": "Dynamic and Distributed Optimization for the Allocation of Aerial Swarm\n  Vehicles",
        "authors": [
            "Jason Hughes",
            "Dominic Larkin",
            "Charles O'Donnell",
            "Christopher Korpela"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Optimal transport (OT) is a framework that can guide the design of efficient\nresource allocation strategies in a network of multiple sources and targets.\nThis paper applies discrete OT to a swarm of UAVs in a novel way to achieve\nappropriate task allocation and execution. Drone swarm deployments already\noperate in multiple domains where sensors are used to gain knowledge of an\nenvironment [1]. Use cases such as, chemical and radiation detection, and\nthermal and RGB imaging create a specific need for an algorithm that considers\nparameters on both the UAV and waypoint side and allows for updating the\nmatching scheme as the swarm gains information from the environment.\nAdditionally, the need for a centralized planner can be removed by using a\ndistributed algorithm that can dynamically update based on changes in the swarm\nnetwork or parameters. To this end, we develop a dynamic and distributed OT\nalgorithm that matches a UAV to the optimal waypoint based on one parameter at\nthe UAV and another parameter at the waypoint. We show the convergence and\nallocation of the algorithm through a case study and test the algorithm's\neffectiveness against a greedy assignment algorithm in simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.17077v1"
    },
    {
        "title": "A Comparison of New Swarm Task Allocation Algorithms in Unknown\n  Environments with Varying Task Density",
        "authors": [
            "Grace Cai",
            "Noble Harasha",
            "Nancy Lynch"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Task allocation is an important problem for robot swarms to solve, allowing\nagents to reduce task completion time by performing tasks in a distributed\nfashion. Existing task allocation algorithms often assume prior knowledge of\ntask location and demand or fail to consider the effects of the geometric\ndistribution of tasks on the completion time and communication cost of the\nalgorithms. In this paper, we examine an environment where agents must explore\nand discover tasks with positive demand and successfully assign themselves to\ncomplete all such tasks. We first provide a new discrete general model for\nmodeling swarms. Operating within this theoretical framework, we propose two\nnew task allocation algorithms for initially unknown environments -- one based\non N-site selection and the other on virtual pheromones. We analyze each\nalgorithm separately and also evaluate the effectiveness of the two algorithms\nin dense vs. sparse task distributions. Compared to the Levy walk, which has\nbeen theorized to be optimal for foraging, our virtual pheromone inspired\nalgorithm is much faster in sparse to medium task densities but is\ncommunication and agent intensive. Our site selection inspired algorithm also\noutperforms Levy walk in sparse task densities and is a less resource-intensive\noption than our virtual pheromone algorithm for this case. Because the\nperformance of both algorithms relative to random walk is dependent on task\ndensity, our results shed light on how task density is important in choosing a\ntask allocation algorithm in initially unknown environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.00844v3"
    },
    {
        "title": "Flexible social inference facilitates targeted social learning when\n  rewards are not observable",
        "authors": [
            "Robert D. Hawkins",
            "Andrew M. Berdahl",
            "Alex \"Sandy\" Pentland",
            "Joshua B. Tenenbaum",
            "Noah D. Goodman",
            "P. M. Krafft"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Groups coordinate more effectively when individuals are able to learn from\nothers' successes. But acquiring such knowledge is not always easy, especially\nin real-world environments where success is hidden from public view. We suggest\nthat social inference capacities may help bridge this gap, allowing individuals\nto update their beliefs about others' underlying knowledge and success from\nobservable trajectories of behavior. We compared our social inference model\nagainst simpler heuristics in three studies of human behavior in a collective\nsensing task. In Experiment 1, we found that average performance improves as a\nfunction of group size at a rate greater than predicted by non-inferential\nmodels. Experiment 2 introduced artificial agents to evaluate how individuals\nselectively rely on social information. Experiment 3 generalized these findings\nto a more complex reward landscape. Taken together, our findings provide\ninsight into the relationship between individual social cognition and the\nflexibility of collective behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.00869v2"
    },
    {
        "title": "Cooperative control of environmental extremes by artificial intelligent\n  agents",
        "authors": [
            "Martí Sánchez-Fibla",
            "Clément Moulin-Frier",
            "Ricard Solé"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Humans have been able to tackle biosphere complexities by acting as ecosystem\nengineers, profoundly changing the flows of matter, energy and information.\nThis includes major innovations that allowed to reduce and control the impact\nof extreme events. Modelling the evolution of such adaptive dynamics can be\nchallenging given the potentially large number of individual and environmental\nvariables involved. This paper shows how to address this problem by using fire\nas the source of external, bursting and wide fluctuations. Fire propagates on a\nspatial landscape where a group of agents harvest and exploit trees while\navoiding the damaging effects of fire spreading. The agents need to solve a\nconflict to reach a group-level optimal state: while tree harvesting reduces\nthe propagation of fires, it also reduces the availability of resources\nprovided by trees. It is shown that the system displays two major evolutionary\ninnovations that end up in an ecological engineering strategy that favours high\nbiomass along with the suppression of large fires. The implications for\npotential A.I. management of complex ecosystems are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.02395v1"
    },
    {
        "title": "Scalable and Sample Efficient Distributed Policy Gradient Algorithms in\n  Multi-Agent Networked Systems",
        "authors": [
            "Xin Liu",
            "Honghao Wei",
            "Lei Ying"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper studies a class of multi-agent reinforcement learning (MARL)\nproblems where the reward that an agent receives depends on the states of other\nagents, but the next state only depends on the agent's own current state and\naction. We name it REC-MARL standing for REward-Coupled Multi-Agent\nReinforcement Learning. REC-MARL has a range of important applications such as\nreal-time access control and distributed power control in wireless networks.\nThis paper presents a distributed policy gradient algorithm for REC-MARL. The\nproposed algorithm is distributed in two aspects: (i) the learned policy is a\ndistributed policy that maps a local state of an agent to its local action and\n(ii) the learning/training is distributed, during which each agent updates its\npolicy based on its own and neighbors' information. The learned algorithm\nachieves a stationary policy and its iterative complexity bounds depend on the\ndimension of local states and actions. The experimental results of our\nalgorithm for the real-time access control and power control in wireless\nnetworks show that our policy significantly outperforms the state-of-the-art\nalgorithms and well-known benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.06357v2"
    },
    {
        "title": "Natural Way of Solving a Convex Hull Problem",
        "authors": [
            "Sina Saadati",
            "Mohammadreza Razzazi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this article, a new solution for the convex hull problem has been\npresented. The convex hull is a widely known problem in computational geometry.\nAs nature is a rich source of ideas in the field of algorithms, the solution\nhas been inspired by nature. A tight elastic band is modeled using agents and\nalso nails as points of the problem. By simulating an elastic band with nails\nin an environment, solving the convex hull problem will be possible. The\nalgorithm runs in O(t) in which t is the time that an elastic band will get\nfixed.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.11999v1"
    },
    {
        "title": "Learning Individual Policies in Large Multi-agent Systems through Local\n  Variance Minimization",
        "authors": [
            "Tanvi Verma",
            "Pradeep Varakantham"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In multi-agent systems with large number of agents, typically the\ncontribution of each agent to the value of other agents is minimal (e.g.,\naggregation systems such as Uber, Deliveroo). In this paper, we consider such\nmulti-agent systems where each agent is self-interested and takes a sequence of\ndecisions and represent them as a Stochastic Non-atomic Congestion Game (SNCG).\nWe derive key properties for equilibrium solutions in SNCG model with\nnon-atomic and also nearly non-atomic agents. With those key equilibrium\nproperties, we provide a novel Multi-Agent Reinforcement Learning (MARL)\nmechanism that minimizes variance across values of agents in the same state. To\ndemonstrate the utility of this new mechanism, we provide detailed results on a\nreal-world taxi dataset and also a generic simulator for aggregation systems.\nWe show that our approach reduces the variance in revenues earned by taxi\ndrivers, while still providing higher joint revenues than leading approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.13379v1"
    },
    {
        "title": "An Auction-based Coordination Strategy for Task-Constrained Multi-Agent\n  Stochastic Planning with Submodular Rewards",
        "authors": [
            "Ruifan Liu",
            "Hyo-Sang Shin",
            "Binbin Yan",
            "Antonios Tsourdos"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In many domains such as transportation and logistics, search and rescue, or\ncooperative surveillance, tasks are pending to be allocated with the\nconsideration of possible execution uncertainties. Existing task coordination\nalgorithms either ignore the stochastic process or suffer from the\ncomputational intensity. Taking advantage of the weakly coupled feature of the\nproblem and the opportunity for coordination in advance, we propose a\ndecentralized auction-based coordination strategy using a newly formulated\nscore function which is generated by forming the problem into task-constrained\nMarkov decision processes (MDPs). The proposed method guarantees convergence\nand at least 50% optimality in the premise of a submodular reward function.\nFurthermore, for the implementation on large-scale applications, an approximate\nvariant of the proposed method, namely Deep Auction, is also suggested with the\nuse of neural networks, which is evasive of the troublesome for constructing\nMDPs. Inspired by the well-known actor-critic architecture, two Transformers\nare used to map observations to action probabilities and cumulative rewards\nrespectively. Finally, we demonstrate the performance of the two proposed\napproaches in the context of drone deliveries, where the stochastic planning\nfor the drone league is cast into a stochastic price-collecting Vehicle Routing\nProblem (VRP) with time windows. Simulation results are compared with\nstate-of-the-art methods in terms of solution quality, planning efficiency and\nscalability.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.14624v2"
    },
    {
        "title": "Towards Evology: a Market Ecology Agent-Based Model of US Equity Mutual\n  Funds II",
        "authors": [
            "Aymeric Vie",
            "J. Doyne Farmer"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Agent-based models (ABMs) are fit to model heterogeneous, interacting systems\nlike financial markets. We present the latest advances in Evology: a\nheterogeneous, empirically calibrated market ecology agent-based model of the\nUS stock market. Prices emerge endogenously from the interactions of market\nparticipants with diverse investment behaviours and their reactions to\nfundamentals. This approach allows testing trading strategies while accounting\nfor the interactions of this strategy with other market participants and\nconditions. Those early results encourage a closer association between ABMs and\nML algorithms for testing and optimising investment strategies using machine\nlearning algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.01216v1"
    },
    {
        "title": "Ensemble Value Functions for Efficient Exploration in Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Lukas Schäfer",
            "Oliver Slumbers",
            "Stephen McAleer",
            "Yali Du",
            "Stefano V. Albrecht",
            "David Mguni"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Existing value-based algorithms for cooperative multi-agent reinforcement\nlearning (MARL) commonly rely on random exploration, such as $\\epsilon$-greedy,\nto explore the environment. However, such exploration is inefficient at finding\neffective joint actions in states that require cooperation of multiple agents.\nIn this work, we propose ensemble value functions for multi-agent exploration\n(EMAX), a general framework to seamlessly extend value-based MARL algorithms\nwith ensembles of value functions. EMAX leverages the ensemble of value\nfunctions to guide the exploration of agents, stabilises their optimisation,\nand makes their policies more robust to miscoordination. These benefits are\nachieved by using a combination of three techniques. (1) EMAX uses the\nuncertainty of value estimates across the ensemble in a UCB policy to guide the\nexploration. This exploration policy focuses on parts of the environment which\nrequire cooperation across agents and, thus, enables agents to more efficiently\nlearn how to cooperate. (2) During the optimisation, EMAX computes target\nvalues as average value estimates across the ensemble. These targets exhibit\nlower variance compared to commonly applied target networks, leading to\nsignificant benefits in MARL which commonly suffers from high variance caused\nby the exploration and non-stationary policies of other agents. (3) During\nevaluation, EMAX selects actions following a majority vote across the ensemble,\nwhich reduces the likelihood of selecting sub-optimal actions. We instantiate\nthree value-based MARL algorithms with EMAX, independent DQN, VDN and QMIX, and\nevaluate them in 21 tasks across four environments. Using ensembles of five\nvalue functions, EMAX improves sample efficiency and final evaluation returns\nof these algorithms by 60%, 47%, and 539%, respectively, averaged across 21\ntasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03439v6"
    },
    {
        "title": "Low Entropy Communication in Multi-Agent Reinforcement Learning",
        "authors": [
            "Lebin Yu",
            "Yunbo Qiu",
            "Qiexiang Wang",
            "Xudong Zhang",
            "Jian Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Communication in multi-agent reinforcement learning has been drawing\nattention recently for its significant role in cooperation. However,\nmulti-agent systems may suffer from limitations on communication resources and\nthus need efficient communication techniques in real-world scenarios. According\nto the Shannon-Hartley theorem, messages to be transmitted reliably in worse\nchannels require lower entropy. Therefore, we aim to reduce message entropy in\nmulti-agent communication. A fundamental challenge is that the gradients of\nentropy are either 0 or infinity, disabling gradient-based methods. To handle\nit, we propose a pseudo gradient descent scheme, which reduces entropy by\nadjusting the distributions of messages wisely. We conduct experiments on two\nbase communication frameworks with six environment settings and find that our\nscheme can reduce message entropy by up to 90% with nearly no loss of\ncooperation performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.05055v1"
    },
    {
        "title": "Learning Hierarchical Resource Allocation and Multi-agent Coordination\n  of 5G mobile IAB Nodes",
        "authors": [
            "Mohamed Sana",
            "Benoit Miscopein"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We consider a dynamic millimeter-wave network with integrated access and\nbackhaul, where mobile relay nodes move to auto-reconfigure the wireless\nbackhaul. Specifically, we focus on in-band relaying networks, which conduct\naccess and backhaul links on the same frequency band with severe constraints on\nco-channel interference. In this context, we jointly study the complex problem\nof dynamic relay node positioning, user association, and backhaul capacity\nallocation. To address this problem, with limited complexity, we adopt a\nhierarchical multi-agent reinforcement with a two-level structure. A high-level\npolicy dynamically coordinates mobile relay nodes, defining the backhaul\nconfiguration for a low-level policy, which jointly assigns user equipment to\neach relay and allocates the backhaul capacity accordingly. The resulting\nsolution automatically adapts the access and backhaul network to changes in the\nnumber of users, the traffic distribution, and the variations of the channels.\nNumerical results show the effectiveness of our proposed solution in terms of\nconvergence of the hierarchical learning procedure. It also provides a\nsignificant backhaul capacity and network sum-rate increase (up to 3.5x)\ncompared to baseline approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.07573v1"
    },
    {
        "title": "Distributed Planning with Asynchronous Execution with Local Navigation\n  for Multi-agent Pickup and Delivery Problem",
        "authors": [
            "Yuki Miyashita",
            "Tomoki Yamauchi",
            "Toshiharu Sugawara"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We propose a distributed planning method with asynchronous execution for\nmulti-agent pickup and delivery (MAPD) problems for environments with\noccasional delays in agents' activities and flexible endpoints. MAPD is a\ncrucial problem framework with many applications; however, most existing\nstudies assume ideal agent behaviors and environments, such as a fixed speed of\nagents, synchronized movements, and a well-designed environment with many short\ndetours for multiple agents to perform tasks easily. However, such an\nenvironment is often infeasible; for example, the moving speed of agents may be\naffected by weather and floor conditions and is often prone to delays. The\nproposed method can relax some infeasible conditions to apply MAPD in more\nrealistic environments by allowing fluctuated speed in agents' actions and\nflexible working locations (endpoints). Our experiments showed that our method\nenables agents to perform MAPD in such an environment efficiently, compared to\nthe baseline methods. We also analyzed the behaviors of agents using our method\nand discuss the limitations.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09250v1"
    },
    {
        "title": "An agent-based model of the 2020 international policy diffusion in\n  response to the COVID-19 pandemic with particle filter",
        "authors": [
            "Yannick Oswald",
            "Nick Malleson",
            "Keiran Suchak"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Global problems, such as pandemics and climate change, require rapid\ninternational coordination and diffusion of policy. These phenomena are rare\nhowever, with one notable example being the international policy response to\nthe COVID-19 pandemic in early 2020. Here we build an agent-based model of this\nrapid policy diffusion, where countries constitute the agents and with the\nprincipal mechanism for diffusion being peer mimicry. Since it is challenging\nto predict accurately the policy diffusion curve, we utilize data assimilation,\nthat is an ``on-line'' feed of data to constrain the model against\nobservations. The specific data assimilation algorithm we apply is a particle\nfilter because of its convenient implementation, its ability to handle\ncategorical variables and because the model is not overly computationally\nexpensive, hence a more efficient algorithm is not required. We find that the\nmodel alone is able to predict the policy diffusion relatively well with an\nensemble of at least 100 simulation runs. The particle filter however improves\nthe fit to the data, reliably so from 500 runs upwards, and increasing\nfiltering frequency results in improved prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.11277v1"
    },
    {
        "title": "Decentralized core-periphery structure in social networks accelerates\n  cultural innovation in agent-based model",
        "authors": [
            "Jesse Milzman",
            "Cody Moser"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Previous investigations into creative and innovation networks have suggested\nthat innovations often occurs at the boundary between the network's core and\nperiphery. In this work, we investigate the effect of global core-periphery\nnetwork structure on the speed and quality of cultural innovation. Drawing on\ndiffering notions of core-periphery structure from [arXiv:1808.07801] and\n[doi:10.1016/S0378-8733(99)00019-2], we distinguish decentralized\ncore-periphery, centralized core-periphery, and affinity network structure. We\ngenerate networks of these three classes from stochastic block models (SBMs),\nand use them to run an agent-based model (ABM) of collective cultural\ninnovation, in which agents can only directly interact with their network\nneighbors. In order to discover the highest-scoring innovation, agents must\ndiscover and combine the highest innovations from two completely parallel\ntechnology trees. We find that decentralized core-periphery networks outperform\nthe others by finding the final crossover innovation more quickly on average.\nWe hypothesize that decentralized core-periphery network structure accelerates\ncollective problem-solving by shielding peripheral nodes from the local optima\nknown by the core community at any given time. We then build upon the \"Two\nTruths\" hypothesis regarding community structure in spectral graph embeddings,\nfirst articulated in [arXiv:1808.07801], which suggests that the adjacency\nspectral embedding (ASE) captures core-periphery structure, while the Laplacian\nspectral embedding (LSE) captures affinity. We find that, for core-periphery\nnetworks, ASE-based resampling best recreates networks with similar performance\non the innovation SBM, compared to LSE-based resampling. Since the Two Truths\nhypothesis suggests that ASE captures core-periphery structure, this result\nfurther supports our hypothesis.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12121v1"
    },
    {
        "title": "AC2C: Adaptively Controlled Two-Hop Communication for Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Xuefeng Wang",
            "Xinran Li",
            "Jiawei Shao",
            "Jun Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Learning communication strategies in cooperative multi-agent reinforcement\nlearning (MARL) has recently attracted intensive attention. Early studies\ntypically assumed a fully-connected communication topology among agents, which\ninduces high communication costs and may not be feasible. Some recent works\nhave developed adaptive communication strategies to reduce communication\noverhead, but these methods cannot effectively obtain valuable information from\nagents that are beyond the communication range. In this paper, we consider a\nrealistic communication model where each agent has a limited communication\nrange, and the communication topology dynamically changes. To facilitate\neffective agent communication, we propose a novel communication protocol called\nAdaptively Controlled Two-Hop Communication (AC2C). After an initial local\ncommunication round, AC2C employs an adaptive two-hop communication strategy to\nenable long-range information exchange among agents to boost performance, which\nis implemented by a communication controller. This controller determines\nwhether each agent should ask for two-hop messages and thus helps to reduce the\ncommunication overhead during distributed execution. We evaluate AC2C on three\ncooperative multi-agent tasks, and the experimental results show that it\noutperforms relevant baselines with lower communication costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12515v2"
    },
    {
        "title": "A Variational Approach to Mutual Information-Based Coordination for\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Woojun Kim",
            "Whiyoung Jung",
            "Myungsik Cho",
            "Youngchul Sung"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we propose a new mutual information framework for multi-agent\nreinforcement learning to enable multiple agents to learn coordinated behaviors\nby regularizing the accumulated return with the simultaneous mutual information\nbetween multi-agent actions. By introducing a latent variable to induce nonzero\nmutual information between multi-agent actions and applying a variational\nbound, we derive a tractable lower bound on the considered MMI-regularized\nobjective function. The derived tractable objective can be interpreted as\nmaximum entropy reinforcement learning combined with uncertainty reduction of\nother agents actions. Applying policy iteration to maximize the derived lower\nbound, we propose a practical algorithm named variational maximum mutual\ninformation multi-agent actor-critic, which follows centralized learning with\ndecentralized execution. We evaluated VM3-AC for several games requiring\ncoordination, and numerical results show that VM3-AC outperforms other MARL\nalgorithms in multi-agent tasks requiring high-quality coordination.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00451v1"
    },
    {
        "title": "Parameter Sharing with Network Pruning for Scalable Multi-Agent Deep\n  Reinforcement Learning",
        "authors": [
            "Woojun Kim",
            "Youngchul Sung"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Handling the problem of scalability is one of the essential issues for\nmulti-agent reinforcement learning (MARL) algorithms to be applied to\nreal-world problems typically involving massively many agents. For this,\nparameter sharing across multiple agents has widely been used since it reduces\nthe training time by decreasing the number of parameters and increasing the\nsample efficiency. However, using the same parameters across agents limits the\nrepresentational capacity of the joint policy and consequently, the performance\ncan be degraded in multi-agent tasks that require different behaviors for\ndifferent agents. In this paper, we propose a simple method that adopts\nstructured pruning for a deep neural network to increase the representational\ncapacity of the joint policy without introducing additional parameters. We\nevaluate the proposed method on several benchmark tasks, and numerical results\nshow that the proposed method significantly outperforms other parameter-sharing\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.00912v1"
    },
    {
        "title": "Multi-agent Distributed Model Predictive Control with Connectivity\n  Constraint",
        "authors": [
            "Andrea Carron",
            "Danilo Saccani",
            "Lorenzo Fagiano",
            "Melanie N. Zeilinger"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In cooperative multi-agent robotic systems, coordination is necessary in\norder to complete a given task. Important examples include search and rescue,\noperations in hazardous environments, and environmental monitoring.\nCoordination, in turn, requires simultaneous satisfaction of safety critical\nconstraints, in the form of state and input constraints, and a connectivity\nconstraint, in order to ensure that at every time instant there exists a\ncommunication path between every pair of agents in the network. In this work,\nwe present a model predictive controller that tackles the problem of performing\nmulti-agent coordination while simultaneously satisfying safety critical and\nconnectivity constraints. The former is formulated in the form of state and\ninput constraints and the latter as a constraint on the second smallest\neigenvalue of the associated communication graph Laplacian matrix, also known\nas Fiedler eigenvalue, which enforces the connectivity of the communication\nnetwork. We propose a sequential quadratic programming formulation to solve the\nassociated optimization problem that is amenable to distributed optimization,\nmaking the proposed solution suitable for control of multi-agent robotics\nsystems relying on local computation. Finally, the effectiveness of the\nalgorithm is highlighted with a numerical simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.06957v1"
    },
    {
        "title": "Efficient Planning of Multi-Robot Collective Transport using Graph\n  Reinforcement Learning with Higher Order Topological Abstraction",
        "authors": [
            "Steve Paul",
            "Wenyuan Li",
            "Brian Smyth",
            "Yuzhou Chen",
            "Yulia Gel",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Efficient multi-robot task allocation (MRTA) is fundamental to various\ntime-sensitive applications such as disaster response, warehouse operations,\nand construction. This paper tackles a particular class of these problems that\nwe call MRTA-collective transport or MRTA-CT -- here tasks present varying\nworkloads and deadlines, and robots are subject to flight range, communication\nrange, and payload constraints. For large instances of these problems involving\n100s-1000's of tasks and 10s-100s of robots, traditional non-learning solvers\nare often time-inefficient, and emerging learning-based policies do not scale\nwell to larger-sized problems without costly retraining. To address this gap,\nwe use a recently proposed encoder-decoder graph neural network involving\nCapsule networks and multi-head attention mechanism, and innovatively add\ntopological descriptors (TD) as new features to improve transferability to\nunseen problems of similar and larger size. Persistent homology is used to\nderive the TD, and proximal policy optimization is used to train our\nTD-augmented graph neural network. The resulting policy model compares\nfavorably to state-of-the-art non-learning baselines while being much faster.\nThe benefit of using TD is readily evident when scaling to test problems of\nsize larger than those used in training.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.08933v2"
    },
    {
        "title": "Integrated Design of Cooperative Area Coverage and Target Tracking with\n  Multi-UAV System",
        "authors": [
            "Mengge Zhang",
            "Jie Li",
            "Xiangke Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper systematically studies the cooperative area coverage and target\ntracking problem of multiple-unmanned aerial vehicles (multi-UAVs). The problem\nis solved by decomposing into three sub-problems: information fusion, task\nassignment, and multi-UAV behavior decision-making. Specifically, in the\ninformation fusion process, we use the maximum consistency protocol to update\nthe joint estimation states of multi-targets (JESMT) and the area detection\ninformation. The area detection information is represented by the equivalent\nvisiting time map (EVTM), which is built based on the detection probability and\nthe actual visiting time of the area. Then, we model the task assignment\nproblem of multi-UAV searching and tracking multi-targets as a network flow\nmodel with upper and lower flow bounds. An algorithm named task assignment\nminimum-cost maximum-flow (TAMM) is proposed. Cooperative behavior\ndecision-making uses Fisher information as the mission reward to obtain the\noptimal tracking action of the UAV. Furthermore, a coverage behavior\ndecision-making algorithm based on the anti-flocking method is designed for\nthose UAVs assigned the coverage task. Finally, a distributed multi-UAV\ncooperative area coverage and target tracking algorithm is designed, which\nintegrates information fusion, task assignment, and behavioral decision-making.\nNumerical and hardware-in-the-loop simulation results show that the proposed\nmethod can achieve persistent area coverage and cooperative target tracking.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.09003v1"
    },
    {
        "title": "marl-jax: Multi-Agent Reinforcement Leaning Framework",
        "authors": [
            "Kinal Mehta",
            "Anuj Mahajan",
            "Pawan Kumar"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Recent advances in Reinforcement Learning (RL) have led to many exciting\napplications. These advancements have been driven by improvements in both\nalgorithms and engineering, which have resulted in faster training of RL\nagents. We present marl-jax, a multi-agent reinforcement learning software\npackage for training and evaluating social generalization of the agents. The\npackage is designed for training a population of agents in multi-agent\nenvironments and evaluating their ability to generalize to diverse background\nagents. It is built on top of DeepMind's JAX ecosystem~\\cite{deepmind2020jax}\nand leverages the RL ecosystem developed by DeepMind. Our framework marl-jax is\ncapable of working in cooperative and competitive, simultaneous-acting\nenvironments with multiple agents. The package offers an intuitive and\nuser-friendly command-line interface for training a population and evaluating\nits generalization capabilities. In conclusion, marl-jax provides a valuable\nresource for researchers interested in exploring social generalization in the\ncontext of MARL. The open-source code for marl-jax is available at:\n\\href{https://github.com/kinalmehta/marl-jax}{https://github.com/kinalmehta/marl-jax}\n",
        "pdf_link": "http://arxiv.org/pdf/2303.13808v2"
    },
    {
        "title": "Attrition-Aware Adaptation for Multi-Agent Patrolling",
        "authors": [
            "Anthony Goeckner",
            "Xinliang Li",
            "Ermin Wei",
            "Qi Zhu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent patrolling is a key problem in a variety of domains such as\nintrusion detection, area surveillance, and policing which involves repeated\nvisits by a group of agents to specified points in an environment. While the\nproblem is well-studied, most works do not provide performance guarantees and\neither do not consider agent attrition or impose significant communication\nrequirements to enable adaptation. In this work, we present the Adaptive\nHeuristic-based Patrolling Algorithm, which is capable of adaptation to agent\nloss using minimal communication by taking advantage of Voronoi partitioning,\nand which meets guaranteed performance bounds. Additionally, we provide new\ncentralized and distributed mathematical programming formulations of the\npatrolling problem, analyze the properties of Voronoi partitioning, and\nfinally, show the value of our adaptive heuristic algorithm by comparison with\nvarious benchmark algorithms using physical robots and simulation based on the\nRobot Operating System (ROS) 2.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01386v3"
    },
    {
        "title": "Agent-Based Modeling and its Tradeoffs: An Introduction & Examples",
        "authors": [
            "G. Wade McDonald",
            "Nathaniel D. Osgood"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Agent-based modeling is a computational dynamic modeling technique that may\nbe less familiar to some readers. Agent-based modeling seeks to understand the\nbehaviour of complex systems by situating agents in an environment and studying\nthe emergent outcomes of agent-agent and agent-environment interactions. In\ncomparison with compartmental models, agent-based models offer simpler, more\nscalable and flexible representation of heterogeneity, the ability to capture\ndynamic and static network and spatial context, and the ability to consider\nhistory of individuals within the model. In contrast, compartmental models\noffer faster development time with less programming required, lower\ncomputational requirements that do not scale with population, and the option\nfor concise mathematical formulation with ordinary, delay or stochastic\ndifferential equations supporting derivation of properties of the system\nbehaviour. In this chapter, basic characteristics of agent-based models are\nintroduced, advantages and disadvantages of agent-based models, as compared\nwith compartmental models, are discussed, and two example agent-based\ninfectious disease models are reviewed.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.08497v1"
    },
    {
        "title": "Deep Continuum Deformation Coordination and Optimization with Safety\n  Guarantees",
        "authors": [
            "Harshvardhan Uppaluru",
            "Hossein Rastgoftar"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we develop and present a novel strategy for safe coordination\nof a large-scale multi-agent team with ``\\textit{local deformation}\"\ncapabilities. Multi-agent coordination is defined by our proposed method as a\nmulti-layer deformation problem specified as a Deep Neural Network (DNN)\noptimization problem. The proposed DNN consists of $p$ hidden layers, each of\nwhich contains artificial neurons representing unique agents. Furthermore,\nbased on the desired positions of the agents of hidden layer $k$\n($k=1,\\cdots,p-1$), the desired deformation of the agents of hidden layer $k +\n1$ is planned. In contrast to the available neural network learning problems,\nour proposed neural network optimization receives time-invariant reference\npositions of the boundary agents as inputs and trains the weights based on the\ndesired trajectory of the agent team configuration, where the weights are\nconstrained by certain lower and upper bounds to ensure inter-agent collision\navoidance. We simulate and provide the results of a large-scale quadcopter team\ncoordination tracking a desired elliptical trajectory to validate the proposed\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.08638v1"
    },
    {
        "title": "Inducing Stackelberg Equilibrium through Spatio-Temporal Sequential\n  Decision-Making in Multi-Agent Reinforcement Learning",
        "authors": [
            "Bin Zhang",
            "Lijuan Li",
            "Zhiwei Xu",
            "Dapeng Li",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In multi-agent reinforcement learning (MARL), self-interested agents attempt\nto establish equilibrium and achieve coordination depending on game structure.\nHowever, existing MARL approaches are mostly bound by the simultaneous actions\nof all agents in the Markov game (MG) framework, and few works consider the\nformation of equilibrium strategies via asynchronous action coordination. In\nview of the advantages of Stackelberg equilibrium (SE) over Nash equilibrium,\nwe construct a spatio-temporal sequential decision-making structure derived\nfrom the MG and propose an N-level policy model based on a conditional\nhypernetwork shared by all agents. This approach allows for asymmetric training\nwith symmetric execution, with each agent responding optimally conditioned on\nthe decisions made by superior agents. Agents can learn heterogeneous SE\npolicies while still maintaining parameter sharing, which leads to reduced cost\nfor learning and storage and enhanced scalability as the number of agents\nincreases. Experiments demonstrate that our method effectively converges to the\nSE policies in repeated matrix game scenarios, and performs admirably in\nimmensely complex settings including cooperative tasks and mixed tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.10351v2"
    },
    {
        "title": "Heterogeneous Social Value Orientation Leads to Meaningful Diversity in\n  Sequential Social Dilemmas",
        "authors": [
            "Udari Madhushani",
            "Kevin R. McKee",
            "John P. Agapiou",
            "Joel Z. Leibo",
            "Richard Everett",
            "Thomas Anthony",
            "Edward Hughes",
            "Karl Tuyls",
            "Edgar A. Duéñez-Guzmán"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In social psychology, Social Value Orientation (SVO) describes an\nindividual's propensity to allocate resources between themself and others. In\nreinforcement learning, SVO has been instantiated as an intrinsic motivation\nthat remaps an agent's rewards based on particular target distributions of\ngroup reward. Prior studies show that groups of agents endowed with\nheterogeneous SVO learn diverse policies in settings that resemble the\nincentive structure of Prisoner's dilemma. Our work extends this body of\nresults and demonstrates that (1) heterogeneous SVO leads to meaningfully\ndiverse policies across a range of incentive structures in sequential social\ndilemmas, as measured by task-specific diversity metrics; and (2) learning a\nbest response to such policy diversity leads to better zero-shot generalization\nin some situations. We show that these best-response agents learn policies that\nare conditioned on their co-players, which we posit is the reason for improved\nzero-shot generalization results.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00768v1"
    },
    {
        "title": "Attention Based Feature Fusion For Multi-Agent Collaborative Perception",
        "authors": [
            "Ahmed N. Ahmed",
            "Siegfried Mercelis",
            "Ali Anwar"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In the domain of intelligent transportation systems (ITS), collaborative\nperception has emerged as a promising approach to overcome the limitations of\nindividual perception by enabling multiple agents to exchange information, thus\nenhancing their situational awareness. Collaborative perception overcomes the\nlimitations of individual sensors, allowing connected agents to perceive\nenvironments beyond their line-of-sight and field of view. However, the\nreliability of collaborative perception heavily depends on the data aggregation\nstrategy and communication bandwidth, which must overcome the challenges posed\nby limited network resources. To improve the precision of object detection and\nalleviate limited network resources, we propose an intermediate collaborative\nperception solution in the form of a graph attention network (GAT). The\nproposed approach develops an attention-based aggregation strategy to fuse\nintermediate representations exchanged among multiple connected agents. This\napproach adaptively highlights important regions in the intermediate feature\nmaps at both the channel and spatial levels, resulting in improved object\ndetection precision. We propose a feature fusion scheme using attention-based\narchitectures and evaluate the results quantitatively in comparison to other\nstate-of-the-art collaborative perception approaches. Our proposed approach is\nvalidated using the V2XSim dataset. The results of this work demonstrate the\nefficacy of the proposed approach for intermediate collaborative perception in\nimproving object detection average precision while reducing network resource\nusage.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.02061v1"
    },
    {
        "title": "Social Value Orientation and Integral Emotions in Multi-Agent Systems",
        "authors": [
            "Daniel Collins",
            "Conor Houghton",
            "Nirav Ajmeri"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Human social behavior is influenced by individual differences in social\npreferences. Social value orientation (SVO) is a measurable personality trait\nwhich indicates the relative importance an individual places on their own and\non others' welfare when making decisions. SVO and other individual difference\nvariables are strong predictors of human behavior and social outcomes. However,\nthere are transient changes human behavior associated with emotions that are\nnot captured by individual differences alone. Integral emotions, the emotions\nwhich arise in direct response to a decision-making scenario, have been linked\nto temporary shifts in decision-making preferences.\n  In this work, we investigated the effects of moderating social preferences\nwith integral emotions in multi-agent societies. We developed Svoie, a method\nfor designing agents which make decisions based on established SVO policies, as\nwell as alternative integral emotion policies in response to task outcomes. We\nconducted simulation experiments in a resource-sharing task environment, and\ncompared societies of Svoie agents with societies of agents with fixed SVO\npolicies. We find that societies of agents which adapt their behavior through\nintegral emotions achieved similar collective welfare to societies of agents\nwith fixed SVO policies, but with significantly reduced inequality between the\nwelfare of agents with different SVO traits. We observed that by allowing\nagents to change their policy in response to task outcomes, agents can moderate\ntheir behavior to achieve greater social equality. \\end{abstract}\n",
        "pdf_link": "http://arxiv.org/pdf/2305.05549v1"
    },
    {
        "title": "Boosting Value Decomposition via Unit-Wise Attentive State\n  Representation for Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Qingpeng Zhao",
            "Yuanyang Zhu",
            "Zichuan Liu",
            "Zhi Wang",
            "Chunlin Chen"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In cooperative multi-agent reinforcement learning (MARL), the environmental\nstochasticity and uncertainties will increase exponentially when the number of\nagents increases, which puts hard pressure on how to come up with a compact\nlatent representation from partial observation for boosting value\ndecomposition. To tackle these issues, we propose a simple yet powerful method\nthat alleviates partial observability and efficiently promotes coordination by\nintroducing the UNit-wise attentive State Representation (UNSR). In UNSR, each\nagent learns a compact and disentangled unit-wise state representation\noutputted from transformer blocks, and produces its local action-value\nfunction. The proposed UNSR is used to boost the value decomposition with a\nmulti-head attention mechanism for producing efficient credit assignment in the\nmixing network, providing an efficient reasoning path between the individual\nvalue function and joint value function. Experimental results demonstrate that\nour method achieves superior performance and data efficiency compared to solid\nbaselines on the StarCraft II micromanagement challenge. Additional ablation\nexperiments also help identify the key factors contributing to the performance\nof UNSR.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.07182v1"
    },
    {
        "title": "On a Voter Model with Context-Dependent Opinion Adoption",
        "authors": [
            "Luca Becchetti",
            "Vincenzo Bonifaci",
            "Emilio Cruciani",
            "Francesco Pasquale"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Opinion diffusion is a crucial phenomenon in social networks, often\nunderlying the way in which a collective of agents develops a consensus on\nrelevant decisions. The voter model is a well-known theoretical model to study\nopinion spreading in social networks and structured populations. Its simplest\nversion assumes that an updating agent will adopt the opinion of a neighboring\nagent chosen at random. The model allows us to study, for example, the\nprobability that a certain opinion will fixate into a consensus opinion, as\nwell as the expected time it takes for a consensus opinion to emerge.\n  Standard voter models are oblivious to the opinions held by the agents\ninvolved in the opinion adoption process. We propose and study a\ncontext-dependent opinion spreading process on an arbitrary social graph, in\nwhich the probability that an agent abandons opinion $a$ in favor of opinion\n$b$ depends on both $a$ and $b$. We discuss the relations of the model with\nexisting voter models and then derive theoretical results for both the fixation\nprobability and the expected consensus time for two opinions, for both the\nsynchronous and the asynchronous update models.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.07377v2"
    },
    {
        "title": "Stackelberg Decision Transformer for Asynchronous Action Coordination in\n  Multi-Agent Systems",
        "authors": [
            "Bin Zhang",
            "Hangyu Mao",
            "Lijuan Li",
            "Zhiwei Xu",
            "Dapeng Li",
            "Rui Zhao",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Asynchronous action coordination presents a pervasive challenge in\nMulti-Agent Systems (MAS), which can be represented as a Stackelberg game (SG).\nHowever, the scalability of existing Multi-Agent Reinforcement Learning (MARL)\nmethods based on SG is severely constrained by network structures or\nenvironmental limitations. To address this issue, we propose the Stackelberg\nDecision Transformer (STEER), a heuristic approach that resolves the\ndifficulties of hierarchical coordination among agents. STEER efficiently\nmanages decision-making processes in both spatial and temporal contexts by\nincorporating the hierarchical decision structure of SG, the modeling\ncapability of autoregressive sequence models, and the exploratory learning\nmethodology of MARL. Our research contributes to the development of an\neffective and adaptable asynchronous action coordination method that can be\nwidely applied to various task types and environmental configurations in MAS.\nExperimental results demonstrate that our method can converge to Stackelberg\nequilibrium solutions and outperforms other existing methods in complex\nscenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.07856v1"
    },
    {
        "title": "Counterfactual Fairness Filter for Fair-Delay Multi-Robot Navigation",
        "authors": [
            "Hikaru Asano",
            "Ryo Yonetani",
            "Mai Nishimura",
            "Tadashi Kozuno"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-robot navigation is the task of finding trajectories for a team of\nrobotic agents to reach their destinations as quickly as possible without\ncollisions. In this work, we introduce a new problem: fair-delay multi-robot\nnavigation, which aims not only to enable such efficient, safe travels but also\nto equalize the travel delays among agents in terms of actual trajectories as\ncompared to the best possible trajectories. The learning of a navigation policy\nto achieve this objective requires resolving a nontrivial credit assignment\nproblem with robotic agents having continuous action spaces. Hence, we\ndeveloped a new algorithm called Navigation with Counterfactual Fairness Filter\n(NCF2). With NCF2, each agent performs counterfactual inference on whether it\ncan advance toward its goal or should stay still to let other agents go. Doing\nso allows us to effectively address the aforementioned credit assignment\nproblem and improve fairness regarding travel delays while maintaining high\nefficiency and safety. Our extensive experimental results in several\nchallenging multi-robot navigation environments demonstrate the greater\neffectiveness of NCF2 as compared to state-of-the-art fairness-aware\nmulti-agent reinforcement learning methods. Our demo videos and code are\navailable on the project webpage: https://omron-sinicx.github.io/ncf2/\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11465v1"
    },
    {
        "title": "Robust Multi-agent Communication via Multi-view Message Certification",
        "authors": [
            "Lei Yuan",
            "Tao Jiang",
            "Lihe Li",
            "Feng Chen",
            "Zongzhang Zhang",
            "Yang Yu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Many multi-agent scenarios require message sharing among agents to promote\ncoordination, hastening the robustness of multi-agent communication when\npolicies are deployed in a message perturbation environment. Major relevant\nworks tackle this issue under specific assumptions, like a limited number of\nmessage channels would sustain perturbations, limiting the efficiency in\ncomplex scenarios. In this paper, we take a further step addressing this issue\nby learning a robust multi-agent communication policy via multi-view message\ncertification, dubbed CroMAC. Agents trained under CroMAC can obtain guaranteed\nlower bounds on state-action values to identify and choose the optimal action\nunder a worst-case deviation when the received messages are perturbed.\nConcretely, we first model multi-agent communication as a multi-view problem,\nwhere every message stands for a view of the state. Then we extract a\ncertificated joint message representation by a multi-view variational\nautoencoder (MVAE) that uses a product-of-experts inference network. For the\noptimization phase, we do perturbations in the latent space of the state for a\ncertificate guarantee. Then the learned joint message representation is used to\napproximate the certificated state representation during training. Extensive\nexperiments in several cooperative multi-agent benchmarks validate the\neffectiveness of the proposed CroMAC.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13936v1"
    },
    {
        "title": "Multi-agent Continual Coordination via Progressive Task\n  Contextualization",
        "authors": [
            "Lei Yuan",
            "Lihe Li",
            "Ziqian Zhang",
            "Fuxiang Zhang",
            "Cong Guan",
            "Yang Yu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Cooperative Multi-agent Reinforcement Learning (MARL) has attracted\nsignificant attention and played the potential for many real-world\napplications. Previous arts mainly focus on facilitating the coordination\nability from different aspects (e.g., non-stationarity, credit assignment) in\nsingle-task or multi-task scenarios, ignoring the stream of tasks that appear\nin a continual manner. This ignorance makes the continual coordination an\nunexplored territory, neither in problem formulation nor efficient algorithms\ndesigned. Towards tackling the mentioned issue, this paper proposes an approach\nMulti-Agent Continual Coordination via Progressive Task Contextualization,\ndubbed MACPro. The key point lies in obtaining a factorized policy, using\nshared feature extraction layers but separated independent task heads, each\nspecializing in a specific class of tasks. The task heads can be progressively\nexpanded based on the learned task contextualization. Moreover, to cater to the\npopular CTDE paradigm in MARL, each agent learns to predict and adopt the most\nrelevant policy head based on local information in a decentralized manner. We\nshow in multiple multi-agent benchmarks that existing continual learning\nmethods fail, while MACPro is able to achieve close-to-optimal performance.\nMore results also disclose the effectiveness of MACPro from multiple aspects\nlike high generalization ability.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.13937v1"
    },
    {
        "title": "Distributed Set-membership Filtering Frameworks For Multi-agent Systems\n  With Absolute and Relative Measurements",
        "authors": [
            "Yu Ding",
            "Yirui Cong",
            "Xiangke Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we focus on the distributed set-membership filtering (SMFing)\nproblem for a multi-agent system with absolute (taken from agents themselves)\nand relative (taken from neighbors) measurements. In the literature, the\nrelative measurements are difficult to deal with, and the SMFs highly rely on\nspecific set descriptions. As a result, establishing the general distributed\nSMFing framework having relative measurements is still an open problem. To\nsolve this problem, first, we provide the set description based on uncertain\nvariables determined by the relative measurements between two agents as the\nfoundation. Surprisingly, the accurate description requires only a single\ncalculation step rather than multiple iterations, which can effectively reduce\ncomputational complexity. Based on the derived set description, called the\nuncertain range, we propose two distributed SMFing frameworks: one calculates\nthe joint uncertain range of the agent itself and its neighbors, while the\nother only computes the marginal uncertain range of each local system.\nFurthermore, we compare the performance of our proposed two distributed SMFing\nframeworks and the benchmark -- centralized SMFing framework. A rigorous set\nanalysis reveals that the distributed SMF can be essentially considered as the\nprocess of computing the marginal uncertain range to outer bound the projection\nof the uncertain range obtained by the centralized SMF in the corresponding\nsubspace. Simulation results corroborate the effectiveness of our proposed\ndistributed frameworks and verify our theoretical analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.15797v1"
    },
    {
        "title": "On Computing Universal Plans for Partially Observable Multi-Agent Path\n  Finding",
        "authors": [
            "Fengming Zhu",
            "Fangzhen Lin"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent routing problems have drawn significant attention nowadays due to\ntheir broad industrial applications in, e.g., warehouse robots, logistics\nautomation, and traffic control. Conventionally, they are modelled as classical\nplanning problems. In this paper, we argue that it is beneficial to formulate\nthem as universal planning problems. We therefore propose universal plans, also\nknown as policies, as the solution concepts, and implement a system called\nASP-MAUPF (Answer Set Programming for Multi-Agent Universal Plan Finding) for\ncomputing them. Given an arbitrary two-dimensional map and a profile of goals\nfor the agents, the system finds a feasible universal plan for each agent that\nensures no collision with others. We use the system to conduct some\nexperiments, and make some observations on the types of goal profiles and\nenvironments that will have feasible policies, and how they may depend on\nagents' sensors. We also demonstrate how users can customize action preferences\nto compute more efficient policies, even (near-)optimal ones.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.16203v3"
    },
    {
        "title": "A Unified Framework for Factorizing Distributional Value Functions for\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Wei-Fang Sun",
            "Cheng-Kuang Lee",
            "Simon See",
            "Chun-Yi Lee"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In fully cooperative multi-agent reinforcement learning (MARL) settings,\nenvironments are highly stochastic due to the partial observability of each\nagent and the continuously changing policies of other agents. To address the\nabove issues, we proposed a unified framework, called DFAC, for integrating\ndistributional RL with value function factorization methods. This framework\ngeneralizes expected value function factorization methods to enable the\nfactorization of return distributions. To validate DFAC, we first demonstrate\nits ability to factorize the value functions of a simple matrix game with\nstochastic rewards. Then, we perform experiments on all Super Hard maps of the\nStarCraft Multi-Agent Challenge and six self-designed Ultra Hard maps, showing\nthat DFAC is able to outperform a number of baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.02430v1"
    },
    {
        "title": "Coverage Path Planning with Budget Constraints for Multiple Unmanned\n  Ground Vehicles",
        "authors": [
            "Vu Phi Tran",
            "Asanka Perera",
            "Matthew A. Garratt",
            "Kathryn Kasmarik",
            "Sreenatha Anavatti"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper proposes a state-machine model for a multi-modal, multi-robot\nenvironmental sensing algorithm. This multi-modal algorithm integrates two\ndifferent exploration algorithms: (1) coverage path planning using variable\nformations and (2) collaborative active sensing using multi-robot swarms. The\nstate machine provides the logic for when to switch between these different\nsensing algorithms. We evaluate the performance of the proposed approach on a\ngas source localisation and mapping task. We use hardware-in-the-loop\nexperiments and real-time experiments with a radio source simulating a real gas\nfield. We compare the proposed approach with a single-mode, state-of-the-art\ncollaborative active sensing approach. Our results indicate that our\nmulti-modal switching approach can converge more rapidly than single-mode\nactive sensing.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.04083v1"
    },
    {
        "title": "The Viability of Domain Constrained Coalition Formation for Robotic\n  Collectives",
        "authors": [
            "Grace Diehl",
            "Julie A. Adams"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Applications, such as military and disaster response, can benefit from\nrobotic collectives' ability to perform multiple cooperative tasks (e.g.,\nsurveillance, damage assessments) efficiently across a large spatial area.\nCoalition formation algorithms can potentially facilitate collective robots'\nassignment to appropriate task teams; however, most coalition formation\nalgorithms were designed for smaller multiple robot systems (i.e., 2-50\nrobots). Collectives' scale and domain-relevant constraints (i.e.,\ndistribution, near real-time, minimal communication) make coalition formation\nmore challenging. This manuscript identifies the challenges inherent to\ndesigning coalition formation algorithms for very large collectives (e.g., 1000\nrobots). A survey of multiple robot coalition formation algorithms finds that\nmost are unable to transfer directly to collectives, due to the identified\nsystem differences; however, auctions and hedonic games may be the most\ntransferable. A simulation-based evaluation of three auction and hedonic game\nalgorithms, applied to homogeneous and heterogeneous collectives, demonstrates\nthat there are collective compositions for which no existing algorithm is\nviable; however, the experimental results and literature survey suggest paths\nforward.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.05590v1"
    },
    {
        "title": "Ball Trajectory Inference from Multi-Agent Sports Contexts Using Set\n  Transformer and Hierarchical Bi-LSTM",
        "authors": [
            "Hyunsung Kim",
            "Han-Jun Choi",
            "Chang Jo Kim",
            "Jinsung Yoon",
            "Sang-Ki Ko"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  As artificial intelligence spreads out to numerous fields, the application of\nAI to sports analytics is also in the spotlight. However, one of the major\nchallenges is the difficulty of automated acquisition of continuous movement\ndata during sports matches. In particular, it is a conundrum to reliably track\na tiny ball on a wide soccer pitch with obstacles such as occlusion and\nimitations. Tackling the problem, this paper proposes an inference framework of\nball trajectory from player trajectories as a cost-efficient alternative to\nball tracking. We combine Set Transformers to get permutation-invariant and\nequivariant representations of the multi-agent contexts with a hierarchical\narchitecture that intermediately predicts the player ball possession to support\nthe final trajectory inference. Also, we introduce the reality loss term and\npostprocessing to secure the estimated trajectories to be physically realistic.\nThe experimental results show that our model provides natural and accurate\ntrajectories as well as admissible player ball possession at the same time.\nLastly, we suggest several practical applications of our framework including\nmissing trajectory imputation, semi-automated pass annotation, automated\nzoom-in for match broadcasting, and calculating possession-wise running\nperformance metrics.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.08206v1"
    },
    {
        "title": "Robust Multi-Agent Control via Maximum Entropy Heterogeneous-Agent\n  Reinforcement Learning",
        "authors": [
            "Simin Li",
            "Yifan Zhong",
            "Jiarong Liu",
            "Jianing Guo",
            "Siyuan Qi",
            "Ruixiao Xu",
            "Xin Yu",
            "Siyi Hu",
            "Haobo Fu",
            "Qiang Fu",
            "Xiaojun Chang",
            "Yujing Hu",
            "Bo An",
            "Xianglong Liu",
            "Yaodong Yang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In multi-agent reinforcement learning, optimal control with robustness\nguarantees are critical for its deployment in real world. However, existing\nmethods face challenges related to sample complexity, training instability,\npotential suboptimal Nash Equilibrium convergence and non-robustness to\nmultiple perturbations. In this paper, we propose a unified framework for\nlearning \\emph{stochastic} policies to resolve these issues. We embed\ncooperative MARL problems into probabilistic graphical models, from which we\nderive the maximum entropy (MaxEnt) objective optimal for MARL. Based on the\nMaxEnt framework, we propose \\emph{Heterogeneous-Agent Soft Actor-Critic}\n(HASAC) algorithm. Theoretically, we prove the monotonic improvement and\nconvergence to \\emph{quantal response equilibrium} (QRE) properties of HASAC.\nFurthermore, HASAC is provably robust against a wide range of real-world\nuncertainties, including perturbations in rewards, environment dynamics,\nstates, and actions. Finally, we generalize a unified template for MaxEnt\nalgorithmic design named \\emph{Maximum Entropy Heterogeneous-Agent Mirror\nLearning} (MEHAML), which provides any induced method with the same guarantees\nas HASAC. We evaluate HASAC on seven benchmarks: Bi-DexHands, Multi-Agent\nMuJoCo, Pursuit-Evade, StarCraft Multi-Agent Challenge, Google Research\nFootball, Multi-Agent Particle Environment, Light Aircraft Game. Results show\nthat HASAC consistently outperforms strong baselines in 34 out of 38 tasks,\nexhibiting improved training stability, better sample efficiency and sufficient\nexploration. The robustness of HASAC was further validated when encountering\nuncertainties in rewards, dynamics, states, and actions of 14 magnitudes, and\nreal-world deployment in a multi-robot arena against these four types of\nuncertainties. See our page at \\url{https://sites.google.com/view/meharl}.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.10715v5"
    },
    {
        "title": "Decentralized Aerial Transportation and Manipulation of a Cable-Slung\n  Payload With Swarm of Agents",
        "authors": [
            "Aniket Sharma",
            "Nandan K Sinha"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  With the advent of Unmanned Aerial Vehicles (UAV) and Micro Aerial Vehicles\n(MAV) in commercial sectors, their application for transporting and\nmanipulating payloads has attracted many research work. A swarm of agents,\ncooperatively working to transport and manipulate a payload can overcome the\nphysical limitations of a single agent, adding redundancy and tolerance against\nfailures. In this paper, the dynamics of a swarm connected to a payload via\nflexible cables are modeled, and a decentralized control is designed using\nArtificial Potential Field (APF). The swarm is able to transport the payload\nthrough an unknown environment to a goal position while avoiding obstacles from\nthe local information received from the onboard sensors. The key contributions\nare (a) the cables are modelled more accurately using lumped mass model instead\nof geometric constraints, (b) a decentralized swarm control is designed using\npotential field approach to ensure hover stability of system without payload\nstate information, (c) the manipulation of payload elevation and azimuth angles\nare controlled by APF, and (d) the trajectory of the payload for transportation\nis governed by potential fields generated by goal point and obstacles. The\nefficacy of the method proposed in this work are evaluated through numerical\nsimulations under the influence of external disturbances and failure of agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.12331v1"
    },
    {
        "title": "Emergent Resource Exchange and Tolerated Theft Behavior using\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Jack Garbus",
            "Jordan Pollack"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  For decades, the evolution of cooperation has piqued the interest of numerous\nacademic disciplines such as game theory, economics, biology, and computer\nscience. In this work, we demonstrate the emergence of a novel and effective\nresource exchange protocol formed by dropping and picking up resources in a\nforaging environment. This form of cooperation is made possible by the\nintroduction of a campfire, which adds an extended period of congregation and\ndowntime for agents to explore otherwise unlikely interactions. We find that\nthe agents learn to avoid getting cheated by their exchange partners, but not\nalways from a third party. We also observe the emergence of behavior analogous\nto tolerated theft, despite the lack of any punishment, combat, or larceny\nmechanism in the environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.01862v1"
    },
    {
        "title": "Comparing Social Network Dynamic Operators",
        "authors": [
            "Edoardo Baccini",
            "Zoé Christoff"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Numerous logics have been developed to reason either about threshold-induced\nopinion diffusion in a network, or about similarity-driven network structure\nevolution, or about both. In this paper, we first introduce a logic containing\ndifferent dynamic operators to capture changes that are 'asynchronous' (opinion\nchange only, network-link change only) and changes that are 'synchronous' (both\nat the same time). Second, we show that synchronous operators cannot, in\ngeneral, be replaced by asynchronous operators and vice versa. Third, we\ncharacterise the class of models on which the synchronous operator can be\nreduced to sequences of asynchronous operators.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.05055v1"
    },
    {
        "title": "Enhancing Evacuation Planning through Multi-Agent Simulation and\n  Artificial Intelligence: Understanding Human Behavior in Hazardous\n  Environments",
        "authors": [
            "Afnan Alazbah",
            "Khalid Fakeeh",
            "Osama Rabie"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper focuses on the crucial task of addressing the evacuation of\nhazardous places, which holds great importance for coordinators, event hosts,\nand authorities. To facilitate the development of effective solutions, the\npaper employs Artificial Intelligence (AI) techniques, specifically Multi-Agent\nSystems (MAS), to construct a simulation model for evacuation. NetLogo is\nselected as the simulation tool of choice due to its ability to provide a\ncomprehensive understanding of human behaviour in distressing situations within\nhazardous environments. The primary objective of this paper is to enhance our\ncomprehension of how individuals react and respond during such distressing\nsituations. By leveraging AI and MAS, the simulation model aims to capture the\ncomplex dynamics of evacuation scenarios, enabling policymakers and emergency\nplanners to make informed decisions and implement more efficient and effective\nevacuation strategies. This paper endeavours to contribute to the advancement\nof evacuation planning and ultimately improve the safety and well-being of\nindividuals in hazardous places\n",
        "pdf_link": "http://arxiv.org/pdf/2307.09485v1"
    },
    {
        "title": "Consensus-based Participatory Budgeting for Legitimacy: Decision Support\n  via Multi-agent Reinforcement Learning",
        "authors": [
            "Srijoni Majumdar",
            "Evangelos Pournaras"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The legitimacy of bottom-up democratic processes for the distribution of\npublic funds by policy-makers is challenging and complex. Participatory\nbudgeting is such a process, where voting outcomes may not always be fair or\ninclusive. Deliberation for which project ideas to put for voting and choose\nfor implementation lack systematization and do not scale. This paper addresses\nthese grand challenges by introducing a novel and legitimate iterative\nconsensus-based participatory budgeting process. Consensus is designed to be a\nresult of decision support via an innovative multi-agent reinforcement learning\napproach. Voters are assisted to interact with each other to make viable\ncompromises. Extensive experimental evaluation with real-world participatory\nbudgeting data from Poland reveal striking findings: Consensus is reachable,\nefficient and robust. Compromise is required, which is though comparable to the\none of existing voting aggregation methods that promote fairness and inclusion\nwithout though attaining consensus.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12915v1"
    },
    {
        "title": "Bi-level Network Design for UAM Vertiport Allocation Using\n  Activity-Based Transport Simulations",
        "authors": [
            "Sebastian Brulin",
            "Markus Olhofer"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The design or the optimization of transport systems is a difficult task. This\nis especially true in the case of the introduction of new transport modes in an\nexisting system. The main reason is, that even small additions and changes\nresult in the emergence of new travel patterns, likely resulting in an\nadaptation of the travel behavior of multiple other agents in the system. Here\nwe consider the optimization of future Urban Air Mobility services under\nconsideration of effects induced by the new mode to an existing system. We\ntackle this problem through a bi-level network design approach, in which the\ndiscrete decisions of the network design planner are optimized based on the\nevaluated dynamic demand of the user's mode choices. We solve the\nactivity-based network design problem (AB-NDP) using a Genetic Algorithm on a\nmulti-objective optimization problem while evaluating the dynamic demand with\nthe large-scale Multi-Agent Transport Simulation (MATSim) framework. The\nproposed bi-level approach is compared against the results of a coverage\napproach using a static demand method. The bi-level study shows better results\nfor expected UAM demand and total travel time savings across the transportation\nsystem. Due to its generic character, the demonstrated utilization of a\nbi-level method is applicable to other mobility service design questions and to\nother regions.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.14731v1"
    },
    {
        "title": "Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility\n  Cooperation",
        "authors": [
            "Soohyun Park",
            "Jae Pyoung Kim",
            "Chanyoung Park",
            "Soyi Jung",
            "Joongheon Kim"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  For Industry 4.0 Revolution, cooperative autonomous mobility systems are\nwidely used based on multi-agent reinforcement learning (MARL). However, the\nMARL-based algorithms suffer from huge parameter utilization and convergence\ndifficulties with many agents. To tackle these problems, a quantum MARL (QMARL)\nalgorithm based on the concept of actor-critic network is proposed, which is\nbeneficial in terms of scalability, to deal with the limitations in the noisy\nintermediate-scale quantum (NISQ) era. Additionally, our QMARL is also\nbeneficial in terms of efficient parameter utilization and fast convergence due\nto quantum supremacy. Note that the reward in our QMARL is defined as task\nprecision over computation time in multiple agents, thus, multi-agent\ncooperation can be realized. For further improvement, an additional technique\nfor scalability is proposed, which is called projection value measure (PVM).\nBased on PVM, our proposed QMARL can achieve the highest reward, by reducing\nthe action dimension into a logarithmic-scale. Finally, we can conclude that\nour proposed QMARL with PVM outperforms the other algorithms in terms of\nefficient parameter utilization, fast convergence, and scalability.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.01519v1"
    },
    {
        "title": "SICO: Simulation for Infection Control Operations",
        "authors": [
            "Karleigh Pine",
            "Razvan Veliche",
            "Jared Bennett",
            "Joel Klipfel"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In response to the COVID-19 pandemic and the potential threat of future\nepidemics caused by novel viruses, we developed a flexible framework for\nmodeling disease intervention effects. This tool is intended to aid decision\nmakers at multiple levels as they compare possible responses to emerging\nepidemiological threats for optimal control and reduction of harm. The\nframework is specifically designed to be both scalable and modular, allowing it\nto model a variety of population levels, viruses, testing methods and\nstrategies--including pooled testing--and intervention strategies. In this\npaper, we provide an overview of this framework and examine the impact of\ndifferent intervention strategies and their impact on infection dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09852v1"
    },
    {
        "title": "Multi-agent Coordination Under Temporal Logic Tasks and Team-Wise\n  Intermittent Communication",
        "authors": [
            "Junjie Wang",
            "Meng Guo",
            "Zhongkui Li"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent systems outperform single agent in complex collaborative tasks.\nHowever, in large-scale scenarios, ensuring timely information exchange during\ndecentralized task execution remains a challenge. This work presents an online\ndecentralized coordination scheme for multi-agent systems under complex local\ntasks and intermittent communication constraints. Unlike existing strategies\nthat enforce all-time or intermittent connectivity, our approach allows agents\nto join or leave communication networks at aperiodic intervals, as deemed\noptimal by their online task execution. This scheme concurrently determines\nlocal plans and refines the communication strategy, i.e., where and when to\ncommunicate as a team. A decentralized potential game is modeled among agents,\nfor which a Nash equilibrium is generated iteratively through online local\nsearch. It guarantees local task completion and intermittent communication\nconstraints. Extensive numerical simulations are conducted against several\nstrong baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.14042v2"
    },
    {
        "title": "Individually Rational Collaborative Vehicle Routing through\n  Give-And-Take Exchanges",
        "authors": [
            "Paul Mingzheng Tang",
            "Ba Phong Tran",
            "Hoong Chuin Lau"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we are concerned with the automated exchange of orders between\nlogistics companies in a marketplace platform to optimize total revenues. We\nintroduce a novel multi-agent approach to this problem, focusing on the\nCollaborative Vehicle Routing Problem (CVRP) through the lens of individual\nrationality. Our proposed algorithm applies the principles of Vehicle Routing\nProblem (VRP) to pairs of vehicles from different logistics companies,\noptimizing the overall routes while considering standard VRP constraints plus\nindividual rationality constraints. By facilitating cooperation among competing\nlogistics agents through a Give-and-Take approach, we show that it is possible\nto reduce travel distance and increase operational efficiency system-wide. More\nimportantly, our approach ensures individual rationality and faster\nconvergence, which are important properties of ensuring the long-term\nsustainability of the marketplace platform. We demonstrate the efficacy of our\napproach through extensive experiments using real-world test data from major\nlogistics companies. The results reveal our algorithm's ability to rapidly\nidentify numerous optimal solutions, underscoring its practical applicability\nand potential to transform the logistics industry.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.16501v1"
    },
    {
        "title": "Decentralized shape formation and force-based interactive formation\n  control in robot swarms",
        "authors": [
            "Akshaya C S",
            "Karthik Soma",
            "Visweswaran B",
            "Aditya Ravichander",
            "Venkata Nagarjun PM"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Swarm robotic systems utilize collective behaviour to achieve goals that\nmight be too complex for a lone entity, but become attainable with localized\ncommunication and collective decision making. In this paper, a behaviour-based\ndistributed approach to shape formation is proposed. Flocking into strategic\nformations is observed in migratory birds and fish to avoid predators and also\nfor energy conservation. The formation is maintained throughout long periods\nwithout collapsing and is advantageous for communicating within the flock.\nSimilar behaviour can be deployed in multi-agent systems to enhance\ncoordination within the swarm. Existing methods for formation control are\neither dependent on the size and geometry of the formation or rely on\nmaintaining the formation with a single reference in the swarm (the leader).\nThese methods are not resilient to failure and involve a high degree of\ndeformation upon obstacle encounter before the shape is recovered again. To\nimprove the performance, artificial force-based interaction amongst the\nentities of the swarm to maintain shape integrity while encountering obstacles\nis elucidated.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.01240v1"
    },
    {
        "title": "Personalized Federated Deep Reinforcement Learning-based Trajectory\n  Optimization for Multi-UAV Assisted Edge Computing",
        "authors": [
            "Zhengrong Song",
            "Chuan Ma",
            "Ming Ding",
            "Howard H. Yang",
            "Yuwen Qian",
            "Xiangwei Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In the era of 5G mobile communication, there has been a significant surge in\nresearch focused on unmanned aerial vehicles (UAVs) and mobile edge computing\ntechnology. UAVs can serve as intelligent servers in edge computing\nenvironments, optimizing their flight trajectories to maximize communication\nsystem throughput. Deep reinforcement learning (DRL)-based trajectory\noptimization algorithms may suffer from poor training performance due to\nintricate terrain features and inadequate training data. To overcome this\nlimitation, some studies have proposed leveraging federated learning (FL) to\nmitigate the data isolation problem and expedite convergence. Nevertheless, the\nefficacy of global FL models can be negatively impacted by the high\nheterogeneity of local data, which could potentially impede the training\nprocess and even compromise the performance of local agents. This work proposes\na novel solution to address these challenges, namely personalized federated\ndeep reinforcement learning (PF-DRL), for multi-UAV trajectory optimization.\nPF-DRL aims to develop individualized models for each agent to address the data\nscarcity issue and mitigate the negative impact of data heterogeneity.\nSimulation results demonstrate that the proposed algorithm achieves superior\ntraining performance with faster convergence rates, and improves service\nquality compared to other DRL-based approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.02193v1"
    },
    {
        "title": "Implementation of Autonomous Supply Chains for Digital Twinning: a\n  Multi-Agent Approach",
        "authors": [
            "Liming Xu",
            "Yaniv Proselkov",
            "Stefan Schoepf",
            "David Minarsch",
            "Maria Minaricova",
            "Alexandra Brintrup"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Trade disruptions, the pandemic, and the Ukraine war over the past years have\nadversely affected global supply chains, revealing their vulnerability.\nAutonomous supply chains are an emerging topic that has gained attention in\nindustry and academia as a means of increasing their monitoring and robustness.\nWhile many theoretical frameworks exist, there is only sparse work to\nfacilitate generalisable technical implementation. We address this gap by\ninvestigating multi-agent system approaches for implementing autonomous supply\nchains, presenting an autonomous economic agent-based technical framework. We\nillustrate this framework with a prototype, studied in a perishable food supply\nchain scenario, and discuss possible extensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.04785v1"
    },
    {
        "title": "Multicopy Reinforcement Learning Agents",
        "authors": [
            "Alicia P. Wolfe",
            "Oliver Diamond",
            "Brigitte Goeler-Slough",
            "Remi Feuerman",
            "Magdalena Kisielinska",
            "Victoria Manfredi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper examines a novel type of multi-agent problem, in which an agent\nmakes multiple identical copies of itself in order to achieve a single agent\ntask better or more efficiently. This strategy improves performance if the\nenvironment is noisy and the task is sometimes unachievable by a single agent\ncopy. We propose a learning algorithm for this multicopy problem which takes\nadvantage of the structure of the value function to efficiently learn how to\nbalance the advantages and costs of adding additional copies.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.10908v2"
    },
    {
        "title": "A Digital Marketplace Combining WS-Agreement, Service Negotiation\n  Protocols and Heterogeneous Services",
        "authors": [
            "Ralph Vigne",
            "Juergen Mangler",
            "Erich Schikuta"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  With the ever increasing importance of web services and the Cloud as a\nreliable commodity to provide business value as well as consolidate IT\ninfrastructure, electronic contracts have become very important. WS-Agreement\nhas itself established as a well accepted container format for describing such\ncontracts. However, the semantic interpretation of the terms contained in these\ncontracts, as well as the process of agreeing to contracts when multiple\noptions have to be considered (negotiation), are still pretty much dealt with\non a case by case basis. In this paper we address the issues of diverging\ncontracts and varying contract negotiation protocols by introducing the concept\nof a contract aware marketplace, which abstracts from the heterogeneous offers\nof different services providers. This allows for the automated consumption of\nservices solely based on preferences, instead of additional restrictions such\nas understanding of contract terms and/or negotiation protocols. We also\ncontribute an evaluation of several existing negotiation concepts/protocols. We\nthink that reducing the complexity for automated contract negotiation and thus\nservice consumption is a key for the success of future service and Cloud\ninfrastructures.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.11941v1"
    },
    {
        "title": "King of the Hill: C2 for Next Generation Swarm Warfare",
        "authors": [
            "Takuma Adams",
            "Timothy McLennan-Smith"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  As the reliability of cheap, off-the-shelf autonomous platforms increases, so\ndoes the risk posed by intelligent multi-agent systems to military operations.\nIn the contemporary context of the Russo-Ukrainian war alone, we have seen\nautonomous aerial vehicles and surface vessels deployed both individually and\nin multitude to deliver critical effects to both sides. While there is a large\nbody of literature on tactical level communications and interactions between\nagents, the exploration of high-level command and control (C2) structures that\nwill underpin future autonomous multi-agent military operations is a less\nexplored area of research. We propose a quantitative game-theoretic framework\nto study effective C2 structures in cooperative and competitive multi-agent\nswarming scenarios. To test our framework, we construct a virtual environment\nwhere two adversarial swarms compete to achieve outcomes comparable to\nreal-world scenarios. The framework we present in this paper enables us to\nquickly test and interrogate different C2 configurations in multi-agent systems\nto explore C2 as a force multiplier when at a force disadvantage.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.00228v1"
    },
    {
        "title": "Proceedings of the Third Workshop on Agents and Robots for reliable\n  Engineered Autonomy",
        "authors": [
            "Angelo Ferrando",
            "Rafael Cardoso"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The volume comprises the proceedings of the Third Workshop on Agents and\nRobots for reliable Engineered Autonomy (AREA 2023), held alongside the 26th\nEuropean Conference on Artificial Intelligence (ECAI 2023). It explores the\nconvergence of autonomous agents and robotics, emphasizing the practical\napplication of agents in real-world scenarios with physical interactions. The\nworkshop highlights the growing importance of enhanced autonomy and reliable\nbehavior in robotic systems and the need for novel verification and validation\nmethods. Its primary objective is to promote collaboration between researchers\nin these fields, aiming to address complex challenges in autonomous robotic\nsystems. The volume includes 7 full papers and 5 short papers.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.00333v1"
    },
    {
        "title": "Making Friends in the Dark: Ad Hoc Teamwork Under Partial Observability",
        "authors": [
            "João G. Ribeiroa",
            "Cassandro Martinhoa",
            "Alberto Sardinhaa",
            "Francisco S. Melo"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper introduces a formal definition of the setting of ad hoc teamwork\nunder partial observability and proposes a first-principled model-based\napproach which relies only on prior knowledge and partial observations of the\nenvironment in order to perform ad hoc teamwork. We make three distinct\nassumptions that set it apart previous works, namely: i) the state of the\nenvironment is always partially observable, ii) the actions of the teammates\nare always unavailable to the ad hoc agent and iii) the ad hoc agent has no\naccess to a reward signal which could be used to learn the task from scratch.\nOur results in 70 POMDPs from 11 domains show that our approach is not only\neffective in assisting unknown teammates in solving unknown tasks but is also\nrobust in scaling to more challenging problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.01439v1"
    },
    {
        "title": "Homotopy-Aware Multi-Agent Path Planning on Plane",
        "authors": [
            "Kazumi Kasaura"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We propose an efficient framework using Dynnikov coordinates for\nhomotopy-aware multi-agent path planning in planar domains that may contain\nobstacles. We developed a method for generating multiple homotopically distinct\nsolutions for the multi-agent path planning problem in planar domains by\ncombining our framework with revised prioritized planning and proved its\ncompleteness under specific assumptions. Experimentally, we demonstrated that\nour method is significantly faster than a method without Dynnikov coordinates.\nWe also confirmed experimentally that homotopy-aware planning contributes to\navoiding locally optimal solutions when searching for low-cost trajectories for\na swarm of agents in a continuous environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.01945v4"
    },
    {
        "title": "Safe and Robust Robot Behavior Planning via Constraint Programming",
        "authors": [
            "Jan Vermaelen",
            "Tom Holvoet"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The safe operation of an autonomous system is a complex endeavor, one pivotal\nelement being its decision-making. Decision-making logic can formally be\nanalyzed using model checking or other formal verification approaches. Yet, the\nnon-deterministic nature of realistic environments makes these approaches\nrather troublesome and often impractical. Constraint-based planning approaches\nsuch as Tumato have been shown to be capable of generating policies for a\nsystem to reach a stated goal and abiding safety constraints, with guarantees\nof soundness and completeness by construction. However, uncertain outcomes of\nactions in the environment are not explicitly modeled or accounted for,\nseverely limiting the expressiveness of Tumato.\n  In this work, we extend Tumato with support for non-deterministic outcomes of\nactions. Actions have a specific intended result yet can be modeled to have\nalternative outcomes that may realistically occur. The adapted solver generates\na policy that enables reaching the goals in a safe manner, even when\nalternative outcomes of actions occur. Furthermore, we introduce a purely\ndeclarative way of defining safety in Tumato, increasing its expressiveness.\nFinally, the addition of cost or duration values to actions enables the solver\nto restore safety when necessary, in the most preferred way.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.02339v1"
    },
    {
        "title": "Evaluating Heuristic Search Algorithms in Pathfinding: A Comprehensive\n  Study on Performance Metrics and Domain Parameters",
        "authors": [
            "Aya Kherrour",
            "Marco Robol",
            "Marco Roveri",
            "Paolo Giorgini"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The paper presents a comprehensive performance evaluation of some heuristic\nsearch algorithms in the context of autonomous systems and robotics. The\nobjective of the study is to evaluate and compare the performance of different\nsearch algorithms in different problem settings on the pathfinding domain.\nExperiments give us insight into the behavior of the evaluated heuristic search\nalgorithms, over the variation of different parameters: domain size, obstacle\ndensity, and distance between the start and the goal states. Results are then\nused to design a selection algorithm that, on the basis of problem\ncharacteristics, suggests the best search algorithm to use.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.02346v1"
    },
    {
        "title": "Online Proactive Multi-Task Assignment with Resource Availability\n  Anticipation",
        "authors": [
            "Déborah Conforto Nedelmann",
            "Jérôme Lacan",
            "Caroline Chanel"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  With the emergence of services and online applications as taxi dispatching,\ncrowdsourcing, package or food delivery, industrials and researchers are paying\nattention to the online multi-task assignment optimization field to quickly and\nefficiently met demands. In this context, this paper is interested in the\nmulti-task assignment problem where multiple requests (e.g. tasks) arrive over\ntime and must be dynamically matched to (mobile) agents. This optimization\nproblem is known to be NP-hard. In order to treat this problem with a proactive\nmindset, we propose to use a receding-horizon approach to determine which\nresources (e.g. taxis, mobile agents, drones, robots) would be available within\nthis (possibly dynamic) receding-horizon to meet the current set of requests\n(i.e. tasks) as good as possible. Contrarily to several works in this domain,\nwe have chosen to make no assumption concerning future locations of requests.\nTo achieve fast optimized online solutions in terms of costs and amount of\nallocated tasks, we have designed a genetic algorithm based on a fitness\nfunction integrating the traveled distance and the age of the requests. We\ncompared our proactive multi-task assignment with resource availability\nanticipation approach with a classical reactive approach. The results obtained\nin two benchmark problems, one synthetic and another based on real data, show\nthat our resource availability anticipation method can achieve better results\nin terms of costs (e.g. traveled distance) and amount of allocated tasks than\nreactive approaches while decreasing resources idle time.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.02353v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning Based on Representational\n  Communication for Large-Scale Traffic Signal Control",
        "authors": [
            "Rohit Bokade",
            "Xiaoning Jin",
            "Christopher Amato"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Traffic signal control (TSC) is a challenging problem within intelligent\ntransportation systems and has been tackled using multi-agent reinforcement\nlearning (MARL). While centralized approaches are often infeasible for\nlarge-scale TSC problems, decentralized approaches provide scalability but\nintroduce new challenges, such as partial observability. Communication plays a\ncritical role in decentralized MARL, as agents must learn to exchange\ninformation using messages to better understand the system and achieve\neffective coordination. Deep MARL has been used to enable inter-agent\ncommunication by learning communication protocols in a differentiable manner.\nHowever, many deep MARL communication frameworks proposed for TSC allow agents\nto communicate with all other agents at all times, which can add to the\nexisting noise in the system and degrade overall performance. In this study, we\npropose a communication-based MARL framework for large-scale TSC. Our framework\nallows each agent to learn a communication policy that dictates \"which\" part of\nthe message is sent \"to whom\". In essence, our framework enables agents to\nselectively choose the recipients of their messages and exchange variable\nlength messages with them. This results in a decentralized and flexible\ncommunication mechanism in which agents can effectively use the communication\nchannel only when necessary. We designed two networks, a synthetic $4 \\times 4$\ngrid network and a real-world network based on the Pasubio neighborhood in\nBologna. Our framework achieved the lowest network congestion compared to\nrelated methods, with agents utilizing $\\sim 47-65 \\%$ of the communication\nchannel. Ablation studies further demonstrated the effectiveness of the\ncommunication policies learned within our framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.02435v1"
    },
    {
        "title": "Dynamics of the Ride-Sourcing Market: A Coevolutionary Model of\n  Competition between Two-Sided Mobility Platforms",
        "authors": [
            "Farnoud Ghasemi",
            "Arkadiusz Drabicki",
            "Rafał Kucharski"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  There is a fierce competition between two-sided mobility platforms (e.g.,\nUber and Lyft) fueled by massive subsidies, yet the underlying dynamics and\ninteractions between the competing plat-forms are largely unknown. These\nplatforms rely on the cross-side network effects to grow, they need to attract\nagents from both sides to kick-off: travellers are needed for drivers and\ndrivers are needed for travellers. We use our coevolutionary model featured by\nthe S-shaped learning curves to simulate the day-to-day dynamics of the\nride-sourcing market at the microscopic level. We run three scenarios to\nillustrate the possible equilibria in the market. Our results underline how the\ncorrelation inside the ride-sourcing nest of the agents choice set\nsignificantly affects the plat-forms' market shares. While late entry to the\nmarket decreases the chance of platform success and possibly results in\n\"winner-takes-all\", heavy subsidies can keep the new platform in competition\ngiving rise to \"market sharing\" regime.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.05543v1"
    },
    {
        "title": "Multi-Robot Task Assignment and Path Finding for Time-Sensitive Missions\n  with Online Task Generation",
        "authors": [
            "David Thorne",
            "Brett T. Lopez"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Executing time-sensitive multi-robot missions involves two distinct problems:\nMulti-Robot Task Assignment (MRTA) and Multi-Agent Path Finding (MAPF).\nComputing safe paths that complete every task and minimize the time to mission\ncompletion, or makespan, is a significant computational challenge even for\nsmall teams. In many missions, tasks can be generated during execution which is\ntypically handled by either recomputing task assignments and paths from\nscratch, or by modifying existing plans using approximate approaches. While\nperforming task reassignment and path finding from scratch produces\ntheoretically optimal results, the computational load makes it too expensive\nfor online implementation. In this work, we present Time-Sensitive Online Task\nAssignment and Navigation (TSOTAN), a framework which can quickly incorporate\nonline generated tasks while guaranteeing bounded suboptimal task assignment\nmakespans. It does this by assessing the quality of partial task reassignments\nand only performing a complete reoptimization when the makespan exceeds a user\nspecified suboptimality bound. Through experiments in 2D environments we\ndemonstrate TSOTAN's ability to produce quality solutions with computation\ntimes suitable for online implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.06153v1"
    },
    {
        "title": "Quantifying Agent Interaction in Multi-agent Reinforcement Learning for\n  Cost-efficient Generalization",
        "authors": [
            "Yuxin Chen",
            "Chen Tang",
            "Ran Tian",
            "Chenran Li",
            "Jinning Li",
            "Masayoshi Tomizuka",
            "Wei Zhan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Generalization poses a significant challenge in Multi-agent Reinforcement\nLearning (MARL). The extent to which an agent is influenced by unseen\nco-players depends on the agent's policy and the specific scenario. A\nquantitative examination of this relationship sheds light on effectively\ntraining agents for diverse scenarios. In this study, we present the Level of\nInfluence (LoI), a metric quantifying the interaction intensity among agents\nwithin a given scenario and environment. We observe that, generally, a more\ndiverse set of co-play agents during training enhances the generalization\nperformance of the ego agent; however, this improvement varies across distinct\nscenarios and environments. LoI proves effective in predicting these\nimprovement disparities within specific scenarios. Furthermore, we introduce a\nLoI-guided resource allocation method tailored to train a set of policies for\ndiverse scenarios under a constrained budget. Our results demonstrate that\nstrategic resource allocation based on LoI can achieve higher performance than\nuniform allocation under the same computation budget.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.07218v1"
    },
    {
        "title": "MARVEL: Multi-Agent Reinforcement-Learning for Large-Scale Variable\n  Speed Limits",
        "authors": [
            "Yuhang Zhang",
            "Marcos Quinones-Grueiro",
            "Zhiyao Zhang",
            "Yanbing Wang",
            "William Barbour",
            "Gautam Biswas",
            "Daniel Work"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Variable Speed Limit (VSL) control acts as a promising highway traffic\nmanagement strategy with worldwide deployment, which can enhance traffic safety\nby dynamically adjusting speed limits according to real-time traffic\nconditions. Most of the deployed VSL control algorithms so far are rule-based,\nlacking generalizability under varying and complex traffic scenarios. In this\nwork, we propose MARVEL (Multi-Agent Reinforcement-learning for large-scale\nVariable spEed Limits), a novel framework for large-scale VSL control on\nhighway corridors with real-world deployment settings. MARVEL utilizes only\nsensing information observable in the real world as state input and learns\nthrough a reward structure that incorporates adaptability to traffic\nconditions, safety, and mobility, thereby enabling multi-agent coordination.\nWith parameter sharing among all VSL agents, the proposed framework scales to\ncover corridors with many agents. The policies are trained in a microscopic\ntraffic simulation environment, focusing on a short freeway stretch with 8 VSL\nagents spanning 7 miles. For testing, these policies are applied to a more\nextensive network with 34 VSL agents spanning 17 miles of I-24 near Nashville,\nTN, USA. MARVEL-based method improves traffic safety by 63.4% compared to the\nno control scenario and enhances traffic mobility by 58.6% compared to a\nstate-of-the-practice algorithm that has been deployed on I-24. Besides, we\nconduct an explainability analysis to examine the decision-making process of\nthe agents and explore the learned policy under different traffic conditions.\nFinally, we test the response of the policy learned from the simulation-based\nexperiments with real-world data collected from I-24 and illustrate its\ndeployment capability.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.12359v2"
    },
    {
        "title": "GRAPE-S: Near Real-Time Coalition Formation for Multiple Service\n  Collectives",
        "authors": [
            "Grace Diehl",
            "Julie A. Adams"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Robotic collectives for military and disaster response applications require\ncoalition formation algorithms to partition robots into appropriate task teams.\nCollectives' missions will often incorporate tasks that require multiple\nhigh-level robot behaviors or services, which coalition formation must\naccommodate. The highly dynamic and unstructured application domains also\nnecessitate that coalition formation algorithms produce near optimal solutions\n(i.e., >95% utility) in near real-time (i.e., <5 minutes) with very large\ncollectives (i.e., hundreds of robots). No previous coalition formation\nalgorithm satisfies these requirements. An initial evaluation found that\ntraditional auction-based algorithms' runtimes are too long, even though the\ncentralized simulator incorporated ideal conditions unlikely to occur in\nreal-world deployments (i.e., synchronization across robots and perfect,\ninstantaneous communication). The hedonic game-based GRAPE algorithm can\nproduce solutions in near real-time, but cannot be applied to multiple service\ncollectives. This manuscript integrates GRAPE and a services model, producing\nGRAPE-S and Pair-GRAPE-S. These algorithms and two auction baselines were\nevaluated using a centralized simulator with up to 1000 robots, and via the\nlargest distributed coalition formation simulated evaluation to date, with up\nto 500 robots. The evaluations demonstrate that auctions transfer poorly to\ndistributed collectives, resulting in excessive runtimes and low utility\nsolutions. GRAPE-S satisfies the target domains' coalition formation\nrequirements, producing near optimal solutions in near real-time, and\nPair-GRAPE-S more than satisfies the domain requirements, producing optimal\nsolutions in near real-time. GRAPE-S and Pair-GRAPE-S are the first algorithms\ndemonstrated to support near real-time coalition formation for very large,\ndistributed collectives with multiple services.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.12480v1"
    },
    {
        "title": "Impact of Relational Networks in Multi-Agent Learning: A Value-Based\n  Factorization View",
        "authors": [
            "Yasin Findik",
            "Paul Robinette",
            "Kshitij Jerath",
            "S. Reza Ahmadzadeh"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Effective coordination and cooperation among agents are crucial for\naccomplishing individual or shared objectives in multi-agent systems. In many\nreal-world multi-agent systems, agents possess varying abilities and\nconstraints, making it necessary to prioritize agents based on their specific\nproperties to ensure successful coordination and cooperation within the team.\nHowever, most existing cooperative multi-agent algorithms do not take into\naccount these individual differences, and lack an effective mechanism to guide\ncoordination strategies. We propose a novel multi-agent learning approach that\nincorporates relationship awareness into value-based factorization methods.\nGiven a relational network, our approach utilizes inter-agents relationships to\ndiscover new team behaviors by prioritizing certain agents over other,\naccounting for differences between them in cooperative tasks. We evaluated the\neffectiveness of our proposed approach by conducting fifteen experiments in two\ndifferent environments. The results demonstrate that our proposed algorithm can\ninfluence and shape team behavior, guide cooperation strategies, and expedite\nagent learning. Therefore, our approach shows promise for use in multi-agent\nsystems, especially when agents have diverse properties.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.12912v1"
    },
    {
        "title": "DePAint: A Decentralized Safe Multi-Agent Reinforcement Learning\n  Algorithm considering Peak and Average Constraints",
        "authors": [
            "Raheeb Hassan",
            "K. M. Shadman Wadith",
            "Md. Mamun or Rashid",
            "Md. Mosaddek Khan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The domain of safe multi-agent reinforcement learning (MARL), despite its\npotential applications in areas ranging from drone delivery and vehicle\nautomation to the development of zero-energy communities, remains relatively\nunexplored. The primary challenge involves training agents to learn optimal\npolicies that maximize rewards while adhering to stringent safety constraints,\nall without the oversight of a central controller. These constraints are\ncritical in a wide array of applications. Moreover, ensuring the privacy of\nsensitive information in decentralized settings introduces an additional layer\nof complexity, necessitating innovative solutions that uphold privacy while\nachieving the system's safety and efficiency goals. In this paper, we address\nthe problem of multi-agent policy optimization in a decentralized setting,\nwhere agents communicate with their neighbors to maximize the sum of their\ncumulative rewards while also satisfying each agent's safety constraints. We\nconsider both peak and average constraints. In this scenario, there is no\ncentral controller coordinating the agents and both the rewards and constraints\nare only known to each agent locally/privately. We formulate the problem as a\ndecentralized constrained multi-agent Markov Decision Problem and propose a\nmomentum-based decentralized policy gradient method, DePAint, to solve it. To\nthe best of our knowledge, this is the first privacy-preserving fully\ndecentralized multi-agent reinforcement learning algorithm that considers both\npeak and average constraints. We then provide theoretical analysis and\nempirical evaluation of our algorithm in a number of scenarios and compare its\nperformance to centralized algorithms that consider similar constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.14348v2"
    },
    {
        "title": "Covert Planning against Imperfect Observers",
        "authors": [
            "Haoxiang Ma",
            "Chongyang Shi",
            "Shuo Han",
            "Michael R. Dorothy",
            "Jie Fu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Covert planning refers to a class of constrained planning problems where an\nagent aims to accomplish a task with minimal information leaked to a passive\nobserver to avoid detection. However, existing methods of covert planning often\nconsider deterministic environments or do not exploit the observer's imperfect\ninformation. This paper studies how covert planning can leverage the coupling\nof stochastic dynamics and the observer's imperfect observation to achieve\noptimal task performance without being detected. Specifically, we employ a\nMarkov decision process to model the interaction between the agent and its\nstochastic environment, and a partial observation function to capture the\nleaked information to a passive observer. Assuming the observer employs\nhypothesis testing to detect if the observation deviates from a nominal policy,\nthe covert planning agent aims to maximize the total discounted reward while\nkeeping the probability of being detected as an adversary below a given\nthreshold. We prove that finite-memory policies are more powerful than\nMarkovian policies in covert planning. Then, we develop a primal-dual proximal\npolicy gradient method with a two-time-scale update to compute a (locally)\noptimal covert policy. We demonstrate the effectiveness of our methods using a\nstochastic gridworld example. Our experimental results illustrate that the\nproposed method computes a policy that maximizes the adversary's expected\nreward without violating the detection constraint, and empirically demonstrates\nhow the environmental noises can influence the performance of the covert\npolicies.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.16791v2"
    },
    {
        "title": "Detecting subtle cyberattacks on adaptive cruise control vehicles: A\n  machine learning approach",
        "authors": [
            "Tianyi Li",
            "Mingfeng Shang",
            "Shian Wang",
            "Raphael Stern"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  With the advent of vehicles equipped with advanced driver-assistance systems,\nsuch as adaptive cruise control (ACC) and other automated driving features, the\npotential for cyberattacks on these automated vehicles (AVs) has emerged. While\novert attacks that force vehicles to collide may be easily identified, more\ninsidious attacks, which only slightly alter driving behavior, can result in\nnetwork-wide increases in congestion, fuel consumption, and even crash risk\nwithout being easily detected. To address the detection of such attacks, we\nfirst present a traffic model framework for three types of potential\ncyberattacks: malicious manipulation of vehicle control commands, false data\ninjection attacks on sensor measurements, and denial-of-service (DoS) attacks.\nWe then investigate the impacts of these attacks at both the individual vehicle\n(micro) and traffic flow (macro) levels. A novel generative adversarial network\n(GAN)-based anomaly detection model is proposed for real-time identification of\nsuch attacks using vehicle trajectory data. We provide numerical evidence {to\ndemonstrate} the efficacy of our machine learning approach in detecting\ncyberattacks on ACC-equipped vehicles. The proposed method is compared against\nsome recently proposed neural network models and observed to have higher\naccuracy in identifying anomalous driving behaviors of ACC vehicles.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.17091v2"
    },
    {
        "title": "Fuzzy Multi-Agent Simulation of COVID-19 Pandemic Spreading",
        "authors": [
            "Didier El Baz",
            "Andrei Doncescu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we present a new approach for Covid-19 Pandemic spreading\nsimulation based on fuzzy multi agents. The agent parameters consider\ndistribution of the population according to age, and the index of\nsocio-economic fragility. Medical knowledge affirms that the COVID-19 main risk\nfactors are age and obesity. The worst medical situation is caused by the\ncombination of these two risk factors which in almost99% of cases finish in\nICU. The appearance of virus variants is another aspect parameter by our\nsimulation through a simplified modeling of the contagiousness. Using real data\nfrom people from West Indies (Guadeloupe, F.W.I.), we modeled the infection\nrate of the risk population, if neither vaccination nor barrier gestures are\nrespected. The results show that hospital capacities are exceeded, and the\nnumber of deaths exceeds 2% of the infected population, which is close to the\nreality.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.17986v1"
    },
    {
        "title": "Emergence of Collective Open-Ended Exploration from Decentralized\n  Meta-Reinforcement Learning",
        "authors": [
            "Richard Bornemann",
            "Gautier Hamon",
            "Eleni Nisioti",
            "Clément Moulin-Frier"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Recent works have proven that intricate cooperative behaviors can emerge in\nagents trained using meta reinforcement learning on open ended task\ndistributions using self-play. While the results are impressive, we argue that\nself-play and other centralized training techniques do not accurately reflect\nhow general collective exploration strategies emerge in the natural world:\nthrough decentralized training and over an open-ended distribution of tasks. In\nthis work we therefore investigate the emergence of collective exploration\nstrategies, where several agents meta-learn independent recurrent policies on\nan open ended distribution of tasks. To this end we introduce a novel\nenvironment with an open ended procedurally generated task space which\ndynamically combines multiple subtasks sampled from five diverse task types to\nform a vast distribution of task trees. We show that decentralized agents\ntrained in our environment exhibit strong generalization abilities when\nconfronted with novel objects at test time. Additionally, despite never being\nforced to cooperate during training the agents learn collective exploration\nstrategies which allow them to solve novel tasks never encountered during\ntraining. We further find that the agents learned collective exploration\nstrategies extend to an open ended task setting, allowing them to solve task\ntrees of twice the depth compared to the ones seen during training. Our open\nsource code as well as videos of the agents can be found on our companion\nwebsite.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.00651v3"
    },
    {
        "title": "On Convex Optimal Value Functions For POSGs",
        "authors": [
            "Rafael F. Cunha",
            "Jacopo Castellini",
            "Johan Peralez",
            "Jilles S. Dibangoye"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent planning and reinforcement learning can be challenging when\nagents cannot see the state of the world or communicate with each other due to\ncommunication costs, latency, or noise. Partially Observable Stochastic Games\n(POSGs) provide a mathematical framework for modelling such scenarios. This\npaper aims to improve the efficiency of planning and reinforcement learning\nalgorithms for POSGs by identifying the underlying structure of optimal\nstate-value functions. The approach involves reformulating the original game\nfrom the perspective of a trusted third party who plans on behalf of the agents\nsimultaneously. From this viewpoint, the original POSGs can be viewed as Markov\ngames where states are occupancy states, \\ie posterior probability\ndistributions over the hidden states of the world and the stream of actions and\nobservations that agents have experienced so far. This study mainly proves that\nthe optimal state-value function is a convex function of occupancy states\nexpressed on an appropriate basis in all zero-sum, common-payoff, and\nStackelberg POSGs.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09459v3"
    },
    {
        "title": "HMAS: enabling seamless collaboration between drones, quadruped robots,\n  and human operators with efficient spatial awareness",
        "authors": [
            "Amaury Saint-Jore",
            "Ye-Qiong Song",
            "Laurent Ciarletta"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Heterogeneous robots equipped with multi-modal sensors (e.g., UAV, wheeled\nand legged terrestrial robots) provide rich and complementary functions that\nmay help human operators to accomplish complex tasks in unknown environments.\nHowever, seamlessly integrating heterogeneous agents and making them interact\nand collaborate still arise challenging issues. In this paper, we define a ROS\n2 based software architecture that allows to build incarnated heterogeneous\nmulti-agent systems (HMAS) in a generic way. We showcase its effectiveness\nthrough a scenario integrating aerial drones, quadruped robots, and human\noperators (see https://youtu.be/iOtCCticGuk). In addition, agent spatial\nawareness in unknown outdoor environments is a critical step for realizing\nautonomous individual movements, interactions, and collaborations. Through\nintensive experimental measurements, RTK-GPS is shown to be a suitable solution\nfor achieving the required locating accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.18394v1"
    },
    {
        "title": "Viral transmission in pedestrian crowds: Coupling an open-source code\n  assessing the risks of airborne contagion with diverse pedestrian dynamics\n  models",
        "authors": [
            "Alexandre Nicolas",
            "Simon Mendez"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We study viral transmission in crowds via the short-ranged airborne pathway\nusing a purely model-based approach. Our goal is two-pronged. Firstly, we\nillustrate with a concrete and pedagogical case study how to estimate the risks\nof new viral infections by coupling pedestrian simulations with the\ntransmission algorithm that we recently released as open-source code. The\nalgorithm hinges on pre-computed viral concentration maps derived from\ncomputational fluid dynamics (CFD) simulations. Secondly, we investigate to\nwhat extent the transmission risk predictions depend on the pedestrian dynamics\nmodel in use. For the simple bidirectional flow under consideration, the\npredictions are found to be surprisingly stable across initial conditions and\nmodels, despite the different microscopic arrangements of the simulated crowd,\nas long as the crowd evolves in a qualitatively similarly way. On the other\nhand, when major changes are observed in the crowd's behaviour, notably\nwhenever a jam occurs at the centre of the channel, the estimated risks surge\ndrastically.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.01779v1"
    },
    {
        "title": "Mastering Complex Coordination through Attention-based Dynamic Graph",
        "authors": [
            "Guangchong Zhou",
            "Zhiwei Xu",
            "Zeren Zhang",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The coordination between agents in multi-agent systems has become a popular\ntopic in many fields. To catch the inner relationship between agents, the graph\nstructure is combined with existing methods and improves the results. But in\nlarge-scale tasks with numerous agents, an overly complex graph would lead to a\nboost in computational cost and a decline in performance. Here we present\nDAGMIX, a novel graph-based value factorization method. Instead of a complete\ngraph, DAGMIX generates a dynamic graph at each time step during training, on\nwhich it realizes a more interpretable and effective combining process through\nthe attention mechanism. Experiments show that DAGMIX significantly outperforms\nprevious SOTA methods in large-scale scenarios, as well as achieving promising\nresults on other tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.04245v1"
    },
    {
        "title": "Optimizing Local Satisfaction of Long-Run Average Objectives in Markov\n  Decision Processes",
        "authors": [
            "David Klaška",
            "Antonín Kučera",
            "Vojtěch Kůr",
            "Vít Musil",
            "Vojtěch Řehák"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Long-run average optimization problems for Markov decision processes (MDPs)\nrequire constructing policies with optimal steady-state behavior, i.e., optimal\nlimit frequency of visits to the states. However, such policies may suffer from\nlocal instability, i.e., the frequency of states visited in a bounded time\nhorizon along a run differs significantly from the limit frequency. In this\nwork, we propose an efficient algorithmic solution to this problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.12325v1"
    },
    {
        "title": "TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy\n  Gradient",
        "authors": [
            "Xingzhou Lou",
            "Junge Zhang",
            "Timothy J. Norman",
            "Kaiqi Huang",
            "Yali Du"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-Agent Policy Gradient (MAPG) has made significant progress in recent\nyears. However, centralized critics in state-of-the-art MAPG methods still face\nthe centralized-decentralized mismatch (CDM) issue, which means sub-optimal\nactions by some agents will affect other agent's policy learning. While using\nindividual critics for policy updates can avoid this issue, they severely limit\ncooperation among agents. To address this issue, we propose an agent topology\nframework, which decides whether other agents should be considered in policy\ngradient and achieves compromise between facilitating cooperation and\nalleviating the CDM issue. The agent topology allows agents to use coalition\nutility as learning objective instead of global utility by centralized critics\nor local utility by individual critics. To constitute the agent topology,\nvarious models are studied. We propose Topology-based multi-Agent Policy\ngradiEnt (TAPE) for both stochastic and deterministic MAPG methods. We prove\nthe policy improvement theorem for stochastic TAPE and give a theoretical\nexplanation for the improved cooperation among agents. Experiment results on\nseveral benchmarks show the agent topology is able to facilitate agent\ncooperation and alleviate CDM issue respectively to improve performance of\nTAPE. Finally, multiple ablation studies and a heuristic graph search algorithm\nare devised to show the efficacy of the agent topology.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.15667v3"
    },
    {
        "title": "Controlling identical linear multi-agent systems over directed graphs",
        "authors": [
            "Nicola Zaupa",
            "Luca Zaccarian",
            "Isabelle Queinnec",
            "Sophie Tarbouriech",
            "Giulia Giordano"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We consider the problem of synchronizing a multi-agent system (MAS) composed\nof several identical linear systems connected through a directed graph.To\ndesign a suitable controller, we construct conditions based on Bilinear Matrix\nInequalities (BMIs) that ensure state synchronization.Since these conditions\nare non-convex, we propose an iterative algorithm based on a suitable\nrelaxation that allows us to formulate Linear Matrix Inequality (LMI)\nconditions.As a result, the algorithm yields a common static state-feedback\nmatrix for the controller that satisfies general linear performance\nconstraints.Our results are achieved under the mild assumption that the graph\nis time-invariant and connected.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.15929v1"
    },
    {
        "title": "Contrastive learning-based agent modeling for deep reinforcement\n  learning",
        "authors": [
            "Wenhao Ma",
            "Yu-Cheng Chang",
            "Jie Yang",
            "Yu-Kai Wang",
            "Chin-Teng Lin"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent systems often require agents to collaborate with or compete\nagainst other agents with diverse goals, behaviors, or strategies. Agent\nmodeling is essential when designing adaptive policies for intelligent machine\nagents in multiagent systems, as this is the means by which the ego agent\nunderstands other agents' behavior and extracts their meaningful policy\nrepresentations. These representations can be used to enhance the ego agent's\nadaptive policy which is trained by reinforcement learning. However, existing\nagent modeling approaches typically assume the availability of local\nobservations from other agents (modeled agents) during training or a long\nobservation trajectory for policy adaption. To remove these constrictive\nassumptions and improve agent modeling performance, we devised a Contrastive\nLearning-based Agent Modeling (CLAM) method that relies only on the local\nobservations from the ego agent during training and execution. With these\nobservations, CLAM is capable of generating consistent high-quality policy\nrepresentations in real-time right from the beginning of each episode. We\nevaluated the efficacy of our approach in both cooperative and competitive\nmulti-agent environments. Our experiments demonstrate that our approach\nachieves state-of-the-art on both cooperative and competitive tasks,\nhighlighting the potential of contrastive learning-based agent modeling for\nenhancing reinforcement learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.00132v2"
    },
    {
        "title": "Leveraging Partial Symmetry for Multi-Agent Reinforcement Learning",
        "authors": [
            "Xin Yu",
            "Rongye Shi",
            "Pu Feng",
            "Yongkai Tian",
            "Simin Li",
            "Shuhao Liao",
            "Wenjun Wu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Incorporating symmetry as an inductive bias into multi-agent reinforcement\nlearning (MARL) has led to improvements in generalization, data efficiency, and\nphysical consistency. While prior research has succeeded in using perfect\nsymmetry prior, the realm of partial symmetry in the multi-agent domain remains\nunexplored. To fill in this gap, we introduce the partially symmetric Markov\ngame, a new subclass of the Markov game. We then theoretically show that the\nperformance error introduced by utilizing symmetry in MARL is bounded, implying\nthat the symmetry prior can still be useful in MARL even in partial symmetry\nsituations. Motivated by this insight, we propose the Partial Symmetry\nExploitation (PSE) framework that is able to adaptively incorporate symmetry\nprior in MARL under different symmetry-breaking conditions. Specifically, by\nadaptively adjusting the exploitation of symmetry, our framework is able to\nachieve superior sample efficiency and overall performance of MARL algorithms.\nExtensive experiments are conducted to demonstrate the superior performance of\nthe proposed framework over baselines. Finally, we implement the proposed\nframework in real-world multi-robot testbed to show its superiority.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.00167v1"
    },
    {
        "title": "Distributed Multi-Object Tracking Under Limited Field of View\n  Heterogeneous Sensors with Density Clustering",
        "authors": [
            "Fei Chen",
            "Hoa Van Nguyen",
            "Alex S. Leong",
            "Sabita Panicker",
            "Robin Baker",
            "Damith C. Ranasinghe"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We consider the problem of tracking multiple, unknown, and time-varying\nnumbers of objects using a distributed network of heterogeneous sensors. In an\neffort to derive a formulation for practical settings, we consider limited and\nunknown sensor field-of-views (FoVs), sensors with limited local computational\nresources and communication channel capacity. The resulting distributed\nmulti-object tracking algorithm involves solving an NP-hard multidimensional\nassignment problem either optimally for small-size problems or sub-optimally\nfor general practical problems. For general problems, we propose an efficient\ndistributed multi-object tracking algorithm that performs track-to-track fusion\nusing a clustering-based analysis of the state space transformed into a density\nspace to mitigate the complexity of the assignment problem. The proposed\nalgorithm can more efficiently group local track estimates for fusion than\nexisting approaches. To ensure we achieve globally consistent identities for\ntracks across a network of nodes as objects move between FoVs, we develop a\ngraph-based algorithm to achieve label consensus and minimise track\nsegmentation. Numerical experiments with synthetic and real-world trajectory\ndatasets demonstrate that our proposed method is significantly more\ncomputationally efficient than state-of-the-art solutions, achieving similar\ntracking accuracy and bandwidth requirements but with improved label\nconsistency.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.00605v2"
    },
    {
        "title": "AgentMixer: Multi-Agent Correlated Policy Factorization",
        "authors": [
            "Zhiyuan Li",
            "Wenshuai Zhao",
            "Lijun Wu",
            "Joni Pajarinen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In multi-agent reinforcement learning, centralized training with\ndecentralized execution (CTDE) methods typically assume that agents make\ndecisions based on their local observations independently, which may not lead\nto a correlated joint policy with coordination. Coordination can be explicitly\nencouraged during training and individual policies can be trained to imitate\nthe correlated joint policy. However, this may lead to an \\textit{asymmetric\nlearning failure} due to the observation mismatch between the joint and\nindividual policies. Inspired by the concept of correlated equilibrium, we\nintroduce a \\textit{strategy modification} called AgentMixer that allows agents\nto correlate their policies. AgentMixer combines individual partially\nobservable policies into a joint fully observable policy non-linearly. To\nenable decentralized execution, we introduce\n\\textit{Individual-Global-Consistency} to guarantee mode consistency during\njoint training of the centralized and decentralized policies and prove that\nAgentMixer converges to an $\\epsilon$-approximate Correlated Equilibrium. In\nthe Multi-Agent MuJoCo, SMAC-v2, Matrix Game, and Predator-Prey benchmarks,\nAgentMixer outperforms or matches state-of-the-art methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.08728v3"
    },
    {
        "title": "Decentralizing Coordination in Open Vehicle Fleets for Scalable and\n  Dynamic Task Allocation",
        "authors": [
            "Marin Lujak",
            "Stefano Giordani",
            "Andrea Omicini",
            "Sascha Ossowski"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  One of the major challenges in the coordination of large, open,\ncollaborative, and commercial vehicle fleets is dynamic task allocation.\nSelf-concerned individually rational vehicle drivers have both local and global\nobjectives, which require coordination using some fair and efficient task\nallocation method. In this paper, we review the literature on scalable and\ndynamic task allocation focusing on deterministic and dynamic two-dimensional\nlinear assignment problems. We focus on multiagent system representation of\nopen vehicle fleets where dynamically appearing vehicles are represented by\nsoftware agents that should be allocated to a set of dynamically appearing\ntasks. We give a comparison and critical analysis of recent research results\nfocusing on centralized, distributed, and decentralized solution approaches.\nMoreover, we propose mathematical models for dynamic versions of the following\nassignment problems well known in combinatorial optimization: the assignment\nproblem, bottleneck assignment problem, fair matching problem, dynamic minimum\ndeviation assignment problem, $\\sum_{k}$-assignment problem, the semiassignment\nproblem, the assignment problem with side constraints, and the assignment\nproblem while recognizing agent qualification; all while considering the main\naspect of open vehicle fleets: random arrival of tasks and vehicles (agents)\nthat may become available after assisting previous tasks or by participating in\nthe fleet at times based on individual interest.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.10965v1"
    },
    {
        "title": "T2MAC: Targeted and Trusted Multi-Agent Communication through Selective\n  Engagement and Evidence-Driven Integration",
        "authors": [
            "Chuxiong Sun",
            "Zehua Zang",
            "Jiabao Li",
            "Jiangmeng Li",
            "Xiao Xu",
            "Rui Wang",
            "Changwen Zheng"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Communication stands as a potent mechanism to harmonize the behaviors of\nmultiple agents. However, existing works primarily concentrate on broadcast\ncommunication, which not only lacks practicality, but also leads to information\nredundancy. This surplus, one-fits-all information could adversely impact the\ncommunication efficiency. Furthermore, existing works often resort to basic\nmechanisms to integrate observed and received information, impairing the\nlearning process. To tackle these difficulties, we propose Targeted and Trusted\nMulti-Agent Communication (T2MAC), a straightforward yet effective method that\nenables agents to learn selective engagement and evidence-driven integration.\nWith T2MAC, agents have the capability to craft individualized messages,\npinpoint ideal communication windows, and engage with reliable partners,\nthereby refining communication efficiency. Following the reception of messages,\nthe agents integrate information observed and received from different sources\nat an evidence level. This process enables agents to collectively use evidence\ngarnered from multiple perspectives, fostering trusted and cooperative\nbehaviors. We evaluate our method on a diverse set of cooperative multi-agent\ntasks, with varying difficulties, involving different scales and ranging from\nHallway, MPE to SMAC. The experiments indicate that the proposed model not only\nsurpasses the state-of-the-art methods in terms of cooperative performance and\ncommunication efficiency, but also exhibits impressive generalization.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.10973v1"
    },
    {
        "title": "Measuring Policy Distance for Multi-Agent Reinforcement Learning",
        "authors": [
            "Tianyi Hu",
            "Zhiqiang Pu",
            "Xiaolin Ai",
            "Tenghai Qiu",
            "Jianqiang Yi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Diversity plays a crucial role in improving the performance of multi-agent\nreinforcement learning (MARL). Currently, many diversity-based methods have\nbeen developed to overcome the drawbacks of excessive parameter sharing in\ntraditional MARL. However, there remains a lack of a general metric to quantify\npolicy differences among agents. Such a metric would not only facilitate the\nevaluation of the diversity evolution in multi-agent systems, but also provide\nguidance for the design of diversity-based MARL algorithms. In this paper, we\npropose the multi-agent policy distance (MAPD), a general tool for measuring\npolicy differences in MARL. By learning the conditional representations of\nagents' decisions, MAPD can computes the policy distance between any pair of\nagents. Furthermore, we extend MAPD to a customizable version, which can\nquantify differences among agent policies on specified aspects. Based on the\nonline deployment of MAPD, we design a multi-agent dynamic parameter sharing\n(MADPS) algorithm as an example of the MAPD's applications. Extensive\nexperiments demonstrate that our method is effective in measuring differences\nin agent policies and specific behavioral tendencies. Moreover, in comparison\nto other methods of parameter sharing, MADPS exhibits superior performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11257v2"
    },
    {
        "title": "Controlling the Misinformation Diffusion in Social Media by the Effect\n  of Different Classes of Agents",
        "authors": [
            "Ali Khodabandeh Yalabadi",
            "Mehdi Yazdani-Jahromi",
            "Sina Abdidizaji",
            "Ivan Garibay",
            "Ozlem Ozmen Garibay"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The rapid and widespread dissemination of misinformation through social\nnetworks is a growing concern in today's digital age. This study focused on\nmodeling fake news diffusion, discovering the spreading dynamics, and designing\ncontrol strategies. A common approach for modeling the misinformation dynamics\nis SIR-based models. Our approach is an extension of a model called 'SBFC'\nwhich is a SIR-based model. This model has three states, Susceptible, Believer,\nand Fact-Checker. The dynamics and transition between states are based on\nneighbors' beliefs, hoax credibility, spreading rate, probability of verifying\nthe news, and probability of forgetting the current state. Our contribution is\nto push this model to real social networks by considering different classes of\nagents with their characteristics. We proposed two main strategies for\nconfronting misinformation diffusion. First, we can educate a minor class, like\nscholars or influencers, to improve their ability to verify the news or\nremember their state longer. The second strategy is adding fact-checker bots to\nthe network to spread the facts and influence their neighbors' states. Our\nresult shows that both of these approaches can effectively control the\nmisinformation spread.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11524v1"
    },
    {
        "title": "Collaborative Reinforcement Learning Based Unmanned Aerial Vehicle (UAV)\n  Trajectory Design for 3D UAV Tracking",
        "authors": [
            "Yujiao Zhu",
            "Mingzhe Chen",
            "Sihua Wang",
            "Ye Hu",
            "Yuchen Liu",
            "Changchuan Yin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper, the problem of using one active unmanned aerial vehicle (UAV)\nand four passive UAVs to localize a 3D target UAV in real time is investigated.\nIn the considered model, each passive UAV receives reflection signals from the\ntarget UAV, which are initially transmitted by the active UAV. The received\nreflection signals allow each passive UAV to estimate the signal transmission\ndistance which will be transmitted to a base station (BS) for the estimation of\nthe position of the target UAV. Due to the movement of the target UAV, each\nactive/passive UAV must optimize its trajectory to continuously localize the\ntarget UAV. Meanwhile, since the accuracy of the distance estimation depends on\nthe signal-to-noise ratio of the transmission signals, the active UAV must\noptimize its transmit power. This problem is formulated as an optimization\nproblem whose goal is to jointly optimize the transmit power of the active UAV\nand trajectories of both active and passive UAVs so as to maximize the target\nUAV positioning accuracy. To solve this problem, a Z function decomposition\nbased reinforcement learning (ZD-RL) method is proposed. Compared to value\nfunction decomposition based RL (VD-RL), the proposed method can find the\nprobability distribution of the sum of future rewards to accurately estimate\nthe expected value of the sum of future rewards thus finding better transmit\npower of the active UAV and trajectories for both active and passive UAVs and\nimproving target UAV positioning accuracy. Simulation results show that the\nproposed ZD-RL method can reduce the positioning errors by up to 39.4% and\n64.6%, compared to VD-RL and independent deep RL methods, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12079v1"
    },
    {
        "title": "Agreement Technologies for Coordination in Smart Cities",
        "authors": [
            "Holger Billhardt",
            "Alberto Fernández",
            "Marin Lujak",
            "Sascha Ossowski"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Many challenges in today's society can be tackled by distributed open\nsystems. This is particularly true for domains that are commonly perceived\nunder the umbrella of smart cities, such as intelligent transportation, smart\nenergy grids, or participative governance. When designing computer applications\nfor these domains, it is necessary to account for the fact that the elements of\nsuch systems, often called software agents, are usually made by different\ndesigners and act on behalf of particular stakeholders. Furthermore, it is\nunknown at design time when such agents will enter or leave the system, and\nwhat interests new agents will represent. To instil coordination in such\nsystems is particularly demanding, as usually only part of them can be directly\ncontrolled at runtime. Agreement technologies refer to a sandbox of tools and\nmechanisms for the development of such open multiagent systems, which are based\non the notion of agreement. In this paper, we argue that agreement technologies\nare a suitable means for achieving coordination in smart city domains, and back\nour claim through examples of several real-world applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12259v1"
    },
    {
        "title": "Trust model of privacy-concerned, emotionally-aware agents in a\n  cooperative logistics problem",
        "authors": [
            "J. Carbo",
            "J. M. Molina"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper we propose a trust model to be used into a hypothetical mixed\nenvironment where humans and unmanned vehicles cooperate. We address the\ninclusion of emotions inside a trust model in a coherent way to the practical\napproaches to the current psychology theories. The most innovative contribution\nis how privacy issues play a role in the cooperation decisions of the emotional\ntrust model. Both, emotions and trust have been cognitively modeled and managed\nwith the Beliefs, Desires and Intentions (BDI) paradigm into autonomous agents\nimplemented in GAML (the programming language of GAMA agent platform) that\ncommunicates using the IEEE FIPA standard. The trusting behaviour of these\nemotional agents is tested in a cooperative logistics problem where: agents\nhave to move objects to destinations and some of the objects and places have\nprivacy issues. The execution of simulations of this logistic problem shows how\nemotions and trust contribute to improve the performance of agents in terms of\nboth, time savings and privacy protection\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14436v1"
    },
    {
        "title": "Modelling Solar PV Adoption in Irish Dairy Farms using Agent-Based\n  Modelling",
        "authors": [
            "Iias Faiud",
            "Michael Schukat",
            "Karl Mason"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The agricultural sector is facing mounting demands to enhance energy\nefficiency within farm enterprises, concurrent with a steady escalation in\nelectricity costs. This paper focuses on modelling the adoption rate of\nphotovoltaic (PV) energy within the dairy sector in Ireland. An agent-based\nmodelling approach is introduced to estimate the adoption rate. The model\nconsiders grid energy prices, revenue, costs, and maintenance expenses to\ncalculate the probability of PV adoption. The ABM outputs estimate that by year\n2022, 2.45% of dairy farmers have installed PV. This is a 0.45% difference to\nthe actual PV adoption rate in year 2022. This validates the proposed ABM. The\npaper demonstrates the increasing interest in PV systems as evidenced by the\nrate of adoption, shedding light on the potential advantages of PV energy\nadoption in agriculture. This study possesses the potential to forecast future\nrates of PV energy adoption among dairy farmers. It establishes a groundwork\nfor further research on predicting and understanding the factors influencing\nthe adoption of renewable energy.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16222v1"
    },
    {
        "title": "LLM Multi-Agent Systems: Challenges and Open Problems",
        "authors": [
            "Shanshan Han",
            "Qifan Zhang",
            "Yuhang Yao",
            "Weizhao Jin",
            "Zhaozhuo Xu",
            "Chaoyang He"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper explores existing works of multi-agent systems and identifies\nchallenges that remain inadequately addressed. By leveraging the diverse\ncapabilities and roles of individual agents within a multi-agent system, these\nsystems can tackle complex tasks through collaboration. We discuss optimizing\ntask allocation, fostering robust reasoning through iterative debates, managing\ncomplex and layered context information, and enhancing memory management to\nsupport the intricate interactions within multi-agent systems. We also explore\nthe potential application of multi-agent systems in blockchain systems to shed\nlight on their future development and application in real-world distributed\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.03578v1"
    },
    {
        "title": "Joint Intrinsic Motivation for Coordinated Exploration in Multi-Agent\n  Deep Reinforcement Learning",
        "authors": [
            "Maxime Toquebiau",
            "Nicolas Bredeche",
            "Faïz Benamar",
            "Jae-Yun Jun"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent deep reinforcement learning (MADRL) problems often encounter the\nchallenge of sparse rewards. This challenge becomes even more pronounced when\ncoordination among agents is necessary. As performance depends not only on one\nagent's behavior but rather on the joint behavior of multiple agents, finding\nan adequate solution becomes significantly harder. In this context, a group of\nagents can benefit from actively exploring different joint strategies in order\nto determine the most efficient one. In this paper, we propose an approach for\nrewarding strategies where agents collectively exhibit novel behaviors. We\npresent JIM (Joint Intrinsic Motivation), a multi-agent intrinsic motivation\nmethod that follows the centralized learning with decentralized execution\nparadigm. JIM rewards joint trajectories based on a centralized measure of\nnovelty designed to function in continuous environments. We demonstrate the\nstrengths of this approach both in a synthetic environment designed to reveal\nshortcomings of state-of-the-art MADRL methods, and in simulated robotic tasks.\nResults show that joint exploration is crucial for solving tasks where the\noptimal strategy requires a high level of coordination.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.03972v1"
    },
    {
        "title": "Towards Generalizability of Multi-Agent Reinforcement Learning in Graphs\n  with Recurrent Message Passing",
        "authors": [
            "Jannis Weil",
            "Zhenghua Bao",
            "Osama Abboud",
            "Tobias Meuser"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Graph-based environments pose unique challenges to multi-agent reinforcement\nlearning. In decentralized approaches, agents operate within a given graph and\nmake decisions based on partial or outdated observations. The size of the\nobserved neighborhood limits the generalizability to different graphs and\naffects the reactivity of agents, the quality of the selected actions, and the\ncommunication overhead. This work focuses on generalizability and resolves the\ntrade-off in observed neighborhood size with a continuous information flow in\nthe whole graph. We propose a recurrent message-passing model that iterates\nwith the environment's steps and allows nodes to create a global representation\nof the graph by exchanging messages with their neighbors. Agents receive the\nresulting learned graph observations based on their location in the graph. Our\napproach can be used in a decentralized manner at runtime and in combination\nwith a reinforcement learning algorithm of choice. We evaluate our method\nacross 1000 diverse graphs in the context of routing in communication networks\nand find that it enables agents to generalize and adapt to changes in the\ngraph.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.05027v3"
    },
    {
        "title": "Linking Vision and Multi-Agent Communication through Visible Light\n  Communication using Event Cameras",
        "authors": [
            "Haruyuki Nakagawa",
            "Yoshitaka Miyatani",
            "Asako Kanezaki"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Various robots, rovers, drones, and other agents of mass-produced products\nare expected to encounter scenes where they intersect and collaborate in the\nnear future. In such multi-agent systems, individual identification and\ncommunication play crucial roles. In this paper, we explore camera-based\nvisible light communication using event cameras to tackle this problem. An\nevent camera captures the events occurring in regions with changes in\nbrightness and can be utilized as a receiver for visible light communication,\nleveraging its high temporal resolution. Generally, agents with identical\nappearances in mass-produced products are visually indistinguishable when using\nconventional CMOS cameras. Therefore, linking visual information with\ninformation acquired through conventional radio communication is challenging.\nWe empirically demonstrate the advantages of a visible light communication\nsystem employing event cameras and LEDs for visual individual identification\nover conventional CMOS cameras with ArUco marker recognition. In the\nsimulation, we also verified scenarios where our event camera-based visible\nlight communication outperforms conventional radio communication in situations\nwith visually indistinguishable multi-agents. Finally, our newly implemented\nmulti-agent system verifies its functionality through physical robot\nexperiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.05619v2"
    },
    {
        "title": "CityFlowER: An Efficient and Realistic Traffic Simulator with Embedded\n  Machine Learning Models",
        "authors": [
            "Longchao Da",
            "Chen Chu",
            "Weinan Zhang",
            "Hua Wei"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Traffic simulation is an essential tool for transportation infrastructure\nplanning, intelligent traffic control policy learning, and traffic flow\nanalysis. Its effectiveness relies heavily on the realism of the simulators\nused. Traditional traffic simulators, such as SUMO and CityFlow, are often\nlimited by their reliance on rule-based models with hyperparameters that\noversimplify driving behaviors, resulting in unrealistic simulations. To\nenhance realism, some simulators have provided Application Programming\nInterfaces (APIs) to interact with Machine Learning (ML) models, which learn\nfrom observed data and offer more sophisticated driving behavior models.\nHowever, this approach faces challenges in scalability and time efficiency as\nvehicle numbers increase. Addressing these limitations, we introduce\nCityFlowER, an advancement over the existing CityFlow simulator, designed for\nefficient and realistic city-wide traffic simulation. CityFlowER innovatively\npre-embeds ML models within the simulator, eliminating the need for external\nAPI interactions and enabling faster data computation. This approach allows for\na blend of rule-based and ML behavior models for individual vehicles, offering\nunparalleled flexibility and efficiency, particularly in large-scale\nsimulations. We provide detailed comparisons with existing simulators,\nimplementation insights, and comprehensive experiments to demonstrate\nCityFlowER's superiority in terms of realism, efficiency, and adaptability.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.06127v1"
    },
    {
        "title": "A Novel Multivariate Skew-Normal Mixture Model and Its Application in\n  Path-Planning for Very-Large-Scale Robotic Systems",
        "authors": [
            "Pingping Zhu",
            "Chang Liu",
            "Peter Estephan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper addresses the path-planning challenge for very large-scale robotic\nsystems (VLSR) operating in complex and cluttered environments. VLSR systems\nconsist of numerous cooperative agents or robots working together autonomously.\nTraditionally, many approaches for VLSR systems are developed based on Gaussian\nmixture models (GMMs), where the GMMs represent agents' evolving spatial\ndistribution, serving as a macroscopic view of the system's state. However, our\nrecent research into VLSR systems has unveiled limitations in using GMMs to\nrepresent agent distributions, especially in cluttered environments. To\novercome these limitations, we propose a novel model called the skew-normal\nmixture model (SNMM) for representing agent distributions. Additionally, we\npresent a parameter learning algorithm designed to estimate the SNMM's\nparameters using sample data. Furthermore, we develop two SNMM-based\npath-planning algorithms to guide VLSR systems through complex and cluttered\nenvironments. Our simulation results demonstrate the effectiveness and\nsuperiority of these algorithms compared to GMM-based path-planning methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11091v1"
    },
    {
        "title": "Multi-Generative Agent Collective Decision-Making in Urban Planning: A\n  Case Study for Kendall Square Renovation",
        "authors": [
            "Jin Gao",
            "Hanyong Xu",
            "Luc Dao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this study, we develop a multiple-generative agent system to simulate\ncommunity decision-making for the redevelopment of Kendall Square's Volpe\nbuilding. Drawing on interviews with local stakeholders, our simulations\nincorporated varying degrees of communication, demographic data, and life\nvalues in the agent prompts. The results revealed that communication among\nagents improved collective reasoning, while the inclusion of demographic and\nlife values led to more distinct opinions. These findings highlight the\npotential application of AI in understanding complex social interactions and\ndecision-making processes, offering valuable insights for urban planning and\ncommunity engagement in diverse settings like Kendall Square.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11314v1"
    },
    {
        "title": "On the Limits of Information Spread by Memory-less Agents",
        "authors": [
            "Niccolò D'Archivio",
            "Robin Vacus"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We address the self-stabilizing bit-dissemination problem, designed to\ncapture the challenges of spreading information and reaching consensus among\nentities with minimal cognitive and communication capacities. Specifically, a\ngroup of $n$ agents is required to adopt the correct opinion, initially held by\na single informed individual, choosing from two possible opinions. In order to\nmake decisions, agents are restricted to observing the opinions of a few\nrandomly sampled agents, and lack the ability to communicate further and to\nidentify the informed individual. Additionally, agents cannot retain any\ninformation from one round to the next. According to a recent publication by\nBecchetti et al. in SODA (2024), a logarithmic convergence time without memory\nis achievable in the parallel setting (where agents are updated\nsimultaneously), as long as the number of samples is at least $\\Omega(\\sqrt{n\n\\log n})$. However, determining the minimal sample size for an efficient\nprotocol to exist remains a challenging open question. As a preliminary step\ntowards an answer, we establish the first lower bound for this problem in the\nparallel setting. Specifically, we demonstrate that it is impossible for any\nmemory-less protocol with constant sample size, to converge with high\nprobability in less than an almost-linear number of rounds. This lower bound\nholds even when agents are aware of both the exact value of $n$ and their own\nopinion, and encompasses various simple existing dynamics designed to achieve\nconsensus. Beyond the bit-dissemination problem, our result sheds light on the\nconvergence time of the ``minority'' dynamics, the counterpart of the\nwell-known majority rule, whose chaotic behavior is yet to be fully understood\ndespite the apparent simplicity of the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.11553v3"
    },
    {
        "title": "Aligning Individual and Collective Objectives in Multi-Agent Cooperation",
        "authors": [
            "Yang Li",
            "Wenhao Zhang",
            "Jianhong Wang",
            "Shao Zhang",
            "Yali Du",
            "Ying Wen",
            "Wei Pan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Among the research topics in multi-agent learning, mixed-motive cooperation\nis one of the most prominent challenges, primarily due to the mismatch between\nindividual and collective goals. The cutting-edge research is focused on\nincorporating domain knowledge into rewards and introducing additional\nmechanisms to incentivize cooperation. However, these approaches often face\nshortcomings such as the effort on manual design and the absence of theoretical\ngroundings. To close this gap, we model the mixed-motive game as a\ndifferentiable game for the ease of illuminating the learning dynamics towards\ncooperation. More detailed, we introduce a novel optimization method named\n\\textbf{\\textit{A}}ltruistic \\textbf{\\textit{G}}radient\n\\textbf{\\textit{A}}djustment (\\textbf{\\textit{AgA}}) that employs gradient\nadjustments to progressively align individual and collective objectives.\nFurthermore, we theoretically prove that AgA effectively attracts gradients to\nstable fixed points of the collective objective while considering individual\ninterests, and we validate these claims with empirical evidence. We evaluate\nthe effectiveness of our algorithm AgA through benchmark environments for\ntesting mixed-motive collaboration with small-scale agents such as the\ntwo-player public good game and the sequential social dilemma games, Cleanup\nand Harvest, as well as our self-developed large-scale environment in the game\nStarCraft II.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.12416v3"
    },
    {
        "title": "AgentScope: A Flexible yet Robust Multi-Agent Platform",
        "authors": [
            "Dawei Gao",
            "Zitao Li",
            "Xuchen Pan",
            "Weirui Kuang",
            "Zhijian Ma",
            "Bingchen Qian",
            "Fei Wei",
            "Wenhao Zhang",
            "Yuexiang Xie",
            "Daoyuan Chen",
            "Liuyi Yao",
            "Hongyi Peng",
            "Zeyu Zhang",
            "Lin Zhu",
            "Chen Cheng",
            "Hongzhu Shi",
            "Yaliang Li",
            "Bolin Ding",
            "Jingren Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the rapid advancement of Large Language Models (LLMs), significant\nprogress has been made in multi-agent applications. However, the complexities\nin coordinating agents' cooperation and LLMs' erratic performance pose notable\nchallenges in developing robust and efficient multi-agent applications. To\ntackle these challenges, we propose AgentScope, a developer-centric multi-agent\nplatform with message exchange as its core communication mechanism. The\nabundant syntactic tools, built-in agents and service functions, user-friendly\ninterfaces for application demonstration and utility monitor, zero-code\nprogramming workstation, and automatic prompt tuning mechanism significantly\nlower the barriers to both development and deployment. Towards robust and\nflexible multi-agent application, AgentScope provides both built-in and\ncustomizable fault tolerance mechanisms. At the same time, it is also armed\nwith system-level support for managing and utilizing multi-modal data, tools,\nand external knowledge. Additionally, we design an actor-based distribution\nframework, enabling easy conversion between local and distributed deployments\nand automatic parallel optimization without extra effort. With these features,\nAgentScope empowers developers to build applications that fully realize the\npotential of intelligent agents. We have released AgentScope at\nhttps://github.com/modelscope/agentscope, and hope AgentScope invites wider\nparticipation and innovation in this fast-moving field.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.14034v2"
    },
    {
        "title": "Open Ad Hoc Teamwork with Cooperative Game Theory",
        "authors": [
            "Jianhong Wang",
            "Yang Li",
            "Yuan Zhang",
            "Wei Pan",
            "Samuel Kaski"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Ad hoc teamwork poses a challenging problem, requiring the design of an agent\nto collaborate with teammates without prior coordination or joint training.\nOpen ad hoc teamwork (OAHT) further complicates this challenge by considering\nenvironments with a changing number of teammates, referred to as open teams.\nOne promising solution in practice to this problem is leveraging the\ngeneralizability of graph neural networks to handle an unrestricted number of\nagents with various agent-types, named graph-based policy learning (GPL).\nHowever, its joint Q-value representation over a coordination graph lacks\nconvincing explanations. In this paper, we establish a new theory to understand\nthe representation of the joint Q-value for OAHT and its learning paradigm,\nthrough the lens of cooperative game theory. Building on our theory, we propose\na novel algorithm named CIAO, based on GPL's framework, with additional\nprovable implementation tricks that can facilitate learning. The demos of\nexperimental results are available on https://sites.google.com/view/ciao2024,\nand the code of experiments is published on https://github.com/hsvgbkhgbv/CIAO.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15259v5"
    },
    {
        "title": "Shapley Value Based Multi-Agent Reinforcement Learning: Theory, Method\n  and Its Application to Energy Network",
        "authors": [
            "Jianhong Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent reinforcement learning is an area of rapid advancement in\nartificial intelligence and machine learning. One of the important questions to\nbe answered is how to conduct credit assignment in a multi-agent system. There\nhave been many schemes designed to conduct credit assignment by multi-agent\nreinforcement learning algorithms. Although these credit assignment schemes\nhave been proved useful in improving the performance of multi-agent\nreinforcement learning, most of them are designed heuristically without a\nrigorous theoretic basis and therefore infeasible to understand how agents\ncooperate. In this thesis, we aim at investigating the foundation of credit\nassignment in multi-agent reinforcement learning via cooperative game theory.\nWe first extend a game model called convex game and a payoff distribution\nscheme called Shapley value in cooperative game theory to Markov decision\nprocess, named as Markov convex game and Markov Shapley value respectively. We\nrepresent a global reward game as a Markov convex game under the grand\ncoalition. As a result, Markov Shapley value can be reasonably used as a credit\nassignment scheme in the global reward game. Markov Shapley value possesses the\nfollowing virtues: (i) efficiency; (ii) identifiability of dummy agents; (iii)\nreflecting the contribution and (iv) symmetry, which form the fair credit\nassignment. Based on Markov Shapley value, we propose three multi-agent\nreinforcement learning algorithms called SHAQ, SQDDPG and SMFPPO. Furthermore,\nwe extend Markov convex game to partial observability to deal with the\npartially observable problems, named as partially observable Markov convex\ngame. In application, we evaluate SQDDPG and SMFPPO on the real-world problem\nin energy networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15324v1"
    },
    {
        "title": "AgentLite: A Lightweight Library for Building and Advancing\n  Task-Oriented LLM Agent System",
        "authors": [
            "Zhiwei Liu",
            "Weiran Yao",
            "Jianguo Zhang",
            "Liangwei Yang",
            "Zuxin Liu",
            "Juntao Tan",
            "Prafulla K. Choubey",
            "Tian Lan",
            "Jason Wu",
            "Huan Wang",
            "Shelby Heinecke",
            "Caiming Xiong",
            "Silvio Savarese"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The booming success of LLMs initiates rapid development in LLM agents. Though\nthe foundation of an LLM agent is the generative model, it is critical to\ndevise the optimal reasoning strategies and agent architectures. Accordingly,\nLLM agent research advances from the simple chain-of-thought prompting to more\ncomplex ReAct and Reflection reasoning strategy; agent architecture also\nevolves from single agent generation to multi-agent conversation, as well as\nmulti-LLM multi-agent group chat. However, with the existing intricate\nframeworks and libraries, creating and evaluating new reasoning strategies and\nagent architectures has become a complex challenge, which hinders research\ninvestigation into LLM agents. Thus, we open-source a new AI agent library,\nAgentLite, which simplifies this process by offering a lightweight,\nuser-friendly platform for innovating LLM agent reasoning, architectures, and\napplications with ease. AgentLite is a task-oriented framework designed to\nenhance the ability of agents to break down tasks and facilitate the\ndevelopment of multi-agent systems. Furthermore, we introduce multiple\npractical applications developed with AgentLite to demonstrate its convenience\nand flexibility. Get started now at:\n\\url{https://github.com/SalesforceAIResearch/AgentLite}.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15538v1"
    },
    {
        "title": "Bike3S: A Tool for Bike Sharing Systems Simulation",
        "authors": [
            "Alberto Fernández",
            "Holger Billhardt",
            "Sascha Ossowski",
            "Óscar Sánchez"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Vehicle sharing systems are becoming increasingly popular. The effectiveness\nof such systems depends, among other factors, on different strategic and\noperational management decisions and policies, like the dimension of the fleet\nor the distribution of vehicles. It is of foremost importance to be able to\nanticipate and evaluate the potential effects of such strategies before they\ncan be successfully deployed. In this paper we present Bike3S, a simulator for\na station-based bike sharing system. The simulator performs semi-realistic\nsimulations of the operation of a bike sharing system and allows for evaluating\nand testing different management decisions and strategies. In particular, the\nsimulator has been designed to test different station capacities, station\ndistributions, and balancing strategies. The simulator carries out microscopic\nagent-based simulations, where users of different types can be defined that act\naccording to their individual goals and objectives which influences the overall\ndynamics of the whole system.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.16871v1"
    },
    {
        "title": "A Multi-Agent Model for Opinion Evolution under Cognitive Biases",
        "authors": [
            "Mário S. Alvim",
            "Artur Gaspar da Silva",
            "Sophia Knight",
            "Frank Valencia"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We generalize the DeGroot model for opinion dynamics to better capture\nrealistic social scenarios. We introduce a model where each agent has their own\nindividual cognitive biases. Society is represented as a directed graph whose\nedges indicate how much agents influence one another. Biases are represented as\nthe functions in the square region $[-1,1]^2$ and categorized into four\nsub-regions based on the potential reactions they may elicit in an agent during\ninstances of opinion disagreement. Under the assumption that each bias of every\nagent is a continuous function within the region of receptive but resistant\nreactions ($\\mathbf{R}$), we show that the society converges to a consensus if\nthe graph is strongly connected. Under the same assumption, we also establish\nthat the entire society converges to a unanimous opinion if and only if the\nsource components of the graph-namely, strongly connected components with no\nexternal influence-converge to that opinion. We illustrate that convergence is\nnot guaranteed for strongly connected graphs when biases are either\ndiscontinuous functions in $\\mathbf{R}$ or not included in $\\mathbf{R}$. We\nshowcase our model through a series of examples and simulations, offering\ninsights into how opinions form in social networks under cognitive biases.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.17615v1"
    },
    {
        "title": "A Heterogeneous Agent Model of Mortgage Servicing: An Income-based\n  Relief Analysis",
        "authors": [
            "Deepeka Garg",
            "Benjamin Patrick Evans",
            "Leo Ardon",
            "Annapoorani Lakshmi Narayanan",
            "Jared Vann",
            "Udari Madhushani",
            "Makada Henry-Nickie",
            "Sumitra Ganesh"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Mortgages account for the largest portion of household debt in the United\nStates, totaling around \\$12 trillion nationwide. In times of financial\nhardship, alleviating mortgage burdens is essential for supporting affected\nhouseholds. The mortgage servicing industry plays a vital role in offering this\nassistance, yet there has been limited research modelling the complex\nrelationship between households and servicers. To bridge this gap, we developed\nan agent-based model that explores household behavior and the effectiveness of\nrelief measures during financial distress. Our model represents households as\nadaptive learning agents with realistic financial attributes. These households\nexperience exogenous income shocks, which may influence their ability to make\nmortgage payments. Mortgage servicers provide relief options to these\nhouseholds, who then choose the most suitable relief based on their unique\nfinancial circumstances and individual preferences. We analyze the impact of\nvarious external shocks and the success of different mortgage relief strategies\non specific borrower subgroups. Through this analysis, we show that our model\ncan not only replicate real-world mortgage studies but also act as a tool for\nconducting a broad range of what-if scenario analyses. Our approach offers\nfine-grained insights that can inform the development of more effective and\ninclusive mortgage relief solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.17932v2"
    },
    {
        "title": "Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model\n  for Policy Making",
        "authors": [
            "Alba Aguilera",
            "Nieves Montes",
            "Georgina Curto",
            "Carles Sierra",
            "Nardine Osman"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In the last decades, there has been a deceleration in the rates of poverty\nreduction, suggesting that traditional redistributive approaches to poverty\nmitigation could be losing effectiveness, and alternative insights to advance\nthe number one UN Sustainable Development Goal are required. The\ncriminalization of poor people has been denounced by several NGOs, and an\nincreasing number of voices suggest that discrimination against the poor (a\nphenomenon known as \\emph{aporophobia}) could be an impediment to mitigating\npoverty. In this paper, we present the novel Aporophobia Agent-Based Model\n(AABM) to provide evidence of the correlation between aporophobia and poverty\ncomputationally. We present our use case built with real-world demographic data\nand poverty-mitigation public policies (either enforced or under parliamentary\ndiscussion) for the city of Barcelona. We classify policies as discriminatory\nor non-discriminatory against the poor, with the support of specialized NGOs,\nand we observe the results in the AABM in terms of the impact on wealth\ninequality. The simulation provides evidence of the relationship between\naporophobia and the increase of wealth inequality levels, paving the way for a\nnew generation of poverty reduction policies that act on discrimination and\ntackle poverty as a societal problem (not only a problem of the poor).\n",
        "pdf_link": "http://arxiv.org/pdf/2403.01600v1"
    },
    {
        "title": "Scalable Distributed Optimization of Multi-Dimensional Functions Despite\n  Byzantine Adversaries",
        "authors": [
            "Kananart Kuwaranancharoen",
            "Lei Xin",
            "Shreyas Sundaram"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The problem of distributed optimization requires a group of networked agents\nto compute a parameter that minimizes the average of their local cost\nfunctions. While there are a variety of distributed optimization algorithms\nthat can solve this problem, they are typically vulnerable to \"Byzantine\"\nagents that do not follow the algorithm. Recent attempts to address this issue\nfocus on single dimensional functions, or assume certain statistical properties\nof the functions at the agents. In this paper, we provide two resilient,\nscalable, distributed optimization algorithms for multi-dimensional functions.\nOur schemes involve two filters, (1) a distance-based filter and (2) a min-max\nfilter, which each remove neighborhood states that are extreme (defined\nprecisely in our algorithms) at each iteration. We show that these algorithms\ncan mitigate the impact of up to $F$ (unknown) Byzantine agents in the\nneighborhood of each regular agent. In particular, we show that if the network\ntopology satisfies certain conditions, all of the regular agents' states are\nguaranteed to converge to a bounded region that contains the minimizer of the\naverage of the regular agents' functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.06502v2"
    },
    {
        "title": "Ariadne and Theseus: Exploration and Rendezvous with Two Mobile Agents\n  in an Unknown Graph",
        "authors": [
            "Romain Cosson"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We investigate two fundamental problems in mobile computing: exploration and\nrendezvous, with two distinct mobile agents in an unknown graph. The agents may\ncommunicate by reading and writing information on whiteboards that are located\nat all nodes. They both move along one adjacent edge at every time-step. In the\nexploration problem, the agents start from the same arbitrary node and must\ntraverse all the edges. We present an algorithm achieving collective\nexploration in $m$ time-steps, where $m$ is the number of edges of the graph.\nThis improves over the guarantee of depth-first search, which requires $2m$\ntime-steps. In the rendezvous problem, the agents start from different nodes of\nthe graph and must meet as fast as possible. We present an algorithm\nguaranteeing rendezvous in at most $\\frac{3}{2}m$ time-steps. This improves\nover the so-called `wait for Mommy' algorithm which is based on depth-first\nsearch and which also requires $2m$ time-steps. Importantly, all our guarantees\nare derived from a more general asynchronous setting in which the speeds of the\nagents are controlled by an adversary at all times. Our guarantees generalize\nto weighted graphs, when replacing the number of edges $m$ with the sum of all\nedge lengths. We show that our guarantees are met with matching lower-bounds in\nthe asynchronous setting.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.07748v2"
    },
    {
        "title": "Online Multi-Agent Pickup and Delivery with Task Deadlines",
        "authors": [
            "Hiroya Makino",
            "Seigo Ito"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Managing delivery deadlines in automated warehouses and factories is crucial\nfor maintaining customer satisfaction and ensuring seamless production. This\nstudy introduces the problem of online multi-agent pickup and delivery with\ntask deadlines (MAPD-D), an advanced variant of the online MAPD problem\nincorporating delivery deadlines. In the MAPD problem, agents must manage a\ncontinuous stream of delivery tasks online. Tasks are added at any time. Agents\nmust complete their tasks while avoiding collisions with each other. MAPD-D\nintroduces a dynamic, deadline-driven approach that incorporates task\ndeadlines, challenging the conventional MAPD frameworks. To tackle MAPD-D, we\npropose a novel algorithm named deadline-aware token passing (D-TP). The D-TP\nalgorithm calculates pickup deadlines and assigns tasks while balancing\nexecution cost and deadline proximity. Additionally, we introduce the D-TP with\ntask swaps (D-TPTS) method to further reduce task tardiness, enhancing\nflexibility and efficiency through task-swapping strategies. Numerical\nexperiments were conducted in simulated warehouse environments to showcase the\neffectiveness of the proposed methods. Both D-TP and D-TPTS demonstrated\nsignificant reductions in task tardiness compared to existing methods. Our\nmethods contribute to efficient operations in automated warehouses and\nfactories with delivery deadlines.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.12377v3"
    },
    {
        "title": "Graph Neural Network-based Multi-agent Reinforcement Learning for\n  Resilient Distributed Coordination of Multi-Robot Systems",
        "authors": [
            "Anthony Goeckner",
            "Yueyuan Sui",
            "Nicolas Martinet",
            "Xinliang Li",
            "Qi Zhu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Existing multi-agent coordination techniques are often fragile and vulnerable\nto anomalies such as agent attrition and communication disturbances, which are\nquite common in the real-world deployment of systems like field robotics. To\nbetter prepare these systems for the real world, we present a graph neural\nnetwork (GNN)-based multi-agent reinforcement learning (MARL) method for\nresilient distributed coordination of a multi-robot system. Our method,\nMulti-Agent Graph Embedding-based Coordination (MAGEC), is trained using\nmulti-agent proximal policy optimization (PPO) and enables distributed\ncoordination around global objectives under agent attrition, partial\nobservability, and limited or disturbed communications. We use a multi-robot\npatrolling scenario to demonstrate our MAGEC method in a ROS 2-based simulator\nand then compare its performance with prior coordination approaches. Results\ndemonstrate that MAGEC outperforms existing methods in several experiments\ninvolving agent attrition and communication disturbance, and provides\ncompetitive results in scenarios without such anomalies.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.13093v1"
    },
    {
        "title": "Towards a Formalisation of Value-based Actions and Consequentialist\n  Ethics",
        "authors": [
            "Adam Wyner",
            "Tomasz Zurek",
            "DOrota Stachura-Zurek"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Agents act to bring about a state of the world that is more compatible with\ntheir personal or institutional values. To formalise this intuition, the paper\nproposes an action framework based on the STRIPS formalisation. Technically,\nthe contribution expresses actions in terms of Value-based Formal Reasoning\n(VFR), which provides a set of propositions derived from an Agent's value\nprofile and the Agent's assessment of propositions with respect to the profile.\nConceptually, the contribution provides a computational framework for a form of\nconsequentialist ethics which is satisficing, luralistic, act-based, and\npreferential.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.16719v1"
    },
    {
        "title": "GOV-REK: Governed Reward Engineering Kernels for Designing Robust\n  Multi-Agent Reinforcement Learning Systems",
        "authors": [
            "Ashish Rana",
            "Michael Oesterle",
            "Jannik Brinkmann"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  For multi-agent reinforcement learning systems (MARLS), the problem\nformulation generally involves investing massive reward engineering effort\nspecific to a given problem. However, this effort often cannot be translated to\nother problems; worse, it gets wasted when system dynamics change drastically.\nThis problem is further exacerbated in sparse reward scenarios, where a\nmeaningful heuristic can assist in the policy convergence task. We propose\nGOVerned Reward Engineering Kernels (GOV-REK), which dynamically assign reward\ndistributions to agents in MARLS during its learning stage. We also introduce\ngovernance kernels, which exploit the underlying structure in either state or\njoint action space for assigning meaningful agent reward distributions. During\nthe agent learning stage, it iteratively explores different reward distribution\nconfigurations with a Hyperband-like algorithm to learn ideal agent reward\nmodels in a problem-agnostic manner. Our experiments demonstrate that our\nmeaningful reward priors robustly jumpstart the learning process for\neffectively learning different MARL problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.01131v2"
    },
    {
        "title": "EnergAIze: Multi Agent Deep Deterministic Policy Gradient for Vehicle to\n  Grid Energy Management",
        "authors": [
            "Tiago Fonseca",
            "Luis Ferreira",
            "Bernardo Cabral",
            "Ricardo Severino",
            "Isabel Praca"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper investigates the increasing roles of Renewable Energy Sources\n(RES) and Electric Vehicles (EVs). While indicating a new era of sustainable\nenergy, these also introduce complex challenges, including the need to balance\nsupply and demand and smooth peak consumptions amidst rising EV adoption rates.\nAddressing these challenges requires innovative solutions such as Demand\nResponse (DR), energy flexibility management, Renewable Energy Communities\n(RECs), and more specifically for EVs, Vehicle-to-Grid (V2G). However, existing\nV2G approaches often fall short in real-world adaptability, global REC\noptimization with other flexible assets, scalability, and user engagement. To\nbridge this gap, this paper introduces EnergAIze, a Multi-Agent Reinforcement\nLearning (MARL) energy management framework, leveraging the Multi-Agent Deep\nDeterministic Policy Gradient (MADDPG) algorithm. EnergAIze enables\nuser-centric and multi-objective energy management by allowing each prosumer to\nselect from a range of personal management objectives, thus encouraging\nengagement. Additionally, it architects' data protection and ownership through\ndecentralized computing, where each prosumer can situate an energy management\noptimization node directly at their own dwelling. The local node not only\nmanages local energy assets but also fosters REC wide optimization. The\nefficacy of EnergAIze was evaluated through case studies employing the\nCityLearn simulation framework. These simulations were instrumental in\ndemonstrating EnergAIze's adeptness at implementing V2G technology within a REC\nand other energy assets. The results show reduction in peak loads, ramping,\ncarbon emissions, and electricity costs at the REC level while optimizing for\nindividual prosumers objectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02361v2"
    },
    {
        "title": "MARL-LNS: Cooperative Multi-agent Reinforcement Learning via Large\n  Neighborhoods Search",
        "authors": [
            "Weizhe Chen",
            "Sven Koenig",
            "Bistra Dilkina"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Cooperative multi-agent reinforcement learning (MARL) has been an\nincreasingly important research topic in the last half-decade because of its\ngreat potential for real-world applications. Because of the curse of\ndimensionality, the popular \"centralized training decentralized execution\"\nframework requires a long time in training, yet still cannot converge\nefficiently. In this paper, we propose a general training framework, MARL-LNS,\nto algorithmically address these issues by training on alternating subsets of\nagents using existing deep MARL algorithms as low-level trainers, while not\ninvolving any additional parameters to be trained. Based on this framework, we\nprovide three algorithm variants based on the framework: random large\nneighborhood search (RLNS), batch large neighborhood search (BLNS), and\nadaptive large neighborhood search (ALNS), which alternate the subsets of\nagents differently. We test our algorithms on both the StarCraft Multi-Agent\nChallenge and Google Research Football, showing that our algorithms can\nautomatically reduce at least 10% of training time while reaching the same\nfinal skill level as the original algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.03101v1"
    },
    {
        "title": "Kernel-based learning with guarantees for multi-agent applications",
        "authors": [
            "Krzysztof Kowalczyk",
            "Paweł Wachel",
            "Cristian R. Rojas"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper addresses a kernel-based learning problem for a network of agents\nlocally observing a latent multidimensional, nonlinear phenomenon in a noisy\nenvironment. We propose a learning algorithm that requires only mild a priori\nknowledge about the phenomenon under investigation and delivers a model with\ncorresponding non-asymptotic high probability error bounds. Both non-asymptotic\nanalysis of the method and numerical simulation results are presented and\ndiscussed in the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.09708v1"
    },
    {
        "title": "A biologically inspired computational trust model for open multi-agent\n  systems which is resilient to trustor population changes",
        "authors": [
            "Zoi Lygizou",
            "Dimitris Kalles"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Current trust and reputation models continue to have significant limitations,\nsuch as the inability to deal with agents constantly entering or exiting open\nmulti-agent systems (open MAS), as well as continuously changing behaviors. Our\nstudy is based on CA, a previously proposed decentralized computational trust\nmodel from the trustee's point of view, inspired by synaptic plasticity and the\nformation of assemblies in the human brain. It is designed to meet the\nrequirements of highly dynamic and open MAS, and its main difference with most\nconventional trust and reputation models is that the trustor does not select a\ntrustee to delegate a task; instead, the trustee determines whether it is\nqualified to successfully execute it. We ran a series of simulations to compare\nCA model to FIRE, a well-established, decentralized trust and reputation model\nfor open MAS under conditions of continuous trustee and trustor population\nreplacement, as well as continuous change of trustees' abilities to perform\ntasks. The main finding is that FIRE is superior to changes in the trustee\npopulation, whereas CA is resilient to the trustor population changes. When the\ntrustees switch performance profiles FIRE clearly outperforms despite the fact\nthat both models' performances are significantly impacted by this environmental\nchange. Findings lead us to conclude that learning to use the appropriate trust\nmodel, according to the dynamic conditions in effect could maximize the\ntrustor's benefits.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.10014v1"
    },
    {
        "title": "Towards Multi-agent Reinforcement Learning based Traffic Signal Control\n  through Spatio-temporal Hypergraphs",
        "authors": [
            "Kang Wang",
            "Zhishu Shen",
            "Zhen Lei",
            "Tiehua Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Traffic signal control systems (TSCSs) are integral to intelligent traffic\nmanagement, fostering efficient vehicle flow. Traditional approaches often\nsimplify road networks into standard graphs, which results in a failure to\nconsider the dynamic nature of traffic data at neighboring intersections,\nthereby neglecting higher-order interconnections necessary for real-time\ncontrol. To address this, we propose a novel TSCS framework to realize\nintelligent traffic control. This framework collaborates with multiple\nneighboring edge computing servers to collect traffic information across the\nroad network. To elevate the efficiency of traffic signal control, we have\ncrafted a multi-agent soft actor-critic (MA-SAC) reinforcement learning\nalgorithm. Within this algorithm, individual agents are deployed at each\nintersection with a mandate to optimize traffic flow across the entire road\nnetwork collectively. Furthermore, we introduce hypergraph learning into the\ncritic network of MA-SAC to enable the spatio-temporal interactions from\nmultiple intersections in the road network. This method fuses hypergraph and\nspatio-temporal graph structures to encode traffic data and capture the complex\nspatial and temporal correlations between multiple intersections. Our empirical\nevaluation, tested on varied datasets, demonstrates the superiority of our\nframework in minimizing average vehicle travel times and sustaining\nhigh-throughput performance. This work facilitates the development of more\nintelligent and reactive urban traffic management solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.11014v1"
    },
    {
        "title": "A Stochastic Geo-spatiotemporal Bipartite Network to Optimize GCOOS\n  Sensor Placement Strategies",
        "authors": [
            "Ted Edward Holmberg",
            "Elias Ioup",
            "Mahdi Abdelguerfi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper proposes two new measures applicable in a spatial bipartite\nnetwork model: coverage and coverage robustness. The bipartite network must\nconsist of observer nodes, observable nodes, and edges that connect observer\nnodes to observable nodes. The coverage and coverage robustness scores evaluate\nthe effectiveness of the observer node placements. This measure is beneficial\nfor stochastic data as it may be coupled with Monte Carlo simulations to\nidentify optimal placements for new observer nodes. In this paper, we construct\na Geo-SpatioTemporal Bipartite Network (GSTBN) within the stochastic and\ndynamical environment of the Gulf of Mexico. This GSTBN consists of GCOOS\nsensor nodes and HYCOM Region of Interest (RoI) event nodes. The goal is to\nidentify optimal placements to expand GCOOS to improve the forecasting outcomes\nby the HYCOM ocean prediction model.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.14357v2"
    },
    {
        "title": "From Space-Time to Space-Order: Directly Planning a Temporal Planning\n  Graph by Redefining CBS",
        "authors": [
            "Yu Wu",
            "Rishi Veerapaneni",
            "Jiaoyang Li",
            "Maxim Likhachev"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The majority of multi-agent path finding (MAPF) methods compute\ncollision-free space-time paths which require agents to be at a specific\nlocation at a specific discretized timestep. However, executing these\nspace-time paths directly on robotic systems is infeasible due to real-time\nexecution differences (e.g. delays) which can lead to collisions. To combat\nthis, current methods translate the space-time paths into a temporal plan graph\n(TPG) that only requires that agents observe the order in which they navigate\nthrough locations where their paths cross. However, planning space-time paths\nand then post-processing them into a TPG does not reduce the required\nagent-to-agent coordination, which is fixed once the space-time paths are\ncomputed. To that end, we propose a novel algorithm Space-Order CBS that can\ndirectly plan a TPG and explicitly minimize coordination. Our main theoretical\ninsight is our novel perspective on viewing a TPG as a set of space-visitation\norder paths where agents visit locations in relative orders (e.g. 1st vs 2nd)\nas opposed to specific timesteps. We redefine unique conflicts and constraints\nfor adapting CBS for space-order planning. We experimentally validate how\nSpace-Order CBS can return TPGs which significantly reduce coordination, thus\nsubsequently reducing the amount of agent-agent communication and leading to\nmore robustness to delays during execution.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.15137v1"
    },
    {
        "title": "Scaling Lifelong Multi-Agent Path Finding to More Realistic Settings:\n  Research Challenges and Opportunities",
        "authors": [
            "He Jiang",
            "Yulun Zhang",
            "Rishi Veerapaneni",
            "Jiaoyang Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Path Finding (MAPF) is the problem of moving multiple agents from\nstarts to goals without collisions. Lifelong MAPF (LMAPF) extends MAPF by\ncontinuously assigning new goals to agents. We present our winning approach to\nthe 2023 League of Robot Runners LMAPF competition, which leads us to several\ninteresting research challenges and future directions. In this paper, we\noutline three main research challenges. The first challenge is to search for\nhigh-quality LMAPF solutions within a limited planning time (e.g., 1s per step)\nfor a large number of agents (e.g., 10,000) or extremely high agent density\n(e.g., 97.7%). We present future directions such as developing more competitive\nrule-based and anytime MAPF algorithms and parallelizing state-of-the-art MAPF\nalgorithms. The second challenge is to alleviate congestion and the effect of\nmyopic behaviors in LMAPF algorithms. We present future directions, such as\ndeveloping moving guidance and traffic rules to reduce congestion,\nincorporating future prediction and real-time search, and determining the\noptimal agent number. The third challenge is to bridge the gaps between the\nLMAPF models used in the literature and real-world applications. We present\nfuture directions, such as dealing with more realistic kinodynamic models,\nexecution uncertainty, and evolving systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.16162v1"
    },
    {
        "title": "Verco: Learning Coordinated Verbal Communication for Multi-agent\n  Reinforcement Learning",
        "authors": [
            "Dapeng Li",
            "Hang Dong",
            "Lu Wang",
            "Bo Qiao",
            "Si Qin",
            "Qingwei Lin",
            "Dongmei Zhang",
            "Qi Zhang",
            "Zhiwei Xu",
            "Bin Zhang",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In recent years, multi-agent reinforcement learning algorithms have made\nsignificant advancements in diverse gaming environments, leading to increased\ninterest in the broader application of such techniques. To address the\nprevalent challenge of partial observability, communication-based algorithms\nhave improved cooperative performance through the sharing of numerical\nembedding between agents. However, the understanding of the formation of\ncollaborative mechanisms is still very limited, making designing a\nhuman-understandable communication mechanism a valuable problem to address. In\nthis paper, we propose a novel multi-agent reinforcement learning algorithm\nthat embeds large language models into agents, endowing them with the ability\nto generate human-understandable verbal communication. The entire framework has\na message module and an action module. The message module is responsible for\ngenerating and sending verbal messages to other agents, effectively enhancing\ninformation sharing among agents. To further enhance the message module, we\nemploy a teacher model to generate message labels from the global view and\nupdate the student model through Supervised Fine-Tuning (SFT). The action\nmodule receives messages from other agents and selects actions based on current\nlocal observations and received messages. Experiments conducted on the\nOvercooked game demonstrate our method significantly enhances the learning\nefficiency and performance of existing methods, while also providing an\ninterpretable tool for humans to understand the process of multi-agent\ncooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.17780v1"
    },
    {
        "title": "Mitigating Side Effects in Multi-Agent Systems Using Blame Assignment",
        "authors": [
            "Pulkit Rustagi",
            "Sandhya Saisubramanian"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  When independently trained or designed robots are deployed in a shared\nenvironment, their combined actions can lead to unintended negative side\neffects (NSEs). To ensure safe and efficient operation, robots must optimize\ntask performance while minimizing the penalties associated with NSEs, balancing\nindividual objectives with collective impact. We model the problem of\nmitigating NSEs in a cooperative multi-agent system as a bi-objective\nlexicographic decentralized Markov decision process. We assume independence of\ntransitions and rewards with respect to the robots' tasks, but the joint NSE\npenalty creates a form of dependence in this setting. To improve scalability,\nthe joint NSE penalty is decomposed into individual penalties for each robot\nusing credit assignment, which facilitates decentralized policy computation. We\nempirically demonstrate, using mobile robots and in simulation, the\neffectiveness and scalability of our approach in mitigating NSEs.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.04702v3"
    },
    {
        "title": "Robust Reward Placement under Uncertainty",
        "authors": [
            "Petros Petsinis",
            "Kaichen Zhang",
            "Andreas Pavlogiannis",
            "Jingbo Zhou",
            "Panagiotis Karras"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We consider a problem of placing generators of rewards to be collected by\nrandomly moving agents in a network. In many settings, the precise mobility\npattern may be one of several possible, based on parameters outside our\ncontrol, such as weather conditions. The placement should be robust to this\nuncertainty, to gain a competent total reward across possible networks. To\nstudy such scenarios, we introduce the Robust Reward Placement problem (RRP).\nAgents move randomly by a Markovian Mobility Model with a predetermined set of\nlocations whose connectivity is chosen adversarially from a known set $\\Pi$ of\ncandidates. We aim to select a set of reward states within a budget that\nmaximizes the minimum ratio, among all candidates in $\\Pi$, of the collected\ntotal reward over the optimal collectable reward under the same candidate. We\nprove that RRP is NP-hard and inapproximable, and develop $\\Psi$-Saturate, a\npseudo-polynomial time algorithm that achieves an $\\epsilon$-additive\napproximation by exceeding the budget constraint by a factor that scales as\n$O(\\ln |\\Pi|/\\epsilon)$. In addition, we present several heuristics, most\nprominently one inspired by a dynamic programming algorithm for the max-min 0-1\nKNAPSACK problem. We corroborate our theoretical analysis with an experimental\nevaluation on synthetic and real data.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.05433v4"
    },
    {
        "title": "Pragmatic Communication for Remote Control of Finite-State Markov\n  Processes",
        "authors": [
            "Pietro Talli",
            "Edoardo David Santi",
            "Federico Chiariotti",
            "Touraj Soleymani",
            "Federico Mason",
            "Andrea Zanella",
            "Deniz Gündüz"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Pragmatic or goal-oriented communication can optimize communication decisions\nbeyond the reliable transmission of data, instead aiming at directly affecting\napplication performance with the minimum channel utilization. In this paper, we\ndevelop a general theoretical framework for the remote control of finite-state\nMarkov processes, using pragmatic communication over a costly zero-delay\ncommunication channel. To that end, we model a cyber-physical system composed\nof an encoder, which observes and transmits the states of a process in\nreal-time, and a decoder, which receives that information and controls the\nbehavior of the process. The encoder and the decoder should cooperatively\noptimize the trade-off between the control performance (i.e., reward) and the\ncommunication cost (i.e., channel use). This scenario underscores a pragmatic\n(i.e., goal-oriented) communication problem, where the purpose is to convey\nonly the data that is most valuable for the underlying task, taking into\naccount the state of the decoder (hence, the pragmatic aspect). We investigate\ntwo different decision-making architectures: in pull-based remote control, the\ndecoder is the only decision-maker, while in push-based remote control, the\nencoder and the decoder constitute two independent decision-makers, leading to\na multi-agent scenario. We propose three algorithms to optimize our system\n(i.e., design the encoder and the decoder policies), discuss the optimality\nguarantees ofs the algorithms, and shed light on their computational complexity\nand fundamental limits.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.10672v1"
    },
    {
        "title": "Review on modeling the societal impact of infrastructure disruptions due\n  to disasters",
        "authors": [
            "Yongsheng Yang",
            "Huan Liu",
            "Ali Mostafavi",
            "Hirokazu Tatano"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Infrastructure systems play a critical role in providing essential products\nand services for the functioning of modern society; however, they are\nvulnerable to disasters and their service disruptions can cause severe societal\nimpacts. To protect infrastructure from disasters and reduce potential impacts,\ngreat achievements have been made in modeling interdependent infrastructure\nsystems in past decades. In recent years, scholars have gradually shifted their\nresearch focus to understanding and modeling societal impacts of disruptions\nconsidering the fact that infrastructure systems are critical because of their\nrole in societal functioning, especially under situations of modern societies.\nExploring how infrastructure disruptions impair society to enhance resilient\ncity has become a key field of study. By comprehensively reviewing relevant\nstudies, this paper demonstrated the definition and types of societal impact of\ninfrastructure disruptions, and summarized the modeling approaches into four\ntypes: extended infrastructure modeling approaches, empirical approaches,\nagent-based approaches, and big data-driven approaches. For each approach, this\npaper organized relevant literature in terms of modeling ideas, advantages, and\ndisadvantages. Furthermore, the four approaches were compared according to\nseveral criteria, including the input data, types of societal impact, and\napplication scope. Finally, this paper illustrated the challenges and future\nresearch directions in the field.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.12732v1"
    },
    {
        "title": "Mimicry and the Emergence of Cooperative Communication",
        "authors": [
            "Dylan Cope",
            "Peter McBurney"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In many situations, communication between agents is a critical component of\ncooperative multi-agent systems, however, it can be difficult to learn or\nevolve. In this paper, we investigate a simple way in which the emergence of\ncommunication may be facilitated. Namely, we explore the effects of when agents\ncan mimic preexisting, externally generated useful signals. The key idea here\nis that these signals incentivise listeners to develop positive responses, that\ncan then also be invoked by speakers mimicking those signals. This\ninvestigation starts with formalising this problem, and demonstrating that this\nform of mimicry changes optimisation dynamics and may provide the opportunity\nto escape non-communicative local optima. We then explore the problem\nempirically with a simulation in which spatially situated agents must\ncommunicate to collect resources. Our results show that both evolutionary\noptimisation and reinforcement learning may benefit from this intervention.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.16622v1"
    },
    {
        "title": "CoSLight: Co-optimizing Collaborator Selection and Decision-making to\n  Enhance Traffic Signal Control",
        "authors": [
            "Jingqing Ruan",
            "Ziyue Li",
            "Hua Wei",
            "Haoyuan Jiang",
            "Jiaming Lu",
            "Xuantang Xiong",
            "Hangyu Mao",
            "Rui Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Effective multi-intersection collaboration is pivotal for\nreinforcement-learning-based traffic signal control to alleviate congestion.\nExisting work mainly chooses neighboring intersections as collaborators.\nHowever, quite an amount of congestion, even some wide-range congestion, is\ncaused by non-neighbors failing to collaborate. To address these issues, we\npropose to separate the collaborator selection as a second policy to be\nlearned, concurrently being updated with the original signal-controlling\npolicy. Specifically, the selection policy in real-time adaptively selects the\nbest teammates according to phase- and intersection-level features. Empirical\nresults on both synthetic and real-world datasets provide robust validation for\nthe superiority of our approach, offering significant improvements over\nexisting state-of-the-art methods. The code is available at\nhttps://github.com/bonaldli/CoSLight.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.17152v3"
    },
    {
        "title": "Cognitive Insights and Stable Coalition Matching for Fostering\n  Multi-Agent Cooperation",
        "authors": [
            "Jiaqi Shao",
            "Tianjun Yuan",
            "Tao Lin",
            "Xuanyu Cao",
            "Bing Luo"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Cognitive abilities, such as Theory of Mind (ToM), play a vital role in\nfacilitating cooperation in human social interactions. However, our study\nreveals that agents with higher ToM abilities may not necessarily exhibit\nbetter cooperative behavior compared to those with lower ToM abilities. To\naddress this challenge, we propose a novel matching coalition mechanism that\nleverages the strengths of agents with different ToM levels by explicitly\nconsidering belief alignment and specialized abilities when forming coalitions.\nOur proposed matching algorithm seeks to find stable coalitions that maximize\nthe potential for cooperative behavior and ensure long-term viability. By\nincorporating cognitive insights into the design of multi-agent systems, our\nwork demonstrates the potential of leveraging ToM to create more sophisticated\nand human-like coordination strategies that foster cooperation and improve\noverall system performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.18044v1"
    },
    {
        "title": "Distributed Online Planning for Min-Max Problems in Networked Markov\n  Games",
        "authors": [
            "Alexandros E. Tzikas",
            "Jinkyoo Park",
            "Mykel J. Kochenderfer",
            "Ross E. Allen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Min-max problems are important in multi-agent sequential decision-making\nbecause they improve the performance of the worst-performing agent in the\nnetwork. However, solving the multi-agent min-max problem is challenging. We\npropose a modular, distributed, online planning-based algorithm that is able to\napproximate the solution of the min-max objective in networked Markov games,\nassuming that the agents communicate within a network topology and the\ntransition and reward functions are neighborhood-dependent. This set-up is\nencountered in the multi-robot setting. Our method consists of two phases at\nevery planning step. In the first phase, each agent obtains sample returns\nbased on its local reward function, by performing online planning. Using the\nsamples from online planning, each agent constructs a concave approximation of\nits underlying local return as a function of only the action of its\nneighborhood at the next planning step. In the second phase, the agents deploy\na distributed optimization framework that converges to the optimal immediate\nnext action for each agent, based on the function approximations of the first\nphase. We demonstrate our algorithm's performance through formation control\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.19570v1"
    },
    {
        "title": "Fast and Robust Flocking of Protesters on Street Networks",
        "authors": [
            "Guillaume Moinard",
            "Matthieu Latapy"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We propose a simple model of protesters scattered throughout a city who want\nto gather into large and mobile groups. This model relies on random walkers on\na street network that follow tactics built from a set of basic rules. Our goal\nis to identify the most important rules for fast and robust flocking of\nwalkers. We explore a wide set of tactics and show the central importance of a\nspecific rule based on alignment. Other rules alone perform poorly, but our\nexperiments show that combining alignment with them enhances flocking, and that\nobtained groups are then remarkably robust.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01101v1"
    },
    {
        "title": "Teams of LLM Agents can Exploit Zero-Day Vulnerabilities",
        "authors": [
            "Richard Fang",
            "Rohan Bindu",
            "Akul Gupta",
            "Qiusi Zhan",
            "Daniel Kang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  LLM agents have become increasingly sophisticated, especially in the realm of\ncybersecurity. Researchers have shown that LLM agents can exploit real-world\nvulnerabilities when given a description of the vulnerability and toy\ncapture-the-flag problems. However, these agents still perform poorly on\nreal-world vulnerabilities that are unknown to the agent ahead of time\n(zero-day vulnerabilities).\n  In this work, we show that teams of LLM agents can exploit real-world,\nzero-day vulnerabilities. Prior agents struggle with exploring many different\nvulnerabilities and long-range planning when used alone. To resolve this, we\nintroduce HPTSA, a system of agents with a planning agent that can launch\nsubagents. The planning agent explores the system and determines which\nsubagents to call, resolving long-term planning issues when trying different\nvulnerabilities. We construct a benchmark of 15 real-world vulnerabilities and\nshow that our team of agents improve over prior work by up to 4.5$\\times$.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01637v1"
    },
    {
        "title": "Reciprocal Reward Influence Encourages Cooperation From Self-Interested\n  Agents",
        "authors": [
            "John L. Zhou",
            "Weizhe Hong",
            "Jonathan C. Kao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Cooperation between self-interested individuals is a widespread phenomenon in\nthe natural world, but remains elusive in interactions between artificially\nintelligent agents. Instead, naive reinforcement learning algorithms typically\nconverge to Pareto-dominated outcomes in even the simplest of social dilemmas.\nAn emerging literature on opponent shaping has demonstrated the ability to\nreach prosocial outcomes by influencing the learning of other agents. However,\nsuch methods differentiate through the learning step of other agents or\noptimize for meta-game dynamics, which rely on privileged access to opponents'\nlearning algorithms or exponential sample complexity, respectively. To provide\na learning rule-agnostic and sample-efficient alternative, we introduce\nReciprocators, reinforcement learning agents which are intrinsically motivated\nto reciprocate the influence of opponents' actions on their returns. This\napproach seeks to modify other agents' $Q$-values by increasing their return\nfollowing beneficial actions (with respect to the Reciprocator) and decreasing\nit after detrimental actions, guiding them towards mutually beneficial actions\nwithout directly differentiating through a model of their policy. We show that\nReciprocators can be used to promote cooperation in temporally extended social\ndilemmas during simultaneous learning. Our code is available at\nhttps://github.com/johnlyzhou/reciprocator/.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01641v3"
    },
    {
        "title": "Large Language Model-Enabled Multi-Agent Manufacturing Systems",
        "authors": [
            "Jonghan Lim",
            "Birgit Vogel-Heuser",
            "Ilya Kovalenko"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Traditional manufacturing faces challenges adapting to dynamic environments\nand quickly responding to manufacturing changes. The use of multi-agent systems\nhas improved adaptability and coordination but requires further advancements in\nrapid human instruction comprehension, operational adaptability, and\ncoordination through natural language integration. Large language models like\nGPT-3.5 and GPT-4 enhance multi-agent manufacturing systems by enabling agents\nto communicate in natural language and interpret human instructions for\ndecision-making. This research introduces a novel framework where large\nlanguage models enhance the capabilities of agents in manufacturing, making\nthem more adaptable, and capable of processing context-specific instructions. A\ncase study demonstrates the practical application of this framework, showing\nhow agents can effectively communicate, understand tasks, and execute\nmanufacturing processes, including precise G-code allocation among agents. The\nfindings highlight the importance of continuous large language model\nintegration into multi-agent manufacturing systems and the development of\nsophisticated agent communication protocols for a more flexible manufacturing\nsystem.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.01893v2"
    },
    {
        "title": "Mini Honor of Kings: A Lightweight Environment for Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Lin Liu",
            "Jian Zhao",
            "Cheng Hu",
            "Zhengtao Cao",
            "Youpeng Zhao",
            "Zhenbin Ye",
            "Meng Meng",
            "Wenjun Wang",
            "Zhaofeng He",
            "Houqiang Li",
            "Xia Lin",
            "Lanxiao Huang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Games are widely used as research environments for multi-agent reinforcement\nlearning (MARL), but they pose three significant challenges: limited\ncustomization, high computational demands, and oversimplification. To address\nthese issues, we introduce the first publicly available map editor for the\npopular mobile game Honor of Kings and design a lightweight environment, Mini\nHonor of Kings (Mini HoK), for researchers to conduct experiments. Mini HoK is\nhighly efficient, allowing experiments to be run on personal PCs or laptops\nwhile still presenting sufficient challenges for existing MARL algorithms. We\nhave tested our environment on common MARL algorithms and demonstrated that\nthese algorithms have yet to find optimal solutions within this environment.\nThis facilitates the dissemination and advancement of MARL methods within the\nresearch community. Additionally, we hope that more researchers will leverage\nthe Honor of Kings map editor to develop innovative and scientifically valuable\nnew maps. Our code and user manual are available at:\nhttps://github.com/tencent-ailab/mini-hok.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.03978v2"
    },
    {
        "title": "Active Scout: Multi-Target Tracking Using Neural Radiance Fields in\n  Dense Urban Environments",
        "authors": [
            "Christopher D. Hsu",
            "Pratik Chaudhari"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We study pursuit-evasion games in highly occluded urban environments, e.g.\ntall buildings in a city, where a scout (quadrotor) tracks multiple dynamic\ntargets on the ground. We show that we can build a neural radiance field (NeRF)\nrepresentation of the city -- online -- using RGB and depth images from\ndifferent vantage points. This representation is used to calculate the\ninformation gain to both explore unknown parts of the city and track the\ntargets -- thereby giving a completely first-principles approach to actively\ntracking dynamic targets. We demonstrate, using a custom-built simulator using\nOpen Street Maps data of Philadelphia and New York City, that we can explore\nand locate 20 stationary targets within 300 steps. This is slower than a greedy\nbaseline, which does not use active perception. But for dynamic targets that\nactively hide behind occlusions, we show that our approach maintains, at worst,\na tracking error of 200m; the greedy baseline can have a tracking error as\nlarge as 600m. We observe a number of interesting properties in the scout's\npolicies, e.g., it switches its attention to track a different target\nperiodically, as the quality of the NeRF representation improves over time, the\nscout also becomes better in terms of target tracking.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.07431v2"
    },
    {
        "title": "Tree Search for Simultaneous Move Games via Equilibrium Approximation",
        "authors": [
            "Ryan Yu",
            "Alex Olshevsky",
            "Peter Chin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Neural network supported tree-search has shown strong results in a variety of\nperfect information multi-agent tasks. However, the performance of these\nmethods on partial information games has generally been below competing\napproaches. Here we study the class of simultaneous-move games, which are a\nsubclass of partial information games which are most similar to perfect\ninformation games: both agents know the game state with the exception of the\nopponent's move, which is revealed only after each agent makes its own move.\nSimultaneous move games include popular benchmarks such as Google Research\nFootball and Starcraft.\n  In this study we answer the question: can we take tree search algorithms\ntrained through self-play from perfect information settings and adapt them to\nsimultaneous move games without significant loss of performance? We answer this\nquestion by deriving a practical method that attempts to approximate a coarse\ncorrelated equilibrium as a subroutine within a tree search. Our algorithm\nworks on cooperative, competitive, and mixed tasks. Our results are better than\nthe current best MARL algorithms on a wide range of accepted baseline\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.10411v1"
    },
    {
        "title": "Tactical Game-theoretic Decision-making with Homotopy Class Constraints",
        "authors": [
            "Michael Khayyat",
            "Alessandro Zanardi",
            "Stefano Arrigoni",
            "Francesco Braghin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We propose a tactical homotopy-aware decision-making framework for\ngame-theoretic motion planning in urban environments. We model urban driving as\na generalized Nash equilibrium problem and employ a mixed-integer approach to\ntame the combinatorial aspect of motion planning. More specifically, by\nutilizing homotopy classes, we partition the high-dimensional solution space\ninto finite, well-defined subregions. Each subregion (homotopy) corresponds to\na high-level tactical decision, such as the passing order between pairs of\nplayers. The proposed formulation allows to find global optimal Nash equilibria\nin a computationally tractable manner by solving a mixed-integer quadratic\nprogram. Each homotopy decision is represented by a binary variable that\nactivates different sets of linear collision avoidance constraints. This extra\nhomotopic constraint allows to find solutions in a more efficient way (on a\nroundabout scenario on average 5-times faster). We experimentally validate the\nproposed approach on scenarios taken from the rounD dataset. Simulation-based\ntesting in receding horizon fashion demonstrates the capability of the\nframework in achieving globally optimal solutions while yielding a 78% average\ndecrease in the computational time with respect to an implementation without\nthe homotopic constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.13656v1"
    },
    {
        "title": "Vahana.jl -- A framework (not only) for large-scale agent-based models",
        "authors": [
            "Steffen Fürst",
            "Tim Conrad",
            "Carlo Jaeger",
            "Sarah Wolf"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Agent-based models (ABMs) offer a powerful framework for understanding\ncomplex systems. However, their computational demands often become a\nsignificant barrier as the number of agents and complexity of the simulation\nincrease. Traditional ABM platforms often struggle to fully exploit modern\ncomputing resources, hindering the development of large-scale simulations. This\npaper presents Vahana.jl, a high performance computing open source framework\nthat aims to address these limitations. Building on the formalism of\nsynchronous graph dynamical systems, Vahana.jl is especially well suited for\nmodels with a focus on (social) networks. The framework seamlessly supports\ndistribution across multiple compute nodes, enabling simulations that would\notherwise be beyond the capabilities of a single machine. Implemented in Julia,\nVahana.jl leverages the interactive Read-Eval-Print Loop (REPL) environment,\nfacilitating rapid model development and experimentation.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14441v1"
    },
    {
        "title": "Towards General Negotiation Strategies with End-to-End Reinforcement\n  Learning",
        "authors": [
            "Bram M. Renting",
            "Thomas M. Moerland",
            "Holger H. Hoos",
            "Catholijn M. Jonker"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The research field of automated negotiation has a long history of designing\nagents that can negotiate with other agents. Such negotiation strategies are\ntraditionally based on manual design and heuristics. More recently,\nreinforcement learning approaches have also been used to train agents to\nnegotiate. However, negotiation problems are diverse, causing observation and\naction dimensions to change, which cannot be handled by default linear policy\nnetworks. Previous work on this topic has circumvented this issue either by\nfixing the negotiation problem, causing policies to be non-transferable between\nnegotiation problems or by abstracting the observations and actions into\nfixed-size representations, causing loss of information and expressiveness due\nto feature design. We developed an end-to-end reinforcement learning method for\ndiverse negotiation problems by representing observations and actions as a\ngraph and applying graph neural networks in the policy. With empirical\nevaluations, we show that our method is effective and that we can learn to\nnegotiate with other agents on never-before-seen negotiation problems. Our\nresult opens up new opportunities for reinforcement learning in negotiation\nagents.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.15096v1"
    },
    {
        "title": "Towards Hypermedia Environments for Adaptive Coordination in Industrial\n  Automation",
        "authors": [
            "Ganesh Ramanathan",
            "Simon Mayer",
            "Andrei Ciortea"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Electromechanical systems manage physical processes through a network of\ninter-connected components. Today, programming the interactions required for\ncoordinating these components is largely a manual process. This process is\ntime-consuming and requires manual adaptation when system features change. To\novercome this issue, we use autonomous software agents that process semantic\ndescriptions of the system to determine coordination requirements and\nconstraints; on this basis, they then interact with one another to control the\nsystem in a decentralized and coordinated manner.Our core insight is that\ncoordination requirements between individual components are, ultimately,\nlargely due to underlying physical interdependencies between the components,\nwhich can be (and, in many cases, already are) semantically modeled in\nautomation projects. Agents then use hypermedia to discover, at run time, the\nplans and protocols required for enacting the coordination. A key novelty of\nour approach is the use of hypermedia-driven interaction: it reduces coupling\nin the system and enables its run-time adaptation as features change.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.17816v1"
    },
    {
        "title": "Multi-agent Cooperative Games Using Belief Map Assisted Training",
        "authors": [
            "Qinwei Huang",
            "Chen Luo",
            "Alex B. Wu",
            "Simon Khan",
            "Hai Li",
            "Qinru Qiu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In a multi-agent system, agents share their local observations to gain global\nsituational awareness for decision making and collaboration using a message\npassing system. When to send a message, how to encode a message, and how to\nleverage the received messages directly affect the effectiveness of the\ncollaboration among agents. When training a multi-agent cooperative game using\nreinforcement learning (RL), the message passing system needs to be optimized\ntogether with the agent policies. This consequently increases the model's\ncomplexity and poses significant challenges to the convergence and performance\nof learning. To address this issue, we propose the Belief-map Assisted\nMulti-agent System (BAMS), which leverages a neuro-symbolic belief map to\nenhance training. The belief map decodes the agent's hidden state to provide a\nsymbolic representation of the agent's understanding of the environment and\nother agent's status. The simplicity of symbolic representation allows the\ngathering and comparison of the ground truth information with the belief, which\nprovides an additional channel of feedback for the learning. Compared to the\nsporadic and delayed feedback coming from the reward in RL, the feedback from\nthe belief map is more consistent and reliable. Agents using BAMS can learn a\nmore effective message passing network to better understand each other,\nresulting in better performance in a cooperative predator and prey game with\nvarying levels of map complexity and compare it to previous multi-agent message\npassing models. The simulation results showed that BAMS reduced training epochs\nby 66\\%, and agents who apply the BAMS model completed the game with 34.62\\%\nfewer steps on average.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.19477v1"
    },
    {
        "title": "BMW Agents -- A Framework For Task Automation Through Multi-Agent\n  Collaboration",
        "authors": [
            "Noel Crawford",
            "Edward B. Duffy",
            "Iman Evazzade",
            "Torsten Foehr",
            "Gregory Robbins",
            "Debbrata Kumar Saha",
            "Jiya Varma",
            "Marcin Ziolkowski"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Autonomous agents driven by Large Language Models (LLMs) offer enormous\npotential for automation. Early proof of this technology can be found in\nvarious demonstrations of agents solving complex tasks, interacting with\nexternal systems to augment their knowledge, and triggering actions. In\nparticular, workflows involving multiple agents solving complex tasks in a\ncollaborative fashion exemplify their capacity to operate in less strict and\nless well-defined environments. Thus, a multi-agent approach has great\npotential for serving as a backbone in many industrial applications, ranging\nfrom complex knowledge retrieval systems to next generation robotic process\nautomation. Given the reasoning abilities within the current generation of\nLLMs, complex processes require a multi-step approach that includes a plan of\nwell-defined and modular tasks. Depending on the level of complexity, these\ntasks can be executed either by a single agent or a group of agents. In this\nwork, we focus on designing a flexible agent engineering framework with careful\nattention to planning and execution, capable of handling complex use case\napplications across various domains. The proposed framework provides\nreliability in industrial applications and presents techniques to ensure a\nscalable, flexible, and collaborative workflow for multiple autonomous agents\nworking together towards solving tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.20041v3"
    },
    {
        "title": "Multi-Agent Training for Pommerman: Curriculum Learning and\n  Population-based Self-Play Approach",
        "authors": [
            "Nhat-Minh Huynh",
            "Hoang-Giang Cao",
            "I-Chen Wu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Pommerman is a multi-agent environment that has received considerable\nattention from researchers in recent years. This environment is an ideal\nbenchmark for multi-agent training, providing a battleground for two teams with\ncommunication capabilities among allied agents. Pommerman presents significant\nchallenges for model-free reinforcement learning due to delayed action effects,\nsparse rewards, and false positives, where opponent players can lose due to\ntheir own mistakes. This study introduces a system designed to train\nmulti-agent systems to play Pommerman using a combination of curriculum\nlearning and population-based self-play. We also tackle two challenging\nproblems when deploying the multi-agent training system for competitive games:\nsparse reward and suitable matchmaking mechanism. Specifically, we propose an\nadaptive annealing factor based on agents' performance to adjust the dense\nexploration reward during training dynamically. Additionally, we implement a\nmatchmaking mechanism utilizing the Elo rating system to pair agents\neffectively. Our experimental results demonstrate that our trained agent can\noutperform top learning agents without requiring communication among allied\nagents.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.00662v2"
    },
    {
        "title": "Impact of the Network Size and Frequency of Information Receipt on\n  Polarization in Social Networks",
        "authors": [
            "Sudhakar Krisharao",
            "Shaja Arul Selvamani"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Opinion Dynamics is an interdisciplinary area of research. Psychology and\nSociology have proposed models of how individuals form opinions and how social\ninteractions influence this process. Socio-Physicists have interpreted patterns\nin opinion formation as arising from non-linearity in the underlying process,\nshaping the models. Agent-based modeling has offered a platform to study the\nOpinion Dynamics of large groups. This paper recasts recent models in opinion\nformation into a proper dynamical system, injecting the idea of clock time into\nevolving opinions. The time interval between successive receipts of new\ninformation (frequency of information receipts) becomes a factor to study.\nSocial media has shrunk time intervals between information receipts, increasing\ntheir frequency. The recast models show that shorter intervals and larger\nnetworks increase an individual's propensity for polarization, defined as an\ninability to hold a neutral opinion. A Polarization number based on\nsociological parameters is proposed, with critical values beyond which\nindividuals are prone to polarization, depending on psychological parameters.\nReduced time intervals and larger interacting groups can push the Polarization\nnumber to critical values, contributing to polarization. The Extent of\nPolarization is defined as the width of the region around neutral within which\nan individual cannot hold an opinion. Results are reported for model parameters\nfound in the literature. The findings offer an opportunity to adjust model\nparameters to align with empirical evidence, aiding the study of Opinion\nDynamics in large social networks using Agent-Based Modeling.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.01788v1"
    },
    {
        "title": "Enhancing Automotive User Experience with Dynamic Service Orchestration\n  for Software Defined Vehicles",
        "authors": [
            "Pierre Laclau",
            "Stéphane Bonnet",
            "Bertrand Ducourthial",
            "Xiaoting Li",
            "Trista Lin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the increasing demand for dynamic behaviors in automotive use cases,\nSoftware Defined Vehicles (SDVs) have emerged as a promising solution by\nbringing dynamic onboard service management capabilities. While users may\nrequest a wide range of services during vehicle operation, background tasks\nsuch as cooperative Vehicle-to-Everything (V2X) services can activate\non-the-fly in response to real-time road conditions. In this dynamic\nenvironment, the efficient allocation of onboard resources becomes a complex\nchallenge, in order to meet mixed-criticality onboard Quality-of-Service (QoS)\nnetwork requirements while ensuring an optimal user experience. Additionally,\nthe ever-evolving real-time network connectivity and computational availability\nconditions further complicate the process. In this context, we present a\ndynamic resource-based onboard service orchestration algorithm that considers\nreal-time in-vehicle and V2X network health, along with onboard resource\nconstraints, to select degraded modes for onboard applications and maximize\nuser experience. To enable dynamic orchestration, we introduce the concept of\nAutomotive eXperience Integrity Level (AXIL) which expresses a runtime priority\nfor non-safety-critical applications. This algorithm produces near-optimal\nsolutions while significantly reducing execution time compared to\nstraightforward methods as demonstrated by simulation results. With this\napproach, we aim to enable efficient onboard execution for a user\nexperience-focused service orchestration.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.02491v2"
    },
    {
        "title": "A multi-objective combinatorial optimisation framework for large scale\n  hierarchical population synthesis",
        "authors": [
            "Imran Mahmood",
            "Nicholas Bishop",
            "Anisoara Calinescu",
            "Michael Wooldridge",
            "Ioannis Zachos"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In agent-based simulations, synthetic populations of agents are commonly used\nto represent the structure, behaviour, and interactions of individuals.\nHowever, generating a synthetic population that accurately reflects real\npopulation statistics is a challenging task, particularly when performed at\nscale. In this paper, we propose a multi objective combinatorial optimisation\ntechnique for large scale population synthesis. We demonstrate the\neffectiveness of our approach by generating a synthetic population for selected\nregions and validating it on contingency tables from real population data. Our\napproach supports complex hierarchical structures between individuals and\nhouseholds, is scalable to large populations and achieves minimal contigency\ntable reconstruction error. Hence, it provides a useful tool for policymakers\nand researchers for simulating the dynamics of complex populations.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.03180v1"
    },
    {
        "title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
        "authors": [
            "Shmuel Berman",
            "Kathleen McKeown",
            "Baishakhi Ray"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Prior research has enhanced the ability of Large Language Models (LLMs) to\nsolve logic puzzles using techniques such as chain-of-thought prompting or\nintroducing a symbolic representation. These frameworks are still usually\ninsufficient to solve complicated logical problems, such as Zebra puzzles, due\nto the inherent complexity of translating natural language clues into logical\nstatements. We introduce a multi-agent system, ZPS, that integrates LLMs with\nan off the shelf theorem prover. This system tackles the complex puzzle-solving\ntask by breaking down the problem into smaller, manageable parts, generating\nSMT (Satisfiability Modulo Theories) code to solve them with a theorem prover,\nand using feedback between the agents to repeatedly improve their answers. We\nalso introduce an automated grid puzzle grader to assess the correctness of our\npuzzle solutions and show that the automated grader is reliable by evaluating\nit in a user-study. Our approach shows improvement in all three LLMs we tested,\nwith GPT-4 showing 166% improvement in the number of fully correct solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.03956v2"
    },
    {
        "title": "Fair Money -- Public Good Value Pricing With Karma Economies",
        "authors": [
            "Kevin Riehl",
            "Anastasios Kouvelas",
            "Michail Makridis"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  City road infrastructure is a public good, and over-consumption by\nself-interested, rational individuals leads to traffic jams. Congestion pricing\nis effective in reducing demand to sustainable levels, but also controversial,\nas it introduces equity issues and systematically discriminates lower-income\ngroups. Karma is a non-monetary, fair, and efficient resource allocation\nmechanism, that employs an artificial currency different from money, that\nincentivizes cooperation amongst selfish individuals, and achieves a balance\nbetween giving and taking. Where money does not do its job, Karma achieves\nsocially more desirable resource allocations by being aligned with consumers'\nneeds rather than their financial power. This work highlights the value\nproposition of Karma, gives guidance on important Karma mechanism design\nelements, and equips the reader with a useful software framework to model Karma\neconomies and predict consumers' behaviour. A case study demonstrates the\npotential of this feasible alternative to money, without the burden of\nadditional fees.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.05132v1"
    },
    {
        "title": "United We Stand: Decentralized Multi-Agent Planning With Attrition",
        "authors": [
            "Nhat Nguyen",
            "Duong Nguyen",
            "Gianluca Rizzo",
            "Hung Nguyen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Decentralized planning is a key element of cooperative multi-agent systems\nfor information gathering tasks. However, despite the high frequency of agent\nfailures in realistic large deployment scenarios, current approaches perform\npoorly in the presence of failures, by not converging at all, and/or by making\nvery inefficient use of resources (e.g. energy). In this work, we propose\nAttritable MCTS (A-MCTS), a decentralized MCTS algorithm capable of timely and\nefficient adaptation to changes in the set of active agents. It is based on the\nuse of a global reward function for the estimation of each agent's local\ncontribution, and regret matching for coordination. We evaluate its\neffectiveness in realistic data-harvesting problems under different scenarios.\nWe show both theoretically and experimentally that A-MCTS enables efficient\nadaptation even under high failure rates. Results suggest that, in the presence\nof frequent failures, our solution improves substantially over the best\nexisting approaches in terms of global utility and scalability.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.08254v2"
    },
    {
        "title": "Graph Neural Networks with Model-based Reinforcement Learning for\n  Multi-agent Systems",
        "authors": [
            "Hanxiao Chen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent systems (MAS) constitute a significant role in exploring machine\nintelligence and advanced applications. In order to deeply investigate\ncomplicated interactions within MAS scenarios, we originally propose \"GNN for\nMBRL\" model, which utilizes a state-spaced Graph Neural Networks with\nModel-based Reinforcement Learning to address specific MAS missions (e.g.,\nBilliard-Avoidance, Autonomous Driving Cars). In detail, we firstly used GNN\nmodel to predict future states and trajectories of multiple agents, then\napplied the Cross-Entropy Method (CEM) optimized Model Predictive Control to\nassist the ego-agent planning actions and successfully accomplish certain MAS\ntasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.09249v2"
    },
    {
        "title": "Strategic Pseudo-Goal Perturbation for Deadlock-Free Multi-Agent\n  Navigation in Social Mini-Games",
        "authors": [
            "Abhishek Jha",
            "Tanishq Gupta",
            "Sumit Singh Rawat",
            "Girish Kumar"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This work introduces a Strategic Pseudo-Goal Perturbation (SPGP) technique, a\nnovel approach to resolve deadlock situations in multi-agent navigation\nscenarios. Leveraging the robust framework of Safety Barrier Certificates, our\nmethod integrates a strategic perturbation mechanism that guides agents through\nsocial mini-games where deadlock and collision occur frequently. The method\nadopts a strategic calculation process where agents, upon encountering a\ndeadlock select a pseudo goal within a predefined radius around the current\nposition to resolve the deadlock among agents. The calculation is based on\ncontrolled strategic algorithm, ensuring that deviation towards pseudo-goal is\nboth purposeful and effective in resolution of deadlock. Once the agent reaches\nthe pseudo goal, it resumes the path towards the original goal, thereby\nenhancing navigational efficiency and safety. Experimental results demonstrates\nSPGP's efficacy in reducing deadlock instances and improving overall system\nthroughput in variety of multi-agent navigation scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.17766v1"
    },
    {
        "title": "Very Large-Scale Multi-Agent Simulation in AgentScope",
        "authors": [
            "Xuchen Pan",
            "Dawei Gao",
            "Yuexiang Xie",
            "Yushuo Chen",
            "Zhewei Wei",
            "Yaliang Li",
            "Bolin Ding",
            "Ji-Rong Wen",
            "Jingren Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Recent advances in large language models (LLMs) have opened new avenues for\napplying multi-agent systems in very large-scale simulations. However, there\nremain several challenges when conducting multi-agent simulations with existing\nplatforms, such as limited scalability and low efficiency, unsatisfied agent\ndiversity, and effort-intensive management processes. To address these\nchallenges, we develop several new features and components for AgentScope, a\nuser-friendly multi-agent platform, enhancing its convenience and flexibility\nfor supporting very large-scale multi-agent simulations. Specifically, we\npropose an actor-based distributed mechanism as the underlying technological\ninfrastructure towards great scalability and high efficiency, and provide\nflexible environment support for simulating various real-world scenarios, which\nenables parallel execution of multiple agents, automatic workflow conversion\nfor distributed deployment, and both inter-agent and agent-environment\ninteractions. Moreover, we integrate an easy-to-use configurable tool and an\nautomatic background generation pipeline in AgentScope, simplifying the process\nof creating agents with diverse yet detailed background settings. Last but not\nleast, we provide a web-based interface for conveniently monitoring and\nmanaging a large number of agents that might deploy across multiple devices. We\nconduct a comprehensive simulation to demonstrate the effectiveness of these\nproposed enhancements in AgentScope, and provide detailed observations and\ninsightful discussions to highlight the great potential of applying multi-agent\nsystems in large-scale simulations. The source code is released on GitHub at\nhttps://github.com/modelscope/agentscope/tree/main/examples/paper_large_scale_simulation\nto inspire further research and development in large-scale multi-agent\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.17789v2"
    },
    {
        "title": "Collaborative Adaptation for Recovery from Unforeseen Malfunctions in\n  Discrete and Continuous MARL Domains",
        "authors": [
            "Yasin Findik",
            "Hunter Hasenfus",
            "Reza Azadeh"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Cooperative multi-agent learning plays a crucial role for developing\neffective strategies to achieve individual or shared objectives in multi-agent\nteams. In real-world settings, agents may face unexpected failures, such as a\nrobot's leg malfunctioning or a teammate's battery running out. These\nmalfunctions decrease the team's ability to accomplish assigned task(s),\nespecially if they occur after the learning algorithms have already converged\nonto a collaborative strategy. Current leading approaches in Multi-Agent\nReinforcement Learning (MARL) often recover slowly -- if at all -- from such\nmalfunctions. To overcome this limitation, we present the Collaborative\nAdaptation (CA) framework, highlighting its unique capability to operate in\nboth continuous and discrete domains. Our framework enhances the adaptability\nof agents to unexpected failures by integrating inter-agent relationships into\ntheir learning processes, thereby accelerating the recovery from malfunctions.\nWe evaluated our framework's performance through experiments in both discrete\nand continuous environments. Empirical results reveal that in scenarios\ninvolving unforeseen malfunction, although state-of-the-art algorithms often\nconverge on sub-optimal solutions, the proposed CA framework mitigates and\nrecovers more effectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.19144v1"
    },
    {
        "title": "Modeling Urban Transport Choices: Incorporating Sociocultural Aspects",
        "authors": [
            "Kathleen Salazar-Serna",
            "Lorena Cadavid",
            "Carlos J. Franco"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper introduces an agent-based simulation model aimed at understanding\nurban commuters mode choices and evaluating the impacts of transport policies\nto promote sustainable mobility. Crafted for developing countries, where\nutilitarian travel heavily relies on motorcycles, the model integrates\nsociocultural factors that influence transport behavior. Multinomial models and\ninferential statistics applied to survey data from Cali, Colombia, inform the\nmodel, revealing significant influences of sociodemographic factors and travel\nattributes on mode choice. Findings highlight the importance of cost, time,\nsafety, comfort, and personal security, with disparities across socioeconomic\ngroups. Policy simulations demonstrate positive responses to interventions like\nfree public transportation, increased bus frequency, and enhanced security, yet\nwith modest shifts in mode choice. Multifaceted policy approaches are deemed\nmore effective, addressing diverse user preferences. Outputs can be extended to\ncities with similar sociocultural characteristics and transport dynamics. The\nmethodology applied in this work can be replicated for other territories.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.21307v1"
    },
    {
        "title": "CommonUppRoad: A Framework of Formal Modelling, Verifying, Learning, and\n  Visualisation of Autonomous Vehicles",
        "authors": [
            "Rong Gu",
            "Kaige Tan",
            "Andreas Holck Høeg-Petersen",
            "Lei Feng",
            "Kim Guldstrand Larsen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Combining machine learning and formal methods (FMs) provides a possible\nsolution to overcome the safety issue of autonomous driving (AD) vehicles.\nHowever, there are gaps to be bridged before this combination becomes\npractically applicable and useful. In an attempt to facilitate researchers in\nboth FMs and AD areas, this paper proposes a framework that combines two\nwell-known tools, namely CommonRoad and UPPAAL. On the one hand, CommonRoad can\nbe enhanced by the rigorous semantics of models in UPPAAL, which enables a\nsystematic and comprehensive understanding of the AD system's behaviour and\nthus strengthens the safety of the system. On the other hand, controllers\nsynthesised by UPPAAL can be visualised by CommonRoad in real-world road\nnetworks, which facilitates AD vehicle designers greatly adopting formal models\nin system design. In this framework, we provide automatic model conversions\nbetween CommonRoad and UPPAAL. Therefore, users only need to program in Python\nand the framework takes care of the formal models, learning, and verification\nin the backend. We perform experiments to demonstrate the applicability of our\nframework in various AD scenarios, discuss the advantages of solving motion\nplanning in our framework, and show the scalability limit and possible\nsolutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01093v1"
    },
    {
        "title": "Assessing the Effects of Container Handling Strategies on Enhancing\n  Freight Throughput",
        "authors": [
            "Sarita Rattanakunuprakarn",
            "Mingzhou Jin",
            "Mustafa Can Camur",
            "Xueping Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  As global supply chains and freight volumes grow, the U.S. faces escalating\ntransportation demands. The heavy reliance on road transport, coupled with the\nunderutilization of the railway system, results in congested highways,\nprolonged transportation times, higher costs, and increased carbon emissions.\nCalifornia's San Pedro Port Complex (SPPC), the nation's busiest, incurs a\nsignificant share of these challenges. We utilize an agent-based simulation to\nreplicate real-world scenarios, focusing on the intricacies of interactions in\na modified intermodal inbound freight system for the SPPC. This involves\nrelocating container classification to potential warehouses in California,\nUtah, Arizona, and Nevada, rather than exclusively at port areas. Our primary\naim is to evaluate the proposed system's efficiency, considering cost and\nfreight throughput, while also examining the effects of workforce shortages.\nComputational analysis suggests that strategically installing intermodal\ncapabilities in select warehouses can reduce transportation costs, boost\nthroughput, and foster resour\n",
        "pdf_link": "http://arxiv.org/pdf/2408.02768v1"
    },
    {
        "title": "QTypeMix: Enhancing Multi-Agent Cooperative Strategies through\n  Heterogeneous and Homogeneous Value Decomposition",
        "authors": [
            "Songchen Fu",
            "Shaojing Zhao",
            "Ta Li",
            "YongHong Yan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In multi-agent cooperative tasks, the presence of heterogeneous agents is\nfamiliar. Compared to cooperation among homogeneous agents, collaboration\nrequires considering the best-suited sub-tasks for each agent. However, the\noperation of multi-agent systems often involves a large amount of complex\ninteraction information, making it more challenging to learn heterogeneous\nstrategies. Related multi-agent reinforcement learning methods sometimes use\ngrouping mechanisms to form smaller cooperative groups or leverage prior domain\nknowledge to learn strategies for different roles. In contrast, agents should\nlearn deeper role features without relying on additional information.\nTherefore, we propose QTypeMix, which divides the value decomposition process\ninto homogeneous and heterogeneous stages. QTypeMix learns to extract type\nfeatures from local historical observations through the TE loss. In addition,\nwe introduce advanced network structures containing attention mechanisms and\nhypernets to enhance the representation capability and achieve the value\ndecomposition process. The results of testing the proposed method on 14 maps\nfrom SMAC and SMACv2 show that QTypeMix achieves state-of-the-art performance\nin tasks of varying difficulty.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07098v1"
    },
    {
        "title": "Improving Global Parameter-sharing in Physically Heterogeneous\n  Multi-agent Reinforcement Learning with Unified Action Space",
        "authors": [
            "Xiaoyang Yu",
            "Youfang Lin",
            "Shuo Wang",
            "Kai Lv",
            "Sheng Han"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In a multi-agent system (MAS), action semantics indicates the different\ninfluences of agents' actions toward other entities, and can be used to divide\nagents into groups in a physically heterogeneous MAS. Previous multi-agent\nreinforcement learning (MARL) algorithms apply global parameter-sharing across\ndifferent types of heterogeneous agents without careful discrimination of\ndifferent action semantics. This common implementation decreases the\ncooperation and coordination between agents in complex situations. However,\nfully independent agent parameters dramatically increase the computational cost\nand training difficulty. In order to benefit from the usage of different action\nsemantics while also maintaining a proper parameter-sharing structure, we\nintroduce the Unified Action Space (UAS) to fulfill the requirement. The UAS is\nthe union set of all agent actions with different semantics. All agents first\ncalculate their unified representation in the UAS, and then generate their\nheterogeneous action policies using different available-action-masks. To\nfurther improve the training of extra UAS parameters, we introduce a\nCross-Group Inverse (CGI) loss to predict other groups' agent policies with the\ntrajectory information. As a universal method for solving the physically\nheterogeneous MARL problem, we implement the UAS adding to both value-based and\npolicy-based MARL algorithms, and propose two practical algorithms: U-QMIX and\nU-MAPPO. Experimental results in the SMAC environment prove the effectiveness\nof both U-QMIX and U-MAPPO compared with several state-of-the-art MARL methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07395v1"
    },
    {
        "title": "A Nested Graph Reinforcement Learning-based Decision-making Strategy for\n  Eco-platooning",
        "authors": [
            "Xin Gao",
            "Xueyuan Li",
            "Hao Liu",
            "Ao Li",
            "Zhaoyang Ma",
            "Zirui Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Platooning technology is renowned for its precise vehicle control, traffic\nflow optimization, and energy efficiency enhancement. However, in large-scale\nmixed platoons, vehicle heterogeneity and unpredictable traffic conditions lead\nto virtual bottlenecks. These bottlenecks result in reduced traffic throughput\nand increased energy consumption within the platoon. To address these\nchallenges, we introduce a decision-making strategy based on nested graph\nreinforcement learning. This strategy improves collaborative decision-making,\nensuring energy efficiency and alleviating congestion. We propose a theory of\nnested traffic graph representation that maps dynamic interactions between\nvehicles and platoons in non-Euclidean spaces. By incorporating spatio-temporal\nweighted graph into a multi-head attention mechanism, we further enhance the\nmodel's capacity to process both local and global data. Additionally, we have\ndeveloped a nested graph reinforcement learning framework to enhance the\nself-iterative learning capabilities of platooning. Using the I-24 dataset, we\ndesigned and conducted comparative algorithm experiments, generalizability\ntesting, and permeability ablation experiments, thereby validating the proposed\nstrategy's effectiveness. Compared to the baseline, our strategy increases\nthroughput by 10% and decreases energy use by 9%. Specifically, increasing the\npenetration rate of CAVs significantly enhances traffic throughput, though it\nalso increases energy consumption.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.07578v1"
    },
    {
        "title": "AgentSimulator: An Agent-based Approach for Data-driven Business Process\n  Simulation",
        "authors": [
            "Lukas Kirchdorfer",
            "Robert Blümel",
            "Timotheus Kampik",
            "Han van der Aa",
            "Heiner Stuckenschmidt"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Business process simulation (BPS) is a versatile technique for estimating\nprocess performance across various scenarios. Traditionally, BPS approaches\nemploy a control-flow-first perspective by enriching a process model with\nsimulation parameters. Although such approaches can mimic the behavior of\ncentrally orchestrated processes, such as those supported by workflow systems,\ncurrent control-flow-first approaches cannot faithfully capture the dynamics of\nreal-world processes that involve distinct resource behavior and decentralized\ndecision-making. Recognizing this issue, this paper introduces AgentSimulator,\na resource-first BPS approach that discovers a multi-agent system from an event\nlog, modeling distinct resource behaviors and interaction patterns to simulate\nthe underlying process. Our experiments show that AgentSimulator achieves\nstate-of-the-art simulation accuracy with significantly lower computation times\nthan existing approaches while providing high interpretability and adaptability\nto different types of process-execution scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.08571v1"
    },
    {
        "title": "Beyond Local Views: Global State Inference with Diffusion Models for\n  Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Hangyu Mao",
            "Nianmin Zhang",
            "Xin Xin",
            "Pengjie Ren",
            "Dapeng Li",
            "Bin Zhang",
            "Guoliang Fan",
            "Zhumin Chen",
            "Changwei Wang",
            "Jiangjin Yin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In partially observable multi-agent systems, agents typically only have\naccess to local observations. This severely hinders their ability to make\nprecise decisions, particularly during decentralized execution. To alleviate\nthis problem and inspired by image outpainting, we propose State Inference with\nDiffusion Models (SIDIFF), which uses diffusion models to reconstruct the\noriginal global state based solely on local observations. SIDIFF consists of a\nstate generator and a state extractor, which allow agents to choose suitable\nactions by considering both the reconstructed global state and local\nobservations. In addition, SIDIFF can be effortlessly incorporated into current\nmulti-agent reinforcement learning algorithms to improve their performance.\nFinally, we evaluated SIDIFF on different experimental platforms, including\nMulti-Agent Battle City (MABC), a novel and flexible multi-agent reinforcement\nlearning environment we developed. SIDIFF achieved desirable results and\noutperformed other popular algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.09501v1"
    },
    {
        "title": "Subgoal-based Hierarchical Reinforcement Learning for Multi-Agent\n  Collaboration",
        "authors": [
            "Cheng Xu",
            "Changtian Zhang",
            "Yuchen Shi",
            "Ran Wang",
            "Shihong Duan",
            "Yadong Wan",
            "Xiaotong Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Recent advancements in reinforcement learning have made significant impacts\nacross various domains, yet they often struggle in complex multi-agent\nenvironments due to issues like algorithm instability, low sampling efficiency,\nand the challenges of exploration and dimensionality explosion. Hierarchical\nreinforcement learning (HRL) offers a structured approach to decompose complex\ntasks into simpler sub-tasks, which is promising for multi-agent settings. This\npaper advances the field by introducing a hierarchical architecture that\nautonomously generates effective subgoals without explicit constraints,\nenhancing both flexibility and stability in training. We propose a dynamic goal\ngeneration strategy that adapts based on environmental changes. This method\nsignificantly improves the adaptability and sample efficiency of the learning\nprocess. Furthermore, we address the critical issue of credit assignment in\nmulti-agent systems by synergizing our hierarchical architecture with a\nmodified QMIX network, thus improving overall strategy coordination and\nefficiency. Comparative experiments with mainstream reinforcement learning\nalgorithms demonstrate the superior convergence speed and performance of our\napproach in both single-agent and multi-agent environments, confirming its\neffectiveness and flexibility in complex scenarios. Our code is open-sourced\nat: \\url{https://github.com/SICC-Group/GMAH}.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.11416v1"
    },
    {
        "title": "Graph Attention Inference of Network Topology in Multi-Agent Systems",
        "authors": [
            "Akshay Kolli",
            "Reza Azadeh",
            "Kshitj Jerath"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Accurately identifying the underlying graph structures of multi-agent systems\nremains a difficult challenge. Our work introduces a novel machine\nlearning-based solution that leverages the attention mechanism to predict\nfuture states of multi-agent systems by learning node representations. The\ngraph structure is then inferred from the strength of the attention values.\nThis approach is applied to both linear consensus dynamics and the non-linear\ndynamics of Kuramoto oscillators, resulting in implicit learning of the graph\nby learning good agent representations. Our results demonstrate that the\npresented data-driven graph attention machine learning model can identify the\nnetwork topology in multi-agent systems, even when the underlying dynamic model\nis not known, as evidenced by the F1 scores achieved in the link prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.15449v2"
    },
    {
        "title": "Different Facets for Different Experts: A Framework for Streamlining The\n  Integration of Qualitative Insights into ABM Development",
        "authors": [
            "Vivek Nallur",
            "Pedram Aghaei",
            "Graham Finlay"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  A key problem in agent-based simulation is that integrating qualitative\ninsights from multiple discipline experts is extremely hard. In most\nsimulations, agent capabilities and corresponding behaviour needs to be\nprogrammed into the agent. We report on the architecture of a tool that\ndisconnects the programmed functions of the agent, from the acquisition of\ncapability and displayed behaviour. This allows multiple different domain\nexperts to represent qualitative insights, without the need for code to be\nchanged. It also allows a continuous integration (or even change) of\nqualitative behaviour processes, as more insights are gained. The consequent\nbehaviour observed in the model is both, more faithful to the expert's insight\nas well as able to be contrasted against other models representing other\ninsights.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.15725v1"
    },
    {
        "title": "A Survey on Emergent Language",
        "authors": [
            "Jannik Peters",
            "Constantin Waubert de Puiseau",
            "Hasan Tercan",
            "Arya Gopikrishnan",
            "Gustavo Adolpho Lucas De Carvalho",
            "Christian Bitter",
            "Tobias Meisen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The field of emergent language represents a novel area of research within the\ndomain of artificial intelligence, particularly within the context of\nmulti-agent reinforcement learning. Although the concept of studying language\nemergence is not new, early approaches were primarily concerned with explaining\nhuman language formation, with little consideration given to its potential\nutility for artificial agents. In contrast, studies based on reinforcement\nlearning aim to develop communicative capabilities in agents that are\ncomparable to or even superior to human language. Thus, they extend beyond the\nlearned statistical representations that are common in natural language\nprocessing research. This gives rise to a number of fundamental questions, from\nthe prerequisites for language emergence to the criteria for measuring its\nsuccess. This paper addresses these questions by providing a comprehensive\nreview of 181 scientific publications on emergent language in artificial\nintelligence. Its objective is to serve as a reference for researchers\ninterested in or proficient in the field. Consequently, the main contributions\nare the definition and overview of the prevailing terminology, the analysis of\nexisting evaluation methods and metrics, and the description of the identified\nresearch gaps.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.02645v1"
    },
    {
        "title": "PARCO: Learning Parallel Autoregressive Policies for Efficient\n  Multi-Agent Combinatorial Optimization",
        "authors": [
            "Federico Berto",
            "Chuanbo Hua",
            "Laurin Luttmann",
            "Jiwoo Son",
            "Junyoung Park",
            "Kyuree Ahn",
            "Changhyun Kwon",
            "Lin Xie",
            "Jinkyoo Park"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent combinatorial optimization problems such as routing and\nscheduling have great practical relevance but present challenges due to their\nNP-hard combinatorial nature, hard constraints on the number of possible\nagents, and hard-to-optimize objective functions. This paper introduces PARCO\n(Parallel AutoRegressive Combinatorial Optimization), a novel approach that\nlearns fast surrogate solvers for multi-agent combinatorial problems with\nreinforcement learning by employing parallel autoregressive decoding. We\npropose a model with a Multiple Pointer Mechanism to efficiently decode\nmultiple decisions simultaneously by different agents, enhanced by a\nPriority-based Conflict Handling scheme. Moreover, we design specialized\nCommunication Layers that enable effective agent collaboration, thus enriching\ndecision-making. We evaluate PARCO in representative multi-agent combinatorial\nproblems in routing and scheduling and demonstrate that our learned solvers\noffer competitive results against both classical and neural baselines in terms\nof both solution quality and speed. We make our code openly available at\nhttps://github.com/ai4co/parco.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.03811v1"
    },
    {
        "title": "Swarm Algorithms for Dynamic Task Allocation in Unknown Environments",
        "authors": [
            "Adithya Balachandran",
            "Noble Harasha",
            "Nancy Lynch"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Robot swarms, systems of many robots that operate in a distributed fashion,\nhave many applications in areas such as search-and-rescue, natural disaster\nresponse, and self-assembly. Several of these applications can be abstracted to\nthe general problem of task allocation in an environment, in which robots must\nassign themselves to and complete tasks. While several algorithms for task\nallocation have been proposed, most of them assume either prior knowledge of\ntask locations or a static set of tasks. Operating under a discrete general\nmodel where tasks dynamically appear in unknown locations, we present three new\nswarm algorithms for task allocation. We demonstrate that when tasks appear\nslowly, our variant of a distributed algorithm based on propagating task\ninformation completes tasks more efficiently than a Levy random walk algorithm,\nwhich is a strategy used by many organisms in nature to efficiently search an\nenvironment. We also propose a division of labor algorithm where some agents\nare using our algorithm based on propagating task information while the\nremaining agents are using the Levy random walk algorithm. Finally, we\nintroduce a hybrid algorithm where each agent dynamically switches between\nusing propagated task information and following a Levy random walk. We show\nthat our division of labor and hybrid algorithms can perform better than both\nour algorithm based on propagated task information and the Levy walk algorithm,\nespecially at low and medium task rates. When tasks appear fast, we observe the\nLevy random walk strategy performs as well or better when compared to these\nnovel approaches. Our work demonstrates the relative performance of these\nalgorithms on a variety of task rates and also provide insight into optimizing\nour algorithms based on environment parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09550v1"
    },
    {
        "title": "Context-aware Advertisement Modeling and Applications in Rapid Transit\n  Systems",
        "authors": [
            "Afzal Ahmed",
            "Muhammad Raees"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In today's businesses, marketing has been a central trend for growth.\nMarketing quality is equally important as product quality and relevant metrics.\nQuality of Marketing depends on targeting the right person. Technology\nadaptations have been slow in many fields but have captured some aspects of\nhuman life to make an impact. For instance, in marketing, recent developments\nhave provided a significant shift toward data-driven approaches. In this paper,\nwe present an advertisement model using behavioral and tracking analysis. We\nextract users' behavioral data upholding their privacy principle and perform\ndata manipulations and pattern mining for effective analysis. We present a\nmodel using the agent-based modeling (ABM) technique, with the target audience\nof rapid transit system users to target the right person for advertisement\napplications. We also outline the Overview, Design, and Details concept of ABM.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09956v1"
    },
    {
        "title": "Optimality Gap of Decentralized Submodular Maximization under\n  Probabilistic Communication",
        "authors": [
            "Joan Vendrell",
            "Solmaz Kia"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper considers the problem of decentralized submodular maximization\nsubject to partition matroid constraint using a sequential greedy algorithm\nwith probabilistic inter-agent message-passing. We propose a\ncommunication-aware framework where the probability of successful communication\nbetween connected devices is considered. Our analysis introduces the notion of\nthe probabilistic optimality gap, highlighting its potential influence on\ndetermining the message-passing sequence based on the agent's broadcast\nreliability and strategic decisions regarding agents that can broadcast their\nmessages multiple times in a resource-limited environment. This work not only\ncontributes theoretical insights but also has practical implications for\ndesigning and analyzing decentralized systems in uncertain communication\nenvironments. A numerical example demonstrates the impact of our results.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09979v1"
    },
    {
        "title": "On the limits of agency in agent-based models",
        "authors": [
            "Ayush Chopra",
            "Shashank Kumar",
            "Nurullah Giray-Kuru",
            "Ramesh Raskar",
            "Arnau Quera-Bofarull"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Agent-based modeling (ABM) offers powerful insights into complex systems, but\nits practical utility has been limited by computational constraints and\nsimplistic agent behaviors, especially when simulating large populations.\nRecent advancements in large language models (LLMs) could enhance ABMs with\nadaptive agents, but their integration into large-scale simulations remains\nchallenging. This work introduces a novel methodology that bridges this gap by\nefficiently integrating LLMs into ABMs, enabling the simulation of millions of\nadaptive agents. We present LLM archetypes, a technique that balances\nbehavioral complexity with computational efficiency, allowing for nuanced agent\nbehavior in large-scale simulations. Our analysis explores the crucial\ntrade-off between simulation scale and individual agent expressiveness,\ncomparing different agent architectures ranging from simple heuristic-based\nagents to fully adaptive LLM-powered agents. We demonstrate the real-world\napplicability of our approach through a case study of the COVID-19 pandemic,\nsimulating 8.4 million agents representing New York City and capturing the\nintricate interplay between health behaviors and economic outcomes. Our method\nsignificantly enhances ABM capabilities for predictive and counterfactual\nanalyses, addressing limitations of historical data in policy design. By\nimplementing these advances in an open-source framework, we facilitate the\nadoption of LLM archetypes across diverse ABM applications. Our results show\nthat LLM archetypes can markedly improve the realism and utility of large-scale\nABMs while maintaining computational feasibility, opening new avenues for\nmodeling complex societal challenges and informing data-driven policy\ndecisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.10568v3"
    },
    {
        "title": "Multi-agent Path Finding in Continuous Environment",
        "authors": [
            "Kristýna Janovská",
            "Pavel Surynek"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We address a variant of multi-agent path finding in continuous environment\n(CE-MAPF), where agents move along sets of smooth curves. Collisions between\nagents are resolved via avoidance in the space domain. A new Continuous\nEnvironment Conflict-Based Search (CE-CBS) algorithm is proposed in this work.\nCE-CBS combines conflict-based search (CBS) for the high-level search framework\nwith RRT* for low-level path planning. The CE-CBS algorithm is tested under\nvarious settings on diverse CE-MAPF instances. Experimental results show that\nCE-CBS is competitive w.r.t. to other algorithms that consider continuous\naspect in MAPF such as MAPF with continuous time.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.10680v1"
    },
    {
        "title": "On-policy Actor-Critic Reinforcement Learning for Multi-UAV Exploration",
        "authors": [
            "Ali Moltajaei Farid",
            "Jafar Roshanian",
            "Malek Mouhoub"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Unmanned aerial vehicles (UAVs) have become increasingly popular in various\nfields, including precision agriculture, search and rescue, and remote sensing.\nHowever, exploring unknown environments remains a significant challenge. This\nstudy aims to address this challenge by utilizing on-policy Reinforcement\nLearning (RL) with Proximal Policy Optimization (PPO) to explore the {two\ndimensional} area of interest with multiple UAVs. The UAVs will avoid collision\nwith obstacles and each other and do the exploration in a distributed manner.\nThe proposed solution includes actor-critic networks using deep convolutional\nneural networks {(CNN)} and long short-term memory (LSTM) for identifying the\nUAVs and areas that have already been covered. Compared to other RL techniques,\nsuch as policy gradient (PG) and asynchronous advantage actor-critic (A3C), the\nsimulation results demonstrate the superiority of the proposed PPO approach.\nAlso, the results show that combining LSTM with CNN in critic can improve\nexploration. Since the proposed exploration has to work in unknown\nenvironments, the results showed that the proposed setup can complete the\ncoverage when we have new maps that differ from the trained maps. Finally, we\nshowed how tuning hyper parameters may affect the overall performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.11058v1"
    },
    {
        "title": "Multi-Agent Vulcan: An Information-Driven Multi-Agent Path Finding\n  Approach",
        "authors": [
            "Jake Olkin",
            "Viraj Parimi",
            "Brian Williams"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Scientists often search for phenomena of interest while exploring new\nenvironments. Autonomous vehicles are deployed to explore such areas where\nhuman-operated vehicles would be costly or dangerous. Online control of\nautonomous vehicles for information-gathering is called adaptive sampling and\ncan be framed as a POMDP that uses information gain as its principal objective.\nWhile prior work focuses largely on single-agent scenarios, this paper\nconfronts challenges unique to multi-agent adaptive sampling, such as avoiding\nredundant observations, preventing vehicle collision, and facilitating path\nplanning under limited communication. We start with Multi-Agent Path Finding\n(MAPF) methods, which address collision avoidance by decomposing the MAPF\nproblem into a series of single-agent path planning problems. We then present\ninformation-driven MAPF which addresses multi-agent information gain under\nlimited communication. First, we introduce an admissible heuristic that relaxes\nmutual information gain to an additive function that can be evaluated as a set\nof independent single agent path planning problems. Second, we extend our\napproach to a distributed system that is robust to limited communication. When\nall agents are in range, the group plans jointly to maximize information. When\nsome agents move out of range, communicating subgroups are formed and the\nsubgroups plan independently. Since redundant observations are less likely when\nvehicles are far apart, this approach only incurs a small loss in information\ngain, resulting in an approach that gracefully transitions from full to partial\ncommunication. We evaluate our method against other adaptive sampling\nstrategies across various scenarios, including real-world robotic applications.\nOur method was able to locate up to 200% more unique phenomena in certain\nscenarios, and each agent located its first unique phenomenon faster by up to\n50%.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.13065v1"
    },
    {
        "title": "Cooperative Resilience in Artificial Intelligence Multiagent Systems",
        "authors": [
            "Manuela Chacon-Chamorro",
            "Luis Felipe Giraldo",
            "Nicanor Quijano",
            "Vicente Vargas-Panesso",
            "César González",
            "Juan Sebastián Pinzón",
            "Rubén Manrique",
            "Manuel Ríos",
            "Yesid Fonseca",
            "Daniel Gómez-Barrera",
            "Mónica Perdomo-Pérez"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Resilience refers to the ability of systems to withstand, adapt to, and\nrecover from disruptive events. While studies on resilience have attracted\nsignificant attention across various research domains, the precise definition\nof this concept within the field of cooperative artificial intelligence remains\nunclear. This paper addresses this gap by proposing a clear definition of\n`cooperative resilience' and outlining a methodology for its quantitative\nmeasurement. The methodology is validated in an environment with RL-based and\nLLM-augmented autonomous agents, subjected to environmental changes and the\nintroduction of agents with unsustainable behaviors. These events are\nparameterized to create various scenarios for measuring cooperative resilience.\nThe results highlight the crucial role of resilience metrics in analyzing how\nthe collective system prepares for, resists, recovers from, sustains\nwell-being, and transforms in the face of disruptions. These findings provide\nfoundational insights into the definition, measurement, and preliminary\nanalysis of cooperative resilience, offering significant implications for the\nbroader field of AI. Moreover, the methodology and metrics developed here can\nbe adapted to a wide range of AI applications, enhancing the reliability and\neffectiveness of AI in dynamic and unpredictable environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.13187v2"
    },
    {
        "title": "Scalable Multi-agent Reinforcement Learning for Factory-wide Dynamic\n  Scheduling",
        "authors": [
            "Jaeyeon Jang",
            "Diego Klabjan",
            "Han Liu",
            "Nital S. Patel",
            "Xiuqi Li",
            "Balakrishnan Ananthanarayanan",
            "Husam Dauod",
            "Tzung-Han Juang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Real-time dynamic scheduling is a crucial but notoriously challenging task in\nmodern manufacturing processes due to its high decision complexity. Recently,\nreinforcement learning (RL) has been gaining attention as an impactful\ntechnique to handle this challenge. However, classical RL methods typically\nrely on human-made dispatching rules, which are not suitable for large-scale\nfactory-wide scheduling. To bridge this gap, this paper applies a\nleader-follower multi-agent RL (MARL) concept to obtain desired coordination\nafter decomposing the scheduling problem into a set of sub-problems that are\nhandled by each individual agent for scalability. We further strengthen the\nprocedure by proposing a rule-based conversion algorithm to prevent\ncatastrophic loss of production capacity due to an agent's error. Our\nexperimental results demonstrate that the proposed model outperforms the\nstate-of-the-art deep RL-based scheduling models in various aspects.\nAdditionally, the proposed model provides the most robust scheduling\nperformance to demand changes. Overall, the proposed MARL-based scheduling\nmodel presents a promising solution to the real-time scheduling problem, with\npotential applications in various manufacturing industries.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.13571v1"
    },
    {
        "title": "Work Smarter Not Harder: Simple Imitation Learning with CS-PIBT\n  Outperforms Large Scale Imitation Learning for MAPF",
        "authors": [
            "Rishi Veerapaneni",
            "Arthur Jakobsson",
            "Kevin Ren",
            "Samuel Kim",
            "Jiaoyang Li",
            "Maxim Likhachev"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Path Finding (MAPF) is the problem of effectively finding\nefficient collision-free paths for a group of agents in a shared workspace. The\nMAPF community has largely focused on developing high-performance heuristic\nsearch methods. Recently, several works have applied various machine learning\n(ML) techniques to solve MAPF, usually involving sophisticated architectures,\nreinforcement learning techniques, and set-ups, but none using large amounts of\nhigh-quality supervised data. Our initial objective in this work was to show\nhow simple large scale imitation learning of high-quality heuristic search\nmethods can lead to state-of-the-art ML MAPF performance. However, we find\nthat, at least with our model architecture, simple large scale (700k examples\nwith hundreds of agents per example) imitation learning does \\textit{not}\nproduce impressive results. Instead, we find that by using prior work that\npost-processes MAPF model predictions to resolve 1-step collisions (CS-PIBT),\nwe can train a simple ML MAPF model in minutes that dramatically outperforms\nexisting ML MAPF policies. This has serious implications for all future ML MAPF\npolicies (with local communication) which currently struggle to scale. In\nparticular, this finding implies that future learnt policies should (1) always\nuse smart 1-step collision shields (e.g. CS-PIBT), (2) always include the\ncollision shield with greedy actions as a baseline (e.g. PIBT) and (3)\nmotivates future models to focus on longer horizon / more complex planning as\n1-step collisions can be efficiently resolved.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.14491v1"
    },
    {
        "title": "From homeostasis to resource sharing: Biologically and economically\n  compatible multi-objective multi-agent AI safety benchmarks",
        "authors": [
            "Roland Pihlakas",
            "Joel Pyykkö"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Developing safe agentic AI systems benefits from automated empirical testing\nthat conforms with human values, a subfield that is largely underdeveloped at\nthe moment. To contribute towards this topic, present work focuses on\nintroducing biologically and economically motivated themes that have been\nneglected in the safety aspects of modern reinforcement learning literature,\nnamely homeostasis, balancing multiple objectives, bounded objectives,\ndiminishing returns, sustainability, and multi-agent resource sharing. We\nimplemented eight main benchmark environments on the above themes, for\nillustrating the potential shortcomings of current mainstream discussions on AI\nsafety.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.00081v1"
    },
    {
        "title": "Cut the Crap: An Economical Communication Pipeline for LLM-based\n  Multi-Agent Systems",
        "authors": [
            "Guibin Zhang",
            "Yanwei Yue",
            "Zhixun Li",
            "Sukwon Yun",
            "Guancheng Wan",
            "Kun Wang",
            "Dawei Cheng",
            "Jeffrey Xu Yu",
            "Tianlong Chen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Recent advancements in large language model (LLM)-powered agents have shown\nthat collective intelligence can significantly outperform individual\ncapabilities, largely attributed to the meticulously designed inter-agent\ncommunication topologies. Though impressive in performance, existing\nmulti-agent pipelines inherently introduce substantial token overhead, as well\nas increased economic costs, which pose challenges for their large-scale\ndeployments. In response to this challenge, we propose an economical, simple,\nand robust multi-agent communication framework, termed $\\texttt{AgentPrune}$,\nwhich can seamlessly integrate into mainstream multi-agent systems and prunes\nredundant or even malicious communication messages. Technically,\n$\\texttt{AgentPrune}$ is the first to identify and formally define the\n\\textit{communication redundancy} issue present in current LLM-based\nmulti-agent pipelines, and efficiently performs one-shot pruning on the\nspatial-temporal message-passing graph, yielding a token-economic and\nhigh-performing communication topology. Extensive experiments across six\nbenchmarks demonstrate that $\\texttt{AgentPrune}$ \\textbf{(I)} achieves\ncomparable results as state-of-the-art topologies at merely $\\$5.6$ cost\ncompared to their $\\$43.7$, \\textbf{(II)} integrates seamlessly into existing\nmulti-agent frameworks with $28.1\\%\\sim72.8\\%\\downarrow$ token reduction, and\n\\textbf{(III)} successfully defend against two types of agent-based adversarial\nattacks with $3.5\\%\\sim10.8\\%\\uparrow$ performance boost.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.02506v1"
    },
    {
        "title": "Learning Emergence of Interaction Patterns across Independent RL Agents\n  in Multi-Agent Environments",
        "authors": [
            "Vasanth Reddy Baddam",
            "Suat Gumussoy",
            "Almuatazbellah Boker",
            "Hoda Eldardiry"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Many real-world problems, such as controlling swarms of drones and urban\ntraffic, naturally lend themselves to modeling as multi-agent reinforcement\nlearning (RL) problems. However, existing multi-agent RL methods often suffer\nfrom scalability challenges, primarily due to the introduction of communication\namong agents. Consequently, a key challenge lies in adapting the success of\ndeep learning in single-agent RL to the multi-agent setting. In response to\nthis challenge, we propose an approach that fundamentally reimagines\nmulti-agent environments. Unlike conventional methods that model each agent\nindividually with separate networks, our approach, the Bottom Up Network (BUN),\nadopts a unique perspective. BUN treats the collective of multi-agents as a\nunified entity while employing a specialized weight initialization strategy\nthat promotes independent learning. Furthermore, we dynamically establish\nconnections among agents using gradient information, enabling coordination when\nnecessary while maintaining these connections as limited and sparse to\neffectively manage the computational budget. Our extensive empirical\nevaluations across a variety of cooperative multi-agent scenarios, including\ntasks such as cooperative navigation and traffic control, consistently\ndemonstrate BUN's superiority over baseline methods with substantially reduced\ncomputational costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.02516v1"
    },
    {
        "title": "Distributed Networked Multi-task Learning",
        "authors": [
            "Lingzhou Hong",
            "Alfredo Garcia"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We consider a distributed multi-task learning scheme that accounts for\nmultiple linear model estimation tasks with heterogeneous and/or correlated\ndata streams. We assume that nodes can be partitioned into groups corresponding\nto different learning tasks and communicate according to a directed network\ntopology. Each node estimates a linear model asynchronously and is subject to\nlocal (within-group) regularization and global (across groups) regularization\nterms targeting noise reduction and generalization performance improvement\nrespectively. We provide a finite-time characterization of convergence of the\nestimators and task relation and illustrate the scheme's general applicability\nin two examples: random field temperature estimation and modeling student\nperformance from different academic districts.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.03403v1"
    },
    {
        "title": "GenSim: A General Social Simulation Platform with Large Language Model\n  based Agents",
        "authors": [
            "Jiakai Tang",
            "Heyang Gao",
            "Xuchen Pan",
            "Lei Wang",
            "Haoran Tan",
            "Dawei Gao",
            "Yushuo Chen",
            "Xu Chen",
            "Yankai Lin",
            "Yaliang Li",
            "Bolin Ding",
            "Jingren Zhou",
            "Jun Wang",
            "Ji-Rong Wen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the rapid advancement of large language models (LLMs), recent years have\nwitnessed many promising studies on leveraging LLM-based agents to simulate\nhuman social behavior. While prior work has demonstrated significant potential\nacross various domains, much of it has focused on specific scenarios involving\na limited number of agents and has lacked the ability to adapt when errors\noccur during simulation. To overcome these limitations, we propose a novel\nLLM-agent-based simulation platform called \\textit{GenSim}, which: (1)\n\\textbf{Abstracts a set of general functions} to simplify the simulation of\ncustomized social scenarios; (2) \\textbf{Supports one hundred thousand agents}\nto better simulate large-scale populations in real-world contexts; (3)\n\\textbf{Incorporates error-correction mechanisms} to ensure more reliable and\nlong-term simulations. To evaluate our platform, we assess both the efficiency\nof large-scale agent simulations and the effectiveness of the error-correction\nmechanisms. To our knowledge, GenSim represents an initial step toward a\ngeneral, large-scale, and correctable social simulation platform based on LLM\nagents, promising to further advance the field of social science.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.04360v2"
    },
    {
        "title": "Online Dynamic Pricing for Electric Vehicle Charging Stations with\n  Reservations",
        "authors": [
            "Jan Mrkos",
            "Antonín Komenda",
            "David Fiedler",
            "Jiří Vokřínek"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The transition to electric vehicles (EVs), coupled with the rise of renewable\nenergy sources, will significantly impact the electric grid. Unlike\nconventional fuel sources, electricity for EVs is constrained by grid capacity,\nprice fluctuations, and long EV charging times, requiring new pricing solutions\nto manage demand and supply. This paper proposes a model for online dynamic\npricing of reserved EV charging services, including reservation, parking, and\ncharging as a bundled service priced as a whole. Our approach focuses on the\nindividual charging station operator, employing a stochastic demand model and\nonline dynamic pricing based on expected demand. The proposed model uses a\nMarkov Decision Process (MDP) formulation to optimize sequential pricing\ndecisions for charging session requests. A key contribution is the novel\ndefinition and quantification of discretization error introduced by the\ndiscretization of the Poisson process for use in the MDP. The model's viability\nis demonstrated with a heuristic solution method based on Monte-Carlo tree\nsearch, offering a viable path for real-world application.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.05538v2"
    },
    {
        "title": "G-Designer: Architecting Multi-agent Communication Topologies via Graph\n  Neural Networks",
        "authors": [
            "Guibin Zhang",
            "Yanwei Yue",
            "Xiangguo Sun",
            "Guancheng Wan",
            "Miao Yu",
            "Junfeng Fang",
            "Kun Wang",
            "Dawei Cheng"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Recent advancements in large language model (LLM)-based agents have\ndemonstrated that collective intelligence can significantly surpass the\ncapabilities of individual agents, primarily due to well-crafted inter-agent\ncommunication topologies. Despite the diverse and high-performing designs\navailable, practitioners often face confusion when selecting the most effective\npipeline for their specific task: \\textit{Which topology is the best choice for\nmy task, avoiding unnecessary communication token overhead while ensuring\nhigh-quality solution?} In response to this dilemma, we introduce G-Designer,\nan adaptive, efficient, and robust solution for multi-agent deployment, which\ndynamically designs task-aware, customized communication topologies.\nSpecifically, G-Designer models the multi-agent system as a multi-agent\nnetwork, leveraging a variational graph auto-encoder to encode both the nodes\n(agents) and a task-specific virtual node, and decodes a task-adaptive and\nhigh-performing communication topology. Extensive experiments on six benchmarks\nshowcase that G-Designer is: \\textbf{(1) high-performing}, achieving superior\nresults on MMLU with accuracy at $84.50\\%$ and on HumanEval with pass@1 at\n$89.90\\%$; \\textbf{(2) task-adaptive}, architecting communication protocols\ntailored to task difficulty, reducing token consumption by up to $95.33\\%$ on\nHumanEval; and \\textbf{(3) adversarially robust}, defending against agent\nadversarial attacks with merely $0.3\\%$ accuracy drop.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.11782v2"
    },
    {
        "title": "Using Protected Attributes to Consider Fairness in Multi-Agent Systems",
        "authors": [
            "Gabriele La Malfa",
            "Jie M. Zhang",
            "Michael Luck",
            "Elizabeth Black"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Fairness in Multi-Agent Systems (MAS) has been extensively studied,\nparticularly in reward distribution among agents in scenarios such as goods\nallocation, resource division, lotteries, and bargaining systems. Fairness in\nMAS depends on various factors, including the system's governing rules, the\nbehaviour of the agents, and their characteristics. Yet, fairness in human\nsociety often involves evaluating disparities between disadvantaged and\nprivileged groups, guided by principles of Equality, Diversity, and Inclusion\n(EDI). Taking inspiration from the work on algorithmic fairness, which\naddresses bias in machine learning-based decision-making, we define protected\nattributes for MAS as characteristics that should not disadvantage an agent in\nterms of its expected rewards. We adapt fairness metrics from the algorithmic\nfairness literature -- namely, demographic parity, counterfactual fairness, and\nconditional statistical parity -- to the multi-agent setting, where\nself-interested agents interact within an environment. These metrics allow us\nto evaluate the fairness of MAS, with the ultimate aim of designing MAS that do\nnot disadvantage agents based on protected attributes.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.12889v1"
    },
    {
        "title": "A Semi-decentralized and Variational-Equilibrium-Based Trajectory\n  Planner for Connected and Autonomous Vehicles",
        "authors": [
            "Zhengqin Liu",
            "Jinlong Lei",
            "Peng Yi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper designs a novel trajectory planning approach to resolve the\ncomputational efficiency and safety problems in uncoordinated methods by\nexploiting vehicle-to-everything (V2X) technology. The trajectory planning for\nconnected and autonomous vehicles (CAVs) is formulated as a game with coupled\nsafety constraints. We then define interaction-fair trajectories and prove that\nthey correspond to the variational equilibrium (VE) of this game. We propose a\nsemi-decentralized planner for the vehicles to seek VE-based fair trajectories,\nwhich can significantly improve computational efficiency through parallel\ncomputing among CAVs and enhance the safety of planned trajectories by ensuring\nequilibrium concordance among CAVs. Finally, experimental results show the\nadvantages of the approach, including fast computation speed, high scalability,\nequilibrium concordance, and safety.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.15394v1"
    },
    {
        "title": "NetSafe: Exploring the Topological Safety of Multi-agent Networks",
        "authors": [
            "Miao Yu",
            "Shilong Wang",
            "Guibin Zhang",
            "Junyuan Mao",
            "Chenlong Yin",
            "Qijiong Liu",
            "Qingsong Wen",
            "Kun Wang",
            "Yang Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large language models (LLMs) have empowered nodes within multi-agent networks\nwith intelligence, showing growing applications in both academia and industry.\nHowever, how to prevent these networks from generating malicious information\nremains unexplored with previous research on single LLM's safety be challenging\nto transfer. In this paper, we focus on the safety of multi-agent networks from\na topological perspective, investigating which topological properties\ncontribute to safer networks. To this end, we propose a general framework,\nNetSafe along with an iterative RelCom interaction to unify existing diverse\nLLM-based agent frameworks, laying the foundation for generalized topological\nsafety research. We identify several critical phenomena when multi-agent\nnetworks are exposed to attacks involving misinformation, bias, and harmful\ninformation, termed as Agent Hallucination and Aggregation Safety. Furthermore,\nwe find that highly connected networks are more susceptible to the spread of\nadversarial attacks, with task performance in a Star Graph Topology decreasing\nby 29.7%. Besides, our proposed static metrics aligned more closely with\nreal-world dynamic evaluations than traditional graph-theoretic metrics,\nindicating that networks with greater average distances from attackers exhibit\nenhanced safety. In conclusion, our work introduces a new topological\nperspective on the safety of LLM-based multi-agent networks and discovers\nseveral unreported phenomena, paving the way for future research to explore the\nsafety of such networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.15686v1"
    },
    {
        "title": "PyTSC: A Unified Platform for Multi-Agent Reinforcement Learning in\n  Traffic Signal Control",
        "authors": [
            "Rohit Bokade",
            "Xiaoning Jin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) presents a promising approach for\naddressing the complexity of Traffic Signal Control (TSC) in urban\nenvironments. However, existing platforms for MARL-based TSC research face\nchallenges such as slow simulation speeds and convoluted, difficult-to-maintain\ncodebases. To address these limitations, we introduce PyTSC, a robust and\nflexible simulation environment that facilitates the training and evaluation of\nMARL algorithms for TSC. PyTSC integrates multiple simulators, such as SUMO and\nCityFlow, and offers a streamlined API, empowering researchers to explore a\nbroad spectrum of MARL approaches efficiently. PyTSC accelerates\nexperimentation and provides new opportunities for advancing intelligent\ntraffic management systems in real-world applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.18202v1"
    },
    {
        "title": "The Sound of Silence in Social Networks",
        "authors": [
            "Jesús Aranda",
            "Juan Francisco Díaz",
            "David Gaona",
            "Frank Valencia"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We generalize the classic multi-agent DeGroot model for opinion dynamics to\nincorporate the Spiral of Silence theory from political science. This theory\nstates that individuals may withhold their opinions when they perceive them to\nbe in the minority. As in the DeGroot model, a community of agents is\nrepresented as a weighted directed graph whose edges indicate how much agents\ninfluence one another. However, agents whose current opinions are in the\nminority become silent (i.e., they do not express their opinion). Two models\nfor opinion update are then introduced. In the memoryless opinion model\n($\\mbox{SOM}^-$), agents update their opinion by taking the weighted average of\ntheir non-silent neighbors' opinions. In the memory based opinion model\n($\\mbox{SOM}^+$), agents update their opinions by taking the weighted average\nof the opinions of all their neighbors, but for silent neighbors, their most\nrecent opinion is considered.\n  We show that for $\\mbox{SOM}^-$ convergence to consensus is guaranteed for\nclique graphs but, unlike for the classic DeGroot, not guaranteed for\nstrongly-connected aperiodic graphs. In contrast, we show that for\n$\\mbox{SOM}^+$ convergence to consensus is not guaranteed even for clique\ngraphs. We showcase our models through simulations offering experimental\ninsights that align with key aspects of the Spiral of Silence theory. These\nfindings reveal the impact of silence dynamics on opinion formation and\nhighlight the limitations of consensus in more nuanced social models.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.19685v1"
    },
    {
        "title": "OpenCity: A Scalable Platform to Simulate Urban Activities with Massive\n  LLM Agents",
        "authors": [
            "Yuwei Yan",
            "Qingbin Zeng",
            "Zhiheng Zheng",
            "Jingzhe Yuan",
            "Jie Feng",
            "Jun Zhang",
            "Fengli Xu",
            "Yong Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Agent-based models (ABMs) have long been employed to explore how individual\nbehaviors aggregate into complex societal phenomena in urban space. Unlike\nblack-box predictive models, ABMs excel at explaining the micro-macro linkages\nthat drive such emergent behaviors. The recent rise of Large Language Models\n(LLMs) has led to the development of LLM agents capable of simulating urban\nactivities with unprecedented realism. However, the extreme high computational\ncost of LLMs presents significant challenges for scaling up the simulations of\nLLM agents. To address this problem, we propose OpenCity, a scalable simulation\nplatform optimized for both system and prompt efficiencies. Specifically, we\npropose a LLM request scheduler to reduce communication overhead by\nparallelizing requests through IO multiplexing. Besides, we deisgn a\n\"group-and-distill\" prompt optimization strategy minimizes redundancy by\nclustering agents with similar static attributes. Through experiments on six\nglobal cities, OpenCity achieves a 600-fold acceleration in simulation time per\nagent, a 70% reduction in LLM requests, and a 50% reduction in token usage.\nThese improvements enable the simulation of 10,000 agents' daily activities in\n1 hour on commodity hardware. Besides, the substantial speedup of OpenCity\nallows us to establish a urban simulation benchmark for LLM agents for the\nfirst time, comparing simulated urban activities with real-world data in 6\nmajor cities around the globe. We believe our OpenCity platform provides a\ncritical infrastructure to harness the power of LLMs for interdisciplinary\nstudies in urban space, fostering the collective efforts of broader research\ncommunities. Code repo is available at\nhttps://anonymous.4open.science/r/Anonymous-OpenCity-42BD.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.21286v1"
    },
    {
        "title": "Heterogeneous Interaction Modeling With Reduced Accumulated Error for\n  Multi-Agent Trajectory Prediction",
        "authors": [
            "Siyuan Chen",
            "Jiahai Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Dynamical complex systems composed of interactive heterogeneous agents are\nprevalent in the world, including urban traffic systems and social networks.\nModeling the interactions among agents is the key to understanding and\npredicting the dynamics of the complex system, e.g., predicting the\ntrajectories of traffic participants in the city. Compared with interaction\nmodeling in homogeneous systems such as pedestrians in a crowded scene,\nheterogeneous interaction modeling is less explored. Worse still, the error\naccumulation problem becomes more severe since the interactions are more\ncomplex. To tackle the two problems, this paper proposes heterogeneous\ninteraction modeling with reduced accumulated error for multi-agent trajectory\nprediction. Based on the historical trajectories, our method infers the dynamic\ninteraction graphs among agents, featured by directed interacting relations and\ninteracting effects. A heterogeneous attention mechanism is defined on the\ninteraction graphs for aggregating the influence from heterogeneous neighbors\nto the target agent. To alleviate the error accumulation problem, this paper\nanalyzes the error sources from the spatial and temporal perspectives, and\nproposes to introduce the graph entropy and the mixup training strategy for\nreducing the two types of errors respectively. Our method is examined on three\nreal-world datasets containing heterogeneous agents, and the experimental\nresults validate the superiority of our method.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.21342v1"
    },
    {
        "title": "Soft Condorcet Optimization for Ranking of General Agents",
        "authors": [
            "Marc Lanctot",
            "Kate Larson",
            "Michael Kaisers",
            "Quentin Berthet",
            "Ian Gemp",
            "Manfred Diaz",
            "Roberto-Rafael Maura-Rivero",
            "Yoram Bachrach",
            "Anna Koop",
            "Doina Precup"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  A common way to drive progress of AI models and agents is to compare their\nperformance on standardized benchmarks. Comparing the performance of general\nagents requires aggregating their individual performances across a potentially\nwide variety of different tasks. In this paper, we describe a novel ranking\nscheme inspired by social choice frameworks, called Soft Condorcet Optimization\n(SCO), to compute the optimal ranking of agents: the one that makes the fewest\nmistakes in predicting the agent comparisons in the evaluation data. This\noptimal ranking is the maximum likelihood estimate when evaluation data (which\nwe view as votes) are interpreted as noisy samples from a ground truth ranking,\na solution to Condorcet's original voting system criteria. SCO ratings are\nmaximal for Condorcet winners when they exist, which we show is not necessarily\ntrue for the classical rating system Elo. We propose three optimization\nalgorithms to compute SCO ratings and evaluate their empirical performance.\nWhen serving as an approximation to the Kemeny-Young voting method, SCO\nrankings are on average 0 to 0.043 away from the optimal ranking in normalized\nKendall-tau distance across 865 preference profiles from the PrefLib open\nranking archive. In a simulated noisy tournament setting, SCO achieves accurate\napproximations to the ground truth ranking and the best among several baselines\nwhen 59\\% or more of the preference data is missing. Finally, SCO ranking\nprovides the best approximation to the optimal ranking, measured on held-out\ntest sets, in a problem containing 52,958 human players across 31,049 games of\nthe classic seven-player game of Diplomacy.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.00119v2"
    },
    {
        "title": "Measuring Responsibility in Multi-Agent Systems",
        "authors": [
            "Chunyan Mu",
            "Nir Oren"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We introduce a family of quantitative measures of responsibility in\nmulti-agent planning, building upon the concepts of causal responsibility\nproposed by Parker et al.~[ParkerGL23]. These concepts are formalised within a\nvariant of probabilistic alternating-time temporal logic. Unlike existing\napproaches, our framework ascribes responsibility to agents for a given outcome\nby linking probabilities between behaviours and responsibility through three\nmetrics, including an entropy-based measurement of responsibility. This latter\nmeasure is the first to capture the causal responsibility properties of\noutcomes over time, offering an asymptotic measurement that reflects the\ndifficulty of achieving these outcomes. Our approach provides a fresh\nunderstanding of responsibility in multi-agent systems, illuminating both the\nqualitative and quantitative aspects of agents' roles in achieving or\npreventing outcomes.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.00887v1"
    },
    {
        "title": "Integration of Large Vision Language Models for Efficient Post-disaster\n  Damage Assessment and Reporting",
        "authors": [
            "Zhaohui Chen",
            "Elyas Asadi Shamsabadi",
            "Sheng Jiang",
            "Luming Shen",
            "Daniel Dias-da-Costa"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Traditional natural disaster response involves significant coordinated\nteamwork where speed and efficiency are key. Nonetheless, human limitations can\ndelay critical actions and inadvertently increase human and economic losses.\nAgentic Large Vision Language Models (LVLMs) offer a new avenue to address this\nchallenge, with the potential for substantial socio-economic impact,\nparticularly by improving resilience and resource access in underdeveloped\nregions. We introduce DisasTeller, the first multi-LVLM-powered framework\ndesigned to automate tasks in post-disaster management, including on-site\nassessment, emergency alerts, resource allocation, and recovery planning. By\ncoordinating four specialised LVLM agents with GPT-4 as the core model,\nDisasTeller autonomously implements disaster response activities, reducing\nhuman execution time and optimising resource distribution. Our evaluations\nthrough both LVLMs and humans demonstrate DisasTeller's effectiveness in\nstreamlining disaster response. This framework not only supports expert teams\nbut also simplifies access to disaster management processes for non-experts,\nbridging the gap between traditional response methods and LVLM-driven\nefficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.01511v1"
    },
    {
        "title": "Data-Driven Distributed Common Operational Picture from Heterogeneous\n  Platforms using Multi-Agent Reinforcement Learning",
        "authors": [
            "Indranil Sur",
            "Aswin Raghavan",
            "Abrar Rahman",
            "James Z Hare",
            "Daniel Cassenti",
            "Carl Busart"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The integration of unmanned platforms equipped with advanced sensors promises\nto enhance situational awareness and mitigate the \"fog of war\" in military\noperations. However, managing the vast influx of data from these platforms\nposes a significant challenge for Command and Control (C2) systems. This study\npresents a novel multi-agent learning framework to address this challenge. Our\nmethod enables autonomous and secure communication between agents and humans,\nwhich in turn enables real-time formation of an interpretable Common\nOperational Picture (COP). Each agent encodes its perceptions and actions into\ncompact vectors, which are then transmitted, received and decoded to form a COP\nencompassing the current state of all agents (friendly and enemy) on the\nbattlefield. Using Deep Reinforcement Learning (DRL), we jointly train COP\nmodels and agent's action selection policies. We demonstrate resilience to\ndegraded conditions such as denied GPS and disrupted communications.\nExperimental validation is performed in the Starcraft-2 simulation environment\nto evaluate the precision of the COPs and robustness of policies. We report\nless than 5% error in COPs and policies resilient to various adversarial\nconditions. In summary, our contributions include a method for autonomous COP\nformation, increased resilience through distributed prediction, and joint\ntraining of COP models and multi-agent RL policies. This research advances\nadaptive and resilient C2, facilitating effective control of heterogeneous\nunmanned platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05683v1"
    },
    {
        "title": "Learning Collective Dynamics of Multi-Agent Systems using Event-based\n  Vision",
        "authors": [
            "Minah Lee",
            "Uday Kamal",
            "Saibal Mukhopadhyay"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper proposes a novel problem: vision-based perception to learn and\npredict the collective dynamics of multi-agent systems, specifically focusing\non interaction strength and convergence time. Multi-agent systems are defined\nas collections of more than ten interacting agents that exhibit complex group\nbehaviors. Unlike prior studies that assume knowledge of agent positions, we\nfocus on deep learning models to directly predict collective dynamics from\nvisual data, captured as frames or events. Due to the lack of relevant\ndatasets, we create a simulated dataset using a state-of-the-art flocking\nsimulator, coupled with a vision-to-event conversion framework. We empirically\ndemonstrate the effectiveness of event-based representation over traditional\nframe-based methods in predicting these collective behaviors. Based on our\nanalysis, we present event-based vision for Multi-Agent dynamic Prediction\n(evMAP), a deep learning architecture designed for real-time, accurate\nunderstanding of interaction strength and collective behavior emergence in\nmulti-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.07039v1"
    },
    {
        "title": "RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent\n  Collaboration",
        "authors": [
            "Young-Min Cho",
            "Raphael Shu",
            "Nilaksh Das",
            "Tamer Alkhouli",
            "Yi-An Lai",
            "Jason Cai",
            "Monica Sunkara",
            "Yi Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This study investigates the efficacy of Multi-Agent Systems in eliciting\ncross-agent communication and enhancing collective intelligence through group\ndecision-making in a decentralized setting. Unlike centralized mechanisms,\nwhere a fixed hierarchy governs social choice, decentralized group\ndecision-making allows agents to engage in joint deliberation. Our research\nfocuses on the dynamics of communication and decision-making within various\nsocial choice methods. By applying different voting rules in various\nenvironments, we find that moderate decision flexibility yields better\noutcomes. Additionally, exploring the linguistic features of agent-to-agent\nconversations reveals indicators of effective collaboration, offering insights\ninto communication patterns that facilitate or hinder collaboration. Finally,\nwe propose various methods for determining the optimal stopping point in\nmulti-agent collaborations based on linguistic cues. Our findings contribute to\na deeper understanding of how decentralized decision-making and group\nconversation shape multi-agent collaboration, with implications for the design\nof more effective MAS environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.07161v1"
    },
    {
        "title": "Evaluating Creativity and Deception in Large Language Models: A\n  Simulation Framework for Multi-Agent Balderdash",
        "authors": [
            "Parsa Hejabi",
            "Elnaz Rahmati",
            "Alireza S. Ziabari",
            "Preni Golazizian",
            "Jesse Thomason",
            "Morteza Dehghani"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large Language Models (LLMs) have shown impressive capabilities in complex\ntasks and interactive environments, yet their creativity remains underexplored.\nThis paper introduces a simulation framework utilizing the game Balderdash to\nevaluate both the creativity and logical reasoning of LLMs. In Balderdash,\nplayers generate fictitious definitions for obscure terms to deceive others\nwhile identifying correct definitions. Our framework enables multiple LLM\nagents to participate in this game, assessing their ability to produce\nplausible definitions and strategize based on game rules and history. We\nimplemented a centralized game engine featuring various LLMs as participants\nand a judge LLM to evaluate semantic equivalence. Through a series of\nexperiments, we analyzed the performance of different LLMs, examining metrics\nsuch as True Definition Ratio, Deception Ratio, and Correct Guess Ratio. The\nresults provide insights into the creative and deceptive capabilities of LLMs,\nhighlighting their strengths and areas for improvement. Specifically, the study\nreveals that infrequent vocabulary in LLMs' input leads to poor reasoning on\ngame rules and historical context\n(https://github.com/ParsaHejabi/Simulation-Framework-for-Multi-Agent-Balderdash).\n",
        "pdf_link": "http://arxiv.org/pdf/2411.10422v1"
    },
    {
        "title": "Evolutionary Multi-agent Reinforcement Learning in Group Social Dilemmas",
        "authors": [
            "Brian Mintz",
            "Feng Fu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Reinforcement learning (RL) is a powerful machine learning technique that has\nbeen successfully applied to a wide variety of problems. However, it can be\nunpredictable and produce suboptimal results in complicated learning\nenvironments. This is especially true when multiple agents learn\nsimultaneously, which creates a complex system that is often analytically\nintractable. Our work considers the fundamental framework of Q-learning in\nPublic Goods Games, where RL individuals must work together to achieve a common\ngoal. This setting allows us to study the tragedy of the commons and free rider\neffects in AI cooperation, an emerging field with potential to resolve\nchallenging obstacles to the wider application of artificial intelligence.\nWhile this social dilemma has been mainly investigated through traditional and\nevolutionary game theory, our approach bridges the gap between these two by\nstudying agents with an intermediate level of intelligence. Specifically, we\nconsider the influence of learning parameters on cooperation levels in\nsimulations and a limiting system of differential equations, as well as the\neffect of evolutionary pressures on exploration rate in both of these models.\nWe find selection for higher and lower levels of exploration, as well as\nattracting values, and a condition that separates these in a restricted class\nof games. Our work enhances the theoretical understanding of evolutionary\nQ-learning, and extends our knowledge of the evolution of machine behavior in\nsocial dilemmas.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.10459v1"
    },
    {
        "title": "Creative Agents: Simulating the Systems Model of Creativity with\n  Generative Agents",
        "authors": [
            "Naomi Imasato",
            "Kazuki Miyazawa",
            "Takayuki Nagai",
            "Takato Horii"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the growing popularity of generative AI for images, video, and music, we\nwitnessed models rapidly improve in quality and performance. However, not much\nattention is paid towards enabling AI's ability to \"be creative\". In this\nstudy, we implemented and simulated the systems model of creativity (proposed\nby Csikszentmihalyi) using virtual agents utilizing large language models\n(LLMs) and text prompts. For comparison, the simulations were conducted with\nthe \"virtual artists\" being: 1)isolated and 2)placed in a multi-agent system.\nBoth scenarios were compared by analyzing the variations and overall\n\"creativity\" in the generated artifacts (measured via a user study and LLM).\nOur results suggest that the generative agents may perform better in the\nframework of the systems model of creativity.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.17065v1"
    },
    {
        "title": "Exploration of LLM Multi-Agent Application Implementation Based on\n  LangGraph+CrewAI",
        "authors": [
            "Zhihua Duan",
            "Jialin Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the rapid development of large model technology, the application of\nagent technology in various fields is becoming increasingly widespread,\nprofoundly changing people's work and lifestyles. In complex and dynamic\nsystems, multi-agents achieve complex tasks that are difficult for a single\nagent to complete through division of labor and collaboration among agents.\nThis paper discusses the integrated application of LangGraph and CrewAI.\nLangGraph improves the efficiency of information transmission through graph\narchitecture, while CrewAI enhances team collaboration capabilities and system\nperformance through intelligent task allocation and resource management. The\nmain research contents of this paper are: (1) designing the architecture of\nagents based on LangGraph for precise control; (2) enhancing the capabilities\nof agents based on CrewAI to complete a variety of tasks. This study aims to\ndelve into the application of LangGraph and CrewAI in multi-agent systems,\nproviding new perspectives for the future development of agent technology, and\npromoting technological progress and application innovation in the field of\nlarge model intelligent agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.18241v1"
    },
    {
        "title": "Collective decision making by embodied neural agents",
        "authors": [
            "Nicolas Coucke",
            "Mary Katherine Heinrich",
            "Axel Cleeremans",
            "Marco Dorigo",
            "Guillaume Dumas"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Collective decision making using simple social interactions has been studied\nin many types of multi-agent systems, including robot swarms and human social\nnetworks. However, existing multi-agent studies have rarely modeled the neural\ndynamics that underlie sensorimotor coordination in embodied biological agents.\nIn this study, we investigated collective decisions that resulted from\nsensorimotor coordination among agents with simple neural dynamics. We equipped\nour agents with a model of minimal neural dynamics based on the coordination\ndynamics framework, and embedded them in an environment with a stimulus\ngradient. In our single-agent setup, the decision between two stimulus sources\ndepends solely on the coordination of the agent's neural dynamics with its\nenvironment. In our multi-agent setup, that same decision also depends on the\nsensorimotor coordination between agents, via their simple social interactions.\nOur results show that the success of collective decisions depended on a balance\nof intra-agent, inter-agent, and agent-environment coupling, and we use these\nresults to identify the influences of environmental factors on decision\ndifficulty. More generally, our results demonstrate the impact of intra- and\ninter-brain coordination dynamics on collective behavior, can contribute to\nexisting knowledge on the functional role of inter-agent synchrony, and are\nrelevant to ongoing developments in neuro-AI and self-organized multi-agent\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.18498v1"
    },
    {
        "title": "Streamlining the Action Dependency Graph Framework: Two Key Enhancements",
        "authors": [
            "Joachim Dunkel"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi Agent Path Finding (MAPF) is critical for coordinating multiple robots\nin shared environments, yet robust execution of generated plans remains\nchallenging due to operational uncertainties. The Action Dependency Graph (ADG)\nframework offers a way to ensure correct action execution by establishing\nprecedence-based dependencies between wait and move actions retrieved from a\nMAPF planning result. The original construction algorithm is not only\ninefficient, with a quadratic worst-case time complexity it also results in a\nnetwork with many redundant dependencies between actions. This paper introduces\ntwo key improvements to the ADG framework. First, we prove that wait actions\nare generally redundant and show that removing them can lead to faster overall\nplan execution on real robot systems. Second, we propose an optimized ADG\nconstruction algorithm, termed Sparse Candidate Partitioning (SCP), which skips\nunnecessary dependencies and lowers the time complexity to quasi-linear,\nthereby significantly improving construction speed.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.01277v1"
    },
    {
        "title": "Evolution of Collective AI Beyond Individual Optimization",
        "authors": [
            "Ryosuke Takata",
            "Yujin Tang",
            "Yingtao Tian",
            "Norihiro Maruyama",
            "Hiroki Kojima",
            "Takashi Ikegami"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This study investigates collective behaviors that emerge from a group of\nhomogeneous individuals optimized for a specific capability. We created a group\nof simple, identical neural network based agents modeled after\nchemotaxis-driven vehicles that follow pheromone trails and examined\nmulti-agent simulations using clones of these evolved individuals. Our results\nshow that the evolution of individuals led to population differentiation.\nSurprisingly, we observed that collective fitness significantly changed during\nlater evolutionary stages, despite maintained high individual performance and\nsimplified neural architectures. This decline occurred when agents developed\nreduced sensor-motor coupling, suggesting that over-optimization of individual\nagents almost always lead to less effective group behavior. Our research\ninvestigates how individual differentiation can evolve through what\nevolutionary pathways.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.02085v1"
    },
    {
        "title": "Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution",
        "authors": [
            "Tomer Jordi Chaffer",
            "Justin Goldston",
            "Gemach D. A. T. A. I"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Cooperation is vital to our survival and progress. Evolutionary game theory\noffers a lens to understand the structures and incentives that enable\ncooperation to be a successful strategy. As artificial intelligence agents\nbecome integral to human systems, the dynamics of cooperation take on\nunprecedented significance. The convergence of human-agent teaming, contract\ntheory, and decentralized frameworks like Web3, grounded in transparency,\naccountability, and trust, offers a foundation for fostering cooperation by\nestablishing enforceable rules and incentives for humans and AI agents. We\nconceptualize Incentivized Symbiosis as a social contract between humans and\nAI, inspired by Web3 principles and encoded in blockchain technology, to define\nand enforce rules, incentives, and consequences for both parties. By exploring\nthis paradigm, we aim to catalyze new research at the intersection of systems\nthinking in AI, Web3, and society, fostering innovative pathways for\ncooperative human-agent coevolution.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.06855v3"
    },
    {
        "title": "Heterogeneous Multi-Robot Graph Coverage with Proximity and Movement\n  Constraints",
        "authors": [
            "Dolev Mutzari",
            "Yonatan Aumann",
            "Sarit Kraus"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Robot Coverage problems have been extensively studied in robotics,\nplanning and multi-agent systems. In this work, we consider the coverage\nproblem when there are constraints on the proximity (e.g., maximum distance\nbetween the agents, or a blue agent must be adjacent to a red agent) and the\nmovement (e.g., terrain traversability and material load capacity) of the\nrobots. Such constraints naturally arise in many real-world applications, e.g.\nin search-and-rescue and maintenance operations. Given such a setting, the goal\nis to compute a covering tour of the graph with a minimum number of steps, and\nthat adheres to the proximity and movement constraints. For this problem, our\ncontributions are four: (i) a formal formulation of the problem, (ii) an exact\nalgorithm that is FPT in F, d and tw, the set of robot formations that encode\nthe proximity constraints, the maximum nodes degree, and the tree-width of the\ngraph, respectively, (iii) for the case that the graph is a tree: a PTAS\napproximation scheme, that given an approximation parameter epsilon, produces a\ntour that is within a epsilon times error(||F||, d) of the optimal one, and the\ncomputation runs in time poly(n) times h(1/epsilon,||F||). (iv) for the case\nthat the graph is a tree, with $k=3$ robots, and the constraint is that all\nagents are connected: a PTAS scheme with multiplicative approximation error of\n1+O(epsilon), independent of the maximal degree d.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.10083v2"
    },
    {
        "title": "Cultural Evolution of Cooperation among LLM Agents",
        "authors": [
            "Aron Vallinder",
            "Edward Hughes"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large language models (LLMs) provide a compelling foundation for building\ngenerally-capable AI agents. These agents may soon be deployed at scale in the\nreal world, representing the interests of individual humans (e.g., AI\nassistants) or groups of humans (e.g., AI-accelerated corporations). At\npresent, relatively little is known about the dynamics of multiple LLM agents\ninteracting over many generations of iterative deployment. In this paper, we\nexamine whether a \"society\" of LLM agents can learn mutually beneficial social\nnorms in the face of incentives to defect, a distinctive feature of human\nsociality that is arguably crucial to the success of civilization. In\nparticular, we study the evolution of indirect reciprocity across generations\nof LLM agents playing a classic iterated Donor Game in which agents can observe\nthe recent behavior of their peers. We find that the evolution of cooperation\ndiffers markedly across base models, with societies of Claude 3.5 Sonnet agents\nachieving significantly higher average scores than Gemini 1.5 Flash, which, in\nturn, outperforms GPT-4o. Further, Claude 3.5 Sonnet can make use of an\nadditional mechanism for costly punishment to achieve yet higher scores, while\nGemini 1.5 Flash and GPT-4o fail to do so. For each model class, we also\nobserve variation in emergent behavior across random seeds, suggesting an\nunderstudied sensitive dependence on initial conditions. We suggest that our\nevaluation regime could inspire an inexpensive and informative new class of LLM\nbenchmarks, focussed on the implications of LLM agent deployment for the\ncooperative infrastructure of society.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.10270v1"
    },
    {
        "title": "Loosely Synchronized Rule-Based Planning for Multi-Agent Path Finding\n  with Asynchronous Actions",
        "authors": [
            "Shuai Zhou",
            "Shizhe Zhao",
            "Zhongqiang Ren"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Path Finding (MAPF) seeks collision-free paths for multiple\nagents from their respective starting locations to their respective goal\nlocations while minimizing path costs. Although many MAPF algorithms were\ndeveloped and can handle up to thousands of agents, they usually rely on the\nassumption that each action of the agent takes a time unit, and the actions of\nall agents are synchronized in a sense that the actions of agents start at the\nsame discrete time step, which may limit their use in practice. Only a few\nalgorithms were developed to address asynchronous actions, and they all lie on\none end of the spectrum, focusing on finding optimal solutions with limited\nscalability. This paper develops new planners that lie on the other end of the\nspectrum, trading off solution quality for scalability, by finding an unbounded\nsub-optimal solution for many agents. Our method leverages both search methods\n(LSS) in handling asynchronous actions and rule-based planning methods (PIBT)\nfor MAPF. We analyze the properties of our method and test it against several\nbaselines with up to 1000 agents in various maps. Given a runtime limit, our\nmethod can handle an order of magnitude more agents than the baselines with\nabout 25% longer makespan.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.11678v2"
    },
    {
        "title": "Heuristic Planner for Communication-Constrained Multi-Agent Multi-Goal\n  Path Planning",
        "authors": [
            "Jáchym Herynek",
            "Stefan Edelkamp"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In robotics, coordinating a group of robots is an essential task. This work\npresents the communication-constrained multi-agent multi-goal path planning\nproblem and proposes a graph-search based algorithm to address this task. Given\na fleet of robots, an environment represented by a weighted graph, and a\nsequence of goals, the aim is to visit all the goals without breaking the\ncommunication constraints between the agents, minimizing the completion time.\nThe resulting paths produced by our approach show how the agents can coordinate\ntheir individual paths, not only with respect to the next goal but also with\nrespect to all future goals, all the time keeping the communication within the\nfleet intact.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.13719v1"
    },
    {
        "title": "Adaptive Urban Planning: A Hybrid Framework for Balanced City\n  Development",
        "authors": [
            "Pratham Singla",
            "Ayush Singh",
            "Adesh Gupta",
            "Shivank Garg"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Urban planning faces a critical challenge in balancing city-wide\ninfrastructure needs with localized demographic preferences, particularly in\nrapidly developing regions. Although existing approaches typically focus on\ntop-down optimization or bottom-up community planning, only some frameworks\nsuccessfully integrate both perspectives. Our methodology employs a two-tier\napproach: First, a deterministic solver optimizes basic infrastructure\nrequirements in the city region. Second, four specialized planning agents, each\nrepresenting distinct sub-regions, propose demographic-specific modifications\nto a master planner. The master planner then evaluates and integrates these\nsuggestions to ensure cohesive urban development. We validate our framework\nusing a newly created dataset comprising detailed region and sub-region maps\nfrom three developing cities in India, focusing on areas undergoing rapid\nurbanization. The results demonstrate that this hybrid approach enables more\nnuanced urban development while maintaining overall city functionality.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15349v1"
    },
    {
        "title": "An Agent-based Model for Competitive Agents",
        "authors": [
            "Mohammad Daneshvar",
            "Mandana Delavari"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper, we analyze the behavior of a multi-agent system driven by the\ninteractions of agents within a competitive environment. To achieve this, we\ndescribe the transition probabilities that underlie the system's stochastic\nnature. We also derive the Fokker-Planck equations for the density distribution\nof the number of agents in the system and solve these equations for specific\ncases.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15485v1"
    },
    {
        "title": "Multi Agent Reinforcement Learning for Sequential Satellite Assignment\n  Problems",
        "authors": [
            "Joshua Holder",
            "Natasha Jaques",
            "Mehran Mesbahi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Assignment problems are a classic combinatorial optimization problem in which\na group of agents must be assigned to a group of tasks such that maximum\nutility is achieved while satisfying assignment constraints. Given the utility\nof each agent completing each task, polynomial-time algorithms exist to solve a\nsingle assignment problem in its simplest form. However, in many modern-day\napplications such as satellite constellations, power grids, and mobile robot\nscheduling, assignment problems unfold over time, with the utility for a given\nassignment depending heavily on the state of the system. We apply multi-agent\nreinforcement learning to this problem, learning the value of assignments by\nbootstrapping from a known polynomial-time greedy solver and then learning from\nfurther experience. We then choose assignments using a distributed optimal\nassignment mechanism rather than by selecting them directly. We demonstrate\nthat this algorithm is theoretically justified and avoids pitfalls experienced\nby other RL algorithms in this setting. Finally, we show that our algorithm\nsignificantly outperforms other methods in the literature, even while scaling\nto realistic scenarios with hundreds of agents and tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15573v1"
    },
    {
        "title": "M2I2: Learning Efficient Multi-Agent Communication via Masked State\n  Modeling and Intention Inference",
        "authors": [
            "Chuxiong Sun",
            "Peng He",
            "Qirui Ji",
            "Zehua Zang",
            "Jiangmeng Li",
            "Rui Wang",
            "Wei Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Communication is essential in coordinating the behaviors of multiple agents.\nHowever, existing methods primarily emphasize content, timing, and partners for\ninformation sharing, often neglecting the critical aspect of integrating shared\ninformation. This gap can significantly impact agents' ability to understand\nand respond to complex, uncertain interactions, thus affecting overall\ncommunication efficiency. To address this issue, we introduce M2I2, a novel\nframework designed to enhance the agents' capabilities to assimilate and\nutilize received information effectively. M2I2 equips agents with advanced\ncapabilities for masked state modeling and joint-action prediction, enriching\ntheir perception of environmental uncertainties and facilitating the\nanticipation of teammates' intentions. This approach ensures that agents are\nfurnished with both comprehensive and relevant information, bolstering more\ninformed and synergistic behaviors. Moreover, we propose a Dimensional Rational\nNetwork, innovatively trained via a meta-learning paradigm, to identify the\nimportance of dimensional pieces of information, evaluating their contributions\nto decision-making and auxiliary tasks. Then, we implement an importance-based\nheuristic for selective information masking and sharing. This strategy\noptimizes the efficiency of masked state modeling and the rationale behind\ninformation sharing. We evaluate M2I2 across diverse multi-agent tasks, the\nresults demonstrate its superior performance, efficiency, and generalization\ncapabilities, over existing state-of-the-art methods in various complex\nscenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00312v1"
    },
    {
        "title": "PIMAEX: Multi-Agent Exploration through Peer Incentivization",
        "authors": [
            "Michael Kölle",
            "Johannes Tochtermann",
            "Julian Schönberger",
            "Gerhard Stenzel",
            "Philipp Altmann",
            "Claudia Linnhoff-Popien"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  While exploration in single-agent reinforcement learning has been studied\nextensively in recent years, considerably less work has focused on its\ncounterpart in multi-agent reinforcement learning. To address this issue, this\nwork proposes a peer-incentivized reward function inspired by previous research\non intrinsic curiosity and influence-based rewards. The \\textit{PIMAEX} reward,\nshort for Peer-Incentivized Multi-Agent Exploration, aims to improve\nexploration in the multi-agent setting by encouraging agents to exert influence\nover each other to increase the likelihood of encountering novel states. We\nevaluate the \\textit{PIMAEX} reward in conjunction with\n\\textit{PIMAEX-Communication}, a multi-agent training algorithm that employs a\ncommunication channel for agents to influence one another. The evaluation is\nconducted in the \\textit{Consume/Explore} environment, a partially observable\nenvironment with deceptive rewards, specifically designed to challenge the\nexploration vs.\\ exploitation dilemma and the credit-assignment problem. The\nresults empirically demonstrate that agents using the \\textit{PIMAEX} reward\nwith \\textit{PIMAEX-Communication} outperform those that do not.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.01266v1"
    },
    {
        "title": "CAMP: Collaborative Attention Model with Profiles for Vehicle Routing\n  Problems",
        "authors": [
            "Chuanbo Hua",
            "Federico Berto",
            "Jiwoo Son",
            "Seunghyun Kang",
            "Changhyun Kwon",
            "Jinkyoo Park"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  The profiled vehicle routing problem (PVRP) is a generalization of the\nheterogeneous capacitated vehicle routing problem (HCVRP) in which the\nobjective is to optimize the routes of vehicles to serve client demands subject\nto different vehicle profiles, with each having a preference or constraint on a\nper-client basis. While existing learning methods have shown promise for\nsolving the HCVRP in real-time, no learning method exists to solve the more\npractical and challenging PVRP. In this paper, we propose a Collaborative\nAttention Model with Profiles (CAMP), a novel approach that learns efficient\nsolvers for PVRP using multi-agent reinforcement learning. CAMP employs a\nspecialized attention-based encoder architecture to embed profiled client\nembeddings in parallel for each vehicle profile. We design a communication\nlayer between agents for collaborative decision-making across profiled\nembeddings at each decoding step and a batched pointer mechanism to attend to\nthe profiled embeddings to evaluate the likelihood of the next actions. We\nevaluate CAMP on two variants of PVRPs: PVRP with preferences, which explicitly\ninfluence the reward function, and PVRP with zone constraints with different\nnumbers of agents and clients, demonstrating that our learned solvers achieve\ncompetitive results compared to both classical state-of-the-art neural\nmulti-agent models in terms of solution quality and computational efficiency.\nWe make our code openly available at https://github.com/ai4co/camp.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.02977v1"
    },
    {
        "title": "CoDe: Communication Delay-Tolerant Multi-Agent Collaboration via Dual\n  Alignment of Intent and Timeliness",
        "authors": [
            "Shoucheng Song",
            "Youfang Lin",
            "Sheng Han",
            "Chang Yao",
            "Hao Wu",
            "Shuo Wang",
            "Kai Lv"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Communication has been widely employed to enhance multi-agent collaboration.\nPrevious research has typically assumed delay-free communication, a strong\nassumption that is challenging to meet in practice. However, real-world agents\nsuffer from channel delays, receiving messages sent at different time points,\ntermed {\\it{Asynchronous Communication}}, leading to cognitive biases and\nbreakdowns in collaboration. This paper first defines two communication delay\nsettings in MARL and emphasizes their harm to collaboration. To handle the\nabove delays, this paper proposes a novel framework, Communication\nDelay-tolerant Multi-Agent Collaboration (CoDe). At first, CoDe learns an\nintent representation as messages through future action inference, reflecting\nthe stable future behavioral trends of the agents. Then, CoDe devises a dual\nalignment mechanism of intent and timeliness to strengthen the fusion process\nof asynchronous messages. In this way, agents can extract the long-term intent\nof others, even from delayed messages, and selectively utilize the most recent\nmessages that are relevant to their intent. Experimental results demonstrate\nthat CoDe outperforms baseline algorithms in three MARL benchmarks without\ndelay and exhibits robustness under fixed and time-varying delays.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.05207v1"
    },
    {
        "title": "Scaling Safe Multi-Agent Control for Signal Temporal Logic\n  Specifications",
        "authors": [
            "Joe Eappen",
            "Zikang Xiong",
            "Dipam Patel",
            "Aniket Bera",
            "Suresh Jagannathan"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Existing methods for safe multi-agent control using logic specifications like\nSignal Temporal Logic (STL) often face scalability issues. This is because they\nrely either on single-agent perspectives or on Mixed Integer Linear Programming\n(MILP)-based planners, which are complex to optimize. These methods have proven\nto be computationally expensive and inefficient when dealing with a large\nnumber of agents. To address these limitations, we present a new scalable\napproach to multi-agent control in this setting. Our method treats the\nrelationships between agents using a graph structure rather than in terms of a\nsingle-agent perspective. Moreover, it combines a multi-agent collision\navoidance controller with a Graph Neural Network (GNN) based planner, models\nthe system in a decentralized fashion, and trains on STL-based objectives to\ngenerate safe and efficient plans for multiple agents, thereby optimizing the\nsatisfaction of complex temporal specifications while also facilitating\nmulti-agent collision avoidance. Our experiments show that our approach\nsignificantly outperforms existing methods that use a state-of-the-art\nMILP-based planner in terms of scalability and performance. The project website\nis https://jeappen.com/mastl-gcbf-website/ and the code is at\nhttps://github.com/jeappen/mastl-gcbf .\n",
        "pdf_link": "http://arxiv.org/pdf/2501.05639v1"
    },
    {
        "title": "Learning Flexible Heterogeneous Coordination with Capability-Aware\n  Shared Hypernetworks",
        "authors": [
            "Kevin Fu",
            "Pierce Howell",
            "Shalin Jain",
            "Harish Ravichandar"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Cooperative heterogeneous multi-agent tasks require agents to effectively\ncoordinate their behaviors while accounting for their relative capabilities.\nLearning-based solutions to this challenge span between two extremes: i)\nshared-parameter methods, which encode diverse behaviors within a single\narchitecture by assigning an ID to each agent, and are sample-efficient but\nresult in limited behavioral diversity; ii) independent methods, which learn a\nseparate policy for each agent, and show greater behavioral diversity but lack\nsample-efficiency. Prior work has also explored selective parameter-sharing,\nallowing for a compromise between diversity and efficiency. None of these\napproaches, however, effectively generalize to unseen agents or teams. We\npresent Capability-Aware Shared Hypernetworks (CASH), a novel architecture for\nheterogeneous multi-agent coordination that generates sufficient diversity\nwhile maintaining sample-efficiency via soft parameter-sharing hypernetworks.\nIntuitively, CASH allows the team to learn common strategies using a shared\nencoder, which are then adapted according to the team's individual and\ncollective capabilities with a hypernetwork, allowing for zero-shot\ngeneralization to unseen teams and agents. We present experiments across two\nheterogeneous coordination tasks and three standard learning paradigms\n(imitation learning, on- and off-policy reinforcement learning). CASH is able\nto outperform baseline architectures in success rate and sample efficiency when\nevaluated on unseen teams and agents despite using less than half of the\nlearnable parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.06058v1"
    },
    {
        "title": "Finite-Horizon Single-Pull Restless Bandits: An Efficient Index Policy\n  For Scarce Resource Allocation",
        "authors": [
            "Guojun Xiong",
            "Haichuan Wang",
            "Yuqi Pan",
            "Saptarshi Mandal",
            "Sanket Shah",
            "Niclas Boehmer",
            "Milind Tambe"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Restless multi-armed bandits (RMABs) have been highly successful in\noptimizing sequential resource allocation across many domains. However, in many\npractical settings with highly scarce resources, where each agent can only\nreceive at most one resource, such as healthcare intervention programs, the\nstandard RMAB framework falls short. To tackle such scenarios, we introduce\nFinite-Horizon Single-Pull RMABs (SPRMABs), a novel variant in which each arm\ncan only be pulled once. This single-pull constraint introduces additional\ncomplexity, rendering many existing RMAB solutions suboptimal or ineffective.\n%To address this, we propose using dummy states to duplicate the system,\nensuring that once an arm is activated, it transitions exclusively within the\ndummy states. To address this shortcoming, we propose using \\textit{dummy\nstates} that expand the system and enforce the one-pull constraint. We then\ndesign a lightweight index policy for this expanded system. For the first time,\nwe demonstrate that our index policy achieves a sub-linearly decaying average\noptimality gap of $\\tilde{\\mathcal{O}}\\left(\\frac{1}{\\rho^{1/2}}\\right)$ for a\nfinite number of arms, where $\\rho$ is the scaling factor for each arm cluster.\nExtensive simulations validate the proposed method, showing robust performance\nacross various domains compared to existing benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.06103v1"
    },
    {
        "title": "Heterogeneous Update Processes Shape Information Cascades in Social\n  Networks",
        "authors": [
            "Flávio L. Pinheiro",
            "Vítor V. Vasconcelos"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  A common assumption in the literature on information diffusion is that\npopulations are homogeneous regarding individuals' information acquisition and\npropagation process: Individuals update their informed and actively\ncommunicating state either through imitation (simple contagion) or peer\ninfluence (complex contagion). Here, we study the impact of the mixing and\nplacement of individuals with different update processes on how information\ncascades in social networks. We consider Simple Spreaders, which take\ninformation from a random neighbor and communicate it, and Threshold-based\nSpreaders, which require a threshold number of active neighbors to change their\nstate to active communication. Even though, in a population made exclusively of\nSimple Spreaders, information reaches all elements of any (connected) network,\nwe show that, when Simple and Threshold-based Spreaders coexist and occupy\nrandom positions in a social network, the number of Simple Spreaders\nsystematically amplifies the cascades only in degree heterogeneous networks\n(exponential and scale-free). In random and modular structures, this cascading\neffect originated by Simple Spreaders only exists above a critical mass of\nthese individuals. In contrast, when Threshold-based Spreaders are assorted\npreferentially in the nodes with a higher degree, the cascading effect of\nSimple Spreaders vanishes, and the spread of information is drastically\nimpaired. Overall, the study highlights the significance of the strategic\nplacement of different roles in networked structures, with Simple Spreaders\ndriving widespread cascades in heterogeneous networks and Threshold-based\nSpreaders playing a critical regulatory role in information spread with a\ntunable effect based on the threshold value.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08498v1"
    },
    {
        "title": "Adaptivity in Agent-Based Routing for Data Networks",
        "authors": [
            "David H. Wolpert",
            "Sergey Kirshner",
            "Chris J. Merz",
            "Kagan Tumer"
        ],
        "category": "cs.MA",
        "published_year": "1999",
        "summary": "  Adaptivity, both of the individual agents and of the interaction structure\namong the agents, seems indispensable for scaling up multi-agent systems\n(MAS's) in noisy environments. One important consideration in designing\nadaptive agents is choosing their action spaces to be as amenable as possible\nto machine learning techniques, especially to reinforcement learning (RL)\ntechniques. One important way to have the interaction structure connecting\nagents itself be adaptive is to have the intentions and/or actions of the\nagents be in the input spaces of the other agents, much as in Stackelberg\ngames. We consider both kinds of adaptivity in the design of a MAS to control\nnetwork packet routing.\n  We demonstrate on the OPNET event-driven network simulator the perhaps\nsurprising fact that simply changing the action space of the agents to be\nbetter suited to RL can result in very large improvements in their potential\nperformance: at their best settings, our learning-amenable router agents\nachieve throughputs up to three and one half times better than that of the\nstandard Bellman-Ford routing algorithm, even when the Bellman-Ford protocol\ntraffic is maintained. We then demonstrate that much of that potential\nimprovement can be realized by having the agents learn their settings when the\nagent interaction structure is itself adaptive.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9912011v1"
    },
    {
        "title": "A dynamical model of a GRID market",
        "authors": [
            "Uli Harder",
            "Peter Harrison",
            "Maya Paczuski",
            "Tejas Shah"
        ],
        "category": "cs.MA",
        "published_year": "2004",
        "summary": "  We discuss potential market mechanisms for the GRID. A complete dynamical\nmodel of a GRID market is defined with three types of agents. Providers,\nmiddlemen and users exchange universal GRID computing units (GCUs) at varying\nprices. Providers and middlemen have strategies aimed at maximizing profit\nwhile users are 'satisficing' agents, and only change their behavior if the\nservice they receive is sufficiently poor or overpriced. Preliminary results\nfrom a multi-agent numerical simulation of the market model shows that the\ndistribution of price changes has a power law tail.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0410005v1"
    },
    {
        "title": "Naming Games in Spatially-Embedded Random Networks",
        "authors": [
            "Qiming Lu",
            "G. Korniss",
            "Boleslaw K. Szymanski"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  We investigate a prototypical agent-based model, the Naming Game, on random\ngeometric networks. The Naming Game is a minimal model, employing local\ncommunications that captures the emergence of shared communication schemes\n(languages) in a population of autonomous semiotic agents. Implementing the\nNaming Games on random geometric graphs, local communications being local\nbroadcasts, serves as a model for agreement dynamics in large-scale,\nautonomously operating wireless sensor networks. Further, it captures essential\nfeatures of the scaling properties of the agreement process for\nspatially-embedded autonomous agents. We also present results for the case when\na small density of long-range communication links are added on top of the\nrandom geometric graph, resulting in a \"small-world\"-like network and yielding\na significantly reduced time to reach global agreement.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604075v3"
    },
    {
        "title": "A framework of reusable structures for mobile agent development",
        "authors": [
            "Tudor Marian",
            "Bogdan Dumitriu",
            "Mihaela Dinsoreanu",
            "Ioan Salomie"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  Mobile agents research is clearly aiming towards imposing agent based\ndevelopment as the next generation of tools for writing software. This paper\ncomes with its own contribution to this global goal by introducing a novel\nunifying framework meant to bring simplicity and interoperability to and among\nagent platforms as we know them today. In addition to this, we also introduce a\nset of agent behaviors which, although tailored for and from the area of\nvirtual learning environments, are none the less generic enough to be used for\nrapid, simple, useful and reliable agent deployment. The paper also presents an\nillustrative case study brought forward to prove the feasibility of our design.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605032v1"
    },
    {
        "title": "Mobile Agent Based Solutions for Knowledge Assessment in elearning\n  Environments",
        "authors": [
            "Mihaela Dinsoreanu",
            "Cristian Godja",
            "Claudiu Anghel",
            "Ioan Salomie",
            "Tom Coffey"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  E-learning is nowadays one of the most interesting of the \"e- \" domains\navailable through the Internet. The main problem to create a Web-based, virtual\nenvironment is to model the traditional domain and to implement the model using\nthe most suitable technologies. We analyzed the distance learning domain and\ninvestigated the possibility to implement some e-learning services using mobile\nagent technologies. This paper presents a model of the Student Assessment\nService (SAS) and an agent-based framework developed to be used for\nimplementing specific applications. A specific Student Assessment application\nthat relies on the framework was developed.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605033v1"
    },
    {
        "title": "Geographic Gossip on Geometric Random Graphs via Affine Combinations",
        "authors": [
            "Hariharan Narayanan"
        ],
        "category": "cs.MA",
        "published_year": "2006",
        "summary": "  In recent times, a considerable amount of work has been devoted to the\ndevelopment and analysis of gossip algorithms in Geometric Random Graphs. In a\nrecently introduced model termed \"Geographic Gossip,\" each node is aware of its\nposition but possesses no further information. Traditionally, gossip protocols\nhave always used convex linear combinations to achieve averaging. We develop a\nnew protocol for Geographic Gossip, in which counter-intuitively, we use {\\it\nnon-convex affine combinations} as updates in addition to convex combinations\nto accelerate the averaging process. The dependence of the number of\ntransmissions used by our algorithm on the number of sensors $n$ is $n\n\\exp(O(\\log \\log n)^2) = n^{1 + o(1)}$. For the previous algorithm, this\ndependence was $\\tilde{O}(n^{1.5})$. The exponent 1+ o(1) of our algorithm is\nasymptotically optimal. Our algorithm involves a hierarchical structure of\n$\\log \\log n$ depth and is not completely decentralized. However, the extent of\ncontrol exercised by a sensor on another is restricted to switching the other\non or off.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0612012v1"
    },
    {
        "title": "Optimal strategies in the average consensus problem",
        "authors": [
            "Jean-Charles Delvenne",
            "Ruggero Carli",
            "Sandro Zampieri"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  We prove that for a set of communicating agents to compute the average of\ntheir initial positions (average consensus problem), the optimal topology of\ncommunication is given by a de Bruijn's graph. Consensus is then reached in a\nfinitely many steps. A more general family of strategies, constructed by block\nKronecker products, is investigated and compared to Cayley strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/0708.3220v1"
    },
    {
        "title": "Computational Chemotaxis in Ants and Bacteria over Dynamic Environments",
        "authors": [
            "Vitorino Ramos",
            "C. M. Fernandes",
            "A. C. Rosa",
            "A. Abraham"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  Chemotaxis can be defined as an innate behavioural response by an organism to\na directional stimulus, in which bacteria, and other single-cell or\nmulticellular organisms direct their movements according to certain chemicals\nin their environment. This is important for bacteria to find food (e.g.,\nglucose) by swimming towards the highest concentration of food molecules, or to\nflee from poisons. Based on self-organized computational approaches and similar\nstigmergic concepts we derive a novel swarm intelligent algorithm. What strikes\nfrom these observations is that both eusocial insects as ant colonies and\nbacteria have similar natural mechanisms based on stigmergy in order to emerge\ncoherent and sophisticated patterns of global collective behaviour. Keeping in\nmind the above characteristics we will present a simple model to tackle the\ncollective adaptation of a social swarm based on real ant colony behaviors (SSA\nalgorithm) for tracking extrema in dynamic environments and highly multimodal\ncomplex functions described in the well-know De Jong test suite. Later, for the\npurpose of comparison, a recent model of artificial bacterial foraging (BFOA\nalgorithm) based on similar stigmergic features is described and analyzed.\nFinal results indicate that the SSA collective intelligence is able to cope and\nquickly adapt to unforeseen situations even when over the same cooperative\nforaging period, the community is requested to deal with two different and\ncontradictory purposes, while outperforming BFOA in adaptive speed. Results\nindicate that the present approach deals well in severe Dynamic Optimization\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.0744v1"
    },
    {
        "title": "Distributed Consensus Algorithms in Sensor Networks: Quantized Data and\n  Random Link Failures",
        "authors": [
            "Soummya Kar",
            "Jose M. F. Moura"
        ],
        "category": "cs.MA",
        "published_year": "2007",
        "summary": "  The paper studies the problem of distributed average consensus in sensor\nnetworks with quantized data and random link failures. To achieve consensus,\ndither (small noise) is added to the sensor states before quantization. When\nthe quantizer range is unbounded (countable number of quantizer levels),\nstochastic approximation shows that consensus is asymptotically achieved with\nprobability one and in mean square to a finite random variable. We show that\nthe meansquared error (m.s.e.) can be made arbitrarily small by tuning the link\nweight sequence, at a cost of the convergence rate of the algorithm. To study\ndithered consensus with random links when the range of the quantizer is\nbounded, we establish uniform boundedness of the sample paths of the unbounded\nquantizer. This requires characterization of the statistical properties of the\nsupremum taken over the sample paths of the state of the quantizer. This is\naccomplished by splitting the state vector of the quantizer in two components:\none along the consensus subspace and the other along the subspace orthogonal to\nthe consensus subspace. The proofs use maximal inequalities for submartingale\nand supermartingale sequences. From these, we derive probability bounds on the\nexcursions of the two subsequences, from which probability bounds on the\nexcursions of the quantizer state vector follow. The paper shows how to use\nthese probability bounds to design the quantizer parameters and to explore\ntradeoffs among the number of quantizer levels, the size of the quantization\nsteps, the desired probability of saturation, and the desired level of accuracy\n$\\epsilon$ away from consensus. Finally, the paper illustrates the quantizer\ndesign with a numerical study.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.1609v3"
    },
    {
        "title": "Distributed Parameter Estimation in Sensor Networks: Nonlinear\n  Observation Models and Imperfect Communication",
        "authors": [
            "Soummya Kar",
            "Jose M. F. Moura",
            "Kavita Ramanan"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  The paper studies distributed static parameter (vector) estimation in sensor\nnetworks with nonlinear observation models and noisy inter-sensor\ncommunication. It introduces \\emph{separably estimable} observation models that\ngeneralize the observability condition in linear centralized estimation to\nnonlinear distributed estimation. It studies two distributed estimation\nalgorithms in separably estimable models, the $\\mathcal{NU}$ (with its linear\ncounterpart $\\mathcal{LU}$) and the $\\mathcal{NLU}$. Their update rule combines\na \\emph{consensus} step (where each sensor updates the state by weight\naveraging it with its neighbors' states) and an \\emph{innovation} step (where\neach sensor processes its local current observation.) This makes the three\nalgorithms of the \\textit{consensus + innovations} type, very different from\ntraditional consensus. The paper proves consistency (all sensors reach\nconsensus almost surely and converge to the true parameter value,) efficiency,\nand asymptotic unbiasedness. For $\\mathcal{LU}$ and $\\mathcal{NU}$, it proves\nasymptotic normality and provides convergence rate guarantees. The three\nalgorithms are characterized by appropriately chosen decaying weight sequences.\nAlgorithms $\\mathcal{LU}$ and $\\mathcal{NU}$ are analyzed in the framework of\nstochastic approximation theory; algorithm $\\mathcal{NLU}$ exhibits mixed\ntime-scale behavior and biased perturbations, and its analysis requires a\ndifferent approach that is developed in the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.0009v2"
    },
    {
        "title": "Modeling Cultural Dynamics",
        "authors": [
            "Liane Gabora"
        ],
        "category": "cs.MA",
        "published_year": "2008",
        "summary": "  EVOC (for EVOlution of Culture) is a computer model of culture that enables\nus to investigate how various factors such as barriers to cultural diffusion,\nthe presence and choice of leaders, or changes in the ratio of innovation to\nimitation affect the diversity and effectiveness of ideas. It consists of\nneural network based agents that invent ideas for actions, and imitate\nneighbors' actions. The model is based on a theory of culture according to\nwhich what evolves through culture is not memes or artifacts, but the internal\nmodels of the world that give rise to them, and they evolve not through a\nDarwinian process of competitive exclusion but a Lamarckian process involving\nexchange of innovation protocols. EVOC shows an increase in mean fitness of\nactions over time, and an increase and then decrease in the diversity of\nactions. Diversity of actions is positively correlated with population size and\ndensity, and with barriers between populations. Slowly eroding borders increase\nfitness without sacrificing diversity by fostering specialization followed by\nsharing of fit actions. Introducing a leader that broadcasts its actions\nthroughout the population increases the fitness of actions but reduces\ndiversity of actions. Increasing the number of leaders reduces this effect.\nEfforts are underway to simulate the conditions under which an agent\nimmigrating from one culture to another contributes new ideas while still\nfitting in.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.2551v3"
    },
    {
        "title": "Multi-agent Coordination in Directed Moving Neighborhood Random Networks",
        "authors": [
            "Yilun Shang"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  In this paper, we consider the consensus problem of dynamical multiple agents\nthat communicate via a directed moving neighborhood random network. Each agent\nperforms random walk on a weighted directed network. Agents interact with each\nother through random unidirectional information flow when they coincide in the\nunderlying network at a given instant. For such a framework, we present\nsufficient conditions for almost sure asymptotic consensus. Some existed\nconsensus schemes are shown to be reduced versions of the current model.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.3475v1"
    },
    {
        "title": "Leader-following Consensus Problems with a Time-varying Leader under\n  Measurement Noises",
        "authors": [
            "Yilun Shang"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  In this paper, we consider a leader-following consensus problem for networks\nof continuous-time integrator agents with a time-varying leader under\nmeasurement noises. We propose a neighbor-based state-estimation protocol for\nevery agent to track the leader, and time-varying consensus gains are\nintroduced to attenuate the noises. By combining the tools of stochastic\nanalysis and algebraic graph theory, we study mean square convergence of this\nmulti-agent system under directed fixed as well as switching interconnection\ntopologies. Sufficient conditions are given for mean square consensus in both\ncases. Finally, a numerical example is given to illustrate our theoretical\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.4349v1"
    },
    {
        "title": "Variance Analysis of Randomized Consensus in Switching Directed Networks",
        "authors": [
            "Victor M. Preciado",
            "Alireza Tahbaz-Salehi",
            "Ali Jadbabaie"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  In this paper, we study the asymptotic properties of distributed consensus\nalgorithms over switching directed random networks. More specifically, we focus\non consensus algorithms over independent and identically distributed, directed\nErdos-Renyi random graphs, where each agent can communicate with any other\nagent with some exogenously specified probability $p$. While it is well-known\nthat consensus algorithms over Erdos-Renyi random networks result in an\nasymptotic agreement over the network, an analytical characterization of the\ndistribution of the asymptotic consensus value is still an open question. In\nthis paper, we provide closed-form expressions for the mean and variance of the\nasymptotic random consensus value, in terms of the size of the network and the\nprobability of communication $p$. We also provide numerical simulations that\nillustrate our results.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.3883v1"
    },
    {
        "title": "Synchronized Task Decomposition for Cooperative Multi-agent Systems",
        "authors": [
            "Mohammad Karimadini",
            "Hai Lin"
        ],
        "category": "cs.MA",
        "published_year": "2009",
        "summary": "  It is an amazing fact that remarkably complex behaviors could emerge from a\nlarge collection of very rudimentary dynamical agents through very simple local\ninteractions. However, it still remains elusive on how to design these local\ninteractions among agents so as to achieve certain desired collective\nbehaviors. This paper aims to tackle this challenge and proposes a\ndivide-and-conquer approach to guarantee specified global behaviors through\nlocal coordination and control design for multi-agent systems. The basic idea\nis to decompose the requested global specification into subtasks for each\nindividual agent. It should be noted that the decomposition is not arbitrary.\nThe global specification should be decomposed in such a way that the fulfilment\nof these subtasks by each individual agent will imply the satisfaction of the\nglobal specification as a team. First, it is shown by a counterexample that not\nall specifications can be decomposed in this sense. Then, a natural follow-up\nquestion is what the necessary and sufficient condition should be for the\nproposed decomposability of a global specification. The main part of the paper\nis set to answer this question. The case of two cooperative agents is\ninvestigated first, and a necessary and sufficient condition is presented and\nproven. Later on, the result is generalized to the case of arbitrary finite\nnumber of agents, and a hierarchical algorithm is proposed, which is shown to\nbe a sufficient condition. Finally, a cooperative control scenario for a team\nof three robots is developed to illustrate the task decomposition procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0231v3"
    },
    {
        "title": "Artificial Immune Systems Metaphor for Agent Based Modeling of Crisis\n  Response Operations",
        "authors": [
            "Khaled M. Khalil",
            "M. Abdel-Aziz",
            "Taymour T. Nazmy",
            "Abdel-Badeeh M. Salem"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Crisis response requires information intensive efforts utilized for reducing\nuncertainty, calculating and comparing costs and benefits, and managing\nresources in a fashion beyond those regularly available to handle routine\nproblems. This paper presents an Artificial Immune Systems (AIS) metaphor for\nagent based modeling of crisis response operations. The presented model\nproposes integration of hybrid set of aspects (multi-agent systems, built-in\ndefensive model of AIS, situation management, and intensity-based learning) for\ncrisis response operations. In addition, the proposed response model is applied\non the spread of pandemic influenza in Egypt as a case study.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3809v1"
    },
    {
        "title": "An Agent-based Simulation of the Effectiveness of Creative Leadership",
        "authors": [
            "Stefan Leijnen",
            "Liane Gabora"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  This paper investigates the effectiveness of creative versus uncreative\nleadership using EVOC, an agent-based model of cultural evolution. Each\niteration, each agent in the artificial society invents a new action, or\nimitates a neighbor's action. Only the leader's actions can be imitated by all\nother agents, referred to as followers. Two measures of creativity were used:\n(1) invention-to-imitation ratio, iLeader, which measures how often an agent\ninvents, and (2) rate of conceptual change, cLeader, which measures how\ncreative an invention is. High iLeader increased mean fitness of ideas, but\nonly when creativity of followers was low. High iLeader was associated with\ngreater diversity of ideas in the early stage of idea generation only. High\ncLeader increased mean fitness of ideas in the early stage of idea generation;\nin the later stage it decreased idea fitness. Reasons for these findings and\ntentative implications for creative leadership in human society are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.1516v4"
    },
    {
        "title": "Analysis of Collectivism and Egoism Phenomena within the Context of\n  Social Welfare",
        "authors": [
            "P. Yu. Chebotarev",
            "A. K. Loginov",
            "Ya. Yu. Tsodikova",
            "Z. M. Lezina",
            "V. I. Borzenko"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  Comparative benefits provided by the basic social strategies including\ncollectivism and egoism are investigated within the framework of democratic\ndecision-making. In particular, we study the mechanism of growing \"snowball\" of\ncooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0741v1"
    },
    {
        "title": "Timing matters: Lessons From The CA Literature On Updating",
        "authors": [
            "Wolfgang Radax",
            "Bernhard Rengs"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  In the present article we emphasize the importance of modeling time in the\ncontext of agent-based models. To this end, we present a (selective) survey of\nthe Cellular Automata-literature on updating and draw parallels to the issue of\nagent activation in agent-based models. By means of two simple models,\nSchelling's segregation model and Epstein's demographic prisoner's dilemma we\ninvestigate the influence of choosing different regimes of agent activation.\nOur experiments indicate that timing is not a critical issue for very simple\nmodels but bears huge influence on model behavior and results as soon as the\ndegree of complexity increases only so slightly. After a brief review of the\nway commonly used ABM simulation environments handle the issue of timing, we\ndraw some tentative conclusions about the importance of timing and the need for\nmore research towards that direction, similar to the concerted effort on\nupdating in cellular automata.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.0941v1"
    },
    {
        "title": "Efficient Collaborative Application Monitoring Scheme for Mobile\n  Networks",
        "authors": [
            "Yaniv Altshuler",
            "Shlomi Dolev",
            "Yuval Elovici"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  New operating systems for mobile devices allow their users to download\nmillions of applications created by various individual programmers, some of\nwhich may be malicious or flawed. In order to detect that an application is\nmalicious, monitoring its operation in a real environment for a significant\nperiod of time is often required. Mobile devices have limited computation and\npower resources and thus are limited in their monitoring capabilities. In this\npaper we propose an efficient collaborative monitoring scheme that harnesses\nthe collective resources of many mobile devices, \"vaccinating\" them against\npotentially unsafe applications. We suggest a new local information flooding\nalgorithm called \"TTL Probabilistic Propagation\" (TPP). The algorithm\nperiodically monitors one or more application and reports its conclusions to a\nsmall number of other mobile devices, who then propagate this information\nonwards. The algorithm is analyzed, and is shown to outperform existing state\nof the art information propagation algorithms, in terms of convergence time as\nwell as network overhead. The maximal \"load\" of the algorithm (the fastest\narrival rate of new suspicious applications, that can still guarantee complete\nmonitoring), is analytically calculated and shown to be significantly superior\ncompared to any non-collaborative approach. Finally, we show both analytically\nand experimentally using real world network data that implementing the proposed\nalgorithm significantly reduces the number of infected mobile devices. In\naddition, we analytically prove that the algorithm is tolerant to several types\nof Byzantine attacks where some adversarial agents may generate false\ninformation, or abuse the algorithm in other ways.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.1132v2"
    },
    {
        "title": "Comments on \"Consensus and Cooperation in Networked Multi-Agent Systems\"",
        "authors": [
            "Pavel Chebotarev"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  This note corrects a pretty serious mistake and some inaccuracies in\n\"Consensus and cooperation in networked multi-agent systems\" by R.\nOlfati-Saber, J.A. Fax, and R.M. Murray, published in Vol. 95 of the\nProceedings of the IEEE (2007, No. 1, P. 215-233). It also mentions several\nstronger results applicable to the class of problems under consideration and\naddresses the issue of priority whose interpretation in the above-mentioned\npaper is not exact.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.6050v1"
    },
    {
        "title": "Spectral Control of Mobile Robot Networks",
        "authors": [
            "Michael M. Zavlanos",
            "Victor M. Preciado",
            "Ali Jadbabaie"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  The eigenvalue spectrum of the adjacency matrix of a network is closely\nrelated to the behavior of many dynamical processes run over the network. In\nthe field of robotics, this spectrum has important implications in many\nproblems that require some form of distributed coordination within a team of\nrobots. In this paper, we propose a continuous-time control scheme that\nmodifies the structure of a position-dependent network of mobile robots so that\nit achieves a desired set of adjacency eigenvalues. For this, we employ a novel\nabstraction of the eigenvalue spectrum by means of the adjacency matrix\nspectral moments. Since the eigenvalue spectrum is uniquely determined by its\nspectral moments, this abstraction provides a way to indirectly control the\neigenvalues of the network. Our construction is based on artificial potentials\nthat capture the distance of the network's spectral moments to their desired\nvalues. Minimization of these potentials is via a gradient descent closed-loop\nsystem that, under certain convexity assumptions, ensures convergence of the\nnetwork topology to one with the desired set of moments and, therefore,\neigenvalues. We illustrate our approach in nontrivial computer simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.0034v1"
    },
    {
        "title": "The Inverse Task of the Reflexive Game Theory: Theoretical Matters,\n  Practical Applications and Relationship with Other Issues",
        "authors": [
            "Sergey Tarasenko"
        ],
        "category": "cs.MA",
        "published_year": "2010",
        "summary": "  The Reflexive Game Theory (RGT) has been recently proposed by Vladimir\nLefebvre to model behavior of individuals in groups. The goal of this study is\nto introduce the Inverse task. We consider methods of solution together with\npractical applications. We present a brief overview of the RGT for easy\nunderstanding of the problem. We also develop the schematic representation of\nthe RGT inference algorithms to create the basis for soft- and hardware\nsolutions of the RGT tasks. We propose a unified hierarchy of schemas to\nrepresent humans and robots. This hierarchy is considered as a unified\nframework to solve the entire spectrum of the RGT tasks. We conclude by\nillustrating how this framework can be applied for modeling of mixed groups of\nhumans and robots. All together this provides the exhaustive solution of the\nInverse task and clearly illustrates its role and relationships with other\nissues considered in the RGT.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.3397v1"
    },
    {
        "title": "Communicate only when necessary: Cooperative tasking for multi-agent\n  systems",
        "authors": [
            "Mohammad Karimadini",
            "Hai Lin"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  New advances in large scale distributed systems have amazingly offered\ncomplex functionalities through parallelism of simple and rudimentary\ncomponents. The key issue in cooperative control of multi-agent systems is the\nsynthesis of local control and interaction rules among the agents such that the\nentire controlled system achieves a desired global behavior. For this purpose,\nthree fundamental problems have to be addressed: (1) task decomposition for\ntop-down design, such that the fulfillment of local tasks guarantees the\nsatisfaction of the global task, by the team; (2) fault-tolerant top-down\ndesign, such that the global task remains decomposable and achievable, in spite\nof some failures, and (3) design of interactions among agents to make an\nundecomposable task decomposable and achievable in a top-down framework. The\nfirst two problems have been addressed in our previous works, by identifying\nnecessary and sufficient conditions for task automaton decomposition, and\nfault-tolerant task decomposability. This paper deals with the third problem\nand proposes a procedure to redistribute the events among agents in order to\nenforce decomposability of an undecomposable task automaton. The\ndecomposability conditions are used to identify the root causes of\nundecomposability which are found to be due to over-communications that have to\nbe deleted, while respecting the fault-tolerant decomposability conditions; or\nbecause of the lack of communications that require new sharing of events, while\nconsidering new violations of decomposability conditions. This result provides\na sufficient condition to make any undecomposable deterministic task automaton\ndecomposable in order to facilitate cooperative tasking. Illustrative examples\nare presented to show the concept of task automaton decomposabilization.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.3134v1"
    },
    {
        "title": "Randomized Optimal Consensus of Multi-agent Systems",
        "authors": [
            "Guodong Shi",
            "Karl Henrik Johansson"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  In this paper, we formulate and solve a randomized optimal consensus problem\nfor multi-agent systems with stochastically time-varying interconnection\ntopology. The considered multi-agent system with a simple randomized iterating\nrule achieves an almost sure consensus meanwhile solving the optimization\nproblem $\\min_{z\\in \\mathds{R}^d}\\ \\sum_{i=1}^n f_i(z),$ in which the optimal\nsolution set of objective function $f_i$ can only be observed by agent $i$\nitself. At each time step, simply determined by a Bernoulli trial, each agent\nindependently and randomly chooses either taking an average among its neighbor\nset, or projecting onto the optimal solution set of its own optimization\ncomponent. Both directed and bidirectional communication graphs are studied.\nConnectivity conditions are proposed to guarantee an optimal consensus almost\nsurely with proper convexity and intersection assumptions. The convergence\nanalysis is carried out using convex analysis. We compare the randomized\nalgorithm with the deterministic one via a numerical example. The results\nillustrate that a group of autonomous agents can reach an optimal opinion by\neach node simply making a randomized trade-off between following its neighbors\nor sticking to its own opinion at each time step.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.3223v2"
    },
    {
        "title": "Fashion, Cooperation, and Social Interactions",
        "authors": [
            "Zhigang Cao",
            "Haoyu Gao",
            "Xinglong Qu",
            "Mingmin Yang",
            "Xiaoguang Yang"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Fashion plays such a crucial rule in the evolution of culture and society\nthat it is regarded as a second nature to the human being. Also, its impact on\neconomy is quite nontrivial. On what is fashionable, interestingly, there are\ntwo viewpoints that are both extremely widespread but almost opposite:\nconformists think that what is popular is fashionable, while rebels believe\nthat being different is the essence. Fashion color is fashionable in the first\nsense, and Lady Gaga in the second. We investigate a model where the population\nconsists of the afore-mentioned two groups of people that are located on social\nnetworks (a spatial cellular automata network and small-world networks). This\nmodel captures two fundamental kinds of social interactions (coordination and\nanti-coordination) simultaneously, and also has its own interest to game\ntheory: it is a hybrid model of pure competition and pure cooperation. This is\ntrue because when a conformist meets a rebel, they play the zero sum matching\npennies game, which is pure competition. When two conformists (rebels) meet,\nthey play the (anti-) coordination game, which is pure cooperation. Simulation\nshows that simple social interactions greatly promote cooperation: in most\ncases people can reach an extraordinarily high level of cooperation, through a\nselfish, myopic, naive, and local interacting dynamic (the best response\ndynamic). We find that degree of synchronization also plays a critical role,\nbut mostly on the negative side. Four indices, namely cooperation degree,\naverage satisfaction degree, equilibrium ratio and complete ratio, are defined\nand applied to measure people's cooperation levels from various angles. Phase\ntransition, as well as emergence of many interesting geographic patterns in the\ncellular automata network, is also observed.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.0163v3"
    },
    {
        "title": "A Consensual Linear Opinion Pool",
        "authors": [
            "Arthur Carvalho",
            "Kate Larson"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  An important question when eliciting opinions from experts is how to\naggregate the reported opinions. In this paper, we propose a pooling method to\naggregate expert opinions. Intuitively, it works as if the experts were\ncontinuously updating their opinions in order to accommodate the expertise of\nothers. Each updated opinion takes the form of a linear opinion pool, where the\nweight that an expert assigns to a peer's opinion is inversely related to the\ndistance between their opinions. In other words, experts are assumed to prefer\nopinions that are close to their own opinions. We prove that such an updating\nprocess leads to consensus, \\textit{i.e.}, the experts all converge towards the\nsame opinion. Further, we show that if rational experts are rewarded using the\nquadratic scoring rule, then the assumption that they prefer opinions that are\nclose to their own opinions follows naturally. We empirically demonstrate the\nefficacy of the proposed method using real-world data.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.5399v3"
    },
    {
        "title": "Multi-model-based Access Control in Construction Projects",
        "authors": [
            "Frank Hilbert",
            "Raimar J. Scherer",
            "Larissa Araujo"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  During the execution of large scale construction projects performed by\nVirtual Organizations (VO), relatively complex technical models have to be\nexchanged between the VO members. For linking the trade and transfer of these\nmodels, a so-called multi-model container format was developed. Considering the\ndifferent skills and tasks of the involved partners, it is not necessary for\nthem to know all the models in every technical detailing. Furthermore, the\nmodel size can lead to a delay in communication. In this paper an approach is\npresented for defining model cut-outs according to the current project context.\nDynamic dependencies to the project context as well as static dependencies on\nthe organizational structure are mapped in a context-sensitive rule. As a\nresult, an approach for dynamic filtering of multi-models is obtained which\nensures, together with a filtering service, that the involved VO members get a\nsimplified view of complex multi-models as well as sufficient permissions\ndepending on their tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.6089v1"
    },
    {
        "title": "Modelling the emergence of spatial patterns of economic activity",
        "authors": [
            "Jung-Hun Yang",
            "Dick Ettema",
            "Koen Frenken"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Understanding how spatial configurations of economic activity emerge is\nimportant when formulating spatial planning and economic policy. A simple model\nwas proposed by Simon, who assumed that firms grow at a rate proportional to\ntheir size, and that new divisions of firms with certain probabilities relocate\nto other firms or to new centres of economic activity. Simon's model produces\nrealistic results in the sense that the sizes of economic centres follow a Zipf\ndistribution, which is also observed in reality. It lacks realism in the sense\nthat mechanisms such as cluster formation, congestion (defined as an overly\nhigh density of the same activities) and dependence on the spatial distribution\nof external parties (clients, labour markets) are ignored.\n  The present paper proposed an extension of the Simon model that includes both\ncentripetal and centrifugal forces. Centripetal forces are included in the\nsense that firm divisions are more likely to settle in locations that offer a\nhigher accessibility to other firms. Centrifugal forces are represented by an\naversion of a too high density of activities in the potential location. The\nmodel is implemented as an agent-based simulation model in a simplified spatial\nsetting. By running both the Simon model and the extended model, comparisons\nare made with respect to their effects on spatial configurations. To this end a\nseries of metrics are used, including the rank-size distribution and indices of\nthe degree of clustering and concentration.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.6638v1"
    },
    {
        "title": "A distributed classification/estimation algorithm for sensor networks",
        "authors": [
            "Fabio Fagnani",
            "Sophie M. Fosson",
            "Chiara Ravazzi"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  In this paper, we address the problem of simultaneous classification and\nestimation of hidden parameters in a sensor network with communications\nconstraints. In particular, we consider a network of noisy sensors which\nmeasure a common scalar unknown parameter. We assume that a fraction of the\nnodes represent faulty sensors, whose measurements are poorly reliable. The\ngoal for each node is to simultaneously identify its class (faulty or\nnon-faulty) and estimate the common parameter.\n  We propose a novel cooperative iterative algorithm which copes with the\ncommunication constraints imposed by the network and shows remarkable\nperformance. Our main result is a rigorous proof of the convergence of the\nalgorithm and a characterization of the limit behavior. We also show that, in\nthe limit when the number of sensors goes to infinity, the common unknown\nparameter is estimated with arbitrary small error, while the classification\nerror converges to that of the optimal centralized maximum likelihood\nestimator. We also show numerical results that validate the theoretical\nanalysis and support their possible generalization. We compare our strategy\nwith the Expectation-Maximization algorithm and we discuss trade-offs in terms\nof robustness, speed of convergence and implementation simplicity.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.3793v1"
    },
    {
        "title": "Stochastic Optimal Control in Continuous Space-Time Multi-Agent Systems",
        "authors": [
            "Wim Wiegerinck",
            "Bart van den Broek",
            "Hilbert Kappen"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Recently, a theory for stochastic optimal control in non-linear dynamical\nsystems in continuous space-time has been developed (Kappen, 2005). We apply\nthis theory to collaborative multi-agent systems. The agents evolve according\nto a given non-linear dynamics with additive Wiener noise. Each agent can\ncontrol its own dynamics. The goal is to minimize the accumulated joint cost,\nwhich consists of a state dependent term and a term that is quadratic in the\ncontrol. We focus on systems of non-interacting agents that have to distribute\nthemselves optimally over a number of targets, given a set of end-costs for the\ndifferent possible agent-target combinations. We show that optimal control is\nthe combinatorial sum of independent single-agent single-target optimal\ncontrols weighted by a factor proportional to the end-costs of the different\ncombinations. Thus, multi-agent control is related to a standard graphical\nmodel inference problem. The additional computational cost compared to\nsingle-agent control is exponential in the tree-width of the graph specifying\nthe combinatorial sum times the number of targets. We illustrate the result by\nsimulations of systems with up to 42 agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.6866v1"
    },
    {
        "title": "Genetic agent approach for improving on-the-fly web map generalization",
        "authors": [
            "Brahim lejdel",
            "Okba kazar"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  The utilization of web mapping becomes increasingly important in the domain\nof cartography. Users want access to spatial data on the web specific to their\nneeds. For this reason, different approaches were appeared for generating\non-the-fly the maps demanded by users, but those not suffice for guide a\nflexible and efficient process. Thus, new approach must be developed for\nimproving this process according to the user needs. This work focuses on\ndefining a new strategy which improves on-the-fly map generalization process\nand resolves the spatial conflicts. This approach uses the multiple\nrepresentation and cartographic generalization. The map generalization process\nis based on the implementation of multi- agent system where each agent was\nequipped with a genetic patrimony.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.2697v1"
    },
    {
        "title": "On the genericity properties in networked estimation: Topology design\n  and sensor placement",
        "authors": [
            "Mohammadreza Doostmohammadian",
            "Usman A. Khan"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  In this paper, we consider networked estimation of linear, discrete-time\ndynamical systems monitored by a network of agents. In order to minimize the\npower requirement at the (possibly, battery-operated) agents, we require that\nthe agents can exchange information with their neighbors only \\emph{once per\ndynamical system time-step}; in contrast to consensus-based estimation where\nthe agents exchange information until they reach a consensus. It can be\nverified that with this restriction on information exchange, measurement fusion\nalone results in an unbounded estimation error at every such agent that does\nnot have an observable set of measurements in its neighborhood. To over come\nthis challenge, state-estimate fusion has been proposed to recover the system\nobservability. However, we show that adding state-estimate fusion may not\nrecover observability when the system matrix is structured-rank ($S$-rank)\ndeficient.\n  In this context, we characterize the state-estimate fusion and measurement\nfusion under both full $S$-rank and $S$-rank deficient system matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.3691v1"
    },
    {
        "title": "Discrete modelling of bacterial conjugation dynamics",
        "authors": [
            "Angel Goni-Moreno",
            "Martyn Amos"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  In bacterial populations, cells are able to cooperate in order to yield\ncomplex collective functionalities. Interest in population-level cellular\nbehaviour is increasing, due to both our expanding knowledge of the underlying\nbiological principles, and the growing range of possible applications for\nengineered microbial consortia. Researchers in the field of synthetic biology -\nthe application of engineering principles to living systems - have, for\nexample, recently shown how useful decision-making circuits may be distributed\nacross a bacterial population. The ability of cells to interact through small\nsignalling molecules (a mechanism known as it quorum sensing) is the basis for\nthe majority of existing engineered systems. However, horizontal gene transfer\n(or conjugation) offers the possibility of cells exchanging messages (using\nDNA) that are much more information-rich. The potential of engineering this\nconjugation mechanism to suit specific goals will guide future developments in\nthis area. Motivated by a lack of computational models for examining the\nspecific dynamics of conjugation, we present a simulation framework for its\nfurther study. We present an agent-based model for conjugation dynamics, with\nrealistic handling of physical forces. Our framework combines the management of\nintercellular interactions together with simulation of intracellular genetic\nnetworks, to provide a general-purpose platform. We validate our simulations\nagainst existing experimental data, and then demonstrate how the emergent\nmixing patterns of multi-strain populations can affect conjugation dynamics.\nOur model of conjugation, based on a probability distribution, may be easily\ntuned to correspond to the behaviour of different cell types. Simulation code\nand movies are available at http://code.google.com/p/discus/.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.1146v1"
    },
    {
        "title": "Random Utility Theory for Social Choice",
        "authors": [
            "Hossein Azari Soufiani",
            "David C. Parkes",
            "Lirong Xia"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Random utility theory models an agent's preferences on alternatives by\ndrawing a real-valued score on each alternative (typically independently) from\na parameterized distribution, and then ranking the alternatives according to\nscores. A special case that has received significant attention is the\nPlackett-Luce model, for which fast inference methods for maximum likelihood\nestimators are available. This paper develops conditions on general random\nutility models that enable fast inference within a Bayesian framework through\nMC-EM, providing concave loglikelihood functions and bounded sets of global\nmaxima solutions. Results on both real-world and simulated data provide support\nfor the scalability of the approach and capability for model selection among\ngeneral random utility models including Plackett-Luce.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.2476v1"
    },
    {
        "title": "Rendezvous of two robots with visible bits",
        "authors": [
            "Giovanni Viglietta"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  We study the rendezvous problem for two robots moving in the plane (or on a\nline). Robots are autonomous, anonymous, oblivious, and carry colored lights\nthat are visible to both. We consider deterministic distributed algorithms in\nwhich robots do not use distance information, but try to reduce (or increase)\ntheir distance by a constant factor, depending on their lights' colors.\n  We give a complete characterization of the number of colors that are\nnecessary to solve the rendezvous problem in every possible model, ranging from\nfully synchronous to semi-synchronous to asynchronous, rigid and non-rigid,\nwith preset or arbitrary initial configuration.\n  In particular, we show that three colors are sufficient in the non-rigid\nasynchronous model with arbitrary initial configuration. In contrast, two\ncolors are insufficient in the rigid asynchronous model with arbitrary initial\nconfiguration and in the non-rigid asynchronous model with preset initial\nconfiguration.\n  Additionally, if the robots are able to distinguish between zero and non-zero\ndistances, we show how they can solve rendezvous and detect termination using\nonly three colors, even in the non-rigid asynchronous model with arbitrary\ninitial configuration.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.6039v2"
    },
    {
        "title": "Multi-agent learning using Fictitious Play and Extended Kalman Filter",
        "authors": [
            "Michalis Smyrnakis"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Decentralised optimisation tasks are important components of multi-agent\nsystems. These tasks can be interpreted as n-player potential games: therefore\ngame-theoretic learning algorithms can be used to solve decentralised\noptimisation tasks. Fictitious play is the canonical example of these\nalgorithms. Nevertheless fictitious play implicitly assumes that players have\nstationary strategies. We present a novel variant of fictitious play where\nplayers predict their opponents' strategies using Extended Kalman filters and\nuse their predictions to update their strategies.\n  We show that in 2 by 2 games with at least one pure Nash equilibrium and in\npotential games where players have two available actions, the proposed\nalgorithm converges to the pure Nash equilibrium. The performance of the\nproposed algorithm was empirically tested, in two strategic form games and an\nad-hoc sensor network surveillance problem. The proposed algorithm performs\nbetter than the classic fictitious play algorithm in these games and therefore\nimproves the performance of game-theoretical learning in decentralised\noptimisation.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.3347v1"
    },
    {
        "title": "A theoretical framework for conducting multi-level studies of complex\n  social systems with agent-based models and empirical data",
        "authors": [
            "Chih-Chun Chen"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  A formal but intuitive framework is introduced to bridge the gap between data\nobtained from empirical studies and that generated by agent-based models. This\nis based on three key tenets. Firstly, a simulation can be given multiple\nformal descriptions corresponding to static and dynamic properties at different\nlevels of observation. These can be easily mapped to empirically observed\nphenomena and data obtained from them. Secondly, an agent-based model generates\na set of closed systems, and computational simulation is the means by which we\nsample from this set. Thirdly, properties at different levels and statistical\nrelationships between them can be used to classify simulations as those that\ninstantiate a more sophisticated set of constraints. These can be validated\nwith models obtained from statistical models of empirical data (for example,\nstructural equation or multi-level models) and hence provide more stringent\ncriteria for validating the agent-based model itself.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.4774v1"
    },
    {
        "title": "Rendezvous of Two Robots with Constant Memory",
        "authors": [
            "Paola Flocchini",
            "Nicola Santoro",
            "Giovanni Viglietta",
            "Masafumi Yamashita"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  We study the impact that persistent memory has on the classical rendezvous\nproblem of two mobile computational entities, called robots, in the plane. It\nis well known that, without additional assumptions, rendezvous is impossible if\nthe entities are oblivious (i.e., have no persistent memory) even if the system\nis semi-synchronous (SSynch). It has been recently shown that rendezvous is\npossible even if the system is asynchronous (ASynch) if each robot is endowed\nwith O(1) bits of persistent memory, can transmit O(1) bits in each cycle, and\ncan remember (i.e., can persistently store) the last received transmission.\nThis setting is overly powerful.\n  In this paper we weaken that setting in two different ways: (1) by\nmaintaining the O(1) bits of persistent memory but removing the communication\ncapabilities; and (2) by maintaining the O(1) transmission capability and the\nability to remember the last received transmission, but removing the ability of\nan agent to remember its previous activities. We call the former setting\nfinite-state (FState) and the latter finite-communication (FComm). Note that,\neven though its use is very different, in both settings, the amount of\npersistent memory of a robot is constant.\n  We investigate the rendezvous problem in these two weaker settings. We model\nboth settings as a system of robots endowed with visible lights: in FState, a\nrobot can only see its own light, while in FComm a robot can only see the other\nrobot's light. We prove, among other things, that finite-state robots can\nrendezvous in SSynch, and that finite-communication robots are able to\nrendezvous even in ASynch. All proofs are constructive: in each setting, we\npresent a protocol that allows the two robots to rendezvous in finite time.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.1956v1"
    },
    {
        "title": "Opinion dynamics and wisdom under out-group discrimination",
        "authors": [
            "Steffen Eger"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  We study a DeGroot-like opinion dynamics model in which agents may oppose\nother agents. As an underlying motivation, in our setup, agents want to adjust\ntheir opinions to match those of the agents of their 'in-group' and, in\naddition, they want to adjust their opinions to match the 'inverse' of those of\nthe agents of their 'out-group'. Our paradigm can account for persistent\ndisagreement in connected societies as well as bi- and multi-polarization.\nOutcomes depend upon network structure and the choice of deviation function\nmodeling the mode of opposition between agents. For a particular choice of\ndeviation function, which we call soft opposition, we derive necessary and\nsufficient conditions for long-run polarization. We also consider social\ninfluence (who are the opinion leaders in the network?) as well as the question\nof wisdom in our naive learning paradigm, finding that wisdom is difficult to\nattain when there exist sufficiently strong negative relations between agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.3134v6"
    },
    {
        "title": "Coevolutionary networks of reinforcement-learning agents",
        "authors": [
            "Ardeshir Kianercy",
            "Aram Galstyan"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This paper presents a model of network formation in repeated games where the\nplayers adapt their strategies and network ties simultaneously using a simple\nreinforcement-learning scheme. It is demonstrated that the coevolutionary\ndynamics of such systems can be described via coupled replicator equations. We\nprovide a comprehensive analysis for three-player two-action games, which is\nthe minimum system size with nontrivial structural dynamics. In particular, we\ncharacterize the Nash equilibria (NE) in such games and examine the local\nstability of the rest points corresponding to those equilibria. We also study\ngeneral n-player networks via both simulations and analytical methods and find\nthat in the absence of exploration, the stable equilibria consist of star\nmotifs as the main building blocks of the network. Furthermore, in all stable\nequilibria the agents play pure strategies, even when the game allows mixed NE.\nFinally, we study the impact of exploration on learning outcomes, and observe\nthat there is a critical exploration rate above which the symmetric and\nuniformly connected network topology becomes stable.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.1049v1"
    },
    {
        "title": "Modelling Complexity for Policy: Opportunities and Challenges",
        "authors": [
            "Bruce Edmonds",
            "Carlos Gershenson"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This chapter reviews the purpose and use of models from the field of complex\nsystems and, in particular, the implications of trying to use models to\nunderstand or make decisions within complex situations, such as policy makers\nusually face. A discussion of the different dimensions one can formalise\nsituations, the different purposes for models and the different kinds of\nrelationship they can have with the policy making process, is followed by an\nexamination of the compromises forced by the complexity of the target issues.\nSeveral modelling approaches from complexity science are briefly described,\nwith notes as to their abilities and limitations. These approaches include\nsystem dynamics, network theory, information theory, cellular automata, and\nagent-based modelling. Some examples of policy models are presented and\ndiscussed in the context of the previous analysis. Finally we conclude by\noutlining some of the major pitfalls facing those wishing to use such models\nfor policy evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.2290v1"
    },
    {
        "title": "Diversity and Social Network Structure in Collective Decision Making:\n  Evolutionary Perspectives with Agent-Based Simulations",
        "authors": [
            "Shelley D. Dionne",
            "Hiroki Sayama",
            "Francis J. Yammarino"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Collective, especially group-based, managerial decision making is crucial in\norganizations. Using an evolutionary theoretic approach to collective decision\nmaking, agent-based simulations were conducted to investigate how human\ncollective decision making would be affected by the agents' diversity in\nproblem understanding and/or behavior in discussion, as well as by their social\nnetwork structure. Simulation results indicated that groups with consistent\nproblem understanding tended to produce higher utility values of ideas and\ndisplayed better decision convergence, but only if there was no group-level\nbias in collective problem understanding. Simulation results also indicated the\nimportance of balance between selection-oriented (i.e., exploitative) and\nvariation-oriented (i.e., explorative) behaviors in discussion to achieve\nquality final decisions. Expanding the group size and introducing non-trivial\nsocial network structure generally improved the quality of ideas at the cost of\ndecision convergence. Simulations with different social network topologies\nrevealed collective decision making on small-world networks with high local\nclustering tended to achieve highest decision quality more often than on random\nor scale-free networks. Implications of this evolutionary theory and simulation\napproach for future managerial research on collective, group, and multi-level\ndecision making are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3674v3"
    },
    {
        "title": "On the Learning Behavior of Adaptive Networks - Part II: Performance\n  Analysis",
        "authors": [
            "Jianshu Chen",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Part I of this work examined the mean-square stability and convergence of the\nlearning process of distributed strategies over graphs. The results identified\nconditions on the network topology, utilities, and data in order to ensure\nstability; the results also identified three distinct stages in the learning\nbehavior of multi-agent networks related to transient phases I and II and the\nsteady-state phase. This Part II examines the steady-state phase of distributed\nlearning by networked agents. Apart from characterizing the performance of the\nindividual agents, it is shown that the network induces a useful equalization\neffect across all agents. In this way, the performance of noisier agents is\nenhanced to the same level as the performance of agents with less noisy data.\nIt is further shown that in the small step-size regime, each agent in the\nnetwork is able to achieve the same performance level as that of a centralized\nstrategy corresponding to a fully connected network. The results in this part\nreveal explicitly which aspects of the network topology and operation influence\nperformance and provide important insights into the design of effective\nmechanisms for the processing and diffusion of information over networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7580v4"
    },
    {
        "title": "On the Learning Behavior of Adaptive Networks - Part I: Transient\n  Analysis",
        "authors": [
            "Jianshu Chen",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  This work carries out a detailed transient analysis of the learning behavior\nof multi-agent networks, and reveals interesting results about the learning\nabilities of distributed strategies. Among other results, the analysis reveals\nhow combination policies influence the learning process of networked agents,\nand how these policies can steer the convergence point towards any of many\npossible Pareto optimal solutions. The results also establish that the learning\nprocess of an adaptive network undergoes three (rather than two) well-defined\nstages of evolution with distinctive convergence rates during the first two\nstages, while attaining a finite mean-square-error (MSE) level in the last\nstage. The analysis reveals what aspects of the network topology influence\nperformance directly and suggests design procedures that can optimize\nperformance by adjusting the relevant topology parameters. Interestingly, it is\nfurther shown that, in the adaptation regime, each agent in a sparsely\nconnected network is able to achieve the same performance level as that of a\ncentralized stochastic-gradient strategy even for left-stochastic combination\nstrategies. These results lead to a deeper understanding and useful insights on\nthe convergence behavior of coupled distributed learners. The results also lead\nto effective design mechanisms to help diffuse information more thoroughly over\nnetworks.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7581v4"
    },
    {
        "title": "Distributed Policy Evaluation Under Multiple Behavior Strategies",
        "authors": [
            "Sergio Valcarcel Macua",
            "Jianshu Chen",
            "Santiago Zazo",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  We apply diffusion strategies to develop a fully-distributed cooperative\nreinforcement learning algorithm in which agents in a network communicate only\nwith their immediate neighbors to improve predictions about their environment.\nThe algorithm can also be applied to off-policy learning, meaning that the\nagents can predict the response to a behavior different from the actual\npolicies they are following. The proposed distributed strategy is efficient,\nwith linear complexity in both computation time and memory footprint. We\nprovide a mean-square-error performance analysis and establish convergence\nunder constant step-size updates, which endow the network with continuous\nlearning capabilities. The results show a clear gain from cooperation: when the\nindividual agents can estimate the solution, cooperation increases stability\nand reduces bias and variance of the prediction error; but, more importantly,\nthe network is able to approach the optimal solution even when none of the\nindividual agents can (e.g., when the individual behavior policies restrict\neach agent to sample a small portion of the state space).\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7606v2"
    },
    {
        "title": "On Decentralized Estimation with Active Queries",
        "authors": [
            "Theodoros Tsiligkaridis",
            "Brian M. Sadler",
            "Alfred O. Hero III"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  We consider the problem of decentralized 20 questions with noise for multiple\nplayers/agents under the minimum entropy criterion in the setting of stochastic\nsearch over a parameter space, with application to target localization. We\npropose decentralized extensions of the active query-based stochastic search\nstrategy that combines elements from the 20 questions approach and social\nlearning. We prove convergence to correct consensus on the value of the\nparameter. This framework provides a flexible and tractable mathematical model\nfor decentralized parameter estimation systems based on active querying. We\nillustrate the effectiveness and robustness of the proposed decentralized\ncollaborative 20 questions algorithm for random network topologies with\ninformation sharing.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7847v3"
    },
    {
        "title": "Distributed Algorithms for Stochastic Source Seeking with Mobile Robot\n  Networks: Technical Report",
        "authors": [
            "Nikolay A. Atanasov",
            "Jerome Le Ny",
            "George J. Pappas"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Autonomous robot networks are an effective tool for monitoring large-scale\nenvironmental fields. This paper proposes distributed control strategies for\nlocalizing the source of a noisy signal, which could represent a physical\nquantity of interest such as magnetic force, heat, radio signal, or chemical\nconcentration. We develop algorithms specific to two scenarios: one in which\nthe sensors have a precise model of the signal formation process and one in\nwhich a signal model is not available. In the model-free scenario, a team of\nsensors is used to follow a stochastic gradient of the signal field. Our\napproach is distributed, robust to deformations in the group geometry, does not\nnecessitate global localization, and is guaranteed to lead the sensors to a\nneighborhood of a local maximum of the field. In the model-based scenario, the\nsensors follow the stochastic gradient of the mutual information between their\nexpected measurements and the location of the source in a distributed manner.\nThe performance is demonstrated in simulation using a robot sensor network to\nlocalize the source of a wireless radio signal.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.0051v2"
    },
    {
        "title": "Decentralized Goal Assignment and Safe Trajectory Generation in\n  Multi-Robot Networks via Multiple Lyapunov Functions",
        "authors": [
            "Dimitra Panagou",
            "Matthew Turpin",
            "Vijay Kumar"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper considers the problem of decentralized goal assignment and\ntrajectory generation for multi-robot networks when only local communication is\navailable, and proposes an approach based on methods related to switched\nsystems and set invariance. A family of Lyapunov-like functions is employed to\nencode the (local) decision making among candidate goal assignments, under\nwhich a group of connected agents chooses the assignment that results in the\nshortest total distance to the goals. An additional family of Lyapunov-like\nbarrier functions is activated in the case when the optimal assignment may lead\nto colliding trajectories, maintaining thus system safety while preserving the\nconvergence guarantees. The proposed switching strategies give rise to feedback\ncontrol policies that are computationally efficient and scalable with the\nnumber of agents, and therefore suitable for applications including\nfirst-response deployment of robotic networks under limited information\nsharing. The efficacy of the proposed method is demonstrated via simulation\nresults and experiments with six ground robots.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3735v3"
    },
    {
        "title": "The Anatomy of a Modular System for Media Content Analysis",
        "authors": [
            "Ilias Flaounas",
            "Thomas Lansdall-Welfare",
            "Panagiota Antonakaki",
            "Nello Cristianini"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Intelligent systems for the annotation of media content are increasingly\nbeing used for the automation of parts of social science research. In this\ndomain the problem of integrating various Artificial Intelligence (AI)\nalgorithms into a single intelligent system arises spontaneously. As part of\nour ongoing effort in automating media content analysis for the social\nsciences, we have built a modular system by combining multiple AI modules into\na flexible framework in which they can cooperate in complex tasks. Our system\ncombines data gathering, machine translation, topic classification, extraction\nand annotation of entities and social networks, as well as many other tasks\nthat have been perfected over the past years of AI research. Over the last few\nyears, it has allowed us to realise a series of scientific studies over a vast\nrange of applications including comparative studies between news outlets and\nmedia content in different countries, modelling of user preferences, and\nmonitoring public mood. The framework is flexible and allows the design and\nimplementation of modular agents, where simple modules cooperate in the\nannotation of a large dataset without central coordination.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.6208v2"
    },
    {
        "title": "Simulation leagues: Analysis of competition formats",
        "authors": [
            "David Budden",
            "Peter Wang",
            "Oliver Obst",
            "Mikhail Prokopenko"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The selection of an appropriate competition format is critical for both the\nsuccess and credibility of any competition, both real and simulated. In this\npaper, the automated parallelism offered by the RoboCupSoccer 2D simulation\nleague is leveraged to conduct a 28,000 game round-robin between the top 8\nteams from RoboCup 2012 and 2013. A proposed new competition format is found to\nreduce variation from the resultant statistically significant team performance\nrankings by 75% and 67%, when compared to the actual competition results from\nRoboCup 2012 and 2013 respectively. These results are statistically validated\nby generating 10,000 random tournaments for each of the three considered\nformats and comparing the respective distributions of ranking discrepancy.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.4023v2"
    },
    {
        "title": "Don't Believe Everything You Hear; Preserving Relevant Information by\n  Discarding Social Information",
        "authors": [
            "Christoph Salge",
            "Daniel Polani"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Integrating information gained by observing others via Social Bayesian\nLearning can be beneficial for an agent's performance, but can also enable\npopulation wide information cascades that perpetuate false beliefs through the\nagent population. We show how agents can influence the observation network by\nchanging their probability of observing others, and demonstrate the existence\nof a population-wide equilibrium, where the advantages and disadvantages of the\nSocial Bayesian update are balanced. We also use the formalism of relevant\ninformation to illustrate how negative information cascades are characterized\nby processing increasing amounts of non-relevant information.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.1034v1"
    },
    {
        "title": "Crowdsourcing for Participatory Democracies: Efficient Elicitation of\n  Social Choice Functions",
        "authors": [
            "David Lee",
            "Ashish Goel",
            "Tanja Aitamurto",
            "Helene Landemore"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We present theoretical and empirical results demonstrating the usefulness of\nvoting rules for participatory democracies. We first give algorithms which\nefficiently elicit \\epsilon-approximations to two prominent voting rules: the\nBorda rule and the Condorcet winner. This result circumvents previous\nprohibitive lower bounds and is surprisingly strong: even if the number of\nideas is as large as the number of participants, each participant will only\nhave to make a logarithmic number of comparisons, an exponential improvement\nover the linear number of comparisons previously needed. We demonstrate the\napproach in an experiment in Finland's recent off-road traffic law reform,\nobserving that the total number of comparisons needed to achieve a fixed\n\\epsilon approximation is linear in the number of ideas and that the constant\nis not large.\n  Finally, we note a few other experimental observations which support the use\nof voting rules for aggregation. First, we observe that rating, one of the\ncommon alternatives to ranking, manifested effects of bias in our data. Second,\nwe show that very few of the topics lacked a Condorcet winner, one of the\nprominent negative results in voting. Finally, we show data hinting at a\npotential future direction: the use of partial rankings as opposed to pairwise\ncomparisons to further decrease the elicitation time.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.7542v2"
    },
    {
        "title": "A Psychologically-Motivated Model of Opinion Change with Applications to\n  American Politics",
        "authors": [
            "Peter Duggins"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  Agent-based models are versatile tools for studying how societal opinion\nchange, including political polarization and cultural diffusion, emerges from\nindividual behavior. This study expands agents' psychological realism using\nempirically-motivated rules governing interpersonal influence, commitment to\nprevious beliefs, and conformity in social contexts. Computational experiments\nestablish that these extensions produce three novel results: (a) sustained\nstrong diversity of opinions within the population, (b) opinion subcultures,\nand (c) pluralistic ignorance. These phenomena arise from a combination of\nagents' intolerance, susceptibility and conformity, with extremist agents and\nsocial networks playing important roles. The distribution and dynamics of\nsimulated opinions reproduce two empirical datasets on Americans' political\nopinions.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.7770v3"
    },
    {
        "title": "Information Exchange and Learning Dynamics over Weakly-Connected\n  Adaptive Networks",
        "authors": [
            "Bicheng Ying",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The paper examines the learning mechanism of adaptive agents over\nweakly-connected graphs and reveals an interesting behavior on how information\nflows through such topologies. The results clarify how asymmetries in the\nexchange of data can mask local information at certain agents and make them\ntotally dependent on other agents. A leader-follower relationship develops with\nthe performance of some agents being fully determined by the performance of\nother agents that are outside their domain of influence. This scenario can\narise, for example, due to intruder attacks by malicious agents or as the\nresult of failures by some critical links. The findings in this work help\nexplain why strong-connectivity of the network topology, adaptation of the\ncombination weights, and clustering of agents are important ingredients to\nequalize the learning abilities of all agents against such disturbances. The\nresults also clarify how weak-connectivity can be helpful in reducing the\neffect of outlier data on learning performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.1523v2"
    },
    {
        "title": "Converting a Systems Dynamic Model to an Agent-based model for studying\n  the Bicoid morphogen gradient in Drosophila embryo",
        "authors": [
            "Mariam Kiran",
            "Wei Liu"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  The concentration gradient of the Bicoid morphogen, which is established\nduring the early stages of a Drosophila melanogaster embryonic development,\ndetermines the differential spatial patterns of gene expression and subsequent\ncell fate determination. This is mainly achieved by diffusion elicited by the\ndifferent concentrations of the Bicoid protein in the embryo. Such chemical\ndynamic progress can be simulated by stochastic models, particularly the\nGillespie alogrithm. However, as with various modelling approaches in biology,\neach technique involves drawing assumptions and reducing the model complexity\nsometimes limiting the model capability. This is mainly due to the complexity\nof the software modelling approaches to construct these models. Agent-based\nmodelling is a technique which is becoming increasingly popular for modelling\nthe behaviour of individual molecules or cells in computational biology.\n  This paper attempts to compare these two popular modelling techniques of\nstochastic and agent-based modelling to show how the model can be studied in\ndetail using the different approaches. This paper presents how to use these\ntechniques with the advantages and disadvantages of using either of these.\nThrough various comparisons, such as computation complexity and results\nobtained, we show that although the same model is implemented, both approaches\ncan give varying results. The results of the paper show that the stochastic\nmodel is able to give smoother results compared to the agent-based model which\nmay need further analysis at a later stage. We discuss the reasons for these\nresults and how these could be rectified in systems biology research.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.5459v1"
    },
    {
        "title": "Building Robust Crowdsourcing Systems with Reputation-aware Decision\n  Support Techniques",
        "authors": [
            "Han Yu"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Crowdsourcing refers to the arrangement in which contributions are solicited\nfrom a large group of unrelated people. Due to this nature, crowdsourcers (or\ntask requesters) often face uncertainty about the workers' capabilities which,\nin turn, affects the quality and timeliness of the results obtained. Trust is a\nmechanism used by people to facilitate interactions in human societies where\nrisk and uncertain are common. The crucial challenge to building a robust\ncrowdsourcing system is how to make trust-aware task delegation decisions to\nefficiently utilize the capacities of workers (or trustee agents) to achieve\nhigh social welfare?\n  This book presents the research addressing this challenge. It goes beyond the\nexisting trust management research framework by removing a widespread\nassumption implicitly adopted by existing research: that a trustee agent can\nprocess an unlimited number of interaction requests per discrete time unit\nwithout compromising its performance as perceived by the task requesters (or\ntruster agents). Decision support in crowdsourcing is re-formalized as a\nmulti-agent trust game based on the principles of the Congestion Game, which is\nsolved by two trust-aware interaction decision-making approaches: 1) the Social\nWelfare Optimizing approach for Reputation-aware Decision-making (SWORD)\napproach, and 2) the Distributed Request Acceptance approach for Fair\nutilization of Trustee agents (DRAFT). SWORD is designed for centralized\nsystems, while DRAFT is designed for fully distributed systems. Theoretical\nanalyses have shown that the social welfare produced by these two approaches\ncan be made closer to optimal by adjusting only one key parameter. With these\ntwo approaches, the framework of research for crowdsourcing systems can be\nenriched to handle more realistic scenarios where workers have varied and\nlimited capabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.02106v2"
    },
    {
        "title": "Decentralized Control of Partially Observable Markov Decision Processes\n  using Belief Space Macro-actions",
        "authors": [
            "Shayegan Omidshafiei",
            "Ali-akbar Agha-mohammadi",
            "Christopher Amato",
            "Jonathan P. How"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  The focus of this paper is on solving multi-robot planning problems in\ncontinuous spaces with partial observability. Decentralized partially\nobservable Markov decision processes (Dec-POMDPs) are general models for\nmulti-robot coordination problems, but representing and solving Dec-POMDPs is\noften intractable for large problems. To allow for a high-level representation\nthat is natural for multi-robot problems and scalable to large discrete and\ncontinuous problems, this paper extends the Dec-POMDP model to the\ndecentralized partially observable semi-Markov decision process (Dec-POSMDP).\nThe Dec-POSMDP formulation allows asynchronous decision-making by the robots,\nwhich is crucial in multi-robot domains. We also present an algorithm for\nsolving this Dec-POSMDP which is much more scalable than previous methods since\nit can incorporate closed-loop belief space macro-actions in planning. These\nmacro-actions are automatically constructed to produce robust solutions. The\nproposed method's performance is evaluated on a complex multi-robot package\ndelivery problem under uncertainty, showing that our approach can naturally\nrepresent multi-robot problems and provide high-quality solutions for\nlarge-scale problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.06030v1"
    },
    {
        "title": "Task Allocation in Robotic Swarms: Explicit Communication Based\n  Approaches",
        "authors": [
            "Aryo Jamshidpey",
            "Mohsen Afsharchi"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  In this paper we study multi robot cooperative task allocation issue in a\nsituation where a swarm of robots is deployed in a confined unknown environment\nwhere the number of colored spots which represent tasks and the ratios of them\nare unknown. The robots should cover this spots as far as possible to do\ncleaning and sampling actions desirably. It means that they should discover the\nspots cooperatively and spread proportional to the spots area and avoid from\nremaining idle. We proposed 4 self-organized distributed methods which are\ncalled hybrid methods for coping with this scenario. In two different\nexperiments the performance of the methods is analyzed. We compared them with\neach other and investigated their scalability and robustness in term of single\npoint of failure.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.00237v1"
    },
    {
        "title": "Formation of Robust Multi-Agent Networks Through Self-Organizing Random\n  Regular Graphs",
        "authors": [
            "A. Yasin Yazicioglu",
            "Magnus Egerstedt",
            "Jeff S. Shamma"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Multi-agent networks are often modeled as interaction graphs, where the nodes\nrepresent the agents and the edges denote some direct interactions. The\nrobustness of a multi-agent network to perturbations such as failures, noise,\nor malicious attacks largely depends on the corresponding graph. In many\napplications, networks are desired to have well-connected interaction graphs\nwith relatively small number of links. One family of such graphs is the random\nregular graphs. In this paper, we present a decentralized scheme for\ntransforming any connected interaction graph with a possibly non-integer\naverage degree of k into a connected random m-regular graph for some m in [k, k\n+ 2]. Accordingly, the agents improve the robustness of the network with a\nminimal change in the overall sparsity by optimizing the graph connectivity\nthrough the proposed local operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.08131v1"
    },
    {
        "title": "Dynamics of Complex Systems Built as Coupled Physical, Communication and\n  Decision Layers",
        "authors": [
            "Florian Kühnlenz",
            "Pedro H. J. Nardelli"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper proposes a simple model to capture the complexity of multi-layer\nsystems where their constituent layers affect, are affected by, each other. The\nphysical layer is a circuit composed by a power source and resistors in\nparallel. Individual agents can add, remove or keep the resistors they have,\nand their decisions aiming at maximising the delivered power - a non-linear\nfunction dependent on the others' behaviour - based on their internal state,\ntheir global state perception, the information received from their neighbours\nin the communication network, and a randomised selfishness. We develop an\nagent-based simulation to analyse the effects of number of agents (size of the\nsystem), communication network topology, communication errors and the minimum\npower gain that triggers a behavioural change. Our results show that a\nwave-like behaviour at macro-level (caused by individual changes in the\ndecision layer) can only emerge for a specific system size, the ratio between\ncooperators and defectors depends on minimum gain assumed - lower minimal gains\nlead to less cooperation and vice-versa, different communication network\ntopologies lead to different levels of power utilisation and fairness at the\nphysical layer, and a certain level of error in the communication layer leads\nto more cooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.04235v2"
    },
    {
        "title": "Multi-Target Tracking in Distributed Sensor Networks using Particle PHD\n  Filters",
        "authors": [
            "Mark R. Leonard",
            "Abdelhak M. Zoubir"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  Multi-target tracking is an important problem in civilian and military\napplications. This paper investigates multi-target tracking in distributed\nsensor networks. Data association, which arises particularly in multi-object\nscenarios, can be tackled by various solutions. We consider sequential Monte\nCarlo implementations of the Probability Hypothesis Density (PHD) filter based\non random finite sets. This approach circumvents the data association issue by\njointly estimating all targets in the region of interest. To this end, we\ndevelop the Diffusion Particle PHD Filter (D-PPHDF) as well as a centralized\nversion, called the Multi-Sensor Particle PHD Filter (MS-PPHDF). Their\nperformance is evaluated in terms of the Optimal Subpattern Assignment (OSPA)\nmetric, benchmarked against a distributed extension of the Posterior\nCram\\'er-Rao Lower Bound (PCRLB), and compared to the performance of an\nexisting distributed PHD Particle Filter. Furthermore, the robustness of the\nproposed tracking algorithms against outliers and their performance with\nrespect to different amounts of clutter is investigated.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.01668v5"
    },
    {
        "title": "Model of human collective decision-making in complex environments",
        "authors": [
            "Giuseppe Carbone",
            "Ilaria Giannoccaro"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  A continuous-time Markov process is proposed to analyze how a group of humans\nsolves a complex task, consisting in the search of the optimal set of decisions\non a fitness landscape. Individuals change their opinions driven by two\ndifferent forces: (i) the self-interest, which pushes them to increase their\nown fitness values, and (ii) the social interactions, which push individuals to\nreduce the diversity of their opinions in order to reach consensus. Results\nshow that the performance of the group is strongly affected by the strength of\nsocial interactions and by the level of knowledge of the individuals.\nIncreasing the strength of social interactions improves the performance of the\nteam. However, too strong social interactions slow down the search of the\noptimal solution and worsen the performance of the group. In particular, we\nfind that the threshold value of the social interaction strength, which leads\nto the emergence of a superior intelligence of the group, is just the critical\nthreshold at which the consensus among the members sets in. We also prove that\na moderate level of knowledge is already enough to guarantee high performance\nof the group in making decisions.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.02139v2"
    },
    {
        "title": "Modelling Structured Societies: a Multi-relational Approach to Context\n  Permeability",
        "authors": [
            "Davide Nunes",
            "Luis Antunes"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  The structure of social relations is fundamental for the construction of\nplausible simulation scenarios. It shapes the way actors interact and create\ntheir identity within overlapping social contexts. Each actor interacts in\nmultiple contexts within different types of social relations that constitute\ntheir social space. In this article, we present an approach to model structured\nagent societies with multiple coexisting social networks. We study the notion\nof context permeability, using a game in which agents try to achieve global\nconsensus. We design and analyse two different models of permeability. In the\nfirst model, agents interact concurrently in multiple social networks. In the\nsecond, we introduce a context switching mechanism which adds a dynamic\ntemporal component to agent interaction in the model. Agents switch between the\ndifferent networks spending more or less time in each one. We compare these\nmodels and analyse the influence of different social networks regarding the\nspeed of convergence to consensus. We conduct a series of experiments that show\nthe impact of different configurations for coexisting social networks. This\napproach unveils both the limitations of the current modelling approaches and\npossible research directions for complex social space simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.03826v1"
    },
    {
        "title": "Inter-Robot Interactions in Multi-Robot Systems Using Braids",
        "authors": [
            "Yancy Diaz-Mercado",
            "Magnus Egerstedt"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper describes a framework for multi-robot coordination and motion\nplanning with emphasis on inter-agent interactions. We focus on the\ncharacterization of inter-agent interactions with sufficient level of\nabstraction so as to allow for the enforcement of desired interaction patterns\nin a provably safe (i.e., collision-free) manner, e.g., for achieving rich\nmovement patterns in a shared space, or to exchange sensor information. We\npropose to specify interaction patterns through elements of the so-called braid\ngroup. This allows us to not focus on a particular pattern per se, but rather\non the problem of being able to execute a whole class of patterns. The result\nfrom such a construction is a hybrid system driven by symbolic inputs that must\nbe mapped onto actual paths that both realize the desired interaction levels\nand remain safe in the sense that collisions are avoided.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.04826v1"
    },
    {
        "title": "Confinement Control of Double Integrators using Partially Periodic\n  Leader Trajectories",
        "authors": [
            "Karthik Elamvazhuthi",
            "Sean Wilson",
            "Spring Berman"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  We consider a multi-agent confinement control problem in which a single\nleader has a purely repulsive effect on follower agents with double-integrator\ndynamics. By decomposing the leader's control inputs into periodic and\naperiodic components, we show that the leader can be driven so as to guarantee\nconfinement of the followers about a time-dependent trajectory in the plane. We\nuse tools from averaging theory and an input-to-state stability type argument\nto derive conditions on the model parameters that guarantee confinement of the\nfollowers about the trajectory. For the case of a single follower, we show that\nif the follower starts at the origin, then the error in trajectory tracking can\nbe made arbitrarily small depending on the frequency of the periodic control\ncomponents and the rate of change of the trajectory. We validate our approach\nusing simulations and experiments with a small mobile robot.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.00109v3"
    },
    {
        "title": "Track selection in Multifunction Radars for Multi-target tracking: an\n  Anti-Coordination game",
        "authors": [
            "Nikola Bogdanović",
            "Hans Driessen",
            "Alexander Yarovoy"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  In this paper, a track selection problem for multi-target tracking in a\nmultifunction radar network is studied using the concepts from game theory. The\nproblem is formulated as a non-cooperative game, and specifically as an\nanti-coordination game, where each player aims to differ from what other\nplayers do. The players' utilities are modeled using a proper tracking accuracy\ncriterion and, under different assumptions on the structure of these utilities,\nthe corresponding Nash equilibria are characterized. To find an equilibrium, a\ndistributed algorithm based on the best-response dynamics is proposed. Finally,\ncomputer simulations are carried out to verify the effectiveness of the\nproposed algorithm in a multi-target tracking scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.02032v1"
    },
    {
        "title": "Estimation of Discretized Motion of Pedestrians by the Decision-Making\n  Model",
        "authors": [
            "Pavel Hrabák",
            "Ondřej Ticháček",
            "Vladimíra Sečkárová"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  The contribution gives a micro-structural insight into the pedestrian\ndecision process during an egress situation. A method how to extract the\ndecisions of pedestrians from the trajectories recorded during the experiments\nis introduced. The underlying Markov decision process is estimated using the\nfinite mixture approximation. Furthermore, the results of this estimation can\nbe used as an input to the optimization of a Markov decision process for one\n`clever' agent. This agent optimizes his strategy of motion with respect to\ndifferent reward functions, minimizing the time spent in the room or minimizing\nthe amount of inhaled CO.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.09107v1"
    },
    {
        "title": "Proximity Without Consensus in Online Multi-Agent Optimization",
        "authors": [
            "Alec Koppel",
            "Brian M. Sadler",
            "Alejandro Ribeiro"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We consider stochastic optimization problems in multi-agent settings, where a\nnetwork of agents aims to learn parameters which are optimal in terms of a\nglobal objective, while giving preference to locally observed streaming\ninformation. To do so, we depart from the canonical decentralized optimization\nframework where agreement constraints are enforced, and instead formulate a\nproblem where each agent minimizes a global objective while enforcing network\nproximity constraints. This formulation includes online consensus optimization\nas a special case, but allows for the more general hypothesis that there is\ndata heterogeneity across the network. To solve this problem, we propose using\na stochastic saddle point algorithm inspired by Arrow and Hurwicz. This method\nyields a decentralized algorithm for processing observations sequentially\nreceived at each node of the network. Using Lagrange multipliers to penalize\nthe discrepancy between them, only neighboring nodes exchange model\ninformation. We establish that under a constant step-size regime the\ntime-average suboptimality and constraint violation are contained in a\nneighborhood whose radius vanishes with increasing number of iterations. As a\nconsequence, we prove that the time-average primal vectors converge to the\noptimal objective while satisfying the network proximity constraints. We apply\nthis method to the problem of sequentially estimating a correlated random field\nin a sensor network, as well as an online source localization problem, both of\nwhich demonstrate the empirical validity of the aforementioned convergence\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.05578v1"
    },
    {
        "title": "Coordinate-Descent Diffusion Learning by Networked Agents",
        "authors": [
            "Chengcheng Wang",
            "Yonggang Zhang",
            "Bicheng Ying",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This work examines the mean-square error performance of diffusion stochastic\nalgorithms under a generalized coordinate-descent scheme. In this setting, the\nadaptation step by each agent is limited to a random subset of the coordinates\nof its stochastic gradient vector. The selection of coordinates varies randomly\nfrom iteration to iteration and from agent to agent across the network. Such\nschemes are useful in reducing computational complexity at each iteration in\npower-intensive large data applications. They are also useful in modeling\nsituations where some partial gradient information may be missing at random.\nInterestingly, the results show that the steady-state performance of the\nlearning strategy is not always degraded, while the convergence rate suffers\nsome degradation. The results provide yet another indication of the resilience\nand robustness of adaptive distributed strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.01838v2"
    },
    {
        "title": "Multi Exit Configuration of Mesoscopic Pedestrian Simulation",
        "authors": [
            "Allan Lao",
            "Kardi Teknomo"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  A mesoscopic approach to modeling pedestrian simulation with multiple exits\nis proposed in this paper. A floor field based on Qlearning Algorithm is used.\nAttractiveness of exits to pedestrian typically is based on shortest path.\nHowever, several factors may influence pedestrian choice of exits. Scenarios\nwith multiple exits are presented and effect of Q-learning rewards system on\nnavigation is investigated\n",
        "pdf_link": "http://arxiv.org/pdf/1609.01475v1"
    },
    {
        "title": "Asynchronous and Dynamic Coverage Control Scheme for Persistent\n  Surveillance Missions",
        "authors": [
            "Jeffrey R. Peters",
            "Sean J. Wang",
            "Amit Surana",
            "Francesco Bullo"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  A decomposition-based coverage control scheme is proposed for multi-agent,\npersistent surveillance missions operating in a communication-constrained,\ndynamic environment. The proposed approach decouples high-level task assignment\nfrom low-level motion planning in a modular framework. Coverage assignments and\nsurveillance parameters are managed by a central base station, and transmitted\nto mobile agents via unplanned and asynchronous exchanges. Coverage updates\npromote load balancing, while maintaining geometric and temporal\ncharacteristics that allow effective pairing with generic path planners.\nNamely, the proposed scheme guarantees that (i) coverage regions are connected\nand collectively cover the environment, (ii) subregions may only go uncovered\nfor bounded periods of time, (iii) collisions (or sensing overlaps) are\ninherently avoided, and (iv) under static event likelihoods, the collective\ncoverage regions converge to a Pareto-optimal configuration. This management\nscheme is then paired with a generic path planner satisfying loose assumptions.\nThe scheme is illustrated through simulated surveillance missions.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.05264v2"
    },
    {
        "title": "Distributed Consistent Data Association",
        "authors": [
            "Spyridon Leonardos",
            "Xiaowei Zhou",
            "Kostas Daniilidis"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Data association is one of the fundamental problems in multi-sensor systems.\nMost current techniques rely on pairwise data associations which can be\nspurious even after the employment of outlier rejection schemes. Considering\nmultiple pairwise associations at once significantly increases accuracy and\nleads to consistency. In this work, we propose two fully decentralized methods\nfor consistent global data association from pairwise data associations. The\nfirst method is a consensus algorithm on the set of doubly stochastic matrices.\nThe second method is a decentralization of the spectral method proposed by\nPachauri et al.. We demonstrate the effectiveness of both methods using\ntheoretical analysis and experimental evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.07015v2"
    },
    {
        "title": "Simultaneous Intermittent Communication Control and Path Optimization in\n  Networks of Mobile Robots",
        "authors": [
            "Yiannis Kantaros",
            "Michael M. Zavlanos"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  In this paper, we propose an intermittent communication framework for mobile\nrobot networks. Specifically, we consider robots that move along the edges of a\nconnected mobility graph and communicate only when they meet at the nodes of\nthat graph giving rise to a dynamic communication network. Our proposed\ndistributed controllers ensure intermittent connectivity of the network and\npath optimization, simultaneously. We show that the intermittent connectivity\nrequirement can be encapsulated by a global Linear Temporal Logic (LTL)\nformula. Then we approximately decompose it into local LTL expressions which\nare then assigned to the robots. To avoid conflicting robot behaviors that can\noccur due to this approximate decomposition, we develop a distributed conflict\nresolution scheme that generates non-conflicting discrete motion plans for\nevery robot, based on the assigned local LTL expressions, whose composition\nsatisfies the global LTL formula. By appropriately introducing delays in the\nexecution of the generated motion plans we also show that the proposed\ncontrollers can be executed asynchronously.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.07038v1"
    },
    {
        "title": "A Passivity-Based Distributed Reference Governor for Constrained Robotic\n  Networks",
        "authors": [
            "Tam Nguyen",
            "Takeshi Hatanaka",
            "Mamoru Doi",
            "Emanuele Garone",
            "Masayuki Fujita"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper focuses on a passivity-based distributed reference governor (RG)\napplied to a pre-stabilized mobile robotic network. The novelty of this paper\nlies in the method used to solve the RG problem, where a passivity-based\ndistributed optimization scheme is proposed. In particular, the gradient\ndescent method minimizes the global objective function while the dual ascent\nmethod maximizes the Hamiltonian. To make the agents converge to the agreed\noptimal solution, a proportional-integral consensus estimator is used. This\npaper proves the convergence of the state estimates of the RG to the optimal\nsolution through passivity arguments, considering the physical system static.\nThen, the effectiveness of the scheme considering the dynamics of the physical\nsystem is demonstrated through simulations and experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.06416v1"
    },
    {
        "title": "The Social Benefits of Balancing Creativity and Imitation: Evidence from\n  an Agent-based Model",
        "authors": [
            "Liane Gabora",
            "Simon Tseng"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Although creativity is encouraged in the abstract it is often discouraged in\neducational and workplace settings. Using an agent-based model of cultural\nevolution, we investigated the idea that tempering the novelty-generating\neffects of creativity with the novelty-preserving effects of imitation is\nbeneficial for society. In Experiment One we systematically introduced\nindividual differences in creativity, and observed a trade-off between the\nratio of creators to imitators, and how creative the creators were. Excess\ncreativity was detrimental because creators invested in unproven ideas at the\nexpense of propagating proven ones. Experiment Two tested the hypothesis that\nsociety as a whole benefits if individuals adjust how creative they are in\naccordance with their creative success. When effective creators created more,\nand ineffective creators created less (social regulation), the agents\nsegregated into creators and imitators, and the mean fitness of outputs was\ntemporarily higher. We hypothesized that the temporary nature of the effect was\ndue to a ceiling on output fitness. In Experiment Three we made the space of\npossible outputs open-ended by giving agents the capacity to chain simple\noutputs into arbitrarily complex ones such that fitter outputs were always\npossible. With the capacity for chained outputs, the effect of social\nregulation could indeed be maintained indefinitely. The results are discussed\nin light of empirical data.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00107v1"
    },
    {
        "title": "Stability and Performance of Coalitions of Prosumers Through\n  Diversification in the Smart Grid",
        "authors": [
            "Nicolas Gensollen",
            "Vincent Gauthier",
            "Monique Becker",
            "Michel Marot"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Achieving a successful energetic transition through a smarter and greener\nelectricity grid is a major goal for the 21st century. It is assumed that such\nsmart grids will be characterized by bidirectional electricity flows coupled\nwith the use of small renewable generators and a proper efficient information\nsystem. All these bricks might enable end users to take part in the grid\nstability by injecting power, or by shaping their consumption against financial\ncompensation. In this paper, we propose an algorithm that forms coalitions of\nagents, called prosumers, that both produce and consume. It is designed to be\nused by aggregators that aim at selling the aggregated surplus of production of\nthe prosumers they control. We rely on real weather data sampled across\nstations of a given territory in order to simulate realistic production and\nconsumption patterns for each prosumer. This approach enables us to capture\ngeographical correlations among the agents while preserving the diversity due\nto different behaviors. As aggregators are bound to the grid operator by a\ncontract, they seek to maximize their offer while minimizing their risk. The\nproposed graph based algorithm takes the underlying correlation structure of\nthe agents into account and outputs coalitions with both high productivity and\nlow variability. We show then that the resulting diversified coalitions are\nable to generate higher benefits on a constrained energy market, and are more\nresilient to random failures of the agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.06130v1"
    },
    {
        "title": "A Novel Formal Agent-based Simulation Modeling Framework of an AIDS\n  Complex Adaptive System",
        "authors": [
            "Amnah Siddiqa",
            "Muaz A. Niazi"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  HIV/AIDS spread depends upon complex patterns of interaction among various\nsub-sets emerging at population level. This added complexity makes it difficult\nto study and model AIDS and its dynamics. AIDS is therefore a natural candidate\nto be modeled using agent-based modeling, a paradigm well-known for modeling\nComplex Adaptive Systems (CAS). While agent-based models are also well-known to\neffectively model CAS, often times models can tend to be ambiguous and the use\nof purely text-based specifications (such as ODD) can make models difficult to\nbe replicated. Previous work has shown how formal specification may be used in\nconjunction with agent-based modeling to develop models of various CAS.\nHowever, to the best of our knowledge, no such model has been developed in\nconjunction with AIDS. In this paper, we present a Formal Agent-Based\nSimulation modeling framework (FABS-AIDS) for an AIDS-based CAS. FABS-AIDS\nemploys the use of a formal specification model in conjunction with an\nagent-based model to reduce ambiguity as well as improve clarity in the model\ndefinition. The proposed model demonstrates the effectiveness of using formal\nspecification in conjunction with agent-based simulation for developing models\nof CAS in general and, social network-based agent-based models, in particular.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.02938v1"
    },
    {
        "title": "A Simple and Realistic Pedestrian Model for Crowd Simulation and\n  Application",
        "authors": [
            "Wonho Kang",
            "Youngnam Han"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The simulation of pedestrian crowd that reflects reality is a major challenge\nfor researches. Several crowd simulation models have been proposed such as\ncellular automata model, agent-based model, fluid dynamic model, etc. It is\nimportant to note that agent-based model is able, over others approaches, to\nprovide a natural description of the system and then to capture complex human\nbehaviors. In this paper, we propose a multi-agent simulation model in which\npedestrian positions are updated at discrete time intervals. It takes into\naccount the major normal conditions of a simple pedestrian situated in a crowd\nsuch as preferences, realistic perception of environment, etc. Our objective is\nto simulate the pedestrian crowd realistically towards a simulation of\nbelievable pedestrian behaviors. Typical pedestrian phenomena, including the\nunidirectional and bidirectional movement in a corridor as well as the flow\nthrough bottleneck, are simulated. The conducted simulations show that our\nmodel is able to produce realistic pedestrian behaviors. The obtained\nfundamental diagram and flow rate at bottleneck agree very well with classic\nconclusions and empirical study results. It is hoped that the idea of this\nstudy may be helpful in promoting the modeling and simulation of pedestrian\ncrowd in a simple way.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.03080v2"
    },
    {
        "title": "Resilient Autonomous Control of Distributed Multi-agent Systems in\n  Contested Environments",
        "authors": [
            "Rohollah Moghadam",
            "Hamidreza Modares"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  An autonomous and resilient controller is proposed for leader-follower\nmulti-agent systems under uncertainties and cyber-physical attacks. The leader\nis assumed non-autonomous with a nonzero control input, which allows changing\nthe team behavior or mission in response to environmental changes. A resilient\nlearning-based control protocol is presented to find optimal solutions to the\nsynchronization problem in the presence of attacks and system dynamic\nuncertainties. An observer-based distributed H_infinity controller is first\ndesigned to prevent propagating the effects of attacks on sensors and actuators\nthroughout the network, as well as to attenuate the effect of these attacks on\nthe compromised agent itself. Non-homogeneous game algebraic Riccati equations\nare derived to solve the H_infinity optimal synchronization problem and\noff-policy reinforcement learning is utilized to learn their solution without\nrequiring any knowledge of the agent's dynamics. A trust-confidence based\ndistributed control protocol is then proposed to mitigate attacks that hijack\nthe entire node and attacks on communication links. A confidence value is\ndefined for each agent based solely on its local evidence. The proposed\nresilient reinforcement learning algorithm employs the confidence value of each\nagent to indicate the trustworthiness of its own information and broadcast it\nto its neighbors to put weights on the data they receive from it during and\nafter learning. If the confidence value of an agent is low, it employs a trust\nmechanism to identify compromised agents and remove the data it receives from\nthem from the learning process. Simulation results are provided to show the\neffectiveness of the proposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.09630v4"
    },
    {
        "title": "Consensus of second order multi-agents with actuator saturation and\n  asynchronous time-delays",
        "authors": [
            "Venkata Karteek Yanumula",
            "Indrani Kar",
            "Somanath Majhi"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This article presents the consensus of a saturated second order multi-agent\nsystem with non-switching dynamics that can be represented by a directed graph.\nThe system is affected by data processing (input delay) and communication\ntime-delays that are assumed to be asynchronous. The agents have saturation\nnonlinearities, each of them is approximated into separate linear and nonlinear\nelements. Nonlinear elements are represented by describing functions.\nDescribing functions and stability of linear elements are used to estimate the\nexistence of limit cycles in the system with multiple control laws. Stability\nanalysis of the linear element is performed using Lyapunov-Krasovskii functions\nand frequency domain analysis. A comparison of pros and cons of both the\nanalyses with respect to time-delay ranges, applicability and computation\ncomplexity is presented. Simulation and corresponding hardware implementation\nresults are demonstrated to support theoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.00951v3"
    },
    {
        "title": "Features of Agent-based Models",
        "authors": [
            "Reiko Heckel",
            "Alexander Kurz",
            "Edmund Chattoe-Brown"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The design of agent-based models (ABMs) is often ad-hoc when it comes to\ndefining their scope. In order for the inclusion of features such as network\nstructure, location, or dynamic change to be justified, their role in a model\nshould be systematically analysed. We propose a mechanism to compare and assess\nthe impact of such features. In particular we are using techniques from\nsoftware engineering and semantics to support the development and assessment of\nABMs, such as graph transformations as semantic representations for agent-based\nmodels, feature diagrams to identify ingredients under consideration, and\nextension relations between graph transformation systems to represent model\nfragments expressing features.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.09496v1"
    },
    {
        "title": "Toward a Theory of Markov Influence Systems and their Renormalization",
        "authors": [
            "Bernard Chazelle"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We introduce the concept of a Markov influence system (MIS) and analyze its\ndynamics. An MIS models a random walk in a graph whose edges and transition\nprobabilities change endogenously as a function of the current distribution.\nThis article consists of two independent parts: in the first one, we generalize\nthe standard classification of Markov chain states to the time-varying case by\nshowing how to \"parse\" graph sequences; in the second part, we use this\nframework to carry out the bifurcation analysis of a few important MIS\nfamilies. We show that, in general, these systems can be chaotic but that\nirreducible MIS are almost always asymptotically periodic. We give an example\nof \"hyper-torpid\" mixing, where a stationary distribution is reached in\nsuper-exponential time, a timescale beyond the reach of any Markov chain.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.01208v3"
    },
    {
        "title": "Mean Field Multi-Agent Reinforcement Learning",
        "authors": [
            "Yaodong Yang",
            "Rui Luo",
            "Minne Li",
            "Ming Zhou",
            "Weinan Zhang",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Existing multi-agent reinforcement learning methods are limited typically to\na small number of agents. When the agent number increases largely, the learning\nbecomes intractable due to the curse of the dimensionality and the exponential\ngrowth of agent interactions. In this paper, we present \\emph{Mean Field\nReinforcement Learning} where the interactions within the population of agents\nare approximated by those between a single agent and the average effect from\nthe overall population or neighboring agents; the interplay between the two\nentities is mutually reinforced: the learning of the individual agent's optimal\npolicy depends on the dynamics of the population, while the dynamics of the\npopulation change according to the collective patterns of the individual\npolicies. We develop practical mean field Q-learning and mean field\nActor-Critic algorithms and analyze the convergence of the solution to Nash\nequilibrium. Experiments on Gaussian squeeze, Ising model, and battle games\njustify the learning effectiveness of our mean field approaches. In addition,\nwe report the first result to solve the Ising model via model-free\nreinforcement learning methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.05438v5"
    },
    {
        "title": "Weighted Double Deep Multiagent Reinforcement Learning in Stochastic\n  Cooperative Environments",
        "authors": [
            "Yan Zheng",
            "Jianye Hao",
            "Zongzhang Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Recently, multiagent deep reinforcement learning (DRL) has received\nincreasingly wide attention. Existing multiagent DRL algorithms are inefficient\nwhen facing with the non-stationarity due to agents update their policies\nsimultaneously in stochastic cooperative environments. This paper extends the\nrecently proposed weighted double estimator to the multiagent domain and\npropose a multiagent DRL framework, named weighted double deep Q-network\n(WDDQN). By utilizing the weighted double estimator and the deep neural\nnetwork, WDDQN can not only reduce the bias effectively but also be extended to\nscenarios with raw visual inputs. To achieve efficient cooperation in the\nmultiagent domain, we introduce the lenient reward network and the scheduled\nreplay strategy. Experiments show that the WDDQN outperforms the existing DRL\nand multiaent DRL algorithms, i.e., double DQN and lenient Q-learning, in terms\nof the average reward and the convergence rate in stochastic cooperative\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.08534v2"
    },
    {
        "title": "This One Simple Trick Disrupts Digital Communities",
        "authors": [
            "Philip Feldman",
            "Aaron Dant",
            "Wayne Lutters"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper describes an agent based simulation used to model human actions in\nbelief space, a high-dimensional subset of information space associated with\nopinions. Using insights from animal collective behavior, we are able to\nsimulate and identify behavior patterns that are similar to nomadic, flocking\nand stampeding patterns of animal groups. These behaviors have analogous\nmanifestations in human interaction, emerging as solitary explorers, the\nfashion-conscious, and members of polarized echo chambers. We demonstrate that\na small portion of nomadic agents that widely traverse belief space can disrupt\na larger population of stampeding agents. Extending the model, we introduce the\nconcept of Adversarial Herding, where bad actors can exploit properties of\ntechnologically mediated communication to artificially create self sustaining\nrunaway polarization. We call this condition the Pishkin Effect as it recalls\nthe large scale buffalo stampedes that could be created by native Americans\nhunters. We then discuss opportunities for system design that could leverage\nthe ability to recognize these negative patterns, and discuss affordances that\nmay disrupt the formation of natural and deliberate echo chambers.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.02251v2"
    },
    {
        "title": "Analysis of the Social Community Based on the Network Growing Model in\n  Open Source Software Community",
        "authors": [
            "Takumi Ichimura",
            "Takuya Uemoto"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The social community in open source software developers has a complex network\nstructure. The network structure represents the relations between the project\nand the engineer in the software developer's community. A project forms some\nteams which consist of engineers categorized into some task group. Source Forge\nis well known to be one of open source websites. The node and arc in the\nnetwork structure means the engineer and their connection among engineers in\nthe Source Forge. In the previous study, we found the growing process of\nproject becomes strong according to the number of developers joining into the\nproject. In the growing phase, we found some characteristic patterns between\nthe number of agents and the produced projects. By such observations, we\ndeveloped a simulation model of performing the growing process of project. In\nthis paper, we introduced the altruism behavior as shown in the Army Ant model\ninto the software developer's simulation model. The efficiency of the software\ndeveloping process was investigated by some experimental simulation results.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.02822v1"
    },
    {
        "title": "Complexity Reduction in the Negotiation of New Lexical Conventions",
        "authors": [
            "William Schueller",
            "Vittorio Loreto",
            "Pierre-Yves Oudeyer"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In the process of collectively inventing new words for new concepts in a\npopulation, conflicts can quickly become numerous, in the form of synonymy and\nhomonymy. Remembering all of them could cost too much memory, and remembering\ntoo few may slow down the overall process. Is there an efficient behavior that\ncould help balance the two? The Naming Game is a multi-agent computational\nmodel for the emergence of language, focusing on the negotiation of new lexical\nconventions, where a common lexicon self-organizes but going through a phase of\nhigh complexity. Previous work has been done on the control of complexity\ngrowth in this particular model, by allowing agents to actively choose what\nthey talk about. However, those strategies were relying on ad hoc heuristics\nhighly dependent on fine-tuning of parameters. We define here a new principled\nmeasure and a new strategy, based on the beliefs of each agent on the global\nstate of the population. The measure does not rely on heavy computation, and is\ncognitively plausible. The new strategy yields an efficient control of\ncomplexity growth, along with a faster agreement process. Also, we show that\nshort-term memory is enough to build relevant beliefs about the global lexicon.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.05631v2"
    },
    {
        "title": "Accelerated Gossip in Networks of Given Dimension using Jacobi\n  Polynomial Iterations",
        "authors": [
            "Raphaël Berthier",
            "Francis Bach",
            "Pierre Gaillard"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Consider a network of agents connected by communication links, where each\nagent holds a real value. The gossip problem consists in estimating the average\nof the values diffused in the network in a distributed manner. We develop a\nmethod solving the gossip problem that depends only on the spectral dimension\nof the network, that is, in the communication network set-up, the dimension of\nthe space in which the agents live. This contrasts with previous work that\nrequired the spectral gap of the network as a parameter, or suffered from slow\nmixing. Our method shows an important improvement over existing algorithms in\nthe non-asymptotic regime, i.e., when the values are far from being fully mixed\nin the network. Our approach stems from a polynomial-based point of view on\ngossip algorithms, as well as an approximation of the spectral measure of the\ngraphs with a Jacobi measure. We show the power of the approach with\nsimulations on various graphs, and with performance guarantees on graphs of\nknown spectral dimension, such as grids and random percolation bonds. An\nextension of this work to distributed Laplacian solvers is discussed. As a side\nresult, we also use the polynomial-based point of view to show the convergence\nof the message passing algorithm for gossip of Moallemi \\& Van Roy on regular\ngraphs. The explicit computation of the rate of the convergence shows that\nmessage passing has a slow rate of convergence on graphs with small spectral\ngap.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.08531v4"
    },
    {
        "title": "An Optimal Rewiring Strategy for Reinforcement Social Learning in\n  Cooperative Multiagent Systems",
        "authors": [
            "Hongyao Tang",
            "Li Wang",
            "Zan Wang",
            "Tim Baarslag",
            "Jianye Hao"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Multiagent coordination in cooperative multiagent systems (MASs) has been\nwidely studied in both fixed-agent repeated interaction setting and the static\nsocial learning framework. However, two aspects of dynamics in real-world\nmultiagent scenarios are currently missing in existing works. First, the\nnetwork topologies can be dynamic where agents may change their connections\nthrough rewiring during the course of interactions. Second, the game matrix\nbetween each pair of agents may not be static and usually not known as a prior.\nBoth the network dynamic and game uncertainty increase the coordination\ndifficulty among agents. In this paper, we consider a multiagent dynamic social\nlearning environment in which each agent can choose to rewire potential\npartners and interact with randomly chosen neighbors in each round. We propose\nan optimal rewiring strategy for agents to select most beneficial peers to\ninteract with for the purpose of maximizing the accumulated payoff in repeated\ninteractions. We empirically demonstrate the effectiveness and robustness of\nour approach through comparing with benchmark strategies. The performance of\nthree representative learning strategies under our social learning framework\nwith our optimal rewiring is investigated as well.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.08588v1"
    },
    {
        "title": "Local Tomography of Large Networks under the Low-Observability Regime",
        "authors": [
            "Augusto Santos",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This article studies the problem of reconstructing the topology of a network\nof interacting agents via observations of the state-evolution of the agents. We\nfocus on the large-scale network setting with the additional constraint of\n$partial$ observations, where only a small fraction of the agents can be\nfeasibly observed. The goal is to infer the underlying subnetwork of\ninteractions and we refer to this problem as $local$ $tomography$. In order to\nstudy the large-scale setting, we adopt a proper stochastic formulation where\nthe unobserved part of the network is modeled as an Erd\\\"{o}s-R\\'enyi random\ngraph, while the observable subnetwork is left arbitrary. The main result of\nthis work is establishing that, under this setting, local tomography is\nactually possible with high probability, provided that certain conditions on\nthe network model are met (such as stability and symmetry of the network\ncombination matrix). Remarkably, such conclusion is established under the\n$low$-$observability$ $regime$, where the cardinality of the observable\nsubnetwork is fixed, while the size of the overall network scales to infinity.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.09081v3"
    },
    {
        "title": "Supervised Learning Under Distributed Features",
        "authors": [
            "Bicheng Ying",
            "Kun Yuan",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This work studies the problem of learning under both large datasets and\nlarge-dimensional feature space scenarios. The feature information is assumed\nto be spread across agents in a network, where each agent observes some of the\nfeatures. Through local cooperation, the agents are supposed to interact with\neach other to solve an inference problem and converge towards the global\nminimizer of an empirical risk. We study this problem exclusively in the primal\ndomain, and propose new and effective distributed solutions with guaranteed\nconvergence to the minimizer with linear rate under strong convexity. This is\nachieved by combining a dynamic diffusion construction, a pipeline strategy,\nand variance-reduced techniques. Simulation results illustrate the conclusions.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.11384v3"
    },
    {
        "title": "A Survey and Critique of Multiagent Deep Reinforcement Learning",
        "authors": [
            "Pablo Hernandez-Leal",
            "Bilal Kartal",
            "Matthew E. Taylor"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Deep reinforcement learning (RL) has achieved outstanding results in recent\nyears. This has led to a dramatic increase in the number of applications and\nmethods. Recent works have explored learning beyond single-agent scenarios and\nhave considered multiagent learning (MAL) scenarios. Initial results report\nsuccesses in complex multiagent domains, although there are several challenges\nto be addressed. The primary goal of this article is to provide a clear\noverview of current multiagent deep reinforcement learning (MDRL) literature.\nAdditionally, we complement the overview with a broader analysis: (i) we\nrevisit previous key components, originally presented in MAL and RL, and\nhighlight how they have been adapted to multiagent deep reinforcement learning\nsettings. (ii) We provide general guidelines to new practitioners in the area:\ndescribing lessons learned from MDRL works, pointing to recent benchmarks, and\noutlining open avenues of research. (iii) We take a more critical tone raising\npractical challenges of MDRL (e.g., implementation and computational demands).\nWe expect this article will help unify and motivate future research to take\nadvantage of the abundant literature that exists (e.g., RL and MAL) in a joint\neffort to promote fruitful research in the multiagent community.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.05587v3"
    },
    {
        "title": "Agent-based models of collective intelligence",
        "authors": [
            "Sandro M. Reia",
            "André C. Amado",
            "José F. Fontanari"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Collective or group intelligence is manifested in the fact that a team of\ncooperating agents can solve problems more efficiently than when those agents\nwork in isolation. Although cooperation is, in general, a successful problem\nsolving strategy, it is not clear whether it merely speeds up the time to find\nthe solution, or whether it alters qualitatively the statistical signature of\nthe search for the solution. Here we review and offer insights on two\nagent-based models of distributed cooperative problem-solving systems, whose\ntask is to solve a cryptarithmetic puzzle. The first model is the imitative\nlearning search in which the agents exchange information on the quality of\ntheir partial solutions to the puzzle and imitate the most successful agent in\nthe group. This scenario predicts a very poor performance in the case imitation\nis too frequent or the group is too large, a phenomenon akin to Groupthink of\nsocial psychology. The second model is the blackboard organization in which\nagents read and post hints on a public blackboard. This brainstorming scenario\nperforms the best when there is a stringent limit to the amount of information\nthat is exhibited on the board. Both cooperative scenarios produce a\nsubstantial speed up of the time to solve the puzzle as compared with the\nsituation where the agents work in isolation. The statistical signature of the\nsearch, however, is the same as that of the independent search.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.11634v1"
    },
    {
        "title": "Individual decision making in task-oriented groups",
        "authors": [
            "Sandro M. Reia",
            "Paulo F. Gomes",
            "José F. Fontanari"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The strategies adopted by individuals to select relevant information to pass\non are central to understanding problem solving by groups. Here we use\nagent-based simulations to revisit a cooperative problem-solving scenario where\nthe task is to find the common card in decks distributed to the group members.\nThe agents can display only a sample of their cards and we explore different\nstrategies to select those samples based on the confidences assigned to the\ncards. An agent's confidence that a particular card is the correct one is given\nby the number of times it observed that card in the decks of the other agents.\nWe use a Gibbs distribution to select the card samples with the temperature\nmeasuring the strength of a noise that prevents the agents to correctly rank\nthe cards. The group is guaranteed to find the common card in all runs solely\nin the infinite temperature limit, where the cards are sampled regardless of\ntheir confidences. In this case, we obtain the scaling form of the time\nconstant that characterizes the asymptotic exponential decay of the failure\nprobability. For finite time, however, a finite temperature yields a\nprobability of failure that is several orders of magnitude lower than in the\ninfinite temperature limit. The available experimental results are consistent\nwith the decision-making model for finite temperature only.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.06136v1"
    },
    {
        "title": "Neural MMO: A Massively Multiagent Game Environment for Training and\n  Evaluating Intelligent Agents",
        "authors": [
            "Joseph Suarez",
            "Yilun Du",
            "Phillip Isola",
            "Igor Mordatch"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The emergence of complex life on Earth is often attributed to the arms race\nthat ensued from a huge number of organisms all competing for finite resources.\nWe present an artificial intelligence research environment, inspired by the\nhuman game genre of MMORPGs (Massively Multiplayer Online Role-Playing Games,\na.k.a. MMOs), that aims to simulate this setting in microcosm. As with MMORPGs\nand the real world alike, our environment is persistent and supports a large\nand variable number of agents. Our environment is well suited to the study of\nlarge-scale multiagent interaction: it requires that agents learn robust combat\nand navigation policies in the presence of large populations attempting to do\nthe same. Baseline experiments reveal that population size magnifies and\nincentivizes the development of skillful behaviors and results in agents that\noutcompete agents trained in smaller populations. We further show that the\npolicies of agents with unshared weights naturally diverge to fill different\nniches in order to avoid competition.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.00784v1"
    },
    {
        "title": "Microscopic Traffic Simulation by Cooperative Multi-agent Deep\n  Reinforcement Learning",
        "authors": [
            "Giulio Bacchiani",
            "Daniele Molinari",
            "Marco Patander"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Expert human drivers perform actions relying on traffic laws and their\nprevious experience. While traffic laws are easily embedded into an artificial\nbrain, modeling human complex behaviors which come from past experience is a\nmore challenging task. One of these behaviors is the capability of\ncommunicating intentions and negotiating the right of way through driving\nactions, as when a driver is entering a crowded roundabout and observes other\ncars movements to guess the best time to merge in. In addition, each driver has\nits own unique driving style, which is conditioned by both its personal\ncharacteristics, such as age and quality of sight, and external factors, such\nas being late or in a bad mood. For these reasons, the interaction between\ndifferent drivers is not trivial to simulate in a realistic manner. In this\npaper, this problem is addressed by developing a microscopic simulator using a\nDeep Reinforcement Learning Algorithm based on a combination of visual frames,\nrepresenting the perception around the vehicle, and a vector of numerical\nparameters. In particular, the algorithm called Asynchronous Advantage\nActor-Critic has been extended to a multi-agent scenario in which every agent\nneeds to learn to interact with other similar agents. Moreover, the model\nincludes a novel architecture such that the driving style of each vehicle is\nadjustable by tuning some of its input parameters, permitting to simulate\ndrivers with different levels of aggressiveness and desired cruising speeds.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.01365v1"
    },
    {
        "title": "Simulating Emergent Properties of Human Driving Behavior Using\n  Multi-Agent Reward Augmented Imitation Learning",
        "authors": [
            "Raunak P. Bhattacharyya",
            "Derek J. Phillips",
            "Changliu Liu",
            "Jayesh K. Gupta",
            "Katherine Driggs-Campbell",
            "Mykel J. Kochenderfer"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Recent developments in multi-agent imitation learning have shown promising\nresults for modeling the behavior of human drivers. However, it is challenging\nto capture emergent traffic behaviors that are observed in real-world datasets.\nSuch behaviors arise due to the many local interactions between agents that are\nnot commonly accounted for in imitation learning. This paper proposes Reward\nAugmented Imitation Learning (RAIL), which integrates reward augmentation into\nthe multi-agent imitation learning framework and allows the designer to specify\nprior knowledge in a principled fashion. We prove that convergence guarantees\nfor the imitation learning process are preserved under the application of\nreward augmentation. This method is validated in a driving scenario, where an\nentire traffic scene is controlled by driving policies learned using our\nproposed algorithm. Further, we demonstrate improved performance in comparison\nto traditional imitation learning algorithms both in terms of the local actions\nof a single agent and the behavior of emergent properties in complex,\nmulti-agent settings.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.05766v1"
    },
    {
        "title": "How to Make Swarms Open-Ended? Evolving Collective Intelligence Through\n  a Constricted Exploration of Adjacent Possibles",
        "authors": [
            "Olaf Witkowski",
            "Takashi Ikegami"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We propose an approach of open-ended evolution via the simulation of swarm\ndynamics. In nature, swarms possess remarkable properties, which allow many\norganisms, from swarming bacteria to ants and flocking birds, to form\nhigher-order structures that enhance their behavior as a group. Swarm\nsimulations highlight three important factors to create novelty and diversity:\n(a) communication generates combinatorial cooperative dynamics, (b) concurrency\nallows for separation of timescales, and (c) complexity and size increases push\nthe system towards transitions in innovation. We illustrate these three\ncomponents in a model computing the continuous evolution of a swarm of agents.\nThe results, divided in three distinct applications, show how emergent\nstructures are capable of filtering information through the bottleneck of their\nmemory, to produce meaningful novelty and diversity within their simulated\nenvironment.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.08228v1"
    },
    {
        "title": "Institutional Grammar 2.0 Codebook",
        "authors": [
            "Christopher K. Frantz",
            "Saba N. Siddiki"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The Grammar of Institutions, or Institutional Grammar, is an established\napproach to encode policy information in terms of institutional statements\nbased on a set of pre-defined syntactic components. This codebook provides\ncoding guidelines for a revised version of the Institutional Grammar, the\nInstitutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at\nfacilitating the encoding of policy to meet varying analytical objectives. To\nthis end, it revises the grammar with respect to comprehensiveness,\nflexibility, and specificity by offering multiple levels of expressiveness (IG\nCore, IG Extended, IG Logico). In addition to the encoding of regulative\nstatements, it further introduces the encoding of constitutive institutional\nstatements, as well as statements that exhibit both constitutive and regulative\ncharacteristics. Introducing those aspects, the codebook initially covers\nfundamental concepts of IG 2.0, before providing an overview of pre-coding\nsteps relevant for document preparation. Detailed coding guidelines are\nprovided for both regulative and constitutive statements across all levels of\nexpressiveness, along with the encoding guidelines for statements of mixed form\n-- hybrid and polymorphic institutional statements. The document further\nprovides an overview of taxonomies used in the encoding process and referred to\nthroughout the codebook. The codebook concludes with a summary and discussion\nof relevant considerations to facilitate the coding process. An initial\nReader's Guide helps the reader tailor the content to her interest.\n  Note that this codebook specifically focuses on operational aspects of IG 2.0\nin the context of policy coding. Links to additional resources such as the\nunderlying scientific literature (that offers a comprehensive treatment of the\nunderlying theoretical concepts) are referred to in the DOI and the concluding\nsection of the codebook.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.08937v5"
    },
    {
        "title": "Evaluation of the cumulated impacts on the marine resource of a\n  socio-ecological coral system: approach by agent-based modeling",
        "authors": [
            "Olivier Rousselle"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In the context of climate change and significant changes in human activities\naround the world, coral reefs are subject to many disruptions. We develop here\na tool to help decision-making in Moorea (French Polynesia), based on\nmulti-agent modeling. We model the trophic interactions with a Lotka-Volterra\nmodel, and also the interactions between fishermen, trophic groups and tourist\noperators. The results are generated through global, temporal (time series),\nand spatial (GIS maps) outputs. The model produced here can be transposed to\nother ecological and economic situations, and other geographical areas, by\nmodifying the parameters and changing the input map data.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.09521v1"
    },
    {
        "title": "Computational Models of Human Decision-Making with Application to the\n  Internet of Everything",
        "authors": [
            "Setareh Maghsudi",
            "Max Davy"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The concept of the Internet of Things (IoT) first appeared a few decades ago.\nToday, by the ubiquitous wireless connectivity, the boost of machine learning\nand artificial intelligence, and the advances in big data analytics, it is safe\nto say that IoT has evolved to a new concept called the Internet of Everything\n(IoE) or the Internet of All. IoE has four pillars: Things, human, data, and\nprocesses, which render it as an inhomogeneous large-scale network. A crucial\nchallenge of such a network is to develop management, analysis, and\noptimization policies that besides utility-maximizer machines, also take\nirrational humans into account. We discuss several networking applications in\nwhich appropriate modeling of human decision-making is vital. We then provide a\nbrief review of computational models of human decision-making. Based on one\nsuch model, we develop a solution for a task offloading problem in fog\ncomputing and we analyze the implications of including humans in the loop.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.11958v1"
    },
    {
        "title": "High Accuracy Traffic Light Controller for Increasing the Given Green\n  Time Utilization",
        "authors": [
            "Maythem K. Abbas",
            "Mohd N. Karsiti",
            "Madzlan Napiah",
            "Brahim B. Samir",
            "Marwan Al-Jemeli"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Traffic congestion has become one of the major problems in the urban cities\naccording to the increasing number of vehicles in those cities, obsolete\ntechnologies used on the roads of those cities, inappropriate road design, and\nmany other reasons. So, that has urged the need for a more accurate traffic\nlight controlling system; one that will help in maintaining high stability at\nall levels of demand. This paper introduces a dynamic traffic light phase plan\nprotocol for Single-Isolated Intersections. The developed controlling method\nwas compared with four other methods and showed a good performance in terms of\nreducing the average and maximum queue lengths, optimizing the given green time\namount as needed, and increased the intersections throughput (increased the\ngiven green time utilization). In addition, it maintained a good traffic light\nstability at all levels of demand.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.13738v1"
    },
    {
        "title": "Lenient Multi-Agent Deep Reinforcement Learning",
        "authors": [
            "Gregory Palmer",
            "Karl Tuyls",
            "Daan Bloembergen",
            "Rahul Savani"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Much of the success of single agent deep reinforcement learning (DRL) in\nrecent years can be attributed to the use of experience replay memories (ERM),\nwhich allow Deep Q-Networks (DQNs) to be trained efficiently through sampling\nstored state transitions. However, care is required when using ERMs for\nmulti-agent deep reinforcement learning (MA-DRL), as stored transitions can\nbecome outdated because agents update their policies in parallel [11]. In this\nwork we apply leniency [23] to MA-DRL. Lenient agents map state-action pairs to\ndecaying temperature values that control the amount of leniency applied towards\nnegative policy updates that are sampled from the ERM. This introduces optimism\nin the value-function update, and has been shown to facilitate cooperation in\ntabular fully-cooperative multi-agent reinforcement learning problems. We\nevaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN\n(HDQN) algorithm [22] as well as a modified version we call scheduled-HDQN,\nthat uses average reward learning near terminal states. Evaluations take place\nin extended variations of the Coordinated Multi-Agent Object Transportation\nProblem (CMOTP) [8] which include fully-cooperative sub-tasks and stochastic\nrewards. We find that LDQN agents are more likely to converge to the optimal\npolicy in a stochastic reward CMOTP compared to standard and scheduled-HDQN\nagents.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.04402v2"
    },
    {
        "title": "Consistent Tomography under Partial Observations over Adaptive Networks",
        "authors": [
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This work studies the problem of inferring whether an agent is directly\ninfluenced by another agent over an adaptive diffusion network. Agent i\ninfluences agent j if they are connected (according to the network topology),\nand if agent j uses the data from agent i to update its online statistic. The\nsolution of this inference task is challenging for two main reasons. First,\nonly the output of the diffusion learning algorithm is available to the\nexternal observer that must perform the inference based on these indirect\nmeasurements. Second, only output measurements from a fraction of the network\nagents is available, with the total number of agents itself being also unknown.\nThe main focus of this article is ascertaining under these demanding conditions\nwhether consistent tomography is possible, namely, whether it is possible to\nreconstruct the interaction profile of the observable portion of the network,\nwith negligible error as the network size increases. We establish a critical\nachievability result, namely, that for symmetric combination policies and for\nany given fraction of observable agents, the interacting and non-interacting\nagent pairs split into two separate clusters as the network size increases.\nThis remarkable property then enables the application of clustering algorithms\nto identify the interacting agents influencing the observations. We provide a\nset of numerical experiments that verify the results for finite network sizes\nand time horizons. The numerical experiments show that the results hold for\nasymmetric combination policies as well, which is particularly relevant in the\ncontext of causation.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.06444v1"
    },
    {
        "title": "A multi-agent reinforcement learning model of common-pool resource\n  appropriation",
        "authors": [
            "Julien Perolat",
            "Joel Z. Leibo",
            "Vinicius Zambaldi",
            "Charles Beattie",
            "Karl Tuyls",
            "Thore Graepel"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Humanity faces numerous problems of common-pool resource appropriation. This\nclass of multi-agent social dilemma includes the problems of ensuring\nsustainable use of fresh water, common fisheries, grazing pastures, and\nirrigation systems. Abstract models of common-pool resource appropriation based\non non-cooperative game theory predict that self-interested agents will\ngenerally fail to find socially positive equilibria---a phenomenon called the\ntragedy of the commons. However, in reality, human societies are sometimes able\nto discover and implement stable cooperative solutions. Decades of behavioral\ngame theory research have sought to uncover aspects of human behavior that make\nthis possible. Most of that work was based on laboratory experiments where\nparticipants only make a single choice: how much to appropriate. Recognizing\nthe importance of spatial and temporal resource dynamics, a recent trend has\nbeen toward experiments in more complex real-time video game-like environments.\nHowever, standard methods of non-cooperative game theory can no longer be used\nto generate predictions for this case. Here we show that deep reinforcement\nlearning can be used instead. To that end, we study the emergent behavior of\ngroups of independently learning agents in a partially observed Markov game\nmodeling common-pool resource appropriation. Our experiments highlight the\nimportance of trial-and-error learning in common-pool resource appropriation\nand shed light on the relationship between exclusion, sustainability, and\ninequality.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.06600v2"
    },
    {
        "title": "Robust Tracking and Behavioral Modeling of Movements of Biological\n  Collectives from Ordinary Video Recordings",
        "authors": [
            "Hiroki Sayama",
            "Farnaz Zamani Esfahlani",
            "Ali Jazayeri",
            "J. Scott Turner"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  We propose a novel computational method to extract information about\ninteractions among individuals with different behavioral states in a biological\ncollective from ordinary video recordings. Assuming that individuals are acting\nas finite state machines, our method first detects discrete behavioral states\nof those individuals and then constructs a model of their state transitions,\ntaking into account the positions and states of other individuals in the\nvicinity. We have tested the proposed method through applications to two\nreal-world biological collectives: termites in an experimental setting and\nhuman pedestrians in a university campus. For each application, a robust\ntracking system was developed in-house, utilizing interactive human\nintervention (for termite tracking) or online agent-based simulation (for\npedestrian tracking). In both cases, significant interactions were detected\nbetween nearby individuals with different states, demonstrating the\neffectiveness of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.07310v2"
    },
    {
        "title": "Learning for Multi-robot Cooperation in Partially Observable Stochastic\n  Environments with Macro-actions",
        "authors": [
            "Miao Liu",
            "Kavinayan Sivakumar",
            "Shayegan Omidshafiei",
            "Christopher Amato",
            "Jonathan P. How"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper presents a data-driven approach for multi-robot coordination in\npartially-observable domains based on Decentralized Partially Observable Markov\nDecision Processes (Dec-POMDPs) and macro-actions (MAs). Dec-POMDPs provide a\ngeneral framework for cooperative sequential decision making under uncertainty\nand MAs allow temporally extended and asynchronous action execution. To date,\nmost methods assume the underlying Dec-POMDP model is known a priori or a full\nsimulator is available during planning time. Previous methods which aim to\naddress these issues suffer from local optimality and sensitivity to initial\nconditions. Additionally, few hardware demonstrations involving a large team of\nheterogeneous robots and with long planning horizons exist. This work addresses\nthese gaps by proposing an iterative sampling based Expectation-Maximization\nalgorithm (iSEM) to learn polices using only trajectory data containing\nobservations, MAs, and rewards. Our experiments show the algorithm is able to\nachieve better solution quality than the state-of-the-art learning-based\nmethods. We implement two variants of multi-robot Search and Rescue (SAR)\ndomains (with and without obstacles) on hardware to demonstrate the learned\npolicies can effectively control a team of distributed robots to cooperate in a\npartially observable stochastic environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.07399v2"
    },
    {
        "title": "Multi Type Mean Field Reinforcement Learning",
        "authors": [
            "Sriram Ganapathi Subramanian",
            "Pascal Poupart",
            "Matthew E. Taylor",
            "Nidhi Hegde"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Mean field theory provides an effective way of scaling multiagent\nreinforcement learning algorithms to environments with many agents that can be\nabstracted by a virtual mean agent. In this paper, we extend mean field\nmultiagent algorithms to multiple types. The types enable the relaxation of a\ncore assumption in mean field reinforcement learning, which is that all agents\nin the environment are playing almost similar strategies and have the same\ngoal. We conduct experiments on three different testbeds for the field of many\nagent reinforcement learning, based on the standard MAgents framework. We\nconsider two different kinds of mean field environments: a) Games where agents\nbelong to predefined types that are known a priori and b) Games where the type\nof each agent is unknown and therefore must be learned based on observations.\nWe introduce new algorithms for each type of game and demonstrate their\nsuperior performance over state of the art algorithms that assume that all\nagents belong to the same type and other baseline algorithms in the MAgent\nframework.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.02513v7"
    },
    {
        "title": "Multi-Agent Reinforcement Learning as a Computational Tool for Language\n  Evolution Research: Historical Context and Future Challenges",
        "authors": [
            "Clément Moulin-Frier",
            "Pierre-Yves Oudeyer"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Computational models of emergent communication in agent populations are\ncurrently gaining interest in the machine learning community due to recent\nadvances in Multi-Agent Reinforcement Learning (MARL). Current contributions\nare however still relatively disconnected from the earlier theoretical and\ncomputational literature aiming at understanding how language might have\nemerged from a prelinguistic substance. The goal of this paper is to position\nrecent MARL contributions within the historical context of language evolution\nresearch, as well as to extract from this theoretical and computational\nbackground a few challenges for future research.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08878v2"
    },
    {
        "title": "On Local Computation for Optimization in Multi-Agent Systems",
        "authors": [
            "Robin Brown",
            "Federico Rossi",
            "Kiril Solovey",
            "Michael T. Wolf",
            "Marco Pavone"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  A number of prototypical optimization problems in multi-agent systems (e.g.,\ntask allocation and network load-sharing) exhibit a highly local structure:\nthat is, each agent's decision variables are only directly coupled to few other\nagent's variables through the objective function or the constraints.\nNevertheless, existing algorithms for distributed optimization generally do not\nexploit the locality structure of the problem, requiring all agents to compute\nor exchange the full set of decision variables. In this paper, we develop a\nrigorous notion of \"locality\" that quantifies the degree to which agents can\ncompute their portion of the global solution based solely on information in\ntheir local neighborhood. This notion provides a theoretical basis for a rather\nsimple algorithm in which agents individually solve a truncated sub-problem of\nthe global problem, where the size of the sub-problem used depends on the\nlocality of the problem, and the desired accuracy. Numerical results show that\nthe proposed theoretical bounds are remarkably tight for well-conditioned\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.12313v2"
    },
    {
        "title": "Joint Estimation and Localization in Sensor Networks",
        "authors": [
            "Nikolay A. Atanasov",
            "Roberto Tron",
            "Victor M. Preciado",
            "George J. Pappas"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper addresses the problem of collaborative tracking of dynamic targets\nin wireless sensor networks. A novel distributed linear estimator, which is a\nversion of a distributed Kalman filter, is derived. We prove that the filter is\nmean square consistent in the case of static target estimation. When large\nsensor networks are deployed, it is common that the sensors do not have good\nknowledge of their locations, which affects the target estimation procedure.\nUnlike most existing approaches for target tracking, we investigate the\nperformance of our filter when the sensor poses need to be estimated by an\nauxiliary localization procedure. The sensors are localized via a distributed\nJacobi algorithm from noisy relative measurements. We prove strong convergence\nguarantees for the localization method and in turn for the joint localization\nand target estimation approach. The performance of our algorithms is\ndemonstrated in simulation on environmental monitoring and target tracking\ntasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3580v1"
    },
    {
        "title": "SNA-based reasoning for multiagent team composition",
        "authors": [
            "Andre Filipe de Moraes Batista",
            "Maria das Graças Bruno Marietto"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  The social network analysis (SNA), branch of complex systems can be used in\nthe construction of multiagent systems. This paper proposes a study of how\nsocial network analysis can assist in modeling multiagent systems, while\naddressing similarities and differences between the two theories. We built a\nprototype of multi-agent systems for resolution of tasks through the formation\nof teams of agents that are formed on the basis of the social network\nestablished between agents. Agents make use of performance indicators to assess\nwhen should change their social network to maximize the participation in teams\n",
        "pdf_link": "http://arxiv.org/pdf/1506.05154v1"
    },
    {
        "title": "LocDyn: Robust Distributed Localization for Mobile Underwater Networks",
        "authors": [
            "Cláudia Soares",
            "João Gomes",
            "Beatriz Ferreira",
            "João Paulo Costeira"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  How to self-localize large teams of underwater nodes using only noisy range\nmeasurements? How to do it in a distributed way, and incorporating dynamics\ninto the problem? How to reject outliers and produce trustworthy position\nestimates? The stringent acoustic communication channel and the accuracy needs\nof our geophysical survey application demand faster and more accurate\nlocalization methods. We approach dynamic localization as a MAP estimation\nproblem where the prior encodes dynamics, and we devise a convex relaxation\nmethod that takes advantage of previous estimates at each measurement\nacquisition step; The algorithm converges at an optimal rate for first order\nmethods. LocDyn is distributed: there is no fusion center responsible for\nprocessing acquired data and the same simple computations are performed for\neach node. LocDyn is accurate: experiments attest to a smaller positioning\nerror than a comparable Kalman filter. LocDyn is robust: it rejects outlier\nnoise, while the comparing methods succumb in terms of positioning error.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.08027v1"
    },
    {
        "title": "Evaluation of Automated Vehicles Encountering Pedestrians at\n  Unsignalized Crossings",
        "authors": [
            "Baiming Chen",
            "Ding Zhao",
            "Huei Peng"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Interactions between vehicles and pedestrians have always been a major\nproblem in traffic safety. Experienced human drivers are able to analyze the\nenvironment and choose driving strategies that will help them avoid crashes.\nWhat is not yet clear, however, is how automated vehicles will interact with\npedestrians. This paper proposes a new method for evaluating the safety and\nfeasibility of the driving strategy of automated vehicles when encountering\nunsignalized crossings. MobilEye sensors installed on buses in Ann Arbor,\nMichigan, collected data on 2,973 valid crossing events. A stochastic\ninteraction model was then created using a multivariate Gaussian mixture model.\nThis model allowed us to simulate the movements of pedestrians reacting to an\noncoming vehicle when approaching unsignalized crossings, and to evaluate the\npassing strategies of automated vehicles. A simulation was then conducted to\ndemonstrate the evaluation procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.00785v3"
    },
    {
        "title": "Modelling community formation driven by the status of individual in a\n  society",
        "authors": [
            "Jan E. Snellman",
            "Gerardo Iñiguez",
            "Tzipe Govezensky",
            "Rafael A. Barrio",
            "Kimmo K. Kaski"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In human societies, people's willingness to compete and strive for better\nsocial status as well as being envious of those perceived in some way superior\nlead to social structures that are intrinsically hierarchical. Here we propose\nan agent-based, network model to mimic the ranking behaviour of individuals and\nits possible repercussions in human society. The main ingredient of the model\nis the assumption that the relevant feature of social interactions is each\nindividual's keenness to maximise his or her status relative to others. The\nsocial networks produced by the model are homophilous and assortative, as\nfrequently observed in human communities and most of the network properties\nseem quite independent of its size. However, it is seen that for small number\nof agents the resulting network consists of disjoint weakly connected\ncommunities while being highly assortative and homophilic. On the other hand\nlarger networks turn out to be more cohesive with larger communities but less\nhomophilic. We find that the reason for these changes is that larger network\nsize allows agents to use new strategies for maximizing their social status\nallowing for more diverse links between them.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.02541v1"
    },
    {
        "title": "Towards Agent-Based Model Specification in Smart Grid: A Cognitive\n  Agent-based Computing Approach",
        "authors": [
            "Waseem Akram",
            "Muaz A. Niazi",
            "Laszlo Barna Iantovics"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  A smart grid can be considered as a complex network where each node\nrepresents a generation unit or a consumer. Whereas links can be used to\nrepresent transmission lines. One way to study complex systems is by using the\nagent-based modeling (ABM) paradigm. An ABM is a way of representing a complex\nsystem of autonomous agents interacting with each other. Previously, a number\nof studies have been presented in the smart grid domain making use of the ABM\nparadigm. However, to the best of our knowledge, none of these studies have\nfocused on the specification aspect of ABM. An ABM specification is important\nnot only for understanding but also for replication of the model. In this\nstudy, we focus on development as well as specification of ABM for smart grid.\nWe propose an ABM by using a combination of agent-based and complex\nnetwork-based approaches. For ABM specification, we use ODD and DREAM\nspecification approaches. We analyze these two specification approaches\nqualitatively as well as quantitatively. Extensive experiments demonstrate that\nDREAM is a most useful approach as compared with ODD for modeling as well as\nfor replication of models for smart grid.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.03189v2"
    },
    {
        "title": "A Class of Distributed Event-Triggered Average Consensus Algorithms for\n  Multi-Agent Systems",
        "authors": [
            "Ping Xu",
            "Cameron Nowzari",
            "Zhi Tian"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper proposes a class of distributed event-triggered algorithms that\nsolve the average consensus problem in multi-agent systems. By designing events\nsuch that a specifically chosen Lyapunov function is monotonically decreasing,\nevent-triggered algorithms succeed in reducing communications among agents\nwhile still ensuring that the entire system converges to the desired state.\nHowever, depending on the chosen Lyapunov function the transient behaviors can\nbe very different. Moreover, performance requirements also vary from\napplication to application. Consequently, we are instead interested in\nconsidering a class of Lyapunov functions such that each Lyapunov function\nproduces a different event-triggered coordination algorithm to solve the\nmulti-agent average consensus problem. The proposed class of algorithms all\nguarantee exponential convergence of the resulting system and exclusion of Zeno\nbehaviors. This allows us to easily implement different algorithms that all\nguarantee correctness to meet varying performance needs. We show that our\nfindings can be applied to the practical clock synchronization problem in\nwireless sensor networks (WSNs) and further corroborate their effectiveness\nwith simulation results.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.02649v2"
    },
    {
        "title": "Topology Inference over Networks with Nonlinear Coupling",
        "authors": [
            "Augusto Santos",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This work examines the problem of topology inference over discrete-time\nnonlinear stochastic networked dynamical systems. The goal is to recover the\nunderlying digraph linking the network agents, from observations of their\nstate-evolution. The dynamical law governing the state-evolution of the\ninteracting agents might be nonlinear, i.e., the next state of an agent can\ndepend nonlinearly on its current state and on the states of its immediate\nneighbors. We establish sufficient conditions that allow consistent graph\nlearning over a special class of networked systems, namely, logistic-type\ndynamical systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.09029v1"
    },
    {
        "title": "Finding Core Members of Cooperative Games using Agent-Based Modeling",
        "authors": [
            "Daniele Vernon-Bido",
            "Andrew J. Collins"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Agent-based modeling (ABM) is a powerful paradigm to gain insight into social\nphenomena. One area that ABM has rarely been applied is coalition formation.\nTraditionally, coalition formation is modeled using cooperative game theory. In\nthis paper, a heuristic algorithm is developed that can be embedded into an ABM\nto allow the agents to find coalition. The resultant coalition structures are\ncomparable to those found by cooperative game theory solution approaches,\nspecifically, the core. A heuristic approach is required due to the\ncomputational complexity of finding a cooperative game theory solution which\nlimits its application to about only a score of agents. The ABM paradigm\nprovides a platform in which simple rules and interactions between agents can\nproduce a macro-level effect without the large computational requirements. As\nsuch, it can be an effective means for approximating cooperative game solutions\nfor large numbers of agents. Our heuristic algorithm combines agent-based\nmodeling and cooperative game theory to help find agent partitions that are\nmembers of a games' core solution. The accuracy of our heuristic algorithm can\nbe determined by comparing its outcomes to the actual core solutions. This\ncomparison achieved by developing an experiment that uses a specific example of\na cooperative game called the glove game. The glove game is a type of exchange\neconomy game. Finding the traditional cooperative game theory solutions is\ncomputationally intensive for large numbers of players because each possible\npartition must be compared to each possible coalition to determine the core\nset; hence our experiment only considers games of up to nine players. The\nresults indicate that our heuristic approach achieves a core solution over 90%\nof the time for the games considered in our experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.00519v1"
    },
    {
        "title": "Quasi-synchronization of bounded confidence opinion dynamics with\n  stochastic asynchronous rule",
        "authors": [
            "Wei Su",
            "Xueqiao Wang",
            "Ge Chen",
            "Kai Shen"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Recently the theory of noise-induced synchronization of Hegselmann-Krause\n(HK) dynamics has been well developed. As a typical opinion dynamics of bounded\nconfidence, the HK model obeys a synchronous updating rule, i.e., \\emph{all}\nagents check and update their opinions at each time point. However, whether\nasynchronous bounded confidence models, including the famous Deffuant-Weisbuch\n(DW) model, can be synchronized by noise have not been theoretically proved. In\nthis paper, we propose a generalized bounded confidence model which possesses a\nstochastic asynchronous rule. The model takes the DW model and the HK model as\nspecial cases and can significantly generalize the bounded confidence models to\npractical application. We discover that the asynchronous model possesses a\ndifferent noise-based synchronization behavior compared to the synchronous HK\nmodel. Generally, the HK dynamics can achieve quasi-synchronization\n\\emph{almost surely} under the drive of noise. For the asynchronous dynamics,\nwe prove that the model can achieve quasi-synchronization \\emph{in mean}, which\nis a new type of quasi-synchronization weaker than the \"almost surely\" sense.\nThe results unify the theory of noise-induced synchronization of bounded\nconfidence opinion dynamics and hence proves the noise-induced synchronization\nof DW model theoretically for the first time. Moreover, the results provide a\ntheoretical foundation for developing noise-based control strategy of more\ncomplex social opinion systems with stochastic asynchronous rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.01455v1"
    },
    {
        "title": "Collaboratively Optimizing Power Scheduling and Mitigating Congestion\n  using Local Pricing in a Receding Horizon Market",
        "authors": [
            "Cornelis Jan van Leeuwen",
            "Joost Stam",
            "Arun Subramanian",
            "Koen Kok"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  A distributed, hierarchical, market based approach is introduced to solve the\neconomic dispatch problem. The approach requires only a minimal amount of\ninformation to be shared between a central market operator and the end-users.\nPrice signals from the market operator are sent down to end-user device agents,\nwhich in turn respond with power schedules. Intermediate congestion agents make\nsure that local power constraints are satisfied and any potential congestion is\navoided by adding local pricing differences. Our results show that in 20% of\nthe evaluated scenarios the solutions are identical to the global optimum when\nperfect knowledge is available. In the other 80% the results are not\nsignificantly worse, while providing a higher level of scalability and\nincreasing the consumer's privacy.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.02166v1"
    },
    {
        "title": "Hybrid DCOP Solvers: Boosting Performance of Local Search Algorithms",
        "authors": [
            "Cornelis Jan van Leeuwen",
            "Przemyzław Pawełczak"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We propose a novel method for expediting both symmetric and asymmetric\nDistributed Constraint Optimization Problem (DCOP) solvers. The core idea is\nbased on initializing DCOP solvers with greedy fast non-iterative DCOP solvers.\nThis is contrary to existing methods where initialization is always achieved\nusing a random value assignment. We empirically show that changing the starting\nconditions of existing DCOP solvers not only reduces the algorithm convergence\ntime by up to 50\\%, but also reduces the communication overhead and leads to a\nbetter solution quality. We show that this effect is due to structural\nimprovements in the variable assignment, which is caused by the spreading\npattern of DCOP algorithm activation.) /Subject (Hybrid DCOPs)\n",
        "pdf_link": "http://arxiv.org/pdf/2009.02240v1"
    },
    {
        "title": "An Agent-Based Model of Delegation Relationships With Hidden-Action: On\n  the Effects of Heterogeneous Memory on Performance",
        "authors": [
            "Patrick Reinwald",
            "Stephan Leitner",
            "Friederike Wall"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We introduce an agent-based model of delegation relationships between a\nprincipal and an agent, which is based on the standard-hidden action model\nintroduced by Holmstr\\\"om and, by doing so, provide a model which can be used\nto further explore theoretical topics in managerial economics, such as the\nefficiency of incentive mechanisms. We employ the concept of agentization,\ni.e., we systematically transform the standard hidden-action model into an\nagent-based model. Our modeling approach allows for a relaxation of some of the\nrather \"heroic\" assumptions included in the standard hidden-action model,\nwhereby we particularly focus on assumptions related to the (i) availability of\ninformation about the environment and the (ii) principal's and agent's\ncognitive capabilities (with a particular focus on their learning capabilities\nand their memory). Our analysis focuses on how close and how fast the incentive\nscheme, which endogenously emerges from the agent-based model, converges to the\nsolution proposed by the standard hidden-action model. Also, we investigate\nwhether a stable solution can emerge from the agent-based model variant. The\nresults show that in stable environments the emergent result can nearly reach\nthe solution proposed by the standard hidden-action model. Surprisingly, the\nresults indicate that turbulence in the environment leads to stability in\nearlier time periods.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.07124v2"
    },
    {
        "title": "Decentralized Game-Theoretic Control for Dynamic Task Allocation\n  Problems for Multi-Agent Systems",
        "authors": [
            "Efstathios Bakolas",
            "Yoonjae Lee"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We propose a decentralized game-theoretic framework for dynamic task\nallocation problems for multi-agent systems. In our problem formulation, the\nagents' utilities depend on both the rewards and the costs associated with the\nsuccessful completion of the tasks assigned to them. The rewards reflect how\nlikely is for the agents to accomplish their assigned tasks whereas the costs\nreflect the effort needed to complete these tasks (this effort is determined by\nthe solution of corresponding optimal control problems). The task allocation\nproblem considered herein corresponds to a dynamic game whose solution depends\non the states of the agents in contrast with classic static (or single-act)\ngame formulations. We propose a greedy solution approach in which the agents\nnegotiate with each other to find a mutually agreeable (or individually\nrational) task assignment profile based on evaluations of the task utilities\nthat reflect their current states. We illustrate the main ideas of this work by\nmeans of extensive numerical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.08628v2"
    },
    {
        "title": "Safe Coverage of Moving Domains for Vehicles with Second Order Dynamics",
        "authors": [
            "Juan Chacon",
            "Mo Chen",
            "Razvan Fetecau"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Autonomous coverage of a specified area by robots operating in close\nproximity with each other has many potential applications such as real-time\nmonitoring of rapidly changing environments, and search and rescue; however,\ncoordination and safety are two fundamental challenges. For coordination, we\npropose a distributed controller for covering moving, compact domains for two\ntypes of vehicles with second order dynamics (double integrator and fixed-wing\naircraft) with bounded input forces. This control policy is based on artificial\npotentials and alignment forces designed to promote desired vehicle-domain and\ninter-vehicle separations and relative velocities. We prove that certain\ncoverage configurations are locally asymptotically stable. For safety, we\nestablish energy conditions for collision free motion and utilize\nHamilton-Jacobi (HJ) reachability theory for last-resort pairwise collision\navoidance. We derive an analytical solution to the associated HJ partial\ndifferential equation corresponding to the collision avoidance problem between\ntwo double integrator vehicles. We demonstrate our approach in several\nnumerical simulations involving the two types of vehicles covering convex and\nnon-convex moving domains.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.12211v1"
    },
    {
        "title": "Liquid Democracy: An Analysis in Binary Aggregation and Diffusion",
        "authors": [
            "Zoé Christoff",
            "Davide Grossi"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  The paper proposes an analysis of liquid democracy (or, delegable proxy\nvoting) from the perspective of binary aggregation and of binary diffusion\nmodels. We show how liquid democracy on binary issues can be embedded into the\nframework of binary aggregation with abstentions, enabling the transfer of\nknown results about the latter---such as impossibility theorems---to the\nformer. This embedding also sheds light on the relation between delegation\ncycles in liquid democracy and the probability of collective abstentions, as\nwell as the issue of individual rationality in a delegable proxy voting\nsetting. We then show how liquid democracy on binary issues can be modeled and\nanalyzed also as a specific process of dynamics of binary opinions on networks.\nThese processes---called Boolean DeGroot processes---are a special case of the\nDeGroot stochastic model of opinion diffusion. We establish the convergence\nconditions of such processes and show they provide some novel insights on how\nthe effects of delegation cycles and individual rationality could be mitigated\nwithin liquid democracy.\n  The study is a first attempt to provide theoretical foundations to the\ndelgable proxy features of the liquid democracy voting system. Our analysis\nsuggests recommendations on how the system may be modified to make it more\nresilient with respect to the handling of delegation cycles and of inconsistent\nmajorities.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.08048v2"
    },
    {
        "title": "Investigating Spatiotemporal Dynamics and Synchrony of Influenza\n  Epidemics in Australia: An Agent-Based Modelling Approach",
        "authors": [
            "Oliver M. Cliff",
            "Nathan Harding",
            "Mahendra Piraveenan",
            "E. Yagmur Erten",
            "Manoj Gambhir",
            "Mikhail Prokopenko"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In this paper we present ACEMod, an agent-based modelling framework for\nstudying influenza epidemics in Australia. The simulator is designed to analyse\nthe spatiotemporal spread of contagion and influenza spatial synchrony across\nthe nation. The individual-based epidemiological model accounts for mobility\n(worker and student commuting) patterns and human interactions derived from the\n2006 Australian census and other national data sources. The high-precision\nsimulation comprises 19.8 million stochastically generated software agents and\ntraces the dynamics of influenza viral infection and transmission at several\nscales. Using this approach, we are able to synthesise epidemics in Australia\nwith varying outbreak locations and severity. For each scenario, we investigate\nthe spatiotemporal profiles of these epidemics, both qualitatively and\nquantitatively, via incidence curves, prevalence choropleths, and epidemic\nsynchrony. This analysis exemplifies the nature of influenza pandemics within\nAustralia and facilitates future planning of effective intervention, mitigation\nand crisis management strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.02578v1"
    },
    {
        "title": "Decentralized Multi-Agents by Imitation of a Centralized Controller",
        "authors": [
            "Alex Tong Lin",
            "Mark J. Debord",
            "Katia Estabridis",
            "Gary Hewer",
            "Guido Montufar",
            "Stanley Osher"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We consider a multi-agent reinforcement learning problem where each agent\nseeks to maximize a shared reward while interacting with other agents, and they\nmay or may not be able to communicate. Typically the agents do not have access\nto other agent policies and thus each agent is situated in a non-stationary and\npartially-observable environment. In order to obtain multi-agents that act in a\ndecentralized manner, we introduce a novel algorithm under the popular\nframework of centralized training, but decentralized execution. This training\nframework first obtains solutions to a multi-agent problem with a single\ncentralized joint-space learner, which is then used to guide imitation learning\nfor independent decentralized multi-agents. This framework has the flexibility\nto use any reinforcement learning algorithm to obtain the expert as well as any\nimitation learning algorithm to obtain the decentralized agents. This is in\ncontrast to other multi-agent learning algorithms that, for example, can\nrequire more specific structures. We present some theoretical bounds for our\nmethod, and we show that one can obtain decentralized solutions to a\nmulti-agent problem through imitation learning.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.02311v4"
    },
    {
        "title": "Privacy of Existence of Secrets: Introducing Steganographic DCOPs and\n  Revisiting DCOP Frameworks",
        "authors": [
            "Viorel D. Silaghi",
            "Marius C. Silaghi",
            "René Mandiau"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Here we identify a type of privacy concern in Distributed Constraint\nOptimization (DCOPs) not previously addressed in literature, despite its\nimportance and impact on the application field: the privacy of existence of\nsecrets. Science only starts where metrics and assumptions are clearly defined.\nThe area of Distributed Constraint Optimization has emerged at the intersection\nof the multi-agent system community and constraint programming. For the\nmulti-agent community, the constraint optimization problems are an elegant way\nto express many of the problems occurring in trading and distributed robotics.\nFor the theoretical constraint programming community the DCOPs are a natural\nextension of their main object of study, the constraint satisfaction problem.\nAs such, the understanding of the DCOP framework has been refined with the\nneeds of the two communities, but sometimes without spelling the new\nassumptions formally and therefore making it difficult to compare techniques.\nHere we give a direction to the efforts for structuring concepts in this area.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.05943v1"
    },
    {
        "title": "Winning an Election: On Emergent Strategic Communication in Multi-Agent\n  Networks",
        "authors": [
            "Shubham Gupta",
            "Ambedkar Dukkipati"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Humans use language to collectively execute abstract strategies besides using\nit as a referential tool for identifying physical entities. Recently, multiple\nattempts at replicating the process of emergence of language in artificial\nagents have been made. While existing approaches study emergent languages as\nreferential tools, in this paper, we study their role in discovering and\nimplementing strategies. We formulate the problem using a voting game where two\ncandidate agents contest in an election with the goal of convincing population\nmembers (other agents), that are connected to each other via an underlying\nnetwork, to vote for them. To achieve this goal, agents are only allowed to\nexchange messages in the form of sequences of discrete symbols to spread their\npropaganda. We use neural networks with Gumbel-Softmax relaxation for sampling\ncategorical random variables to parameterize the policies followed by all\nagents. Using our proposed framework, we provide concrete answers to the\nfollowing questions: (i) Do the agents learn to communicate in a meaningful way\nand does the emergent communication play a role in deciding the winner? (ii)\nDoes the system evolve as expected under various reward structures? (iii) How\nis the emergent language affected by the community structure in the network? To\nthe best of our knowledge, we are the first to explore emergence of\ncommunication for discovering and implementing strategies in a setting where\nagents communicate over a network.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.06897v2"
    },
    {
        "title": "Policies for allocation of information in task-oriented groups: elitism\n  and egalitarianism outperform welfarism",
        "authors": [
            "Sandro M. Reia",
            "Paulo F. Gomes",
            "José F. Fontanari"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Communication or influence networks are probably the most controllable of all\nfactors that are known to impact on the problem-solving capability of\ntask-forces. In the case connections are costly, it is necessary to implement a\npolicy to allocate them to the individuals. Here we use an agent-based model to\nstudy how distinct allocation policies affect the performance of a group of\nagents whose task is to find the global maxima of NK fitness landscapes. Agents\ncooperate by broadcasting messages informing on their fitness and use this\ninformation to imitate the fittest agent in their influence neighborhoods. The\nlarger the influence neighborhood of an agent, the more links, and hence\ninformation, the agent receives. We find that the elitist policy in which\nagents with above-average fitness have their influence neighborhoods amplified,\nwhereas agents with below-average fitness have theirs deflated, is optimal for\nsmooth landscapes, provided the group size is not too small. For rugged\nlandscapes, however, the elitist policy can perform very poorly for certain\ngroup sizes. In addition, we find that the egalitarian policy, in which the\nsize of the influence neighborhood is the same for all agents, is optimal for\nboth smooth and rugged landscapes in the case of small groups. The welfarist\npolicy, in which the actions of the elitist policy are reversed, is always\nsuboptimal, i.e., depending on the group size it is outperformed by either the\nelitist or the egalitarian policies.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.08183v3"
    },
    {
        "title": "Skynet: A Top Deep RL Agent in the Inaugural Pommerman Team Competition",
        "authors": [
            "Chao Gao",
            "Pablo Hernandez-Leal",
            "Bilal Kartal",
            "Matthew E. Taylor"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The Pommerman Team Environment is a recently proposed benchmark which\ninvolves a multi-agent domain with challenges such as partial observability,\ndecentralized execution (without communication), and very sparse and delayed\nrewards. The inaugural Pommerman Team Competition held at NeurIPS 2018 hosted\n25 participants who submitted a team of 2 agents. Our submission\nnn_team_skynet955_skynet955 won 2nd place of the \"learning agents'' category.\nOur team is composed of 2 neural networks trained with state of the art deep\nreinforcement learning algorithms and makes use of concepts like reward\nshaping, curriculum learning, and an automatic reasoning module for action\npruning. Here, we describe these elements and additionally we present a\ncollection of open-sourced agents that can be used for training and testing in\nthe Pommerman environment. Code available at:\nhttps://github.com/BorealisAI/pommerman-baseline\n",
        "pdf_link": "http://arxiv.org/pdf/1905.01360v1"
    },
    {
        "title": "On the Detection of Mutual Influences and Their Consideration in\n  Reinforcement Learning Processes",
        "authors": [
            "Stefan Rudolph",
            "Sven Tomforde",
            "Jörg Hähner"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Self-adaptation has been proposed as a mechanism to counter complexity in\ncontrol problems of technical systems. A major driver behind self-adaptation is\nthe idea to transfer traditional design-time decisions to runtime and into the\nresponsibility of systems themselves. In order to deal with unforeseen events\nand conditions, systems need creativity -- typically realized by means of\nmachine learning capabilities. Such learning mechanisms are based on different\nsources of knowledge. Feedback from the environment used for reinforcement\npurposes is probably the most prominent one within the self-adapting and\nself-organizing (SASO) systems community. However, the impact of other\n(sub-)systems on the success of the individual system's learning performance\nhas mostly been neglected in this context. In this article, we propose a novel\nmethodology to identify effects of actions performed by other systems in a\nshared environment on the utility achievement of an autonomous system. Consider\nsmart cameras (SC) as illustrating example: For goals such as 3D reconstruction\nof objects, the most promising configuration of one SC in terms of\npan/tilt/zoom parameters depends largely on the configuration of other SCs in\nthe vicinity. Since such mutual influences cannot be pre-defined for dynamic\nsystems, they have to be learned at runtime. Furthermore, they have to be taken\ninto consideration when self-improving the own configuration decisions based on\na feedback loop concept, e.g., known from the SASO domain or the Autonomic and\nOrganic Computing initiatives. We define a methodology to detect such\ninfluences at runtime, present an approach to consider this information in a\nreinforcement learning technique, and analyze the behavior in artificial as\nwell as real-world SASO system settings.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04205v1"
    },
    {
        "title": "A Regularized Opponent Model with Maximum Entropy Objective",
        "authors": [
            "Zheng Tian",
            "Ying Wen",
            "Zhichen Gong",
            "Faiz Punakkath",
            "Shihao Zou",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In a single-agent setting, reinforcement learning (RL) tasks can be cast into\nan inference problem by introducing a binary random variable o, which stands\nfor the \"optimality\". In this paper, we redefine the binary random variable o\nin multi-agent setting and formalize multi-agent reinforcement learning (MARL)\nas probabilistic inference. We derive a variational lower bound of the\nlikelihood of achieving the optimality and name it as Regularized Opponent\nModel with Maximum Entropy Objective (ROMMEO). From ROMMEO, we present a novel\nperspective on opponent modeling and show how it can improve the performance of\ntraining agents theoretically and empirically in cooperative games. To optimize\nROMMEO, we first introduce a tabular Q-iteration method ROMMEO-Q with proof of\nconvergence. We extend the exact algorithm to complex environments by proposing\nan approximate version, ROMMEO-AC. We evaluate these two algorithms on the\nchallenging iterated matrix game and differential game respectively and show\nthat they can outperform strong MARL baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.08087v2"
    },
    {
        "title": "winPIBT: Extended Prioritized Algorithm for Iterative Multi-agent Path\n  Finding",
        "authors": [
            "Keisuke Okumura",
            "Yasumasa Tamura",
            "Xavier Défago"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The problem of Multi-agent Path Finding (MAPF) consists in providing agents\nwith efficient paths while preventing collisions. Numerous solvers have been\ndeveloped so far since MAPF is critical for practical applications such as\nautomated warehouses. The recently-proposed Priority Inheritance with\nBacktracking (PIBT) is a promising decoupled method that solves MAPF\niteratively with flexible priorities. The method is aimed to be decentralized\nand has a very low computational cost, but it is shortsighted in the sense that\nit plans only one step ahead, thus occasionally resulting in inefficient\nplannings. This work proposes a generalization of PIBT, called windowed PIBT\n(winPIBT), that introduces a configurable time window. winPIBT allows agents to\nplan paths anticipating multiple steps ahead. We prove that, similarly to PIBT,\nall agents reach their own destinations in finite time as long as the\nenvironment is a graph with adequate properties, e.g., biconnected.\nExperimental results over various scenarios confirm that winPIBT mitigates\nlivelock situations occurring in PIBT, and usually plans more efficient paths\ngiven adequate window size.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.10149v5"
    },
    {
        "title": "Modeling Theory of Mind in Multi-Agent Games Using Adaptive Feedback\n  Control",
        "authors": [
            "Ismael T. Freire",
            "Xerxes D. Arsiwalla",
            "Jordi-Ysard Puigbò",
            "Paul Verschure"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  A major challenge in cognitive science and AI has been to understand how\nautonomous agents might acquire and predict behavioral and mental states of\nother agents in the course of complex social interactions. How does such an\nagent model the goals, beliefs, and actions of other agents it interacts with?\nWhat are the computational principles to model a Theory of Mind (ToM)? Deep\nlearning approaches to address these questions fall short of a better\nunderstanding of the problem. In part, this is due to the black-box nature of\ndeep networks, wherein computational mechanisms of ToM are not readily\nrevealed. Here, we consider alternative hypotheses seeking to model how the\nbrain might realize a ToM. In particular, we propose embodied and situated\nagent models based on distributed adaptive control theory to predict actions of\nother agents in five different game theoretic tasks (Harmony Game, Hawk-Dove,\nStag-Hunt, Prisoner's Dilemma and Battle of the Exes). Our multi-layer control\nmodels implement top-down predictions from adaptive to reactive layers of\ncontrol and bottom-up error feedback from reactive to adaptive layers. We test\ncooperative and competitive strategies among seven different agent models\n(cooperative, greedy, tit-for-tat, reinforcement-based, rational, predictive\nand other's-model agents). We show that, compared to pure reinforcement-based\nstrategies, probabilistic learning agents modeled on rational, predictive and\nother's-model phenotypes perform better in game-theoretic metrics across tasks.\nOur autonomous multi-agent models capture systems-level processes underlying a\nToM and highlight architectural principles of ToM from a control-theoretic\nperspective.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.13225v1"
    },
    {
        "title": "MANELA: A Multi-Agent Algorithm for Learning Network Embeddings",
        "authors": [
            "Han Zhang",
            "Hong Xu"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Playing an essential role in data mining, machine learning has a long history\nof being applied to networks on multifarious tasks and has played an essential\nrole in data mining. However, the discrete and sparse natures of networks often\nrender it difficult to apply machine learning directly to networks. To\ncircumvent this difficulty, one major school of thought to approach networks\nusing machine learning is via network embeddings. On the one hand, this network\nembeddings have achieved huge success on aggregated network data in recent\nyears. On the other hand, learning network embeddings on distributively stored\nnetworks still remained understudied: To the best of our knowledge, all\nexisting algorithms for learning network embeddings have hitherto been\nexclusively centralized and thus cannot be applied to these networks. To\naccommodate distributively stored networks, in this paper, we proposed a\nmulti-agent model. Under this model, we developed the multi-agent network\nembedding learning algorithm (MANELA) for learning network embeddings. We\ndemonstrate MANELA's advantages over other existing centralized network\nembedding learning algorithms both theoretically and experimentally. Finally,\nwe further our understanding in MANELA via visualization and exploration of its\nrelationship to DeepWalk.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.00303v1"
    },
    {
        "title": "A Simulation Model for Pedestrian Crowd Evacuation Based on Various AI\n  Techniques",
        "authors": [
            "Danial A. Muhammed",
            "Soran A. M. Saeed",
            "Tarik A. Rashid"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper attempts to design an intelligent simulation model for pedestrian\ncrowd evacuation. For this purpose, the cellular automata(CA) was fully\nintegrated with fuzzy logic, the kth nearest neighbors (KNN), and some\nstatistical equations. In this model, each pedestrian was assigned a specific\nspeed, according to his/her physical, biological and emotional features. The\nemergency behavior and evacuation efficiency of each pedestrian were evaluated\nby coupling his or her speed with various elements, such as environment,\npedestrian distribution and familiarity with the exits. These elements all have\ngreat impacts on the evacuation process. Several experiments were carried out\nto verify the performance of the model in different emergency scenarios. The\nresults show that the proposed model can predict the evacuation time and\nemergency behavior in various types of building interiors and pedestrian\ndistributions. The research provides a good reference to the design of building\nevacuation systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01629v1"
    },
    {
        "title": "The surprising little effectiveness of cooperative algorithms in\n  parallel problem solving",
        "authors": [
            "Sandro M. Reia",
            "Larissa F. Aquino",
            "José F. Fontanari"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Biological and cultural inspired optimization algorithms are nowadays part of\nthe basic toolkit of a great many research domains. By mimicking processes in\nnature and animal societies, these general-purpose search algorithms promise to\ndeliver optimal or near-optimal solutions using hardly any information on the\noptimization problems they are set to tackle. Here we study the performances of\na cultural-inspired algorithm -- the imitative learning search -- as well as of\nasexual and sexual variants of evolutionary algorithms in finding the global\nmaxima of NK-fitness landscapes. The main performance measure is the total\nnumber of agent updates required by the algorithms to find those global maxima\nand the baseline performance, which establishes the effectiveness of the\ncooperative algorithms, is set by the blind search in which the agents explore\nthe problem space (binary strings) by flipping bits at random. We find that\neven for smooth landscapes that exhibit a single maximum, the evolutionary\nalgorithms do not perform much better than the blind search due to the\nstochastic effects of the genetic roulette. The imitative learning is immune to\nthis effect thanks to the deterministic choice of the fittest string in the\npopulation, which is used as a model for imitation. The tradeoff is that for\nrugged landscapes the imitative learning search is more prone to be trapped in\nlocal maxima than the evolutionary algorithms. In fact, in the case of rugged\nlandscapes with a mild density of local maxima, the blind search either beats\nor matches the cooperative algorithms regardless of whether the task is to find\nthe global maximum or to find the fittest state within a given runtime.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.03347v3"
    },
    {
        "title": "Biases for Emergent Communication in Multi-agent Reinforcement Learning",
        "authors": [
            "Tom Eccles",
            "Yoram Bachrach",
            "Guy Lever",
            "Angeliki Lazaridou",
            "Thore Graepel"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We study the problem of emergent communication, in which language arises\nbecause speakers and listeners must communicate information in order to solve\ntasks. In temporally extended reinforcement learning domains, it has proved\nhard to learn such communication without centralized training of agents, due in\npart to a difficult joint exploration problem. We introduce inductive biases\nfor positive signalling and positive listening, which ease this problem. In a\nsimple one-step environment, we demonstrate how these biases ease the learning\nproblem. We also apply our methods to a more extended environment, showing that\nagents with these inductive biases achieve better performance, and analyse the\nresulting communication protocols.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05676v1"
    },
    {
        "title": "Multi-Agent Task Allocation in Complementary Teams: A Hunter and\n  Gatherer Approach",
        "authors": [
            "Mehdi Dadvar",
            "Saeed Moazami",
            "Harley R. Myler",
            "Hassan Zargarzadeh"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Consider a dynamic task allocation problem, where tasks are unknowingly\ndistributed over an environment. This paper considers each task comprised of\ntwo sequential subtasks: detection and completion, where each subtask can only\nbe carried out by a certain type of agent. We address this problem using a\nnovel nature-inspired approach called \"hunter and gatherer\". The proposed\nmethod employs two complementary teams of agents: one agile in detecting\n(hunters) and another skillful in completing (gatherers) the tasks. To minimize\nthe collective cost of task accomplishments in a distributed manner, a\ngame-theoretic solution is introduced to couple agents from complementary\nteams. We utilize market-based negotiation models to develop incentive-based\ndecision-making algorithms relying on innovative notions of \"certainty and\nuncertainty profit margins\". The simulation results demonstrate that employing\ntwo complementary teams of hunters and gatherers can effectually improve the\nnumber of tasks completed by agents compared to conventional methods, while the\ncollective cost of accomplishments is minimized. In addition, the stability and\nefficacy of the proposed solutions are studied using Nash equilibrium analysis\nand statistical analysis respectively. It is also numerically shown that the\nproposed solutions function fairly, i.e. for each type of agent, the overall\nworkload is distributed equally.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05748v2"
    },
    {
        "title": "Spatial Influence-aware Reinforcement Learning for Intelligent\n  Transportation System",
        "authors": [
            "Wenhang Bao",
            "Xiao-yang Liu"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Intelligent transportation systems (ITSs) are envisioned to be crucial for\nsmart cities, which aims at improving traffic flow to improve the life quality\nof urban residents and reducing congestion to improve the efficiency of\ncommuting. However, several challenges need to be resolved before such systems\ncan be deployed, for example, conventional solutions for Markov decision\nprocess (MDP) and single-agent Reinforcement Learning (RL) algorithms suffer\nfrom poor scalability, and multi-agent systems suffer from poor communication\nand coordination. In this paper, we explore the potential of mutual information\nsharing, or in other words, spatial influence based communication, to optimize\ntraffic light control policy. First, we mathematically analyze the\ntransportation system. We conclude that the transportation system does not have\nstationary Nash Equilibrium, thereby reinforcement learning algorithms offer\nsuitable solutions. Secondly, we describe how to build a multi-agent Deep\nDeterministic Policy Gradient (DDPG) system with spatial influence and social\ngroup utility incorporated. Then we utilize the grid topology road network to\nempirically demonstrate the scalability of the new system. We demonstrate three\ntypes of directed communications to show the effect of directions of social\ninfluence on the entire network utility and individual utility. Lastly, we\ndefine \"selfish index\" and analyze the effect of it on total group utility.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.06880v1"
    },
    {
        "title": "Exploration and Coordination of Complementary Multi-Robot Teams in a\n  Hunter and Gatherer Scenario",
        "authors": [
            "Mehdi Dadvar",
            "Saeed Moazami",
            "Harley R. Myler",
            "Hassan Zargarzadeh"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The hunter and gatherer approach copes with the problem of dynamic\nmulti-robot task allocation, where tasks are unknowingly distributed over an\nenvironment. This approach employs two complementary teams of agents: one agile\nin exploring (hunters) and another dexterous in completing (gatherers) the\ntasks. Although this approach has been studied from the task planning point of\nview in our previous works, the multi-robot exploration and coordination\naspects of the problem remain uninvestigated. This paper proposes a multi-robot\nexploration algorithm for hunters based on innovative notions of \"expected\ninformation gain\" to minimize the collective cost of task accomplishments in a\ndistributed manner. Besides, we present a coordination solution between hunters\nand gatherers by integrating the novel notion of profit margins into the\nconcept of expected information gain. Statistical analysis of extensive\nsimulation results confirms the efficacy of the proposed algorithms compared in\ndifferent environments with varying levels of obstacles complexities. We also\ndemonstrate that the lack of effective coordination between hunters and\ngatherers significantly hurts the total effectiveness of the planning,\nespecially in environments containing dense obstacles and confined corridors.\nFinally, it is statistically proven that the overall workload is distributed\nequally for each type of agent which ensures that the proposed solution is not\nbiased to a particular agent and all agents behave analogously under similar\ncharacteristics.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.07521v3"
    },
    {
        "title": "Graph Learning Under Partial Observability",
        "authors": [
            "Vincenzo Matta",
            "Augusto Santos",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Many optimization, inference and learning tasks can be accomplished\nefficiently by means of decentralized processing algorithms where the network\ntopology (i.e., the graph) plays a critical role in enabling the interactions\namong neighboring nodes. There is a large body of literature examining the\neffect of the graph structure on the performance of decentralized processing\nstrategies. In this article, we examine the inverse problem and consider the\nreverse question: How much information does observing the behavior at the nodes\nof a graph convey about the underlying topology? For large-scale networks, the\ndifficulty in addressing such inverse problems is compounded by the fact that\nusually only a limited fraction of the nodes can be probed, giving rise to a\nsecond important question: Despite the presence of unobserved nodes, can\npartial observations still be sufficient to discover the graph linking the\nprobed nodes? The article surveys recent advances on this challenging learning\nproblem and related questions.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.08465v3"
    },
    {
        "title": "A Survey of Deep Reinforcement Learning in Video Games",
        "authors": [
            "Kun Shao",
            "Zhentao Tang",
            "Yuanheng Zhu",
            "Nannan Li",
            "Dongbin Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Deep reinforcement learning (DRL) has made great achievements since proposed.\nGenerally, DRL agents receive high-dimensional inputs at each step, and make\nactions according to deep-neural-network-based policies. This learning\nmechanism updates the policy to maximize the return with an end-to-end method.\nIn this paper, we survey the progress of DRL methods, including value-based,\npolicy gradient, and model-based algorithms, and compare their main techniques\nand properties. Besides, DRL plays an important role in game artificial\nintelligence (AI). We also take a review of the achievements of DRL in various\nvideo games, including classical Arcade games, first-person perspective games\nand multi-agent real-time strategy games, from 2D to 3D, and from single-agent\nto multi-agent. A large number of video game AIs with DRL have achieved\nsuper-human performance, while there are still some challenges in this domain.\nTherefore, we also discuss some key points when applying DRL methods to this\nfield, including exploration-exploitation, sample efficiency, generalization\nand transfer, multi-agent learning, imperfect information, and delayed spare\nrewards, as well as some research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.10944v2"
    },
    {
        "title": "A Policy-oriented Agent-based Model of Recruitment into Organized Crime",
        "authors": [
            "Gian Maria Campedelli",
            "Francesco Calderoni",
            "Mario Paolucci",
            "Tommaso Comunale",
            "Daniele Vilone",
            "Federico Cecconi",
            "Giulia Andrighetto"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Criminal organizations exploit their presence on territories and local\ncommunities to recruit new workforce in order to carry out their criminal\nactivities and business. The ability to attract individuals is crucial for\nmaintaining power and control over the territories in which these groups are\nsettled. This study proposes the formalization, development and analysis of an\nagent-based model (ABM) that simulates a neighborhood of Palermo (Sicily) with\nthe aim to understand the pathways that lead individuals to recruitment into\norganized crime groups (OCGs). Using empirical data on social, economic and\ncriminal conditions of the area under analysis, we use a multi-layer network\napproach to simulate this scenario. As the final goal, we test different\npolicies to counter recruitment into OCGs. These scenarios are based on two\ndifferent dimensions of prevention and intervention: (i) primary and secondary\nsocialization and (ii) law enforcement targeting strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.03494v1"
    },
    {
        "title": "Peer-to-Peer Trading in Electricity Networks: An Overview",
        "authors": [
            "Wayes Tushar",
            "Tapan K. Saha",
            "Chau Yuen",
            "David Smith",
            "H. Vincent Poor"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Peer-to-peer trading is a next-generation energy management technique that\neconomically benefits proactive consumers (prosumers) transacting their energy\nas goods and services. At the same time, peer-to-peer energy trading is also\nexpected to help the grid by reducing peak demand, lowering reserve\nrequirements, and curtailing network loss. However, large-scale deployment of\npeer-to-peer trading in electricity networks poses a number of challenges in\nmodeling transactions in both the virtual and physical layers of the network.\nAs such, this article provides a comprehensive review of the state-of-the-art\nin research on peer-to-peer energy trading techniques. By doing so, we provide\nan overview of the key features of peer-to-peer trading and its benefits of\nrelevance to the grid and prosumers. Then, we systematically classify the\nexisting research in terms of the challenges that the studies address in the\nvirtual and the physical layers. We then further identify and discuss those\ntechnical approaches that have been extensively used to address the challenges\nin peer-to-peer transactions. Finally, the paper is concluded with potential\nfuture research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.06882v1"
    },
    {
        "title": "Objective Social Choice: Using Auxiliary Information to Improve Voting\n  Outcomes",
        "authors": [
            "Silviu Pitis",
            "Michael R. Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  How should one combine noisy information from diverse sources to make an\ninference about an objective ground truth? This frequently recurring, normative\nquestion lies at the core of statistics, machine learning, policy-making, and\neveryday life. It has been called \"combining forecasts\", \"meta-analysis\",\n\"ensembling\", and the \"MLE approach to voting\", among other names. Past studies\ntypically assume that noisy votes are identically and independently distributed\n(i.i.d.), but this assumption is often unrealistic. Instead, we assume that\nvotes are independent but not necessarily identically distributed and that our\nensembling algorithm has access to certain auxiliary information related to the\nunderlying model governing the noise in each vote. In our present work, we: (1)\ndefine our problem and argue that it reflects common and socially relevant real\nworld scenarios, (2) propose a multi-arm bandit noise model and count-based\nauxiliary information set, (3) derive maximum likelihood aggregation rules for\nranked and cardinal votes under our noise model, (4) propose, alternatively, to\nlearn an aggregation rule using an order-invariant neural network, and (5)\nempirically compare our rules to common voting rules and naive\nexperience-weighted modifications. We find that our rules successfully use\nauxiliary information to outperform the naive baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.10092v1"
    },
    {
        "title": "Multi-Agent Continuous Transportation with Online Balanced Partitioning",
        "authors": [
            "Chao Wang",
            "Somchaya Liemhetcharat",
            "Kian Hsiang Low"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  We introduce the concept of continuous transportation task to the context of\nmulti-agent systems. A continuous transportation task is one in which a\nmulti-agent team visits a number of fixed locations, picks up objects, and\ndelivers them to a final destination. The goal is to maximize the rate of\ntransportation while the objects are replenished over time. Examples of\nproblems that need continuous transportation are foraging, area sweeping, and\nfirst/last mile problem. Previous approaches typically neglect the interference\nand are highly dependent on communications among agents. Some also incorporate\nan additional reconnaissance agent to gather information. In this paper, we\npresent a hybrid of centralized and distributed approaches that minimize the\ninterference and communications in the multi-agent team without the need for a\nreconnaissance agent. We contribute two partitioning-transportation algorithms\ninspired by existing algorithms, and contribute one novel online\npartitioning-transportation algorithm with information gathering in the\nmulti-agent team. Our algorithms have been implemented and tested extensively\nin the simulation. The results presented in this paper demonstrate the\neffectiveness of our algorithms that outperform the existing algorithms, even\nwithout any communications between the agents and without the presence of a\nreconnaissance agent.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.07209v2"
    },
    {
        "title": "Valuing knowledge, information and agency in Multi-agent Reinforcement\n  Learning: a case study in smart buildings",
        "authors": [
            "Hussain Kazmi",
            "Johan Suykens",
            "Johan Driesen"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Increasing energy efficiency in buildings can reduce costs and emissions\nsubstantially. Historically, this has been treated as a local, or single-agent,\noptimization problem. However, many buildings utilize the same types of thermal\nequipment e.g. electric heaters and hot water vessels. During operation,\noccupants in these buildings interact with the equipment differently thereby\ndriving them to diverse regions in the state-space. Reinforcement learning\nagents can learn from these interactions, recorded as sensor data, to optimize\nthe overall energy efficiency. However, if these agents operate individually at\na household level, they can not exploit the replicated structure in the\nproblem. In this paper, we demonstrate that this problem can indeed benefit\nfrom multi-agent collaboration by making use of targeted exploration of the\nstate-space allowing for better generalization. We also investigate trade-offs\nbetween integrating human knowledge and additional sensors. Results show that\nsavings of over 40% are possible with collaborative multi-agent systems making\nuse of either expert knowledge or additional sensors with no loss of occupant\ncomfort. We find that such multi-agent systems comfortably outperform\ncomparable single agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.03491v1"
    },
    {
        "title": "An Agent-Based Simulation of Residential Location Choice of Tenants in\n  Tehran, Iran",
        "authors": [
            "A. Shirzadi Babakan",
            "A. Alimohammadi"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Residential location choice modeling is one of the substantial components of\nland use and transportation models. While numerous aggregated mathematical and\nstatistical approaches have been developed to model the residence choice\nbehavior of households, disaggregated approaches such as the agent-based\nmodeling have shown interesting capabilities. In this article, a novel\nagent-based approach is developed to simulate the residential location choice\nof tenants in Tehran, the capital of Iran. Tenants are considered as agents who\nselect their desired residential alternatives according to their\ncharacteristics and preferences for various criteria such as the rent,\naccessibility to different services and facilities, environmental pollution,\nand distance from their workplace and former residence. The choice set of\nagents is limited to their desired residential alternatives by applying a\nconstrained NSGA-II algorithm. Then, agents compete with each other to select\ntheir final residence among their alternatives. Results of the proposed\napproach are validated by comparing simulated and actual residences of a sample\nof tenants. Results show that the proposed approach is able to accurately\nsimulate the residence of 59.3% of tenants at the traffic analysis zone level.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.04927v1"
    },
    {
        "title": "Impacts of transport development on residence choice of renter\n  households: An agent-based evaluation",
        "authors": [
            "A. S. Babakan",
            "M. Taleai"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Because of improving accessibility, transport developments play an important\nrole in residence choice of renter households. In this paper, an agent-based\nmodel is developed to investigate impacts of different transport developments\non residence choice of renter households in Tehran, the capital of Iran. In the\nproposed model, renter households are considered as agents who make a\nmulti-objective decision and compete with each other to rent a preferred\nresidential zone. Then, three transport development scenarios including\nconstruction a new highway, subway and bus rapid transit (BRT) line are\nsimulated and resulting changes in residence choice of agents are evaluated.\nResults show that transport development scenarios significantly affect\nresidence choice behavior of different socio-economic categories of renter\nhouseholds and lead to considerable changes in the residential demand,\ncomposition of residents, mean income level and mean car ownership in their\nvicinities.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.04932v1"
    },
    {
        "title": "An agent-based evaluation of impacts of transport developments on the\n  modal shift in Tehran, Iran",
        "authors": [
            "A. Shirzadi Babakan",
            "A. Alimohammadi",
            "M. Taleai"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Changes in travel modes used by people, particularly reduction of the private\ncar use, is an important determinant of effectiveness of transportation plans.\nBecause of dependencies between the choices of residential location and travel\nmode, integrated modelling of these choices has been proposed by some\nresearchers. In this paper, an agent-based microsimulation model has been\ndeveloped to evaluate impacts of different transport development plans on\nchoices of residential location and commuting mode of tenant households in\nTehran, the capital of Iran. In the proposed model, households are considered\nas agents who select their desired residential location using a constrained\nNSGA-II algorithm and in a competition with other households. In addition, they\nchoose their commuting mode by applying a multi-criteria decision making\nmethod. Afterwards, effects of development of a new highway, subway and bus\nrapid transit (BRT) line on their residential location and commuting mode\nchoices are evaluated. Results show that despite the residential self-selection\neffects, these plans result in considerable changes in the commuting mode of\ndifferent socioeconomic categories of households. Development of the new subway\nline shows promising results by reducing the private car use among the all\nsocio-economic categories of households. But the new highway development\nunsatisfactorily results in increase in the private car use. In addition,\ndevelopment of the new BRT line does not show significant effects on the\ncommuting mode change, particularly on decrease in the private car use.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.04934v1"
    },
    {
        "title": "Asynchronous opinion dynamics on the $k$-nearest-neighbors graph",
        "authors": [
            "Wilbert Samuel Rossi",
            "Paolo Frasca"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper is about a new model of opinion dynamics with opinion-dependent\nconnectivity. We assume that agents update their opinions asynchronously and\nthat each agent's new opinion depends on the opinions of the $k$ agents that\nare closest to it. We show that the resulting dynamics is substantially\ndifferent from comparable models in the literature, such as bounded-confidence\nmodels. We study the equilibria of the dynamics, observing that they are robust\nto perturbations caused by the introduction of new agents. We also prove that\nif the number of agents $n$ is smaller than $2k$, the dynamics converge to\nconsensus. This condition is only sufficient.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.07401v2"
    },
    {
        "title": "Asynchronous Gradient-Push",
        "authors": [
            "Mahmoud Assran",
            "Michael Rabbat"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We consider a multi-agent framework for distributed optimization where each\nagent has access to a local smooth strongly convex function, and the collective\ngoal is to achieve consensus on the parameters that minimize the sum of the\nagents' local functions. We propose an algorithm wherein each agent operates\nasynchronously and independently of the other agents. When the local functions\nare strongly-convex with Lipschitz-continuous gradients, we show that the\niterates at each agent converge to a neighborhood of the global minimum, where\nthe neighborhood size depends on the degree of asynchrony in the multi-agent\nnetwork. When the agents work at the same rate, convergence to the global\nminimizer is achieved. Numerical experiments demonstrate that Asynchronous\nGradient-Push can minimize the global objective faster than state-of-the-art\nsynchronous first-order methods, is more robust to failing or stalling agents,\nand scales better with the network size.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.08950v3"
    },
    {
        "title": "Min-Max Tours for Task Allocation to Heterogeneous Agents",
        "authors": [
            "Amritha Prasad",
            "Han-Lim Choi",
            "Shreyas Sundaram"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  We consider a scenario consisting of a set of heterogeneous mobile agents\nlocated at a depot, and a set of tasks dispersed over a geographic area. The\nagents are partitioned into different types. The tasks are partitioned into\nspecialized tasks that can only be done by agents of a certain type, and\ngeneric tasks that can be done by any agent. The distances between each pair of\ntasks are specified, and satisfy the triangle inequality. Given this scenario,\nwe address the problem of allocating these tasks among the available agents\n(subject to type compatibility constraints) while minimizing the maximum cost\nto tour the allocation by any agent and return to the depot. This problem is\nNP-hard, and we give a three phase algorithm to solve this problem that\nprovides 5-factor approximation, regardless of the total number of agents and\nthe number of agents of each type. We also show that in the special case where\nthere is only one agent of each type, the algorithm has an approximation factor\nof 4.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.09792v1"
    },
    {
        "title": "A Survey on Agent-based Simulation using Hardware Accelerators",
        "authors": [
            "Jiajian Xiao",
            "Philipp Andelfinger",
            "David Eckhoff",
            "Wentong Cai",
            "Alois Knoll"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Due to decelerating gains in single-core CPU performance, computationally\nexpensive simulations are increasingly executed on highly parallel hardware\nplatforms. Agent-based simulations, where simulated entities act with a certain\ndegree of autonomy, frequently provide ample opportunities for parallelisation.\nThus, a vast variety of approaches proposed in the literature demonstrated\nconsiderable performance gains using hardware platforms such as many-core CPUs\nand GPUs, merged CPU-GPU chips as well as FPGAs. Typically, a combination of\ntechniques is required to achieve high performance for a given simulation\nmodel, putting substantial burden on modellers. To the best of our knowledge,\nno systematic overview of techniques for agent-based simulations on hardware\naccelerators has been given in the literature. To close this gap, we provide an\noverview and categorisation of the literature according to the applied\ntechniques. Since at the current state of research, challenges such as the\npartitioning of a model for execution on heterogeneous hardware are still a\nlargely manual process, we sketch directions for future research towards\nautomating the hardware mapping and execution. This survey targets modellers\nseeking an overview of suitable hardware platforms and execution techniques for\na specific simulation model, as well as methodology researchers interested in\npotential research gaps requiring further exploration.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.01014v1"
    },
    {
        "title": "An agent-based model of an endangered population of the Arctic fox from\n  Mednyi Island",
        "authors": [
            "Angelina Brilliantova",
            "Anton Pletenev",
            "Liliya Doronina",
            "Hadi Hosseini"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Artificial Intelligence techniques such as agent-based modeling and\nprobabilistic reasoning have shown promise in modeling complex biological\nsystems and testing ecological hypotheses through simulation. We develop an\nagent-based model of Arctic foxes from Medniy Island while utilizing\nProbabilistic Graphical Models to capture the conditional dependencies between\nthe random variables. Such models provide valuable insights in analyzing\nfactors behind catastrophic degradation of this population and in revealing\nevolutionary mechanisms of its persistence in high-density environment. Using\nempirical data from studies in Medniy Island, we create a realistic model of\nArctic foxes as agents, and study their survival and population dynamics under\na variety of conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.06103v1"
    },
    {
        "title": "Decentralized Task Allocation in Multi-Robot Systems via Bipartite Graph\n  Matching Augmented with Fuzzy Clustering",
        "authors": [
            "Payam Ghassemi",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Robotic systems, working together as a team, are becoming valuable players in\ndifferent real-world applications, from disaster response to warehouse\nfulfillment services. Centralized solutions for coordinating multi-robot teams\noften suffer from poor scalability and vulnerability to communication\ndisruptions. This paper develops a decentralized multi-agent task allocation\n(Dec-MATA) algorithm for multi-robot applications. The task planning problem is\nposed as a maximum-weighted matching of a bipartite graph, the solution of\nwhich using the blossom algorithm allows each robot to autonomously identify\nthe optimal sequence of tasks it should undertake. The graph weights are\ndetermined based on a soft clustering process, which also plays a problem\ndecomposition role seeking to reduce the complexity of the individual-agents'\ntask assignment problems. To evaluate the new Dec-MATA algorithm, a series of\ncase studies (of varying complexity) are performed, with tasks being\ndistributed randomly over an observable 2D environment. A centralized approach,\nbased on a state-of-the-art MILP formulation of the multi-Traveling Salesman\nproblem is used for comparative analysis. While getting within 7-28% of the\noptimal cost obtained by the centralized algorithm, the Dec-MATA algorithm is\nfound to be 1-3 orders of magnitude faster and minimally sensitive to\ntask-to-robot ratios, unlike the centralized algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.07957v1"
    },
    {
        "title": "Testing Self-Organizing Multiagent Systems",
        "authors": [
            "Nathalia Nascimento",
            "Carlos Lucena",
            "Paulo Alencar",
            "Carlos Juliano Viana"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Multiagent Systems (MASs) involve different characteristics, such as\nautonomy, asynchronous and social features, which make these systems more\ndifficult to understand. Thus, there is a lack of procedures guaranteeing that\nmultiagent systems would behave as desired. Further complicating the situation\nis the fact that current agent-based approaches may also involve\nnon-deterministic characteristics, such as learning, self-adaptation and\nself-organization (SASO). Nonetheless, there is a gap in the literature\nregarding the testing of systems with these features. This paper presents a\npublish-subscribe-based approach to develop test applications that facilitate\nthe process of failure diagnosis in a self-organizing MAS. These tests are able\nto detect failures at the global behavior of the system or at the local\nproperties of its parts. To illustrate the use of this approach, we developed a\nself-organizing MAS system based on the context of the Internet of Things\n(IoT), which simulates a set of smart street lights, and we performed\nfunctional ad-hoc tests. The street lights need to interact with each other in\norder to achieve the global goals of reducing the energy consumption and\nmaintaining the maximum visual comfort in illuminated areas. To achieve these\nglobal behaviors, the street lights develop local behaviors automatically\nthrough a self-organizing process based on machine learning algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.01736v1"
    },
    {
        "title": "Fast multipole networks",
        "authors": [
            "Steve Huntsman"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Two prerequisites for robotic multiagent systems are mobility and\ncommunication. Fast multipole networks (FMNs) enable both ends within a unified\nframework. FMNs can be organized very efficiently in a distributed way from\nlocal information and are ideally suited for motion planning using artificial\npotentials. We compare FMNs to conventional communication topologies, and find\nthat FMNs offer competitive communication performance (including higher network\nefficiency per edge at marginal energy cost) in addition to advantages for\nmobility.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.04869v3"
    },
    {
        "title": "Automatic Calibration of Dynamic and Heterogeneous Parameters in\n  Agent-based Model",
        "authors": [
            "Dongjun Kim",
            "Tae-Sub Yun",
            "Il-Chul Moon"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  While simulations have been utilized in diverse domains, such as urban growth\nmodeling, market dynamics modeling, etc; some of these applications may require\nvalidations based upon some real-world observations modeled in the simulation,\nas well. This validation has been categorized into either qualitative\nface-validation or quantitative empirical validation, but as the importance and\nthe accumulation of data grows, the importance of the quantitative validation\nhas been highlighted in the recent studies, i.e. digital twin. The key\ncomponent of quantitative validation is finding a calibrated set of parameters\nto regenerate the real-world observations with simulation models. While this\nparameter calibration has been fixed throughout a simulation execution, this\npaper expands the static parameter calibration in two dimensions: dynamic\ncalibration and heterogeneous calibration. First, dynamic calibration changes\nthe parameter values over the simulation period by reflecting the simulation\noutput trend. Second, heterogeneous calibration changes the parameter values\nper simulated entity clusters by considering the similarities of entity states.\nWe experimented the suggested calibrations on one hypothetical case and another\nreal-world case. As a hypothetical scenario, we use the Wealth Distribution\nModel to illustrate how our calibration works. As a real-world scenario, we\nselected Real Estate Market Model because of three reasons. First, the models\nhave heterogeneous entities as being agent-based models; second, they are\neconomic models with real-world trends over time; and third, they are\napplicable to the real-world scenarios where we can gather validation data.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.03309v1"
    },
    {
        "title": "Swarm Intelligence for Morphogenetic Engineering",
        "authors": [
            "Bruce J. MacLennan",
            "Allen C. McBride"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We argue that embryological morphogenesis provides a model of how massive\nswarms of microscopic agents can be coordinated to assemble complex, multiscale\nhierarchical structures. This is accomplished by understanding natural\nmorphogenetic processes in mathematical terms, abstracting from the biological\nspecifics, and implementing these mathematical principles in artificial\nsystems. We have developed a notation based on partial differential equations\nfor artificial morphogenesis and have designed a prototype morphogenetic\nprogramming language, which permits precise description of morphogenetic\nalgorithms and their automatic translation to simulation software.\nMorphogenetic programming is illustrated by two examples: (1) use of a modified\nflocking algorithm to route dense fiber bundles between regions of an\nartificial cortex while avoiding other bundles; (2) use of the\nclock-and-wavefront model of spinal segmentation for the assembly of the\nsegmented spine of an insect-like robot body and for assembling segmented legs\non the robot's spine. Finally, we show how a variation of smoothed particle\nhydrodynamics (SPH) swarm robotic control can be applied to the global-to-local\ncompilation problem, that is, the derivation of individual agent control from\nglobal PDE specifications.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.08787v1"
    },
    {
        "title": "STMARL: A Spatio-Temporal Multi-Agent Reinforcement Learning Approach\n  for Cooperative Traffic Light Control",
        "authors": [
            "Yanan Wang",
            "Tong Xu",
            "Xin Niu",
            "Chang Tan",
            "Enhong Chen",
            "Hui Xiong"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The development of intelligent traffic light control systems is essential for\nsmart transportation management. While some efforts have been made to optimize\nthe use of individual traffic lights in an isolated way, related studies have\nlargely ignored the fact that the use of multi-intersection traffic lights is\nspatially influenced and there is a temporal dependency of historical traffic\nstatus for current traffic light control. To that end, in this paper, we\npropose a novel SpatioTemporal Multi-Agent Reinforcement Learning (STMARL)\nframework for effectively capturing the spatio-temporal dependency of multiple\nrelated traffic lights and control these traffic lights in a coordinating way.\nSpecifically, we first construct the traffic light adjacency graph based on the\nspatial structure among traffic lights. Then, historical traffic records will\nbe integrated with current traffic status via Recurrent Neural Network\nstructure. Moreover, based on the temporally-dependent traffic information, we\ndesign a Graph Neural Network based model to represent relationships among\nmultiple traffic lights, and the decision for each traffic light will be made\nin a distributed way by the deep Q-learning method. Finally, the experimental\nresults on both synthetic and real-world data have demonstrated the\neffectiveness of our STMARL framework, which also provides an insightful\nunderstanding of the influence mechanism among multi-intersection traffic\nlights.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.10577v3"
    },
    {
        "title": "Multi-Objective Multi-Agent Decision Making: A Utility-based Analysis\n  and Survey",
        "authors": [
            "Roxana Rădulescu",
            "Patrick Mannion",
            "Diederik M. Roijers",
            "Ann Nowé"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The majority of multi-agent system (MAS) implementations aim to optimise\nagents' policies with respect to a single objective, despite the fact that many\nreal-world problem domains are inherently multi-objective in nature.\nMulti-objective multi-agent systems (MOMAS) explicitly consider the possible\ntrade-offs between conflicting objective functions. We argue that, in MOMAS,\nsuch compromises should be analysed on the basis of the utility that these\ncompromises have for the users of a system. As is standard in multi-objective\noptimisation, we model the user utility using utility functions that map value\nor return vectors to scalar values. This approach naturally leads to two\ndifferent optimisation criteria: expected scalarised returns (ESR) and\nscalarised expected returns (SER). We develop a new taxonomy which classifies\nmulti-objective multi-agent decision making settings, on the basis of the\nreward structures, and which and how utility functions are applied. This allows\nus to offer a structured view of the field, to clearly delineate the current\nstate-of-the-art in multi-objective multi-agent decision making approaches and\nto identify promising directions for future research. Starting from the\nexecution phase, in which the selected policies are applied and the utility for\nthe users is attained, we analyse which solution concepts apply to the\ndifferent settings in our taxonomy. Furthermore, we define and discuss these\nsolution concepts under both ESR and SER optimisation criteria. We conclude\nwith a summary of our main findings and a discussion of many promising future\nresearch directions in multi-objective multi-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.02964v1"
    },
    {
        "title": "Multi-Agent Control Using Coverage Over Time-Varying Domains",
        "authors": [
            "Xiaotian Xu",
            "Yancy Diaz-Mercado"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Multi-agent coverage control is used as a mechanism to influence the behavior\nof a group of robots by introducing time-varying domain. The coverage\noptimization problem is modified to adopt time-varying domains, and the\nproposed control law possesses an exponential convergence characteristic.\nCumbrous control for many robots is simplified by deploying distribution and\nbehavior of the robot team as a whole. In the proposed approach, the inputs to\nthe multi-agent system, i.e., time-varying density and time-varying domain, are\nagnostic to the size of the system. Analytic expressions of surface and line\nintegrals present in the control law are obtained under uniform density. The\nscalability of the proposed control strategy is explained and verified via\nnumerical simulation. Experiments on real robots are used to test the proposed\ncontrol law.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.05377v1"
    },
    {
        "title": "TruPercept: Trust Modelling for Autonomous Vehicle Cooperative\n  Perception from Synthetic Data",
        "authors": [
            "Braden Hurl",
            "Robin Cohen",
            "Krzysztof Czarnecki",
            "Steven Waslander"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Inter-vehicle communication for autonomous vehicles (AVs) stands to provide\nsignificant benefits in terms of perception robustness. We propose a novel\napproach for AVs to communicate perceptual observations, tempered by trust\nmodelling of peers providing reports. Based on the accuracy of reported object\ndetections as verified locally, communicated messages can be fused to augment\nperception performance beyond line of sight and at great distance from the ego\nvehicle. Also presented is a new synthetic dataset which can be used to test\ncooperative perception. The TruPercept dataset includes unreliable and\nmalicious behaviour scenarios to experiment with some challenges cooperative\nperception introduces. The TruPercept runtime and evaluation framework allows\nmodular component replacement to facilitate ablation studies as well as the\ncreation of new trust scenarios we are able to show.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.07867v1"
    },
    {
        "title": "Limited-budget output consensus for descriptor multiagent systems with\n  energy constraints",
        "authors": [
            "Jianxiang Xi",
            "Cheng Wang",
            "Xiaojun Yang",
            "Bailong Yang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The current paper deals with limited-budget output consensus for descriptor\nmultiagent systems with two types of switching communication topologies; that\nis, switching connected ones and jointly connected ones. Firstly, a singular\ndynamic output feedback control protocol with switching communication\ntopologies is proposed on the basis of the observable decomposition, where an\nenergy constraint is involved and protocol states of neighboring agents are\nutilized to derive a new two-step design approach of gain matrices. Then,\nlimited-budget output consensus problems are transformed into asymptotic\nstability ones and a valid candidate of the output consensus function is\ndetermined. Furthermore, sufficient conditions for limited-budget output\nconsensus design for two types of switching communication topologies are\nproposed, respectively. Finally, two numerical simulations are shown to\ndemonstrate theoretical conclusions.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.08345v1"
    },
    {
        "title": "Robust time-varying formation design for multi-agent systems with\n  disturbances: Extended-state-observer method",
        "authors": [
            "Le Wang",
            "Jianxiang Xi",
            "Ming He",
            "Guangbin Liu"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Robust time-varying formation design problems for second-order multi-agent\nsystems subjected to external disturbances are investigated. Firstly, by\nconstructing an extended state observer, the disturbance compensation is\nestimated, which is a critical term in the proposed robust time-varying\nformation control protocol. Then, an explicit expression of the formation\ncenter function is determined and impacts of disturbance compensations on the\nformation center function are presented. With the formation feasibility\nconditions, robust time-varying formation design criteria are derived to\ndetermine the gain matrix of the formation control protocol by utilizing the\nalgebraic Riccati equation technique. Furthermore, the tracking performance and\nthe robustness property of multi-agent systems are analyzed. Finally, the\nnumerical simulation is provided to illustrate the effectiveness of theoretical\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.08974v1"
    },
    {
        "title": "Multiagent Evaluation under Incomplete Information",
        "authors": [
            "Mark Rowland",
            "Shayegan Omidshafiei",
            "Karl Tuyls",
            "Julien Perolat",
            "Michal Valko",
            "Georgios Piliouras",
            "Remi Munos"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper investigates the evaluation of learned multiagent strategies in\nthe incomplete information setting, which plays a critical role in ranking and\ntraining of agents. Traditionally, researchers have relied on Elo ratings for\nthis purpose, with recent works also using methods based on Nash equilibria.\nUnfortunately, Elo is unable to handle intransitive agent interactions, and\nother techniques are restricted to zero-sum, two-player settings or are limited\nby the fact that the Nash equilibrium is intractable to compute. Recently, a\nranking method called {\\alpha}-Rank, relying on a new graph-based\ngame-theoretic solution concept, was shown to tractably apply to general games.\nHowever, evaluations based on Elo or {\\alpha}-Rank typically assume noise-free\ngame outcomes, despite the data often being collected from noisy simulations,\nmaking this assumption unrealistic in practice. This paper investigates\nmultiagent evaluation in the incomplete information regime, involving\ngeneral-sum many-player games with noisy outcomes. We derive sample complexity\nguarantees required to confidently rank agents in this setting. We propose\nadaptive algorithms for accurate ranking, provide correctness and sample\ncomplexity guarantees, then introduce a means of connecting uncertainties in\nnoisy match outcomes to uncertainties in rankings. We evaluate the performance\nof these approaches in several domains, including Bernoulli games, a soccer\nmeta-game, and Kuhn poker.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.09849v4"
    },
    {
        "title": "Resilient Coordinated Movement of Connected Autonomous Vehicles",
        "authors": [
            "Mostafa Safi",
            "Seyed Mehran Dibaji",
            "Mohammad Pirani"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we consider coordinated movement of a network of vehicles\nconsisting of a bounded number of malicious agents, that is, vehicles must\nreach consensus in longitudinal position and a common predefined velocity. The\nmotions of vehicles are modeled by double-integrator dynamics and\ncommunications over the network are asynchronous with delays. Each normal\nvehicle updates its states by utilizing the information it receives from\nvehicles in its vicinity. On the other hand, misbehaving vehicles make updates\narbitrarily and might threaten the consensus within the network by\nintentionally changing their moving direction or broadcasting faulty\ninformation in their neighborhood. We propose an asynchronous updating strategy\nfor normal vehicles, based on filtering extreme values received from\nneighboring vehicles, to save them from being misguided by malicious vehicles.\nWe show that there exist topological constraints on the network in terms of\ngraph robustness under which the vehicles resiliently achieve coordinated\nmovement. Numerical simulations are provided to evaluate the results.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.10874v4"
    },
    {
        "title": "A Generalized Training Approach for Multiagent Learning",
        "authors": [
            "Paul Muller",
            "Shayegan Omidshafiei",
            "Mark Rowland",
            "Karl Tuyls",
            "Julien Perolat",
            "Siqi Liu",
            "Daniel Hennes",
            "Luke Marris",
            "Marc Lanctot",
            "Edward Hughes",
            "Zhe Wang",
            "Guy Lever",
            "Nicolas Heess",
            "Thore Graepel",
            "Remi Munos"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper investigates a population-based training regime based on\ngame-theoretic principles called Policy-Spaced Response Oracles (PSRO). PSRO is\ngeneral in the sense that it (1) encompasses well-known algorithms such as\nfictitious play and double oracle as special cases, and (2) in principle\napplies to general-sum, many-player games. Despite this, prior studies of PSRO\nhave been focused on two-player zero-sum games, a regime wherein Nash\nequilibria are tractably computable. In moving from two-player zero-sum games\nto more general settings, computation of Nash equilibria quickly becomes\ninfeasible. Here, we extend the theoretical underpinnings of PSRO by\nconsidering an alternative solution concept, $\\alpha$-Rank, which is unique\n(thus faces no equilibrium selection issues, unlike Nash) and applies readily\nto general-sum, many-player settings. We establish convergence guarantees in\nseveral games classes, and identify links between Nash equilibria and\n$\\alpha$-Rank. We demonstrate the competitive performance of\n$\\alpha$-Rank-based PSRO against an exact Nash solver-based PSRO in 2-player\nKuhn and Leduc Poker. We then go beyond the reach of prior PSRO applications by\nconsidering 3- to 5-player poker games, yielding instances where $\\alpha$-Rank\nachieves faster convergence than approximate Nash solvers, thus establishing it\nas a favorable general games solver. We also carry out an initial empirical\nvalidation in MuJoCo soccer, illustrating the feasibility of the proposed\napproach in another complex domain.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.12823v2"
    },
    {
        "title": "A perspective on multi-agent communication for information fusion",
        "authors": [
            "Homagni Saha",
            "Vijay Venkataraman",
            "Alberto Speranzon",
            "Soumik Sarkar"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Collaborative decision making in multi-agent systems typically requires a\npredefined communication protocol among agents. Usually, agent-level\nobservations are locally processed and information is exchanged using the\npredefined protocol, enabling the team to perform more efficiently than each\nagent operating in isolation. In this work, we consider the situation where\nagents, with complementary sensing modalities must co-operate to achieve a\ncommon goal/task by learning an efficient communication protocol. We frame the\nproblem within an actor-critic scheme, where the agents learn optimal policies\nin a centralized fashion, while taking action in a distributed manner. We\nprovide an interpretation of the emergent communication between the agents. We\nobserve that the information exchanged is not just an encoding of the raw\nsensor data but is, rather, a specific set of directive actions that depend on\nthe overall task. Simulation results demonstrate the interpretability of the\nlearnt communication in a variety of tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.03743v1"
    },
    {
        "title": "Optimizing Cooperative path-finding: A Scalable Multi-Agent RRT* with\n  Dynamic Potential Fields",
        "authors": [
            "Jinmingwu Jiang",
            "Kaigui Wu",
            "Haiyang Liu",
            "Ren Zhang",
            "Jingxin Liu",
            "Yong He",
            "Xipeng Kou"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Cooperative path-finding in multi-agent systems demands scalable solutions to\nnavigate agents from their origins to destinations without conflict. Despite\nthe breadth of research, scalability remains hampered by increased\ncomputational demands in complex environments. This study introduces the\nmulti-agent RRT* potential field (MA-RRT*PF), an innovative algorithm that\naddresses computational efficiency and path-finding efficacy in dense\nscenarios. MA-RRT*PF integrates a dynamic potential field with a heuristic\nmethod, advancing obstacle avoidance and optimizing the expansion of random\ntrees in congested spaces. The empirical evaluations highlight MA-RRT*PF's\nsignificant superiority over conventional multi-agent RRT* (MA-RRT*) in dense\nenvironments, offering enhanced performance and solution quality without\ncompromising integrity. This work not only contributes a novel approach to the\nfield of cooperative multi-agent path-finding but also offers a new perspective\nfor practical applications in densely populated settings where traditional\nmethods are less effective.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.07840v4"
    },
    {
        "title": "Agent Probing Interaction Policies",
        "authors": [
            "Siddharth Ghiya",
            "Oluwafemi Azeez",
            "Brendan Miller"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Reinforcement learning in a multi agent system is difficult because these\nsystems are inherently non-stationary in nature. In such a case, identifying\nthe type of the opposite agent is crucial and can help us address this\nnon-stationary environment. We have investigated if we can employ some probing\npolicies which help us better identify the type of the other agent in the\nenvironment. We've made a simplifying assumption that the other agent has a\nstationary policy that our probing policy is trying to approximate. Our work\nextends Environmental Probing Interaction Policy framework to handle multi\nagent environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.09535v3"
    },
    {
        "title": "Multi-Objective Multi-Agent Planning for Jointly Discovering and\n  Tracking Mobile Object",
        "authors": [
            "Hoa Van Nguyen",
            "Hamid Rezatofighi",
            "Ba-Ngu Vo",
            "Damith C. Ranasinghe"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We consider the challenging problem of online planning for a team of agents\nto autonomously search and track a time-varying number of mobile objects under\nthe practical constraint of detection range limited onboard sensors. A standard\nPOMDP with a value function that either encourages discovery or accurate\ntracking of mobile objects is inadequate to simultaneously meet the conflicting\ngoals of searching for undiscovered mobile objects whilst keeping track of\ndiscovered objects. The planning problem is further complicated by\nmisdetections or false detections of objects caused by range limited sensors\nand noise inherent to sensor measurements. We formulate a novel multi-objective\nPOMDP based on information theoretic criteria, and an online multi-object\ntracking filter for the problem. Since controlling multi-agent is a well known\ncombinatorial optimization problem, assigning control actions to agents\nnecessitates a greedy algorithm. We prove that our proposed multi-objective\nvalue function is a monotone submodular set function; consequently, the greedy\nalgorithm can achieve a (1-1/e) approximation for maximizing the submodular\nmulti-objective function.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.09807v1"
    },
    {
        "title": "Agent Programming for Industrial Applications: Some Advantages and\n  Drawbacks",
        "authors": [
            "Otávio Arruda Matoso",
            "Luis P. A. Lampert",
            "Jomi Fred Hübner",
            "Mateus Conceição",
            "Sérgio P. Bernardes",
            "Cleber Jorge Amaral",
            "Maicon R. Zatelli",
            "Marcelo L. de Lima"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Autonomous agents are seen as a prominent technology to be applied in\nindustrial scenarios. Classical automation solutions are struggling with\nchallenges related to high dynamism, prompt actuation, heterogeneous entities,\nincluding humans, and decentralised decision-making. Besides promoting\nconcepts, languages, and tools to face such challenges, agents must also\nprovide high reliability. To assess how appropriate and mature are agents for\nindustrial applications, we have investigated its application in two scenarios\nof the gas and oil industry. This paper presents the development of systems and\nthe initial results highlighting the advantages and drawbacks of the agents\napproach when compared with the existing automation solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.05613v1"
    },
    {
        "title": "A Separation-Based Methodology to Consensus Tracking of Switched\n  High-Order Nonlinear Multi-Agent Systems",
        "authors": [
            "Maolong Lv",
            "Wenwu Yu",
            "Jinde Cao",
            "Simone Baldi"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This work investigates a reduced-complexity adaptive methodology to consensus\ntracking for a team of uncertain high-order nonlinear systems with switched\n(possibly asynchronous) dynamics. It is well known that high-order nonlinear\nsystems are intrinsically challenging as feedback linearization and\nbackstepping methods successfully developed for low-order systems fail to work.\nAt the same time, even the adding-one power-integrator methodology, well\nexplored for the single-agent high-order case, presents some complexity issues\nand is unsuited for distributed control. At the core of the proposed\ndistributed methodology is a newly proposed definition for separable functions:\nthis definition allows the formulation of a separation-based lemma to handle\nthe high-order terms with reduced complexity in the control design. Complexity\nis reduced in a twofold sense: the control gain of each virtual control law\ndoes not have to be incorporated in the next virtual control law iteratively,\nthus leading to a simpler expression of the control laws; the order of the\nvirtual control gains increases only proportionally (rather than exponentially)\nwith the order of the systems, dramatically reducing high-gain issues.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.05799v1"
    },
    {
        "title": "Multi-Agent Informational Learning Processes",
        "authors": [
            "J. K. Terry",
            "Nathaniel Grammel"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We introduce a new mathematical model of multi-agent reinforcement learning,\nthe Multi-Agent Informational Learning Processor \"MAILP\" model. The model is\nbased on the notion that agents have policies for a certain amount of\ninformation, models how this information iteratively evolves and propagates\nthrough many agents. This model is very general, and the only meaningful\nassumption made is that learning for individual agents progressively slows over\ntime.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06870v4"
    },
    {
        "title": "Integrating Industrial Artifacts and Agents Through Apache Camel",
        "authors": [
            "Cleber Jorge Amaral",
            "Stephen Cranefield",
            "Jomi Fred Hübner",
            "Mario Lucio Roloff"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  There are many challenges for building up the smart factory, among them to\ndeal with distributed data, high volume of information, and wide diversity of\ndevices and applications. In this sense, Cyber-Physical System (CPS) concept\nemerges to virtualize and integrate factory resources. Based on studies that\nuse Multi-Agent System as the core of a CPS, in this paper, we show that many\nresources of the factories can be modelled following the well-known Agents and\nArtifacts method of integrating agents and their environment. To enhance the\ninteroperability of this system, we use Apache Camel framework, a middleware to\ndefine routes allowing the integration with a wide range of endpoints using\ndifferent protocols. Finally, we present a Camel component for artifacts,\ndesigned in this research, illustrating its use.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.11694v1"
    },
    {
        "title": "An Agent-based Cloud Service Negotiation in Hybrid Cloud Computing",
        "authors": [
            "Saurabh Deochake",
            "Debajyoti Mukhopadhyay"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  With the advent of evolution of cloud computing, large organizations have\nbeen scaling the on-premise IT infrastructure to the cloud. Although this being\na popular practice, it lacks comprehensive efforts to study the aspects of\nautomated negotiation of resources among cloud customers and providers. This\npaper proposes a full-fledged framework for the multi-party, multi-issue\nnegotiation system for cloud resources. It introduces a robust cloud\nmarketplace system to buy and sell cloud resources. The Belief-Desire-Intention\n(BDI) model-based cloud customer and provider agents concurrently negotiate on\nmultiple issues, pursuing a hybrid tactic of time and resource-based dynamic\ndeadline algorithms to generate offers and counter-offers. The cloud\nmarketplace-based system is further augmented with the assignment of behavior\nnorm score and reputation index to the agents to establish trust among them.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.13109v1"
    },
    {
        "title": "The Evolutionary Dynamics of Independent Learning Agents in Population\n  Games",
        "authors": [
            "Shuyue Hu",
            "Chin-Wing Leung",
            "Ho-fung Leung",
            "Harold Soh"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Understanding the evolutionary dynamics of reinforcement learning under\nmulti-agent settings has long remained an open problem. While previous works\nprimarily focus on 2-player games, we consider population games, which model\nthe strategic interactions of a large population comprising small and anonymous\nagents. This paper presents a formal relation between stochastic processes and\nthe dynamics of independent learning agents who reason based on the reward\nsignals. Using a master equation approach, we provide a novel unified framework\nfor characterising population dynamics via a single partial differential\nequation (Theorem 1). Through a case study involving Cross learning agents, we\nillustrate that Theorem 1 allows us to identify qualitatively different\nevolutionary dynamics, to analyse steady states, and to gain insights into the\nexpected behaviour of a population. In addition, we present extensive\nexperimental results validating that Theorem 1 holds for a variety of learning\nmethods and population games.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.16068v1"
    },
    {
        "title": "Multi-agent navigation based on deep reinforcement learning and\n  traditional pathfinding algorithm",
        "authors": [
            "Hongda Qiu"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We develop a new framework for multi-agent collision avoidance problem. The\nframework combined traditional pathfinding algorithm and reinforcement\nlearning. In our approach, the agents learn whether to be navigated or to take\nsimple actions to avoid their partners via a deep neural network trained by\nreinforcement learning at each time step. This framework makes it possible for\nagents to arrive terminal points in abstract new scenarios. In our experiments,\nwe use Unity3D and Tensorflow to build the model and environment for our\nscenarios. We analyze the results and modify the parameters to approach a\nwell-behaved strategy for our agents. Our strategy could be attached in\ndifferent environments under different cases, especially when the scale is\nlarge.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.09134v1"
    },
    {
        "title": "Federated Multi-Agent Actor-Critic Learning for Age Sensitive Mobile\n  Edge Computing",
        "authors": [
            "Zheqi Zhu",
            "Shuo Wan",
            "Pingyi Fan",
            "Khaled B. Letaief"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  As an emerging technique, mobile edge computing (MEC) introduces a new\nprocessing scheme for various distributed communication-computing systems such\nas industrial Internet of Things (IoT), vehicular communication, smart city,\netc. In this work, we mainly focus on the timeliness of the MEC systems where\nthe freshness of the data and computation tasks is significant. Firstly, we\nformulate a kind of age-sensitive MEC models and define the average age of\ninformation (AoI) minimization problems of interests. Then, a novel policy\nbased multi-agent deep reinforcement learning (RL) framework, called\nheterogeneous multi-agent actor critic (H-MAAC), is proposed as a paradigm for\njoint collaboration in the investigated MEC systems, where edge devices and\ncenter controller learn the interactive strategies through their own\nobservations. To improves the system performance, we develop the corresponding\nonline algorithm by introducing an edge federated learning mode into the\nmulti-agent cooperation whose advantages on learning convergence can be\nguaranteed theoretically. To the best of our knowledge, it's the first joint\nMEC collaboration algorithm that combines the edge federated mode with the\nmulti-agent actor-critic reinforcement learning. Furthermore, we evaluate the\nproposed approach and compare it with classical RL based methods. As a result,\nthe proposed framework not only outperforms the baseline on average system age,\nbut also promotes the stability of training process. Besides, the simulation\nresults provide some innovative perspectives for the system design under the\nedge federated collaboration.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.14137v3"
    },
    {
        "title": "HAMMER: Multi-Level Coordination of Reinforcement Learning Agents via\n  Learned Messaging",
        "authors": [
            "Nikunj Gupta",
            "G Srinivasaraghavan",
            "Swarup Kumar Mohalik",
            "Nishant Kumar",
            "Matthew E. Taylor"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Cooperative multi-agent reinforcement learning (MARL) has achieved\nsignificant results, most notably by leveraging the representation-learning\nabilities of deep neural networks. However, large centralized approaches\nquickly become infeasible as the number of agents scale, and fully\ndecentralized approaches can miss important opportunities for information\nsharing and coordination. Furthermore, not all agents are equal -- in some\ncases, individual agents may not even have the ability to send communication to\nother agents or explicitly model other agents. This paper considers the case\nwhere there is a single, powerful, \\emph{central agent} that can observe the\nentire observation space, and there are multiple, low-powered \\emph{local\nagents} that can only receive local observations and are not able to\ncommunicate with each other. The central agent's job is to learn what message\nneeds to be sent to different local agents based on the global observations,\nnot by centrally solving the entire problem and sending action commands, but by\ndetermining what additional information an individual agent should receive so\nthat it can make a better decision. In this work we present our MARL algorithm\n\\algo, describe where it would be most applicable, and implement it in the\ncooperative navigation and multi-agent walker domains. Empirical results show\nthat 1) learned communication does indeed improve system performance, 2)\nresults generalize to heterogeneous local agents, and 3) results generalize to\ndifferent reward structures.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.00824v2"
    },
    {
        "title": "Hybrid Information-driven Multi-agent Reinforcement Learning",
        "authors": [
            "William A. Dawson",
            "Ruben Glatt",
            "Edward Rusu",
            "Braden C. Soper",
            "Ryan A. Goldhahn"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Information theoretic sensor management approaches are an ideal solution to\nstate estimation problems when considering the optimal control of multi-agent\nsystems, however they are too computationally intensive for large state spaces,\nespecially when considering the limited computational resources typical of\nlarge-scale distributed multi-agent systems. Reinforcement learning (RL) is a\npromising alternative which can find approximate solutions to distributed\noptimal control problems that take into account the resource constraints\ninherent in many systems of distributed agents. However, the RL training can be\nprohibitively inefficient, especially in low-information environments where\nagents receive little to no feedback in large portions of the state space. We\npropose a hybrid information-driven multi-agent reinforcement learning (MARL)\napproach that utilizes information theoretic models as heuristics to help the\nagents navigate large sparse state spaces, coupled with information based\nrewards in an RL framework to learn higher-level policies. This paper presents\nour ongoing work towards this objective. Our preliminary findings show that\nsuch an approach can result in a system of agents that are approximately three\norders of magnitude more efficient at exploring a sparse state space than naive\nbaseline metrics. While the work is still in its early stages, it provides a\npromising direction for future research.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01004v1"
    },
    {
        "title": "An Abstraction-based Method to Check Multi-Agent Deep\n  Reinforcement-Learning Behaviors",
        "authors": [
            "Pierre El Mqirmi",
            "Francesco Belardinelli",
            "Borja G. León"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi-agent reinforcement learning (RL) often struggles to ensure the safe\nbehaviours of the learning agents, and therefore it is generally not adapted to\nsafety-critical applications. To address this issue, we present a methodology\nthat combines formal verification with (deep) RL algorithms to guarantee the\nsatisfaction of formally-specified safety constraints both in training and\ntesting. The approach we propose expresses the constraints to verify in\nProbabilistic Computation Tree Logic (PCTL) and builds an abstract\nrepresentation of the system to reduce the complexity of the verification step.\nThis abstract model allows for model checking techniques to identify a set of\nabstract policies that meet the safety constraints expressed in PCTL. Then, the\nagents' behaviours are restricted according to these safe abstract policies. We\nprovide formal guarantees that by using this method, the actions of the agents\nalways meet the safety constraints, and provide a procedure to generate an\nabstract model automatically. We empirically evaluate and show the\neffectiveness of our method in a multi-agent environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01434v2"
    },
    {
        "title": "Approximately Solving Mean Field Games via Entropy-Regularized Deep\n  Reinforcement Learning",
        "authors": [
            "Kai Cui",
            "Heinz Koeppl"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The recent mean field game (MFG) formalism facilitates otherwise intractable\ncomputation of approximate Nash equilibria in many-agent settings. In this\npaper, we consider discrete-time finite MFGs subject to finite-horizon\nobjectives. We show that all discrete-time finite MFGs with non-constant fixed\npoint operators fail to be contractive as typically assumed in existing MFG\nliterature, barring convergence via fixed point iteration. Instead, we\nincorporate entropy-regularization and Boltzmann policies into the fixed point\niteration. As a result, we obtain provable convergence to approximate fixed\npoints where existing methods fail, and reach the original goal of approximate\nNash equilibria. All proposed methods are evaluated with respect to their\nexploitability, on both instructive examples with tractable exact solutions and\nhigh-dimensional problems where exact methods become intractable. In\nhigh-dimensional scenarios, we apply established deep reinforcement learning\nmethods and empirically combine fictitious play with our approximations.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.01585v2"
    },
    {
        "title": "Massive Self-Assembly in Grid Environments",
        "authors": [
            "Wenjie Chu",
            "Wei Zhang",
            "Haiyan Zhao",
            "Zhi Jin",
            "Hong Mei"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Self-assembly plays an essential role in many natural processes, involving\nthe formation and evolution of living or non-living structures, and shows\npotential applications in many emerging domains. In existing research and\npractice, there still lacks an ideal self-assembly mechanism that manifests\nefficiency, scalability, and stability at the same time. Inspired by phototaxis\nobserved in nature, we propose a computational approach for massive\nself-assembly of connected shapes in grid environments. The key component of\nthis approach is an artificial light field superimposed on a grid environment,\nwhich is determined by the positions of all agents and at the same time drives\nall agents to change their positions, forming a dynamic mutual feedback\nprocess. This work advances the understanding and potential applications of\nself-assembly.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.05037v2"
    },
    {
        "title": "Common Information Belief based Dynamic Programs for Stochastic Zero-sum\n  Games with Competing Teams",
        "authors": [
            "Dhruva Kartik",
            "Ashutosh Nayyar",
            "Urbashi Mitra"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Decentralized team problems where players have asymmetric information about\nthe state of the underlying stochastic system have been actively studied, but\n\\emph{games} between such teams are less understood. We consider a general\nmodel of zero-sum stochastic games between two competing teams. This model\nsubsumes many previously considered team and zero-sum game models. For this\ngeneral model, we provide bounds on the upper (min-max) and lower (max-min)\nvalues of the game. Furthermore, if the upper and lower values of the game are\nidentical (i.e., if the game has a \\emph{value}), our bounds coincide with the\nvalue of the game. Our bounds are obtained using two dynamic programs based on\na sufficient statistic known as the common information belief (CIB). We also\nidentify certain information structures in which only the minimizing team\ncontrols the evolution of the CIB. In these cases, we show that one of our CIB\nbased dynamic programs can be used to find the min-max strategy (in addition to\nthe min-max value). We propose an approximate dynamic programming approach for\ncomputing the values (and the strategy when applicable) and illustrate our\nresults with the help of an example.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.05838v2"
    },
    {
        "title": "Distributed Fair Scheduling for Information Exchange in Multi-Agent\n  Systems",
        "authors": [
            "Majid Raeis",
            "S. Jamaloddin Golestani"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Information exchange is a crucial component of many real-world multi-agent\nsystems. However, the communication between the agents involves two major\nchallenges: the limited bandwidth, and the shared communication medium between\nthe agents, which restricts the number of agents that can simultaneously\nexchange information. While both of these issues need to be addressed in\npractice, the impact of the latter problem on the performance of the\nmulti-agent systems has often been neglected. This becomes even more important\nwhen the agents' information or observations have different importance, in\nwhich case the agents require different priorities for accessing the medium and\nsharing their information. Representing the agents' priorities by fairness\nweights and normalizing each agent's share by the assigned fairness weight, the\ngoal can be expressed as equalizing the agents' normalized shares of the\ncommunication medium. To achieve this goal, we adopt a queueing theoretic\napproach and propose a distributed fair scheduling algorithm for providing\nweighted fairness in single-hop networks. Our proposed algorithm guarantees an\nupper-bound on the normalized share disparity among any pair of agents. This\ncan particularly improve the short-term fairness, which is important in\nreal-time applications. Moreover, our scheduling algorithm adjusts itself\ndynamically to achieve a high throughput at the same time. The simulation\nresults validate our claims and comparisons with the existing methods show our\nalgorithm's superiority in providing short-term fairness, while achieving a\nhigh throughput.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.08814v1"
    },
    {
        "title": "PolicySpace2: modeling markets and endogenous public policies",
        "authors": [
            "Bernardo Alves Furtado"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Policymakers decide on alternative policies facing restricted budgets and\nuncertain, ever-changing future. Designing public policies is further difficult\ndue to the need to decide on priorities and handle effects across policies.\nHousing policies, specifically, involve heterogeneous characteristics of\nproperties themselves and the intricacy of housing markets and the spatial\ncontext of cities. We propose PolicySpace2 (PS2) as an adapted and extended\nversion of the open source PolicySpace agent-based model. PS2 is a computer\nsimulation that relies on empirically detailed spatial data to model real\nestate, along with labor, credit, and goods and services markets. Interaction\namong workers, firms, a bank, households and municipalities follow the\nliterature benchmarks to integrate economic, spatial and transport scholarship.\nPS2 is applied to a comparison among three competing public policies aimed at\nreducing inequality and alleviating poverty: (a) house acquisition by the\ngovernment and distribution to lower income households, (b) rental vouchers,\nand (c) monetary aid. Within the model context, the monetary aid, that is,\nsmaller amounts of help for a larger number of households, makes the economy\nperform better in terms of production, consumption, reduction of inequality,\nand maintenance of financial duties. PS2 as such is also a framework that may\nbe further adapted to a number of related research questions.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.11929v4"
    },
    {
        "title": "B-ETS: A Trusted Blockchain-based Emissions Trading System for\n  Vehicle-to-Vehicle Networks",
        "authors": [
            "Lam Duc Nguyen",
            "Amari N. Lewis",
            "Israel Leyva-Mayorga",
            "Amelia Regan",
            "Petar Popovski"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Urban areas are negatively impacted by Carbon Dioxide (CO2 ) and Nitrogen\nOxide (NOx) emissions. In order to achieve a cost-effective reduction of\ngreenhouse gas emissions and to combat climate change, the European Union (EU)\nintroduced an Emissions Trading System (ETS) where organizations can buy or\nreceive emission allowances as needed. The current ETS is a centralized one,\nconsisting of a set of complex rules. It is currently administered at the\norganizational level and is used for fixed-point sources of pollution such as\nfactories, power plants, and refineries. However, the current ETS cannot\nefficiently cope with vehicle mobility, even though vehicles are one of the\nprimary sources of CO2 and NOx emissions. In this study, we propose a new\ndistributed Blockchain-based emissions allowance trading system called B-ETS.\nThis system enables transparent and trustworthy data exchange as well as\ntrading of allowances among vehicles, relying on vehicle-to-vehicle\ncommunication. In addition, we introduce an economic incentive-based mechanism\nthat appeals to individual drivers and leads them to modify their driving\nbehavior in order to reduce emissions. The efficiency of the proposed system is\nstudied through extensive simulations, showing how increased vehicle\nconnectivity can lead to a reduction of the emissions generated from those\nvehicles. We demonstrate that our method can be used for full life-cycle\nmonitoring and fuel economy reporting. This leads us to conjecture that the\nproposed system could lead to important behavioral changes among the drivers\n",
        "pdf_link": "http://arxiv.org/pdf/2102.13477v2"
    },
    {
        "title": "Time Matters: Exploring the Effects of Urgency and Reaction Speed in\n  Automated Traders",
        "authors": [
            "Henry Hanifan",
            "Ben Watson",
            "John Cartlidge",
            "Dave Cliff"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We consider issues of time in automated trading strategies in simulated\nfinancial markets containing a single exchange with public limit order book and\ncontinuous double auction matching. In particular, we explore two effects: (i)\nreaction speed - the time taken for trading strategies to calculate a response\nto market events; and (ii) trading urgency - the sensitivity of trading\nstrategies to approaching deadlines. Much of the literature on trading agents\nfocuses on optimising pricing strategies only and ignores the effects of time,\nwhile real-world markets continue to experience a race to zero latency, as\nautomated trading systems compete to quickly access information and act in the\nmarket ahead of others. We demonstrate that modelling reaction speed can\nsignificantly alter previously published results, with simple strategies such\nas SHVR outperforming more complex adaptive algorithms such as AA. We also show\nthat adding a pace parameter to ZIP traders (ZIP-Pace, or ZIPP) can create a\nsense of urgency that significantly improves profitability.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.00600v1"
    },
    {
        "title": "A Review & Framework for Modeling Complex Engineered System Development\n  Processes",
        "authors": [
            "John Meluso",
            "Jesse Austin-Breneman",
            "James P. Bagrow",
            "Laurent Hébert-Dufresne"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Developing complex engineered systems (CES) poses significant challenges for\nengineers, managers, designers, and businesspeople alike due to the inherent\ncomplexity of the systems and contexts involved. Furthermore, experts have\nexpressed great interest in filling the gap in theory about how CES develop.\nThis article begins to address that gap in two ways. First, it reviews the\nnumerous definitions of CES along with existing theory and methods on CES\ndevelopment processes. Then, it proposes the ComplEx System Integrated\nUtilities Model (CESIUM), a novel framework for exploring how numerous system\nand development process characteristics may affect the performance of CES.\nCESIUM creates simulated representations of a system architecture, the\ncorresponding engineering organization, and the new product development process\nthrough which the organization designs the system. It does so by representing\nthe system as a network of interdependent artifacts designed by agents. Agents\niteratively design their artifacts through optimization and share information\nwith other agents, thereby advancing the CES toward a solution. This paper\ndescribes the model, conducts a sensitivity analysis, provides validation, and\nsuggests directions for future study.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.12820v2"
    },
    {
        "title": "Competing Adaptive Networks",
        "authors": [
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Adaptive networks have the capability to pursue solutions of global\nstochastic optimization problems by relying only on local interactions within\nneighborhoods. The diffusion of information through repeated interactions\nallows for globally optimal behavior, without the need for central\ncoordination. Most existing strategies are developed for cooperative learning\nsettings, where the objective of the network is common to all agents. We\nconsider in this work a team setting, where a subset of the agents form a team\nwith a common goal while competing with the remainder of the network. We\ndevelop an algorithm for decentralized competition among teams of adaptive\nagents, analyze its dynamics and present an application in the decentralized\ntraining of generative adversarial neural networks.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.15664v1"
    },
    {
        "title": "Cost Inference for Feedback Dynamic Games from Noisy Partial State\n  Observations and Incomplete Trajectories",
        "authors": [
            "Jingqi Li",
            "Chih-Yuan Chiu",
            "Lasse Peters",
            "Somayeh Sojoudi",
            "Claire Tomlin",
            "David Fridovich-Keil"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In multi-agent dynamic games, the Nash equilibrium state trajectory of each\nagent is determined by its cost function and the information pattern of the\ngame. However, the cost and trajectory of each agent may be unavailable to the\nother agents. Prior work on using partial observations to infer the costs in\ndynamic games assumes an open-loop information pattern. In this work, we\ndemonstrate that the feedback Nash equilibrium concept is more expressive and\nencodes more complex behavior. It is desirable to develop specific tools for\ninferring players' objectives in feedback games. Therefore, we consider the\ndynamic game cost inference problem under the feedback information pattern,\nusing only partial state observations and incomplete trajectory data. To this\nend, we first propose an inverse feedback game loss function, whose minimizer\nyields a feedback Nash equilibrium state trajectory closest to the observation\ndata. We characterize the landscape and differentiability of the loss function.\nGiven the difficulty of obtaining the exact gradient, our main contribution is\nan efficient gradient approximator, which enables a novel inverse feedback game\nsolver that minimizes the loss using first-order optimization. In thorough\nempirical evaluations, we demonstrate that our algorithm converges reliably and\nhas better robustness and generalization performance than the open-loop\nbaseline method when the observation data reflects a group of players acting in\na feedback Nash game.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01398v1"
    },
    {
        "title": "Scalable Communication for Multi-Agent Reinforcement Learning via\n  Transformer-Based Email Mechanism",
        "authors": [
            "Xudong Guo",
            "Daming Shi",
            "Wenhui Fan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Communication can impressively improve cooperation in multi-agent\nreinforcement learning (MARL), especially for partially-observed tasks.\nHowever, existing works either broadcast the messages leading to information\nredundancy, or learn targeted communication by modeling all the other agents as\ntargets, which is not scalable when the number of agents varies. In this work,\nto tackle the scalability problem of MARL communication for partially-observed\ntasks, we propose a novel framework Transformer-based Email Mechanism (TEM).\nThe agents adopt local communication to send messages only to the ones that can\nbe observed without modeling all the agents. Inspired by human cooperation with\nemail forwarding, we design message chains to forward information to cooperate\nwith the agents outside the observation range. We introduce Transformer to\nencode and decode the message chain to choose the next receiver selectively.\nEmpirically, TEM outperforms the baselines on multiple cooperative MARL\nbenchmarks. When the number of agents varies, TEM maintains superior\nperformance without further training.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01919v2"
    },
    {
        "title": "Measuring a Priori Voting Power -- Taking Delegations Seriously",
        "authors": [
            "Rachael Colley",
            "Théo Delemazure",
            "Hugo Gilbert"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We introduce new power indices to measure the a priori voting power of voters\nin liquid democracy elections where an underlying network restricts\ndelegations. We argue that our power indices are natural extensions of the\nstandard Penrose-Banzhaf index in simple voting games. We show that computing\nthe criticality of a voter is #P-hard even when voting weights are\npolynomially-bounded in the size of the instance. However, for specific\nsettings, such as when the underlying network is a bipartite or complete graph,\nrecursive formulas can compute these indices for weighted voting games in\npseudo-polynomial time. We highlight their theoretical properties and provide\nnumerical results to illustrate how restricting the possible delegations can\nalter voters' voting power.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.02462v4"
    },
    {
        "title": "An Efficient Approach to the Online Multi-Agent Path Finding Problem by\n  Using Sustainable Information",
        "authors": [
            "Mingkai Tang",
            "Boyi Liu",
            "Yuanhang Li",
            "Hongji Liu",
            "Ming Liu",
            "Lujia Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent path finding (MAPF) is the problem of moving agents to the goal\nvertex without collision. In the online MAPF problem, new agents may be added\nto the environment at any time, and the current agents have no information\nabout future agents. The inability of existing online methods to reuse previous\nplanning contexts results in redundant computation and reduces algorithm\nefficiency. Hence, we propose a three-level approach to solve online MAPF\nutilizing sustainable information, which can decrease its redundant\ncalculations. The high-level solver, the Sustainable Replan algorithm (SR),\nmanages the planning context and simulates the environment. The middle-level\nsolver, the Sustainable Conflict-Based Search algorithm (SCBS), builds a\nconflict tree and maintains the planning context. The low-level solver, the\nSustainable Reverse Safe Interval Path Planning algorithm (SRSIPP), is an\nefficient single-agent solver that uses previous planning context to reduce\nduplicate calculations. Experiments show that our proposed method has\nsignificant improvement in terms of computational efficiency. In one of the\ntest scenarios, our algorithm can be 1.48 times faster than SOTA on average\nunder different agent number settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.04446v1"
    },
    {
        "title": "Investigating the Impact of Direct Punishment on the Emergence of\n  Cooperation in Multi-Agent Reinforcement Learning Systems",
        "authors": [
            "Nayana Dasgupta",
            "Mirco Musolesi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Solving the problem of cooperation is fundamentally important for the\ncreation and maintenance of functional societies. Problems of cooperation are\nomnipresent within human society, with examples ranging from navigating busy\nroad junctions to negotiating treaties. As the use of AI becomes more pervasive\nthroughout society, the need for socially intelligent agents capable of\nnavigating these complex cooperative dilemmas is becoming increasingly evident.\nDirect punishment is a ubiquitous social mechanism that has been shown to\nfoster the emergence of cooperation in both humans and non-humans. In the\nnatural world, direct punishment is often strongly coupled with partner\nselection and reputation and used in conjunction with third-party punishment.\nThe interactions between these mechanisms could potentially enhance the\nemergence of cooperation within populations. However, no previous work has\nevaluated the learning dynamics and outcomes emerging from Multi-Agent\nReinforcement Learning (MARL) populations that combine these mechanisms. This\npaper addresses this gap. It presents a comprehensive analysis and evaluation\nof the behaviors and learning dynamics associated with direct punishment,\nthird-party punishment, partner selection, and reputation. Finally, we discuss\nthe implications of using these mechanisms on the design of cooperative AI\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.08278v3"
    },
    {
        "title": "Modeling Moral Choices in Social Dilemmas with Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Elizaveta Tennant",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Practical uses of Artificial Intelligence (AI) in the real world have\ndemonstrated the importance of embedding moral choices into intelligent agents.\nThey have also highlighted that defining top-down ethical constraints on AI\naccording to any one type of morality is extremely challenging and can pose\nrisks. A bottom-up learning approach may be more appropriate for studying and\ndeveloping ethical behavior in AI agents. In particular, we believe that an\ninteresting and insightful starting point is the analysis of emergent behavior\nof Reinforcement Learning (RL) agents that act according to a predefined set of\nmoral rewards in social dilemmas.\n  In this work, we present a systematic analysis of the choices made by\nintrinsically-motivated RL agents whose rewards are based on moral theories. We\naim to design reward structures that are simplified yet representative of a set\nof key ethical systems. Therefore, we first define moral reward functions that\ndistinguish between consequence- and norm-based agents, between morality based\non societal norms or internal virtues, and between single- and mixed-virtue\n(e.g., multi-objective) methodologies. Then, we evaluate our approach by\nmodeling repeated dyadic interactions between learning moral agents in three\niterated social dilemma games (Prisoner's Dilemma, Volunteer's Dilemma and Stag\nHunt). We analyze the impact of different types of morality on the emergence of\ncooperation, defection or exploitation, and the corresponding social outcomes.\nFinally, we discuss the implications of these findings for the development of\nmoral agents in artificial and mixed human-AI societies.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.08491v3"
    },
    {
        "title": "Differential Privacy in Cooperative Multiagent Planning",
        "authors": [
            "Bo Chen",
            "Calvin Hawkins",
            "Mustafa O. Karabag",
            "Cyrus Neary",
            "Matthew Hale",
            "Ufuk Topcu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Privacy-aware multiagent systems must protect agents' sensitive data while\nsimultaneously ensuring that agents accomplish their shared objectives. Towards\nthis goal, we propose a framework to privatize inter-agent communications in\ncooperative multiagent decision-making problems. We study sequential\ndecision-making problems formulated as cooperative Markov games with\nreach-avoid objectives. We apply a differential privacy mechanism to privatize\nagents' communicated symbolic state trajectories, and then we analyze tradeoffs\nbetween the strength of privacy and the team's performance. For a given level\nof privacy, this tradeoff is shown to depend critically upon the total\ncorrelation among agents' state-action processes. We synthesize policies that\nare robust to privacy by reducing the value of the total correlation. Numerical\nexperiments demonstrate that the team's performance under these policies\ndecreases by only 3 percent when comparing private versus non-private\nimplementations of communication. By contrast, the team's performance decreases\nby roughly 86 percent when using baseline policies that ignore total\ncorrelation and only optimize team performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.08811v1"
    },
    {
        "title": "Pedestrian Route Choice by Iterated Equilibrium Search",
        "authors": [
            "Tobias Kretz",
            "Karsten Lehmann",
            "Ingmar Hofsäß"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  In vehicular traffic planning it is a long standing problem how to assign\ndemand such on the available model of a road network that an equilibrium with\nregard to travel time or generalized costs is realized. For pedestrian traffic\nthis question can be asked as well. However, as the infrastructure of\npedestrian dynamics is not a network (a graph), but two-dimensional, there is\nin principle an infinitely large set of routes. As a consequence none of the\niterating assignment methods developed for road traffic can be applied for\npedestrians. In this contribution a method to overcome this problem is briefly\nsummarized and applied with an example geometry which as a result is enhanced\nwith routes with intermediate destination areas of certain shape. The enhanced\ngeometry is used in some exemplary assignment calculations.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1686v1"
    },
    {
        "title": "Multi-agents adaptive estimation and coverage control using Gaussian\n  regression",
        "authors": [
            "Andrea Carron",
            "Marco Todescato",
            "Ruggero Carli",
            "Luca Schenato",
            "Gianluigi Pillonetto"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We consider a scenario where the aim of a group of agents is to perform the\noptimal coverage of a region according to a sensory function. In particular,\ncentroidal Voronoi partitions have to be computed. The difficulty of the task\nis that the sensory function is unknown and has to be reconstructed on line\nfrom noisy measurements. Hence, estimation and coverage needs to be performed\nat the same time. We cast the problem in a Bayesian regression framework, where\nthe sensory function is seen as a Gaussian random field. Then, we design a set\nof control inputs which try to well balance coverage and estimation, also\ndiscussing convergence properties of the algorithm. Numerical experiments show\nthe effectivness of the new approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.5807v1"
    },
    {
        "title": "Success and Failure of Adaptation-Diffusion Algorithms for Consensus in\n  Multi-Agent Networks",
        "authors": [
            "Gemma Morral",
            "Pascal Bianchi",
            "Gersende Fort"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper investigates the problem of distributed stochastic approximation\nin multi-agent systems. The algorithm under study consists of two steps: a\nlocal stochastic approximation step and a diffusion step which drives the\nnetwork to a consensus. The diffusion step uses row-stochastic matrices to\nweight the network exchanges. As opposed to previous works, exchange matrices\nare not supposed to be doubly stochastic, and may also depend on the past\nestimate.\n  We prove that non-doubly stochastic matrices generally influence the limit\npoints of the algorithm. Nevertheless, the limit points are not affected by the\nchoice of the matrices provided that the latter are doubly-stochastic in\nexpectation. This conclusion legitimates the use of broadcast-like diffusion\nprotocols, which are easier to implement. Next, by means of a central limit\ntheorem, we prove that doubly stochastic protocols perform asymptotically as\nwell as centralized algorithms and we quantify the degradation caused by the\nuse of non doubly stochastic matrices. Throughout the paper, a special emphasis\nis put on the special case of distributed non-convex optimization as an\nillustration of our results.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.6956v1"
    },
    {
        "title": "Communication-Free Multi-Agent Control under Local Temporal Tasks and\n  Relative-Distance Constraints",
        "authors": [
            "Meng Guo",
            "Jana Tumova",
            "Dimos V. Dimarogonas"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  We propose a distributed control and coordination strategy for multi-agent\nsystems where each agent has a local task specified as a Linear Temporal Logic\n(LTL) formula and at the same time is subject to relative-distance constraints\nwith its neighboring agents. The local tasks capture the temporal requirements\non individual agents' behaviors, while the relative-distance constraints impose\nrequirements on the collective motion of the whole team. The proposed solution\nrelies only on relative-state measurements among the neighboring agents without\nthe need for explicit information exchange. It is guaranteed that the local\ntasks given as syntactically co-safe or general LTL formulas are fulfilled and\nthe relative-distance constraints are satisfied at all time. The approach is\ndemonstrated with computer simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.8673v1"
    },
    {
        "title": "Emergence of Consensus in a Multi-Robot Network: from Abstract Models to\n  Empirical Validation",
        "authors": [
            "Vito Trianni",
            "Daniele De Simone",
            "Andreagiovanni Reina",
            "Andrea Baronchelli"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Consensus dynamics in decentralised multiagent systems are subject to intense\nstudies, and several different models have been proposed and analysed. Among\nthese, the naming game stands out for its simplicity and applicability to a\nwide range of phenomena and applications, from semiotics to engineering.\nDespite the wide range of studies available, the implementation of theoretical\nmodels in real distributed systems is not always straightforward, as the\nphysical platform imposes several constraints that may have a bearing on the\nconsensus dynamics. In this paper, we investigate the effects of an\nimplementation of the naming game for the kilobot robotic platform, in which we\nconsider concurrent execution of games and physical interferences. Consensus\ndynamics are analysed in the light of the continuously evolving communication\nnetwork created by the robots, highlighting how the different regimes crucially\ndepend on the robot density and on their ability to spread widely in the\nexperimental arena. We find that physical interferences reduce the benefits\nresulting from robot mobility in terms of consensus time, but also result in\nlower cognitive load for individual agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.04952v1"
    },
    {
        "title": "Distributed Detection over Adaptive Networks: Refined Asymptotics and\n  the Role of Connectivity",
        "authors": [
            "Vincenzo Matta",
            "Paolo Braca",
            "Stefano Marano",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We consider distributed detection problems over adaptive networks, where\ndispersed agents learn continually from streaming data by means of local\ninteractions. The simultaneous requirements of adaptation and cooperation are\nachieved by employing diffusion algorithms with constant step-size {\\mu}. In\n[1], [2] some main features of adaptive distributed detection were revealed. By\nresorting to large deviations analysis, it was established that the Type-I and\nType-II error probabilities of all agents vanish exponentially as functions of\n1/{\\mu}, and that all agents share the same Type-I and Type-II error exponents.\nHowever, numerical evidences presented in [1], [2] showed that the theory of\nlarge deviations does not capture the fundamental impact of network\nconnectivity on performance, and that additional tools and efforts are required\nto obtain accurate predictions for the error probabilities. This work addresses\nthese open issues and extends the results of [1], [2] in several directions. By\nconducting a refined asymptotic analysis based on the mathematical framework of\nexact asymptotics, we arrive at a revealing and powerful understanding of the\nuniversal behavior of distributed detection over adaptive networks: as\nfunctions of 1/{\\mu}, the error (log-)probability curves corresponding to\ndifferent agents stay nearly-parallel to each other (as already discovered in\n[1], [2]), however, these curves are ordered following a criterion reflecting\nthe degree of connectivity of each agent. Depending on the combination weights,\nthe more connected an agent is, the lower its error probability curve will be.\nInteresting and somehow unexpected behaviors emerge, in terms of the interplay\nbetween the network topology, the combination weights, and the inference\nperformance. The lesson learned is that connectivity matters.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.07011v1"
    },
    {
        "title": "Approaches to Modeling Insurgency",
        "authors": [
            "Alexander Kott",
            "Bruce Skarin"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  This paper begins with an introduction to qualitative theories and models of\ninsurgency, quantitative measures of insurgency, influence diagrams, system\ndynamics models of insurgency, agent based molding of insurgency,\nhuman-in-the-loop wargaming of insurgency, and statistical models of\ninsurgency. The paper then presents a detailed case study of an agent-based\nmodel that focuses on the Troubles in Northern Ireland starting in 1968. The\nmodel is agent-based and uses a modeling tool called Simulation of Cultural\nIdentities for Prediction of Reactions (SCIPR). The objective in this modeling\neffort was to predict trends in the degree of population's support to parties\nin this conflict. The case studies describes in detail the agents, their\nactions, model initialization and simulation process, and the results of the\nsimulation compared to actual historical results of elections.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.01787v1"
    },
    {
        "title": "Betting and Belief: Prediction Markets and Attribution of Climate Change",
        "authors": [
            "John J. Nay",
            "Martin Van der Linden",
            "Jonathan M. Gilligan"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Despite much scientific evidence, a large fraction of the American public\ndoubts that greenhouse gases are causing global warming. We present a\nsimulation model as a computational test-bed for climate prediction markets.\nTraders adapt their beliefs about future temperatures based on the profits of\nother traders in their social network. We simulate two alternative climate\nfutures, in which global temperatures are primarily driven either by carbon\ndioxide or by solar irradiance. These represent, respectively, the scientific\nconsensus and a hypothesis advanced by prominent skeptics. We conduct\nsensitivity analyses to determine how a variety of factors describing both the\nmarket and the physical climate may affect traders' beliefs about the cause of\nglobal climate change. Market participation causes most traders to converge\nquickly toward believing the \"true\" climate model, suggesting that a climate\nmarket could be useful for building public consensus.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.08961v3"
    },
    {
        "title": "Global network cooperation catalysed by a small prosocial migrant clique",
        "authors": [
            "Steve Miller",
            "Joshua Knowles"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Much research has been carried out to understand the emergence of cooperation\nin simulated social networks of competing individuals. Such research typically\nimplements a population as a single connected network. Here we adopt a more\nrealistic premise; namely that populations consist of multiple networks, whose\nmembers migrate from one to another. Specifically, we isolate the key elements\nof the scenario where a minority of members from a cooperative network migrate\nto a network populated by defectors. Using the public goods game to model\ngroup-wise cooperation, we find that under certain circumstances, the concerted\nactions of a trivial number of such migrants will catalyse widespread\nbehavioural change throughout an entire population. Such results support a\nwider argument: that the general presence of some form of disruption\ncontributes to the emergence of cooperation in social networks, and\nconsequently that simpler models may encode a determinism that precludes the\nemergence of cooperation.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.02652v1"
    },
    {
        "title": "ViewpointS: towards a Collective Brain",
        "authors": [
            "Philippe Lemoisson",
            "Stefano A. Cerri"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Tracing knowledge acquisition and linking learning events to interaction\nbetween peers is a major challenge of our times. We have conceived, designed\nand evaluated a new paradigm for constructing and using collective knowledge by\nWeb interactions that we called ViewpointS. By exploiting the similarity with\nEdelman's Theory of Neuronal Group Selection (TNGS), we conjecture that it may\nbe metaphorically considered a Collective Brain, especially effective in the\ncase of trans-disciplinary representations. Far from being without doubts, in\nthe paper we present the reasons (and the limits) of our proposal that aims to\nbecome a useful integrating tool for future quantitative explorations of\nindividual as well as collective learning at different degrees of granu-larity.\nWe are therefore challenging each of the current approaches: the logical one in\nthe semantic Web, the statistical one in mining and deep learning, the social\none in recommender systems based on authority and trust; not in each of their\nown preferred field of operation, rather in their integration weaknesses far\nfrom the holistic and dynamic behavior of the human brain.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.00564v1"
    },
    {
        "title": "Negative Update Intervals in Deep Multi-Agent Reinforcement Learning",
        "authors": [
            "Gregory Palmer",
            "Rahul Savani",
            "Karl Tuyls"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  In Multi-Agent Reinforcement Learning (MA-RL), independent cooperative\nlearners must overcome a number of pathologies to learn optimal joint policies.\nAddressing one pathology often leaves approaches vulnerable towards others. For\ninstance, hysteretic Q-learning addresses miscoordination while leaving agents\nvulnerable towards misleading stochastic rewards. Other methods, such as\nleniency, have proven more robust when dealing with multiple pathologies\nsimultaneously. However, leniency has predominately been studied within the\ncontext of strategic form games (bimatrix games) and fully observable Markov\ngames consisting of a small number of probabilistic state transitions. This\nraises the question of whether these findings scale to more complex domains.\nFor this purpose we implement a temporally extend version of the Climb Game,\nwithin which agents must overcome multiple pathologies simultaneously,\nincluding relative overgeneralisation, stochasticity, the alter-exploration and\nmoving target problems, while learning from a large observation space. We find\nthat existing lenient and hysteretic approaches fail to consistently learn near\noptimal joint-policies in this environment. To address these pathologies we\nintroduce Negative Update Intervals-DDQN (NUI-DDQN), a Deep MA-RL algorithm\nwhich discards episodes yielding cumulative rewards outside the range of\nexpanding intervals. NUI-DDQN consistently gravitates towards optimal\njoint-policies in our environment, overcoming the outlined pathologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.05096v3"
    },
    {
        "title": "Systems of bounded rational agents with information-theoretic\n  constraints",
        "authors": [
            "Sebastian Gottwald",
            "Daniel A. Braun"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Specialization and hierarchical organization are important features of\nefficient collaboration in economical, artificial, and biological systems.\nHere, we investigate the hypothesis that both features can be explained by the\nfact that each entity of such a system is limited in a certain way. We propose\nan information-theoretic approach based on a Free Energy principle, in order to\ncomputationally analyze systems of bounded rational agents that deal with such\nlimitations optimally. We find that specialization allows to focus on fewer\ntasks, thus leading to a more efficient execution, but in turn requires\ncoordination in hierarchical structures of specialized experts and coordinating\nunits. Our results suggest that hierarchical architectures of specialized units\nat lower levels that are coordinated by units at higher levels are optimal,\ngiven that each unit's information-processing capability is limited and\nconforms to constraints on complexity costs.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.05897v1"
    },
    {
        "title": "Bayesian Action Decoder for Deep Multi-Agent Reinforcement Learning",
        "authors": [
            "Jakob N. Foerster",
            "Francis Song",
            "Edward Hughes",
            "Neil Burch",
            "Iain Dunning",
            "Shimon Whiteson",
            "Matthew Botvinick",
            "Michael Bowling"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  When observing the actions of others, humans make inferences about why they\nacted as they did, and what this implies about the world; humans also use the\nfact that their actions will be interpreted in this manner, allowing them to\nact informatively and thereby communicate efficiently with others. Although\nlearning algorithms have recently achieved superhuman performance in a number\nof two-player, zero-sum games, scalable multi-agent reinforcement learning\nalgorithms that can discover effective strategies and conventions in complex,\npartially observable settings have proven elusive. We present the Bayesian\naction decoder (BAD), a new multi-agent learning method that uses an\napproximate Bayesian update to obtain a public belief that conditions on the\nactions taken by all agents in the environment. BAD introduces a new Markov\ndecision process, the public belief MDP, in which the action space consists of\nall deterministic partial policies, and exploits the fact that an agent acting\nonly on this public belief state can still learn to use its private information\nif the action space is augmented to be over all partial policies mapping\nprivate information into environment actions. The Bayesian update is closely\nrelated to the theory of mind reasoning that humans carry out when observing\nothers' actions. We first validate BAD on a proof-of-principle two-step matrix\ngame, where it outperforms policy gradient methods; we then evaluate BAD on the\nchallenging, cooperative partial-information card game Hanabi, where, in the\ntwo-player setting, it surpasses all previously published learning and\nhand-coded approaches, establishing a new state of the art.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01458v3"
    },
    {
        "title": "Deep Reinforcement Learning for Green Security Games with Real-Time\n  Information",
        "authors": [
            "Yufei Wang",
            "Zheyuan Ryan Shi",
            "Lantao Yu",
            "Yi Wu",
            "Rohit Singh",
            "Lucas Joppa",
            "Fei Fang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Green Security Games (GSGs) have been proposed and applied to optimize\npatrols conducted by law enforcement agencies in green security domains such as\ncombating poaching, illegal logging and overfishing. However, real-time\ninformation such as footprints and agents' subsequent actions upon receiving\nthe information, e.g., rangers following the footprints to chase the poacher,\nhave been neglected in previous work. To fill the gap, we first propose a new\ngame model GSG-I which augments GSGs with sequential movement and the vital\nelement of real-time information. Second, we design a novel deep reinforcement\nlearning-based algorithm, DeDOL, to compute a patrolling strategy that adapts\nto the real-time information against a best-responding attacker. DeDOL is built\nupon the double oracle framework and the policy-space response oracle, solving\na restricted game and iteratively adding best response strategies to it through\ntraining deep Q-networks. Exploring the game structure, DeDOL uses\ndomain-specific heuristic strategies as initial strategies and constructs\nseveral local modes for efficient and parallelized training. To our knowledge,\nthis is the first attempt to use Deep Q-Learning for security games.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.02483v1"
    },
    {
        "title": "Distributed Learning of Average Belief Over Networks Using Sequential\n  Observations",
        "authors": [
            "Kaiqing Zhang",
            "Yang Liu",
            "Ji Liu",
            "Mingyan Liu",
            "Tamer Başar"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  This paper addresses the problem of distributed learning of average belief\nwith sequential observations, in which a network of $n>1$ agents aim to reach a\nconsensus on the average value of their beliefs, by exchanging information only\nwith their neighbors. Each agent has sequentially arriving samples of its\nbelief in an online manner. The neighbor relationships among the $n$ agents are\ndescribed by a graph which is possibly time-varying, whose vertices correspond\nto agents and whose edges depict neighbor relationships. Two distributed online\nalgorithms are introduced for undirected and directed graphs, which are both\nshown to converge to the average belief almost surely. Moreover, the sequences\ngenerated by both algorithms are shown to reach consensus with an $O(1/t)$ rate\nwith high probability, where $t$ is the number of iterations. For undirected\ngraphs, the corresponding algorithm is modified for the case with quantized\ncommunication and limited precision of the division operation. It is shown that\nthe modified algorithm causes all $n$ agents to either reach a quantized\nconsensus or enter a small neighborhood around the average of their beliefs.\nNumerical simulations are then provided to corroborate the theoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07799v1"
    },
    {
        "title": "Stable Opponent Shaping in Differentiable Games",
        "authors": [
            "Alistair Letcher",
            "Jakob Foerster",
            "David Balduzzi",
            "Tim Rocktäschel",
            "Shimon Whiteson"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  A growing number of learning methods are actually differentiable games whose\nplayers optimise multiple, interdependent objectives in parallel -- from GANs\nand intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful\napproach to improve learning dynamics in these games, accounting for player\ninfluence on others' updates. Learning with Opponent-Learning Awareness (LOLA)\nis a recent algorithm that exploits this response and leads to cooperation in\nsettings like the Iterated Prisoner's Dilemma. Although experimentally\nsuccessful, we show that LOLA agents can exhibit 'arrogant' behaviour directly\nat odds with convergence. In fact, remarkably few algorithms have theoretical\nguarantees applying across all (n-player, non-convex) games. In this paper we\npresent Stable Opponent Shaping (SOS), a new method that interpolates between\nLOLA and a stable variant named LookAhead. We prove that LookAhead converges\nlocally to equilibria and avoids strict saddles in all differentiable games.\nSOS inherits these essential guarantees, while also shaping the learning of\nopponents and consistently either matching or outperforming LOLA\nexperimentally.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08469v3"
    },
    {
        "title": "Second-Order Agents on Ring Digraphs",
        "authors": [
            "Sergei Parsegov",
            "Pavel Chebotarev"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  The paper addresses the problem of consensus seeking among second-order\nlinear agents interconnected in a specific ring topology. Unlike the existing\nresults in the field dealing with one-directional digraphs arising in various\ncyclic pursuit algorithms or two-directional graphs, we focus on the case where\nsome arcs in a two-directional ring graph are dropped in a regular fashion. The\nderived condition for achieving consensus turns out to be independent of the\nnumber of agents in a network.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.09306v1"
    },
    {
        "title": "Feedback based Mobility Control Algorithm for Maximizing Node Coverage\n  by Drone Base Stations",
        "authors": [
            "Aniq Ur Rahman",
            "Agnivesh Adhikari"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Drone base stations (DBSs) have recently gained wide popularity as a possible\nsolution to provide wireless connectivity in a variety of scenarios, for\nexample, in inaccessible terrains such as connectivity over vast areas of a\nwater body or in rural areas where the physical deployment of base stations is\nnot feasible at the moment, also in the case of terrestrial infrastructure\nfailure where DBSs can be rapidly deployed to re-establish communication\nchannel. In this paper we propose an algorithm for controlling the motion of\nthe DBSs which maximizes the number of DBS to mobile ground node connections.\nThe overlap extent between the drones is limited to reduce the count of\nredundant connections. The overall approach aims at minimizing the number of\ndrones required to be deployed in a given region by maximizing connectivity per\ndrone.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.09414v2"
    },
    {
        "title": "Evoplex: A platform for agent-based modeling on networks",
        "authors": [
            "Marcos Cardinot",
            "Colm O'Riordan",
            "Josephine Griffith",
            "Matjaž Perc"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Agent-based modeling and network science have been used extensively to\nadvance our understanding of emergent collective behavior in systems that are\ncomposed of a large number of simple interacting individuals or agents. With\nthe increasing availability of high computational power in affordable personal\ncomputers, dedicated efforts to develop multi-threaded, scalable and\neasy-to-use software for agent-based simulations are needed more than ever.\nEvoplex meets this need by providing a fast, robust and extensible platform for\ndeveloping agent-based models and multi-agent systems on networks. Each agent\nis represented as a node and interacts with its neighbors, as defined by the\nnetwork structure. Evoplex is ideal for modeling complex systems, for example\nin evolutionary game theory and computational social science. In Evoplex, the\nmodels are not coupled to the execution parameters or the visualization tools,\nand there is a user-friendly graphical interface which makes it easy for all\nusers, ranging from newcomers to experienced, to create, analyze, replicate and\nreproduce the experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.10116v2"
    },
    {
        "title": "Hierarchical Fuzzy Opinion Networks: Top-Down for Social Organizations\n  and Bottom-Up for Election",
        "authors": [
            "Li-Xin Wang"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  A fuzzy opinion is a Gaussian fuzzy set with the center representing the\nopinion and the standard deviation representing the uncertainty about the\nopinion, and a fuzzy opinion network is a connection of a number of fuzzy\nopinions in a structured way. In this paper, we propose: (a) a top-down\nhierarchical fuzzy opinion network to model how the opinion of a top leader is\npenetrated into the members in social organizations, and (b) a bottom-up fuzzy\nopinion network to model how the opinions of a large number of agents are\nagglomerated layer-by-layer into a consensus or a few opinions in the social\nprocesses such as an election. For the top-down hierarchical fuzzy opinion\nnetwork, we prove that the opinions of all the agents converge to the leaders\nopinion, but the uncertainties of the agents in different groups are generally\nconverging to different values. We demonstrate that the speed of convergence is\ngreatly improved by organizing the agents in a hierarchical structure of small\ngroups. For the bottom-up hierarchical fuzzy opinion network, we simulate how a\nwide spectrum of opinions are negotiating and summarizing with each other in a\nlayer-by-layer fashion in some typical situations.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.00441v1"
    },
    {
        "title": "Decentralized Poisson Multi-Bernoulli Filtering for Vehicle Tracking",
        "authors": [
            "Markus Fröhle",
            "Karl Granström",
            "Henk Wymeersch"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  A decentralized Poisson multi-Bernoulli filter is proposed to track multiple\nvehicles using multiple high-resolution sensors. Independent filters estimate\nthe vehicles' presence, state, and shape using a Gaussian process extent model;\na decentralized filter is realized through fusion of the filters posterior\ndensities. An efficient implementation is achieved by parametric state\nrepresentation, utilization of single hypothesis tracks, and fusion of vehicle\ninformation based on a fusion mapping. Numerical results demonstrate the\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.04518v2"
    },
    {
        "title": "Feudal Multi-Agent Hierarchies for Cooperative Reinforcement Learning",
        "authors": [
            "Sanjeevan Ahilan",
            "Peter Dayan"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We investigate how reinforcement learning agents can learn to cooperate.\nDrawing inspiration from human societies, in which successful coordination of\nmany individuals is often facilitated by hierarchical organisation, we\nintroduce Feudal Multi-agent Hierarchies (FMH). In this framework, a 'manager'\nagent, which is tasked with maximising the environmentally-determined reward\nfunction, learns to communicate subgoals to multiple, simultaneously-operating,\n'worker' agents. Workers, which are rewarded for achieving managerial subgoals,\ntake concurrent actions in the world. We outline the structure of FMH and\ndemonstrate its potential for decentralised learning and control. We find that,\ngiven an adequate set of subgoals from which to choose, FMH performs, and\nparticularly scales, substantially better than cooperative approaches that use\na shared reward function.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.08492v1"
    },
    {
        "title": "Directed Formation Control of n Planar Agents with Distance and Area\n  Constraints",
        "authors": [
            "Tairan Liu",
            "Marcio de Queiroz",
            "Pengpeng Zhang",
            "Milad Khaledyan"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In this paper, we take a first step towards generalizing a recently proposed\nmethod for dealing with the problem of convergence to incorrect equilibrium\npoints of distance-based formation controllers. Specifically, we introduce a\ndistance and area-based scheme for the formation control of $n$-agent systems\nin two dimensions using directed graphs and the single-integrator model. We\nshow that under certain conditions on the edge lengths of the triangulated\ndesired formation, the control ensures almost-global convergence to the correct\nformation.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.10564v2"
    },
    {
        "title": "Priority Inheritance with Backtracking for Iterative Multi-agent Path\n  Finding",
        "authors": [
            "Keisuke Okumura",
            "Manao Machida",
            "Xavier Défago",
            "Yasumasa Tamura"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In the Multi-Agent Path Finding (MAPF) problem, a set of agents moving on a\ngraph must reach their own respective destinations without inter-agent\ncollisions. In practical MAPF applications such as navigation in automated\nwarehouses, where occasionally there are hundreds or more agents, MAPF must be\nsolved iteratively online on a lifelong basis. Such scenarios rule out simple\nadaptations of offline compute-intensive optimal approaches; and scalable\nsub-optimal algorithms are hence appealing for such settings. Ideal algorithms\nare scalable, applicable to iterative scenarios, and output plausible solutions\nin predictable computation time.\n  For the aforementioned purpose, this study presents Priority Inheritance with\nBacktracking (PIBT), a novel sub-optimal algorithm to solve MAPF iteratively.\nPIBT relies on an adaptive prioritization scheme to focus on the adjacent\nmovements of multiple agents; hence it can be applied to several domains. We\nprove that, regardless of their number, all agents are guaranteed to reach\ntheir destination within finite time when the environment is a graph such that\nall pairs of adjacent nodes belong to a simple cycle (e.g., biconnected).\nExperimental results covering various scenarios, including a demonstration with\nreal robots, reveal the benefits of the proposed method. Even with hundreds of\nagents, PIBT yields acceptable solutions almost immediately and can solve large\ninstances that other established MAPF methods cannot. In addition, PIBT\noutperforms an existing approach on an iterative scenario of conveying packages\nin an automated warehouse in both runtime and solution quality.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.11282v5"
    },
    {
        "title": "Collaboration of AI Agents via Cooperative Multi-Agent Deep\n  Reinforcement Learning",
        "authors": [
            "Niranjan Balachandar",
            "Justin Dieter",
            "Govardana Sachithanandam Ramachandran"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  There are many AI tasks involving multiple interacting agents where agents\nshould learn to cooperate and collaborate to effectively perform the task. Here\nwe develop and evaluate various multi-agent protocols to train agents to\ncollaborate with teammates in grid soccer. We train and evaluate our\nmulti-agent methods against a team operating with a smart hand-coded policy. As\na baseline, we train agents concurrently and independently, with no\ncommunication. Our collaborative protocols were parameter sharing, coordinated\nlearning with communication, and counterfactual policy gradients. Against the\nhand-coded team, the team trained with parameter sharing and the team trained\nwith coordinated learning performed the best, scoring on 89.5% and 94.5% of\nepisodes respectively when playing against the hand-coded team. Against the\nparameter sharing team, with adversarial training the coordinated learning team\nscored on 75% of the episodes, indicating it is the most adaptable of our\nmethods. The insights gained from our work can be applied to other domains\nwhere multi-agent collaboration could be beneficial.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.00327v1"
    },
    {
        "title": "Distributed Learning in Non-Convex Environments -- Part II: Polynomial\n  Escape from Saddle-Points",
        "authors": [
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The diffusion strategy for distributed learning from streaming data employs\nlocal stochastic gradient updates along with exchange of iterates over\nneighborhoods. In Part I [2] of this work we established that agents cluster\naround a network centroid and proceeded to study the dynamics of this point. We\nestablished expected descent in non-convex environments in the large-gradient\nregime and introduced a short-term model to examine the dynamics over\nfinite-time horizons. Using this model, we establish in this work that the\ndiffusion strategy is able to escape from strict saddle-points in O(1/$\\mu$)\niterations; it is also able to return approximately second-order stationary\npoints in a polynomial number of iterations. Relative to prior works on the\npolynomial escape from saddle-points, most of which focus on centralized\nperturbed or stochastic gradient descent, our approach requires less\nrestrictive conditions on the gradient noise process.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.01849v1"
    },
    {
        "title": "Decentralized Dynamic Task Allocation in Swarm Robotic Systems for\n  Disaster Response",
        "authors": [
            "Payam Ghassemi",
            "David DePauw",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Multiple robotic systems, working together, can provide important solutions\nto different real-world applications (e.g., disaster response), among which\ntask allocation problems feature prominently. Very few existing decentralized\nmulti-robotic task allocation (MRTA) methods simultaneously offer the following\ncapabilities: consideration of task deadlines, consideration of robot range and\ntask completion capacity limitations, and allowing asynchronous decision-making\nunder dynamic task spaces. To provision these capabilities, this paper presents\na computationally efficient algorithm that involves novel construction and\nmatching of bipartite graphs. Its performance is tested on a multi-UAV flood\nresponse application.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04394v2"
    },
    {
        "title": "Informative Path Planning with Local Penalization for Decentralized and\n  Asynchronous Swarm Robotic Search",
        "authors": [
            "Payam Ghassemi",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Decentralized swarm robotic solutions to searching for targets that emit a\nspatially varying signal promise task parallelism, time efficiency, and fault\ntolerance. It is, however, challenging for swarm algorithms to offer\nscalability and efficiency, while preserving mathematical insights into the\nexhibited behavior. A new decentralized search method (called Bayes-Swarm),\nfounded on batch Bayesian Optimization (BO) principles, is presented here to\naddress these challenges. Unlike swarm heuristics approaches, Bayes-Swarm\ndecouples the knowledge generation and task planning process, thus preserving\ninsights into the emergent behavior. Key contributions lie in: 1) modeling\nknowledge extraction over trajectories, unlike in BO; 2) time-adaptively\nbalancing exploration/exploitation and using an efficient local penalization\napproach to account for potential interactions among different robots' planned\nsamples; and 3) presenting an asynchronous implementation of the algorithm.\nThis algorithm is tested on case studies with bimodal and highly multimodal\nsignal distributions. Up to 76 times better efficiency is demonstrated compared\nto an exhaustive search baseline. The benefits of exploitation/exploration\nbalancing, asynchronous planning, and local penalization, and scalability with\nswarm size, are also demonstrated.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04396v1"
    },
    {
        "title": "Towards automatic estimation of conversation floors within F-formations",
        "authors": [
            "Chirag Raman",
            "Hayley Hung"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  The detection of free-standing conversing groups has received significant\nattention in recent years. In the absence of a formal definition, most studies\noperationalize the notion of a conversation group either through a spatial or a\ntemporal lens. Spatially, the most commonly used representation is the\nF-formation, defined by social scientists as the configuration in which people\narrange themselves to sustain an interaction. However, the use of this\nrepresentation is often accompanied with the simplifying assumption that a\nsingle conversation occurs within an F-formation. Temporally, various\ncategories have been used to organize conversational units; these include,\namong others, turn, topic, and floor. Some of these concepts are hard to define\nobjectively by themselves. The present work constitutes an initial exploration\ninto unifying these perspectives by primarily posing the question: can we use\nthe observation of simultaneous speaker turns to infer whether multiple\nconversation floors exist within an F-formation? We motivate a metric for the\nexistence of distinct conversation floors based on simultaneous speaker turns,\nand provide an analysis using this metric to characterize conversations across\nF-formations of varying cardinality. We contribute two key findings: firstly,\nat the average speaking turn duration of about two seconds for humans, there is\nevidence for the existence of multiple floors within an F-formation; and\nsecondly, an increase in the cardinality of an F-formation correlates with a\ndecrease in duration of simultaneous speaking turns.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10384v2"
    },
    {
        "title": "Distributed Resource Allocation over Time-varying Balanced Digraphs with\n  Discrete-time Communication",
        "authors": [
            "Lanlan Su",
            "Mengmou Li",
            "Vijay Gupta",
            "Graziano Chesi"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This work is concerned with the problem of distributed resource allocation in\ncontinuous-time setting but with discrete-time communication over infinitely\njointly connected and balanced digraphs. We provide a passivity-based\nperspective for the continuous-time algorithm, based on which an intermittent\ncommunication scheme is developed. Particularly, a periodic communication\nscheme is first derived through analyzing the passivity degradation over output\nsampling of the distributed dynamics at each node. Then, an asynchronous\ndistributed event-triggered scheme is further developed. The sampled-based\nevent-triggered communication scheme is exempt from Zeno behavior as the\nminimum inter-event time is lower bounded by the sampling period. The\nparameters in the proposed algorithm rely only on local information of each\nindividual nodes, which can be designed in a truly distributed fashion\n",
        "pdf_link": "http://arxiv.org/pdf/1907.13003v3"
    },
    {
        "title": "DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local &\n  Global Collision Avoidance",
        "authors": [
            "Qingyang Tan",
            "Tingxiang Fan",
            "Jia Pan",
            "Dinesh Manocha"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We present a novel algorithm (DeepMNavigate) for global multi-agent\nnavigation in dense scenarios using deep reinforcement learning (DRL). Our\napproach uses local and global information for each robot from motion\ninformation maps. We use a three-layer CNN that takes these maps as input to\ngenerate a suitable action to drive each robot to its goal position. Our\napproach is general, learns an optimal policy using a multi-scenario,\nmulti-state training algorithm, and can directly handle raw sensor measurements\nfor local observations. We demonstrate the performance on dense, complex\nbenchmarks with narrow passages and environments with tens of agents. We\nhighlight the algorithm's benefits over prior learning methods and geometric\ndecentralized algorithms in complex scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.09441v5"
    },
    {
        "title": "Multi-agent Hierarchical Reinforcement Learning with Dynamic Termination",
        "authors": [
            "Dongge Han",
            "Wendelin Boehmer",
            "Michael Wooldridge",
            "Alex Rogers"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In a multi-agent system, an agent's optimal policy will typically depend on\nthe policies chosen by others. Therefore, a key issue in multi-agent systems\nresearch is that of predicting the behaviours of others, and responding\npromptly to changes in such behaviours. One obvious possibility is for each\nagent to broadcast their current intention, for example, the currently executed\noption in a hierarchical reinforcement learning framework. However, this\napproach results in inflexibility of agents if options have an extended\nduration and are dynamic. While adjusting the executed option at each step\nimproves flexibility from a single-agent perspective, frequent changes in\noptions can induce inconsistency between an agent's actual behaviour and its\nbroadcast intention. In order to balance flexibility and predictability, we\npropose a dynamic termination Bellman equation that allows the agents to\nflexibly terminate their options. We evaluate our model empirically on a set of\nmulti-agent pursuit and taxi tasks, and show that our agents learn to adapt\nflexibly across scenarios that require different termination behaviours.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.09508v1"
    },
    {
        "title": "Patients, Primary Care, and Policy: Simulation Modeling for Health Care\n  Decision Support",
        "authors": [
            "Martin Comis",
            "Catherine Cleophas",
            "Christina Büsing"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Demand for health care is constantly increasing due to the ongoing\ndemographic change, while at the same time health service providers face\ndifficulties in finding skilled personnel. This creates pressure on health care\nsystems around the world, such that the efficient, nationwide provision of\nprimary health care has become one of society's greatest challenges. Due to the\ncomplexity of health care systems, unforeseen future events, and a frequent\nlack of data, analyzing and optimizing the performance of health care systems\nmeans tackling a wicked problem. To support this task for primary care, this\npaper introduces the hybrid agent-based simulation model SiM-Care. SiM-Care\nmodels the interactions of patients and primary care physicians on an\nindividual level. By tracking agent interactions, it enables modelers to assess\nmultiple key indicators such as patient waiting times and physician\nutilization. Based on these indicators, primary care systems can be assessed\nand compared. Moreover, changes in the infrastructure, patient behavior, and\nservice design can be directly evaluated. To showcase the opportunities offered\nby SiM-Care and aid model validation, we present a case study for a primary\ncare system in Germany. Specifically, we investigate the effects of an aging\npopulation, a decrease in the number of physicians, as well as the combined\neffects.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.11027v2"
    },
    {
        "title": "Deep Decentralized Reinforcement Learning for Cooperative Control",
        "authors": [
            "Florian Köpf",
            "Samuel Tesfazgi",
            "Michael Flad",
            "Sören Hohmann"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  In order to collaborate efficiently with unknown partners in cooperative\ncontrol settings, adaptation of the partners based on online experience is\nrequired. The rather general and widely applicable control setting, where each\ncooperation partner might strive for individual goals while the control laws\nand objectives of the partners are unknown, entails various challenges such as\nthe non-stationarity of the environment, the multi-agent credit assignment\nproblem, the alter-exploration problem and the coordination problem. We propose\nnew, modular deep decentralized Multi-Agent Reinforcement Learning mechanisms\nto account for these challenges. Therefore, our method uses a time-dependent\nprioritization of samples, incorporates a model of the system dynamics and\nutilizes variable, accountability-driven learning rates and simulated,\nartificial experiences in order to guide the learning process. The\neffectiveness of our method is demonstrated by means of a simulated, nonlinear\ncooperative control task.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13196v1"
    },
    {
        "title": "Linear Speedup in Saddle-Point Escape for Decentralized Non-Convex\n  Optimization",
        "authors": [
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Under appropriate cooperation protocols and parameter choices, fully\ndecentralized solutions for stochastic optimization have been shown to match\nthe performance of centralized solutions and result in linear speedup (in the\nnumber of agents) relative to non-cooperative approaches in the strongly-convex\nsetting. More recently, these results have been extended to the pursuit of\nfirst-order stationary points in non-convex environments. In this work, we\nexamine in detail the dependence of second-order convergence guarantees on the\nspectral properties of the combination policy for non-convex multi agent\noptimization. We establish linear speedup in saddle-point escape time in the\nnumber of agents for symmetric combination policies and study the potential for\nfurther improvement by employing asymmetric combination weights. The results\nimply that a linear speedup can be expected in the pursuit of second-order\nstationary points, which exclude local maxima as well as strict saddle-points\nand correspond to local or even global minima in many important learning\nsettings.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13852v1"
    },
    {
        "title": "JS-son -- A Lean, Extensible JavaScript Agent Programming Library",
        "authors": [
            "Timotheus Kampik",
            "Juan Carlos Nieves"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  A multitude of agent-oriented software engineering frameworks exist, most of\nwhich are developed by the academic multi-agent systems community. However,\nthese frameworks often impose programming paradigms on their users that are\nchallenging to learn for engineers who are used to modern high-level\nprogramming languages such as JavaScript and Python. To show how the adoption\nof agent-oriented programming by the software engineering mainstream can be\nfacilitated, we provide a lean JavaScript library prototype for implementing\nreasoning-loop agents. The library focuses on core agent programming concepts\nand refrains from imposing further restrictions on the programming approach. To\nillustrate its usefulness, we show how the library can be applied to\nmulti-agent systems simulations on the web, deployed to cloud-hosted\nfunction-as-a-service environments, and embedded in Python-based data science\ntools.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.04690v1"
    },
    {
        "title": "Model-based Reinforcement Learning for Decentralized Multiagent\n  Rendezvous",
        "authors": [
            "Rose E. Wang",
            "J. Chase Kew",
            "Dennis Lee",
            "Tsang-Wei Edward Lee",
            "Tingnan Zhang",
            "Brian Ichter",
            "Jie Tan",
            "Aleksandra Faust"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Collaboration requires agents to align their goals on the fly. Underlying the\nhuman ability to align goals with other agents is their ability to predict the\nintentions of others and actively update their own plans. We propose\nhierarchical predictive planning (HPP), a model-based reinforcement learning\nmethod for decentralized multiagent rendezvous. Starting with pretrained,\nsingle-agent point to point navigation policies and using noisy,\nhigh-dimensional sensor inputs like lidar, we first learn via self-supervision\nmotion predictions of all agents on the team. Next, HPP uses the prediction\nmodels to propose and evaluate navigation subgoals for completing the\nrendezvous task without explicit communication among agents. We evaluate HPP in\na suite of unseen environments, with increasing complexity and numbers of\nobstacles. We show that HPP outperforms alternative reinforcement learning,\npath planning, and heuristic-based baselines on challenging, unseen\nenvironments. Experiments in the real world demonstrate successful transfer of\nthe prediction models from sim to real world without any additional\nfine-tuning. Altogether, HPP removes the need for a centralized operator in\nmultiagent systems by combining model-based RL and inference methods, enabling\nagents to dynamically align plans.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.06906v2"
    },
    {
        "title": "Beyond Reynolds: A Constraint-Driven Approach to Cluster Flocking",
        "authors": [
            "Logan E. Beaver",
            "Andreas A. Malikopoulos"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, we present an original set of flocking rules using an\necologically-inspired paradigm for control of multi-robot systems. We translate\nthese rules into a constraint-driven optimal control problem where the agents\nminimize energy consumption subject to safety and task constraints. We prove\nseveral properties about the feasible space of the optimal control problem and\nshow that velocity consensus is an optimal solution. We also motivate the\ninclusion of slack variables in constraint-driven problems when the global\nstate is only partially observable by each agent. Finally, we analyze the case\nwhere the communication topology is fixed and connected, and prove that our\nproposed flocking rules achieve velocity consensus.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07310v2"
    },
    {
        "title": "Social Navigation with Human Empowerment driven Deep Reinforcement\n  Learning",
        "authors": [
            "Tessa van der Heiden",
            "Florian Mirus",
            "Herke van Hoof"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Mobile robot navigation has seen extensive research in the last decades. The\naspect of collaboration with robots and humans sharing workspaces will become\nincreasingly important in the future. Therefore, the next generation of mobile\nrobots needs to be socially-compliant to be accepted by their human\ncollaborators. However, a formal definition of compliance is not\nstraightforward. On the other hand, empowerment has been used by artificial\nagents to learn complicated and generalized actions and also has been shown to\nbe a good model for biological behaviors. In this paper, we go beyond the\napproach of classical \\acf{RL} and provide our agent with intrinsic motivation\nusing empowerment. In contrast to self-empowerment, a robot employing our\napproach strives for the empowerment of people in its environment, so they are\nnot disturbed by the robot's presence and motion. In our experiments, we show\nthat our approach has a positive influence on humans, as it minimizes its\ndistance to humans and thus decreases human travel time while moving\nefficiently towards its own goal. An interactive user-study shows that our\nmethod is considered more social than other state-of-the-art approaches by the\nparticipants.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.08158v3"
    },
    {
        "title": "Redistribution Systems and PRAM",
        "authors": [
            "Paul Cohen",
            "Tomasz Loboda"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Redistribution systems iteratively redistribute mass between groups under the\ncontrol of rules. PRAM is a framework for building redistribution systems. We\ndiscuss the relationships between redistribution systems, agent-based systems,\ncompartmental models and Bayesian models. PRAM puts agent-based models on a\nsound probabilistic footing by reformulating them as redistribution systems.\nThis provides a basis for integrating agent-based and probabilistic models.\n\\pram/ extends the themes of probabilistic relational models and lifted\ninference to incorporate dynamical models and simulation. We illustrate PRAM\nwith an epidemiological example.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.08783v2"
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Problems with Combined Individual\n  and Team Reward",
        "authors": [
            "Hassam Ullah Sheikh",
            "Ladislau Bölöni"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Many cooperative multi-agent problems require agents to learn individual\ntasks while contributing to the collective success of the group. This is a\nchallenging task for current state-of-the-art multi-agent reinforcement\nalgorithms that are designed to either maximize the global reward of the team\nor the individual local rewards. The problem is exacerbated when either of the\nrewards is sparse leading to unstable learning. To address this problem, we\npresent Decomposed Multi-Agent Deep Deterministic Policy Gradient (DE-MADDPG):\na novel cooperative multi-agent reinforcement learning framework that\nsimultaneously learns to maximize the global and local rewards. We evaluate our\nsolution on the challenging defensive escort team problem and show that our\nsolution achieves a significantly better and more stable performance than the\ndirect adaptation of the MADDPG algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.10598v1"
    },
    {
        "title": "Decentralized Learning for Channel Allocation in IoT Networks over\n  Unlicensed Bandwidth as a Contextual Multi-player Multi-armed Bandit Game",
        "authors": [
            "Wenbo Wang",
            "Amir Leshem",
            "Dusit Niyato",
            "Zhu Han"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We study a decentralized channel allocation problem in an ad-hoc Internet of\nThings network underlaying on the spectrum licensed to a primary cellular\nnetwork. In the considered network, the impoverished channel sensing/probing\ncapability and computational resource on the IoT devices make them difficult to\nacquire the detailed Channel State Information (CSI) for the shared multiple\nchannels. In practice, the unknown patterns of the primary users' transmission\nactivities and the time-varying CSI (e.g., due to small-scale fading or device\nmobility) also cause stochastic changes in the channel quality. Decentralized\nIoT links are thus expected to learn channel conditions online based on partial\nobservations, while acquiring no information about the channels that they are\nnot operating on. They also have to reach an efficient, collision-free solution\nof channel allocation with limited coordination. Our study maps this problem\ninto a contextual multi-player, multi-armed bandit game, and proposes a purely\ndecentralized, three-stage policy learning algorithm through trial-and-error.\nTheoretical analyses shows that the proposed scheme guarantees the IoT links to\njointly converge to the social optimal channel allocation with a sub-linear\n(i.e., polylogarithmic) regret with respect to the operational time.\nSimulations demonstrate that it strikes a good balance between efficiency and\nnetwork scalability when compared with the other state-of-the-art decentralized\nbandit algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.13314v3"
    },
    {
        "title": "Automated Configuration of Negotiation Strategies",
        "authors": [
            "Bram M. Renting",
            "Holger H. Hoos",
            "Catholijn M. Jonker"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Bidding and acceptance strategies have a substantial impact on the outcome of\nnegotiations in scenarios with linear additive and nonlinear utility functions.\nOver the years, it has become clear that there is no single best strategy for\nall negotiation settings, yet many fixed strategies are still being developed.\nWe envision a shift in the strategy design question from: What is a good\nstrategy?, towards: What could be a good strategy? For this purpose, we\ndeveloped a method leveraging automated algorithm configuration to find the\nbest strategies for a specific set of negotiation settings. By empowering\nautomated negotiating agents using automated algorithm configuration, we obtain\na flexible negotiation agent that can be configured automatically for a rich\nspace of opponents and negotiation scenarios.\n  To critically assess our approach, the agent was tested in an ANAC-like\nbilateral automated negotiation tournament setting against past competitors. We\nshow that our automatically configured agent outperforms all other agents, with\na 5.1% increase in negotiation payoff compared to the next-best agent. We note\nthat without our agent in the tournament, the top-ranked agent wins by a margin\nof only 0.01%.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.00094v1"
    },
    {
        "title": "Generate Country-Scale Networks of Interaction from Scattered Statistics",
        "authors": [
            "Samuel Thiriot",
            "Jean-Daniel Kant"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  It is common to define the structure of interactions among a population of\nagents by a network. Most of agent-based models were shown highly sensitive to\nthat network, so the relevance of simulation results directely depends on the\ndescriptive power of that network. When studying social dynamics in large\npopulations, that network cannot be collected, and is rather generated by\nalgorithms which aim to fit general properties of social networks. However,\nmore precise data is available at a country scale in the form of\nsocio-demographic studies, census or sociological studies. These \"scattered\nstatistics\" provide rich information, especially on agents' attributes, similar\nproperties of tied agents and affiliations. In this paper, we propose a generic\nmethodology to bring up together these scattered statistics with bayesian\nnetworks. We explain how to generate a population of heterogeneous agents, and\nhow to create links by using both scattered statistics and knowledge on social\nselection processes. The methodology is illustrated by generating an\ninteraction network for rural Kenya which includes familial structure,\ncolleagues and friendship constrained given field studies and statistics.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.01031v1"
    },
    {
        "title": "Distributed Hypothesis Testing and Social Learning in Finite Time with a\n  Finite Amount of Communication",
        "authors": [
            "Shreyas Sundaram",
            "Aritra Mitra"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We consider the problem of distributed hypothesis testing (or social\nlearning) where a network of agents seeks to identify the true state of the\nworld from a finite set of hypotheses, based on a series of stochastic signals\nthat each agent receives. Prior work on this problem has provided distributed\nalgorithms that guarantee asymptotic learning of the true state, with\ncorresponding efforts to improve the rate of learning. In this paper, we first\nargue that one can readily modify existing asymptotic learning algorithms to\nenable learning in finite time, effectively yielding arbitrarily large\n(asymptotic) rates. We then provide a simple algorithm for finite-time learning\nwhich only requires the agents to exchange a binary vector (of length equal to\nthe number of possible hypotheses) with their neighbors at each time-step.\nFinally, we show that if the agents know the diameter of the network, our\nalgorithm can be further modified to allow all agents to learn the true state\nand stop transmitting to their neighbors after a finite number of time-steps.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.01306v1"
    },
    {
        "title": "A Receding Horizon Scheduling Approach for Search & Rescue Scenarios",
        "authors": [
            "Yousef Emam",
            "Sean Wilson",
            "Mathias Hakenberg",
            "Ulrich Munz",
            "Magnus Egerstedt"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Many applications involving complex multi-task problems such as disaster\nrelief, logistics and manufacturing necessitate the deployment and coordination\nof heterogeneous multi-agent systems due to the sheer number of tasks that must\nbe executed simultaneously. A fundamental requirement for the successful\ncoordination of such systems is leveraging the specialization of each agent\nwithin the team. This work presents a Receding Horizon Planning (RHP) framework\naimed at scheduling tasks for heterogeneous multi-agent teams in a robust\nmanner. In order to allow for the modular addition and removal of different\ntypes of agents to the team, the proposed framework accounts for the\ncapabilities that each agent exhibits (e.g. quadrotors are agile and agnostic\nto rough terrain but are not suited to transport heavy payloads). An\ninstantiation of the proposed RHP is developed and tested for a search and\nrescue scenario. Moreover, we present an abstracted search and rescue\nsimulation environment, where a heterogeneous team of agents is deployed to\nsimultaneously explore the environment, find and rescue trapped victims, and\nextinguish spreading fires as quickly as possible. We validate the\neffectiveness of our approach through extensive simulations comparing the\npresented framework with various planning horizons to a greedy task allocation\nscheme.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.02347v1"
    },
    {
        "title": "Adaptive Social Learning",
        "authors": [
            "Virginia Bordignon",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This work proposes a novel strategy for social learning by introducing the\ncritical feature of adaptation. In social learning, several distributed agents\nupdate continually their belief about a phenomenon of interest through: i)\ndirect observation of streaming data that they gather locally; and ii)\ndiffusion of their beliefs through local cooperation with their neighbors.\nTraditional social learning implementations are known to learn well the\nunderlying hypothesis (which means that the belief of every individual agent\npeaks at the true hypothesis), achieving steady improvement in the learning\naccuracy under stationary conditions. However, these algorithms do not perform\nwell under nonstationary conditions commonly encountered in online learning,\nexhibiting a significant inertia to track drifts in the streaming data. In\norder to address this gap, we propose an Adaptive Social Learning (ASL)\nstrategy, which relies on a small step-size parameter to tune the adaptation\ndegree. First, we provide a detailed characterization of the learning\nperformance by means of a steady-state analysis. Focusing on the small\nstep-size regime, we establish that the ASL strategy achieves consistent\nlearning under standard global identifiability assumptions. We derive reliable\nGaussian approximations for the probability of error (i.e., of choosing a wrong\nhypothesis) at each individual agent. We carry out a large deviations analysis\nrevealing the universal behavior of adaptive social learning: the error\nprobabilities decrease exponentially fast with the inverse of the step-size,\nand we characterize the resulting exponential learning rate. Second, we\ncharacterize the adaptation performance by means of a detailed transient\nanalysis, which allows us to obtain useful analytical formulas relating the\nadaptation time to the step-size.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.02494v2"
    },
    {
        "title": "Fully-Heterogeneous Containment Control of a Network of Leader-Follower\n  Systems",
        "authors": [
            "Majid Mazouchi",
            "Farzaneh Tatari",
            "Bahare Kiumarsi",
            "Hamidreza Modares"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper develops a distributed solution to the fully-heterogeneous\ncontainment control problem (CCP), for which not only the followers' dynamics\nbut also the leaders' dynamics are non-identical. A novel formulation of the\nfully-heterogeneous CCP is first presented in which each follower constructs\nits virtual exo-system. To build these virtual exo-systems by followers, a\nnovel distributed algorithm is developed to calculate the so-called normalized\nlevel of influences (NLIs) of all leaders on each follower and a novel adaptive\ndistributed observer is designed to estimate the dynamics and states of all\nleaders that have an influence on each follower. Then, a distributed control\nprotocol is proposed based on the cooperative output regulation framework,\nutilizing this virtual exo-system. Based on estimations of leaders' dynamics\nand states and NLIs of leaders on each follower, the solutions of the so-called\nlinear regulator equations are calculated in a distributed manner, and\nconsequently, a distributed control protocol is designed for solving the output\ncontainment problem. Finally, theoretical results are verified by performing\nnumerical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.03725v3"
    },
    {
        "title": "A Novel Multi-Agent System for Complex Scheduling Problems",
        "authors": [
            "Peter Hillmann",
            "Tobias Uhlig",
            "Gabi Dreo Rodosek",
            "Oliver Rose"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Complex scheduling problems require a large amount computation power and\ninnovative solution methods. The objective of this paper is the conception and\nimplementation of a multi-agent system that is applicable in various problem\ndomains. Independent specialized agents handle small tasks, to reach a\nsuperordinate target. Effective coordination is therefore required to achieve\nproductive cooperation. Role models and distributed artificial intelligence are\nemployed to tackle the resulting challenges. We simulate a NP-hard scheduling\nproblem to demonstrate the validity of our approach. In addition to the general\nagent based framework we propose new simulation-based optimization heuristics\nto given scheduling problems. Two of the described optimization algorithms are\nimplemented using agents. This paper highlights the advantages of the\nagent-based approach, like the reduction in layout complexity, improved control\nof complicated systems, and extendability.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09312v1"
    },
    {
        "title": "Analysing the combined health, social and economic impacts of the\n  corovanvirus pandemic using agent-based social simulation",
        "authors": [
            "Frank Dignum",
            "Virginia Dignum",
            "Paul Davidsson",
            "Amineh Ghorbani",
            "Mijke van der Hurk",
            "Maarten Jensen",
            "Christian Kammler",
            "Fabian Lorig",
            "Luis Gustavo Ludescher",
            "Alexander Melchior",
            "René Mellema",
            "Cezara Pastrav",
            "Loïs Vanhee",
            "Harko Verhagen"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  During the COVID-19 crisis there have been many difficult decisions\ngovernments and other decision makers had to make. E.g. do we go for a total\nlock down or keep schools open? How many people and which people should be\ntested? Although there are many good models from e.g. epidemiologists on the\nspread of the virus under certain conditions, these models do not directly\ntranslate into the interventions that can be taken by government. Neither can\nthese models contribute to understand the economic and/or social consequences\nof the interventions. However, effective and sustainable solutions need to take\ninto account this combination of factors. In this paper, we propose an\nagent-based social simulation tool, ASSOCC, that supports decision makers\nunderstand possible consequences of policy interventions, bu exploring the\ncombined social, health and economic consequences of these interventions.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.12809v1"
    },
    {
        "title": "Modelling heterogeneous outcomes in multi-agent systems",
        "authors": [
            "Orowa Sikder"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  A broad set of empirical phenomenon in the study of social, economic and\nmachine behaviour can be modelled as complex systems with averaging dynamics.\nHowever many of these models naturally result in consensus or consensus-like\noutcomes. In reality, empirical phenomenon rarely converge to these and instead\nare characterized by rich, persistent variation in the agent states. Such\nheterogeneous outcomes are a natural consequence of a number of models that\nincorporate external perturbation to the otherwise convex dynamics of the\nagents. The purpose of this paper is to formalize the notion of heterogeneity\nand demonstrate which classes of models are able to achieve it as an outcome,\nand therefore are better suited to modelling important empirical questions. We\ndo so by determining how the topology of (time-varying) interaction networks\nrestrict the space of possible steady-state outcomes for agents, and how this\nis related to the study of random walks on graphs. We consider a number of\nintentionally diverse examples to demonstrate how the results can be applied.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.01077v1"
    },
    {
        "title": "Multi-Swarm Herding: Protecting against Adversarial Swarms",
        "authors": [
            "Vishnu S. Chipade",
            "Dimitra Panagou"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper studies a defense approach against one or more swarms of\nadversarial agents. In our earlier work, we employ a closed formation\n(`StringNet') of defending agents (defenders) around a swarm of adversarial\nagents (attackers) to confine their motion within given bounds, and guide them\nto a safe area. The control design relies on the assumption that the\nadversarial agents remain close enough to each other, i.e., within a prescribed\nconnectivity region. To handle situations when the attackers no longer stay\nwithin such a connectivity region, but rather split into smaller swarms\n(clusters) to maximize the chance or impact of attack, this paper proposes an\napproach to learn the attacking sub-swarms and reassign defenders towards the\nattackers. We use a `Density-based Spatial Clustering of Application with Noise\n(DBSCAN)' algorithm to identify the spatially distributed swarms of the\nattackers. Then, the defenders are assigned to each identified swarm of\nattackers by solving a constrained generalized assignment problem. Simulations\nare provided to demonstrate the effectiveness of the approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.04407v1"
    },
    {
        "title": "CellEVAC: An adaptive guidance system for crowd evacuation through\n  behavioral optimization",
        "authors": [
            "Miguel A. Lopez-Carmona",
            "Alvaro Paricio Garcia"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  A critical aspect of crowds' evacuation processes is the dynamism of\nindividual decision making. Here, we investigate how to favor a coordinated\ngroup dynamic through optimal exit-choice instructions using behavioral\nstrategy optimization. We propose and evaluate an adaptive guidance system\n(Cell-based Crowd Evacuation, CellEVAC) that dynamically allocates colors to\ncells in a cell-based pedestrian positioning infrastructure, to provide\nefficient exit-choice indications. The operational module of CellEVAC\nimplements an optimized discrete-choice model that integrates the influential\nfactors that would make evacuees adapt their exit choice. To optimize the\nmodel, we used a simulation-optimization modeling framework that integrates\nmicroscopic pedestrian simulation based on the classical Social Force Model. We\npaid particular attention to safety by using Pedestrian Fundamental Diagrams\nthat model the dynamics of the exit gates. CellEVAC has been tested in a\nsimulated real scenario (Madrid Arena) under different external pedestrian flow\npatterns that simulate complex pedestrian interactions. Results showed that\nCellEVAC outperforms evacuation processes in which the system is not used, with\nan exponential improvement as interactions become complex. We compared our\nsystem with an existing approach based on Cartesian Genetic Programming. Our\nsystem exhibited a better overall performance in terms of safety, evacuation\ntime, and the number of revisions of exit-choice decisions. Further analyses\nalso revealed that Cartesian Genetic Programming generates less natural\npedestrian reactions and movements than CellEVAC. The fact that the decision\nlogic module is built upon a behavioral model seems to favor a more natural and\neffective response. We also found that our proposal has a positive influence on\nevacuations even for a low compliance rate (40%).\n",
        "pdf_link": "http://arxiv.org/pdf/2007.05963v2"
    },
    {
        "title": "A Framework for Automatic Behavior Generation in Multi-Function Swarms",
        "authors": [
            "Sondre A. Engebraaten",
            "Jonas Moen",
            "Oleg A. Yakimenko",
            "Kyrre Glette"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Multi-function swarms are swarms that solve multiple tasks at once. For\nexample, a quadcopter swarm could be tasked with exploring an area of interest\nwhile simultaneously functioning as ad-hoc relays. With this type of\nmulti-function comes the challenge of handling potentially conflicting\nrequirements simultaneously. Using the Quality-Diversity algorithm MAP-elites\nin combination with a suitable controller structure, a framework for automatic\nbehavior generation in multi-function swarms is proposed. The framework is\ntested on a scenario with three simultaneous tasks: exploration, communication\nnetwork creation and geolocation of RF emitters. A repertoire is evolved,\nconsisting of a wide range of controllers, or behavior primitives, with\ndifferent characteristics and trade-offs in the different tasks. This\nrepertoire would enable the swarm to transition between behavior trade-offs\nonline, according to the situational requirements. Furthermore, the effect of\nnoise on the behavior characteristics in MAP-elites is investigated. A moderate\nnumber of re-evaluations is found to increase the robustness while keeping the\ncomputational requirements relatively low. A few selected controllers are\nexamined, and the dynamics of transitioning between these controllers are\nexplored. Finally, the study develops a methodology for analyzing the makeup of\nthe resulting controllers. This is done through a parameter variation study\nwhere the importance of individual inputs to the swarm controllers is assessed\nand analyzed.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.08656v1"
    },
    {
        "title": "Proceedings of the First Workshop on Agents and Robots for reliable\n  Engineered Autonomy",
        "authors": [
            "Rafael C. Cardoso",
            "Angelo Ferrando",
            "Daniela Briola",
            "Claudio Menghi",
            "Tobias Ahlbrecht"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This volume contains the proceedings of the First Workshop on Agents and\nRobots for reliable Engineered Autonomy (AREA 2020), co-located with the 24th\nEuropean Conference on Artificial Intelligence (ECAI 2020). AREA brings\ntogether researchers from autonomous agents, software engineering and robotic\ncommunities, as combining knowledge coming from these research areas may lead\nto innovative approaches that solve complex problems related with the\nverification and validation of autonomous robotic systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11260v1"
    },
    {
        "title": "Exploratory Experiments on Programming Autonomous Robots in Jadescript",
        "authors": [
            "Eleonora Iotti",
            "Giuseppe Petrosino",
            "Stefania Monica",
            "Federico Bergenti"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper describes exploratory experiments to validate the possibility of\nprogramming autonomous robots using an agent-oriented programming language.\nProper perception of the environment, by means of various types of sensors, and\ntimely reaction to external events, by means of effective actuators, are\nessential to provide robots with a sufficient level of autonomy. The\nagent-oriented programming paradigm is relevant with this respect because it\noffers language-level abstractions to process events and to command actuators.\nA recent agent-oriented programming language called Jadescript is presented in\nthis paper together with its new features specifically designed to handle\nevents. Exploratory experiments on a simple case-study application are\npresented to show the validity of the proposed approach and to exemplify the\nuse of the language to program autonomous robots.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11741v1"
    },
    {
        "title": "Toward Campus Mail Delivery Using BDI",
        "authors": [
            "Chidiebere Onyedinma",
            "Patrick Gavigan",
            "Babak Esfandiari"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Autonomous systems developed with the Belief-Desire-Intention (BDI)\narchitecture are usually mostly implemented in simulated environments. In this\nproject we sought to build a BDI agent for use in the real world for campus\nmail delivery in the tunnel system at Carleton University. Ideally, the robot\nshould receive a delivery order via a mobile application, pick up the mail at a\nstation, navigate the tunnels to the destination station, and notify the\nrecipient.\n  We linked the Robot Operating System (ROS) with a BDI reasoning system to\nachieve a subset of the required use cases. ROS handles the low-level sensing\nand actuation, while the BDI reasoning system handles the high-level reasoning\nand decision making. Sensory data is orchestrated and sent from ROS to the\nreasoning system as perceptions. These perceptions are then deliberated upon,\nand an action string is sent back to ROS for interpretation and driving of the\nnecessary actuator for the action to be performed.\n  In this paper we present our current implementation, which closes the loop on\nthe hardware-software integration, and implements a subset of the use cases\nrequired for the full system.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.16089v1"
    },
    {
        "title": "A Distributed Model-Free Ride-Sharing Approach for Joint Matching,\n  Pricing, and Dispatching using Deep Reinforcement Learning",
        "authors": [
            "Marina Haliem",
            "Ganapathy Mani",
            "Vaneet Aggarwal",
            "Bharat Bhargava"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Significant development of ride-sharing services presents a plethora of\nopportunities to transform urban mobility by providing personalized and\nconvenient transportation while ensuring efficiency of large-scale ride\npooling. However, a core problem for such services is route planning for each\ndriver to fulfill the dynamically arriving requests while satisfying given\nconstraints. Current models are mostly limited to static routes with only two\nrides per vehicle (optimally) or three (with heuristics). In this paper, we\npresent a dynamic, demand aware, and pricing-based vehicle-passenger matching\nand route planning framework that (1) dynamically generates optimal routes for\neach vehicle based on online demand, pricing associated with each ride, vehicle\ncapacities and locations. This matching algorithm starts greedily and optimizes\nover time using an insertion operation, (2) involves drivers in the\ndecision-making process by allowing them to propose a different price based on\nthe expected reward for a particular ride as well as the destination locations\nfor future rides, which is influenced by supply-and demand computed by the Deep\nQ-network, (3) allows customers to accept or reject rides based on their set of\npreferences with respect to pricing and delay windows, vehicle type and\ncarpooling preferences, and (4) based on demand prediction, our approach\nre-balances idle vehicles by dispatching them to the areas of anticipated high\ndemand using deep Reinforcement Learning (RL). Our framework is validated using\nthe New York City Taxi public dataset; however, we consider different vehicle\ntypes and designed customer utility functions to validate the setup and study\ndifferent settings. Experimental results show the effectiveness of our approach\nin real-time and large scale settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.01755v2"
    },
    {
        "title": "EB-DEVS: A Formal Framework for Modeling and Simulation of Emergent\n  Behavior in Dynamic Complex Systems",
        "authors": [
            "Daniel J. Foguelman",
            "Philipp Henning",
            "Adelinde Uhrmacher",
            "Rodrigo Castro"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Emergent behavior is a key feature defining a system under study as a complex\nsystem. Simulation has been recognized as the only way to deal with the study\nof the emergency of properties (at a macroscopic level) among groups of system\ncomponents (at a microscopic level), for the manifestations of emergent\nstructures cannot be deduced from analysing components in isolation. A\nsystems-oriented generalisation must consider the presence of feedback loops\n(micro components react to macro properties), interaction among components of\ndifferent classes (modular composition) and layered interaction of subsystems\noperating at different spatio-temporal scales (hierarchical organisation). In\nthis work we introduce Emergent Behavior-DEVS (EB-DEVS) a Modeling and\nSimulation (M&S) formalism that permits reasoning about complex systems where\nemergent behavior is placed at the forefront of the analysis activity. EB-DEVS\nbuilds on the DEVS formalism, adding upward/downward communication channels to\nwell-established capabilities for modular and hierarchical M&S of heterogeneous\nmulti-formalism systems. EB-DEVS takes a minimalist stance on expressiveness,\nintroducing a small set of extensions on Classic DEVS that can cope with\nemergent behavior, and making both formalisms interoperable (the modeler\ndecides which subsystems deserve to be expressed via micro-macro dynamics). We\npresent three case studies: flocks of birds with learning, population epidemics\nwith vaccination and sub-cellular dynamics with homeostasis, through which we\nshowcase how EB-DEVS performs by placing emergent properties at the center of\nthe M&S process.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.05042v2"
    },
    {
        "title": "Agent-based Simulation Model and Deep Learning Techniques to Evaluate\n  and Predict Transportation Trends around COVID-19",
        "authors": [
            "Ding Wang",
            "Fan Zuo",
            "Jingqin Gao",
            "Yueshuai He",
            "Zilin Bian",
            "Suzana Duran Bernardes",
            "Chaekuk Na",
            "Jingxing Wang",
            "John Petinos",
            "Kaan Ozbay",
            "Joseph Y. J. Chow",
            "Shri Iyer",
            "Hani Nassif",
            "Xuegang Jeff Ban"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The COVID-19 pandemic has affected travel behaviors and transportation system\noperations, and cities are grappling with what policies can be effective for a\nphased reopening shaped by social distancing. This edition of the white paper\nupdates travel trends and highlights an agent-based simulation model's results\nto predict the impact of proposed phased reopening strategies. It also\nintroduces a real-time video processing method to measure social distancing\nthrough cameras on city streets.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.09648v1"
    },
    {
        "title": "A simulation-based evaluation of a Cargo-Hitching service for E-commerce\n  using mobility-on-demand vehicles",
        "authors": [
            "Andre Alho",
            "Takanori Sakai",
            "Simon Oh",
            "Cheng Cheng",
            "Ravi Seshadri",
            "Wen Han Chong",
            "Yusuke Hara",
            "Julia Caravias",
            "Lynette Cheah",
            "Moshe Ben-Akiva"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Time-sensitive parcel deliveries, shipments requested for delivery in a day\nor less, are an increasingly important research subject. It is challenging to\ndeal with these deliveries from a carrier perspective since it entails\nadditional planning constraints, preventing an efficient consolidation of\ndeliveries which is possible when demand is well known in advance. Furthermore,\nsuch time-sensitive deliveries are requested to a wider spatial scope than\nretail centers, including homes and offices. Therefore, an increase in such\ndeliveries is considered to exacerbate negative externalities such as\ncongestion and emissions. One of the solutions is to leverage spare capacity in\npassenger transport modes. This concept is often denominated as cargo-hitching.\nWhile there are various possible system designs, it is crucial that such\nsolution does not deteriorate the quality of service of passenger trips. This\nresearch aims to evaluate the use of Mobility-On-Demand services to perform\nsame-day parcel deliveries. For this purpose, we use SimMobility, a\nhigh-resolution agent-based simulation platform of passenger and freight flows,\napplied in Singapore. E-commerce demand carrier data are used to characterize\nsimulated parcel delivery demand. Operational scenarios that aim to minimize\nthe adverse effect of fulfilling deliveries with Mobility-On-Demand vehicles on\nMobility-On-Demand passenger flows (fulfillment, wait and travel times) are\nexplored. Results indicate that the Mobility-On-Demand services have potential\nto fulfill a considerable amount of parcel deliveries and decrease freight\nvehicle traffic and total vehicle-kilometers-travelled without compromising the\nquality of Mobility On-Demand for passenger travel.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.11585v1"
    },
    {
        "title": "Gramian-Based Adaptive Combination Policies for Diffusion Learning over\n  Networks",
        "authors": [
            "Y. Efe Erginbas",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  This paper presents an adaptive combination strategy for distributed learning\nover diffusion networks. Since learning relies on the collaborative processing\nof the stochastic information at the dispersed agents, the overall performance\ncan be improved by designing combination policies that adjust the weights\naccording to the quality of the data. Such policies are important because they\nwould add a new degree of freedom and endow multi-agent systems with the\nability to control the flow of information over their edges for enhanced\nperformance. Most adaptive and static policies available in the literature\noptimize certain performance metrics related to steady-state behavior, to the\ndetriment of transient behavior. In contrast, we develop an adaptive\ncombination rule that aims at optimizing the transient learning performance,\nwhile maintaining the enhanced steady-state performance obtained using policies\npreviously developed in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.13104v1"
    },
    {
        "title": "Data-Driven Predictive Control Towards Multi-Agent Motion Planning With\n  Non-Parametric Closed-Loop Behavior Learning",
        "authors": [
            "Jun Ma",
            "Zilong Cheng",
            "Wenxin Wang",
            "Abdullah Al Mamun",
            "Clarence W. de Silva",
            "Tong Heng Lee"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In many specific scenarios, accurate and effective system identification is a\ncommonly encountered challenge in the model predictive control (MPC)\nformulation. As a consequence, the overall system performance could be\nsignificantly weakened in outcome when the traditional MPC algorithm is adopted\nunder those circumstances when such accuracy is lacking. This paper\ninvestigates a non-parametric closed-loop behavior learning method for\nmulti-agent motion planning, which underpins a data-driven predictive control\nframework. Utilizing an innovative methodology with closed-loop input/output\nmeasurements of the unknown system, the behavior of the system is learned based\non the collected dataset, and thus the constructed non-parametric predictive\nmodel can be used to determine the optimal control actions. This non-parametric\npredictive control framework alleviates the heavy computational burden commonly\nencountered in the optimization procedures typically in alternate methodologies\nrequiring open-loop input/output measurement data collection and parametric\nsystem identification. The proposed data-driven approach is also shown to\npreserve good robustness properties. Finally, a multi-UAV system is used to\ndemonstrate the highly effective outcome of this promising development.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.03213v3"
    },
    {
        "title": "A Distributed Differentially Private Algorithm for Resource Allocation\n  in Unboundedly Large Settings",
        "authors": [
            "Panayiotis Danassis",
            "Aleksei Triastcyn",
            "Boi Faltings"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  We introduce a practical and scalable algorithm (PALMA) for solving one of\nthe fundamental problems of multi-agent systems -- finding matches and\nallocations -- in unboundedly large settings (e.g., resource allocation in\nurban environments, mobility-on-demand systems, etc.), while providing strong\nworst-case privacy guarantees. PALMA is decentralized, runs on-device, requires\nno inter-agent communication, and converges in constant time under reasonable\nassumptions. We evaluate PALMA in a mobility-on-demand and a paper assignment\nscenario, using real data in both, and demonstrate that it provides a strong\nlevel of privacy ($\\varepsilon \\leq 1$ and median as low as $\\varepsilon = 0.5$\nacross agents) and high-quality matchings (up to $86\\%$ of the non-private\noptimal, outperforming even the privacy-preserving centralized maximum-weight\nmatching baseline).\n",
        "pdf_link": "http://arxiv.org/pdf/2011.07934v2"
    },
    {
        "title": "Research Needed in Computational Social Science for Power System\n  Reliability, Resilience, and Restoration",
        "authors": [
            "Jaber Valinejad",
            "Lamine Mili",
            "Natalie van der Wal"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In the literature, smart grids are modeled as cyber-physical power systems\nwithout considering the computational social aspects. However, end-users are\nplaying a key role in their operation and response to disturbances via demand\nresponse and distributed energy resources. Therefore, due to the critical role\nof active and passive end-users and the intermittency of renewable energy,\nsmart grids must be planned and operated by considering the computational\nsocial aspects in addition to the technical aspects. The level of cooperation,\nflexibility, and other social features of the various stakeholders, including\nconsumers, prosumers, and microgrids, affect the system efficiency,\nreliability, and resilience. In this paper, we design an artificial society\nsimulating the interaction between power systems and the social communities\nthat they serve via agent-based modeling inspired by Barsade's theory on the\nemotional spread. The simulation results show a decline in the consumers' and\nprosumers' satisfaction levels induced by a shortage of electricity. It also\nshows the effects of social diffusion via the Internet and mass media on the\nsatisfaction level. In view of the importance of computational social science\nfor power system applications and the limited number of publications devoted to\nit, we provide a list of research topics that need to be achieved to enhance\nthe reliability and resilience of power systems' operation and planning.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.08064v1"
    },
    {
        "title": "Low-Bandwidth Communication Emerges Naturally in Multi-Agent Learning\n  Systems",
        "authors": [
            "Niko A. Grupen",
            "Daniel D. Lee",
            "Bart Selman"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this work, we study emergent communication through the lens of cooperative\nmulti-agent behavior in nature. Using insights from animal communication, we\npropose a spectrum from low-bandwidth (e.g. pheromone trails) to high-bandwidth\n(e.g. compositional language) communication that is based on the cognitive,\nperceptual, and behavioral capabilities of social agents. Through a series of\nexperiments with pursuit-evasion games, we identify multi-agent reinforcement\nlearning algorithms as a computational model for the low-bandwidth end of the\ncommunication spectrum.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.14890v2"
    },
    {
        "title": "Semi-Definite Relaxation Based ADMM for Cooperative Planning and Control\n  of Connected Autonomous Vehicles",
        "authors": [
            "Xiaoxue Zhang",
            "Zilong Cheng",
            "Jun Ma",
            "Sunan Huang",
            "Frank L. Lewis",
            "Tong Heng Lee"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper investigates the cooperative planning and control problem for\nmultiple connected autonomous vehicles (CAVs) in different scenarios. In the\nexisting literature, most of the methods suffer from significant problems in\ncomputational efficiency. Besides, as the optimization problem is nonlinear and\nnonconvex, it typically poses great difficultly in determining the optimal\nsolution. To address this issue, this work proposes a novel and completely\nparallel computation framework by leveraging the alternating direction method\nof multipliers (ADMM). The nonlinear and nonconvex optimization problem in the\nautonomous driving problem can be divided into two manageable subproblems; and\nthe resulting subproblems can be solved by using effective optimization methods\nin a parallel framework. Here, the differential dynamic programming (DDP)\nalgorithm is capable of addressing the nonlinearity of the system dynamics\nrather effectively; and the nonconvex coupling constraints with small\ndimensions can be approximated by invoking the notion of semi-definite\nrelaxation (SDR), which can also be solved in a very short time. Due to the\nparallel computation and efficient relaxation of nonconvex constraints, our\nproposed approach effectively realizes real-time implementation and thus also\nextra assurance of driving safety is provided. In addition, two transportation\nscenarios for multiple CAVs are used to illustrate the effectiveness and\nefficiency of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00201v1"
    },
    {
        "title": "Generation of Traffic Flows in Multi-Agent Traffic Simulation with Agent\n  Behavior Model based on Deep Reinforcement Learning",
        "authors": [
            "Junjie Zhong",
            "Hiromitsu Hattori"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In multi-agent based traffic simulation, agents are always supposed to move\nfollowing existing instructions, and mechanically and unnaturally imitate human\nbehavior. The human drivers perform acceleration or deceleration irregularly\nall the time, which seems unnecessary in some conditions. For letting agents in\ntraffic simulation behave more like humans and recognize other agents' behavior\nin complex conditions, we propose a unified mechanism for agents learn to\ndecide various accelerations by using deep reinforcement learning based on a\ncombination of regenerated visual images revealing some notable features, and\nnumerical vectors containing some important data such as instantaneous speed.\nBy handling batches of sequential data, agents are enabled to recognize\nsurrounding agents' behavior and decide their own acceleration. In addition, we\ncan generate a traffic flow behaving diversely to simulate the real traffic\nflow by using an architecture of fully decentralized training and fully\ncentralized execution without violating Markov assumptions.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.03230v2"
    },
    {
        "title": "Neurosymbolic Transformers for Multi-Agent Communication",
        "authors": [
            "Jeevana Priya Inala",
            "Yichen Yang",
            "James Paulos",
            "Yewen Pu",
            "Osbert Bastani",
            "Vijay Kumar",
            "Martin Rinard",
            "Armando Solar-Lezama"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We study the problem of inferring communication structures that can solve\ncooperative multi-agent planning problems while minimizing the amount of\ncommunication. We quantify the amount of communication as the maximum degree of\nthe communication graph; this metric captures settings where agents have\nlimited bandwidth. Minimizing communication is challenging due to the\ncombinatorial nature of both the decision space and the objective; for\ninstance, we cannot solve this problem by training neural networks using\ngradient descent. We propose a novel algorithm that synthesizes a control\npolicy that combines a programmatic communication policy used to generate the\ncommunication graph with a transformer policy network used to choose actions.\nOur algorithm first trains the transformer policy, which implicitly generates a\n\"soft\" communication graph; then, it synthesizes a programmatic communication\npolicy that \"hardens\" this graph, forming a neurosymbolic transformer. Our\nexperiments demonstrate how our approach can synthesize policies that generate\nlow-degree communication graphs while maintaining near-optimal performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.03238v1"
    },
    {
        "title": "GPS Spoofing Mitigation and Timing Risk Analysis in Networked PMUs via\n  Stochastic Reachability",
        "authors": [
            "Sriramya Bhamidipati",
            "Grace Xingxin Gao"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  To address PMU vulnerability against spoofing, we propose a set-valued state\nestimation technique known as Stochastic Reachability-based Distributed Kalman\nFilter (SR-DKF) that computes secure GPS timing across a network of receivers.\nUtilizing stochastic reachability, we estimate not only GPS time but also its\nstochastic reachable set, which is parameterized via probabilistic zonotope\n(p-Zonotope). While requiring known measurement error bounds in only\nnon-spoofed conditions, we design a two-tier approach: We first perform\nmeasurement-level spoofing mitigation via deviation of measurement innovation\nfrom its expected p-Zonotope and second perform state-level timing risk\nanalysis via intersection probability of estimated pZonotope with an unsafe set\nthat violates IEEE C37.118.1a-2014 standards. We validate the proposed SR-DKF\nby subjecting a simulated receiver network to coordinated signal-level\nspoofing. We demonstrate improved GPS timing accuracy and successful spoofing\nmitigation via our SR-DKF. We validate the robustness of the estimated timing\nrisk as the number of receivers is varied.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.04835v1"
    },
    {
        "title": "Act to Reason: A Dynamic Game Theoretical Model of Driving",
        "authors": [
            "Cevahir Köprülü",
            "Yıldıray Yıldız"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The focus of this paper is to propose a driver model that incorporates human\nreasoning levels as actions during interactions with other drivers. Different\nfrom earlier work using game theoretical human reasoning levels, we propose a\ndynamic approach, where the actions are the levels themselves, instead of\nconventional driving actions such as accelerating or braking. This results in a\ndynamic behavior, where the agent adapts to its environment by exploiting\ndifferent behavior models as available moves to choose from, depending on the\nrequirements of the traffic situation. The bounded rationality assumption is\npreserved since the selectable strategies are designed by adhering to the fact\nthat humans are cognitively limited in their understanding and decision making.\nUsing a highway merging scenario, it is demonstrated that the proposed dynamic\napproach produces more realistic outcomes compared to the conventional method\nthat employs fixed human reasoning levels.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05399v2"
    },
    {
        "title": "Learning Safe Multi-Agent Control with Decentralized Neural Barrier\n  Certificates",
        "authors": [
            "Zengyi Qin",
            "Kaiqing Zhang",
            "Yuxiao Chen",
            "Jingkai Chen",
            "Chuchu Fan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We study the multi-agent safe control problem where agents should avoid\ncollisions to static obstacles and collisions with each other while reaching\ntheir goals. Our core idea is to learn the multi-agent control policy jointly\nwith learning the control barrier functions as safety certificates. We propose\na novel joint-learning framework that can be implemented in a decentralized\nfashion, with generalization guarantees for certain function classes. Such a\ndecentralized framework can adapt to an arbitrarily large number of agents.\nBuilding upon this framework, we further improve the scalability by\nincorporating neural network architectures that are invariant to the quantity\nand permutation of neighboring agents. In addition, we propose a new\nspontaneous policy refinement method to further enforce the certificate\ncondition during testing. We provide extensive experiments to demonstrate that\nour method significantly outperforms other leading multi-agent control\napproaches in terms of maintaining safety and completing original tasks. Our\napproach also shows exceptional generalization capability in that the control\npolicy can be trained with 8 agents in one scenario, while being used on other\nscenarios with up to 1024 agents in complex multi-agent environments and\ndynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05436v4"
    },
    {
        "title": "Medical Information Retrieval and Interpretation: A Question-Answer\n  based Interaction Model",
        "authors": [
            "Nilanjan Sinhababu",
            "Rahul Saxena",
            "Monalisa Sarma",
            "Debasis Samanta"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The Internet has become a very powerful platform where diverse medical\ninformation are expressed daily. Recently, a huge growth is seen in searches\nlike symptoms, diseases, medicines, and many other health related queries\naround the globe. The search engines typically populate the result by using the\nsingle query provided by the user and hence reaching to the final result may\nrequire a lot of manual filtering from the user's end. Current search engines\nand recommendation systems still lack real time interactions that may provide\nmore precise result generation. This paper proposes an intelligent and\ninteractive system tied up with the vast medical big data repository on the web\nand illustrates its potential in finding medical information.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.09662v1"
    },
    {
        "title": "Alternating Direction Method of Multipliers-Based Parallel Optimization\n  for Multi-Agent Collision-Free Model Predictive Control",
        "authors": [
            "Zilong Cheng",
            "Jun Ma",
            "Wenxin Wang",
            "Zicheng Zhu",
            "Clarence W. de Silva",
            "Tong Heng Lee"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper investigates the collision-free control problem for multi-agent\nsystems. For such multi-agent systems, it is the typical situation where\nconventional methods using either the usual centralized model predictive\ncontrol (MPC), or even the distributed counterpart, would suffer from\nsubstantial difficulty in balancing optimality and computational efficiency.\nAdditionally, the non-convex characteristics that invariably arise in such\ncollision-free control and optimization problems render it difficult to\neffectively derive a reliable solution (and also to thoroughly analyze the\nassociated convergence properties). To overcome these challenging issues, this\nwork establishes a suitably novel parallel computation framework through an\ninnovative mathematical problem formulation; and then with this framework and\nformulation, a parallel algorithm based on alternating direction method of\nmultipliers (ADMM) is presented to solve the sub-problems arising from the\nresulting parallel structure. Furthermore, an efficient and intuitive\ninitialization procedure is developed to accelerate the optimization process,\nand the optimum is thus determined with significantly improved computational\nefficiency. As supported by rigorous proofs, the convergence of the proposed\nADMM iterations for this non-convex optimization problem is analyzed and\ndiscussed in detail. Finally, a simulation with a group of unmanned aerial\nvehicles (UAVs) serves as an illustrative example here to demonstrate the\neffectiveness and efficiency of the proposed approach. Also, the simulation\nresults verify significant improvements in accuracy and computational\nefficiency compared to other baselines, including primal quadratic mixed\ninteger programming (PQ-MIP), non-convex quadratic mixed integer programming\n(NC-MIP), and non-convex quadratically constrained quadratic programming\n(NC-QCQP).\n",
        "pdf_link": "http://arxiv.org/pdf/2101.09894v2"
    },
    {
        "title": "Multi-agent simulation of voter's behaviour",
        "authors": [
            "Albin Soutif",
            "Carole Adam",
            "Sylvain Bouveret"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The goal of this paper is to simulate the voters behaviour given a voting\nmethod. Our approach uses a multi-agent simulation in order to model a voting\nprocess through many iterations, so that the voters can vote by taking into\naccount the results of polls. Here we only tried basic rules and a single\nvoting method, but further attempts could explore new features.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.11538v1"
    },
    {
        "title": "Modelling the Impact of Scandals: the case of the 2017 French\n  Presidential Election",
        "authors": [
            "Yassine Bouachrine",
            "Carole Adam"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper proposes an agent-based simulation of a presidential election,\ninspired by the French 2017 presidential election. The simulation is based on\ndata extracted from polls, media coverage, and Twitter. The main contribution\nis to consider the impact of scandals and media bashing on the result of the\nelection. In particular, it is shown that scandals can lead to higher\nabstention at the election, as voters have no relevant candidate left to vote\nfor. The simulation is implemented in Unity 3D and is available to play online.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.11548v1"
    },
    {
        "title": "Learning to Coordinate via Multiple Graph Neural Networks",
        "authors": [
            "Zhiwei Xu",
            "Bin Zhang",
            "Yunpeng Bai",
            "Dapeng Li",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The collaboration between agents has gradually become an important topic in\nmulti-agent systems. The key is how to efficiently solve the credit assignment\nproblems. This paper introduces MGAN for collaborative multi-agent\nreinforcement learning, a new algorithm that combines graph convolutional\nnetworks and value-decomposition methods. MGAN learns the representation of\nagents from different perspectives through multiple graph networks, and\nrealizes the proper allocation of attention between all agents. We show the\namazing ability of the graph network in representation learning by visualizing\nthe output of the graph network, and therefore improve interpretability for the\nactions of each agent in the multi-agent system.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.03503v1"
    },
    {
        "title": "A Hierarchical State-Machine-Based Framework for Platoon Manoeuvre\n  Descriptions",
        "authors": [
            "Corvin Deboeser",
            "Jordan Ivanchev",
            "Thomas Braud",
            "Alois Knoll",
            "David Eckhoff",
            "Alberto Sangiovanni-Vincentelli"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper introduces the SEAD framework that simplifies the process of\ndesigning and describing autonomous vehicle platooning manoeuvres. Although a\nlarge body of research has been formulating platooning manoeuvres, it is still\nchallenging to design, describe, read, and understand them. This difficulty\nlargely arises from missing formalisation. To fill this gap, we analysed\nexisting ways of describing manoeuvres, derived the causes of difficulty, and\ndesigned a framework that simplifies the manoeuvre design process. Alongside, a\nManoeuvre Design Language was developed to structurally describe manoeuvres in\na machine-readable format. Unlike state-of-the-art manoeuvre descriptions that\nrequire one state machine for every participating vehicle, the SEAD framework\nallows describing any manoeuvre from the single perspective of the platoon\nleader. %As a proof of concept, the proposed framework was implemented in the\nmixed traffic simulation environment BEHAVE for an autonomous highway scenario.\nUsing this framework, we implemented several manoeuvres as they were described\nin literature. To demonstrate the applicability of the framework, an experiment\nwas performed to evaluate the execution time performance of multiple\nalternatives of the Join-Middle manoeuvre. This proof-of-concept experiment\nrevealed that the manoeuvre execution time can be reduced by 28 \\% through\nparallelising various steps without considerable secondary effects. We hope\nthat the SEAD framework will pave the way for further research in the area of\nnew manoeuvre design and optimisation by largely simplifying and unifying\nplatooning manoeuvre representation.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.05305v1"
    },
    {
        "title": "Revisiting the Complexity Analysis of Conflict-Based Search: New\n  Computational Techniques and Improved Bounds",
        "authors": [
            "Ofir Gordon",
            "Yuval Filmus",
            "Oren Salzman"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The problem of Multi-Agent Path Finding (MAPF) calls for finding a set of\nconflict-free paths for a fleet of agents operating in a given environment.\nArguably, the state-of-the-art approach to computing optimal solutions is\nConflict-Based Search (CBS). In this work we revisit the complexity analysis of\nCBS to provide tighter bounds on the algorithm's run-time in the worst-case.\nOur analysis paves the way to better pinpoint the parameters that govern (in\nthe worst case) the algorithm's computational complexity.\n  Our analysis is based on two complementary approaches: In the first approach\nwe bound the run-time using the size of a Multi-valued Decision Diagram (MDD)\n-- a layered graph which compactly contains all possible single-agent paths\nbetween two given vertices for a specific path length.\n  In the second approach we express the running time by a novel recurrence\nrelation which bounds the algorithm's complexity. We use generating\nfunctions-based analysis in order to tightly bound the recurrence.\n  Using these technique we provide several new upper-bounds on CBS's\ncomplexity. The results allow us to improve the existing bound on the running\ntime of CBS for many cases. For example, on a set of common benchmarks we\nimprove the upper-bound by a factor of at least $2^{10^{7}}$.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.08759v1"
    },
    {
        "title": "Game Theory to Study Interactions between Mobility Stakeholders",
        "authors": [
            "Gioele Zardini",
            "Nicolas Lanzetti",
            "Laura Guerrini",
            "Emilio Frazzoli",
            "Florian Dörfler"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Increasing urbanization and exacerbation of sustainability goals threaten the\noperational efficiency of current transportation systems and confront cities\nwith complex choices with huge impact on future generations. At the same time,\nthe rise of private, profit-maximizing Mobility Service Providers leveraging\npublic resources, such as ride-hailing companies, entangles current regulation\nschemes. This calls for tools to study such complex socio-technical problems.\nIn this paper, we provide a game-theoretic framework to study interactions\nbetween stakeholders of the mobility ecosystem, modeling regulatory aspects\nsuch as taxes and public transport prices, as well as operational matters for\nMobility Service Providers such as pricing strategy, fleet sizing, and vehicle\ndesign. Our framework is modular and can readily accommodate different types of\nMobility Service Providers, actions of municipalities, and low-level models of\ncustomers choices in the mobility system. Through both an analytical and a\nnumerical case study for the city of Berlin, Germany, we showcase the ability\nof our framework to compute equilibria of the problem, to study fundamental\ntradeoffs, and to inform stakeholders and policy makers on the effects of\ninterventions. Among others, we show tradeoffs between customers satisfaction,\nenvironmental impact, and public revenue, as well as the impact of strategic\ndecisions on these metrics.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.10394v3"
    },
    {
        "title": "Birds of a Feather Flock Together: A Close Look at Cooperation Emergence\n  via Multi-Agent RL",
        "authors": [
            "Heng Dong",
            "Tonghan Wang",
            "Jiayuan Liu",
            "Chi Han",
            "Chongjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  How cooperation emerges is a long-standing and interdisciplinary problem.\nGame-theoretical studies on social dilemmas reveal that altruistic incentives\nare critical to the emergence of cooperation but their analyses are limited to\nstateless games. For more realistic scenarios, multi-agent reinforcement\nlearning has been used to study sequential social dilemmas (SSDs). Recent works\nshow that learning to incentivize other agents can promote cooperation in SSDs.\nHowever, we find that, with these incentivizing mechanisms, the team\ncooperation level does not converge and regularly oscillates between\ncooperation and defection during learning. We show that a second-order social\ndilemma resulting from the incentive mechanisms is the main reason for such\nfragile cooperation. We formally analyze the dynamics of second-order social\ndilemmas and find that a typical tendency of humans, called homophily, provides\na promising solution. We propose a novel learning framework to encourage\nhomophilic incentives and show that it achieves stable cooperation in both SSDs\nof public goods and tragedy of the commons.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.11455v2"
    },
    {
        "title": "A ridesharing simulation platform that considers dynamic supply-demand\n  interactions",
        "authors": [
            "Rui Yao",
            "Shlomo Bekhor"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper presents a new ridesharing simulation platform that accounts for\ndynamic driver supply and passenger demand, and complex interactions between\ndrivers and passengers. The proposed simulation platform explicitly considers\ndriver and passenger acceptance/rejection on the matching options, and\ncancellation before/after being matched. New simulation events, procedures and\nmodules have been developed to handle these realistic interactions. The\ncapabilities of the simulation platform are illustrated using numerical\nexperiments. The experiments confirm the importance of considering supply and\ndemand interactions and provide new insights to ridesharing operations. Results\nshow that increase of driver supply does not always increase matching option\naccept rate, and larger matching window could have negative impacts on overall\nridesharing success rate. These results emphasize the importance of a careful\nplanning of a ridesharing system.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.13463v2"
    },
    {
        "title": "Polynomial-Time Algorithms for Multi-Agent Minimal-Capacity Planning",
        "authors": [
            "Murat Cubuktepe",
            "František Blahoudek",
            "Ufuk Topcu"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We study the problem of minimizing the resource capacity of autonomous agents\ncooperating to achieve a shared task. More specifically, we consider high-level\nplanning for a team of homogeneous agents that operate under resource\nconstraints in stochastic environments and share a common goal: given a set of\ntarget locations, ensure that each location will be visited infinitely often by\nsome agent almost surely. We formalize the dynamics of agents by consumption\nMarkov decision processes. In a consumption Markov decision process, the agent\nhas a resource of limited capacity. Each action of the agent may consume some\namount of the resource. To avoid exhaustion, the agent can replenish its\nresource to full capacity in designated reload states. The resource capacity\nrestricts the capabilities of the agent. The objective is to assign target\nlocations to agents, and each agent is only responsible for visiting the\nassigned subset of target locations repeatedly. Moreover, the assignment must\nensure that the agents can carry out their tasks with minimal resource\ncapacity. We reduce the problem of finding target assignments for a team of\nagents with the lowest possible capacity to an equivalent graph-theoretical\nproblem. We develop an algorithm that solves this graph problem in time that is\n\\emph{polynomial} in the number of agents, target locations, and size of the\nconsumption Markov decision process. We demonstrate the applicability and\nscalability of the algorithm in a scenario where hundreds of unmanned\nunderwater vehicles monitor hundreds of locations in environments with\nstochastic ocean currents.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.01225v1"
    },
    {
        "title": "Calibration of Human Driving Behavior and Preference Using Naturalistic\n  Traffic Data",
        "authors": [
            "Qi Dai",
            "Di Shen",
            "Jinhong Wang",
            "Suzhou Huang",
            "Dimitar Filev"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Understanding human driving behaviors quantitatively is critical even in the\nera when connected and autonomous vehicles and smart infrastructure are\nbecoming ever more prevalent. This is particularly so as that mixed traffic\nsettings, where autonomous vehicles and human driven vehicles co-exist, are\nexpected to persist for quite some time. Towards this end it is necessary that\nwe have a comprehensive modeling framework for decision-making within which\nhuman driving preferences can be inferred statistically from observed driving\nbehaviors in realistic and naturalistic traffic settings. Leveraging a recently\nproposed computational framework for smart vehicles in a smart world using\nmulti-agent based simulation and optimization, we first recapitulate how the\nforward problem of driving decision-making is modeled as a state space model.\nWe then show how the model can be inverted to estimate driver preferences from\nnaturalistic traffic data using the standard Kalman filter technique. We\nexplicitly illustrate our approach using the vehicle trajectory data from\nSugiyama experiment that was originally meant to demonstrate how stop-and-go\nshockwave can arise spontaneously without bottlenecks. Not only the estimated\nstate filter can fit the observed data well for each individual vehicle, the\ninferred utility functions can also re-produce quantitatively similar pattern\nof the observed collective behaviors. One distinct advantage of our approach is\nthe drastically reduced computational burden. This is possible because our\nforward model treats driving decision process, which is intrinsically dynamic\nwith multi-agent interactions, as a sequence of independent static optimization\nproblems contingent on the state with a finite look ahead anticipation.\nConsequently we can practically sidestep solving an interacting dynamic\ninversion problem that would have been much more computationally demanding.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.01820v1"
    },
    {
        "title": "Scalable, Decentralized Multi-Agent Reinforcement Learning Methods\n  Inspired by Stigmergy and Ant Colonies",
        "authors": [
            "Austin Anhkhoi Nguyen"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Bolstering multi-agent learning algorithms to tackle complex coordination and\ncontrol tasks has been a long-standing challenge of on-going research. Numerous\nmethods have been proposed to help reduce the effects of non-stationarity and\nunscalability. In this work, we investigate a novel approach to decentralized\nmulti-agent learning and planning that attempts to address these two\nchallenges. In particular, this method is inspired by the cohesion,\ncoordination, and behavior of ant colonies. As a result, these algorithms are\ndesigned to be naturally scalable to systems with numerous agents. While no\noptimality is guaranteed, the method is intended to work well in practice and\nscale better in efficacy with the number of agents present than others. The\napproach combines single-agent RL and an ant-colony-inspired decentralized,\nstigmergic algorithm for multi-agent path planning and environment\nmodification. Specifically, we apply this algorithm in a setting where agents\nmust navigate to a goal location, learning to push rectangular boxes into holes\nto yield new traversable pathways. It is shown that while the approach yields\npromising success in this particular environment, it may not be as easily\ngeneralized to others. The algorithm designed is notably scalable to numerous\nagents but is limited in its performance due to its relatively simplistic,\nrule-based approach. Furthermore, the composability of RL-trained policies is\ncalled into question, where, while policies are successful in their training\nenvironments, applying trained policies to a larger-scale, multi-agent\nframework results in unpredictable behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.03546v1"
    },
    {
        "title": "SIDE: State Inference for Partially Observable Cooperative Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Yunpeng Bai",
            "Dapeng Li",
            "Bin Zhang",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  As one of the solutions to the decentralized partially observable Markov\ndecision process (Dec-POMDP) problems, the value decomposition method has\nachieved significant results recently. However, most value decomposition\nmethods require the fully observable state of the environment during training,\nbut this is not feasible in some scenarios where only incomplete and noisy\nobservations can be obtained. Therefore, we propose a novel value decomposition\nframework, named State Inference for value DEcomposition (SIDE), which\neliminates the need to know the global state by simultaneously seeking\nsolutions to the two problems of optimal control and state inference. SIDE can\nbe extended to any value decomposition method to tackle partially observable\nproblems. By comparing with the performance of different algorithms in\nStarCraft II micromanagement tasks, we verified that though without accessible\nstates, SIDE can infer the current state that contributes to the reinforcement\nlearning process based on past local observations and even achieve superior\nresults to many baselines in some complex scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.06228v2"
    },
    {
        "title": "How Can Robots Trust Each Other For Better Cooperation? A Relative Needs\n  Entropy Based Robot-Robot Trust Assessment Model",
        "authors": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Cooperation in multi-agent and multi-robot systems can help agents build\nvarious formations, shapes, and patterns presenting corresponding functions and\npurposes adapting to different situations. Relationships between agents such as\ntheir spatial proximity and functional similarities could play a crucial role\nin cooperation between agents. Trust level between agents is an essential\nfactor in evaluating their relationships' reliability and stability, much as\npeople do. This paper proposes a new model called Relative Needs Entropy (RNE)\nto assess trust between robotic agents. RNE measures the distance of needs\ndistribution between individual agents or groups of agents. To exemplify its\nutility, we implement and demonstrate our trust model through experiments\nsimulating a heterogeneous multi-robot grouping task in a persistent urban\nsearch and rescue mission consisting of tasks at two levels of difficulty. The\nresults suggest that RNE trust-Based grouping of robots can achieve better\nperformance and adaptability for diverse task execution compared to the\nstate-of-the-art energy-based or distance-based grouping models.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.07443v2"
    },
    {
        "title": "Attention-based Reinforcement Learning for Real-Time UAV Semantic\n  Communication",
        "authors": [
            "Won Joon Yun",
            "Byungju Lim",
            "Soyi Jung",
            "Young-Chai Ko",
            "Jihong Park",
            "Joongheon Kim",
            "Mehdi Bennis"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this article, we study the problem of air-to-ground ultra-reliable and\nlow-latency communication (URLLC) for a moving ground user. This is done by\ncontrolling multiple unmanned aerial vehicles (UAVs) in real time while\navoiding inter-UAV collisions. To this end, we propose a novel multi-agent deep\nreinforcement learning (MADRL) framework, coined a graph attention exchange\nnetwork (GAXNet). In GAXNet, each UAV constructs an attention graph locally\nmeasuring the level of attention to its neighboring UAVs, while exchanging the\nattention weights with other UAVs so as to reduce the attention mismatch\nbetween them. Simulation results corroborates that GAXNet achieves up to 4.5x\nhigher rewards during training. At execution, without incurring inter-UAV\ncollisions, GAXNet achieves 6.5x lower latency with the target 0.0000001 error\nrate, compared to a state-of-the-art baseline framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10716v1"
    },
    {
        "title": "Cooperative Multi-Agent Path Finding: Beyond Path Planning and Collision\n  Avoidance",
        "authors": [
            "Nir Greshler",
            "Ofir Gordon",
            "Oren Salzman",
            "Nahum Shimkin"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We introduce the Cooperative Multi-Agent Path Finding (Co-MAPF) problem, an\nextension to the classical MAPF problem, where cooperative behavior is\nincorporated. In this setting, a group of autonomous agents operate in a shared\nenvironment and have to complete cooperative tasks while avoiding collisions\nwith the other agents in the group. This extension naturally models many\nreal-world applications, where groups of agents are required to collaborate in\norder to complete a given task. To this end, we formalize the Co-MAPF problem\nand introduce Cooperative Conflict-Based Search (Co-CBS), a CBS-based algorithm\nfor solving the problem optimally for a wide set of Co-MAPF problems. Co-CBS\nuses a cooperation-planning module integrated into CBS such that cooperation\nplanning is decoupled from path planning. Finally, we present empirical results\non several MAPF benchmarks demonstrating our algorithm's properties.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.10993v1"
    },
    {
        "title": "Energy-aware optimization of UAV base stations placement via\n  decentralized multi-agent Q-learning",
        "authors": [
            "Babatunji Omoniwa",
            "Boris Galkin",
            "Ivana Dusparic"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be\ndeployed to provide wireless connectivity to ground devices in events of\nincreased network demand, points-of-failure in existing infrastructure, or\ndisasters. However, it is challenging to conserve the energy of UAVs during\nprolonged coverage tasks, considering their limited on-board battery capacity.\nReinforcement learning-based (RL) approaches have been previously used to\nimprove energy utilization of multiple UAVs, however, a central cloud\ncontroller is assumed to have complete knowledge of the end-devices' locations,\ni.e., the controller periodically scans and sends updates for UAV\ndecision-making. This assumption is impractical in dynamic network environments\nwith UAVs serving mobile ground devices. To address this problem, we propose a\ndecentralized Q-learning approach, where each UAV-BS is equipped with an\nautonomous agent that maximizes the connectivity of mobile ground devices while\nimproving its energy utilization. Experimental results show that the proposed\ndesign significantly outperforms the centralized approaches in jointly\nmaximizing the number of connected ground devices and the energy utilization of\nthe UAV-BSs.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.00845v2"
    },
    {
        "title": "Mission Level Uncertainty in Multi-Agent Resource Allocation",
        "authors": [
            "Rohit Konda",
            "Rahul Chandan",
            "Jason R. Marden"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In recent years, a significant research effort has been devoted to the design\nof distributed protocols for the control of multi-agent systems, as the scale\nand limited communication bandwidth characteristic of such systems render\ncentralized control impossible. Given the strict operating conditions, it is\nunlikely that every agent in a multi-agent system will have local information\nthat is consistent with the true system state. Yet, the majority of works in\nthe literature assume that agents share perfect knowledge of their environment.\nThis paper focuses on understanding the impact that inconsistencies in agents'\nlocal information can have on the performance of multi-agent systems. More\nspecifically, we consider the design of multi-agent operations under a game\ntheoretic lens where individual agents are assigned utilities that guide their\nlocal decision making. We provide a tractable procedure for designing utilities\nthat optimize the efficiency of the resulting collective behavior (i.e., price\nof anarchy) for classes of set covering games where the extent of the\ninformation inconsistencies is known. In the setting where the extent of the\ninformational inconsistencies is not known, we show -- perhaps surprisingly --\nthat underestimating the level of uncertainty leads to better price of anarchy\nthan overestimating it.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.04029v1"
    },
    {
        "title": "Incentivizing Efficient Equilibria in Traffic Networks with Mixed\n  Autonomy",
        "authors": [
            "Erdem Bıyık",
            "Daniel A. Lazar",
            "Ramtin Pedarsani",
            "Dorsa Sadigh"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Traffic congestion has large economic and social costs. The introduction of\nautonomous vehicles can potentially reduce this congestion by increasing road\ncapacity via vehicle platooning and by creating an avenue for influencing\npeople's choice of routes. We consider a network of parallel roads with two\nmodes of transportation: (i) human drivers, who will choose the quickest route\navailable to them, and (ii) a ride hailing service, which provides an array of\nautonomous vehicle route options, each with different prices, to users. We\nformalize a model of vehicle flow in mixed autonomy and a model of how\nautonomous service users make choices between routes with different prices and\nlatencies. Developing an algorithm to learn the preferences of the users, we\nformulate a planning optimization that chooses prices to maximize a social\nobjective. We demonstrate the benefit of the proposed scheme by comparing the\nresults to theoretical benchmarks which we show can be efficiently calculated.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.04678v1"
    },
    {
        "title": "A Game-Theoretic Approach to Multi-Agent Trust Region Optimization",
        "authors": [
            "Ying Wen",
            "Hui Chen",
            "Yaodong Yang",
            "Zheng Tian",
            "Minne Li",
            "Xu Chen",
            "Jun Wang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Trust region methods are widely applied in single-agent reinforcement\nlearning problems due to their monotonic performance-improvement guarantee at\nevery iteration. Nonetheless, when applied in multi-agent settings, the\nguarantee of trust region methods no longer holds because an agent's payoff is\nalso affected by other agents' adaptive behaviors. To tackle this problem, we\nconduct a game-theoretical analysis in the policy space, and propose a\nmulti-agent trust region learning method (MATRL), which enables trust region\noptimization for multi-agent learning. Specifically, MATRL finds a stable\nimprovement direction that is guided by the solution concept of Nash\nequilibrium at the meta-game level. We derive the monotonic improvement\nguarantee in multi-agent settings and empirically show the local convergence of\nMATRL to stable fixed points in the two-player rotational differential game. To\ntest our method, we evaluate MATRL in both discrete and continuous multiplayer\ngeneral-sum games including checker and switch grid worlds, multi-agent MuJoCo,\nand Atari games. Results suggest that MATRL significantly outperforms strong\nmulti-agent reinforcement learning baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.06828v1"
    },
    {
        "title": "Future urban mobility as a bio-inspired collaborative system of\n  multi-functional autonomous vehicles",
        "authors": [
            "Naroa Coretti Sánchez",
            "Juan Múgica González",
            "Luis Alonso Pastor",
            "Kent Larson"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The fast urbanization and climate change challenges require solutions that\nenable the efficient movement of people and goods in cities. We envision future\ncities to be composed of high-performing walkable districts where\ntransportation needs could be served by fleets of ultra-lightweight shared and\nautonomous vehicles. A future in which most vehicles would be autonomous\ncreates a new paradigm for the possible interactions between vehicles. Natural\nswarms are a great example of how rich interactions can be; they can divide\ntasks, cluster, build together, or transport cooperatively. The field of swarm\nrobotics has translated some of the behaviors from natural swarms to artificial\nsystems, proving to make systems more flexible, scalable, and robust. Inspired\nby nature and supported by swarm robotics, this paper proposes a future\nmobility in which shared, electric, and autonomous vehicles would be\nmulti-functional and behave as a collaborative system. In this future, fleets\nof multi-functional vehicles would complete different tasks collaboratively,\ngiving a response to the different urban mobility needs. This paper contributes\nwith the proposal of a framework for future urban mobility that integrates\ncurrent research and mobility trends in a novel and unique way.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.09543v2"
    },
    {
        "title": "Multi-Agent Curricula and Emergent Implicit Signaling",
        "authors": [
            "Niko A. Grupen",
            "Daniel D. Lee",
            "Bart Selman"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Emergent communication has made strides towards learning communication from\nscratch, but has focused primarily on protocols that resemble human language.\nIn nature, multi-agent cooperation gives rise to a wide range of communication\nthat varies in structure and complexity. In this work, we recognize the full\nspectrum of communication that exists in nature and propose studying\nlower-level communication. Specifically, we study emergent implicit signaling\nin the context of decentralized multi-agent learning in difficult, sparse\nreward environments. However, learning to coordinate in such environments is\nchallenging. We propose a curriculum-driven strategy that combines: (i)\nvelocity-based environment shaping, tailored to the skill level of the\nmulti-agent team; and (ii) a behavioral curriculum that helps agents learn\nsuccessful single-agent behaviors as a precursor to learning multi-agent\nbehaviors. Pursuit-evasion experiments show that our approach learns effective\ncoordination, significantly outperforming sophisticated analytical and learned\npolicies. Our method completes the pursuit-evasion task even when pursuers move\nat half of the evader's speed, whereas the highest-performing baseline fails at\n80% of the evader's speed. Moreover, we examine the use of implicit signals in\ncoordination through position-based social influence. We show that pursuers\ntrained with our strategy exchange more than twice as much information (in\nbits) than baseline methods, indicating that our method has learned, and relies\nheavily on, the exchange of implicit signals.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.11156v3"
    },
    {
        "title": "MMD-MIX: Value Function Factorisation with Maximum Mean Discrepancy for\n  Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Dapeng Li",
            "Yunpeng Bai",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In the real world, many tasks require multiple agents to cooperate with each\nother under the condition of local observations. To solve such problems, many\nmulti-agent reinforcement learning methods based on Centralized Training with\nDecentralized Execution have been proposed. One representative class of work is\nvalue decomposition, which decomposes the global joint Q-value $Q_\\text{jt}$\ninto individual Q-values $Q_a$ to guide individuals' behaviors, e.g. VDN\n(Value-Decomposition Networks) and QMIX. However, these baselines often ignore\nthe randomness in the situation. We propose MMD-MIX, a method that combines\ndistributional reinforcement learning and value decomposition to alleviate the\nabove weaknesses. Besides, to improve data sampling efficiency, we were\ninspired by REM (Random Ensemble Mixture) which is a robust RL algorithm to\nexplicitly introduce randomness into the MMD-MIX. The experiments demonstrate\nthat MMD-MIX outperforms prior baselines in the StarCraft Multi-Agent Challenge\n(SMAC) environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.11652v1"
    },
    {
        "title": "Traffic Signal Control with Communicative Deep Reinforcement Learning\n  Agents: a Case Study",
        "authors": [
            "Paolo Fazzini",
            "Isaac Wheeler",
            "Francesco Petracchini"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this work we analyze Multi-Agent Advantage Actor-Critic (MA2C) a recently\nproposed multi-agent reinforcement learning algorithm that can be applied to\nadaptive traffic signal control (ATSC) problems. To evaluate its potential we\ncompare MA2C with Independent Advantage Actor-Critic (IA2C) and other\nReinforcement Learning or heuristic based algorithms. Specifically, we analyze\nMA2C theoretically with the framework provided by non-Markov decision\nprocesses, which allows a deeper insight of the algorithm, and we critically\nexamine the effectiveness and the robustness of the method by testing it in two\ntraffic areas located in Bologna (Italy) simulated in SUMO, a software modeling\ntool for ATSC problems. Our results indicate that MA2C, trained with\npseudo-random vehicle flows, is a promising technique able to outperform the\nalternative methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.01347v4"
    },
    {
        "title": "Effects of Smart Traffic Signal Control on Air Quality",
        "authors": [
            "Paolo Fazzini",
            "Marco Torre",
            "Valeria Rizza",
            "Francesco Petracchini"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Adaptive traffic signal control (ATSC) in urban traffic networks poses a\nchallenging task due to the complicated dynamics arising in traffic systems. In\nrecent years, several approaches based on multi-agent deep reinforcement\nlearning (MARL) have been studied experimentally. These approaches propose\ndistributed techniques in which each signalized intersection is seen as an\nagent in a stochastic game whose purpose is to optimize the flow of vehicles in\nits vicinity. In this setting, the systems evolves towards an equilibrium among\nthe agents that shows beneficial for the whole traffic network. A recently\ndeveloped multi-agent variant of the well-established advantage actor-critic\n(A2C) algorithm, called MA2C (multi-agent A2C) exploits the promising idea of\nsome communication among the agents. In this view,the agents share their\nstrategies with other neighbor agents, thereby stabilizing the learning process\neven when the agents grow in number and variety. We experimented MA2C in two\ntraffic networks located in Bologna (Italy) and found that its action\ntranslates into a significant decrease of the amount of pollutants released\ninto the environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.02361v1"
    },
    {
        "title": "Intelligent Link Adaptation for Grant-Free Access Cellular Networks: A\n  Distributed Deep Reinforcement Learning Approach",
        "authors": [
            "Joao V. C. Evangelista",
            "Zeeshan Sattar",
            "Georges Kaddoum",
            "Bassant Selim",
            "Aydin Sarraf"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  With the continuous growth of machine-type devices (MTDs), it is expected\nthat massive machine-type communication (mMTC) will be the dominant form of\ntraffic in future wireless networks. Applications based on this technology,\nhave fundamentally different traffic characteristics from human-to-human (H2H)\ncommunication, which involves a relatively small number of devices transmitting\nlarge packets consistently. Conversely, in mMTC applications, a very large\nnumber of MTDs transmit small packets sporadically. Therefore, conventional\ngrant-based access schemes commonly adopted for H2H service, are not suitable\nfor mMTC, as they incur in a large overhead associated with the channel request\nprocedure. We propose three grant-free distributed optimization architectures\nthat are able to significantly minimize the average power consumption of the\nnetwork. The problem of physical layer (PHY) and medium access control (MAC)\noptimization in grant-free random access transmission is is modeled as a\npartially observable stochastic game (POSG) aimed at minimizing the average\ntransmit power under a per-device delay constraint. The results show that the\nproposed architectures are able to achieve significantly less average latency\nthan a baseline, while spending less power. Moreover, the proposed\narchitectures are more robust than the baseline, as they present less variance\nin the performance for different system realizations.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.04145v1"
    },
    {
        "title": "Learning-to-Dispatch: Reinforcement Learning Based Flight Planning under\n  Emergency",
        "authors": [
            "Kai Zhang",
            "Yupeng Yang",
            "Chengtao Xu",
            "Dahai Liu",
            "Houbing Song"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  The effectiveness of resource allocation under emergencies especially\nhurricane disasters is crucial. However, most researchers focus on emergency\nresource allocation in a ground transportation system. In this paper, we\npropose Learning-to-Dispatch (L2D), a reinforcement learning (RL) based air\nroute dispatching system, that aims to add additional flights for hurricane\nevacuation while minimizing the airspace's complexity and air traffic\ncontroller's workload. Given a bipartite graph with weights that are learned\nfrom the historical flight data using RL in consideration of short- and\nlong-term gains, we formulate the flight dispatch as an online maximum weight\nmatching problem. Different from the conventional order dispatch problem, there\nis no actual or estimated index that can evaluate how the additional evacuation\nflights influence the air traffic complexity. Then we propose a multivariate\nreward function in the learning phase and compare it with other univariate\nreward designs to show its superior performance. The experiments using the\nreal-world dataset for Hurricane Irma demonstrate the efficacy and efficiency\nof our proposed schema.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.04897v1"
    },
    {
        "title": "Improved Reinforcement Learning in Cooperative Multi-agent Environments\n  Using Knowledge Transfer",
        "authors": [
            "Mahnoosh Mahdavimoghaddam",
            "Amin Nikanjam",
            "Monireh Abdoos"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Nowadays, cooperative multi-agent systems are used to learn how to achieve\ngoals in large-scale dynamic environments. However, learning in these\nenvironments is challenging: from the effect of search space size on learning\ntime to inefficient cooperation among agents. Moreover, reinforcement learning\nalgorithms may suffer from a long time of convergence in such environments. In\nthis paper, a communication framework is introduced. In the proposed\ncommunication framework, agents learn to cooperate effectively and also by\nintroduction of a new state calculation method the size of state space will\ndecline considerably. Furthermore, a knowledge-transferring algorithm is\npresented to share the gained experiences among the different agents, and\ndevelop an effective knowledge-fusing mechanism to fuse the knowledge learnt\nutilizing the agents' own experiences with the knowledge received from other\nteam members. Finally, the simulation results are provided to indicate the\nefficacy of the proposed method in the complex learning task. We have evaluated\nour approach on the shepherding problem and the results show that the learning\nprocess accelerates by making use of the knowledge transferring mechanism and\nthe size of state space has declined by generating similar states based on\nstate abstraction concept.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.09807v5"
    },
    {
        "title": "Risk-Based Safety Envelopes for Autonomous Vehicles Under Perception\n  Uncertainty",
        "authors": [
            "Julian Bernhard",
            "Patrick Hart",
            "Amit Sahu",
            "Christoph Schöller",
            "Michell Guzman Cancimance"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Ensuring the safety of autonomous vehicles, given the uncertainty in sensing\nother road users, is an open problem. Moreover, separate safety specifications\nfor perception and planning components raise how to assess the overall system\nsafety. This work provides a probabilistic approach to calculate safety\nenvelopes under perception uncertainty. The probabilistic envelope definition\nis based on a risk threshold. It limits the cumulative probability that the\nactual safety envelope in a fully observable environment is larger than an\napplied envelope and is solved using iterative worst-case analysis of\nenvelopes. Our approach extends non-probabilistic envelopes - in this work, the\nResponsibility-Sensitive Safety (RSS) - to handle uncertainties. To evaluate\nour probabilistic envelope approach, we compare it in a simulated highway\nmerging scenario against several baseline safety architectures. Our evaluation\nshows that our model allows adjusting safety and performance based on a chosen\nrisk level and the amount of perception uncertainty. We conclude with an\noutline of how to formally argue safety under perception uncertainty using our\nformulation of envelope violation risk.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.09918v1"
    },
    {
        "title": "Resilient Distributed Averaging",
        "authors": [
            "Mostafa Safi",
            "Seyed Mehran Dibaji"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper, a fully distributed averaging algorithm in the presence of\nadversarial Byzantine agents is proposed. The algorithm is based on a resilient\nretrieval procedure, where all non-Byzantine nodes send their own initial\nvalues and retrieve those of other agents. We establish that the convergence of\nthe proposed algorithm relies on strong robustness of the graph for locally\nbounded adversaries. A topology analysis in terms of time complexity and\nrelation between connectivity metrics is also presented. Simulation results are\nprovided to verify the effectiveness of the proposed algorithms under\nprescribed graph conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.12450v1"
    },
    {
        "title": "Linear Quadratic Regulator Design for Multi-input Systems with A\n  Distributed Cooperative Strategy",
        "authors": [
            "Peihu Duan",
            "Lidong He",
            "Zhisheng Duan",
            "Ling Shi"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper, a cooperative Linear Quadratic Regulator (LQR) problem is\ninvestigated for multi-input systems, where each input is generated by an agent\nin a network. The input matrices are different and locally possessed by the\ncorresponding agents respectively, which can be regarded as different ways for\nagents to control the multi-input system. By embedding a fully distributed\ninformation fusion strategy, a novel cooperative LQR-based controller is\nproposed. Each agent only needs to communicate with its neighbors, rather than\nsharing information globally in a network. Moreover, only the joint\ncontrollability is required, which allows the multi-input system to be\nuncontrollable for every single agent or even all its neighbors. In particular,\nonly one-time information exchange is necessary at every control step, which\nsignificantly reduces the communication consumption. It is proved that the\nboundedness (convergence) of the controller gains is guaranteed for\ntime-varying (time-invariant) systems. Furthermore, the control performance of\nthe entire system is ensured. Generally, the proposed controller achieves a\nbetter trade-off between the control performance and the communication\noverhead, compared with the existing centralized/decentralized/consensus-based\nLQR controllers. Finally, the effectiveness of the theoretical results is\nillustrated by several comparative numerical examples.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.12596v2"
    },
    {
        "title": "Survey of Recent Multi-Agent Reinforcement Learning Algorithms Utilizing\n  Centralized Training",
        "authors": [
            "Piyush K. Sharma",
            "Rolando Fernandez",
            "Erin Zaroukian",
            "Michael Dorothy",
            "Anjon Basak",
            "Derrik E. Asher"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Much work has been dedicated to the exploration of Multi-Agent Reinforcement\nLearning (MARL) paradigms implementing a centralized learning with\ndecentralized execution (CLDE) approach to achieve human-like collaboration in\ncooperative tasks. Here, we discuss variations of centralized training and\ndescribe a recent survey of algorithmic approaches. The goal is to explore how\ndifferent implementations of information sharing mechanism in centralized\nlearning may give rise to distinct group coordinated behaviors in multi-agent\nsystems performing cooperative tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.14316v1"
    },
    {
        "title": "Screenline-based Two-step Calibration and its application to an\n  agent-based urban freight simulator",
        "authors": [
            "Yusuke Hara",
            "Takanori Sakai",
            "André Romano Alho",
            "Moshe Ben-Akiva"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Calibration is an essential process to make an agent-based simulator\noperational. Especially, the calibration for freight demand is challenging due\nto the model complexity and the shortage of available freight demand data\ncompared with passenger data. This paper proposes a novel calibration method\nthat relies solely on screenline counts, named Screenline-based Two-step\nCalibration (SLTC). SLTC consists of two parts: (1) tour-based demand\nadjustment and (2) model parameter updates. The former generates\nscreenline-based tours by cloning/removing instances of the simulated goods\nvehicle tours, aiming to minimize the gaps between the observed and the\nsimulated screenline counts. The latter updates the parameters of the commodity\nflow model which generates inputs to simulate goods vehicle tours. To\ndemonstrate the practicality of the proposed method, we apply it to an\nagent-based urban freight simulator, SimMobility Freight. The result shows that\nSLTC allows the simulator to replicate the observed screenline counts with\nreasonable computational cost for calibration.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.05995v1"
    },
    {
        "title": "DROP: Deep relocating option policy for optimal ride-hailing vehicle\n  repositioning",
        "authors": [
            "Xinwu Qian",
            "Shuocheng Guo",
            "Vaneet Aggarwal"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In a ride-hailing system, an optimal relocation of vacant vehicles can\nsignificantly reduce fleet idling time and balance the supply-demand\ndistribution, enhancing system efficiency and promoting driver satisfaction and\nretention. Model-free deep reinforcement learning (DRL) has been shown to\ndynamically learn the relocating policy by actively interacting with the\nintrinsic dynamics in large-scale ride-hailing systems. However, the issues of\nsparse reward signals and unbalanced demand and supply distribution place\ncritical barriers in developing effective DRL models. Conventional exploration\nstrategy (e.g., the $\\epsilon$-greedy) may barely work under such an\nenvironment because of dithering in low-demand regions distant from\nhigh-revenue regions. This study proposes the deep relocating option policy\n(DROP) that supervises vehicle agents to escape from oversupply areas and\neffectively relocate to potentially underserved areas. We propose to learn the\nLaplacian embedding of a time-expanded relocation graph, as an approximation\nrepresentation of the system relocation policy. The embedding generates\ntask-agnostic signals, which in combination with task-dependent signals,\nconstitute the pseudo-reward function for generating DROPs. We present a\nhierarchical learning framework that trains a high-level relocation policy and\na set of low-level DROPs. The effectiveness of our approach is demonstrated\nusing a custom-built high-fidelity simulator with real-world trip record data.\nWe report that DROP significantly improves baseline models with 15.7% more\nhourly revenue and can effectively resolve the dithering issue in low-demand\nareas.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.04149v1"
    },
    {
        "title": "Reactive and Safe Road User Simulations using Neural Barrier\n  Certificates",
        "authors": [
            "Yue Meng",
            "Zengyi Qin",
            "Chuchu Fan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Reactive and safe agent modelings are important for nowadays traffic\nsimulator designs and safe planning applications. In this work, we proposed a\nreactive agent model which can ensure safety without comprising the original\npurposes, by learning only high-level decisions from expert data and a\nlow-level decentralized controller guided by the jointly learned decentralized\nbarrier certificates. Empirical results show that our learned road user\nsimulation models can achieve a significant improvement in safety comparing to\nstate-of-the-art imitation learning and pure control-based methods, while being\nsimilar to human agents by having smaller errors to the expert data. Moreover,\nour learned reactive agents are shown to generalize better to unseen traffic\nconditions, and react better to other road users and therefore can help\nunderstand challenging planning problems pragmatically.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.06689v1"
    },
    {
        "title": "Emergence of Theory of Mind Collaboration in Multiagent Systems",
        "authors": [
            "Luyao Yuan",
            "Zipeng Fu",
            "Linqi Zhou",
            "Kexin Yang",
            "Song-Chun Zhu"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Currently, in the study of multiagent systems, the intentions of agents are\nusually ignored. Nonetheless, as pointed out by Theory of Mind (ToM), people\nregularly reason about other's mental states, including beliefs, goals, and\nintentions, to obtain performance advantage in competition, cooperation or\ncoalition. However, due to its intrinsic recursion and intractable modeling of\ndistribution over belief, integrating ToM in multiagent planning and decision\nmaking is still a challenge. In this paper, we incorporate ToM in multiagent\npartially observable Markov decision process (POMDP) and propose an adaptive\ntraining algorithm to develop effective collaboration between agents with ToM.\nWe evaluate our algorithms with two games, where our algorithm surpasses all\nprevious decentralized execution algorithms without modeling ToM.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.00121v1"
    },
    {
        "title": "Cooperative Multi-Agent Actor-Critic for Privacy-Preserving Load\n  Scheduling in a Residential Microgrid",
        "authors": [
            "Zhaoming Qin",
            "Nanqing Dong",
            "Eric P. Xing",
            "Junwei Cao"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  As a scalable data-driven approach, multi-agent reinforcement learning (MARL)\nhas made remarkable advances in solving the cooperative residential load\nscheduling problems. However, the common centralized training strategy of MARL\nalgorithms raises privacy risks for involved households. In this work, we\npropose a privacy-preserving multi-agent actor-critic framework where the\ndecentralized actors are trained with distributed critics, such that both the\ndecentralized execution and the distributed training do not require the global\nstate information. The proposed framework can preserve the privacy of the\nhouseholds while simultaneously learn the multi-agent credit assignment\nmechanism implicitly. The simulation experiments demonstrate that the proposed\nframework significantly outperforms the existing privacy-preserving\nactor-critic framework, and can achieve comparable performance to the\nstate-of-the-art actor-critic framework without privacy constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.02784v1"
    },
    {
        "title": "Towards a fully RL-based Market Simulator",
        "authors": [
            "Leo Ardon",
            "Nelson Vadori",
            "Thomas Spooner",
            "Mengda Xu",
            "Jared Vann",
            "Sumitra Ganesh"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We present a new financial framework where two families of RL-based agents\nrepresenting the Liquidity Providers and Liquidity Takers learn simultaneously\nto satisfy their objective. Thanks to a parametrized reward formulation and the\nuse of Deep RL, each group learns a shared policy able to generalize and\ninterpolate over a wide range of behaviors. This is a step towards a fully\nRL-based market simulator replicating complex market conditions particularly\nsuited to study the dynamics of the financial market under various scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.06829v2"
    },
    {
        "title": "HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with\n  Dual Coordination Mechanism",
        "authors": [
            "Zhiwei Xu",
            "Yunpeng Bai",
            "Bin Zhang",
            "Dapeng Li",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Recently, some challenging tasks in multi-agent systems have been solved by\nsome hierarchical reinforcement learning methods. Inspired by the intra-level\nand inter-level coordination in the human nervous system, we propose a novel\nvalue decomposition framework HAVEN based on hierarchical reinforcement\nlearning for fully cooperative multi-agent problems. To address the instability\narising from the concurrent optimization of policies between various levels and\nagents, we introduce the dual coordination mechanism of inter-level and\ninter-agent strategies by designing reward functions in a two-level hierarchy.\nHAVEN does not require domain knowledge and pre-training, and can be applied to\nany value decomposition variant. Our method achieves desirable results on\ndifferent decentralized partially observable Markov decision process domains\nand outperforms other popular multi-agent hierarchical reinforcement learning\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.07246v3"
    },
    {
        "title": "Analyzing the performance of distributed conflict resolution among\n  autonomous vehicles",
        "authors": [
            "Ítalo Romani de Oliveira"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper presents a study on how cooperation versus non-cooperation, and\ncentralization versus distribution impact the performance of a traffic game of\nautonomous vehicles. A model using a particle-based, Lagrange representation,\nis developed, instead of a Eulerian, flow-based one, usual in routing problems\nof the game-theoretical approach. This choice allows representation of\nphenomena such as fuel exhaustion, vehicle collision, and wave propagation. The\nelements necessary to represent interactions in a multi-agent transportation\nsystem are defined, including a distributed, priority-based resource allocation\nprotocol, where resources are nodes and links in a spatial network and\nindividual routing strategies are performed. A fuel consumption dynamics is\ndeveloped in order to account for energy cost and vehicles having limited\nrange. The analysis shows that only the scenarios with cooperative resource\nallocation can achieve optimal values of either collective cost or equity\ncoefficient, corresponding respectively to the centralized and to the\ndistributed cases.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08127v1"
    },
    {
        "title": "Simulation of emergence in artificial societies: a practical model-based\n  approach with the EB-DEVS formalism",
        "authors": [
            "Daniel Foguelman",
            "Esteban Lanzarotti",
            "Emanuel Ferreyra",
            "Rodrigo Castro"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Modelling and simulation of complex systems is key to exploring and\nunderstanding social processes, benefiting from formal mechanisms to derive\nglobal-level properties from local-level interactions. In this paper we extend\nthe body of knowledge on formal methods in complex systems by applying EB-DEVS,\na novel formalism tailored for the modelling, simulation and live\nidentification of emergent properties. We guide the reader through the\nimplementation of different classical models for varied social systems to\nintroduce good modelling practices and showcase the advantages and limitations\nof modelling emergence with EB-DEVS, in particular through its live emergence\ndetection capability. This work provides case study-driven evidence for the\nneatness and compactness of the approach to modelling communication structures\nthat can be explicit or implicit, static or dynamic, with or without multilevel\ninteractions, and with weak or strong emergent behaviour. Throughout examples\nwe show that EB-DEVS permits conceptualising the analysed societies by\nincorporating emergent behaviour when required, namely by integrating as a\nmacro-level aggregate the Gini index in the Sugarscape model, Fads and Fashion\nin the Dissemination of Culture model, size-biased degree distribution in a\nPreferential Attachment model, happiness index in the Segregation model and\nquarantines in the SIR epidemic model. In each example we discuss the role of\ncommunication structures in the development of multilevel simulation models,\nand illustrate how micro-macro feedback loops enable the modelling of\nmacro-level properties. Our results stress the relevance of multilevel features\nto support a robust approach in the modelling and simulation of complex\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08170v1"
    },
    {
        "title": "Self-aware Social Learning over Graphs",
        "authors": [
            "Konstantinos Ntemos",
            "Virginia Bordignon",
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper we study the problem of social learning under multiple true\nhypotheses and self-interested agents which exchange information over a graph.\nIn this setup, each agent receives data that might be generated from a\ndifferent hypothesis (or state) than the data other agents receive. In contrast\nto the related literature in social learning, which focuses on showing that the\nnetwork achieves consensus, here we study the case where every agent is\nself-interested and wants to find the hypothesis that generates its own\nobservations. However, agents do not know which ones of their peers wants to\nfind the same state with them and as a result they do not know which agents\nthey should cooperate with. To this end, we propose a scheme with adaptive\ncombination weights and study the consistency of the agents' learning process.\nThe scheme allows each agent to identify and collaborate with neighbors that\nobserve the same hypothesis, while excluding others, thus resulting in improved\nperformance compared to both non-cooperative learning and cooperative social\nlearning solutions. We analyze the asymptotic behavior of agents' beliefs under\nthe proposed social learning algorithm and provide sufficient conditions that\nenable all agents to correctly identify their true hypotheses. The theoretical\nanalysis is corroborated by numerical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.13292v1"
    },
    {
        "title": "ABIDES-Gym: Gym Environments for Multi-Agent Discrete Event Simulation\n  and Application to Financial Markets",
        "authors": [
            "Selim Amrouni",
            "Aymeric Moulin",
            "Jared Vann",
            "Svitlana Vyetrenko",
            "Tucker Balch",
            "Manuela Veloso"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Model-free Reinforcement Learning (RL) requires the ability to sample\ntrajectories by taking actions in the original problem environment or a\nsimulated version of it. Breakthroughs in the field of RL have been largely\nfacilitated by the development of dedicated open source simulators with easy to\nuse frameworks such as OpenAI Gym and its Atari environments. In this paper we\npropose to use the OpenAI Gym framework on discrete event time based Discrete\nEvent Multi-Agent Simulation (DEMAS). We introduce a general technique to wrap\na DEMAS simulator into the Gym framework. We expose the technique in detail and\nimplement it using the simulator ABIDES as a base. We apply this work by\nspecifically using the markets extension of ABIDES, ABIDES-Markets, and develop\ntwo benchmark financial markets OpenAI Gym environments for training daily\ninvestor and execution agents. As a result, these two environments describe\nclassic financial problems with a complex interactive market behavior response\nto the experimental agent's action.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.14771v1"
    },
    {
        "title": "Investigation of Independent Reinforcement Learning Algorithms in\n  Multi-Agent Environments",
        "authors": [
            "Ken Ming Lee",
            "Sriram Ganapathi Subramanian",
            "Mark Crowley"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Independent reinforcement learning algorithms have no theoretical guarantees\nfor finding the best policy in multi-agent settings. However, in practice,\nprior works have reported good performance with independent algorithms in some\ndomains and bad performance in others. Moreover, a comprehensive study of the\nstrengths and weaknesses of independent algorithms is lacking in the\nliterature. In this paper, we carry out an empirical comparison of the\nperformance of independent algorithms on four PettingZoo environments that span\nthe three main categories of multi-agent environments, i.e., cooperative,\ncompetitive, and mixed. We show that in fully-observable environments,\nindependent algorithms can perform on par with multi-agent algorithms in\ncooperative and competitive settings. For the mixed environments, we show that\nagents trained via independent algorithms learn to perform well individually,\nbut fail to learn to cooperate with allies and compete with enemies. We also\nshow that adding recurrence improves the learning of independent algorithms in\ncooperative partially observable environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.01100v1"
    },
    {
        "title": "ArchABM: an agent-based simulator of human interaction with the built\n  environment. $CO_2$ and viral load analysis for indoor air quality",
        "authors": [
            "Iñigo Martinez",
            "Jan L. Bruse",
            "Ane M. Florez-Tapia",
            "Elisabeth Viles",
            "Igor G. Olaizola"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Recent evidence suggests that SARS-CoV-2, which is the virus causing a global\npandemic in 2020, is predominantly transmitted via airborne aerosols in indoor\nenvironments. This calls for novel strategies when assessing and controlling a\nbuilding's indoor air quality (IAQ). IAQ can generally be controlled by\nventilation and/or policies to regulate human-building-interaction. However, in\na building, occupants use rooms in different ways, and it may not be obvious\nwhich measure or combination of measures leads to a cost- and energy-effective\nsolution ensuring good IAQ across the entire building. Therefore, in this\narticle, we introduce a novel agent-based simulator, ArchABM, designed to\nassist in creating new or adapt existing buildings by estimating adequate room\nsizes, ventilation parameters and testing the effect of policies while taking\ninto account IAQ as a result of complex human-building interaction patterns. A\nrecently published aerosol model was adapted to calculate time-dependent carbon\ndioxide ($CO_2$) and virus quanta concentrations in each room and inhaled\n$CO_2$ and virus quanta for each occupant over a day as a measure of\nphysiological response. ArchABM is flexible regarding the aerosol model and the\nbuilding layout due to its modular architecture, which allows implementing\nfurther models, any number and size of rooms, agents, and actions reflecting\nhuman-building interaction patterns. We present a use case based on a real\nfloor plan and working schedules adopted in our research center. This study\ndemonstrates how advanced simulation tools can contribute to improving IAQ\nacross a building, thereby ensuring a healthy indoor environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.01484v2"
    },
    {
        "title": "Posetal Games: Efficiency, Existence, and Refinement of Equilibria in\n  Games with Prioritized Metrics",
        "authors": [
            "Alessandro Zanardi",
            "Gioele Zardini",
            "Sirish Srinivasan",
            "Saverio Bolognani",
            "Andrea Censi",
            "Florian Dörfler",
            "Emilio Frazzoli"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Modern applications require robots to comply with multiple, often conflicting\nrules and to interact with the other agents. We present Posetal Games as a\nclass of games in which each player expresses a preference over the outcomes\nvia a partially ordered set of metrics. This allows one to combine hierarchical\npriorities of each player with the interactive nature of the environment. By\ncontextualizing standard game theoretical notions, we provide two sufficient\nconditions on the preference of the players to prove existence of pure Nash\nEquilibria in finite action sets. Moreover, we define formal operations on the\npreference structures and link them to a refinement of the game solutions,\nshowing how the set of equilibria can be systematically shrunk. The presented\nresults are showcased in a driving game where autonomous vehicles select from a\nfinite set of trajectories. The results demonstrate the interpretability of\nresults in terms of minimum-rank-violation for each player.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.07099v1"
    },
    {
        "title": "Improved cooperation by balancing exploration and exploitation in\n  intertemporal social dilemma tasks",
        "authors": [
            "Zhenbo Cheng",
            "Xingguang Liu",
            "Leilei Zhang",
            "Hangcheng Meng",
            "Qin Li",
            "Xiao Gang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  When an individual's behavior has rational characteristics, this may lead to\nirrational collective actions for the group. A wide range of organisms from\nanimals to humans often evolve the social attribute of cooperation to meet this\nchallenge. Therefore, cooperation among individuals is of great significance\nfor allowing social organisms to adapt to changes in the natural environment.\nBased on multi-agent reinforcement learning, we propose a new learning strategy\nfor achieving coordination by incorporating a learning rate that can balance\nexploration and exploitation. We demonstrate that agents that use the simple\nstrategy improve a relatively collective return in a decision task called the\nintertemporal social dilemma, where the conflict between the individual and the\ngroup is particularly sharp. We also explore the effects of the diversity of\nlearning rates on the population of reinforcement learning agents and show that\nagents trained in heterogeneous populations develop particularly coordinated\npolicies relative to those trained in homogeneous populations.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.09152v1"
    },
    {
        "title": "Execution Order Matters in Greedy Algorithms with Limited Information",
        "authors": [
            "Rohit Konda",
            "David Grimsman",
            "Jason Marden"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this work, we study the multi-agent decision problem where agents try to\ncoordinate to optimize a given system-level objective. While solving for the\nglobal optimal is intractable in many cases, the greedy algorithm is a\nwell-studied and efficient way to provide good approximate solutions - notably\nfor submodular optimization problems. Executing the greedy algorithm requires\nthe agents to be ordered and execute a local optimization based on the\nsolutions of the previous agents. However, in limited information settings,\npassing the solution from the previous agents may be nontrivial, as some agents\nmay not be able to directly communicate with each other. Thus the communication\ntime required to execute the greedy algorithm is closely tied to the order that\nthe agents are given. In this work, we characterize interplay between the\ncommunication complexity and agent orderings by showing that the complexity\nusing the best ordering is O(n) and increases considerably to O(n^2) when using\nthe worst ordering. Motivated by this, we also propose an algorithm that can\nfind an ordering and execute the greedy algorithm quickly, in a distributed\nfashion. We also show that such an execution of the greedy algorithm is\nadvantageous over current methods for distributed submodular maximization.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.09154v3"
    },
    {
        "title": "ToM2C: Target-oriented Multi-agent Communication and Cooperation with\n  Theory of Mind",
        "authors": [
            "Yuanfei Wang",
            "Fangwei Zhong",
            "Jing Xu",
            "Yizhou Wang"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Being able to predict the mental states of others is a key factor to\neffective social interaction. It is also crucial for distributed multi-agent\nsystems, where agents are required to communicate and cooperate. In this paper,\nwe introduce such an important social-cognitive skill, i.e. Theory of Mind\n(ToM), to build socially intelligent agents who are able to communicate and\ncooperate effectively to accomplish challenging tasks. With ToM, each agent is\ncapable of inferring the mental states and intentions of others according to\nits (local) observation. Based on the inferred states, the agents decide \"when\"\nand with \"whom\" to share their intentions. With the information observed,\ninferred, and received, the agents decide their sub-goals and reach a consensus\namong the team. In the end, the low-level executors independently take\nprimitive actions to accomplish the sub-goals. We demonstrate the idea in two\ntypical target-oriented multi-agent tasks: cooperative navigation and\nmulti-sensor target coverage. The experiments show that the proposed model not\nonly outperforms the state-of-the-art methods on reward and communication\nefficiency, but also shows good generalization across different scales of the\nenvironment.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.09189v2"
    },
    {
        "title": "Distributed Policy Gradient with Variance Reduction in Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Xiaoxiao Zhao",
            "Jinlong Lei",
            "Li Li",
            "Jie Chen"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  This paper studies a distributed policy gradient in collaborative multi-agent\nreinforcement learning (MARL), where agents over a communication network aim to\nfind the optimal policy to maximize the average of all agents' local returns.\nDue to the non-concave performance function of policy gradient, the existing\ndistributed stochastic optimization methods for convex problems cannot be\ndirectly used for policy gradient in MARL. This paper proposes a distributed\npolicy gradient with variance reduction and gradient tracking to address the\nhigh variances of policy gradient, and utilizes importance weight to solve the\n{distribution shift} problem in the sampling process. We then provide an upper\nbound on the mean-squared stationary gap, which depends on the number of\niterations, the mini-batch size, the epoch size, the problem parameters, and\nthe network topology. We further establish the sample and communication\ncomplexity to obtain an $\\epsilon$-approximate stationary point. Numerical\nexperiments are performed to validate the effectiveness of the proposed\nalgorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.12961v3"
    },
    {
        "title": "Evaluating Generalization and Transfer Capacity of Multi-Agent\n  Reinforcement Learning Across Variable Number of Agents",
        "authors": [
            "Bengisu Guresti",
            "Nazim Kemal Ure"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Multi-agent Reinforcement Learning (MARL) problems often require cooperation\namong agents in order to solve a task. Centralization and decentralization are\ntwo approaches used for cooperation in MARL. While fully decentralized methods\nare prone to converge to suboptimal solutions due to partial observability and\nnonstationarity, the methods involving centralization suffer from scalability\nlimitations and lazy agent problem. Centralized training decentralized\nexecution paradigm brings out the best of these two approaches; however,\ncentralized training still has an upper limit of scalability not only for\nacquired coordination performance but also for model size and training time. In\nthis work, we adopt the centralized training with decentralized execution\nparadigm and investigate the generalization and transfer capacity of the\ntrained models across variable number of agents. This capacity is assessed by\ntraining variable number of agents in a specific MARL problem and then\nperforming greedy evaluations with variable number of agents for each training\nconfiguration. Thus, we analyze the evaluation performance for each combination\nof agent count for training versus evaluation. We perform experimental\nevaluations on predator prey and traffic junction environments and demonstrate\nthat it is possible to obtain similar or higher evaluation performance by\ntraining with less agents. We conclude that optimal number of agents to perform\ntraining may differ from the target number of agents and argue that transfer\nacross large number of agents can be a more efficient solution to scaling up\nthan directly increasing number of agents during training.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.14177v1"
    },
    {
        "title": "How Can Creativity Occur in Multi-Agent Systems?",
        "authors": [
            "Ted Fujimoto"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Complex systems show how surprising and beautiful phenomena can emerge from\nstructures or agents following simple rules. With the recent success of deep\nreinforcement learning (RL), a natural path forward would be to use the\ncapabilities of multiple deep RL agents to produce emergent behavior of greater\nbenefit and sophistication. In general, this has proved to be an unreliable\nstrategy without significant computation due to the difficulties inherent in\nmulti-agent RL training. In this paper, we propose some criteria for creativity\nin multi-agent RL. We hope this proposal will give artists applying multi-agent\nRL a starting point, and provide a catalyst for further investigation guided by\nphilosophical discussion.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.14310v1"
    },
    {
        "title": "Multi-scale simulation of COVID-19 epidemics",
        "authors": [
            "Benoit Doussin",
            "Carole Adam",
            "Didier Georges"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Over a year after the start of the COVID-19 epidemics, we are still facing\nthe virus and it is hard to correctly predict its future spread over weeks to\ncome, as well as the impacts of potential political interventions. Current\nepidemic models mainly fall in two approaches: compartmental models, divide the\npopulation in epidemiological classes and rely on the mathematical resolution\nof differential equations to give a macroscopic view of the epidemical\ndynamics, allowing to evaluate its spread a posteriori; agent-based models are\ncomputer models that give a microscopic view of the situation, since each human\nis modelled as one autonomous agent, allowing to study the epidemical dynamics\nin relation to (heterogeneous) individual behaviours. In this work, we compared\nboth methodologies and combined them to try and take advantage of the benefits\nof each, and to overcome their limits. In particular, agent-based simulation\ncan be used to refine the values of the parameters of a compartmental model, or\nto predict how these values evolve depending on sanitary policies applied. In\nthis report we discuss the conditions of such a combination of approaches, and\nfuture improvements.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.01167v1"
    },
    {
        "title": "Learning Generalizable Multi-Lane Mixed-Autonomy Behaviors in Single\n  Lane Representations of Traffic",
        "authors": [
            "Abdul Rahman Kreidieh",
            "Yibo Zhao",
            "Samyak Parajuli",
            "Alexandre Bayen"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Reinforcement learning techniques can provide substantial insights into the\ndesired behaviors of future autonomous driving systems. By optimizing for\nsocietal metrics of traffic such as increased throughput and reduced energy\nconsumption, such methods can derive maneuvers that, if adopted by even a small\nportion of vehicles, may significantly improve the state of traffic for all\nvehicles involved. These methods, however, are hindered in practice by the\ndifficulty of designing efficient and accurate models of traffic, as well as\nthe challenges associated with optimizing for the behaviors of dozens of\ninteracting agents. In response to these challenges, this paper tackles the\nproblem of learning generalizable traffic control strategies in simple\nrepresentations of vehicle driving dynamics. In particular, we look to\nmixed-autonomy ring roads as depictions of instabilities that result in the\nformation of congestion. Within this problem, we design a curriculum learning\nparadigm that exploits the natural extendability of the network to effectively\nlearn behaviors that reduce congestion over long horizons. Next, we study the\nimplications of modeling lane changing on the transferability of policies. Our\nfindings suggest that introducing lane change behaviors that even approximately\nmatch trends in more complex systems can significantly improve the\ngeneralizability of subsequent learned models to more accurate multi-lane\nmodels of traffic.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.04688v2"
    },
    {
        "title": "PantheonRL: A MARL Library for Dynamic Training Interactions",
        "authors": [
            "Bidipta Sarkar",
            "Aditi Talati",
            "Andy Shih",
            "Dorsa Sadigh"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We present PantheonRL, a multiagent reinforcement learning software package\nfor dynamic training interactions such as round-robin, adaptive, and ad-hoc\ntraining. Our package is designed around flexible agent objects that can be\neasily configured to support different training interactions, and handles fully\ngeneral multiagent environments with mixed rewards and n agents. Built on top\nof StableBaselines3, our package works directly with existing powerful deep RL\nalgorithms. Finally, PantheonRL comes with an intuitive yet functional web user\ninterface for configuring experiments and launching multiple asynchronous jobs.\nOur package can be found at https://github.com/Stanford-ILIAD/PantheonRL.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.07013v1"
    },
    {
        "title": "Centralizing State-Values in Dueling Networks for Multi-Robot\n  Reinforcement Learning Mapless Navigation",
        "authors": [
            "Enrico Marchesini",
            "Alessandro Farinelli"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  We study the problem of multi-robot mapless navigation in the popular\nCentralized Training and Decentralized Execution (CTDE) paradigm. This problem\nis challenging when each robot considers its path without explicitly sharing\nobservations with other robots and can lead to non-stationary issues in Deep\nReinforcement Learning (DRL). The typical CTDE algorithm factorizes the joint\naction-value function into individual ones, to favor cooperation and achieve\ndecentralized execution. Such factorization involves constraints (e.g.,\nmonotonicity) that limit the emergence of novel behaviors in an individual as\neach agent is trained starting from a joint action-value. In contrast, we\npropose a novel architecture for CTDE that uses a centralized state-value\nnetwork to compute a joint state-value, which is used to inject global state\ninformation in the value-based updates of the agents. Consequently, each model\ncomputes its gradient update for the weights, considering the overall state of\nthe environment. Our idea follows the insights of Dueling Networks as a\nseparate estimation of the joint state-value has both the advantage of\nimproving sample efficiency, while providing each robot information whether the\nglobal state is (or is not) valuable. Experiments in a robotic navigation task\nwith 2 4, and 8 robots, confirm the superior performance of our approach over\nprior CTDE methods (e.g., VDN, QMIX).\n",
        "pdf_link": "http://arxiv.org/pdf/2112.09012v1"
    },
    {
        "title": "Handling Trust in A Cloud Based Multi Agent System",
        "authors": [
            "Imen Bouabdallah",
            "Hakima Mellah"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Cloud computing is an opened and distributed network that guarantees access\nto a large amount of data and IT infrastructure at several levels (software,\nhardware...). With the increase demand, handling clients' needs is getting\nincreasingly challenging. Responding to all requesting clients could lead to\nsecurity breaches, and since it is the provider's responsibility to secure not\nonly the offered cloud services but also the data, it is important to ensure\nclients reliability. Although filtering clients in the cloud is not so common,\nit is required to assure cloud safety.\n  In this paper, by implementing multi agent systems in the cloud to handle\ninteractions for the providers, trust is introduced at agent level to filtrate\nthe clients asking for services by using Particle Swarm Optimization and\nacquaintance knowledge to determine malicious and untrustworthy clients. The\nselection depends on previous knowledge and overall rating of trusted peers.\nThe conducted experiments show that the model outputs relevant results, and\neven with a small number of peers, the framework is able to converge to the\nbest solution. The model presented in this paper is a part of ongoing work to\nadapt interactions in the cloud.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.01807v2"
    },
    {
        "title": "Elephant-Human Conflict Mitigation: An Autonomous UAV Approach",
        "authors": [
            "Weiyun Jiang",
            "Yukai Yang",
            "Yogananda Isukapalli"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Elephant-human conflict (EHC) is one of the major problems in most African\nand Asian countries. As humans overutilize natural resources for their\ndevelopment, elephants' living area continues to decrease; this leads elephants\nto invade the human living area and raid crops more frequently, costing\nmillions of dollars annually. To mitigate EHC, in this paper, we propose an\noriginal solution that comprises of three parts: a compact custom low-power GPS\ntag that is installed on the elephants, a receiver stationed in the human\nliving area that detects the elephants' presence near a farm, and an autonomous\nunmanned aerial vehicle (UAV) system that tracks and herds the elephants away\nfrom the farms. By utilizing proportional-integral-derivative controller and\nmachine learning algorithms, we obtain accurate tracking trajectories at a\nreal-time processing speed of 32 FPS. Our proposed autonomous system can save\nover 68 % cost compared with human-controlled UAVs in mitigating EHC.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.02584v1"
    },
    {
        "title": "Resilient Consensus with Multi-hop Communication",
        "authors": [
            "Liwei Yuan",
            "Hideaki Ishii"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we study the problem of resilient consensus for a multi-agent\nnetwork where some of the nodes might be adversarial, attempting to prevent\nconsensus by transmitting faulty values. Our approach is based on that of the\nso-called weighted mean subsequence reduced (W-MSR) algorithm with a special\nemphasis on its use in agents capable to communicate with multi-hop neighbors.\nThe MSR algorithm is a powerful tool for achieving resilient consensus under\nminimal requirements for network structures, characterized by the class of\nrobust graphs. Our analysis highlights that through multi-hop communication,\nthe network connectivity can be reduced especially in comparison with the\ncommon one-hop communication case. Moreover, we analyze the multi-hop W-MSR\nalgorithm with delays in communication since the values from different\nmulti-hop neighbors may arrive at the agents at different time steps.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.03214v1"
    },
    {
        "title": "Agent-Temporal Attention for Reward Redistribution in Episodic\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Baicen Xiao",
            "Bhaskar Ramasubramanian",
            "Radha Poovendran"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper considers multi-agent reinforcement learning (MARL) tasks where\nagents receive a shared global reward at the end of an episode. The delayed\nnature of this reward affects the ability of the agents to assess the quality\nof their actions at intermediate time-steps. This paper focuses on developing\nmethods to learn a temporal redistribution of the episodic reward to obtain a\ndense reward signal. Solving such MARL problems requires addressing two\nchallenges: identifying (1) relative importance of states along the length of\nan episode (along time), and (2) relative importance of individual agents'\nstates at any single time-step (among agents). In this paper, we introduce\nAgent-Temporal Attention for Reward Redistribution in Episodic Multi-Agent\nReinforcement Learning (AREL) to address these two challenges. AREL uses\nattention mechanisms to characterize the influence of actions on state\ntransitions along trajectories (temporal attention), and how each agent is\naffected by other agents at each time-step (agent attention). The redistributed\nrewards predicted by AREL are dense, and can be integrated with any given MARL\nalgorithm. We evaluate AREL on challenging tasks from the Particle World\nenvironment and the StarCraft Multi-Agent Challenge. AREL results in higher\nrewards in Particle World, and improved win rates in StarCraft compared to\nthree state-of-the-art reward redistribution methods. Our code is available at\nhttps://github.com/baicenxiao/AREL.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.04612v1"
    },
    {
        "title": "Standby-Based Deadlock Avoidance Method for Multi-Agent Pickup and\n  Delivery Tasks",
        "authors": [
            "Tomoki Yamauchi",
            "Yuki Miyashita",
            "Toshiharu Sugawara"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The multi-agent pickup and delivery (MAPD) problem, in which multiple agents\niteratively carry materials without collisions, has received significant\nattention. However, many conventional MAPD algorithms assume a specifically\ndesigned grid-like environment, such as an automated warehouse. Therefore, they\nhave many pickup and delivery locations where agents can stay for a lengthy\nperiod, as well as plentiful detours to avoid collisions owing to the freedom\nof movement in a grid. By contrast, because a maze-like environment such as a\nsearch-and-rescue or construction site has fewer pickup/delivery locations and\ntheir numbers may be unbalanced, many agents concentrate on such locations\nresulting in inefficient operations, often becoming stuck or deadlocked. Thus,\nto improve the transportation efficiency even in a maze-like restricted\nenvironment, we propose a deadlock avoidance method, called standby-based\ndeadlock avoidance (SBDA). SBDA uses standby nodes determined in real-time\nusing the articulation-point-finding algorithm, and the agent is guaranteed to\nstay there for a finite amount of time. We demonstrated that our proposed\nmethod outperforms a conventional approach. We also analyzed how the parameters\nused for selecting standby nodes affect the performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06014v2"
    },
    {
        "title": "Structural Consensus in Networks with Directed Topologies and Its\n  Cryptographic Implementation",
        "authors": [
            "Wentuo Fang",
            "Zhiyong Chen",
            "Mohsen Zamani"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The existing cryptosystem based approaches for privacy-preserving consensus\nof networked systems are usually limited to those with undirected topologies.\nThis paper proposes a new privacy-preserving algorithm for networked systems\nwith directed topologies to reach confidential consensus. As a prerequisite for\napplying the algorithm, a structural consensus problem is formulated and the\nsolvability conditions are discussed for an explicitly constructed controller.\nThe controller is then implemented with encryption to achieve consensus while\navoiding individual's information leakage to external eavesdroppers and/or\nmalicious internal neighbors.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06747v1"
    },
    {
        "title": "Learning Multi-agent Skills for Tabular Reinforcement Learning using\n  Factor Graphs",
        "authors": [
            "Jiayu Chen",
            "Jingdi Chen",
            "Tian Lan",
            "Vaneet Aggarwal"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Covering skill (a.k.a., option) discovery has been developed to improve the\nexploration of reinforcement learning in single-agent scenarios with sparse\nreward signals, through connecting the most distant states in the embedding\nspace provided by the Fiedler vector of the state transition graph. However,\nthese option discovery methods cannot be directly extended to multi-agent\nscenarios, since the joint state space grows exponentially with the number of\nagents in the system. Thus, existing researches on adopting options in\nmulti-agent scenarios still rely on single-agent option discovery and fail to\ndirectly discover the joint options that can improve the connectivity of the\njoint state space of agents. In this paper, we show that it is indeed possible\nto directly compute multi-agent options with collaborative exploratory\nbehaviors among the agents, while still enjoying the ease of decomposition. Our\nkey idea is to approximate the joint state space as a Kronecker graph -- the\nKronecker product of individual agents' state transition graphs, based on which\nwe can directly estimate the Fiedler vector of the joint state space using the\nLaplacian spectrum of individual agents' transition graphs. This decomposition\nenables us to efficiently construct multi-agent joint options by encouraging\nagents to connect the sub-goal joint states which are corresponding to the\nminimum or maximum values of the estimated joint Fiedler vector. The evaluation\nbased on multi-agent collaborative tasks shows that the proposed algorithm can\nsuccessfully identify multi-agent options, and significantly outperforms prior\nworks using single-agent options or no options, in terms of both faster\nexploration and higher cumulative rewards.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.08227v3"
    },
    {
        "title": "Iterated Reasoning with Mutual Information in Cooperative and Byzantine\n  Decentralized Teaming",
        "authors": [
            "Sachin Konan",
            "Esmaeil Seraj",
            "Matthew Gombolay"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Information sharing is key in building team cognition and enables\ncoordination and cooperation. High-performing human teams also benefit from\nacting strategically with hierarchical levels of iterated communication and\nrationalizability, meaning a human agent can reason about the actions of their\nteammates in their decision-making. Yet, the majority of prior work in\nMulti-Agent Reinforcement Learning (MARL) does not support iterated\nrationalizability and only encourage inter-agent communication, resulting in a\nsuboptimal equilibrium cooperation strategy. In this work, we show that\nreformulating an agent's policy to be conditional on the policies of its\nneighboring teammates inherently maximizes Mutual Information (MI) lower-bound\nwhen optimizing under Policy Gradient (PG). Building on the idea of\ndecision-making under bounded rationality and cognitive hierarchy theory, we\nshow that our modified PG approach not only maximizes local agent rewards but\nalso implicitly reasons about MI between agents without the need for any\nexplicit ad-hoc regularization terms. Our approach, InfoPG, outperforms\nbaselines in learning emergent collaborative behaviors and sets the\nstate-of-the-art in decentralized cooperative MARL tasks. Our experiments\nvalidate the utility of InfoPG by achieving higher sample efficiency and\nsignificantly larger cumulative reward in several complex cooperative\nmulti-agent domains.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.08484v4"
    },
    {
        "title": "Multi-Agent Adversarial Attacks for Multi-Channel Communications",
        "authors": [
            "Juncheng Dong",
            "Suya Wu",
            "Mohammadreza Sultani",
            "Vahid Tarokh"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Recently Reinforcement Learning (RL) has been applied as an anti-adversarial\nremedy in wireless communication networks. However, studying the RL-based\napproaches from the adversary's perspective has received little attention.\nAdditionally, RL-based approaches in an anti-adversary or adversarial paradigm\nmostly consider single-channel communication (either channel selection or\nsingle channel power control), while multi-channel communication is more common\nin practice. In this paper, we propose a multi-agent adversary system (MAAS)\nfor modeling and analyzing adversaries in a wireless communication scenario by\ncareful design of the reward function under realistic communication scenarios.\nIn particular, by modeling the adversaries as learning agents, we show that the\nproposed MAAS is able to successfully choose the transmitted channel(s) and\ntheir respective allocated power(s) without any prior knowledge of the sender\nstrategy. Compared to the single-agent adversary (SAA), multi-agents in MAAS\ncan achieve significant reduction in signal-to-noise ratio (SINR) under the\nsame power constraints and partial observability, while providing improved\nstability and a more efficient learning process. Moreover, through empirical\nstudies we show that the results in simulation are close to the ones in\ncommunication in reality, a conclusion that is pivotal to the validity of\nperformance of agents evaluated in simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.09149v2"
    },
    {
        "title": "CTRMs: Learning to Construct Cooperative Timed Roadmaps for Multi-agent\n  Path Planning in Continuous Spaces",
        "authors": [
            "Keisuke Okumura",
            "Ryo Yonetani",
            "Mai Nishimura",
            "Asako Kanezaki"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent path planning (MAPP) in continuous spaces is a challenging\nproblem with significant practical importance. One promising approach is to\nfirst construct graphs approximating the spaces, called roadmaps, and then\napply multi-agent pathfinding (MAPF) algorithms to derive a set of\nconflict-free paths. While conventional studies have utilized roadmap\nconstruction methods developed for single-agent planning, it remains largely\nunexplored how we can construct roadmaps that work effectively for multiple\nagents. To this end, we propose a novel concept of roadmaps called cooperative\ntimed roadmaps (CTRMs). CTRMs enable each agent to focus on its important\nlocations around potential solution paths in a way that considers the behavior\nof other agents to avoid inter-agent collisions (i.e., \"cooperative\"), while\nbeing augmented in the time direction to make it easy to derive a \"timed\"\nsolution path. To construct CTRMs, we developed a machine-learning approach\nthat learns a generative model from a collection of relevant problem instances\nand plausible solutions and then uses the learned model to sample the vertices\nof CTRMs for new, previously unseen problem instances. Our empirical evaluation\nrevealed that the use of CTRMs significantly reduced the planning effort with\nacceptable overheads while maintaining a success rate and solution quality\ncomparable to conventional roadmap construction approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.09467v1"
    },
    {
        "title": "Multidimensional Manhattan Preferences",
        "authors": [
            "Jiehua Chen",
            "Martin Nöllenburg",
            "Sofia Simola",
            "Anaïs Villedieu",
            "Markus Wallinger"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  A preference profile with $m$ alternatives and $n$ voters is $d$-Manhattan\n(resp. $d$-Euclidean) if both the alternatives and the voters can be placed\ninto the $d$-dimensional space such that between each pair of alternatives,\nevery voter prefers the one which has a shorter Manhattan (resp. Euclidean)\ndistance to the voter. Following Bogomolnaia and Laslier [Journal of\nMathematical Economics, 2007] and Chen and Grottke [Social Choice and Welfare,\n2021] who look at $d$-Euclidean preference profiles, we study which preference\nprofiles are $d$-Manhattan depending on the values $m$ and $n$.\n  First, we show that each preference profile with $m$ alternatives and $n$\nvoters is $d$-Manhattan whenever $d$ $\\geq$ min($n$, $m$-$1$). Second, for $d =\n2$, we show that the smallest non $d$-Manhattan preference profile has either\nthree voters and six alternatives, or four voters and five alternatives, or\nfive voters and four alternatives. This is more complex than the case with\n$d$-Euclidean preferences (see [Bogomolnaia and Laslier, 2007] and [Bulteau and\nChen, 2020].\n",
        "pdf_link": "http://arxiv.org/pdf/2201.09691v1"
    },
    {
        "title": "Social Learning under Randomized Collaborations",
        "authors": [
            "Yunus Inan",
            "Mert Kayaalp",
            "Emre Telatar",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We study a social learning scheme where at every time instant, each agent\nchooses to receive information from one of its neighbors at random. We show\nthat under this sparser communication scheme, the agents learn the truth\neventually and the asymptotic convergence rate remains the same as the standard\nalgorithms which use more communication resources. We also derive large\ndeviation estimates of the log-belief ratios for a special case where each\nagent replaces its belief with that of the chosen neighbor.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.10957v2"
    },
    {
        "title": "Leveraging Experience in Lifelong Multi-Agent Pathfinding",
        "authors": [
            "Nitzan Madar",
            "Kiril Solovey",
            "Oren Salzman"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In Lifelong Multi-Agent Path Finding (L-MAPF) a team of agents performs a\nstream of tasks consisting of multiple locations to be visited by the agents on\na shared graph while avoiding collisions with one another. L-MAPF is typically\ntackled by partitioning it into multiple consecutive, and hence similar,\n\"one-shot\" MAPF queries, as in the Rolling-Horizon Collision Resolution (RHCR)\nalgorithm. Therefore, a solution to one query informs the next query, which\nleads to similarity with respect to the agents' start and goal positions, and\nhow collisions need to be resolved from one query to the next. Thus, experience\nfrom solving one MAPF query can potentially be used to speedup solving the next\none. Despite this intuition, current L-MAPF planners solve consecutive MAPF\nqueries from scratch. In this paper, we introduce a new RHCR-inspired approach\ncalled exRHCR, which exploits experience in its constituent MAPF queries. In\nparticular, exRHCR employs an extension of Priority-Based Search (PBS), a\nstate-of-the-art MAPF solver. The extension, which we call exPBS, allows to\nwarm-start the search with the priorities between agents used by PBS in the\nprevious MAPF instances. We demonstrate empirically that exRHCR solves L-MAPF\ninstances up to 39% faster than RHCR, and has the potential to increase system\nthroughput for given task streams by increasing the number of agents a planner\ncan cope with for a given time budget.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.04382v3"
    },
    {
        "title": "A Reliability-aware Distributed Framework to Schedule Residential\n  Charging of Electric Vehicles",
        "authors": [
            "Rounak Meyur",
            "Swapna Thorve",
            "Madhav Marathe",
            "Anil Vullikanti",
            "Samarth Swarup",
            "Henning Mortveit"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Residential consumers have become active participants in the power\ndistribution network after being equipped with residential EV charging\nprovisions. This creates a challenge for the network operator tasked with\ndispatching electric power to the residential consumers through the existing\ndistribution network infrastructure in a reliable manner. In this paper, we\naddress the problem of scheduling residential EV charging for multiple\nconsumers while maintaining network reliability. An additional challenge is the\nrestricted exchange of information: where the consumers do not have access to\nnetwork information and the network operator does not have access to consumer\nload parameters. We propose a distributed framework which generates an optimal\nEV charging schedule for individual residential consumers based on their\npreferences and iteratively updates it until the network reliability\nconstraints set by the operator are satisfied. We validate the proposed\napproach for different EV adoption levels in a synthetically created digital\ntwin of an actual power distribution network. The results demonstrate that the\nnew approach can achieve a higher level of network reliability compared to the\ncase where residential consumers charge EVs based solely on their individual\npreferences, thus providing a solution for the existing grid to keep up with\nincreased adoption rates without significant investments in increasing grid\ncapacity.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.07092v1"
    },
    {
        "title": "Provably Private Distributed Averaging Consensus: An\n  Information-Theoretic Approach",
        "authors": [
            "Mohammad Fereydounian",
            "Aryan Mokhtari",
            "Ramtin Pedarsani",
            "Hamed Hassani"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this work, we focus on solving a decentralized consensus problem in a\nprivate manner. Specifically, we consider a setting in which a group of nodes,\nconnected through a network, aim at computing the mean of their local values\nwithout revealing those values to each other. The distributed consensus problem\nis a classic problem that has been extensively studied and its convergence\ncharacteristics are well-known. Alas, state-of-the-art consensus methods build\non the idea of exchanging local information with neighboring nodes which leaks\ninformation about the users' local values. We propose an algorithmic framework\nthat is capable of achieving the convergence limit and rate of classic\nconsensus algorithms while keeping the users' local values private. The key\nidea of our proposed method is to carefully design noisy messages that are\npassed from each node to its neighbors such that the consensus algorithm still\nconverges precisely to the average of local values, while a minimum amount of\ninformation about local values is leaked. We formalize this by precisely\ncharacterizing the mutual information between the private message of a node and\nall the messages that another adversary collects over time. We prove that our\nmethod is capable of preserving users' privacy for any network without a\nso-called \"generalized leaf\", and formalize the trade-off between privacy and\nconvergence time. Unlike many private algorithms, any desired accuracy is\nachievable by our method, and the required level of privacy only affects the\nconvergence time.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09398v1"
    },
    {
        "title": "Shaping Advice in Deep Reinforcement Learning",
        "authors": [
            "Baicen Xiao",
            "Bhaskar Ramasubramanian",
            "Radha Poovendran"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Reinforcement learning involves agents interacting with an environment to\ncomplete tasks. When rewards provided by the environment are sparse, agents may\nnot receive immediate feedback on the quality of actions that they take,\nthereby affecting learning of policies. In this paper, we propose to methods to\naugment the reward signal from the environment with an additional reward termed\nshaping advice in both single and multi-agent reinforcement learning. The\nshaping advice is specified as a difference of potential functions at\nconsecutive time-steps. Each potential function is a function of observations\nand actions of the agents. The use of potential functions is underpinned by an\ninsight that the total potential when starting from any state and returning to\nthe same state is always equal to zero. We show through theoretical analyses\nand experimental validation that the shaping advice does not distract agents\nfrom completing tasks specified by the environment reward. Theoretically, we\nprove that the convergence of policy gradients and value functions when using\nshaping advice implies the convergence of these quantities in the absence of\nshaping advice. We design two algorithms- Shaping Advice in Single-agent\nreinforcement learning (SAS) and Shaping Advice in Multi-agent reinforcement\nlearning (SAM). Shaping advice in SAS and SAM needs to be specified only once\nat the start of training, and can easily be provided by non-experts.\nExperimentally, we evaluate SAS and SAM on two tasks in single-agent\nenvironments and three tasks in multi-agent environments that have sparse\nrewards. We observe that using shaping advice results in agents learning\npolicies to complete tasks faster, and obtain higher rewards than algorithms\nthat do not use shaping advice.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09489v1"
    },
    {
        "title": "The Role of Heterogeneity in Autonomous Perimeter Defense Problems",
        "authors": [
            "Aviv Adler",
            "Oscar Mickelin",
            "Ragesh K. Ramachandran",
            "Gaurav S. Sukhatme",
            "Sertac Karaman"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  When is heterogeneity in the composition of an autonomous robotic team\nbeneficial and when is it detrimental? We investigate and answer this question\nin the context of a minimally viable model that examines the role of\nheterogeneous speeds in perimeter defense problems, where defenders share a\ntotal allocated speed budget. We consider two distinct problem settings and\ndevelop strategies based on dynamic programming and on local interaction rules.\nWe present a theoretical analysis of both approaches and our results are\nextensively validated using simulations. Interestingly, our results demonstrate\nthat the viability of heterogeneous teams depends on the amount of information\navailable to the defenders. Moreover, our results suggest a universality\nproperty: across a wide range of problem parameters the optimal ratio of the\nspeeds of the defenders remains nearly constant.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10433v1"
    },
    {
        "title": "Hierarchical Control for Head-to-Head Autonomous Racing",
        "authors": [
            "Rishabh Saumil Thakkar",
            "Aryaman Singh Samyal",
            "David Fridovich-Keil",
            "Zhe Xu",
            "Ufuk Topcu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We develop a hierarchical controller for head-to-head autonomous racing. We\nfirst introduce a formulation of a racing game with realistic safety and\nfairness rules. A high-level planner approximates the original formulation as a\ndiscrete game with simplified state, control, and dynamics to easily encode the\ncomplex safety and fairness rules and calculates a series of target waypoints.\nThe low-level controller takes the resulting waypoints as a reference\ntrajectory and computes high-resolution control inputs by solving an\nalternative formulation approximation with simplified objectives and\nconstraints. We consider two approaches for the low-level planner, constructing\ntwo hierarchical controllers. One approach uses multi-agent reinforcement\nlearning (MARL), and the other solves a linear-quadratic Nash game (LQNG) to\nproduce control inputs. The controllers are compared against three baselines:\nan end-to-end MARL controller, a MARL controller tracking a fixed racing line,\nand an LQNG controller tracking a fixed racing line. Quantitative results show\nthat the proposed hierarchical methods outperform their respective baseline\nmethods in terms of head-to-head race wins and abiding by the rules. The\nhierarchical controller using MARL for low-level control consistently\noutperformed all other methods by winning over 90% of head-to-head races and\nmore consistently adhered to the complex racing rules. Qualitatively, we\nobserve the proposed controllers mimicking actions performed by expert human\ndrivers such as shielding/blocking, overtaking, and long-term planning for\ndelayed advantages. We show that hierarchical planning for game-theoretic\nreasoning produces competitive behavior even when challenged with complex rules\nand constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.12861v6"
    },
    {
        "title": "Computational Experiments: Past, Present and Future",
        "authors": [
            "Xiao Xue",
            "Xiang-Ning Yu",
            "De-Yu Zhou",
            "Xiao Wang",
            "Zhang-Bin Zhou",
            "Fei-Yue Wang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Powered by advanced information technology, more and more complex systems are\nexhibiting characteristics of the Cyber-Physical-Social Systems (CPSS).\nUnderstanding the mechanism of CPSS is essential to our ability to control\ntheir actions, reap their benefits and minimize their harms. In consideration\nof the cost, legal and institutional constraints on the study of CPSS in real\nworld, computational experiments have emerged as a new method for quantitative\nanalysis of CPSS. This paper outlines computational experiments from several\nkey aspects, including origin, characteristics, methodological framework, key\ntechnologies, and some typical applications. Finally, this paper highlights\nsome challenges of computational experiments to provide a roadmap for its rapid\ndevelopment and widespread application.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.13690v1"
    },
    {
        "title": "SMA-NBO: A Sequential Multi-Agent Planning with Nominal Belief-State\n  Optimization in Target Tracking",
        "authors": [
            "Tianqi Li",
            "Lucas W. Krakow",
            "Swaminathan Gopalswamy"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In target tracking with mobile multi-sensor systems, sensor deployment\nimpacts the observation capabilities and the resulting state estimation\nquality. Based on a partially observable Markov decision process (POMDP)\nformulation comprised of the observable sensor dynamics, unobservable target\nstates, and accompanying observation laws, we present a distributed\ninformation-driven solution approach to the multi-agent target tracking\nproblem, namely, sequential multi-agent nominal belief-state optimization\n(SMA-NBO). SMA-NBO seeks to minimize the expected tracking error via receding\nhorizon control including a heuristic expected cost-to-go (HECTG). SMA-NBO\nincorporates a computationally efficient approximation of the target\nbelief-state over the horizon. The agent-by-agent decision-making is capable of\nleveraging on-board (edge) compute for selecting (sub-optimal) target-tracking\nmaneuvers exhibiting non-myopic cooperative fleet behavior. The optimization\nproblem explicitly incorporates semantic information defining target occlusions\nfrom a world model. To illustrate the efficacy of our approach, a random\nocclusion forest environment is simulated. SMA-NBO is compared to other\nbaseline approaches. The simulation results show SMA-NBO 1) maintains tracking\nperformance and reduces the computational cost by replacing the calculation of\nthe expected target trajectory with a single sample trajectory based on maximum\na posteriori estimation; 2) generates cooperative fleet decision by\nsequentially optimizing single-agent policy with efficient usage of other\nagents' policy of intent; 3) aptly incorporates the multiple weighted trace\npenalty (MWTP) HECTG, which improves tracking performance with a\ncomputationally efficient heuristic.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.01507v1"
    },
    {
        "title": "Machine Learning Simulates Agent-Based Model Towards Policy",
        "authors": [
            "Bernardo Alves Furtado",
            "Gustavo Onofre Andreão"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Public Policies are not intrinsically positive or negative. Rather, policies\nprovide varying levels of effects across different recipients.\nMethodologically, computational modeling enables the application of multiple\ninfluences on empirical data, thus allowing for heterogeneous response to\npolicies. We use a random forest machine learning algorithm to emulate an\nagent-based model (ABM) and evaluate competing policies across 46 Metropolitan\nRegions (MRs) in Brazil. In doing so, we use input parameters and output\nindicators of 11,076 actual simulation runs and one million emulated runs. As a\nresult, we obtain the optimal (and non-optimal) performance of each region over\nthe policies. Optimum is defined as a combination of GDP production and the\nGini coefficient inequality indicator for the full ensemble of Metropolitan\nRegions. Results suggest that MRs already have embedded structures that favor\noptimal or non-optimal results, but they also illustrate which policy is more\nbeneficial to each place. In addition to providing MR-specific policies'\nresults, the use of machine learning to simulate an ABM reduces the\ncomputational burden, whereas allowing for a much larger variation among model\nparameters. The coherence of results within the context of larger\nuncertainty--vis-\\`a-vis those of the original ABM--reinforces robustness of\nthe model. At the same time the exercise indicates which parameters should\npolicymakers intervene on, in order to work towards precise policy optimal\ninstruments.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.02576v2"
    },
    {
        "title": "Cooperative Trajectory Planning in Uncertain Environments with Monte\n  Carlo Tree Search and Risk Metrics",
        "authors": [
            "Philipp Stegmaier",
            "Karl Kurzer",
            "J. Marius Zöllner"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Automated vehicles require the ability to cooperate with humans for smooth\nintegration into today's traffic. While the concept of cooperation is well\nknown, developing a robust and efficient cooperative trajectory planning method\nis still a challenge. One aspect of this challenge is the uncertainty\nsurrounding the state of the environment due to limited sensor accuracy. This\nuncertainty can be represented by a Partially Observable Markov Decision\nProcess. Our work addresses this problem by extending an existing cooperative\ntrajectory planning approach based on Monte Carlo Tree Search for continuous\naction spaces. It does so by explicitly modeling uncertainties in the form of a\nroot belief state, from which start states for trees are sampled. After the\ntrees have been constructed with Monte Carlo Tree Search, their results are\naggregated into return distributions using kernel regression. We apply two risk\nmetrics for the final selection, namely a Lower Confidence Bound and a\nConditional Value at Risk. It can be demonstrated that the integration of risk\nmetrics in the final selection policy consistently outperforms a baseline in\nuncertain environments, generating considerably safer trajectories.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.04452v3"
    },
    {
        "title": "Refined Hardness of Distance-Optimal Multi-Agent Path Finding",
        "authors": [
            "Tzvika Geft",
            "Dan Halperin"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We study the computational complexity of multi-agent path finding (MAPF).\nGiven a graph $G$ and a set of agents, each having a start and target vertex,\nthe goal is to find collision-free paths minimizing the total distance\ntraveled. To better understand the source of difficulty of the problem, we aim\nto study the simplest and least constrained graph class for which it remains\nhard. To this end, we restrict $G$ to be a 2D grid, which is a ubiquitous\nabstraction, as it conveniently allows for modeling well-structured\nenvironments (e.g., warehouses). Previous hardness results considered highly\nconstrained 2D grids having only one vertex unoccupied by an agent, while the\nmost restricted hardness result that allowed multiple empty vertices was for\n(non-grid) planar graphs. We therefore refine previous results by\nsimultaneously considering both 2D grids and multiple empty vertices. We show\nthat even in this case distance-optimal MAPF remains NP-hard, which settles an\nopen problem posed by Banfi et al. (2017). We present a reduction directly from\n3-SAT using simple gadgets, making our proof arguably more informative than\nprevious work in terms of potential progress towards positive results.\nFurthermore, our reduction is the first linear one for the case where $G$ is\nplanar, appearing nearly four decades after the first related result. This\nallows us to go a step further and exploit the Exponential Time Hypothesis\n(ETH) to obtain an exponential lower bound for the running time of the problem.\nFinally, as a stepping stone towards our main results, we prove the NP-hardness\nof the monotone case, in which agents move one by one with no intermediate\nstops.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.07416v1"
    },
    {
        "title": "Model-based Multi-agent Reinforcement Learning: Recent Progress and\n  Prospects",
        "authors": [
            "Xihuai Wang",
            "Zhicheng Zhang",
            "Weinan Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Significant advances have recently been achieved in Multi-Agent Reinforcement\nLearning (MARL) which tackles sequential decision-making problems involving\nmultiple participants. However, MARL requires a tremendous number of samples\nfor effective training. On the other hand, model-based methods have been shown\nto achieve provable advantages of sample efficiency. However, the attempts of\nmodel-based methods to MARL have just started very recently. This paper\npresents a review of the existing research on model-based MARL, including\ntheoretical analyses, algorithms, and applications, and analyzes the advantages\nand potential of model-based MARL. Specifically, we provide a detailed taxonomy\nof the algorithms and point out the pros and cons for each algorithm according\nto the challenges inherent to multi-agent scenarios. We also outline promising\ndirections for future development of this field.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.10603v1"
    },
    {
        "title": "Collaborative Intelligent Reflecting Surface Networks with Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Jie Zhang",
            "Jun Li",
            "Yijin Zhang",
            "Qingqing Wu",
            "Xiongwei Wu",
            "Feng Shu",
            "Shi Jin",
            "Wen Chen"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Intelligent reflecting surface (IRS) is envisioned to be widely applied in\nfuture wireless networks. In this paper, we investigate a multi-user\ncommunication system assisted by cooperative IRS devices with the capability of\nenergy harvesting. Aiming to maximize the long-term average achievable system\nrate, an optimization problem is formulated by jointly designing the transmit\nbeamforming at the base station (BS) and discrete phase shift beamforming at\nthe IRSs, with the constraints on transmit power, user data rate requirement\nand IRS energy buffer size. Considering time-varying channels and stochastic\narrivals of energy harvested by the IRSs, we first formulate the problem as a\nMarkov decision process (MDP) and then develop a novel multi-agent Q-mix (MAQ)\nframework with two layers to decouple the optimization parameters. The higher\nlayer is for optimizing phase shift resolutions, and the lower one is for phase\nshift beamforming and power allocation. Since the phase shift optimization is\nan integer programming problem with a large-scale action space, we improve MAQ\nby incorporating the Wolpertinger method, namely, MAQ-WP algorithm to achieve a\nsub-optimality with reduced dimensions of action space. In addition, as MAQ-WP\nis still of high complexity to achieve good performance, we propose a policy\ngradient-based MAQ algorithm, namely, MAQ-PG, by mapping the discrete phase\nshift actions into a continuous space at the cost of a slight performance loss.\nSimulation results demonstrate that the proposed MAQ-WP and MAQ-PG algorithms\ncan converge faster and achieve data rate improvements of 10.7% and 8.8% over\nthe conventional multi-agent DDPG, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.14152v1"
    },
    {
        "title": "Fusing Interpretable Knowledge of Neural Network Learning Agents For\n  Swarm-Guidance",
        "authors": [
            "Duy Tung Nguyen",
            "Kathryn Kasmarik",
            "Hussein Abbass"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Neural-based learning agents make decisions using internal artificial neural\nnetworks. In certain situations, it becomes pertinent that this knowledge is\nre-interpreted in a friendly form to both the human and the machine. These\nsituations include: when agents are required to communicate the knowledge they\nlearn to each other in a transparent way in the presence of an external human\nobserver, in human-machine teaming settings where humans and machines need to\ncollaborate on a task, or where there is a requirement to verify the knowledge\nexchanged between the agents. We propose an interpretable knowledge fusion\nframework suited for neural-based learning agents, and propose a Priority on\nWeak State Areas (PoWSA) retraining technique. We first test the proposed\nframework on a synthetic binary classification task before evaluating it on a\nshepherding-based multi-agent swarm guidance task. Results demonstrate that the\nproposed framework increases the success rate on the swarm-guidance environment\nby 11% and better stability in return for a modest increase in computational\ncost of 14.5% to achieve interpretability. Moreover, the framework presents the\nknowledge learnt by an agent in a human-friendly representation, leading to a\nbetter descriptive visual representation of an agent's knowledge.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.00272v1"
    },
    {
        "title": "Robust Event-Driven Interactions in Cooperative Multi-Agent Learning",
        "authors": [
            "Daniel Jarne Ornia",
            "Manuel Mazo Jr"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We present an approach to reduce the communication required between agents in\na Multi-Agent learning system by exploiting the inherent robustness of the\nunderlying Markov Decision Process. We compute so-called robustness surrogate\nfunctions (off-line), that give agents a conservative indication of how far\ntheir state measurements can deviate before they need to update other agents in\nthe system. This results in fully distributed decision functions, enabling\nagents to decide when it is necessary to update others. We derive bounds on the\noptimality of the resulting systems in terms of the discounted sum of rewards\nobtained, and show these bounds are a function of the design parameters.\nAdditionally, we extend the results for the case where the robustness surrogate\nfunctions are learned from data, and present experimental results demonstrating\na significant reduction in communication events between agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.03361v2"
    },
    {
        "title": "Towards Comprehensive Testing on the Robustness of Cooperative\n  Multi-agent Reinforcement Learning",
        "authors": [
            "Jun Guo",
            "Yonghong Chen",
            "Yihang Hao",
            "Zixin Yin",
            "Yin Yu",
            "Simin Li"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  While deep neural networks (DNNs) have strengthened the performance of\ncooperative multi-agent reinforcement learning (c-MARL), the agent policy can\nbe easily perturbed by adversarial examples. Considering the safety critical\napplications of c-MARL, such as traffic management, power management and\nunmanned aerial vehicle control, it is crucial to test the robustness of c-MARL\nalgorithm before it was deployed in reality. Existing adversarial attacks for\nMARL could be used for testing, but is limited to one robustness aspects (e.g.,\nreward, state, action), while c-MARL model could be attacked from any aspect.\nTo overcome the challenge, we propose MARLSafe, the first robustness testing\nframework for c-MARL algorithms. First, motivated by Markov Decision Process\n(MDP), MARLSafe consider the robustness of c-MARL algorithms comprehensively\nfrom three aspects, namely state robustness, action robustness and reward\nrobustness. Any c-MARL algorithm must simultaneously satisfy these robustness\naspects to be considered secure. Second, due to the scarceness of c-MARL\nattack, we propose c-MARL attacks as robustness testing algorithms from\nmultiple aspects. Experiments on \\textit{SMAC} environment reveals that many\nstate-of-the-art c-MARL algorithms are of low robustness in all aspect,\npointing out the urgent need to test and enhance robustness of c-MARL\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.07932v1"
    },
    {
        "title": "Event-triggered Approximate Byzantine Consensus with Multi-hop\n  Communication",
        "authors": [
            "Liwei Yuan",
            "Hideaki Ishii"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we consider a resilient consensus problem for the multi-agent\nnetwork where some of the agents are subject to Byzantine attacks and may\ntransmit erroneous state values to their neighbors. In particular, we develop\nan event-triggered update rule to tackle this problem as well as reduce the\ncommunication for each agent. Our approach is based on the mean subsequence\nreduced (MSR) algorithm with agents being capable to communicate with multi-hop\nneighbors. Since delays are critical in such an environment, we provide\nnecessary graph conditions for the proposed algorithm to perform well with\ndelays in the communication. We highlight that through multi-hop communication,\nthe network connectivity can be reduced especially in comparison with the\ncommon onehop communication case. Lastly, we show the effectiveness of the\nproposed algorithm by a numerical example.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.08883v1"
    },
    {
        "title": "Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Dapeng Li",
            "Bin Zhang",
            "Yuan Zhan",
            "Yunpeng Bai",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Recently, model-based agents have achieved better performance than model-free\nones using the same computational budget and training time in single-agent\nenvironments. However, due to the complexity of multi-agent systems, it is\ntough to learn the model of the environment. The significant compounding error\nmay hinder the learning process when model-based methods are applied to\nmulti-agent tasks. This paper proposes an implicit model-based multi-agent\nreinforcement learning method based on value decomposition methods. Under this\nmethod, agents can interact with the learned virtual environment and evaluate\nthe current state value according to imagined future states in the latent\nspace, making agents have the foresight. Our approach can be applied to any\nmulti-agent value decomposition method. The experimental results show that our\nmethod improves the sample efficiency in different partially observable Markov\ndecision process domains.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.09418v3"
    },
    {
        "title": "PP-MARL: Efficient Privacy-Preserving MARL for Cooperative Intelligence\n  in Communication",
        "authors": [
            "Tingting Yuan",
            "Hwei-Ming Chung",
            "Xiaoming Fu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Artificial intelligence (AI) has been introduced in communication networks\nand services to improve efficiency via self-optimization. Cooperative\nintelligence (CI), also known as collective intelligence and collaborative\nintelligence, is expected to become an integral element in next-generation\nnetworks because it can aggregate the capabilities and intelligence of multiple\ndevices. However, privacy issues may intimidate, obstruct, and hinder the\ndeployment of CI in practice because collaboration heavily relies on data and\ninformation sharing. Additional practical constraints in communication (e.g.,\nlimited bandwidth) further limit the performance of CI. To overcome these\nchallenges, we propose PP-MARL, an efficient privacy-preserving learning scheme\nbased on multi-agent reinforcement learning (MARL). We apply and evaluate our\nscheme in two communication-related use cases: mobility management in\ndrone-assisted communication and network control with edge intelligence.\nSimulation results reveal that the proposed scheme can achieve efficient and\nreliable collaboration with 1.1-6 times better privacy protection and lower\noverheads (e.g., 84-91% reduction in bandwidth) than state-of-the-art\napproaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.12064v1"
    },
    {
        "title": "Dynamic Noises of Multi-Agent Environments Can Improve Generalization:\n  Agent-based Models meets Reinforcement Learning",
        "authors": [
            "Mohamed Akrout",
            "Amal Feriani",
            "Bob McLeod"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We study the benefits of reinforcement learning (RL) environments based on\nagent-based models (ABM). While ABMs are known to offer microfoundational\nsimulations at the cost of computational complexity, we empirically show in\nthis work that their non-deterministic dynamics can improve the generalization\nof RL agents. To this end, we examine the control of an epidemic SIR\nenvironments based on either differential equations or ABMs. Numerical\nsimulations demonstrate that the intrinsic noise in the ABM-based dynamics of\nthe SIR model not only improve the average reward but also allow the RL agent\nto generalize on a wider ranges of epidemic parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.14076v1"
    },
    {
        "title": "Hierarchical Decompositions of Stochastic Pursuit-Evasion Games",
        "authors": [
            "Yue Guan",
            "Mohammad Afshari",
            "Qifan Zhang",
            "Panagiotis Tsiotras"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this work we present a hierarchical framework for solving discrete\nstochastic pursuit-evasion games (PEGs) in large grid worlds. With a partition\nof the grid world into superstates (e.g., \"rooms\"), the proposed approach\ncreates a two-resolution decision-making process, which consists of a set of\nlocal PEGs at the original state level and an aggregated PEG at the superstate\nlevel. Having much smaller cardinality, both the local games and the aggregated\ngame can be easily solved to a Nash equilibrium. To connect the decision-making\nat the two resolutions, we use the Nash values of the local PEGs as the rewards\nfor the aggregated game. Through numerical simulations, we show that the\nproposed hierarchical framework significantly reduces the computation overhead,\nwhile still maintaining a satisfactory level of performance when competing\nagainst the flat Nash policies.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.00885v2"
    },
    {
        "title": "Autonomy and Intelligence in the Computing Continuum: Challenges,\n  Enablers, and Future Directions for Orchestration",
        "authors": [
            "Henna Kokkonen",
            "Lauri Lovén",
            "Naser Hossein Motlagh",
            "Abhishek Kumar",
            "Juha Partala",
            "Tri Nguyen",
            "Víctor Casamayor Pujol",
            "Panos Kostakos",
            "Teemu Leppänen",
            "Alfonso González-Gil",
            "Ester Sola",
            "Iñigo Angulo",
            "Madhusanka Liyanage",
            "Mehdi Bennis",
            "Sasu Tarkoma",
            "Schahram Dustdar",
            "Susanna Pirttikangas",
            "Jukka Riekki"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Future AI applications require performance, reliability and privacy that the\nexisting, cloud-dependant system architectures cannot provide. In this article,\nwe study orchestration in the device-edge-cloud continuum, and focus on edge AI\nfor resource orchestration. We claim that to support the constantly growing\nrequirements of intelligent applications in the device-edge-cloud computing\ncontinuum, resource orchestration needs to embrace edge AI and emphasize local\nautonomy and intelligence. To justify the claim, we provide a general\ndefinition for continuum orchestration, and look at how current and emerging\norchestration paradigms are suitable for the computing continuum. We describe\ncertain major emerging research themes that may affect future orchestration,\nand provide an early vision of an orchestration paradigm that embraces those\nresearch themes. Finally, we survey current key edge AI methods and look at how\nthey may contribute into fulfilling the vision of future continuum\norchestration.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.01423v3"
    },
    {
        "title": "Competition and Cooperation of Autonomous Ridepooling Services:\n  Game-Based Simulation of a Broker Concept",
        "authors": [
            "Roman Engelhardt",
            "Patrick Malcolm",
            "Florian Dandl",
            "Klaus Bogenberger"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Autonomous mobility on demand services have the potential to disrupt the\nfuture mobility system landscape. Ridepooling services in particular can\ndecrease land consumption and increase transportation efficiency by increasing\nthe average vehicle occupancy. Nevertheless, because ridepooling services\nrequire a sufficient user base for pooling to take effect, their performance\ncan suffer if multiple operators offer such a service and must split the\ndemand. This study presents a simulation framework for evaluating the impact of\ncompetition and cooperation among multiple ridepooling providers. Two different\nkinds of interaction via a broker platform are compared with the base cases of\na single monopolistic operator and two independent operators with divided\ndemand. In the first, the broker presents trip offers from all operators to\ncustomers (similar to a mobility-as-a-service platform), who can then freely\nchoose an operator. In the second, a regulated broker platform can manipulate\noperator offers with the goal of shifting the customer-operator assignment from\na user equilibrium towards a system optimum. To model adoptions of the service\ndesign depending on the different interaction scenario, a game setting is\nintroduced. Within alternating turns between operators, operators can adapt\nparameters of their service (fleet size and objective function) to maximize\nprofit. Results for a case study based on Manhattan taxi data, show that\noperators generate the highest profit in the broker setting while operating the\nlargest fleet. Additionally, pooling efficiency can nearly be maintained\ncompared to a single operator. With the resulting increased service rate, the\nregulated competition benefits not only operators (profit) and cities\n(increased pooling efficiency), but also customers. Contrarily, when users can\ndecide freely, the lowest pooling efficiency and operator profit is observed.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04319v1"
    },
    {
        "title": "A Realistic Cyclist Model for SUMO Based on the SimRa Dataset",
        "authors": [
            "Ahmet-Serdar Karakaya",
            "Konstantin Köhler",
            "Julian Heinovski",
            "Falko Dressler",
            "David Bermbach"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Increasing the modal share of bicycle traffic to reduce carbon emissions,\nreduce urban car traffic, and to improve the health of citizens, requires a\nshift away from car-centric city planning. For this, traffic planners often\nrely on simulation tools such as SUMO which allow them to study the effects of\nconstruction changes before implementing them. Similarly, studies of vulnerable\nroad users, here cyclists, also use such models to assess the performance of\ncommunication-based road traffic safety systems. The cyclist model in SUMO,\nhowever, is very imprecise as SUMO cyclists behave either like slow cars or\nfast pedestrians, thus, casting doubt on simulation results for bicycle\ntraffic. In this paper, we analyze acceleration, velocity, and intersection\nleft-turn behavior of cyclists in a large dataset of real world cycle tracks.\nWe use the results to derive an improved cyclist model and implement it in\nSUMO.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04538v1"
    },
    {
        "title": "Informed Steiner Trees: Sampling and Pruning for Multi-Goal Path Finding\n  in High Dimensions",
        "authors": [
            "Nikhil Chandak",
            "Kenny Chour",
            "Sivakumar Rathinam",
            "R. Ravi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We interleave sampling based motion planning methods with pruning ideas from\nminimum spanning tree algorithms to develop a new approach for solving a\nMulti-Goal Path Finding (MGPF) problem in high dimensional spaces. The approach\nalternates between sampling points from selected regions in the search space\nand de-emphasizing regions that may not lead to good solutions for MGPF. Our\napproach provides an asymptotic, 2-approximation guarantee for MGPF. We also\npresent extensive numerical results to illustrate the advantages of our\nproposed approach over uniform sampling in terms of the quality of the\nsolutions found and computation speed.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04548v1"
    },
    {
        "title": "Integrating Parcel Deliveries into a Ride-Pooling Service -- An\n  Agent-Based Simulation Study",
        "authors": [
            "Fabian Fehn",
            "Roman Engelhardt",
            "Florian Dandl",
            "Klaus Bogenberger",
            "Fritz Busch"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper examines the integration of freight delivery into the passenger\ntransport of an on-demand ride-pooling service. The goal of this research is to\nuse existing passenger trips for logistics services and thus reduce additional\nvehicle kilometers for freight delivery and the total number of vehicles on the\nroad network. This is achieved by merging the need for two separate fleets into\na single one by combining the services. To evaluate the potential of such a\nmobility-on-demand service, this paper uses an agent-based simulation framework\nand integrates three heuristic parcel assignment strategies into a ride-pooling\nfleet control algorithm. Two integration scenarios (moderate and full) are set\nup. While in both scenarios passengers and parcels share rides in one vehicle,\nin the moderate scenario no stops for parcel pick-up and delivery are allowed\nduring a passenger ride to decrease customer inconvenience. Using real-world\ndemand data for a case study of Munich, Germany, the two integration scenarios\ntogether with the three assignment strategies are compared to the status quo,\nwhich uses two separate vehicle fleets for passenger and logistics transport.\nThe results indicate that the integration of logistics services into a\nride-pooling service is possible and can exploit unused system capacities\nwithout deteriorating passenger transport. Depending on the assignment\nstrategies nearly all parcels can be served until a parcel to passenger demand\nratio of 1:10 while the overall fleet kilometers can be deceased compared to\nthe status quo.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04718v1"
    },
    {
        "title": "Environmental Sensing Options for Robot Teams: A Computational\n  Complexity Perspective",
        "authors": [
            "Todd Wareham",
            "Andrew Vardy"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Visual and scalar-field (e.g., chemical) sensing are two of the options robot\nteams can use to perceive their environments when performing tasks. We give the\nfirst comparison of the computational characteristic of visual and scalar-field\nsensing, phrased in terms of the computational complexities of verifying and\ndesigning teams of robots to efficiently and robustly perform distributed\nconstruction tasks. This is done relative a basic model in which teams of\nrobots with deterministic finite-state controllers operate in a synchronous\nerror-free manner in 2D grid-based environments. Our results show that for both\ntypes of sensing, all of our problems are polynomial-time intractable in\ngeneral and remain intractable under a variety of restrictions on parameters\ncharacterizing robot controllers, teams, and environments. That being said,\nthese results also include restricted situations for each of our problems in\nwhich those problems are effectively polynomial-time tractable. Though there\nare some differences, our results suggest that (at least in this stage of our\ninvestigation) verification and design problems relative to visual and\nscalar-field sensing have roughly the same patterns and types of tractability\nand intractability results.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.05034v1"
    },
    {
        "title": "Centralized Model-Predictive Control with Human-Driver Interaction for\n  Platooning",
        "authors": [
            "Justin M. Kennedy",
            "Julian Heinovski",
            "Daniel E. Quevedo",
            "Falko Dressler"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Cooperative adaptive cruise control presents an opportunity to improve road\ntransportation through increase in road capacity and reduction in energy use\nand accidents. Clever design of control algorithms and communication systems is\nrequired to ensure that the vehicle platoon is stable and meets desired safety\nrequirements. In this paper, we propose a centralized model predictive\ncontroller for a heterogeneous platoon of vehicles to reach a desired platoon\nvelocity and individual inter-vehicle distances with driver-selected headway\ntime. As a novel concept, we allow for interruption from a human driver in the\nplatoon that temporarily takes control of their vehicle with the assumption\nthat the driver will, at minimum, obey legal velocity limits and the physical\nperformance constraints of their vehicle. The finite horizon cost function of\nour proposed platoon controller is inspired from the infinite horizon design.\nTo the best of our knowledge, this is the first platoon controller that\nintegrates human-driven vehicles. We illustrate the performance of our proposed\ndesign with a numerical study, demonstrating that the safety distance,\nvelocity, and actuation constraints are obeyed. Additionally, in simulation we\nillustrate a key property of string stability where the impact of a disturbance\nis reduced through the platoon.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.09259v5"
    },
    {
        "title": "Correct by Design Coordination of Autonomous Driving Systems",
        "authors": [
            "Marius Bozga",
            "Joseph Sifakis"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The paper proposes a method for the correct by design coordination of\nautonomous driving systems (ADS). It builds on previous results on collision\navoidance policies and the modeling of ADS by combining descriptions of their\nstatic environment in the form of maps, and the dynamic behavior of their\nvehicles. An ADS is modeled as a dynamic system involving a set of vehicles\ncoordinated by a Runtime that based on vehicle positions on a map and their\nkinetic attributes, computes free spaces for each vehicle. Vehicles are bounded\nto move within the corresponding allocated free spaces. We provide a correct by\ndesign safe control policy for an ADS if its vehicles and the Runtime respect\ncorresponding assume-guarantee contracts. The result is established by showing\nthat the composition of assume-guarantee contracts is an inductive invariant\nthat entails ADS safety. We show that it is practically possible to define\nspeed control policies for vehicles that comply with their contracts.\nFurthermore, we show that traffic rules can be specified in a linear-time\ntemporal logic, as a class of formulas that constrain vehicle speeds. The main\nresult is that, given a set of traffic rules, it is possible to derive free\nspace policies of the Runtime such that the resulting system behavior is safe\nby design with respect to the rules.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.10037v1"
    },
    {
        "title": "Trust-based Consensus in Multi-Agent Reinforcement Learning Systems",
        "authors": [
            "Ho Long Fung",
            "Victor-Alexandru Darvariu",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  An often neglected issue in multi-agent reinforcement learning (MARL) is the\npotential presence of unreliable agents in the environment whose deviations\nfrom expected behavior can prevent a system from accomplishing its intended\ntasks. In particular, consensus is a fundamental underpinning problem of\ncooperative distributed multi-agent systems. Consensus requires different\nagents, situated in a decentralized communication network, to reach an\nagreement out of a set of initial proposals that they put forward.\nLearning-based agents should adopt a protocol that allows them to reach\nconsensus despite having one or more unreliable agents in the system. This\npaper investigates the problem of unreliable agents in MARL, considering\nconsensus as a case study. Echoing established results in the distributed\nsystems literature, our experiments show that even a moderate fraction of such\nagents can greatly impact the ability of reaching consensus in a networked\nenvironment. We propose Reinforcement Learning-based Trusted Consensus (RLTC),\na decentralized trust mechanism, in which agents can independently decide which\nneighbors to communicate with. We empirically demonstrate that our trust\nmechanism is able to handle unreliable agents effectively, as evidenced by\nhigher consensus success rates.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.12880v2"
    },
    {
        "title": "Off-Beat Multi-Agent Reinforcement Learning",
        "authors": [
            "Wei Qiu",
            "Weixun Wang",
            "Rundong Wang",
            "Bo An",
            "Yujing Hu",
            "Svetlana Obraztsova",
            "Zinovi Rabinovich",
            "Jianye Hao",
            "Yingfeng Chen",
            "Changjie Fan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We investigate model-free multi-agent reinforcement learning (MARL) in\nenvironments where off-beat actions are prevalent, i.e., all actions have\npre-set execution durations. During execution durations, the environment\nchanges are influenced by, but not synchronised with, action execution. Such a\nsetting is ubiquitous in many real-world problems. However, most MARL methods\nassume actions are executed immediately after inference, which is often\nunrealistic and can lead to catastrophic failure for multi-agent coordination\nwith off-beat actions. In order to fill this gap, we develop an algorithmic\nframework for MARL with off-beat actions. We then propose a novel episodic\nmemory, LeGEM, for model-free MARL algorithms. LeGEM builds agents' episodic\nmemories by utilizing agents' individual experiences. It boosts multi-agent\nlearning by addressing the challenging temporal credit assignment problem\nraised by the off-beat actions via our novel reward redistribution scheme,\nalleviating the issue of non-Markovian reward. We evaluate LeGEM on various\nmulti-agent scenarios with off-beat actions, including Stag-Hunter Game, Quarry\nGame, Afforestation Game, and StarCraft II micromanagement tasks. Empirical\nresults show that LeGEM significantly boosts multi-agent coordination and\nachieves leading performance and improved sample efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.13718v2"
    },
    {
        "title": "Deep Learning-based Spatially Explicit Emulation of an Agent-Based\n  Simulator for Pandemic in a City",
        "authors": [
            "Varun Madhavan",
            "Adway Mitra",
            "Partha Pratim Chakrabarti"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Agent-Based Models are very useful for simulation of physical or social\nprocesses, such as the spreading of a pandemic in a city. Such models proceed\nby specifying the behavior of individuals (agents) and their interactions, and\nparameterizing the process of infection based on such interactions based on the\ngeography and demography of the city. However, such models are computationally\nvery expensive, and the complexity is often linear in the total number of\nagents. This seriously limits the usage of such models for simulations, which\noften have to be run hundreds of times for policy planning and even model\nparameter estimation. An alternative is to develop an emulator, a surrogate\nmodel that can predict the Agent-Based Simulator's output based on its initial\nconditions and parameters. In this paper, we discuss a Deep Learning model\nbased on Dilated Convolutional Neural Network that can emulate such an agent\nbased model with high accuracy. We show that use of this model instead of the\noriginal Agent-Based Model provides us major gains in the speed of simulations,\nallowing much quicker calibration to observations, and more extensive scenario\nanalysis. The models we consider are spatially explicit, as the locations of\nthe infected individuals are simulated instead of the gross counts. Another\naspect of our emulation framework is its divide-and-conquer approach that\ndivides the city into several small overlapping blocks and carries out the\nemulation in them parallelly, after which these results are merged together.\nThis ensures that the same emulator can work for a city of any size, and also\nprovides significant improvement of time complexity of the emulator, compared\nto the original simulator.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.14396v2"
    },
    {
        "title": "DM$^2$: Decentralized Multi-Agent Reinforcement Learning for\n  Distribution Matching",
        "authors": [
            "Caroline Wang",
            "Ishan Durugkar",
            "Elad Liebman",
            "Peter Stone"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Current approaches to multi-agent cooperation rely heavily on centralized\nmechanisms or explicit communication protocols to ensure convergence. This\npaper studies the problem of distributed multi-agent learning without resorting\nto centralized components or explicit communication. It examines the use of\ndistribution matching to facilitate the coordination of independent agents. In\nthe proposed scheme, each agent independently minimizes the distribution\nmismatch to the corresponding component of a target visitation distribution.\nThe theoretical analysis shows that under certain conditions, each agent\nminimizing its individual distribution mismatch allows the convergence to the\njoint policy that generated the target distribution. Further, if the target\ndistribution is from a joint policy that optimizes a cooperative task, the\noptimal policy for a combination of this task reward and the distribution\nmatching reward is the same joint policy. This insight is used to formulate a\npractical algorithm (DM$^2$), in which each individual agent matches a target\ndistribution derived from concurrently sampled trajectories from a joint expert\npolicy. Experimental validation on the StarCraft domain shows that combining\n(1) a task reward, and (2) a distribution matching reward for expert\ndemonstrations for the same task, allows agents to outperform a naive\ndistributed baseline. Additional experiments probe the conditions under which\nexpert demonstrations need to be sampled to obtain the learning benefits.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00233v3"
    },
    {
        "title": "Stable Relationships",
        "authors": [
            "Sam Ganzfried"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We study a dynamic model of the relationship between two people where the\nstates depend on the \"power\" in the relationship. We perform a comprehensive\nanalysis of stability of the system, and determine a set of conditions under\nwhich stable relationships are possible. In particular, stable relationships\ncan occur if both people are dominant, but the sum of dominances is below a\nbound determined by the model's parameters. Stable relationships can also occur\nif one person is dominant and the other is submissive, provided the level of\ndominance exceeds the level of submissiveness but not beyond a threshold. We\nalso conclude that a stable relationship is not possible if both people are\nsubmissive. While our model is motivated by a social or romantic relationship,\nit can also be applied to professional or business relationships as well as\ndiplomatic relationships between nations.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.06468v9"
    },
    {
        "title": "Calibrating Agent-based Models to Microdata with Graph Neural Networks",
        "authors": [
            "Joel Dyer",
            "Patrick Cannon",
            "J. Doyne Farmer",
            "Sebastian M. Schmon"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Calibrating agent-based models (ABMs) to data is among the most fundamental\nrequirements to ensure the model fulfils its desired purpose. In recent years,\nsimulation-based inference methods have emerged as powerful tools for\nperforming this task when the model likelihood function is intractable, as is\noften the case for ABMs. In some real-world use cases of ABMs, both the\nobserved data and the ABM output consist of the agents' states and their\ninteractions over time. In such cases, there is a tension between the desire to\nmake full use of the rich information content of such granular data on the one\nhand, and the need to reduce the dimensionality of the data to prevent\ndifficulties associated with high-dimensional learning tasks on the other. A\npossible resolution is to construct lower-dimensional time-series through the\nuse of summary statistics describing the macrostate of the system at each time\npoint. However, a poor choice of summary statistics can result in an\nunacceptable loss of information from the original dataset, dramatically\nreducing the quality of the resulting calibration. In this work, we instead\npropose to learn parameter posteriors associated with granular microdata\ndirectly using temporal graph neural networks. We will demonstrate that such an\napproach offers highly compelling inductive biases for Bayesian inference using\nthe raw ABM microstates as output.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.07570v1"
    },
    {
        "title": "Belief-Desire-Intention (BDI) Multi-agent System for Cloud Marketplace\n  Negotiation",
        "authors": [
            "Saurabh Deochake"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  With the evolution of cloud computing, there has been a rise of large\nenterprises extending their infrastructure and workloads into the public cloud.\nThis paper proposes a full-fledged framework for a Belief-Desire-Intention\n(BDI) multi-agent-based cloud marketplace system for cloud resources. Each\nparty in the cloud marketplace system supports a BDI agent for autonomous\ndecision making and negotiation to facilitate automated buying and selling of\nresources. Additionally, multiple BDI agents from an enterprise competing for\nthe same cloud resource can consult with each other via Master Negotiation\nClearing House to minimize the overall cost function for the enterprise while\nnegotiating for a cloud resource. The cloud marketplace system is further\naugmented with assignments of behavior norm and reputation index to the agents\nto facilitate trust among them.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.08468v1"
    },
    {
        "title": "Edge-Aided Sensor Data Sharing in Vehicular Communication Networks",
        "authors": [
            "Rui Song",
            "Anupama Hegde",
            "Numan Senel",
            "Alois Knoll",
            "Andreas Festag"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Sensor data sharing in vehicular networks can significantly improve the range\nand accuracy of environmental perception for connected automated vehicles.\nDifferent concepts and schemes for dissemination and fusion of sensor data have\nbeen developed. It is common to these schemes that measurement errors of the\nsensors impair the perception quality and can result in road traffic accidents.\nSpecifically, when the measurement error from the sensors (also referred as\nmeasurement noise) is unknown and time varying, the performance of the data\nfusion process is restricted, which represents a major challenge in the\ncalibration of sensors. In this paper, we consider sensor data sharing and\nfusion in a vehicular network with both, vehicle-to-infrastructure and\nvehicle-to-vehicle communication. We propose a method, named Bidirectional\nFeedback Noise Estimation (BiFNoE), in which an edge server collects and caches\nsensor measurement data from vehicles. The edge estimates the noise and the\ntargets alternately in double dynamic sliding time windows and enhances the\ndistributed cooperative environment sensing at each vehicle with low\ncommunication costs. We evaluate the proposed algorithm and data dissemination\nstrategy in an application scenario by simulation and show that the perception\naccuracy is on average improved by around 80 % with only 12 kbps uplink and 28\nkbps downlink bandwidth.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.08882v1"
    },
    {
        "title": "From Multi-agent to Multi-robot: A Scalable Training and Evaluation\n  Platform for Multi-robot Reinforcement Learning",
        "authors": [
            "Zhiuxan Liang",
            "Jiannong Cao",
            "Shan Jiang",
            "Divya Saxena",
            "Jinlin Chen",
            "Huafeng Xu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent reinforcement learning (MARL) has been gaining extensive\nattention from academia and industries in the past few decades. One of the\nfundamental problems in MARL is how to evaluate different approaches\ncomprehensively. Most existing MARL methods are evaluated in either video games\nor simplistic simulated scenarios. It remains unknown how these methods perform\nin real-world scenarios, especially multi-robot systems. This paper introduces\na scalable emulation platform for multi-robot reinforcement learning (MRRL)\ncalled SMART to meet this need. Precisely, SMART consists of two components: 1)\na simulation environment that provides a variety of complex interaction\nscenarios for training and 2) a real-world multi-robot system for realistic\nperformance evaluation. Besides, SMART offers agent-environment APIs that are\nplug-and-play for algorithm implementation. To illustrate the practicality of\nour platform, we conduct a case study on the cooperative driving lane change\nscenario. Building off the case study, we summarize several unique challenges\nof MRRL, which are rarely considered previously. Finally, we open-source the\nsimulation environments, associated benchmark tasks, and state-of-the-art\nbaselines to encourage and empower MRRL research.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09590v1"
    },
    {
        "title": "Nocturne: a scalable driving benchmark for bringing multi-agent learning\n  one step closer to the real world",
        "authors": [
            "Eugene Vinitsky",
            "Nathan Lichtlé",
            "Xiaomeng Yang",
            "Brandon Amos",
            "Jakob Foerster"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We introduce Nocturne, a new 2D driving simulator for investigating\nmulti-agent coordination under partial observability. The focus of Nocturne is\nto enable research into inference and theory of mind in real-world multi-agent\nsettings without the computational overhead of computer vision and feature\nextraction from images. Agents in this simulator only observe an obstructed\nview of the scene, mimicking human visual sensing constraints. Unlike existing\nbenchmarks that are bottlenecked by rendering human-like observations directly\nusing a camera input, Nocturne uses efficient intersection methods to compute a\nvectorized set of visible features in a C++ back-end, allowing the simulator to\nrun at over 2000 steps-per-second. Using open-source trajectory and map data,\nwe construct a simulator to load and replay arbitrary trajectories and scenes\nfrom real-world driving data. Using this environment, we benchmark\nreinforcement-learning and imitation-learning agents and demonstrate that the\nagents are quite far from human-level coordination ability and deviate\nsignificantly from the expert trajectories.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.09889v3"
    },
    {
        "title": "Hierarchical Reinforcement Learning with Opponent Modeling for\n  Distributed Multi-agent Cooperation",
        "authors": [
            "Zhixuan Liang",
            "Jiannong Cao",
            "Shan Jiang",
            "Divya Saxena",
            "Huafeng Xu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Many real-world applications can be formulated as multi-agent cooperation\nproblems, such as network packet routing and coordination of autonomous\nvehicles. The emergence of deep reinforcement learning (DRL) provides a\npromising approach for multi-agent cooperation through the interaction of the\nagents and environments. However, traditional DRL solutions suffer from the\nhigh dimensions of multiple agents with continuous action space during policy\nsearch. Besides, the dynamicity of agents' policies makes the training\nnon-stationary. To tackle the issues, we propose a hierarchical reinforcement\nlearning approach with high-level decision-making and low-level individual\ncontrol for efficient policy search. In particular, the cooperation of multiple\nagents can be learned in high-level discrete action space efficiently. At the\nsame time, the low-level individual control can be reduced to single-agent\nreinforcement learning. In addition to hierarchical reinforcement learning, we\npropose an opponent modeling network to model other agents' policies during the\nlearning process. In contrast to end-to-end DRL approaches, our approach\nreduces the learning complexity by decomposing the overall task into sub-tasks\nin a hierarchical way. To evaluate the efficiency of our approach, we conduct a\nreal-world case study in the cooperative lane change scenario. Both simulation\nand real-world experiments show the superiority of our approach in the\ncollision rate and convergence speed.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.12718v1"
    },
    {
        "title": "Prescribed-Time Synchronization of Multiweighted and Directed Complex\n  Networks",
        "authors": [
            "Linlong Xu",
            "Xiwei Liu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this note, we study the prescribed-time (PT) synchronization of\nmultiweighted and directed complex networks (MWDCNs) via pinning control.\nUnlike finite-time and fixed-time synchronization, the time for synchronization\ncan be preset as needed, which is independent of initial values and parameters\nlike coupling strength. First and foremost, we reveal the essence of PT\nstability by improper integral, L'Hospital rule and Taylor expansion theory.\nMany controllers established previously for PT stability can be included in our\nnew model. Then, we apply this new result on MWDCNs as an application. The\nsynchronization error at the prescribed time is discussed carefully, so, PT\nsynchronization can be reached. The network topology can be directed and\ndisconnected, which means that the outer coupling matrices (OCMs) can be\nasymmetric and not connected. The relationships between nodes are allowed to be\ncooperative or competitive, so elements in OCMs and inner coupling matrices\n(ICMs) can be positive or negative. We use the rearranging variables' order\ntechnique to combine ICMs and OCMs together to get the sum matrices, which can\nmake a bridge between multiweighted and single-weighted networks. Finally,\nsimulations are presented to illustrate the effectiveness of our theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.13723v1"
    },
    {
        "title": "DistSPECTRL: Distributing Specifications in Multi-Agent Reinforcement\n  Learning Systems",
        "authors": [
            "Joe Eappen",
            "Suresh Jagannathan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  While notable progress has been made in specifying and learning objectives\nfor general cyber-physical systems, applying these methods to distributed\nmulti-agent systems still pose significant challenges. Among these are the need\nto (a) craft specification primitives that allow expression and interplay of\nboth local and global objectives, (b) tame explosion in the state and action\nspaces to enable effective learning, and (c) minimize coordination frequency\nand the set of engaged participants for global objectives. To address these\nchallenges, we propose a novel specification framework that allows natural\ncomposition of local and global objectives used to guide training of a\nmulti-agent system. Our technique enables learning expressive policies that\nallow agents to operate in a coordination-free manner for local objectives,\nwhile using a decentralized communication protocol for enforcing global ones.\nExperimental results support our claim that sophisticated multi-agent\ndistributed planning problems can be effectively realized using\nspecification-guided learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.13754v1"
    },
    {
        "title": "Cooperative Multi-Agent Search on Endogenously-Changing Fitness\n  Landscapes",
        "authors": [
            "Chin Woei Lim",
            "Richard Allmendinger",
            "Joshua Knowles",
            "Ayesha Alhosani",
            "Mercedes Bleda"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We use a multi-agent system to model how agents (representing firms) may\ncollaborate and adapt in a business 'landscape' where some, more influential,\nfirms are given the power to shape the landscape of other firms. The landscapes\nwe study are based on the well-known NK model of Kauffman, with the addition of\n'shapers', firms that can change the landscape's features for themselves and\nall other players. Our work investigates how firms that are additionally\nendowed with cognitive and experiential search, and the ability to form\ncollaborations with other firms, can use these capabilities to adapt more\nquickly and adeptly. We find that, in a collaborative group, firms must still\nhave a mind of their own and resist direct mimicry of stronger partners to\nattain better heights collectively. Larger groups and groups with more\ninfluential members generally do better, so targeted intelligent cooperation is\nbeneficial. These conclusions are tentative, and our results show a sensitivity\nto landscape ruggedness and \"malleability\" (i.e. the capacity of the landscape\nto be changed by the shaper firms). Overall, our work demonstrates the\npotential of computer science, evolution, and machine learning to contribute to\nbusiness strategy in these complex environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.13844v1"
    },
    {
        "title": "Government Intervention in Catastrophe Insurance Markets: A\n  Reinforcement Learning Approach",
        "authors": [
            "Menna Hassan",
            "Nourhan Sakr",
            "Arthur Charpentier"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper designs a sequential repeated game of a micro-founded society with\nthree types of agents: individuals, insurers, and a government. Nascent to\neconomics literature, we use Reinforcement Learning (RL), closely related to\nmulti-armed bandit problems, to learn the welfare impact of a set of proposed\npolicy interventions per $1 spent on them. The paper rigorously discusses the\ndesirability of the proposed interventions by comparing them against each other\non a case-by-case basis. The paper provides a framework for algorithmic policy\nevaluation using calibrated theoretical models which can assist in feasibility\nstudies.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.01010v1"
    },
    {
        "title": "Learning Task Embeddings for Teamwork Adaptation in Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Lukas Schäfer",
            "Filippos Christianos",
            "Amos Storkey",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Successful deployment of multi-agent reinforcement learning often requires\nagents to adapt their behaviour. In this work, we discuss the problem of\nteamwork adaptation in which a team of agents needs to adapt their policies to\nsolve novel tasks with limited fine-tuning. Motivated by the intuition that\nagents need to be able to identify and distinguish tasks in order to adapt\ntheir behaviour to the current task, we propose to learn multi-agent task\nembeddings (MATE). These task embeddings are trained using an encoder-decoder\narchitecture optimised for reconstruction of the transition and reward\nfunctions which uniquely identify tasks. We show that a team of agents is able\nto adapt to novel tasks when provided with task embeddings. We propose three\nMATE training paradigms: independent MATE, centralised MATE, and mixed MATE\nwhich vary in the information used for the task encoding. We show that the\nembeddings learned by MATE identify tasks and provide useful information which\nagents leverage during adaptation to novel tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.02249v2"
    },
    {
        "title": "A Model-based Multi-agent Framework to Enable an Agile Response to\n  Supply Chain Disruptions",
        "authors": [
            "Mingjie Bi",
            "Gongyu Chen",
            "Dawn M. Tilbury",
            "Siqian Shen",
            "Kira Barton"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Due to the COVID-19 pandemic, the global supply chain is disrupted at an\nunprecedented scale under uncertain and unknown trends of labor shortage, high\nmaterial prices, and changing travel or trade regulations. To stay competitive,\nenterprises desire agile and dynamic response strategies to quickly react to\ndisruptions and recover supply-chain functions. Although both centralized and\nmulti-agent approaches have been studied, their implementation requires prior\nknowledge of disruptions and agent-rule-based reasoning. In this paper, we\nintroduce a model-based multi-agent framework that enables agent coordination\nand dynamic agent decision-making to respond to supply chain disruptions in an\nagile and effective manner. Through a small-scale simulated case study, we\nshowcase the feasibility of the proposed approach under several disruption\nscenarios that affect a supply chain network differently, and analyze\nperformance trade-offs between the proposed distributed and centralized\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.03460v1"
    },
    {
        "title": "High Performance Simulation for Scalable Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Jordan Langham-Lopez",
            "Sebastian M. Schmon",
            "Patrick Cannon"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Multi-agent reinforcement learning experiments and open-source training\nenvironments are typically limited in scale, supporting tens or sometimes up to\nhundreds of interacting agents. In this paper we demonstrate the use of Vogue,\na high performance agent based model (ABM) framework. Vogue serves as a\nmulti-agent training environment, supporting thousands to tens of thousands of\ninteracting agents while maintaining high training throughput by running both\nthe environment and reinforcement learning (RL) agents on the GPU. High\nperformance multi-agent environments at this scale have the potential to enable\nthe learning of robust and flexible policies for use in ABMs and simulations of\ncomplex systems. We demonstrate training performance with two newly developed,\nlarge scale multi-agent training environments. Moreover, we show that these\nenvironments can train shared RL policies on time-scales of minutes and hours.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.03945v1"
    },
    {
        "title": "On the properties of path additions for traffic routing",
        "authors": [
            "Matteo Bettini",
            "Amanda Prorok"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper we investigate the impact of path additions to transport\nnetworks with optimised traffic routing. In particular, we study the behaviour\nof total travel time, and consider both self-interested routing paradigms, such\nas User Equilibrium (UE) routing, as well as cooperative paradigms, such as\nclassic Multi-Commodity (MC) network flow and System Optimal (SO) routing. We\nprovide a formal framework for designing transport networks through iterative\npath additions, introducing the concepts of trip spanning tree and trip path\ngraph. Using this formalisation, we prove multiple properties of the objective\nfunction for transport network design. Since the underlying routing problem is\nNP-Hard, we investigate properties that provide guarantees in approximate\nalgorithm design. Firstly, while Braess' paradox has shown that total travel\ntime is not monotonic non-increasing with respect to path additions under\nself-interested routing (UE), we prove that, instead, monotonicity holds for\ncooperative routing (MC and SO). This result has the important implication that\ncooperative agents make the best use of redundant infrastructure. Secondly, we\nprove via a counterexample that the intuitive statement `adding a path to a\ntransport network always grants greater or equal benefit to users than adding\nit to a superset of that network' is false. In other words we prove that, for\nall the routing formulations studied, total travel time is not supermodular\nwith respect to path additions. While this counter-intuitive result yields a\nhardness property for algorithm design, we provide particular instances where,\ninstead, the property of supermodularity holds. Our study on monotonicity and\nsupermodularity of total travel time with respect to path additions provides\nformal proofs and scenarios that constitute important insights for transport\nnetwork designers.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.04505v1"
    },
    {
        "title": "Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent\n  RL",
        "authors": [
            "Siyi Hu",
            "Chuanlong Xie",
            "Xiaodan Liang",
            "Xiaojun Chang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Cooperative multi-agent reinforcement learning (MARL) is making rapid\nprogress for solving tasks in a grid world and real-world scenarios, in which\nagents are given different attributes and goals, resulting in different\nbehavior through the whole multi-agent task. In this study, we quantify the\nagent's behavior difference and build its relationship with the policy\nperformance via {\\bf Role Diversity}, a metric to measure the characteristics\nof MARL tasks. We define role diversity from three perspectives: action-based,\ntrajectory-based, and contribution-based to fully measure a multi-agent task.\nThrough theoretical analysis, we find that the error bound in MARL can be\ndecomposed into three parts that have a strong relation to the role diversity.\nThe decomposed factors can significantly impact policy optimization on three\npopular directions including parameter sharing, communication mechanism, and\ncredit assignment. The main experimental platforms are based on {\\bf Multiagent\nParticle Environment (MPE)} and {\\bf The StarCraft Multi-Agent Challenge\n(SMAC). Extensive experiments} clearly show that role diversity can serve as a\nrobust measurement for the characteristics of a multi-agent cooperation task\nand help diagnose whether the policy fits the current multi-agent system for a\nbetter policy performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.05683v1"
    },
    {
        "title": "Relationship Design for Socially-Aware Behavior in Static Games",
        "authors": [
            "Shenghui Chen",
            "Yigit E. Bayiz",
            "David Fridovich-Keil",
            "Ufuk Topcu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Autonomous agents can adopt socially-aware behaviors to reduce social costs,\nmimicking the way animals interact in nature and humans in society. We present\na new approach to model socially-aware decision-making that includes two key\nelements: bounded rationality and inter-agent relationships. We capture the\ninteragent relationships by introducing a novel model called a relationship\ngame and encode agents' bounded rationality using quantal response equilibria.\nFor each relationship game, we define a social cost function and formulate a\nmechanism design problem to optimize weights for relationships that minimize\nsocial cost at the equilibrium. We address the multiplicity of equilibria by\npresenting the problem in two forms: Min-Max and Min-Min, aimed respectively at\nminimization of the highest and lowest social costs in the equilibria. We\ncompute the quantal response equilibrium by solving a least-squares problem\ndefined with its Karush-Kuhn-Tucker conditions, and propose two projected\ngradient descent algorithms to solve the mechanism design problems. Numerical\nresults, including two-lane congestion and congestion with an ambulance,\nconfirm that these algorithms consistently reach the equilibrium with the\nintended social costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.06392v2"
    },
    {
        "title": "Task Allocation with Load Management in Multi-Agent Teams",
        "authors": [
            "Haochen Wu",
            "Amin Ghadami",
            "Alparslan Emrah Bayrak",
            "Jonathon M. Smereka",
            "Bogdan I. Epureanu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In operations of multi-agent teams ranging from homogeneous robot swarms to\nheterogeneous human-autonomy teams, unexpected events might occur. While\nefficiency of operation for multi-agent task allocation problems is the primary\nobjective, it is essential that the decision-making framework is intelligent\nenough to manage unexpected task load with limited resources. Otherwise,\noperation effectiveness would drastically plummet with overloaded agents facing\nunforeseen risks. In this work, we present a decision-making framework for\nmulti-agent teams to learn task allocation with the consideration of load\nmanagement through decentralized reinforcement learning, where idling is\nencouraged and unnecessary resource usage is avoided. We illustrate the effect\nof load management on team performance and explore agent behaviors in example\nscenarios. Furthermore, a measure of agent importance in collaboration is\ndeveloped to infer team resilience when facing handling potential overload\nsituations.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.08279v1"
    },
    {
        "title": "Proceedings of the Second Workshop on Agents and Robots for reliable\n  Engineered Autonomy",
        "authors": [
            "Rafael C. Cardoso",
            "Angelo Ferrando",
            "Fabio Papacchini",
            "Mehrnoosh Askarpour",
            "Louise A. Dennis"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This volume contains the proceedings of the Second Workshop on Agents and\nRobots for reliable Engineered Autonomy (AREA 2022), co-located with the 31st\nInternational Joint Conference on Artificial Intelligence and the 25th European\nConference on Artificial Intelligence (IJCAI-ECAI 2022). The AREA workshop\nbrings together researchers from autonomous agents, software engineering and\nrobotic communities, as combining knowledge coming from these research areas\nmay lead to innovative approaches that solve complex problems related with the\nverification and validation of autonomous robotic systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.09058v1"
    },
    {
        "title": "RV4JaCa -- Runtime Verification for Multi-Agent Systems",
        "authors": [
            "Debora C. Engelmann",
            "Angelo Ferrando",
            "Alison R. Panisson",
            "Davide Ancona",
            "Rafael H. Bordini",
            "Viviana Mascardi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper presents a Runtime Verification (RV) approach for Multi-Agent\nSystems (MAS) using the JaCaMo framework. Our objective is to bring a layer of\nsecurity to the MAS. This layer is capable of controlling events during the\nexecution of the system without needing a specific implementation in the\nbehaviour of each agent to recognise the events. MAS have been used in the\ncontext of hybrid intelligence. This use requires communication between\nsoftware agents and human beings. In some cases, communication takes place via\nnatural language dialogues. However, this kind of communication brings us to a\nconcern related to controlling the flow of dialogue so that agents can prevent\nany change in the topic of discussion that could impair their reasoning. We\ndemonstrate the implementation of a monitor that aims to control this dialogue\nflow in a MAS that communicates with the user through natural language to aid\ndecision-making in hospital bed allocation.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.09708v1"
    },
    {
        "title": "Towards Global Optimality in Cooperative MARL with the Transformation\n  And Distillation Framework",
        "authors": [
            "Jianing Ye",
            "Chenghao Li",
            "Jianhao Wang",
            "Chongjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Decentralized execution is one core demand in cooperative multi-agent\nreinforcement learning (MARL). Recently, most popular MARL algorithms have\nadopted decentralized policies to enable decentralized execution and use\ngradient descent as their optimizer. However, there is hardly any theoretical\nanalysis of these algorithms taking the optimization method into consideration,\nand we find that various popular MARL algorithms with decentralized policies\nare suboptimal in toy tasks when gradient descent is chosen as their\noptimization method. In this paper, we theoretically analyze two common classes\nof algorithms with decentralized policies -- multi-agent policy gradient\nmethods and value-decomposition methods to prove their suboptimality when\ngradient descent is used. In addition, we propose the Transformation And\nDistillation (TAD) framework, which reformulates a multi-agent MDP as a special\nsingle-agent MDP with a sequential structure and enables decentralized\nexecution by distilling the learned policy on the derived ``single-agent\" MDP.\nThis approach uses a two-stage learning paradigm to address the optimization\nproblem in cooperative MARL, maintaining its performance guarantee.\nEmpirically, we implement TAD-PPO based on PPO, which can theoretically perform\noptimal policy learning in the finite multi-agent MDPs and shows significant\noutperformance on a large set of cooperative multi-agent tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.11143v3"
    },
    {
        "title": "A Geometric Approach to Passive Localisation",
        "authors": [
            "Theofilos Triommatis",
            "Igor Potapov",
            "Gareth Rees",
            "Jason F. Ralph"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we present a geometric framework for the passive localisation\nof static emitters. The objective is to localise the position of the emitters\nin a given area by centralised coordination of mobile passive sensors. This\nframework uses only the geometry of the problem to minimise the maximal bounds\nof the emitters' locations without using a belief or probability distribution.\nThis geometric approach provides effective boundaries on the emitters'\nposition. It can also be useful in evaluating different decision-making\nstrategies for coordinating mobile passive sensors and complementing\nstatistical methods during the initialisation process. The effectiveness of the\ngeometric approach is shown by designing and evaluating a greedy\ndecision-making strategy, where a sensor selects its future position by\nminimising the maximum uncertainty on its next measurement using one of the\nglobal objective functions. Finally, we analyse and discuss the emergent\nbehaviour and robustness of the proposed algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.13396v1"
    },
    {
        "title": "FleetPy: A Modular Open-Source Simulation Tool for Mobility On-Demand\n  Services",
        "authors": [
            "Roman Engelhardt",
            "Florian Dandl",
            "Arslan-Ali Syed",
            "Yunfei Zhang",
            "Fabian Fehn",
            "Fynn Wolf",
            "Klaus Bogenberger"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The market share of mobility on-demand (MoD) services strongly increased in\nrecent years and is expected to rise even higher once vehicle automation is\nfully available. These services might reduce space consumption in cities as\nfewer parking spaces are required if private vehicle trips are replaced. If\nrides are shared additionally, occupancy related traffic efficiency is\nincreased. Simulations help to identify the actual impact of MoD on a traffic\nsystem, evaluate new control algorithms for improved service efficiency and\ndevelop guidelines for regulatory measures. This paper presents the open-source\nagent-based simulation framework FleetPy. FleetPy (written in the programming\nlanguage \"Python\") is explicitly developed to model MoD services in a high\nlevel of detail. It specially focuses on the modeling of interactions of users\nwith operators while its flexibility allows the integration and embedding of\nmultiple operators in the overall transportation system. Its modular structure\nensures the transferabillity of previously developed elements and the selection\nof an appropriate level of modeling detail. This paper compares existing\nsimulation frameworks for MoD services and highlights exclusive features of\nFleetPy. The upper level simulation flows are presented, followed by required\ninput data for the simulation and the output data FleetPy produces.\nAdditionally, the modules within FleetPy and high-level descriptions of current\nimplementations are provided. Finally, an example showcase for Manhattan, NYC\nprovides insights into the impacts of different modules for simulation flow,\nfleet optimization, traveler behavior and network representation.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.14246v1"
    },
    {
        "title": "e-Genia3 An AgentSpeak extension for empathic agents",
        "authors": [
            "Joaquin Taverner",
            "Emilio Vivancos",
            "Vicente Botti"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, we present e-Genia3 an extension of AgentSpeak to provide\nsupport to the development of empathic agents. The new extension modifies the\nagent's reasoning processes to select plans according to the analyzed event and\nthe affective state and personality of the agent. In addition, our proposal\nallows a software agent to simulate the distinction between self and other\nagents through two different event appraisal processes: the empathic appraisal\nprocess, for eliciting emotions as a response to other agents emotions, and the\nregular affective appraisal process for other non-empathic affective events.\nThe empathic regulation process adapts the elicited empathic emotion based on\nintrapersonal factors (e.g., the agent's personality and affective memory) and\ninterpersonal characteristics of the agent (e.g., the affective link between\nthe agents). The use of a memory of past events and their corresponding\nelicited emotions allows the maintaining of an affective link to support\nlong-term empathic interaction between agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.00737v1"
    },
    {
        "title": "Deep Reinforcement Learning for Multi-Agent Interaction",
        "authors": [
            "Ibrahim H. Ahmed",
            "Cillian Brewitt",
            "Ignacio Carlucho",
            "Filippos Christianos",
            "Mhairi Dunion",
            "Elliot Fosong",
            "Samuel Garcin",
            "Shangmin Guo",
            "Balint Gyevnar",
            "Trevor McInroe",
            "Georgios Papoudakis",
            "Arrasy Rahman",
            "Lukas Schäfer",
            "Massimiliano Tamborski",
            "Giuseppe Vecchio",
            "Cheng Wang",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The development of autonomous agents which can interact with other agents to\naccomplish a given task is a core area of research in artificial intelligence\nand machine learning. Towards this goal, the Autonomous Agents Research Group\ndevelops novel machine learning algorithms for autonomous systems control, with\na specific focus on deep reinforcement learning and multi-agent reinforcement\nlearning. Research problems include scalable learning of coordinated agent\npolicies and inter-agent communication; reasoning about the behaviours, goals,\nand composition of other agents from limited observations; and sample-efficient\nlearning based on intrinsic motivation, curriculum learning, causal inference,\nand representation learning. This article provides a broad overview of the\nongoing research portfolio of the group and discusses open problems for future\ndirections.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.01769v1"
    },
    {
        "title": "Socially Intelligent Genetic Agents for the Emergence of Explicit Norms",
        "authors": [
            "Rishabh Agrawal",
            "Nirav Ajmeri",
            "Munindar P. Singh"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Norms help regulate a society. Norms may be explicit (represented in\nstructured form) or implicit. We address the emergence of explicit norms by\ndeveloping agents who provide and reason about explanations for norm violations\nin deciding sanctions and identifying alternative norms. These agents use a\ngenetic algorithm to produce norms and reinforcement learning to learn the\nvalues of these norms. We find that applying explanations leads to norms that\nprovide better cohesion and goal satisfaction for the agents. Our results are\nstable for societies with differing attitudes of generosity.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.03789v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Long-Term Network Resource\n  Allocation through Auction: a V2X Application",
        "authors": [
            "Jing Tan",
            "Ramin Khalili",
            "Holger Karl",
            "Artur Hecker"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We formulate offloading of computational tasks from a dynamic group of mobile\nagents (e.g., cars) as decentralized decision making among autonomous agents.\nWe design an interaction mechanism that incentivizes such agents to align\nprivate and system goals by balancing between competition and cooperation. In\nthe static case, the mechanism provably has Nash equilibria with optimal\nresource allocation. In a dynamic environment, this mechanism's requirement of\ncomplete information is impossible to achieve. For such environments, we\npropose a novel multi-agent online learning algorithm that learns with partial,\ndelayed and noisy state information, thus greatly reducing information need.\nOur algorithm is also capable of learning from long-term and sparse reward\nsignals with varying delay. Empirical results from the simulation of a V2X\napplication confirm that through learning, agents with the learning algorithm\nsignificantly improve both system and individual performance, reducing up to\n30% of offloading failure rate, communication overhead and load variation,\nincreasing computation resource utilization and fairness. Results also confirm\nthe algorithm's good convergence and generalization property in different\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.04237v1"
    },
    {
        "title": "Augmented Driver Behavior Models for High-Fidelity Simulation Study of\n  Crash Detection Algorithms",
        "authors": [
            "Ahura Jami",
            "Mahdi Razzaghpour",
            "Hussein Alnuweiri",
            "Yaser P. Fallah"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Developing safety and efficiency applications for Connected and Automated\nVehicles (CAVs) require a great deal of testing and evaluation. The need for\nthe operation of these systems in critical and dangerous situations makes the\nburden of their evaluation very costly, possibly dangerous, and time-consuming.\nAs an alternative, researchers attempt to study and evaluate their algorithms\nand designs using simulation platforms. Modeling the behavior of drivers or\nhuman operators in CAVs or other vehicles interacting with them is one of the\nmain challenges of such simulations. While developing a perfect model for human\nbehavior is a challenging task and an open problem, we present a significant\naugmentation of the current models used in simulators for driver behavior. In\nthis paper, we present a simulation platform for a hybrid transportation system\nthat includes both human-driven and automated vehicles. In addition, we\ndecompose the human driving task and offer a modular approach to simulating a\nlarge-scale traffic scenario, allowing for a thorough investigation of\nautomated and active safety systems. Such representation through Interconnected\nmodules offers a human-interpretable system that can be tuned to represent\ndifferent classes of drivers. Additionally, we analyze a large driving dataset\nto extract expressive parameters that would best describe different driving\ncharacteristics. Finally, we recreate a similarly dense traffic scenario within\nour simulator and conduct a thorough analysis of various human-specific and\nsystem-specific factors, studying their effect on traffic network performance\nand safety.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.05540v2"
    },
    {
        "title": "The emergence of division of labor through decentralized social\n  sanctioning",
        "authors": [
            "Anil Yaman",
            "Joel Z. Leibo",
            "Giovanni Iacca",
            "Sang Wan Lee"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Human ecological success relies on our characteristic ability to flexibly\nself-organize into cooperative social groups, the most successful of which\nemploy substantial specialization and division of labor. Unlike most other\nanimals, humans learn by trial and error during their lives what role to take\non. However, when some critical roles are more attractive than others, and\nindividuals are self-interested, then there is a social dilemma: each\nindividual would prefer others take on the critical but unremunerative roles so\nthey may remain free to take one that pays better. But disaster occurs if all\nact thusly and a critical role goes unfilled. In such situations learning an\noptimum role distribution may not be possible. Consequently, a fundamental\nquestion is: how can division of labor emerge in groups of self-interested\nlifetime-learning individuals? Here we show that by introducing a model of\nsocial norms, which we regard as emergent patterns of decentralized social\nsanctioning, it becomes possible for groups of self-interested individuals to\nlearn a productive division of labor involving all critical roles. Such social\nnorms work by redistributing rewards within the population to disincentivize\nantisocial roles while incentivizing prosocial roles that do not intrinsically\npay as well as others.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.05568v6"
    },
    {
        "title": "Scalable Multi-Agent Lab Framework for Lab Optimization",
        "authors": [
            "A. Gilad Kusne",
            "Austin McDannald"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Autonomous materials research systems allow scientists to fail smarter, learn\nfaster, and spend less resources in their studies. As these systems grow in\nnumber, capability, and complexity, a new challenge arises - how will they work\ntogether across large facilities? We explore one solution to this question - a\nmulti-agent laboratory control frame-work. We demonstrate this framework with\nan autonomous material science lab in mind - where information from diverse\nresearch campaigns can be combined to ad-dress the scientific question at hand.\nThis framework can 1) account for realistic resource limits such as equipment\nuse, 2) allow for machine learning agents with diverse learning capabilities\nand goals capable of running re-search campaigns, and 3) facilitate multi-agent\ncollaborations and teams. The framework is dubbed the MULTI-agent auTonomous\nfAcilities - a Scalable frameworK aka MULTITASK. MULTITASK makes possible\nfacility-wide simulations, including agent-instrument and agent-agent\ninteractions. Through MULTITASK's modularity, real-world facilities can come\non-line in phases, with simulated instruments gradually replaced by real-world\ninstruments. We hope MULTITASK opens new areas of study in large-scale\nautonomous and semi-autonomous research campaigns and facilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.09099v3"
    },
    {
        "title": "Innovation and informal knowledge exchanges between firms",
        "authors": [
            "Juste Raimbault"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Firm clusters are seen as having a positive effect on innovations, what can\nbe interpreted as economies of scale or knowledge spillovers. The processes\nunderlying the success of these clusters remain difficult to isolate. We\npropose in this paper a stylised agent-based model to test the role of\ngeographical proximity and informal knowledge exchanges between firms on the\nemergence of innovations. The model is run on synthetic firm clusters.\nSensitivity analysis and systematic model exploration unveil a strong impact of\ninteraction distance on innovations, with a qualitative shift when spatial\ninteractions are more intense. Model bi-objective optimisation shows a\ncompromise between innovation and product diversity, suggesting trade-offs for\nclusters in practice. This model provides thus a first basis to systematically\nexplore the interplay between firm cluster geography and innovation, from an\nevolutionary perspective.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.14719v1"
    },
    {
        "title": "A Survey on Large-Population Systems and Scalable Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Kai Cui",
            "Anam Tahir",
            "Gizem Ekinci",
            "Ahmed Elshamanhory",
            "Yannick Eich",
            "Mengguang Li",
            "Heinz Koeppl"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The analysis and control of large-population systems is of great interest to\ndiverse areas of research and engineering, ranging from epidemiology over\nrobotic swarms to economics and finance. An increasingly popular and effective\napproach to realizing sequential decision-making in multi-agent systems is\nthrough multi-agent reinforcement learning, as it allows for an automatic and\nmodel-free analysis of highly complex systems. However, the key issue of\nscalability complicates the design of control and reinforcement learning\nalgorithms particularly in systems with large populations of agents. While\nreinforcement learning has found resounding empirical success in many scenarios\nwith few agents, problems with many agents quickly become intractable and\nnecessitate special consideration. In this survey, we will shed light on\ncurrent approaches to tractably understanding and analyzing large-population\nsystems, both through multi-agent reinforcement learning and through adjacent\nareas of research such as mean-field games, collective intelligence, or complex\nnetwork theory. These classically independent subject areas offer a variety of\napproaches to understanding or modeling large-population systems, which may be\nof great use for the formulation of tractable MARL algorithms in the future.\nFinally, we survey potential areas of application for large-scale control and\nidentify fruitful future applications of learning algorithms in practical\nsystems. We hope that our survey could provide insight and future directions to\njunior and senior researchers in theoretical and applied sciences alike.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.03859v1"
    },
    {
        "title": "Cooperation and Competition: Flocking with Evolutionary Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Yunxiao Guo",
            "Xinjia Xie",
            "Runhao Zhao",
            "Chenglan Zhu",
            "Jiangting Yin",
            "Han Long"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Flocking is a very challenging problem in a multi-agent system; traditional\nflocking methods also require complete knowledge of the environment and a\nprecise model for control. In this paper, we propose Evolutionary Multi-Agent\nReinforcement Learning (EMARL) in flocking tasks, a hybrid algorithm that\ncombines cooperation and competition with little prior knowledge. As for\ncooperation, we design the agents' reward for flocking tasks according to the\nboids model. While for competition, agents with high fitness are designed as\nsenior agents, and those with low fitness are designed as junior, letting\njunior agents inherit the parameters of senior agents stochastically. To\nintensify competition, we also design an evolutionary selection mechanism that\nshows effectiveness on credit assignment in flocking tasks. Experimental\nresults in a range of challenging and self-contrast benchmarks demonstrate that\nEMARL significantly outperforms the full competition or cooperation methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04696v2"
    },
    {
        "title": "Hierarchical Cyclic Pursuit: Algebraic Curves Containing the Laplacian\n  Spectra",
        "authors": [
            "Sergei E. Parsegov",
            "Pavel Yu. Chebotarev",
            "Pavel S. Shcherbakov",
            "Federico M. Ibáñez"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The paper addresses the problem of multi-agent communication in networks with\nregular directed ring structure. These can be viewed as hierarchical extensions\nof the classical cyclic pursuit topology. We show that the spectra of the\ncorresponding Laplacian matrices allow exact localization on the complex plane.\nFurthermore, we derive a general form of the characteristic polynomial of such\nmatrices, analyze the algebraic curves its roots belong to, and propose a way\nto obtain their closed-form equations. In combination with frequency domain\nconsensus criteria for high-order SISO linear agents, these curves enable one\nto analyze the feasibility of consensus in networks with varying number of\nagents.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12178v1"
    },
    {
        "title": "How to solve a classification problem using a cooperative tiling\n  Multi-Agent System?",
        "authors": [
            "Thibault Fourez",
            "Nicolas Verstaevel",
            "Frédéric Migeon",
            "Frédéric Schettini",
            "Frédéric Amblard"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Adaptive Multi-Agent Systems (AMAS) transform dynamic problems into problems\nof local cooperation between agents. We present smapy, an ensemble based AMAS\nimplementation for mobility prediction, whose agents are provided with machine\nlearning models in addition to their cooperation rules. With a detailed\nmethodology, we propose a framework to transform a classification problem into\na cooperative tiling of the input variable space. We show that it is possible\nto use linear classifiers for online non-linear classification on three\nbenchmark toy problems chosen for their different levels of linear\nseparability, if they are integrated in a cooperative Multi-Agent structure.\nThe results obtained show a significant improvement of the performance of\nlinear classifiers in non-linear contexts in terms of classification accuracy\nand decision boundaries, thanks to the cooperative approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.14239v1"
    },
    {
        "title": "Emergent Communication: Generalization and Overfitting in Lewis Games",
        "authors": [
            "Mathieu Rita",
            "Corentin Tallec",
            "Paul Michel",
            "Jean-Bastien Grill",
            "Olivier Pietquin",
            "Emmanuel Dupoux",
            "Florian Strub"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Lewis signaling games are a class of simple communication games for\nsimulating the emergence of language. In these games, two agents must agree on\na communication protocol in order to solve a cooperative task. Previous work\nhas shown that agents trained to play this game with reinforcement learning\ntend to develop languages that display undesirable properties from a linguistic\npoint of view (lack of generalization, lack of compositionality, etc). In this\npaper, we aim to provide better understanding of this phenomenon by\nanalytically studying the learning problem in Lewis games. As a core\ncontribution, we demonstrate that the standard objective in Lewis games can be\ndecomposed in two components: a co-adaptation loss and an information loss.\nThis decomposition enables us to surface two potential sources of overfitting,\nwhich we show may undermine the emergence of a structured communication\nprotocol. In particular, when we control for overfitting on the co-adaptation\nloss, we recover desired properties in the emergent languages: they are more\ncompositional and generalize better.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.15342v2"
    },
    {
        "title": "Assuring Safety of Vision-Based Swarm Formation Control",
        "authors": [
            "Chiao Hsieh",
            "Yubin Koh",
            "Yangge Li",
            "Sayan Mitra"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Vision-based formation control systems are attractive because they can use\ninexpensive sensors and can work in GPS-denied environments. The safety\nassurance for such systems is challenging: the vision component's accuracy\ndepends on the environment in complicated ways, these errors propagate through\nthe system and lead to incorrect control actions, and there exists no formal\nspecification for end-to-end reasoning. We address this problem and propose a\ntechnique for safety assurance of vision-based formation control: First, we\npropose a scheme for constructing quantizers that are consistent with\nvision-based perception. Next, we show how the convergence analysis of a\nstandard quantized consensus algorithm can be adapted for the constructed\nquantizers. We use the recently defined notion of perception contracts to\ncreate error bounds on the actual vision-based perception pipeline using\nsampled data from different ground truth states, environments, and weather\nconditions. Specifically, we use a quantizer in logarithmic polar coordinates,\nand we show that this quantizer is suitable for the constructed perception\ncontracts for the vision-based position estimation, where the error worsens\nwith respect to the absolute distance between agents. We build our formation\ncontrol algorithm with this nonuniform quantizer, and we prove its convergence\nemploying an existing result for quantized consensus.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00982v2"
    },
    {
        "title": "A Liquid Democracy System for Human-Computer Societies",
        "authors": [
            "Anton Kolonin",
            "Ben Goertzel",
            "Cassio Pennachin",
            "Deborah Duong",
            "Marco Argentieri",
            "Matt Iklé",
            "Nejc Znidar"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Problem of reliable democratic governance is critical for survival of any\ncommunity, and it will be critical for communities powered with Artificial\nIntelligence (AI) systems upon developments of the latter. Apparently, it will\nbe getting more and more critical because of increasing speeds and scales of\nelectronic communications and decreasing latencies in system responses. In\norder to address this need, we present design and implementation of a\nreputation system supporting \"liquid democracy\" principle. The system is based\non \"weighted liquid rank\" algorithm employing different sorts of explicit and\nimplicit ratings being exchanged by members of the society as well as implicit\nassessments of of the members based on measures of their activity in the\nsociety. The system is evaluated against live social network data with help of\nsimulation modelling for an online marketplace case.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.02356v1"
    },
    {
        "title": "A Reputation System for Market Security and Equity",
        "authors": [
            "Anton Kolonin",
            "Deborah Duong",
            "Ben Goertzel",
            "Cassio Pennachin",
            "Matt Iklé",
            "Nejc Znidar",
            "Marco Argentieri"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We simulate a reputation system in a market to optimise the balance between\nmarket security and market equity. We introduce a method of using a reputation\nsystem that will stabilise the distribution of wealth in a market in a fair\nmanner. We also introduce metrics of a modified Gini that takes production\nquality into account, a way to use a weighted Pearson as a tool to optimise\nbalance.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.02362v1"
    },
    {
        "title": "ELIGN: Expectation Alignment as a Multi-Agent Intrinsic Reward",
        "authors": [
            "Zixian Ma",
            "Rose Wang",
            "Li Fei-Fei",
            "Michael Bernstein",
            "Ranjay Krishna"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Modern multi-agent reinforcement learning frameworks rely on centralized\ntraining and reward shaping to perform well. However, centralized training and\ndense rewards are not readily available in the real world. Current multi-agent\nalgorithms struggle to learn in the alternative setup of decentralized training\nor sparse rewards. To address these issues, we propose a self-supervised\nintrinsic reward ELIGN - expectation alignment - inspired by the\nself-organization principle in Zoology. Similar to how animals collaborate in a\ndecentralized manner with those in their vicinity, agents trained with\nexpectation alignment learn behaviors that match their neighbors' expectations.\nThis allows the agents to learn collaborative behaviors without any external\nreward or centralized training. We demonstrate the efficacy of our approach\nacross 6 tasks in the multi-agent particle and the complex Google Research\nfootball environments, comparing ELIGN to sparse and curiosity-based intrinsic\nrewards. When the number of agents increases, ELIGN scales well in all\nmulti-agent tasks except for one where agents have different capabilities. We\nshow that agent coordination improves through expectation alignment because\nagents learn to divide tasks amongst themselves, break coordination symmetries,\nand confuse adversaries. These results identify tasks where expectation\nalignment is a more useful strategy than curiosity-driven exploration for\nmulti-agent coordination, enabling agents to do zero-shot coordination.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.04365v2"
    },
    {
        "title": "A Cooperative Perception System Robust to Localization Errors",
        "authors": [
            "Zhiying Song",
            "Fuxi Wen",
            "Hailiang Zhang",
            "Jun Li"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Cooperative perception is challenging for safety-critical autonomous driving\napplications.The errors in the shared position and pose cause an inaccurate\nrelative transform estimation and disrupt the robust mapping of the Ego\nvehicle. We propose a distributed object-level cooperative perception system\ncalled OptiMatch, in which the detected 3D bounding boxes and local state\ninformation are shared between the connected vehicles. To correct the noisy\nrelative transform, the local measurements of both connected vehicles (bounding\nboxes) are utilized, and an optimal transport theory-based algorithm is\ndeveloped to filter out those objects jointly detected by the vehicles along\nwith their correspondence, constructing an associated co-visible set. A\ncorrection transform is estimated from the matched object pairs and further\napplied to the noisy relative transform, followed by global fusion and dynamic\nmapping. Experiment results show that robust performance is achieved for\ndifferent levels of location and heading errors, and the proposed framework\noutperforms the state-of-the-art benchmark fusion schemes, including early,\nlate, and intermediate fusion, on average precision by a large margin when\nlocation and/or heading errors occur.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.06289v2"
    },
    {
        "title": "RPM: Generalizable Behaviors for Multi-Agent Reinforcement Learning",
        "authors": [
            "Wei Qiu",
            "Xiao Ma",
            "Bo An",
            "Svetlana Obraztsova",
            "Shuicheng Yan",
            "Zhongwen Xu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Despite the recent advancement in multi-agent reinforcement learning (MARL),\nthe MARL agents easily overfit the training environment and perform poorly in\nthe evaluation scenarios where other agents behave differently. Obtaining\ngeneralizable policies for MARL agents is thus necessary but challenging mainly\ndue to complex multi-agent interactions. In this work, we model the problem\nwith Markov Games and propose a simple yet effective method, ranked policy\nmemory (RPM), to collect diverse multi-agent trajectories for training MARL\npolicies with good generalizability. The main idea of RPM is to maintain a\nlook-up memory of policies. In particular, we try to acquire various levels of\nbehaviors by saving policies via ranking the training episode return, i.e., the\nepisode return of agents in the training environment; when an episode starts,\nthe learning agent can then choose a policy from the RPM as the behavior\npolicy. This innovative self-play training framework leverages agents' past\npolicies and guarantees the diversity of multi-agent interaction in the\ntraining data. We implement RPM on top of MARL algorithms and conduct extensive\nexperiments on Melting Pot. It has been demonstrated that RPM enables MARL\nagents to interact with unseen agents in multi-agent generalization evaluation\nscenarios and complete given tasks, and it significantly boosts the performance\nup to 402% on average.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.09646v1"
    },
    {
        "title": "Indexability is Not Enough for Whittle: Improved, Near-Optimal\n  Algorithms for Restless Bandits",
        "authors": [
            "Abheek Ghosh",
            "Dheeraj Nagaraj",
            "Manish Jain",
            "Milind Tambe"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We study the problem of planning restless multi-armed bandits (RMABs) with\nmultiple actions. This is a popular model for multi-agent systems with\napplications like multi-channel communication, monitoring and machine\nmaintenance tasks, and healthcare. Whittle index policies, which are based on\nLagrangian relaxations, are widely used in these settings due to their\nsimplicity and near-optimality under certain conditions. In this work, we first\nshow that Whittle index policies can fail in simple and practically relevant\nRMAB settings, even when the RMABs are indexable. We discuss why the optimality\nguarantees fail and why asymptotic optimality may not translate well to\npractically relevant planning horizons.\n  We then propose an alternate planning algorithm based on the mean-field\nmethod, which can provably and efficiently obtain near-optimal policies with a\nlarge number of arms, without the stringent structural assumptions required by\nthe Whittle index policies. This borrows ideas from existing research with some\nimprovements: our approach is hyper-parameter free, and we provide an improved\nnon-asymptotic analysis which has: (a) no requirement for exogenous\nhyper-parameters and tighter polynomial dependence on known problem parameters;\n(b) high probability bounds which show that the reward of the policy is\nreliable; and (c) matching sub-optimality lower bounds for this algorithm with\nrespect to the number of arms, thus demonstrating the tightness of our bounds.\nOur extensive experimental analysis shows that the mean-field approach matches\nor outperforms other baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.00112v2"
    },
    {
        "title": "An Efficient Approach with Dynamic Multi-Swarm of UAVs for Forest\n  Firefighting",
        "authors": [
            "Josy John",
            "K. Harikumar",
            "J. Senthilnath",
            "Suresh Sundaram"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this paper, the Multi-Swarm Cooperative Information-driven search and\nDivide and Conquer mitigation control (MSCIDC) approach is proposed for faster\ndetection and mitigation of forest fire by reducing the loss of biodiversity,\nnutrients, soil moisture, and other intangible benefits. A swarm is a\ncooperative group of Unmanned Aerial Vehicles (UAVs) that fly together to\nsearch and quench the fire effectively. The multi-swarm cooperative\ninformation-driven search uses a multi-level search comprising cooperative\ninformation-driven exploration and exploitation for quick/accurate detection of\nfire location. The search level is selected based on the thermal sensor\ninformation about the potential fire area. The dynamicity of swarms, aided by\nglobal regulative repulsion and merging between swarms, reduces the detection\nand mitigation time compared to the existing methods. The local attraction\namong the members of the swarm helps the non-detector members to reach the fire\nlocation faster, and divide-and-conquer mitigation control ensures a\nnon-overlapping fire sector allocation for all members quenching the fire. The\nperformance of MSCIDC has been compared with different multi-UAV methods using\na simulated environment of pine forest. The performance clearly shows that\nMSCIDC mitigates fire much faster than the multi-UAV methods. The Monte-Carlo\nsimulation results indicate that the proposed method reduces the average forest\narea burnt by $65\\%$ and mission time by $60\\%$ compared to the best result\ncase of the multi-UAV approaches, guaranteeing a faster and successful mission.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.01958v1"
    },
    {
        "title": "Scalable Multi-Agent Reinforcement Learning through Intelligent\n  Information Aggregation",
        "authors": [
            "Siddharth Nayak",
            "Kenneth Choi",
            "Wenqi Ding",
            "Sydney Dolan",
            "Karthik Gopalakrishnan",
            "Hamsa Balakrishnan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We consider the problem of multi-agent navigation and collision avoidance\nwhen observations are limited to the local neighborhood of each agent. We\npropose InforMARL, a novel architecture for multi-agent reinforcement learning\n(MARL) which uses local information intelligently to compute paths for all the\nagents in a decentralized manner. Specifically, InforMARL aggregates\ninformation about the local neighborhood of agents for both the actor and the\ncritic using a graph neural network and can be used in conjunction with any\nstandard MARL algorithm. We show that (1) in training, InforMARL has better\nsample efficiency and performance than baseline approaches, despite using less\ninformation, and (2) in testing, it scales well to environments with arbitrary\nnumbers of agents and obstacles. We illustrate these results using four task\nenvironments, including one with predetermined goals for each agent, and one in\nwhich the agents collectively try to cover all goals. Code available at\nhttps://github.com/nsidn98/InforMARL.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.02127v3"
    },
    {
        "title": "Linear Convergent Distributed Nash Equilibrium Seeking with Compression",
        "authors": [
            "Xiaomeng Chen",
            "Yuchi Wu",
            "Xinlei Yi",
            "Minyi Huang",
            "Ling Shi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Information compression techniques are majorly employed to address the\nconcern of reducing communication cost over peer-to-peer links. In this paper,\nwe investigate distributed Nash equilibrium (NE) seeking problems in a class of\nnon-cooperative games over directed graphs with information compression. To\nimprove communication efficiency, a compressed distributed NE seeking (C-DNES)\nalgorithm is proposed to obtain a NE for games, where the differences between\ndecision vectors and their estimates are compressed. The proposed algorithm is\ncompatible with a general class of compression operators, including both\nunbiased and biased compressors. Moreover, our approach only requires the\nadjacency matrix of the directed graph to be row-stochastic, in contrast to\npast works that relied on balancedness or specific global network parameters.\nIt is shown that C-DNES not only inherits the advantages of conventional\ndistributed NE algorithms, achieving linear convergence rate for games with\nrestricted strongly monotone mappings, but also saves communication costs in\nterms of transmitted bits. Finally, numerical simulations illustrate the\nadvantages of C-DNES in saving communication cost by an order of magnitude\nunder different compressors.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.07849v2"
    },
    {
        "title": "Non-Linear Coordination Graphs",
        "authors": [
            "Yipeng Kang",
            "Tonghan Wang",
            "Xiaoran Wu",
            "Qianlan Yang",
            "Chongjie Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Value decomposition multi-agent reinforcement learning methods learn the\nglobal value function as a mixing of each agent's individual utility functions.\nCoordination graphs (CGs) represent a higher-order decomposition by\nincorporating pairwise payoff functions and thus is supposed to have a more\npowerful representational capacity. However, CGs decompose the global value\nfunction linearly over local value functions, severely limiting the complexity\nof the value function class that can be represented. In this paper, we propose\nthe first non-linear coordination graph by extending CG value decomposition\nbeyond the linear case. One major challenge is to conduct greedy action\nselections in this new function class to which commonly adopted DCOP algorithms\nare no longer applicable. We study how to solve this problem when mixing\nnetworks with LeakyReLU activation are used. An enumeration method with a\nglobal optimality guarantee is proposed and motivates an efficient iterative\noptimization method with a local optimality guarantee. We find that our method\ncan achieve superior performance on challenging multi-agent coordination tasks\nlike MACO.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.08404v1"
    },
    {
        "title": "Multiagent Reinforcement Learning for Autonomous Routing and Pickup\n  Problem with Adaptation to Variable Demand",
        "authors": [
            "Daniel Garces",
            "Sushmita Bhattacharya",
            "Stephanie Gil",
            "Dimitri Bertsekas"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We derive a learning framework to generate routing/pickup policies for a\nfleet of autonomous vehicles tasked with servicing stochastically appearing\nrequests on a city map. We focus on policies that 1) give rise to coordination\namongst the vehicles, thereby reducing wait times for servicing requests, 2)\nare non-myopic, and consider a-priori potential future requests, 3) can adapt\nto changes in the underlying demand distribution. Specifically, we are\ninterested in policies that are adaptive to fluctuations of actual demand\nconditions in urban environments, such as on-peak vs. off-peak hours. We\nachieve this through a combination of (i) an online play algorithm that\nimproves the performance of an offline-trained policy, and (ii) an offline\napproximation scheme that allows for adapting to changes in the underlying\ndemand model. In particular, we achieve adaptivity of our learned policy to\ndifferent demand distributions by quantifying a region of validity using the\nq-valid radius of a Wasserstein Ambiguity Set. We propose a mechanism for\nswitching the originally trained offline approximation when the current demand\nis outside the original validity region. In this case, we propose to use an\noffline architecture, trained on a historical demand model that is closer to\nthe current demand in terms of Wasserstein distance. We learn routing and\npickup policies over real taxicab requests in San Francisco with high\nvariability between on-peak and off-peak hours, demonstrating the ability of\nour method to adapt to real fluctuation in demand distributions. Our numerical\nresults demonstrate that our method outperforms alternative rollout-based\nreinforcement learning schemes, as well as other classical methods from\noperations research.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.14983v2"
    },
    {
        "title": "Distributed Energy Management and Demand Response in Smart Grids: A\n  Multi-Agent Deep Reinforcement Learning Framework",
        "authors": [
            "Amin Shojaeighadikolaei",
            "Arman Ghasemi",
            "Kailani Jones",
            "Yousif Dafalla",
            "Alexandru G. Bardas",
            "Reza Ahmadi",
            "Morteza Haashemi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper presents a multi-agent Deep Reinforcement Learning (DRL) framework\nfor autonomous control and integration of renewable energy resources into smart\npower grid systems. In particular, the proposed framework jointly considers\ndemand response (DR) and distributed energy management (DEM) for residential\nend-users. DR has a widely recognized potential for improving power grid\nstability and reliability, while at the same time reducing end-users energy\nbills. However, the conventional DR techniques come with several shortcomings,\nsuch as the inability to handle operational uncertainties while incurring\nend-user disutility, which prevents widespread adoption in real-world\napplications. The proposed framework addresses these shortcomings by\nimplementing DR and DEM based on real-time pricing strategy that is achieved\nusing deep reinforcement learning. Furthermore, this framework enables the\npower grid service provider to leverage distributed energy resources (i.e., PV\nrooftop panels and battery storage) as dispatchable assets to support the smart\ngrid during peak hours, thus achieving management of distributed energy\nresources. Simulation results based on the Deep Q-Network (DQN) demonstrate\nsignificant improvements of the 24-hour accumulative profit for both prosumers\nand the power grid service provider, as well as major reductions in the\nutilization of the power grid reserve generators.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.15858v1"
    },
    {
        "title": "Agent-Cells with DNA Programming: A Dynamic Decentralized System",
        "authors": [
            "Arash Vaezi"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper introduces a new concept. We intend to give life to a software\nagent. A software agent is a computer program that acts on a user's behalf. We\nput a DNA inside the agent. DNA is a simple text, a whole roadmap of a network\nof agents or a system with details. A Dynamic Numerical Abstract of a\nmultiagent system. It is also a reproductive part for an \\emph{agent} that\nmakes the agent take actions and decide independently and reproduce coworkers.\nBy defining different DNA structures, one can establish new agents and\ndifferent nets for different usages. We initiate such thinking as \\emph{DNA\nprogramming}. This strategy leads to a new field of programming. This type of\nprogramming can help us manage large systems with various elements with an\nincredibly organized customizable structure. An agent can reproduce another\nagent. We put one or a few agents around a given network, and the agents will\nreproduce themselves till they can reach others and pervade the whole network.\nAn agent's position or other environmental or geographical characteristics make\nit possible for an agent to know its active set of \\emph{genes} on its DNA. The\nactive set of genes specifies its duties. There is a database that includes a\nlist of functions s.t. each one is an implementation of what a \\emph{gene}\nrepresents. To utilize a decentralized database, we may use a blockchain-based\nstructure.\n  This design can adapt to a system that manages many static and dynamic\nnetworks. This network could be a distributed system, a decentralized system, a\ntelecommunication network such as a 5G monitoring system, an IoT management\nsystem, or even an energy management system. The final system is the\ncombination of all the agents and the overlay net that connects the agents. We\ndenote the final net as the \\emph{body} of the system.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.17104v3"
    },
    {
        "title": "Incentivising cooperation by rewarding the weakest member",
        "authors": [
            "Jory Schossau",
            "Bamshad Shirmohammadi",
            "Arend Hintze"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Autonomous agents that act with each other on behalf of humans are becoming\nmore common in many social domains, such as customer service, transportation,\nand health care. In such social situations greedy strategies can reduce the\npositive outcome for all agents, such as leading to stop-and-go traffic on\nhighways, or causing a denial of service on a communications channel. Instead,\nwe desire autonomous decision-making for efficient performance while also\nconsidering equitability of the group to avoid these pitfalls. Unfortunately,\nin complex situations it is far easier to design machine learning objectives\nfor selfish strategies than for equitable behaviors. Here we present a simple\nway to reward groups of agents in both evolution and reinforcement learning\ndomains by the performance of their weakest member. We show how this yields\n``fairer'' more equitable behavior, while also maximizing individual outcomes,\nand we show the relationship to biological selection mechanisms of group-level\nselection and inclusive fitness theory.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.00119v1"
    },
    {
        "title": "DACOM: Learning Delay-Aware Communication for Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Tingting Yuan",
            "Hwei-Ming Chung",
            "Jie Yuan",
            "Xiaoming Fu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Communication is supposed to improve multi-agent collaboration and overall\nperformance in cooperative Multi-agent reinforcement learning (MARL). However,\nsuch improvements are prevalently limited in practice since most existing\ncommunication schemes ignore communication overheads (e.g., communication\ndelays). In this paper, we demonstrate that ignoring communication delays has\ndetrimental effects on collaborations, especially in delay-sensitive tasks such\nas autonomous driving. To mitigate this impact, we design a delay-aware\nmulti-agent communication model (DACOM) to adapt communication to delays.\nSpecifically, DACOM introduces a component, TimeNet, that is responsible for\nadjusting the waiting time of an agent to receive messages from other agents\nsuch that the uncertainty associated with delay can be addressed. Our\nexperiments reveal that DACOM has a non-negligible performance improvement over\nother mechanisms by making a better trade-off between the benefits of\ncommunication and the costs of waiting for messages.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.01619v1"
    },
    {
        "title": "JFP: Joint Future Prediction with Interactive Multi-Agent Modeling for\n  Autonomous Driving",
        "authors": [
            "Wenjie Luo",
            "Cheolho Park",
            "Andre Cornman",
            "Benjamin Sapp",
            "Dragomir Anguelov"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We propose JFP, a Joint Future Prediction model that can learn to generate\naccurate and consistent multi-agent future trajectories. For this task, many\ndifferent methods have been proposed to capture social interactions in the\nencoding part of the model, however, considerably less focus has been placed on\nrepresenting interactions in the decoder and output stages. As a result, the\npredicted trajectories are not necessarily consistent with each other, and\noften result in unrealistic trajectory overlaps. In contrast, we propose an\nend-to-end trainable model that learns directly the interaction between pairs\nof agents in a structured, graphical model formulation in order to generate\nconsistent future trajectories. It sets new state-of-the-art results on Waymo\nOpen Motion Dataset (WOMD) for the interactive setting. We also investigate a\nmore complex multi-agent setting for both WOMD and a larger internal dataset,\nwhere our approach improves significantly on the trajectory overlap metrics\nwhile obtaining on-par or better performance on single-agent trajectory\nmetrics.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.08710v1"
    },
    {
        "title": "There's Plenty of Room Right Here: Biological Systems as Evolved,\n  Overloaded, Multi-scale Machines",
        "authors": [
            "Joshua Bongard",
            "Michael Levin"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The applicability of computational models to the biological world is an\nactive topic of debate. We argue that a useful path forward results from\nabandoning hard boundaries between categories and adopting an\nobserver-dependent, pragmatic view. Such a view dissolves the contingent\ndichotomies driven by human cognitive biases (e.g., tendency to oversimplify)\nand prior technological limitations in favor of a more continuous, gradualist\nview necessitated by the study of evolution, developmental biology, and\nintelligent machines. Efforts to re-shape living systems for biomedical or\nbioengineering purposes require prediction and control of their function at\nmultiple scales. This is challenging for many reasons, one of which is that\nliving systems perform multiple functions in the same place at the same time.\nWe refer to this as \"polycomputing\" - the ability of the same substrate to\nsimultaneously compute different things. This ability is an important way in\nwhich living things are a kind of computer, but not the familiar, linear,\ndeterministic kind; rather, living things are computers in the broad sense of\ncomputational materials as reported in the rapidly-growing physical computing\nliterature. We argue that an observer-centered framework for the computations\nperformed by evolved and designed systems will improve the understanding of\nmeso-scale events, as it has already done at quantum and relativistic scales.\nHere, we review examples of biological and technological polycomputing, and\ndevelop the idea that overloading of different functions on the same hardware\nis an important design principle that helps understand and build both evolved\nand designed systems. Learning to hack existing polycomputing substrates, as\nwell as evolve and design new ones, will have massive impacts on regenerative\nmedicine, robotics, and computer engineering.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.10675v1"
    },
    {
        "title": "Autonomous Local Catalog Maintenance of Close Proximity Satellite\n  Systems on Closed Natural Motion Trajectories",
        "authors": [
            "Christopher W. Hays",
            "Kristina Miller",
            "Alexander Soderlund",
            "Sean Phillips",
            "Troy Henderson"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  To enable space mission sets like on-orbit servicing and manufacturing,\nagents in close proximity maybe operating too close to yield resolved\nlocalization solutions to operators from ground sensors. This leads to a\nrequirement on the systems need to maintain a catalog of their local\nneighborhood, however, this may impose a large burden on each agent by\nrequiring updating and maintenance of this catalog at each node. To alleviate\nthis burden, this paper considers the case of a single satellite agent (a\nchief) updating a single catalog. More specifically, we consider the case of\nnumerous satellite deputy agents in a local neighborhood of a chief, the goal\nof the chief satellite is to maintain and update a catalog of all agents within\nthis neighborhood through onboard measurements. We consider the agents having\nrelative translational and attitude motion dynamics between the chief and\ndeputy, with the chief centered at the origin of the frame. We provide an\nend-to-end solution of the this problem through providing both a supervisory\ncontrol method coupled with a Bayesian Filter that propagates the belief state\nand provides the catalog solutions to the supervisor. The goal of the\nsupervisory controller is to determine which agent to look at and at which\ntimes while adhering to constraints of the chief satellite. We provide a\nnumerical validation to this problem with three agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00601v2"
    },
    {
        "title": "Dual Self-Awareness Value Decomposition Framework without Individual\n  Global Max for Cooperative Multi-Agent Reinforcement Learning",
        "authors": [
            "Zhiwei Xu",
            "Bin Zhang",
            "Dapeng Li",
            "Guangchong Zhou",
            "Zeren Zhang",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Value decomposition methods have gained popularity in the field of\ncooperative multi-agent reinforcement learning. However, almost all existing\nmethods follow the principle of Individual Global Max (IGM) or its variants,\nwhich limits their problem-solving capabilities. To address this, we propose a\ndual self-awareness value decomposition framework, inspired by the notion of\ndual self-awareness in psychology, that entirely rejects the IGM premise. Each\nagent consists of an ego policy for action selection and an alter ego value\nfunction to solve the credit assignment problem. The value function\nfactorization can ignore the IGM assumption by utilizing an explicit search\nprocedure. On the basis of the above, we also suggest a novel anti-ego\nexploration mechanism to avoid the algorithm becoming stuck in a local optimum.\nAs the first fully IGM-free value decomposition method, our proposed framework\nachieves desirable performance in various cooperative tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.02180v2"
    },
    {
        "title": "Traffic Shaping and Hysteresis Mitigation Using Deep Reinforcement\n  Learning in a Connected Driving Environment",
        "authors": [
            "Rami Ammourah",
            "Alireza Talebpour"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  A multi-agent deep reinforcement learning-based framework for traffic\nshaping. The proposed framework offers a key advantage over existing congestion\nmanagement strategies which is the ability to mitigate hysteresis phenomena.\nUnlike existing congestion management strategies that focus on breakdown\nprevention, the proposed framework is extremely effective after breakdown\nformation. The proposed framework assumes partial connectivity between the\nautomated vehicles which share information. The framework requires a basic\nlevel of autonomy defined by one-dimensional longitudinal control. This\nframework is primarily built using a centralized training, centralized\nexecution multi-agent deep reinforcement learning approach, where longitudinal\ncontrol is defined by signals of acceleration or deceleration commands which\nare then executed by all agents uniformly. The model undertaken for training\nand testing of the framework is based on the well-known Double Deep Q-Learning\nalgorithm which takes the average state of flow within the traffic stream as\nthe model input and outputs actions in the form of acceleration or deceleration\nvalues. We demonstrate the ability of the model to shape the state of traffic,\nmitigate the negative effects of hysteresis, and even improve traffic flow\nbeyond its original level. This paper also identifies the minimum percentage of\nCAVs required to successfully shape the traffic under an assumption of\nuniformly distributed CAVs within the loop system. The framework illustrated in\nthis work doesnt just show the theoretical applicability of reinforcement\nlearning to tackle such challenges but also proposes a realistic solution that\nonly requires partial connectivity and continuous monitoring of the average\nspeed of the system, which can be achieved using readily available sensors that\nmeasure the speeds of vehicles in reasonable proximity to the CAVs.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03141v1"
    },
    {
        "title": "Quantum Multi-Agent Actor-Critic Networks for Cooperative Mobile Access\n  in Multi-UAV Systems",
        "authors": [
            "Chanyoung Park",
            "Won Joon Yun",
            "Jae Pyoung Kim",
            "Tiago Koketsu Rodrigues",
            "Soohyun Park",
            "Soyi Jung",
            "Joongheon Kim"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper proposes a novel algorithm, named quantum multi-agent actor-critic\nnetworks (QMACN) for autonomously constructing a robust mobile access system\nemploying multiple unmanned aerial vehicles (UAVs). In the context of\nfacilitating collaboration among multiple unmanned aerial vehicles (UAVs), the\napplication of multi-agent reinforcement learning (MARL) techniques is regarded\nas a promising approach. These methods enable UAVs to learn collectively,\noptimizing their actions within a shared environment, ultimately leading to\nmore efficient cooperative behavior. Furthermore, the principles of a quantum\ncomputing (QC) are employed in our study to enhance the training process and\ninference capabilities of the UAVs involved. By leveraging the unique\ncomputational advantages of quantum computing, our approach aims to boost the\noverall effectiveness of the UAV system. However, employing a QC introduces\nscalability challenges due to the near intermediate-scale quantum (NISQ)\nlimitation associated with qubit usage. The proposed algorithm addresses this\nissue by implementing a quantum centralized critic, effectively mitigating the\nconstraints imposed by NISQ limitations. Additionally, the advantages of the\nQMACN with performance improvements in terms of training speed and wireless\nservice quality are verified via various data-intensive evaluations.\nFurthermore, this paper validates that a noise injection scheme can be used for\nhandling environmental uncertainties in order to realize robust mobile access.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04445v2"
    },
    {
        "title": "Learning Complex Teamwork Tasks Using a Given Sub-task Decomposition",
        "authors": [
            "Elliot Fosong",
            "Arrasy Rahman",
            "Ignacio Carlucho",
            "Stefano V. Albrecht"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Training a team to complete a complex task via multi-agent reinforcement\nlearning can be difficult due to challenges such as policy search in a large\njoint policy space, and non-stationarity caused by mutually adapting agents. To\nfacilitate efficient learning of complex multi-agent tasks, we propose an\napproach which uses an expert-provided decomposition of a task into simpler\nmulti-agent sub-tasks. In each sub-task, a subset of the entire team is trained\nto acquire sub-task-specific policies. The sub-teams are then merged and\ntransferred to the target task, where their policies are collectively\nfine-tuned to solve the more complex target task. We show empirically that such\napproaches can greatly reduce the number of timesteps required to solve a\ncomplex target task relative to training from-scratch. However, we also\nidentify and investigate two problems with naive implementations of approaches\nbased on sub-task decomposition, and propose a simple and scalable method to\naddress these problems which augments existing actor-critic algorithms. We\ndemonstrate the empirical benefits of our proposed method, enabling sub-task\ndecomposition approaches to be deployed in diverse multi-agent tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04944v2"
    },
    {
        "title": "Mixed Traffic Control and Coordination from Pixels",
        "authors": [
            "Michael Villarreal",
            "Bibek Poudel",
            "Jia Pan",
            "Weizi Li"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Traffic congestion is a persistent problem in our society. Previous methods\nfor traffic control have proven futile in alleviating current congestion levels\nleading researchers to explore ideas with robot vehicles given the increased\nemergence of vehicles with different levels of autonomy on our roads. This\ngives rise to mixed traffic control, where robot vehicles regulate human-driven\nvehicles through reinforcement learning (RL). However, most existing studies\nuse precise observations that require domain expertise and hand engineering for\neach road network's observation space. Additionally, precise observations use\nglobal information, such as environment outflow, and local information, i.e.,\nvehicle positions and velocities. Obtaining this information requires updating\nexisting road infrastructure with vast sensor environments and communication to\npotentially unwilling human drivers. We consider image observations, a modality\nthat has not been extensively explored for mixed traffic control via RL, as the\nalternative: 1) images do not require a complete re-imagination of the\nobservation space from environment to environment; 2) images are ubiquitous\nthrough satellite imagery, in-car camera systems, and traffic monitoring\nsystems; and 3) images only require communication to equipment. In this work,\nwe show robot vehicles using image observations can achieve competitive\nperformance to using precise information on environments, including ring,\nfigure eight, intersection, merge, and bottleneck. In certain scenarios, our\napproach even outperforms using precision observations, e.g., up to 8% increase\nin average vehicle velocity in the merge environment, despite only using local\ntraffic information as opposed to global traffic information.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09167v4"
    },
    {
        "title": "Differentiable Arbitrating in Zero-sum Markov Games",
        "authors": [
            "Jing Wang",
            "Meichen Song",
            "Feng Gao",
            "Boyi Liu",
            "Zhaoran Wang",
            "Yi Wu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We initiate the study of how to perturb the reward in a zero-sum Markov game\nwith two players to induce a desirable Nash equilibrium, namely arbitrating.\nSuch a problem admits a bi-level optimization formulation. The lower level\nrequires solving the Nash equilibrium under a given reward function, which\nmakes the overall problem challenging to optimize in an end-to-end way. We\npropose a backpropagation scheme that differentiates through the Nash\nequilibrium, which provides the gradient feedback for the upper level. In\nparticular, our method only requires a black-box solver for the (regularized)\nNash equilibrium (NE). We develop the convergence analysis for the proposed\nframework with proper black-box NE solvers and demonstrate the empirical\nsuccesses in two multi-agent reinforcement learning (MARL) environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.10058v1"
    },
    {
        "title": "Scenarios and branch points to future machine intelligence",
        "authors": [
            "Koichi Takahashi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We discuss scenarios and branch points to four major possible consequences\nregarding future machine intelligence; 1) the singleton scenario where the\nfirst and only super-intelligence acquires a decisive strategic advantage, 2)\nthe multipolar scenario where the singleton scenario is not technically denied\nbut political or other factors in human society or multi-agent interactions\nbetween the intelligent agents prevent a single agent from gaining a decisive\nstrategic advantage, 3) the ecosystem scenario where the singleton scenario is\ndenied and many autonomous intelligent agents operate in such a way that they\nare interdependent and virtually unstoppable, and 4) the upper-bound scenario\nwhere cognitive capabilities that can be achieved by human-designed intelligent\nagents or their descendants are inherently limited to the sub-human level. We\nidentify six major constraints that can form branch points to these scenarios;\n(1) constraints on autonomy, (2) constraints on the ability to improve\nself-structure, (3) constraints related to thermodynamic efficiency, (4)\nconstraints on updating physical infrastructure, (5) constraints on relative\nadvantage, and (6) constraints on locality.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.14478v3"
    },
    {
        "title": "GHQ: Grouped Hybrid Q Learning for Heterogeneous Cooperative Multi-agent\n  Reinforcement Learning",
        "authors": [
            "Xiaoyang Yu",
            "Youfang Lin",
            "Xiangsen Wang",
            "Sheng Han",
            "Kai Lv"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Previous deep multi-agent reinforcement learning (MARL) algorithms have\nachieved impressive results, typically in homogeneous scenarios. However,\nheterogeneous scenarios are also very common and usually harder to solve. In\nthis paper, we mainly discuss cooperative heterogeneous MARL problems in\nStarcraft Multi-Agent Challenges (SMAC) environment. We firstly define and\ndescribe the heterogeneous problems in SMAC. In order to comprehensively reveal\nand study the problem, we make new maps added to the original SMAC maps. We\nfind that baseline algorithms fail to perform well in those heterogeneous maps.\nTo address this issue, we propose the Grouped Individual-Global-Max Consistency\n(GIGM) and a novel MARL algorithm, Grouped Hybrid Q Learning (GHQ). GHQ\nseparates agents into several groups and keeps individual parameters for each\ngroup, along with a novel hybrid structure for factorization. To enhance\ncoordination between groups, we maximize the Inter-group Mutual Information\n(IGMI) between groups' trajectories. Experiments on original and new\nheterogeneous maps show the fabulous performance of GHQ compared to other\nstate-of-the-art algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.01070v2"
    },
    {
        "title": "On the use of chaotic dynamics for mobile network design and analysis:\n  towards a trace data generator",
        "authors": [
            "Martin Rosalie",
            "Serge Chaumette"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  With the constant increase of the number of autonomous vehicles and connected\nobjects, tools to understand and reproduce their mobility models are required.\nWe focus on chaotic dynamics and review their applications in the design of\nmobility models. We also provide a review of the nonlinear tools used to\ncharacterize mobility models, as it can be found in the literature. Finally, we\npropose a method to generate traces for a given scenario involving moving\npeople, using tools from the nonlinear analysis domain usually dedicated to\ntopological analysis of chaotic attractors.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.16583v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning with Action Masking for UAV-enabled\n  Mobile Communications",
        "authors": [
            "Danish Rizvi",
            "David Boyle"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Unmanned Aerial Vehicles (UAVs) are increasingly used as aerial base stations\nto provide ad hoc communications infrastructure. Building upon prior research\nefforts which consider either static nodes, 2D trajectories or single UAV\nsystems, this paper focuses on the use of multiple UAVs for providing wireless\ncommunication to mobile users in the absence of terrestrial communications\ninfrastructure. In particular, we jointly optimize UAV 3D trajectory and NOMA\npower allocation to maximize system throughput. Firstly, a weighted\nK-means-based clustering algorithm establishes UAV-user associations at regular\nintervals. The efficacy of training a novel Shared Deep Q-Network (SDQN) with\naction masking is then explored. Unlike training each UAV separately using DQN,\nthe SDQN reduces training time by using the experiences of multiple UAVs\ninstead of a single agent. We also show that SDQN can be used to train a\nmulti-agent system with differing action spaces. Simulation results confirm\nthat: 1) training a shared DQN outperforms a conventional DQN in terms of\nmaximum system throughput (+20%) and training time (-10%); 2) it can converge\nfor agents with different action spaces, yielding a 9% increase in throughput\ncompared to mutual learning algorithms; and 3) combining NOMA with an SDQN\narchitecture enables the network to achieve a better sum rate compared with\nexisting baseline schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.16737v2"
    },
    {
        "title": "Swarm Reinforcement Learning For Adaptive Mesh Refinement",
        "authors": [
            "Niklas Freymuth",
            "Philipp Dahlinger",
            "Tobias Würth",
            "Simon Reisch",
            "Luise Kärger",
            "Gerhard Neumann"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Adaptive Mesh Refinement (AMR) enhances the Finite Element Method, an\nimportant technique for simulating complex problems in engineering, by\ndynamically refining mesh regions, enabling a favorable trade-off between\ncomputational speed and simulation accuracy. Classical methods for AMR depend\non heuristics or expensive error estimators, hindering their use for complex\nsimulations. Recent learning-based AMR methods tackle these issues, but so far\nscale only to simple toy examples. We formulate AMR as a novel Adaptive Swarm\nMarkov Decision Process in which a mesh is modeled as a system of simple\ncollaborating agents that may split into multiple new agents. This framework\nallows for a spatial reward formulation that simplifies the credit assignment\nproblem, which we combine with Message Passing Networks to propagate\ninformation between neighboring mesh elements. We experimentally validate our\napproach, Adaptive Swarm Mesh Refinement (ASMR), on challenging refinement\ntasks. Our approach learns reliable and efficient refinement strategies that\ncan robustly generalize to different domains during inference. Additionally, it\nachieves a speedup of up to $2$ orders of magnitude compared to uniform\nrefinements in more demanding simulations. We outperform learned baselines and\nheuristics, achieving a refinement quality that is on par with costly\nerror-based oracle AMR strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.00818v3"
    },
    {
        "title": "Off-Policy Action Anticipation in Multi-Agent Reinforcement Learning",
        "authors": [
            "Ariyan Bighashdel",
            "Daan de Geus",
            "Pavol Jancura",
            "Gijs Dubbelman"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Learning anticipation in Multi-Agent Reinforcement Learning (MARL) is a\nreasoning paradigm where agents anticipate the learning steps of other agents\nto improve cooperation among themselves. As MARL uses gradient-based\noptimization, learning anticipation requires using Higher-Order Gradients\n(HOG), with so-called HOG methods. Existing HOG methods are based on policy\nparameter anticipation, i.e., agents anticipate the changes in policy\nparameters of other agents. Currently, however, these existing HOG methods have\nonly been applied to differentiable games or games with small state spaces. In\nthis work, we demonstrate that in the case of non-differentiable games with\nlarge state spaces, existing HOG methods do not perform well and are\ninefficient due to their inherent limitations related to policy parameter\nanticipation and multiple sampling stages. To overcome these problems, we\npropose Off-Policy Action Anticipation (OffPA2), a novel framework that\napproaches learning anticipation through action anticipation, i.e., agents\nanticipate the changes in actions of other agents, via off-policy sampling. We\ntheoretically analyze our proposed OffPA2 and employ it to develop multiple HOG\nmethods that are applicable to non-differentiable games with large state\nspaces. We conduct a large set of experiments and illustrate that our proposed\nHOG methods outperform the existing ones regarding efficiency and performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01447v1"
    },
    {
        "title": "Lattice Theory in Multi-Agent Systems",
        "authors": [
            "Hans Riess"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this thesis, we argue that (order-) lattice-based multi-agent information\nsystems constitute a broad class of networked multi-agent systems in which\nrelational data is passed between nodes. Mathematically modeled as\nlattice-valued sheaves, we initiate a discrete Hodge theory with a Laplace\noperator, analogous to the graph Laplacian and the graph connection Laplacian,\nacting on assignments of data to the nodes of a Tarski sheaf. The Hodge-Tarski\ntheorem (the main theorem) relates the fixed point theory of this operator,\ncalled the Tarski Laplacian in deference to the Tarski Fixed Point Theorem, to\nthe global sections (consistent global states) of the sheaf. We present novel\napplications to signal processing and multi-agent semantics and supply a\nplethora of examples throughout.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02568v1"
    },
    {
        "title": "Multi-Layer Continuum Deformation Optimization of Multi-Agent Systems",
        "authors": [
            "Harshvardhan Uppaluru",
            "Hossein Rastgoftar"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper studies the problem of safe and optimal continuum deformation of a\nlarge-scale multi-agent system (MAS). We present a novel approach for MAS\ncontinuum deformation coordination that aims to achieve safe and efficient\nagent movement using a leader-follower multi-layer hierarchical optimization\nframework with a single input layer, multiple hidden layers, and a single\noutput layer. The input layer receives the reference (material) positions of\nthe primary leaders, the hidden layers compute the desired positions of the\ninterior leader agents and followers, and the output layer computes the nominal\nposition of the MAS configuration. By introducing a lower bound on the major\nprinciples of the strain field of the MAS deformation, we obtain linear\ninequality safety constraints and ensure inter-agent collision avoidance. The\ncontinuum deformation optimization is formulated as a quadratic programming\nproblem. It consists of the following components: (i) decision variables that\nrepresent the weights in the first hidden layer; (ii) a quadratic cost function\nthat penalizes deviation of the nominal MAS trajectory from the desired MAS\ntrajectory; and (iii) inequality safety constraints that ensure inter-agent\ncollision avoidance. To validate the proposed approach, we simulate and present\nthe results of continuum deformation on a large-scale quadcopter team tracking\na desired helix trajectory, demonstrating improvements in safety and\nefficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.06839v1"
    },
    {
        "title": "A Dynamic Heterogeneous Team-based Non-iterative Approach for Online\n  Pick-up and Just-In-Time Delivery Problems",
        "authors": [
            "Shridhar Velhal",
            "Srikrishna B R",
            "Mukunda Bharatheesha",
            "Suresh Sundaram"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper presents a non-iterative approach for finding the assignment of\nheterogeneous robots to efficiently execute online Pickup and Just-In-Time\nDelivery (PJITD) tasks with optimal resource utilization. The PJITD assignments\nproblem is formulated as a spatio-temporal multi-task assignment (STMTA)\nproblem. The physical constraints on the map and vehicle dynamics are\nincorporated in the cost formulation. The linear sum assignment problem is\nformulated for the heterogeneous STMTA problem. The recently proposed Dynamic\nResource Allocation with Multi-task assignments (DREAM) approach has been\nmodified to solve the heterogeneous PJITD problem. At the start, it computes\nthe minimum number of robots required (with their types) to execute given\nheterogeneous PJITD tasks. These required robots are added to the team to\nguarantee the feasibility of all PJITD tasks. Then robots in an updated team\nare assigned to execute the PJITD tasks while minimizing the total cost for the\nteam to execute all PJITD tasks. The performance of the proposed non-iterative\napproach has been validated using high-fidelity software-in-loop simulations\nand hardware experiments. The simulations and experimental results clearly\nindicate that the proposed approach is scalable and provides optimal resource\nutilization.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.07124v1"
    },
    {
        "title": "Coordinated Multi-Agent Reinforcement Learning for Unmanned Aerial\n  Vehicle Swarms in Autonomous Mobile Access Applications",
        "authors": [
            "Chanyoung Park",
            "Haemin Lee",
            "Won Joon Yun",
            "Soyi Jung",
            "Joongheon Kim"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  This paper proposes a novel centralized training and distributed execution\n(CTDE)-based multi-agent deep reinforcement learning (MADRL) method for\nmultiple unmanned aerial vehicles (UAVs) control in autonomous mobile access\napplications. For the purpose, a single neural network is utilized in\ncentralized training for cooperation among multiple agents while maximizing the\ntotal quality of service (QoS) in mobile access applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.08493v1"
    },
    {
        "title": "Smart Home Environment Modelled with a Multi-Agent System",
        "authors": [
            "Mohammad Rasras",
            "Iuliana Marin",
            "Serban Radu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  A smart home can be considered a place of residence that enables the\nmanagement of appliances and systems to help with day-to-day life by automated\ntechnology. In the current paper is described a prototype that simulates a\ncontext-aware environment, developed in a designed smart home. The smart home\nenvironment has been simulated using three agents and five locations in a\nhouse. The context-aware agents behave based on predefined rules designed for\ndaily activities. Our proposal aims to reduce operational cost of running\ndevices. In the future, monitors of health aspects belonging to home residents\nwill sustain their healthy life daily.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.08494v1"
    },
    {
        "title": "SEA: A Spatially Explicit Architecture for Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Dapeng Li",
            "Zhiwei Xu",
            "Bin Zhang",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Spatial information is essential in various fields. How to explicitly model\naccording to the spatial location of agents is also very important for the\nmulti-agent problem, especially when the number of agents is changing and the\nscale is enormous. Inspired by the point cloud task in computer vision, we\npropose a spatial information extraction structure for multi-agent\nreinforcement learning in this paper. Agents can effectively share the\nneighborhood and global information through a spatially encoder-decoder\nstructure. Our method follows the centralized training with decentralized\nexecution (CTDE) paradigm. In addition, our structure can be applied to various\nexisting mainstream reinforcement learning algorithms with minor modifications\nand can deal with the problem with a variable number of agents. The experiments\nin several multi-agent scenarios show that the existing methods can get\nconvincing results by adding our spatially explicit architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12532v1"
    },
    {
        "title": "Focusing on Information Context for ITS using a Spatial Age of\n  Information Model",
        "authors": [
            "Julian Heinovski",
            "Jorge Torres Gómez",
            "Falko Dressler"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  New technologies for sensing and communication act as enablers for\ncooperative driving applications. Sensors are able to detect objects in the\nsurrounding environment and information such as their current location is\nexchanged among vehicles. In order to cope with the vehicles' mobility, such\ninformation is required to be as fresh as possible for proper operation of\ncooperative driving applications. The age of information (AoI) has been\nproposed as a metric for evaluating freshness of information; recently also\nwithin the context of intelligent transportation systems (ITS). We investigate\nmechanisms to reduce the AoI of data transported in form of beacon messages\nwhile controlling their emission rate. We aim to balance packet collision\nprobability and beacon frequency using the average peak age of information\n(PAoI) as a metric. This metric, however, only accounts for the generation time\nof the data but not for application-specific aspects, such as the location of\nthe transmitting vehicle. We thus propose a new way of interpreting the AoI by\nconsidering information context, thereby incorporating vehicles' locations. As\nan example, we characterize such importance using the orientation and the\ndistance of the involved vehicles. In particular, we introduce a weighting\ncoefficient used in combination with the PAoI to evaluate the information\nfreshness, thus emphasizing on information from more important neighbors. We\nfurther design the beaconing approach in a way to meet a given AoI requirement,\nthus, saving resources on the wireless channel while keeping the AoI minimal.\nWe illustrate the effectiveness of our approach in Manhattan-like urban\nscenarios, reaching pre-specified targets for the AoI of beacon messages.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.12761v2"
    },
    {
        "title": "From Explicit Communication to Tacit Cooperation:A Novel Paradigm for\n  Cooperative MARL",
        "authors": [
            "Dapeng Li",
            "Zhiwei Xu",
            "Bin Zhang",
            "Guoliang Fan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Centralized training with decentralized execution (CTDE) is a widely-used\nlearning paradigm that has achieved significant success in complex tasks.\nHowever, partial observability issues and the absence of effectively shared\nsignals between agents often limit its effectiveness in fostering cooperation.\nWhile communication can address this challenge, it simultaneously reduces the\nalgorithm's practicality. Drawing inspiration from human team cooperative\nlearning, we propose a novel paradigm that facilitates a gradual shift from\nexplicit communication to tacit cooperation. In the initial training stage, we\npromote cooperation by sharing relevant information among agents and\nconcurrently reconstructing this information using each agent's local\ntrajectory. We then combine the explicitly communicated information with the\nreconstructed information to obtain mixed information. Throughout the training\nprocess, we progressively reduce the proportion of explicitly communicated\ninformation, facilitating a seamless transition to fully decentralized\nexecution without communication. Experimental results in various scenarios\ndemonstrate that the performance of our method without communication can\napproaches or even surpasses that of QMIX and communication-based methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.14656v1"
    },
    {
        "title": "An Integrated System Dynamics and Discrete Event Supply Chain Simulation\n  Framework for Supply Chain Resilience with Non-Stationary Pandemic Demand",
        "authors": [
            "Mustafa Can Camur",
            "Chin-Yuan Tseng",
            "Aristotelis E. Thanos",
            "Chelsea C. White",
            "Walter Yund",
            "Eleftherios Iakovou"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  COVID-19 resulted in some of the largest supply chain disruptions in recent\nhistory. To mitigate the impact of future disruptions, we propose an integrated\nhybrid simulation framework to couple nonstationary demand signals from an\nevent like COVID-19 with a model of an end-to-end supply chain. We first create\na system dynamics susceptible-infected-recovered (SIR) model, augmenting a\nclassic epidemiological model to create a realistic portrayal of demand\npatterns for oxygen concentrators (OC). Informed by this granular demand\nsignal, we then create a supply chain discrete event simulation model of OC\nsourcing, manufacturing, and distribution to test production augmentation\npolicies to satisfy this increased demand. This model utilizes publicly\navailable data, engineering teardowns of OCs, and a supply chain illumination\nto identify suppliers. Our findings indicate that this coupled approach can use\nrealistic demand during a disruptive event to enable rapid recommendations of\npolicies for increased supply chain resilience with controlled cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.00086v2"
    },
    {
        "title": "Achieving Realistic Cyclist Behavior in SUMO using the SimRa Dataset",
        "authors": [
            "Ahmet-Serdar Karakaya",
            "Ioan-Alexandru Stef",
            "Konstantin Köhler",
            "Julian Heinovski",
            "Falko Dressler",
            "David Bermbach"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Increasing the modal share of bicycle traffic to reduce carbon emissions,\nreduce urban car traffic, and to improve the health of citizens, requires a\nshift away from car-centric city planning. For this, traffic planners often\nrely on simulation tools such as SUMO which allow them to study the effects of\nconstruction changes before implementing them. Similarly, studies of vulnerable\nroad users, here cyclists, also use such models to assess the performance of\ncommunication-based road traffic safety systems. The cyclist model in SUMO,\nhowever, is very imprecise as SUMO cyclists behave either like slow cars or\nfast pedestrians, thus, casting doubt on simulation results for bicycle\ntraffic. In this paper, we analyze acceleration, deceleration, velocity, and\nintersection left-turn behavior of cyclists in a large dataset of real world\ncycle tracks. We use the results to improve the existing cyclist model in SUMO\nand add three more detailed cyclist models and implement them in SUMO.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.01763v2"
    },
    {
        "title": "System Neural Diversity: Measuring Behavioral Heterogeneity in\n  Multi-Agent Learning",
        "authors": [
            "Matteo Bettini",
            "Ajay Shankar",
            "Amanda Prorok"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Evolutionary science provides evidence that diversity confers resilience in\nnatural systems. Yet, traditional multi-agent reinforcement learning techniques\ncommonly enforce homogeneity to increase training sample efficiency. When a\nsystem of learning agents is not constrained to homogeneous policies,\nindividuals may develop diverse behaviors, resulting in emergent\ncomplementarity that benefits the system. Despite this, there is a surprising\nlack of tools that quantify behavioral diversity. Such techniques would pave\nthe way towards understanding the impact of diversity in collective artificial\nintelligence and enabling its control. In this paper, we introduce System\nNeural Diversity (SND): a measure of behavioral heterogeneity in multi-agent\nsystems. We discuss and prove its theoretical properties, and compare it with\nalternate, state-of-the-art behavioral diversity metrics used in the robotics\ndomain. Through simulations of a variety of cooperative multi-robot tasks, we\nshow how our metric constitutes an important tool that enables measurement and\ncontrol of behavioral heterogeneity. In dynamic tasks, where the problem is\naffected by repeated disturbances during training, we show that SND allows us\nto measure latent resilience skills acquired by the agents, while other\nproxies, such as task performance (reward), fail to. Finally, we show how the\nmetric can be employed to control diversity, allowing us to enforce a desired\nheterogeneity set-point or range. We demonstrate how this paradigm can be used\nto bootstrap the exploration phase, finding optimal policies faster, thus\nenabling novel and more efficient MARL paradigms.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.02128v2"
    },
    {
        "title": "Robust multi-agent coordination via evolutionary generation of auxiliary\n  adversarial attackers",
        "authors": [
            "Lei Yuan",
            "Zi-Qian Zhang",
            "Ke Xue",
            "Hao Yin",
            "Feng Chen",
            "Cong Guan",
            "Li-He Li",
            "Chao Qian",
            "Yang Yu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Cooperative multi-agent reinforcement learning (CMARL) has shown to be\npromising for many real-world applications. Previous works mainly focus on\nimproving coordination ability via solving MARL-specific challenges (e.g.,\nnon-stationarity, credit assignment, scalability), but ignore the policy\nperturbation issue when testing in a different environment. This issue hasn't\nbeen considered in problem formulation or efficient algorithm design. To\naddress this issue, we firstly model the problem as a limited policy adversary\nDec-POMDP (LPA-Dec-POMDP), where some coordinators from a team might\naccidentally and unpredictably encounter a limited number of malicious action\nattacks, but the regular coordinators still strive for the intended goal. Then,\nwe propose Robust Multi-Agent Coordination via Evolutionary Generation of\nAuxiliary Adversarial Attackers (ROMANCE), which enables the trained policy to\nencounter diversified and strong auxiliary adversarial attacks during training,\nthus achieving high robustness under various policy perturbations. Concretely,\nto avoid the ego-system overfitting to a specific attacker, we maintain a set\nof attackers, which is optimized to guarantee the attackers high attacking\nquality and behavior diversity. The goal of quality is to minimize the\nego-system coordination effect, and a novel diversity regularizer based on\nsparse action is applied to diversify the behaviors among attackers. The\nego-system is then paired with a population of attackers selected from the\nmaintained attacker set, and alternately trained against the constantly\nevolving attackers. Extensive experiments on multiple scenarios from SMAC\nindicate our ROMANCE provides comparable or better robustness and\ngeneralization ability than other baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.05909v1"
    },
    {
        "title": "Multi-Value Alignment in Normative Multi-Agent System: Evolutionary\n  Optimisation Approach",
        "authors": [
            "Maha Riad",
            "Vinicius Renan de Carvalho",
            "Fatemeh Golpayegani"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Value-alignment in normative multi-agent systems is used to promote a certain\nvalue and to ensure the consistent behavior of agents in autonomous intelligent\nsystems with human values. However, the current literature is limited to\nincorporation of effective norms for single value alignment with no\nconsideration of agents' heterogeneity and the requirement of simultaneous\npromotion and alignment of multiple values. This research proposes a\nmulti-value promotion model that uses multi-objective evolutionary algorithms\nto produce the optimum parametric set of norms that is aligned with multiple\nsimultaneous values of heterogeneous agents and the system. To understand\nvarious aspects of this complex problem, several evolutionary algorithms were\nused to find a set of optimised norm parameters considering two toy tax\nscenarios with two and five values are considered. The results are analysed\nfrom different perspectives to show the impact of a selected evolutionary\nalgorithm on the solution, and the importance of understanding the relation\nbetween values when prioritising them.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.07366v1"
    },
    {
        "title": "Set-Membership Filtering-Based Cooperative State Estimation for\n  Multi-Agent Systems",
        "authors": [
            "Yu Ding",
            "Yirui Cong",
            "Xiangke Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this article, we focus on the cooperative state estimation problem of a\nmulti-agent system. Each agent is equipped with absolute and relative\nmeasurements. The purpose of this research is to make each agent generate its\nown state estimation with only local measurement information and local\ncommunication with neighborhood agents using Set Membership Filter(SMF). To\nhandle this problem, we analyzed centralized SMF framework as a benchmark of\ndistributed SMF and propose a finite-horizon method called OIT-Inspired\ncentralized constrained zonotopic algorithm. Moreover, we put forward a\ndistributed Set Membership Filtering(SMFing) framework and develop a\ndistributed constained zonotopic algorithm. Finally, simulation verified our\ntheoretical results, that our proposed algorithms can effectively estimate the\nstate of each agent.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.10366v1"
    },
    {
        "title": "Bayesian calibration of differentiable agent-based models",
        "authors": [
            "Arnau Quera-Bofarull",
            "Ayush Chopra",
            "Anisoara Calinescu",
            "Michael Wooldridge",
            "Joel Dyer"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Agent-based modelling (ABMing) is a powerful and intuitive approach to\nmodelling complex systems; however, the intractability of ABMs' likelihood\nfunctions and the non-differentiability of the mathematical operations\ncomprising these models present a challenge to their use in the real world.\nThese difficulties have in turn generated research on approximate Bayesian\ninference methods for ABMs and on constructing differentiable approximations to\narbitrary ABMs, but little work has been directed towards designing approximate\nBayesian inference techniques for the specific case of differentiable ABMs. In\nthis work, we aim to address this gap and discuss how generalised variational\ninference procedures may be employed to provide misspecification-robust\nBayesian parameter inferences for differentiable ABMs. We demonstrate with\nexperiments on a differentiable ABM of the COVID-19 pandemic that our approach\ncan result in accurate inferences, and discuss avenues for future work.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.15340v1"
    },
    {
        "title": "Leveraging Human Feedback to Evolve and Discover Novel Emergent\n  Behaviors in Robot Swarms",
        "authors": [
            "Connor Mattson",
            "Daniel S. Brown"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Robot swarms often exhibit emergent behaviors that are fascinating to\nobserve; however, it is often difficult to predict what swarm behaviors can\nemerge under a given set of agent capabilities. We seek to efficiently leverage\nhuman input to automatically discover a taxonomy of collective behaviors that\ncan emerge from a particular multi-agent system, without requiring the human to\nknow beforehand what behaviors are interesting or even possible. Our proposed\napproach adapts to user preferences by learning a similarity space over swarm\ncollective behaviors using self-supervised learning and human-in-the-loop\nqueries. We combine our learned similarity metric with novelty search and\nclustering to explore and categorize the space of possible swarm behaviors. We\nalso propose several general-purpose heuristics that improve the efficiency of\nour novelty search by prioritizing robot controllers that are likely to lead to\ninteresting emergent behaviors. We test our approach in simulation on two robot\ncapability models and show that our methods consistently discover a richer set\nof emergent behaviors than prior work. Code, videos, and datasets are available\nat https://sites.google.com/view/evolving-novel-swarms.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.16148v2"
    },
    {
        "title": "Fine-Grained Complexity Analysis of Multi-Agent Path Finding on 2D Grids",
        "authors": [
            "Tzvika Geft"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-Agent Path Finding (MAPF) is a fundamental motion coordination problem\narising in multi-agent systems with a wide range of applications. The problem's\nintractability has led to extensive research on improving the scalability of\nsolvers for it. Since optimal solvers can struggle to scale, a major challenge\nthat arises is understanding what makes MAPF hard. We tackle this challenge\nthrough a fine-grained complexity analysis of time-optimal MAPF on 2D grids,\nthereby closing two gaps and identifying a new tractability frontier. First, we\nshow that 2-colored MAPF, i.e., where the agents are divided into two teams,\neach with its own set of targets, remains NP-hard. Second, for the flowtime\nobjective (also called sum-of-costs), we show that it remains NP-hard to find a\nsolution in which agents have an individually optimal cost, which we call an\nindividually optimal solution. The previously tightest results for these MAPF\nvariants are for (non-grid) planar graphs. We use a single hardness\nconstruction that replaces, strengthens, and unifies previous proofs. We\nbelieve that it is also simpler than previous proofs for the planar case as it\nemploys minimal gadgets that enable its full visualization in one figure.\nFinally, for the flowtime objective, we establish a tractability frontier based\non the number of directions agents can move in. Namely, we complement our\nhardness result, which holds for three directions, with an efficient algorithm\nfor finding an individually optimal solution if only two directions are\nallowed. This result sheds new light on the structure of optimal solutions,\nwhich may help guide algorithm design for the general problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.16303v1"
    },
    {
        "title": "Trust-Aware Resilient Control and Coordination of Connected and\n  Automated Vehicles",
        "authors": [
            "H M Sabbir Ahmad",
            "Ehsan Sabouni",
            "Wei Xiao",
            "Christos G. Cassandras",
            "Wenchao Li"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We address the security of a network of Connected and Automated Vehicles\n(CAVs) cooperating to navigate through a conflict area. Adversarial attacks\nsuch as Sybil attacks can cause safety violations resulting in collisions and\ntraffic jams. In addition, uncooperative (but not necessarily adversarial) CAVs\ncan also induce similar adversarial effects on the traffic network. We propose\na decentralized resilient control and coordination scheme that mitigates the\neffects of adversarial attacks and uncooperative CAVs by utilizing a trust\nframework. Our trust-aware scheme can guarantee safe collision free\ncoordination and mitigate traffic jams. Simulation results validate the\ntheoretical guarantee of our proposed scheme, and demonstrate that it can\neffectively mitigate adversarial effects across different traffic scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.16818v2"
    },
    {
        "title": "Research on Multi-Agent Communication and Collaborative Decision-Making\n  Based on Deep Reinforcement Learning",
        "authors": [
            "Zeng Da"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In a multi-agent environment, In order to overcome and alleviate the\nnon-stationarity of the multi-agent environment, the mainstream method is to\nadopt the framework of Centralized Training Decentralized Execution (CTDE).\nThis thesis is based on the framework of CTDE, and studies the cooperative\ndecision-making of multi-agent based on the Multi-Agent Proximal Policy\nOptimization (MAPPO) algorithm for multi-agent proximal policy optimization. In\norder to alleviate the non-stationarity of the multi-agent environment, a\nmulti-agent communication mechanism based on weight scheduling and attention\nmodule is introduced. Different agents can alleviate the non-stationarity\ncaused by local observations through information exchange between agents,\nassisting in the collaborative decision-making of agents. The specific method\nis to introduce a communication module in the policy network part. The\ncommunication module is composed of a weight generator, a weight scheduler, a\nmessage encoder, a message pool and an attention module. Among them, the weight\ngenerator and weight scheduler will generate weights as the selection basis for\ncommunication, the message encoder is used to compress and encode communication\ninformation, the message pool is used to store communication messages, and the\nattention module realizes the interactive processing of the agent's own\ninformation and communication information. This thesis proposes a Multi-Agent\nCommunication and Global Information Optimization Proximal Policy\nOptimization(MCGOPPO)algorithm, and conducted experiments in the SMAC and the\nMPE. The experimental results show that the improvement has achieved certain\neffects, which can better alleviate the non-stationarity of the multi-agent\nenvironment, and improve the collaborative decision-making ability among the\nagents.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.17141v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Cooperative Air Transportation\n  Services in City-Wide Autonomous Urban Air Mobility",
        "authors": [
            "Chanyoung Park",
            "Gyu Seon Kim",
            "Soohyun Park",
            "Soyi Jung",
            "Joongheon Kim"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The development of urban-air-mobility (UAM) is rapidly progressing with\nspurs, and the demand for efficient transportation management systems is a\nrising need due to the multifaceted environmental uncertainties. Thus, this\npaper proposes a novel air transportation service management algorithm based on\nmulti-agent deep reinforcement learning (MADRL) to address the challenges of\nmulti-UAM cooperation. Specifically, the proposed algorithm in this paper is\nbased on communication network (CommNet) method utilizing centralized training\nand distributed execution (CTDE) in multiple UAMs for providing efficient air\ntransportation services to passengers collaboratively. Furthermore, this paper\nadopts actual vertiport maps and UAM specifications for constructing realistic\nair transportation networks. By evaluating the performance of the proposed\nalgorithm in data-intensive simulations, the results show that the proposed\nalgorithm outperforms existing approaches in terms of air transportation\nservice quality. Furthermore, there are no inferior UAMs by utilizing parameter\nsharing in CommNet and a centralized critic network in CTDE. Therefore, it can\nbe confirmed that the research results in this paper can provide a promising\nsolution for autonomous air transportation management systems in city-wide\nurban areas.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.04137v1"
    },
    {
        "title": "iPLAN: Intent-Aware Planning in Heterogeneous Traffic via Distributed\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Xiyang Wu",
            "Rohan Chandra",
            "Tianrui Guan",
            "Amrit Singh Bedi",
            "Dinesh Manocha"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Navigating safely and efficiently in dense and heterogeneous traffic\nscenarios is challenging for autonomous vehicles (AVs) due to their inability\nto infer the behaviors or intentions of nearby drivers. In this work, we\nintroduce a distributed multi-agent reinforcement learning (MARL) algorithm\nthat can predict trajectories and intents in dense and heterogeneous traffic\nscenarios. Our approach for intent-aware planning, iPLAN, allows agents to\ninfer nearby drivers' intents solely from their local observations. We model\ntwo distinct incentives for agents' strategies: Behavioral Incentive for\nhigh-level decision-making based on their driving behavior or personality and\nInstant Incentive for motion planning for collision avoidance based on the\ncurrent traffic state. Our approach enables agents to infer their opponents'\nbehavior incentives and integrate this inferred information into their\ndecision-making and motion-planning processes. We perform experiments on two\nsimulation environments, Non-Cooperative Navigation and Heterogeneous Highway.\nIn Heterogeneous Highway, results show that, compared with centralized training\ndecentralized execution (CTDE) MARL baselines such as QMIX and MAPPO, our\nmethod yields a 4.3% and 38.4% higher episodic reward in mild and chaotic\ntraffic, with 48.1% higher success rate and 80.6% longer survival time in\nchaotic traffic. We also compare with a decentralized training decentralized\nexecution (DTDE) baseline IPPO and demonstrate a higher episodic reward of\n12.7% and 6.3% in mild traffic and chaotic traffic, 25.3% higher success rate,\nand 13.7% longer survival time.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.06236v3"
    },
    {
        "title": "Measuring and Controlling Divisiveness in Rank Aggregation",
        "authors": [
            "Rachael Colley",
            "Umberto Grandi",
            "César Hidalgo",
            "Mariana Macedo",
            "Carlos Navarrete"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In rank aggregation, members of a population rank issues to decide which are\ncollectively preferred. We focus instead on identifying divisive issues that\nexpress disagreements among the preferences of individuals. We analyse the\nproperties of our divisiveness measures and their relation to existing notions\nof polarisation. We also study their robustness under incomplete preferences\nand algorithms for control and manipulation of divisiveness. Our results\nadvance our understanding of how to quantify disagreements in collective\ndecision-making.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.08511v1"
    },
    {
        "title": "Some challenges of calibrating differentiable agent-based models",
        "authors": [
            "Arnau Quera-Bofarull",
            "Joel Dyer",
            "Anisoara Calinescu",
            "Michael Wooldridge"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Agent-based models (ABMs) are a promising approach to modelling and reasoning\nabout complex systems, yet their application in practice is impeded by their\ncomplexity, discrete nature, and the difficulty of performing parameter\ninference and optimisation tasks. This in turn has sparked interest in the\nconstruction of differentiable ABMs as a strategy for combatting these\ndifficulties, yet a number of challenges remain. In this paper, we discuss and\npresent experiments that highlight some of these challenges, along with\npotential solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.01085v1"
    },
    {
        "title": "Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems",
        "authors": [
            "Nathalia Nascimento",
            "Paulo Alencar",
            "Donald Cowan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In autonomic computing, self-adaptation has been proposed as a fundamental\nparadigm to manage the complexity of multiagent systems (MASs). This achieved\nby extending a system with support to monitor and adapt itself to achieve\nspecific concerns of interest. Communication in these systems is key given that\nin scenarios involving agent interaction, it enhances cooperation and reduces\ncoordination challenges by enabling direct, clear information exchange.\nHowever, improving the expressiveness of the interaction communication with\nMASs is not without challenges. In this sense, the interplay between\nself-adaptive systems and effective communication is crucial for future MAS\nadvancements. In this paper, we propose the integration of large language\nmodels (LLMs) such as GPT-based technologies into multiagent systems. We anchor\nour methodology on the MAPE-K model, which is renowned for its robust support\nin monitoring, analyzing, planning, and executing system adaptations in\nresponse to dynamic environments. We also present a practical illustration of\nthe proposed approach, in which we implement and assess a basic MAS-based\napplication. The approach significantly advances the state-of-the-art of\nself-adaptive systems by proposing a new paradigm for MAS self-adaptation of\nautonomous systems based on LLM capabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06187v1"
    },
    {
        "title": "Inferring epidemic dynamics using Gaussian process emulation of\n  agent-based simulations",
        "authors": [
            "Abdulrahman A. Ahmed",
            "M. Amin Rahimian",
            "Mark S. Roberts"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Computational models help decision makers understand epidemic dynamics to\noptimize public health interventions. Agent-based simulation of disease spread\nin synthetic populations allows us to compare and contrast different effects\nacross identical populations or to investigate the effect of interventions\nkeeping every other factor constant between ``digital twins''. FRED (A\nFramework for Reconstructing Epidemiological Dynamics) is an agent-based\nmodeling system with a geo-spatial perspective using a synthetic population\nthat is constructed based on the U.S. census data. In this paper, we show how\nGaussian process regression can be used on FRED-synthesized data to infer the\ndiffering spatial dispersion of the epidemic dynamics for two disease\nconditions that start from the same initial conditions and spread among\nidentical populations. Our results showcase the utility of agent-based\nsimulation frameworks such as FRED for inferring differences between conditions\nwhere controlling for all confounding factors for such comparisons is next to\nimpossible without synthetic data.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12186v2"
    },
    {
        "title": "ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning",
        "authors": [
            "Xin Yu",
            "Rongye Shi",
            "Pu Feng",
            "Yongkai Tian",
            "Jie Luo",
            "Wenjun Wu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent reinforcement learning (MARL) has achieved promising results in\nrecent years. However, most existing reinforcement learning methods require a\nlarge amount of data for model training. In addition, data-efficient\nreinforcement learning requires the construction of strong inductive biases,\nwhich are ignored in the current MARL approaches. Inspired by the symmetry\nphenomenon in multi-agent systems, this paper proposes a framework for\nexploiting prior knowledge by integrating data augmentation and a well-designed\nconsistency loss into the existing MARL methods. In addition, the proposed\nframework is model-agnostic and can be applied to most of the current MARL\nalgorithms. Experimental tests on multiple challenging tasks demonstrate the\neffectiveness of the proposed framework. Moreover, the proposed framework is\napplied to a physical multi-robot testbed to show its superiority.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.16186v2"
    },
    {
        "title": "Cooperative Multi-Type Multi-Agent Deep Reinforcement Learning for\n  Resource Management in Space-Air-Ground Integrated Networks",
        "authors": [
            "Hengxi Zhang",
            "Huaze Tang",
            "Wenbo Ding",
            "Xiao-Ping Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The Space-Air-Ground Integrated Network (SAGIN), integrating heterogeneous\ndevices including low earth orbit (LEO) satellites, unmanned aerial vehicles\n(UAVs), and ground users (GUs), holds significant promise for advancing smart\ncity applications. However, resource management of the SAGIN is a challenge\nrequiring urgent study in that inappropriate resource management will cause\npoor data transmission, and hence affect the services in smart cities. In this\npaper, we develop a comprehensive SAGIN system that encompasses five distinct\ncommunication links and propose an efficient cooperative multi-type multi-agent\ndeep reinforcement learning (CMT-MARL) method to address the resource\nmanagement issue. The experimental results highlight the efficacy of the\nproposed CMT-MARL, as evidenced by key performance indicators such as the\noverall transmission rate and transmission success rate. These results\nunderscore the potential value and feasibility of future implementation of the\nSAGIN.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.03995v1"
    },
    {
        "title": "Strategic Interactions in Multi-modal Mobility Systems: A Game-Theoretic\n  Perspective",
        "authors": [
            "Gioele Zardini",
            "Nicolas Lanzetti",
            "Giuseppe Belgioioso",
            "Christian Hartnik",
            "Saverio Bolognani",
            "Florian Dörfler",
            "Emilio Frazzoli"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The evolution of existing transportation systems,mainly driven by\nurbanization and increased availability of mobility options, such as private,\nprofit-maximizing ride-hailing companies, calls for tools to reason about their\ndesign and regulation. To study this complex socio-technical problem, one needs\nto account for the strategic interactions of the heterogeneous stakeholders\ninvolved in the mobility ecosystem and analyze how they influence the system.\nIn this paper, we focus on the interactions between citizens who compete for\nthe limited resources of a mobility system to complete their desired trip.\nSpecifically, we present a game-theoretic framework for multi-modal mobility\nsystems, where citizens, characterized by heterogeneous preferences, have\naccess to various mobility options and seek individually-optimal decisions. We\nstudy the arising game and prove the existence of an equilibrium, which can be\nefficiently computed via a convex optimization problem. Through both an\nanalytical and a numerical case study for the classic scenario of Sioux Falls,\nUSA, we illustrate the capabilities of our model and perform sensitivity\nanalyses. Importantly, we show how to embed our framework into a \"larger\" game\namong stakeholders of the mobility ecosystem (e.g., municipality, Mobility\nService Providers, and citizens), effectively giving rise to tools to inform\nstrategic interventions and policy-making in the mobility ecosystem.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.04820v1"
    },
    {
        "title": "Fast Decision Support for Air Traffic Management at Urban Air Mobility\n  Vertiports using Graph Learning",
        "authors": [
            "Prajit KrisshnaKumar",
            "Jhoel Witter",
            "Steve Paul",
            "Hanvit Cho",
            "Karthik Dantu",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Urban Air Mobility (UAM) promises a new dimension to decongested, safe, and\nfast travel in urban and suburban hubs. These UAM aircraft are conceived to\noperate from small airports called vertiports each comprising multiple\ntake-off/landing and battery-recharging spots. Since they might be situated in\ndense urban areas and need to handle many aircraft landings and take-offs each\nhour, managing this schedule in real-time becomes challenging for a traditional\nair-traffic controller but instead calls for an automated solution. This paper\nprovides a novel approach to this problem of Urban Air Mobility - Vertiport\nSchedule Management (UAM-VSM), which leverages graph reinforcement learning to\ngenerate decision-support policies. Here the designated physical spots within\nthe vertiport's airspace and the vehicles being managed are represented as two\nseparate graphs, with feature extraction performed through a graph\nconvolutional network (GCN). Extracted features are passed onto perceptron\nlayers to decide actions such as continue to hover or cruise, continue idling\nor take-off, or land on an allocated vertiport spot. Performance is measured\nbased on delays, safety (no. of collisions) and battery consumption. Through\nrealistic simulations in AirSim applied to scaled down multi-rotor vehicles,\nour results demonstrate the suitability of using graph reinforcement learning\nto solve the UAM-VSM problem and its superiority to basic reinforcement\nlearning (with graph embeddings) or random choice baselines.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09075v1"
    },
    {
        "title": "Intelligent Communication Planning for Constrained Environmental IoT\n  Sensing with Reinforcement Learning",
        "authors": [
            "Yi Hu",
            "Jinhang Zuo",
            "Bob Iannucci",
            "Carlee Joe-Wong"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Internet of Things (IoT) technologies have enabled numerous data-driven\nmobile applications and have the potential to significantly improve\nenvironmental monitoring and hazard warnings through the deployment of a\nnetwork of IoT sensors. However, these IoT devices are often power-constrained\nand utilize wireless communication schemes with limited bandwidth. Such power\nconstraints limit the amount of information each device can share across the\nnetwork, while bandwidth limitations hinder sensors' coordination of their\ntransmissions. In this work, we formulate the communication planning problem of\nIoT sensors that track the state of the environment. We seek to optimize\nsensors' decisions in collecting environmental data under stringent resource\nconstraints. We propose a multi-agent reinforcement learning (MARL) method to\nfind the optimal communication policies for each sensor that maximize the\ntracking accuracy subject to the power and bandwidth limitations. MARL learns\nand exploits the spatial-temporal correlation of the environmental data at each\nsensor's location to reduce the redundant reports from the sensors. Experiments\non wildfire spread with LoRA wireless network simulators show that our MARL\nmethod can learn to balance the need to collect enough data to predict wildfire\nspread with unknown bandwidth limitations.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.10124v1"
    },
    {
        "title": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems",
        "authors": [
            "Nathalia Nascimento",
            "Paulo Alencar",
            "Donald Cowan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper introduces the \"GPT-in-the-loop\" approach, a novel method\ncombining the advanced reasoning capabilities of Large Language Models (LLMs)\nlike Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems.\nVenturing beyond traditional adaptive approaches that generally require long\ntraining processes, our framework employs GPT-4 for enhanced problem-solving\nand explanation skills. Our experimental backdrop is the smart streetlight\nInternet of Things (IoT) application. Here, agents use sensors, actuators, and\nneural networks to create an energy-efficient lighting system. By integrating\nGPT-4, these agents achieve superior decision-making and adaptability without\nthe need for extensive training. We compare this approach with both traditional\nneuroevolutionary methods and solutions provided by software engineers,\nunderlining the potential of GPT-driven multiagent systems in IoT.\nStructurally, the paper outlines the incorporation of GPT into the agent-driven\nFramework for the Internet of Things (FIoT), introduces our proposed\nGPT-in-the-loop approach, presents comparative results in the IoT context, and\nconcludes with insights and future directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.10435v1"
    },
    {
        "title": "${\\rm E}(3)$-Equivariant Actor-Critic Methods for Cooperative\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Dingyang Chen",
            "Qi Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Identification and analysis of symmetrical patterns in the natural world have\nled to significant discoveries across various scientific fields, such as the\nformulation of gravitational laws in physics and advancements in the study of\nchemical structures. In this paper, we focus on exploiting Euclidean symmetries\ninherent in certain cooperative multi-agent reinforcement learning (MARL)\nproblems and prevalent in many applications. We begin by formally\ncharacterizing a subclass of Markov games with a general notion of symmetries\nthat admits the existence of symmetric optimal values and policies. Motivated\nby these properties, we design neural network architectures with symmetric\nconstraints embedded as an inductive bias for multi-agent actor-critic methods.\nThis inductive bias results in superior performance in various cooperative MARL\nbenchmarks and impressive generalization capabilities such as zero-shot\nlearning and transfer learning in unseen scenarios with repeated symmetric\npatterns. The code is available at: https://github.com/dchen48/E3AC.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.11842v3"
    },
    {
        "title": "Estimating Treatment Effects Using Costly Simulation Samples from a\n  Population-Scale Model of Opioid Use Disorder",
        "authors": [
            "Abdulrahman A. Ahmed",
            "M. Amin Rahimian",
            "Mark S. Roberts"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Large-scale models require substantial computational resources for analysis\nand studying treatment conditions. Specifically, estimating treatment effects\nusing simulations may require a lot of infeasible resources to allocate at\nevery treatment condition. Therefore, it is essential to develop efficient\nmethods to allocate computational resources for estimating treatment effects.\nAgent-based simulation allows us to generate highly realistic simulation\nsamples. FRED (A Framework for Reconstructing Epidemiological Dynamics) is an\nagent-based modeling system with a geospatial perspective using a synthetic\npopulation constructed based on the U.S. census data. Given its synthetic\npopulation, FRED simulations present a baseline for comparable results from\ndifferent treatment conditions and treatment conditions. In this paper, we show\nthree other methods for estimating treatment effects. In the first method, we\nresort to brute-force allocation, where all treatment conditions have an equal\nnumber of samples with a relatively large number of simulation runs. In the\nsecond method, we try to reduce the number of simulation runs by customizing\nindividual samples required for each treatment effect based on the width of\nconfidence intervals around the mean estimates. In the third method, we use a\nregression model, which allows us to learn across the treatment conditions such\nthat simulation samples allocated for a treatment condition will help better\nestimate treatment effects in other conditions. We show that the\nregression-based methods result in a comparable estimate of treatment effects\nwith less computational resources. The reduced variability and faster\nconvergence of model-based estimates come at the cost of increased bias, and\nthe bias-variance trade-off can be controlled by adjusting the number of model\nparameters (e.g., including higher-order interaction terms in the regression\nmodel).\n",
        "pdf_link": "http://arxiv.org/pdf/2308.13040v1"
    },
    {
        "title": "Grassroots Flash: A Payment System for Grassroots Cryptocurrencies",
        "authors": [
            "Andrew Lewis-Pye",
            "Oded Naor",
            "Ehud Shapiro"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The goal of grassroots cryptocurrencies is to provide a foundation with which\nlocal digital economies can emerge independently of each other and of global\ndigital platforms and global cryptocurrencies; can form and grow without\ninitial capital or external credit; can trade with each other; and can\ngradually merge into a global digital economy. Grassroots cryptocurrencies turn\nmutual trust into liquidity and thus could be a powerful means for 'banking the\nunbanked'. Grassroots cryptocurrencies have not been provided yet with a\npayment system, which is the goal of this paper. Here, we present Grassroots\nFlash, a payment system for grassroots cryptocurrencies that employs the\nblocklace -- a DAG-like counterpart of the blockchain data structure. We\nanalyze its security (safety, liveness, and privacy) and efficiency, prove that\nit is indeed grassroots.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.13191v1"
    },
    {
        "title": "Deconstructing Cooperation and Ostracism via Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Atsushi Ueshima",
            "Shayegan Omidshafiei",
            "Hirokazu Shirado"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Cooperation is challenging in biological systems, human societies, and\nmulti-agent systems in general. While a group can benefit when everyone\ncooperates, it is tempting for each agent to act selfishly instead. Prior human\nstudies show that people can overcome such social dilemmas while choosing\ninteraction partners, i.e., strategic network rewiring. However, little is\nknown about how agents, including humans, can learn about cooperation from\nstrategic rewiring and vice versa. Here, we perform multi-agent reinforcement\nlearning simulations in which two agents play the Prisoner's Dilemma game\niteratively. Each agent has two policies: one controls whether to cooperate or\ndefect; the other controls whether to rewire connections with another agent.\nThis setting enables us to disentangle complex causal dynamics between\ncooperation and network rewiring. We find that network rewiring facilitates\nmutual cooperation even when one agent always offers cooperation, which is\nvulnerable to free-riding. We then confirm that the network-rewiring effect is\nexerted through agents' learning of ostracism, that is, connecting to\ncooperators and disconnecting from defectors. However, we also find that\nostracism alone is not sufficient to make cooperation emerge. Instead,\nostracism emerges from the learning of cooperation, and existing cooperation is\nsubsequently reinforced due to the presence of ostracism. Our findings provide\ninsights into the conditions and mechanisms necessary for the emergence of\ncooperation with network rewiring.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.04623v1"
    },
    {
        "title": "A Multi-Agent Systems Approach for Peer-to-Peer Energy Trading in Dairy\n  Farming",
        "authors": [
            "Mian Ibad Ali Shah",
            "Abdul Wahid",
            "Enda Barrett",
            "Karl Mason"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  To achieve desired carbon emission reductions, integrating renewable\ngeneration and accelerating the adoption of peer-to-peer energy trading is\ncrucial. This is especially important for energy-intensive farming, like dairy\nfarming. However, integrating renewables and peer-to-peer trading presents\nchallenges. To address this, we propose the Multi-Agent Peer-to-Peer Dairy Farm\nEnergy Simulator (MAPDES), enabling dairy farms to participate in peer-to-peer\nmarkets. Our strategy reduces electricity costs and peak demand by\napproximately 30% and 24% respectively, while increasing energy sales by 37%\ncompared to the baseline scenario without P2P trading. This demonstrates the\neffectiveness of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.05932v1"
    },
    {
        "title": "Leader-Follower Formation Control of Perturbed Nonholonomic Agents along\n  Parametric Curves with Directed Communication",
        "authors": [
            "Bin Zhang",
            "Hui Zhi",
            "Jose Guadalupe Romero",
            "David Navarro-Alarcon"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we propose a novel formation controller for nonholonomic\nagents to form general parametric curves. First, we derive a unified parametric\nrepresentation for both open and closed curves. Then, a leader-follower\nformation controller is designed to form the parametric curves. We consider\ndirected communications and constant input disturbances rejection in the\ncontroller design. Rigorous Lyapunov-based stability analysis proves the\nasymptotic stability of the proposed controller. Detailed numerical simulations\nand experimental studies are conducted to verify the performance of the\nproposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.07608v1"
    },
    {
        "title": "Welfare Diplomacy: Benchmarking Language Model Cooperation",
        "authors": [
            "Gabriel Mukobi",
            "Hannah Erlebach",
            "Niklas Lauffer",
            "Lewis Hammond",
            "Alan Chan",
            "Jesse Clifton"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The growing capabilities and increasingly widespread deployment of AI systems\nnecessitate robust benchmarks for measuring their cooperative capabilities.\nUnfortunately, most multi-agent benchmarks are either zero-sum or purely\ncooperative, providing limited opportunities for such measurements. We\nintroduce a general-sum variant of the zero-sum board game Diplomacy -- called\nWelfare Diplomacy -- in which players must balance investing in military\nconquest and domestic welfare. We argue that Welfare Diplomacy facilitates both\na clearer assessment of and stronger training incentives for cooperative\ncapabilities. Our contributions are: (1) proposing the Welfare Diplomacy rules\nand implementing them via an open-source Diplomacy engine; (2) constructing\nbaseline agents using zero-shot prompted language models; and (3) conducting\nexperiments where we find that baselines using state-of-the-art models attain\nhigh social welfare but are exploitable. Our work aims to promote societal\nsafety by aiding researchers in developing and assessing multi-agent AI\nsystems. Code to evaluate Welfare Diplomacy and reproduce our experiments is\navailable at https://github.com/mukobi/welfare-diplomacy.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.08901v1"
    },
    {
        "title": "Where to Decide? Centralized vs. Distributed Vehicle Assignment for\n  Platoon Formation",
        "authors": [
            "Julian Heinovski",
            "Falko Dressler"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Platooning is a promising cooperative driving application for future\nintelligent transportation systems. In order to assign vehicles to platoons,\nsome algorithm for platoon formation is required. Such vehicle-to-platoon\nassignments have to be computed on-demand, e.g., when vehicles join or leave\nthe freeways. In order to get best results from platooning, individual\nproperties of involved vehicles have to be considered during the assignment\ncomputation. In this paper, we explore the computation of vehicle-to-platoon\nassignments as an optimization problem based on similarity between vehicles. We\ndefine the similarity and, vice versa, the deviation among vehicles based on\nthe desired driving speed of vehicles and their position on the road. We create\nthree approaches to solve this assignment problem: centralized solver,\ncentralized greedy, and distributed greedy, using a Mixed Integer Programming\n(MIP) solver and greedy heuristics, respectively. Conceptually, the approaches\ndiffer in both knowledge about vehicles as well as methodology. We perform a\nlarge-scale simulation study using PlaFoSim to compare all approaches. While\nthe distributed greedy approach seems to have disadvantages due to the limited\nlocal knowledge, it performs as good as the centralized solver approach across\nmost metrics. Both outperform the centralized greedy approach, which suffers\nfrom synchronization and greedy selection effects. The centralized solver\napproach however assumes global knowledge and requires a complex MIP solver to\ncompute vehicle-to-platoon assignments. Overall, the distributed greedy\napproach achieves close to optimal results but requires the least assumptions\nand complexity. Therefore, we consider the distributed greedy approach the best\napproach among all presented approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09580v4"
    },
    {
        "title": "Safe Region Multi-Agent Formation Control With Velocity Tracking",
        "authors": [
            "Ayush Rai",
            "Shaoshuai Mou"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper provides a solution to the problem of safe region formation\ncontrol with reference velocity tracking for a second-order multi-agent system\nwithout velocity measurements. Safe region formation control is a control\nproblem where the agents are expected to attain the desired formation while\nreaching the target region and simultaneously ensuring collision and obstacle\navoidance. To tackle this control problem, we break it down into two distinct\nobjectives: safety and region formation control, to provide a completely\ndistributed algorithm. Region formation control is modeled as a high-level\nabstract objective, whereas safety and actuator saturation are modeled as a\nlow-level objective designed independently, without any knowledge of the\nformer, and being minimally invasive. Our approach incorporates connectivity\npreservation, actuator saturation, safety considerations, and lack of velocity\nmeasurement from other agents with second-order system dynamics which are\nimportant constraints in practical applications. Both internal safety for\ncollision avoidance among agents and external safety for avoiding unsafe\nregions are ensured using exponential control barrier functions. We provide\ntheoretical results for asymptotic convergence and numerical simulation to show\nthe approach's effectiveness.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09681v1"
    },
    {
        "title": "Approximate Multiagent Reinforcement Learning for On-Demand Urban\n  Mobility Problem on a Large Map (extended version)",
        "authors": [
            "Daniel Garces",
            "Sushmita Bhattacharya",
            "Dimitri Bertsekas",
            "Stephanie Gil"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we focus on the autonomous multiagent taxi routing problem for\na large urban environment where the location and number of future ride requests\nare unknown a-priori, but can be estimated by an empirical distribution. Recent\ntheory has shown that a rollout algorithm with a stable base policy produces a\nnear-optimal stable policy. In the routing setting, a policy is stable if its\nexecution keeps the number of outstanding requests uniformly bounded over time.\nAlthough, rollout-based approaches are well-suited for learning cooperative\nmultiagent policies with considerations for future demand, applying such\nmethods to a large urban environment can be computationally expensive due to\nthe large number of taxis required for stability. In this paper, we aim to\naddress the computational bottleneck of multiagent rollout by proposing an\napproximate multiagent rollout-based two phase algorithm that reduces\ncomputational costs, while still achieving a stable near-optimal policy. Our\napproach partitions the graph into sectors based on the predicted demand and\nthe maximum number of taxis that can run sequentially given the user's\ncomputational resources. The algorithm then applies instantaneous assignment\n(IA) for re-balancing taxis across sectors and a sector-wide multiagent rollout\nalgorithm that is executed in parallel for each sector. We provide two main\ntheoretical results: 1) characterize the number of taxis $m$ that is sufficient\nfor IA to be stable; 2) derive a necessary condition on $m$ to maintain\nstability for IA as time goes to infinity. Our numerical results show that our\napproach achieves stability for an $m$ that satisfies the theoretical\nconditions. We also empirically demonstrate that our proposed two phase\nalgorithm has equivalent performance to the one-at-a-time rollout over the\nentire map, but with significantly lower runtimes.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.01534v3"
    },
    {
        "title": "RiskQ: Risk-sensitive Multi-Agent Reinforcement Learning Value\n  Factorization",
        "authors": [
            "Siqi Shen",
            "Chennan Ma",
            "Chao Li",
            "Weiquan Liu",
            "Yongquan Fu",
            "Songzhu Mei",
            "Xinwang Liu",
            "Cheng Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent systems are characterized by environmental uncertainty, varying\npolicies of agents, and partial observability, which result in significant\nrisks. In the context of Multi-Agent Reinforcement Learning (MARL), learning\ncoordinated and decentralized policies that are sensitive to risk is\nchallenging. To formulate the coordination requirements in risk-sensitive MARL,\nwe introduce the Risk-sensitive Individual-Global-Max (RIGM) principle as a\ngeneralization of the Individual-Global-Max (IGM) and Distributional IGM (DIGM)\nprinciples. This principle requires that the collection of risk-sensitive\naction selections of each agent should be equivalent to the risk-sensitive\naction selection of the central policy. Current MARL value factorization\nmethods do not satisfy the RIGM principle for common risk metrics such as the\nValue at Risk (VaR) metric or distorted risk measurements. Therefore, we\npropose RiskQ to address this limitation, which models the joint return\ndistribution by modeling quantiles of it as weighted quantile mixtures of\nper-agent return distribution utilities. RiskQ satisfies the RIGM principle for\nthe VaR and distorted risk metrics. We show that RiskQ can obtain promising\nperformance through extensive experiments. The source code of RiskQ is\navailable in https://github.com/xmu-rl-3dv/RiskQ.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.01753v2"
    },
    {
        "title": "Agent-based Modelling of Credit Card Promotions",
        "authors": [
            "Conor B. Hamill",
            "Raad Khraishi",
            "Simona Gherghel",
            "Jerrard Lawrence",
            "Salvatore Mercuri",
            "Ramin Okhrati",
            "Greig A. Cowan"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Interest-free promotions are a prevalent strategy employed by credit card\nlenders to attract new customers, yet the research exploring their effects on\nboth consumers and lenders remains relatively sparse. The process of selecting\nan optimal promotion strategy is intricate, involving the determination of an\ninterest-free period duration and promotion-availability window, all within the\ncontext of competing offers, fluctuating market dynamics, and complex consumer\nbehaviour. In this paper, we introduce an agent-based model that facilitates\nthe exploration of various credit card promotions under diverse market\nscenarios. Our approach, distinct from previous agent-based models,\nconcentrates on optimising promotion strategies and is calibrated using\nbenchmarks from the UK credit card market from 2019 to 2020, with agent\nproperties derived from historical distributions of the UK population from\nroughly the same period. We validate our model against stylised facts and\ntime-series data, thereby demonstrating the value of this technique for\ninvestigating pricing strategies and understanding credit card customer\nbehaviour. Our experiments reveal that, in the absence of competitor\npromotions, lender profit is maximised by an interest-free duration of\napproximately 12 months while market share is maximised by offering the longest\nduration possible. When competitors do not offer promotions, extended promotion\navailability windows yield maximum profit for lenders while also maximising\nmarket share. In the context of concurrent interest-free promotions, we\nidentify that the optimal lender strategy entails offering a more competitive\ninterest-free period and a rapid response to competing promotional offers.\nNotably, a delay of three months in responding to a rival promotion corresponds\nto a 2.4% relative decline in income.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.01901v2"
    },
    {
        "title": "Evolution of Collective Decision-Making Mechanisms for Collective\n  Perception",
        "authors": [
            "Tanja Katharina Kaiser",
            "Tristan Potten",
            "Heiko Hamann"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Autonomous robot swarms must be able to make fast and accurate collective\ndecisions, but speed and accuracy are known to be conflicting goals. While\ncollective decision-making is widely studied in swarm robotics research, only\nfew works on using methods of evolutionary computation to generate collective\ndecision-making mechanisms exist. These works use task-specific fitness\nfunctions rewarding the accomplishment of the respective collective\ndecision-making task. But task-independent rewards, such as for prediction\nerror minimization, may promote the emergence of diverse and innovative\nsolutions. We evolve collective decision-making mechanisms using a\ntask-specific fitness function rewarding correct robot opinions, a\ntask-independent reward for prediction accuracy, and a hybrid fitness function\ncombining the two previous. In our simulations, we use the collective\nperception scenario, that is, robots must collectively determine which of two\nenvironmental features is more frequent. We show that evolution successfully\noptimizes fitness in all three scenarios, but that only the task-specific\nfitness function and the hybrid fitness function lead to the emergence of\ncollective decision-making behaviors. In benchmark experiments, we show the\ncompetitiveness of the evolved decision-making mechanisms to the voter model\nand the majority rule and analyze the scalability of the decision-making\nmechanisms with problem difficulty.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.02994v1"
    },
    {
        "title": "Fleet Sizing for the Flash Delivery Problem from Multiple Depots a Case\n  Study in Amsterdam",
        "authors": [
            "Maximilian Kronmueller",
            "Andres Fielbaum",
            "Javier Alonso-Mora"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper, we present a novel approach for fleet sizing in the context of\nflash delivery, a time-sensitive delivery service that requires the fulfilment\nof customer requests in minutes. Our approach effectively combines individual\ndelivery requests into groups and generates optimized operational plans that\ncan be executed by a single vehicle or autonomous robot. The groups are formed\nusing a modified routing approach for the flash delivery problem. Combining the\ngroups into operational plans is done by solving an integer linear problem. To\nevaluate the effectiveness of our approach, we compare it against three\nalternative methods: fixed vehicle routing, non-pooled deliveries and a\nstrategy encouraging the pooling of requests. The results demonstrate the value\nof our proposed approach, showcasing its ability to optimize the fleet and\nimprove operational efficiency. Our experimental analysis is based on a\nreal-world dataset provided by a Dutch retailer, allowing us to gain valuable\ninsights into the design of flash delivery operations and to analyze the effect\nof the maximum allowed delay, the number of stores to pick up goods from and\nthe employed cost functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.03869v1"
    },
    {
        "title": "Enhancing Multi-Agent Coordination through Common Operating Picture\n  Integration",
        "authors": [
            "Peihong Yu",
            "Bhoram Lee",
            "Aswin Raghavan",
            "Supun Samarasekara",
            "Pratap Tokekar",
            "James Zachary Hare"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In multi-agent systems, agents possess only local observations of the\nenvironment. Communication between teammates becomes crucial for enhancing\ncoordination. Past research has primarily focused on encoding local information\ninto embedding messages which are unintelligible to humans. We find that using\nthese messages in agent's policy learning leads to brittle policies when tested\non out-of-distribution initial states. We present an approach to multi-agent\ncoordination, where each agent is equipped with the capability to integrate its\n(history of) observations, actions and messages received into a Common\nOperating Picture (COP) and disseminate the COP. This process takes into\naccount the dynamic nature of the environment and the shared mission. We\nconducted experiments in the StarCraft2 environment to validate our approach.\nOur results demonstrate the efficacy of COP integration, and show that\nCOP-based training leads to robust policies compared to state-of-the-art\nMulti-Agent Reinforcement Learning (MARL) methods when faced with\nout-of-distribution initial states.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.04740v1"
    },
    {
        "title": "Privacy-Engineered Value Decomposition Networks for Cooperative\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Parham Gohari",
            "Matthew Hale",
            "Ufuk Topcu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In cooperative multi-agent reinforcement learning (Co-MARL), a team of agents\nmust jointly optimize the team's long-term rewards to learn a designated task.\nOptimizing rewards as a team often requires inter-agent communication and data\nsharing, leading to potential privacy implications. We assume privacy\nconsiderations prohibit the agents from sharing their environment interaction\ndata. Accordingly, we propose Privacy-Engineered Value Decomposition Networks\n(PE-VDN), a Co-MARL algorithm that models multi-agent coordination while\nprovably safeguarding the confidentiality of the agents' environment\ninteraction data. We integrate three privacy-engineering techniques to redesign\nthe data flows of the VDN algorithm, an existing Co-MARL algorithm that\nconsolidates the agents' environment interaction data to train a central\ncontroller that models multi-agent coordination, and develop PE-VDN. In the\nfirst technique, we design a distributed computation scheme that eliminates\nVanilla VDN's dependency on sharing environment interaction data. Then, we\nutilize a privacy-preserving multi-party computation protocol to guarantee that\nthe data flows of the distributed computation scheme do not pose new privacy\nrisks. Finally, we enforce differential privacy to preempt inference threats\nagainst the agents' training data, past environment interactions, when they\ntake actions based on their neural network predictions. We implement PE-VDN in\nStarCraft Multi-Agent Competition (SMAC) and show that it achieves 80% of\nVanilla VDN's win rate while maintaining differential privacy levels that\nprovide meaningful privacy guarantees. The results demonstrate that PE-VDN can\nsafeguard the confidentiality of agents' environment interaction data without\nsacrificing multi-agent coordination.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06255v1"
    },
    {
        "title": "A Cognitive Agent Computing-Based Model For The Primary School Student\n  Migration Problem Using A Descriptive Agent-Based Approach",
        "authors": [
            "Muhammad Tausif"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Students' migration from public to private schools, due to lack of school\nperformance of public schools, is one of the major issues faced by the\nGovernment of Punjab to provide compulsory and quality education at low cost.\nDue to complex adaptive nature of educational system, interdependencies with\nsociety, constant feedback loops conventional linear regression methods, for\nevaluation of effective performance, are ineffective or costly to solve the\nissue. Linear regression techniques present the static view of the system,\nwhich are not enough to understand the complex dynamic nature of educational\nparadigm. We have presented a Cognitive Agent Computing-Based Model for the\nSchool Student Migration Problem Using a Descriptive Agent-Based Modeling\napproach to understand the causes-effects relationship of student migration. We\nhave presented the primary school students' migration model using descriptive\nmodeling approach along with exploratory modeling. Our research, in the context\nof Software Engineering of Simulation & Modeling, and exploring the Complex\nAdaptive nature of school system, is two folds. Firstly, the cause-effect\nrelationship of students' migration is being investigated using Cognitive\nDescriptive Agent-Based Modeling. Secondly, the formalization extent of\nCognitive Agent-Based Computing framework is analyzed by performing its\ncomparative analysis with exploratory modeling protocol 'Overview, Design, and\nDetail'.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.06272v1"
    },
    {
        "title": "Learning to Cooperate and Communicate Over Imperfect Channels",
        "authors": [
            "Jannis Weil",
            "Gizem Ekinci",
            "Heinz Koeppl",
            "Tobias Meuser"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Information exchange in multi-agent systems improves the cooperation among\nagents, especially in partially observable settings. In the real world,\ncommunication is often carried out over imperfect channels. This requires\nagents to handle uncertainty due to potential information loss. In this paper,\nwe consider a cooperative multi-agent system where the agents act and exchange\ninformation in a decentralized manner using a limited and unreliable channel.\nTo cope with such channel constraints, we propose a novel communication\napproach based on independent Q-learning. Our method allows agents to\ndynamically adapt how much information to share by sending messages of\ndifferent sizes, depending on their local observations and the channel's\nproperties. In addition to this message size selection, agents learn to encode\nand decode messages to improve their jointly trained policies. We show that our\napproach outperforms approaches without adaptive capabilities in a novel\ncooperative digit-prediction environment and discuss its limitations in the\ntraffic junction environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.14770v1"
    },
    {
        "title": "Analyzing the Impact of Tax Credits on Households in Simulated Economic\n  Systems with Learning Agents",
        "authors": [
            "Jialin Dong",
            "Kshama Dwarakanath",
            "Svitlana Vyetrenko"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In economic modeling, there has been an increasing investigation into\nmulti-agent simulators. Nevertheless, state-of-the-art studies establish the\nmodel based on reinforcement learning (RL) exclusively for specific agent\ncategories, e.g., households, firms, or the government. It lacks concerns over\nthe resulting adaptation of other pivotal agents, thereby disregarding the\ncomplex interactions within a real-world economic system. Furthermore, we pay\nattention to the vital role of the government policy in distributing tax\ncredits. Instead of uniform distribution considered in state-of-the-art, it\nrequires a well-designed strategy to reduce disparities among households and\nimprove social welfare. To address these limitations, we propose an expansive\nmulti-agent economic model comprising reinforcement learning agents of numerous\ntypes. Additionally, our research comprehensively explores the impact of tax\ncredit allocation on household behavior and captures the spectrum of spending\npatterns that can be observed across diverse households. Further, we propose an\ninnovative government policy to distribute tax credits, strategically\nleveraging insights from tax credit spending patterns. Simulation results\nillustrate the efficacy of the proposed government strategy in ameliorating\ninequalities across households.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17252v1"
    },
    {
        "title": "Consensus group decision making under model uncertainty with a view\n  towards environmental policy making",
        "authors": [
            "Phoebe Koundouri",
            "Georgios I. Papayiannis",
            "Electra V. Petracou",
            "Athanasios N. Yannacopoulos"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In this paper we propose a consensus group decision making scheme under model\nuncertainty consisting of an iterative two-stage procedure and based on the\nconcept of Fr\\'echet barycenter. Each step consists of two stages: the agents\nfirst update their position in the opinion metric space by a local barycenter\ncharacterized by the agents' immediate interactions and then a moderator makes\na proposal in terms of a global barycenter, checking for consensus at each\nstep. In cases of large heterogeneous groups the procedure can be complemented\nby an auxiliary initial homogenization step, consisting of a clustering\nprocedure in opinion space, leading to large homogeneous groups for which the\naforementioned procedure will be applied.\n  The scheme is illustrated in examples motivated from environmental economics.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.00436v1"
    },
    {
        "title": "Evaluating eVTOL Network Performance and Fleet Dynamics through\n  Simulation-Based Analysis",
        "authors": [
            "Emin Burak Onat",
            "Vishwanath Bulusu",
            "Anjan Chakrabarty",
            "Mark Hansen",
            "Raja Sengupta",
            "Banavar Sridar"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Urban Air Mobility (UAM) represents a promising solution for future\ntransportation. In this study, we introduce VertiSim, an advanced event-driven\nsimulator developed to evaluate e-VTOL transportation networks. Uniquely,\nVertiSim simultaneously models passenger, aircraft, and energy flows,\nreflecting the interrelated complexities of UAM systems. We utilized VertiSim\nto assess 19 operational scenarios serving a daily demand for 2,834 passengers\nwith varying fleet sizes and vertiport distances. The study aims to support\nstakeholders in making informed decisions about fleet size, network design, and\ninfrastructure development by understanding tradeoffs in passenger delay time,\noperational costs, and fleet utilization. Our simulations, guided by a\nheuristic dispatch and charge policy, indicate that fleet size significantly\ninfluences passenger delay and energy consumption within UAM networks. We find\nthat increasing the fleet size can reduce average passenger delays, but this\ncomes at the cost of higher operational expenses due to an increase in the\nnumber of repositioning flights. Additionally, our analysis highlights how\nvertiport distances impact fleet utilization: longer distances result in\nreduced total idle time and increased cruise and charge times, leading to more\nefficient fleet utilization but also longer passenger delays. These findings\nare important for UAM network planning, especially in balancing fleet size with\nvertiport capacity and operational costs. Simulator demo is available at:\nhttps://tinyurl.com/vertisim-vis\n",
        "pdf_link": "http://arxiv.org/pdf/2312.02505v1"
    },
    {
        "title": "Development and Assessment of Autonomous Vehicles in Both Fully\n  Automated and Mixed Traffic Conditions",
        "authors": [
            "Ahmed Abdelrahman"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Autonomous Vehicle (AV) technology is advancing rapidly, promising a\nsignificant shift in road transportation safety and potentially resolving\nvarious complex transportation issues. With the increasing deployment of AVs by\nvarious companies, questions emerge about how AVs interact with each other and\nwith human drivers, especially when AVs are prevalent on the roads. Ensuring\ncooperative interaction between AVs and between AVs and human drivers is\ncritical, though there are concerns about possible negative competitive\nbehaviors. This paper presents a multi-stage approach, starting with the\ndevelopment of a single AV and progressing to connected AVs, incorporating\nsharing and caring V2V communication strategy to enhance mutual coordination. A\nsurvey is conducted to validate the driving performance of the AV and will be\nutilized for a mixed traffic case study, which focuses on how the human drivers\nwill react to the AV driving alongside them on the same road. Results show that\nusing deep reinforcement learning, the AV acquired driving behavior that\nreached human driving performance. The adoption of sharing and caring based V2V\ncommunication within AV networks enhances their driving behavior, aids in more\neffective action planning, and promotes collaborative behavior amongst the AVs.\nThe survey shows that safety in mixed traffic cannot be guaranteed, as we\ncannot control human ego-driven actions if they decide to compete with AV.\nConsequently, this paper advocates for enhanced research into the safe\nincorporation of AVs on public roads.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.04805v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Multi-Cell Spectrum and Power\n  Allocation",
        "authors": [
            "Yiming Zhang",
            "Dongning Guo"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This paper introduces a novel approach to radio resource allocation in\nmulti-cell wireless networks using a fully scalable multi-agent reinforcement\nlearning (MARL) framework. A distributed method is developed where agents\ncontrol individual cells and determine spectrum and power allocation based on\nlimited local information, yet achieve quality of service (QoS) performance\ncomparable to centralized methods using global information. The objective is to\nminimize packet delays across devices under stochastic arrivals and applies to\nboth conflict graph abstractions and cellular network configurations. This is\nformulated as a distributed learning problem, implementing a multi-agent\nproximal policy optimization (MAPPO) algorithm with recurrent neural networks\nand queueing dynamics. This traffic-driven MARL-based solution enables\ndecentralized training and execution, ensuring scalability to large networks.\nExtensive simulations demonstrate that the proposed methods achieve comparable\nQoS performance to genie-aided centralized algorithms with significantly less\nexecution time. The trained policies also exhibit scalability and robustness\nacross various network sizes and traffic conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.05746v2"
    },
    {
        "title": "Multi-agent Reinforcement Learning: A Comprehensive Survey",
        "authors": [
            "Dom Huh",
            "Prasant Mohapatra"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Multi-agent systems (MAS) are widely prevalent and crucially important in\nnumerous real-world applications, where multiple agents must make decisions to\nachieve their objectives in a shared environment. Despite their ubiquity, the\ndevelopment of intelligent decision-making agents in MAS poses several open\nchallenges to their effective implementation. This survey examines these\nchallenges, placing an emphasis on studying seminal concepts from game theory\n(GT) and machine learning (ML) and connecting them to recent advancements in\nmulti-agent reinforcement learning (MARL), i.e. the research of data-driven\ndecision-making within MAS. Therefore, the objective of this survey is to\nprovide a comprehensive perspective along the various dimensions of MARL,\nshedding light on the unique opportunities that are presented in MARL\napplications while highlighting the inherent challenges that accompany this\npotential. Therefore, we hope that our work will not only contribute to the\nfield by analyzing the current landscape of MARL but also motivate future\ndirections with insights for deeper integration of concepts from related\ndomains of GT and ML. With this in mind, this work delves into a detailed\nexploration of recent and past efforts of MARL and its related fields and\ndescribes prior solutions that were proposed and their limitations, as well as\ntheir applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.10256v2"
    },
    {
        "title": "Interventionally Consistent Surrogates for Agent-based Simulators",
        "authors": [
            "Joel Dyer",
            "Nicholas Bishop",
            "Yorgos Felekis",
            "Fabio Massimo Zennaro",
            "Anisoara Calinescu",
            "Theodoros Damoulas",
            "Michael Wooldridge"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Agent-based simulators provide granular representations of complex\nintelligent systems by directly modelling the interactions of the system's\nconstituent agents. Their high-fidelity nature enables hyper-local policy\nevaluation and testing of what-if scenarios, but is associated with large\ncomputational costs that inhibits their widespread use. Surrogate models can\naddress these computational limitations, but they must behave consistently with\nthe agent-based model under policy interventions of interest. In this paper, we\ncapitalise on recent developments on causal abstractions to develop a framework\nfor learning interventionally consistent surrogate models for agent-based\nsimulators. Our proposed approach facilitates rapid experimentation with policy\ninterventions in complex systems, while inducing surrogates to behave\nconsistently with high probability with respect to the agent-based simulator\nacross interventions of interest. We demonstrate with empirical studies that\nobservationally trained surrogates can misjudge the effect of interventions and\nmisguide policymakers towards suboptimal policies, while surrogates trained for\ninterventional consistency with our proposed method closely mimic the behaviour\nof an agent-based model under interventions of interest.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.11158v1"
    },
    {
        "title": "Agent Assessment of Others Through the Lens of Self",
        "authors": [
            "Jasmine A. Berry"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The maturation of cognition, from introspection to understanding others, has\nlong been a hallmark of human development. This position paper posits that for\nAI systems to truly emulate or approach human-like interactions, especially\nwithin multifaceted environments populated with diverse agents, they must first\nachieve an in-depth and nuanced understanding of self. Drawing parallels with\nthe human developmental trajectory from self-awareness to mentalizing (also\ncalled theory of mind), the paper argues that the quality of an autonomous\nagent's introspective capabilities of self are crucial in mirroring quality\nhuman-like understandings of other agents. While counterarguments emphasize\npracticality, computational efficiency, and ethical concerns, this position\nproposes a development approach, blending algorithmic considerations of\nself-referential processing. Ultimately, the vision set forth is not merely of\nmachines that compute but of entities that introspect, empathize, and\nunderstand, harmonizing with the complex compositions of human cognition.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.11357v1"
    },
    {
        "title": "Robust Communicative Multi-Agent Reinforcement Learning with Active\n  Defense",
        "authors": [
            "Lebin Yu",
            "Yunbo Qiu",
            "Quanming Yao",
            "Yuan Shen",
            "Xudong Zhang",
            "Jian Wang"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Communication in multi-agent reinforcement learning (MARL) has been proven to\neffectively promote cooperation among agents recently. Since communication in\nreal-world scenarios is vulnerable to noises and adversarial attacks, it is\ncrucial to develop robust communicative MARL technique. However, existing\nresearch in this domain has predominantly focused on passive defense\nstrategies, where agents receive all messages equally, making it hard to\nbalance performance and robustness. We propose an active defense strategy,\nwhere agents automatically reduce the impact of potentially harmful messages on\nthe final decision. There are two challenges to implement this strategy, that\nare defining unreliable messages and adjusting the unreliable messages' impact\non the final decision properly. To address them, we design an Active Defense\nMulti-Agent Communication framework (ADMAC), which estimates the reliability of\nreceived messages and adjusts their impact on the final decision accordingly\nwith the help of a decomposable decision structure. The superiority of ADMAC\nover existing methods is validated by experiments in three\ncommunication-critical tasks under four types of attacks.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.11545v1"
    },
    {
        "title": "Multi-agent reinforcement learning using echo-state network and its\n  application to pedestrian dynamics",
        "authors": [
            "Hisato Komatsu"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  In recent years, simulations of pedestrians using the multi-agent\nreinforcement learning (MARL) have been studied. This study considered the\nroads on a grid-world environment, and implemented pedestrians as MARL agents\nusing an echo-state network and the least squares policy iteration method.\nUnder this environment, the ability of these agents to learn to move forward by\navoiding other agents was investigated. Specifically, we considered two types\nof tasks: the choice between a narrow direct route and a broad detour, and the\nbidirectional pedestrian flow in a corridor. The simulations results indicated\nthat the learning was successful when the density of the agents was not that\nhigh.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.11834v4"
    },
    {
        "title": "Behaviour Modelling of Social Animals via Causal Structure Discovery and\n  Graph Neural Networks",
        "authors": [
            "Gaël Gendron",
            "Yang Chen",
            "Mitchell Rogers",
            "Yiping Liu",
            "Mihailo Azhar",
            "Shahrokh Heidari",
            "David Arturo Soriano Valdez",
            "Kobe Knowles",
            "Padriac O'Leary",
            "Simon Eyre",
            "Michael Witbrock",
            "Gillian Dobbie",
            "Jiamou Liu",
            "Patrice Delmas"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Better understanding the natural world is a crucial task with a wide range of\napplications. In environments with close proximity between humans and animals,\nsuch as zoos, it is essential to better understand the causes behind animal\nbehaviour and what interventions are responsible for changes in their\nbehaviours. This can help to predict unusual behaviours, mitigate detrimental\neffects and increase the well-being of animals. There has been work on\nmodelling the dynamics behind swarms of birds and insects but the complex\nsocial behaviours of mammalian groups remain less explored. In this work, we\npropose a method to build behavioural models using causal structure discovery\nand graph neural networks for time series. We apply this method to a mob of\nmeerkats in a zoo environment and study its ability to predict future actions\nand model the behaviour distribution at an individual-level and at a group\nlevel. We show that our method can match and outperform standard deep learning\narchitectures and generate more realistic data, while using fewer parameters\nand providing increased interpretability.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14333v1"
    },
    {
        "title": "DuaLight: Enhancing Traffic Signal Control by Leveraging\n  Scenario-Specific and Scenario-Shared Knowledge",
        "authors": [
            "Jiaming Lu",
            "Jingqing Ruan",
            "Haoyuan Jiang",
            "Ziyue Li",
            "Hangyu Mao",
            "Rui Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Reinforcement learning has been revolutionizing the traditional traffic\nsignal control task, showing promising power to relieve congestion and improve\nefficiency. However, the existing methods lack effective learning mechanisms\ncapable of absorbing dynamic information inherent to a specific scenario and\nuniversally applicable dynamic information across various scenarios. Moreover,\nwithin each specific scenario, they fail to fully capture the essential\nempirical experiences about how to coordinate between neighboring and target\nintersections, leading to sub-optimal system-wide outcomes.\n  Viewing these issues, we propose DuaLight, which aims to leverage both the\nexperiential information within a single scenario and the generalizable\ninformation across various scenarios for enhanced decision-making.\nSpecifically, DuaLight introduces a scenario-specific experiential weight\nmodule with two learnable parts: Intersection-wise and Feature-wise, guiding\nhow to adaptively utilize neighbors and input features for each scenario, thus\nproviding a more fine-grained understanding of different intersections.\nFurthermore, we implement a scenario-shared Co-Train module to facilitate the\nlearning of generalizable dynamics information across different scenarios.\nEmpirical results on both real-world and synthetic scenarios show DuaLight\nachieves competitive performance across various metrics, offering a promising\nsolution to alleviate traffic congestion, with 3-7\\% improvements. The code is\navailable under: https://github.com/lujiaming-12138/DuaLight.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14532v1"
    },
    {
        "title": "AFSPP: Agent Framework for Shaping Preference and Personality with Large\n  Language Models",
        "authors": [
            "Zihong He",
            "Changwang Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The evolution of Large Language Models (LLMs) has introduced a new paradigm\nfor investigating human behavior emulation. Recent research has employed\nLLM-based Agents to create a sociological research environment, in which agents\nexhibit behavior based on the unfiltered characteristics of large language\nmodels. However, these studies overlook the iterative development within a\nhuman-like setting - Human preferences and personalities are complex, shaped by\nvarious factors and subject to ongoing change as a result of environmental and\nsubjective influences. In light of this observation, we propose Agent Framework\nfor Shaping Preference and Personality (AFSPP), exploring the multifaceted\nimpact of social networks and subjective consciousness on LLM-based Agents'\npreference and personality formation. With AFSPP, we have, for the first time,\nsuccessfully replicated several key findings from human personality\nexperiments. And other AFSPP-based experimental results indicate that plan\nmaking, sensory perceptions and social networking with subjective information,\nwield the most pronounced influence on preference shaping. AFSPP can\nsignificantly enhance the efficiency and scope of psychological experiments,\nwhile yielding valuable insights for Trustworthy Artificial Intelligence\nresearch for strategies to prevent undesirable preference and personality\ndevelopment.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.02870v1"
    },
    {
        "title": "Why Solving Multi-agent Path Finding with Large Language Model has not\n  Succeeded Yet",
        "authors": [
            "Weizhe Chen",
            "Sven Koenig",
            "Bistra Dilkina"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the explosive influence caused by the success of large language models\n(LLM) like ChatGPT and GPT-4, there has been an extensive amount of recent work\nshowing that foundation models can be used to solve a large variety of tasks.\nHowever, there is very limited work that shares insights on multi-agent\nplanning. Multi-agent planning is different from other domains by combining the\ndifficulty of multi-agent coordination and planning, and making it hard to\nleverage external tools to facilitate the reasoning needed. In this paper, we\nfocus on the problem of multi-agent path finding (MAPF), which is also known as\nmulti-robot route planning, and study the performance of solving MAPF with\nLLMs. We first show the motivating success on an empty room map without\nobstacles, then the failure to plan on the harder room map and maze map of the\nstandard MAPF benchmark. We present our position on why directly solving MAPF\nwith LLMs has not been successful yet, and we use various experiments to\nsupport our hypothesis. Based on our results, we discussed how researchers with\ndifferent backgrounds could help with this problem from different perspectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03630v2"
    },
    {
        "title": "First 100 days of pandemic; an interplay of pharmaceutical, behavioral\n  and digital interventions -- A study using agent based modeling",
        "authors": [
            "Gauri Gupta",
            "Ritvik Kapila",
            "Ayush Chopra",
            "Ramesh Raskar"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Pandemics, notably the recent COVID-19 outbreak, have impacted both public\nhealth and the global economy. A profound understanding of disease progression\nand efficient response strategies is thus needed to prepare for potential\nfuture outbreaks. In this paper, we emphasize the potential of Agent-Based\nModels (ABM) in capturing complex infection dynamics and understanding the\nimpact of interventions. We simulate realistic pharmaceutical, behavioral, and\ndigital interventions that mirror challenges in real-world policy adoption and\nsuggest a holistic combination of these interventions for pandemic response.\nUsing these simulations, we study the trends of emergent behavior on a\nlarge-scale population based on real-world socio-demographic and geo-census\ndata from Kings County in Washington. Our analysis reveals the pivotal role of\nthe initial 100 days in dictating a pandemic's course, emphasizing the\nimportance of quick decision-making and efficient policy development. Further,\nwe highlight that investing in behavioral and digital interventions can reduce\nthe burden on pharmaceutical interventions by reducing the total number of\ninfections and hospitalizations, and by delaying the pandemic's peak. We also\ninfer that allocating the same amount of dollars towards extensive testing with\ncontact tracing and self-quarantine offers greater cost efficiency compared to\nspending the entire budget on vaccinations.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.04795v2"
    },
    {
        "title": "Graph Learning-based Fleet Scheduling for Urban Air Mobility under\n  Operational Constraints, Varying Demand & Uncertainties",
        "authors": [
            "Steve Paul",
            "Jhoel Witter",
            "Souma Chowdhury"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper develops a graph reinforcement learning approach to online\nplanning of the schedule and destinations of electric aircraft that comprise an\nurban air mobility (UAM) fleet operating across multiple vertiports. This fleet\nscheduling problem is formulated to consider time-varying demand, constraints\nrelated to vertiport capacity, aircraft capacity and airspace safety\nguidelines, uncertainties related to take-off delay, weather-induced route\nclosures, and unanticipated aircraft downtime. Collectively, such a formulation\npresents greater complexity, and potentially increased realism, than in\nexisting UAM fleet planning implementations. To address these complexities, a\nnew policy architecture is constructed, primary components of which include:\ngraph capsule conv-nets for encoding vertiport and aircraft-fleet states both\nabstracted as graphs; transformer layers encoding time series information on\ndemand and passenger fare; and a Multi-head Attention-based decoder that uses\nthe encoded information to compute the probability of selecting each available\ndestination for an aircraft. Trained with Proximal Policy Optimization, this\npolicy architecture shows significantly better performance in terms of daily\naveraged profits on unseen test scenarios involving 8 vertiports and 40\naircraft, when compared to a random baseline and genetic algorithm-derived\noptimal solutions, while being nearly 1000 times faster in execution than the\nlatter.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.04851v1"
    },
    {
        "title": "Fully Decentralized Cooperative Multi-Agent Reinforcement Learning: A\n  Survey",
        "authors": [
            "Jiechuan Jiang",
            "Kefan Su",
            "Zongqing Lu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Cooperative multi-agent reinforcement learning is a powerful tool to solve\nmany real-world cooperative tasks, but restrictions of real-world applications\nmay require training the agents in a fully decentralized manner. Due to the\nlack of information about other agents, it is challenging to derive algorithms\nthat can converge to the optimal joint policy in a fully decentralized setting.\nThus, this research area has not been thoroughly studied. In this paper, we\nseek to systematically review the fully decentralized methods in two settings:\nmaximizing a shared reward of all agents and maximizing the sum of individual\nrewards of all agents, and discuss open questions and future research\ndirections.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.04934v1"
    },
    {
        "title": "A Hierarchical Framework with Spatio-Temporal Consistency Learning for\n  Emergence Detection in Complex Adaptive Systems",
        "authors": [
            "Siyuan Chen",
            "Xin Du",
            "Jiahai Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Emergence, a global property of complex adaptive systems (CASs) constituted\nby interactive agents, is prevalent in real-world dynamic systems, e.g.,\nnetwork-level traffic congestions. Detecting its formation and evaporation\nhelps to monitor the state of a system, allowing to issue a warning signal for\nharmful emergent phenomena. Since there is no centralized controller of CAS,\ndetecting emergence based on each agent's local observation is desirable but\nchallenging. Existing works are unable to capture emergence-related spatial\npatterns, and fail to model the nonlinear relationships among agents. This\npaper proposes a hierarchical framework with spatio-temporal consistency\nlearning to solve these two problems by learning the system representation and\nagent representations, respectively. Spatio-temporal encoders composed of\nspatial and temporal transformers are designed to capture agents' nonlinear\nrelationships and the system's complex evolution. Agents' and the system's\nrepresentations are learned to preserve the spatio-temporal consistency by\nminimizing the spatial and temporal dissimilarities in a self-supervised manner\nin the latent space. Our method achieves more accurate detection than\ntraditional methods and deep learning methods on three datasets with well-known\nyet hard-to-detect emergent behaviors. Notably, our hierarchical framework is\ngeneric in incorporating other deep learning methods for agent-level and\nsystem-level detection.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.10300v2"
    },
    {
        "title": "The Synergy Between Optimal Transport Theory and Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Ali Baheri",
            "Mykel J. Kochenderfer"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper explores the integration of optimal transport (OT) theory with\nmulti-agent reinforcement learning (MARL). This integration uses OT to handle\ndistributions and transportation problems to enhance the efficiency,\ncoordination, and adaptability of MARL. There are five key areas where OT can\nimpact MARL: (1) policy alignment, where OT's Wasserstein metric is used to\nalign divergent agent strategies towards unified goals; (2) distributed\nresource management, employing OT to optimize resource allocation among agents;\n(3) addressing non-stationarity, using OT to adapt to dynamic environmental\nshifts; (4) scalable multi-agent learning, harnessing OT for decomposing\nlarge-scale learning objectives into manageable tasks; and (5) enhancing energy\nefficiency, applying OT principles to develop sustainable MARL systems. This\npaper articulates how the synergy between OT and MARL can address scalability\nissues, optimize resource distribution, align agent policies in cooperative\nenvironments, and ensure adaptability in dynamically changing conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.10949v2"
    },
    {
        "title": "Energy Flexibility Potential in the Brewery Sector: A Multi-agent Based\n  Simulation of 239 Danish Breweries",
        "authors": [
            "Daniel Anthony Howard",
            "Zheng Grace Ma",
            "Jacob Alstrup Engvang",
            "Morten Hagenau",
            "Kathrine Lau Jorgensen",
            "Jonas Fausing Olesen",
            "Bo Nørregaard Jørgensen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The beverage industry is a typical food processing industry, accounts for\nsignificant energy consumption, and has flexible demands. However, the\ndeployment of energy flexibility in the beverage industry is complex and\nchallenging. Furthermore, activation of energy flexibility from the whole\nbrewery industry is necessary to ensure grid stability. Therefore, this paper\nassesses the energy flexibility potential of Denmark's brewery sector based on\na multi-agent-based simulation. 239 individual brewery facilities are\nsimulated, and each facility, as an agent, can interact with the energy system\nmarket and make decisions based on its underlying parameters and operational\nrestrictions. The results show that the Danish breweries could save 1.56 % of\nelectricity costs annually while maintaining operational security and reducing\napproximately 1745 tonnes of CO2 emissions. Furthermore, medium-size breweries\ncould obtain higher relative benefits by providing energy flexibility,\nespecially those producing lager and ale. The result also shows that the\nbreweries' relative saving potential is electricity market-dependent.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14903v1"
    },
    {
        "title": "Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents",
        "authors": [
            "Sz-Ting Tzeng",
            "Nirav Ajmeri",
            "Munindar P. Singh"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  A multiagent system is a society of autonomous agents whose interactions can\nbe regulated via social norms. In general, the norms of a society are not\nhardcoded but emerge from the agents' interactions. Specifically, how the\nagents in a society react to each other's behavior and respond to the reactions\nof others determines which norms emerge in the society. We think of these\nreactions by an agent to the satisfactory or unsatisfactory behaviors of\nanother agent as communications from the first agent to the second agent.\nUnderstanding these communications is a kind of social intelligence: these\ncommunications provide natural drivers for norm emergence by pushing agents\ntoward certain behaviors, which can become established as norms. Whereas it is\nwell-known that sanctioning can lead to the emergence of norms, we posit that a\nbroader kind of social intelligence can prove more effective in promoting\ncooperation in a multiagent system.\n  Accordingly, we develop Nest, a framework that models social intelligence via\na wider variety of communications and understanding of them than in previous\nwork. To evaluate Nest, we develop a simulated pandemic environment and conduct\nsimulation experiments to compare Nest with baselines considering a combination\nof three kinds of social communication: sanction, tell, and hint.\n  We find that societies formed of Nest agents achieve norms faster. Moreover,\nNest agents effectively avoid undesirable consequences, which are negative\nsanctions and deviation from goals, and yield higher satisfaction for\nthemselves than baseline agents despite requiring only an equivalent amount of\ninformation.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16461v3"
    },
    {
        "title": "Graph Attention-based Reinforcement Learning for Trajectory Design and\n  Resource Assignment in Multi-UAV Assisted Communication",
        "authors": [
            "Zikai Feng",
            "Di Wu",
            "Mengxing Huang",
            "Chau Yuen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In the multiple unmanned aerial vehicle (UAV)- assisted downlink\ncommunication, it is challenging for UAV base stations (UAV BSs) to realize\ntrajectory design and resource assignment in unknown environments. The\ncooperation and competition between UAV BSs in the communication network leads\nto a Markov game problem. Multi-agent reinforcement learning is a significant\nsolution for the above decision-making. However, there are still many common\nissues, such as the instability of the system and low utilization of historical\ndata, that limit its application. In this paper, a novel graph-attention\nmulti-agent trust region (GA-MATR) reinforcement learning framework is proposed\nto solve the multi-UAV assisted communication problem. Graph recurrent network\nis introduced to process and analyze complex topology of the communication\nnetwork, so as to extract useful information and patterns from observational\ninformation. The attention mechanism provides additional weighting for conveyed\ninformation, so that the critic network can accurately evaluate the value of\nbehavior for UAV BSs. This provides more reliable feedback signals and helps\nthe actor network update the strategy more effectively. Ablation simulations\nindicate that the proposed approach attains improved convergence over the\nbaselines. UAV BSs learn the optimal communication strategies to achieve their\nmaximum cumulative rewards. Additionally, multi-agent trust region method with\nmonotonic convergence provides an estimated Nash equilibrium for the multi-UAV\nassisted communication Markov game.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.17880v1"
    },
    {
        "title": "Multi-agent Path Finding for Cooperative Autonomous Driving",
        "authors": [
            "Zhongxia Yan",
            "Han Zheng",
            "Cathy Wu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Anticipating possible future deployment of connected and automated vehicles\n(CAVs), cooperative autonomous driving at intersections has been studied by\nmany works in control theory and intelligent transportation across decades.\nSimultaneously, recent parallel works in robotics have devised efficient\nalgorithms for multi-agent path finding (MAPF), though often in environments\nwith simplified kinematics. In this work, we hybridize insights and algorithms\nfrom MAPF with the structure and heuristics of optimizing the crossing order of\nCAVs at signal-free intersections. We devise an optimal and complete algorithm,\nOrder-based Search with Kinematics Arrival Time Scheduling (OBS-KATS), which\nsignificantly outperforms existing algorithms, fixed heuristics, and\nprioritized planning with KATS. The performance is maintained under different\nvehicle arrival rates, lane lengths, crossing speeds, and control horizon.\nThrough ablations and dissections, we offer insight on the contributing factors\nto OBS-KATS's performance. Our work is directly applicable to many similarly\nscaled traffic and multi-robot scenarios with directed lanes.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.00334v1"
    },
    {
        "title": "Guidance Graph Optimization for Lifelong Multi-Agent Path Finding",
        "authors": [
            "Yulun Zhang",
            "He Jiang",
            "Varun Bhatt",
            "Stefanos Nikolaidis",
            "Jiaoyang Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We study how to use guidance to improve the throughput of lifelong\nMulti-Agent Path Finding (MAPF). Previous studies have demonstrated that, while\nincorporating guidance, such as highways, can accelerate MAPF algorithms, this\noften results in a trade-off with solution quality. In addition, how to\ngenerate good guidance automatically remains largely unexplored, with current\nmethods falling short of surpassing manually designed ones. In this work, we\nintroduce the guidance graph as a versatile representation of guidance for\nlifelong MAPF, framing Guidance Graph Optimization as the task of optimizing\nits edge weights. We present two GGO algorithms to automatically generate\nguidance for arbitrary lifelong MAPF algorithms and maps. The first method\ndirectly optimizes edge weights, while the second method optimizes an update\nmodel capable of generating edge weights. Empirically, we show that (1) our\nguidance graphs improve the throughput of three representative lifelong MAPF\nalgorithms in eight benchmark maps, and (2) our update model can generate\nguidance graphs for as large as $93 \\times 91$ maps and as many as 3,000\nagents. We include the source code at:\n\\url{https://github.com/lunjohnzhang/ggo_public}. All optimized guidance graphs\nare available online at: \\url{https://yulunzhang.net/publication/zhang2024ggo}.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01446v2"
    },
    {
        "title": "A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges\n  and Future Directions",
        "authors": [
            "Hung Du",
            "Srikanth Thudumu",
            "Rajesh Vasa",
            "Kon Mouzakis"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Research interest in autonomous agents is on the rise as an emerging topic.\nThe notable achievements of Large Language Models (LLMs) have demonstrated the\nconsiderable potential to attain human-like intelligence in autonomous agents.\nHowever, the challenge lies in enabling these agents to learn, reason, and\nnavigate uncertainties in dynamic environments. Context awareness emerges as a\npivotal element in fortifying multi-agent systems when dealing with dynamic\nsituations. Despite existing research focusing on both context-aware systems\nand multi-agent systems, there is a lack of comprehensive surveys outlining\ntechniques for integrating context-aware systems with multi-agent systems. To\naddress this gap, this survey provides a comprehensive overview of\nstate-of-the-art context-aware multi-agent systems. First, we outline the\nproperties of both context-aware systems and multi-agent systems that\nfacilitate integration between these systems. Subsequently, we propose a\ngeneral process for context-aware systems, with each phase of the process\nencompassing diverse approaches drawn from various application domains such as\ncollision avoidance in autonomous driving, disaster relief management, utility\nmanagement, supply chain management, human-AI interaction, and others. Finally,\nwe discuss the existing challenges of context-aware multi-agent systems and\nprovide future research directions in this field.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01968v1"
    },
    {
        "title": "Settling Decentralized Multi-Agent Coordinated Exploration by Novelty\n  Sharing",
        "authors": [
            "Haobin Jiang",
            "Ziluo Ding",
            "Zongqing Lu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Exploration in decentralized cooperative multi-agent reinforcement learning\nfaces two challenges. One is that the novelty of global states is unavailable,\nwhile the novelty of local observations is biased. The other is how agents can\nexplore in a coordinated way. To address these challenges, we propose MACE, a\nsimple yet effective multi-agent coordinated exploration method. By\ncommunicating only local novelty, agents can take into account other agents'\nlocal novelty to approximate the global novelty. Further, we newly introduce\nweighted mutual information to measure the influence of one agent's action on\nother agents' accumulated novelty. We convert it as an intrinsic reward in\nhindsight to encourage agents to exert more influence on other agents'\nexploration and boost coordinated exploration. Empirically, we show that MACE\nachieves superior performance in three multi-agent environments with sparse\nrewards.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.02097v2"
    },
    {
        "title": "Cooperative Learning with Gaussian Processes for Euler-Lagrange Systems\n  Tracking Control under Switching Topologies",
        "authors": [
            "Zewen Yang",
            "Songbo Dong",
            "Armin Lederer",
            "Xiaobing Dai",
            "Siyu Chen",
            "Stefan Sosnowski",
            "Georges Hattab",
            "Sandra Hirche"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This work presents an innovative learning-based approach to tackle the\ntracking control problem of Euler-Lagrange multi-agent systems with partially\nunknown dynamics operating under switching communication topologies. The\napproach leverages a correlation-aware cooperative algorithm framework built\nupon Gaussian process regression, which adeptly captures inter-agent\ncorrelations for uncertainty predictions. A standout feature is its exceptional\nefficiency in deriving the aggregation weights achieved by circumventing the\ncomputationally intensive posterior variance calculations. Through Lyapunov\nstability analysis, the distributed control law ensures bounded tracking errors\nwith high probability. Simulation experiments validate the protocol's efficacy\nin effectively managing complex scenarios, establishing it as a promising\nsolution for robust tracking control in multi-agent systems characterized by\nuncertain dynamics and dynamic communication structures.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.03048v1"
    },
    {
        "title": "Mixed Q-Functionals: Advancing Value-Based Methods in Cooperative MARL\n  with Continuous Action Domains",
        "authors": [
            "Yasin Findik",
            "S. Reza Ahmadzadeh"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Tackling multi-agent learning problems efficiently is a challenging task in\ncontinuous action domains. While value-based algorithms excel in sample\nefficiency when applied to discrete action domains, they are usually\ninefficient when dealing with continuous actions. Policy-based algorithms, on\nthe other hand, attempt to address this challenge by leveraging critic networks\nfor guiding the learning process and stabilizing the gradient estimation. The\nlimitations in the estimation of true return and falling into local optima in\nthese methods result in inefficient and often sub-optimal policies. In this\npaper, we diverge from the trend of further enhancing critic networks, and\nfocus on improving the effectiveness of value-based methods in multi-agent\ncontinuous domains by concurrently evaluating numerous actions. We propose a\nnovel multi-agent value-based algorithm, Mixed Q-Functionals (MQF), inspired\nfrom the idea of Q-Functionals, that enables agents to transform their states\ninto basis functions. Our algorithm fosters collaboration among agents by\nmixing their action-values. We evaluate the efficacy of our algorithm in six\ncooperative multi-agent scenarios. Our empirical findings reveal that MQF\noutperforms four variants of Deep Deterministic Policy Gradient through rapid\naction evaluation and increased sample efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.07752v1"
    },
    {
        "title": "ABIDES-Economist: Agent-Based Simulation of Economic Systems with\n  Learning Agents",
        "authors": [
            "Kshama Dwarakanath",
            "Svitlana Vyetrenko",
            "Peyman Tavallali",
            "Tucker Balch"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We introduce a multi-agent simulator for economic systems comprised of\nheterogeneous Households, heterogeneous Firms, Central Bank and Government\nagents, that could be subjected to exogenous, stochastic shocks. The\ninteraction between agents defines the production and consumption of goods in\nthe economy alongside the flow of money. Each agent can be designed to act\naccording to fixed, rule-based strategies or learn their strategies using\ninteractions with others in the simulator. We ground our simulator by choosing\nagent heterogeneity parameters based on economic literature, while designing\ntheir action spaces in accordance with real data in the United States. Our\nsimulator facilitates the use of reinforcement learning strategies for the\nagents via an OpenAI Gym style environment definition for the economic system.\nWe demonstrate the utility of our simulator by simulating and analyzing two\nhypothetical (yet interesting) economic scenarios. The first scenario\ninvestigates the impact of heterogeneous household skills on their learned\npreferences to work at different firms. The second scenario examines the impact\nof a positive production shock to one of two firms on its pricing strategy in\ncomparison to the second firm. We aspire that our platform sets a stage for\nsubsequent research at the intersection of artificial intelligence and\neconomics.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.09563v1"
    },
    {
        "title": "Discovering Sensorimotor Agency in Cellular Automata using Diversity\n  Search",
        "authors": [
            "Gautier Hamon",
            "Mayalen Etcheverry",
            "Bert Wang-Chak Chan",
            "Clément Moulin-Frier",
            "Pierre-Yves Oudeyer"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The research field of Artificial Life studies how life-like phenomena such as\nautopoiesis, agency, or self-regulation can self-organize in computer\nsimulations. In cellular automata (CA), a key open-question has been whether it\nit is possible to find environment rules that self-organize robust\n\"individuals\" from an initial state with no prior existence of things like\n\"bodies\", \"brain\", \"perception\" or \"action\". In this paper, we leverage recent\nadvances in machine learning, combining algorithms for diversity search,\ncurriculum learning and gradient descent, to automate the search of such\n\"individuals\", i.e. localized structures that move around with the ability to\nreact in a coherent manner to external obstacles and maintain their integrity,\nhence primitive forms of sensorimotor agency. We show that this approach\nenables to find systematically environmental conditions in CA leading to\nself-organization of such basic forms of agency. Through multiple experiments,\nwe show that the discovered agents have surprisingly robust capabilities to\nmove, maintain their body integrity and navigate among various obstacles. They\nalso show strong generalization abilities, with robustness to changes of scale,\nrandom updates or perturbations from the environment not seen during training.\nWe discuss how this approach opens new perspectives in AI and synthetic\nbioengineering.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.10236v1"
    },
    {
        "title": "A Conflict-Aware Optimal Goal Assignment Algorithm for Multi-Robot\n  Systems",
        "authors": [
            " Aakash",
            "Indranil Saha"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The fundamental goal assignment problem for a multi-robot application aims to\nassign a unique goal to each robot while ensuring collision-free paths,\nminimizing the total movement cost. A plausible algorithmic solution to this\nNP-hard problem involves an iterative process that integrates a task planner to\ncompute the goal assignment while ignoring the collision possibilities among\nthe robots and a multi-agent path-finding algorithm to find the collision-free\ntrajectories for a given assignment. This procedure involves a method for\ncomputing the next best assignment given the current best assignment. A naive\nway of computing the next best assignment, as done in the state-of-the-art\nsolutions, becomes a roadblock to achieving scalability in solving the overall\nproblem. To obviate this bottleneck, we propose an efficient conflict-guided\nmethod to compute the next best assignment. Additionally, we introduce two more\noptimizations to the algorithm -- first for avoiding the unconstrained path\ncomputations between robot-goal pairs wherever possible, and the second to\nprevent duplicate constrained path computations for multiple robot-goal pairs.\nWe extensively evaluate our algorithm for up to a hundred robots on several\nbenchmark workspaces. The results demonstrate that the proposed algorithm\nachieves nearly an order of magnitude speedup over the state-of-the-art\nalgorithm, showcasing its efficacy in real-world scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.13292v1"
    },
    {
        "title": "A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit\n  Tasks in Public Health",
        "authors": [
            "Nikhil Behari",
            "Edwin Zhang",
            "Yunfan Zhao",
            "Aparna Taneja",
            "Dheeraj Nagaraj",
            "Milind Tambe"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Restless multi-armed bandits (RMAB) have demonstrated success in optimizing\nresource allocation for large beneficiary populations in public health\nsettings. Unfortunately, RMAB models lack flexibility to adapt to evolving\npublic health policy priorities. Concurrently, Large Language Models (LLMs)\nhave emerged as adept automated planners across domains of robotic control and\nnavigation. In this paper, we propose a Decision Language Model (DLM) for\nRMABs, enabling dynamic fine-tuning of RMAB policies in public health settings\nusing human-language commands. We propose using LLMs as automated planners to\n(1) interpret human policy preference prompts, (2) propose reward functions as\ncode for a multi-agent RMAB environment, and (3) iterate on the generated\nreward functions using feedback from grounded RMAB simulations. We illustrate\nthe application of DLM in collaboration with ARMMAN, an India-based non-profit\npromoting preventative care for pregnant mothers, that currently relies on RMAB\npolicies to optimally allocate health worker calls to low-resource populations.\nWe conduct a technology demonstration in simulation using the Gemini Pro model,\nshowing DLM can dynamically shape policy outcomes using only human prompts as\ninput.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.14807v4"
    },
    {
        "title": "HiMAP: Learning Heuristics-Informed Policies for Large-Scale Multi-Agent\n  Pathfinding",
        "authors": [
            "Huijie Tang",
            "Federico Berto",
            "Zihan Ma",
            "Chuanbo Hua",
            "Kyuree Ahn",
            "Jinkyoo Park"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large-scale multi-agent pathfinding (MAPF) presents significant challenges in\nseveral areas. As systems grow in complexity with a multitude of autonomous\nagents operating simultaneously, efficient and collision-free coordination\nbecomes paramount. Traditional algorithms often fall short in scalability,\nespecially in intricate scenarios. Reinforcement Learning (RL) has shown\npotential to address the intricacies of MAPF; however, it has also been shown\nto struggle with scalability, demanding intricate implementation, lengthy\ntraining, and often exhibiting unstable convergence, limiting its practical\napplication. In this paper, we introduce Heuristics-Informed Multi-Agent\nPathfinding (HiMAP), a novel scalable approach that employs imitation learning\nwith heuristic guidance in a decentralized manner. We train on small-scale\ninstances using a heuristic policy as a teacher that maps each single agent\nobservation information to an action probability distribution. During\npathfinding, we adopt several inference techniques to improve performance. With\na simple training scheme and implementation, HiMAP demonstrates competitive\nresults in terms of success rate and scalability in the field of\nimitation-learning-only MAPF, showing the potential of imitation-learning-only\nMAPF equipped with inference techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15546v1"
    },
    {
        "title": "Composite Distributed Learning and Synchronization of Nonlinear\n  Multi-Agent Systems with Complete Uncertain Dynamics",
        "authors": [
            "Emadodin Jandaghi",
            "Dalton L. Stein",
            "Adam Hoburg",
            "Paolo Stegagno",
            "Mingxi Zhou",
            "Chengzhi Yuan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper addresses the problem of composite synchronization and learning\ncontrol in a network of multi-agent robotic manipulator systems with\nheterogeneous nonlinear uncertainties under a leader-follower framework. A\nnovel two-layer distributed adaptive learning control strategy is introduced,\ncomprising a first-layer distributed cooperative estimator and a second-layer\ndecentralized deterministic learning controller. The first layer is to\nfacilitate each robotic agent's estimation of the leader's information. The\nsecond layer is responsible for both controlling individual robot agents to\ntrack desired reference trajectories and accurately identifying/learning their\nnonlinear uncertain dynamics. The proposed distributed learning control scheme\nrepresents an advancement in the existing literature due to its ability to\nmanage robotic agents with completely uncertain dynamics including uncertain\nmass matrices. This allows the robotic control to be environment-independent\nwhich can be used in various settings, from underwater to space where\nidentifying system dynamics parameters is challenging. The stability and\nparameter convergence of the closed-loop system are rigorously analyzed using\nthe Lyapunov method. Numerical simulations validate the effectiveness of the\nproposed scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.00987v3"
    },
    {
        "title": "An AI-enabled Agent-Based Model and Its Application in Measles Outbreak\n  Simulation for New Zealand",
        "authors": [
            "Sijin Zhang",
            "Alvaro Orsi",
            "Lei Chen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Agent Based Models (ABMs) have emerged as a powerful tool for investigating\ncomplex social interactions, particularly in the context of public health and\ninfectious disease investigation. In an effort to enhance the conventional ABM,\nenabling automated model calibration and reducing the computational resources\nneeded for scaling up the model, we have developed a tensorized and\ndifferentiable agent-based model by coupling Graph Neural Network (GNN) and\nLong Short-Term Memory (LSTM) network. The model was employed to investigate\nthe 2019 measles outbreak occurred in New Zealand, demonstrating a promising\nability to accurately simulate the outbreak dynamics, particularly during the\npeak period of repeated cases. This paper shows that by leveraging the latest\nArtificial Intelligence (AI) technology and the capabilities of traditional\nABMs, we gain deeper insights into the dynamics of infectious disease\noutbreaks. This, in turn, helps us make more informed decision when developing\neffective strategies that strike a balance between managing outbreaks and\nminimizing disruptions to everyday life.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.03434v2"
    },
    {
        "title": "Dynamics of Moral Behavior in Heterogeneous Populations of Learning\n  Agents",
        "authors": [
            "Elizaveta Tennant",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Growing concerns about safety and alignment of AI systems highlight the\nimportance of embedding moral capabilities in artificial agents: a promising\nsolution is the use of learning from experience, i.e., Reinforcement Learning.\nIn multi-agent (social) environments, complex population-level phenomena may\nemerge from interactions between individual learning agents. Many of the\nexisting studies rely on simulated social dilemma environments to study the\ninteractions of independent learning agents; however, they tend to ignore the\nmoral heterogeneity that is likely to be present in societies of agents in\npractice. For example, at different points in time a single learning agent may\nface opponents who are consequentialist (i.e., focused on maximizing outcomes\nover time), norm-based (i.e., conforming to specific norms), or virtue-based\n(i.e., considering a combination of different virtues). The extent to which\nagents' co-development may be impacted by such moral heterogeneity in\npopulations is not well understood. In this paper, we present a study of the\nlearning dynamics of morally heterogeneous populations interacting in a social\ndilemma setting. Using an Iterated Prisoner's Dilemma environment with a\npartner selection mechanism, we investigate the extent to which the prevalence\nof diverse moral agents in populations affects individual agents' learning\nbehaviors and emergent population-level outcomes. We observe several types of\nnon-trivial interactions between pro-social and anti-social agents, and find\nthat certain types of moral agents are able to steer selfish agents towards\nmore cooperative behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.04202v7"
    },
    {
        "title": "Rational Silence and False Polarization: How Viewpoint Organizations and\n  Recommender Systems Distort the Expression of Public Opinion",
        "authors": [
            "Atrisha Sarkar",
            "Gillian K. Hadfield"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  AI-based social media platforms has already transformed the nature of\neconomic and social interaction. AI enables the massive scale and highly\npersonalized nature of online information sharing that we now take for granted.\nExtensive attention has been devoted to the polarization that social media\nplatforms appear to facilitate. However, a key implication of the\ntransformation we are experiencing due to these AI-powered platforms has\nreceived much less attention: how platforms impact what observers of online\ndiscourse come to believe about community views. These observers include\npolicymakers and legislators, who look to social media to gauge the prospects\nfor policy and legislative change, as well as developers of AI models trained\non large-scale internet data, whose outputs may similarly reflect a distorted\nview of public opinion. In this paper, we present a nested game-theoretic model\nto show how observed online opinion is produced by the interaction of the\ndecisions made by users about whether and with what rhetorical intensity to\nshare their opinions on a platform, the efforts of organizations (such as\ntraditional media and advocacy organizations) that seek to encourage or\ndiscourage opinion-sharing online, and the operation of AI-powered recommender\nsystems controlled by social media platforms. We show that signals from\nideological organizations encourage an increase in rhetorical intensity,\nleading to the 'rational silence' of moderate users. This, in turn, creates a\npolarized impression of where average opinions lie. We also show that this\nobserved polarization can also be amplified by recommender systems that\nencourage the formation of communities online that end up seeing a skewed\nsample of opinion. We also identify practical strategies platforms can\nimplement, such as reducing exposure to signals from ideological organizations\nand a tailored approach to content moderation.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.06264v2"
    },
    {
        "title": "Generalising Multi-Agent Cooperation through Task-Agnostic Communication",
        "authors": [
            "Dulhan Jayalath",
            "Steven Morad",
            "Amanda Prorok"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Existing communication methods for multi-agent reinforcement learning (MARL)\nin cooperative multi-robot problems are almost exclusively task-specific,\ntraining new communication strategies for each unique task. We address this\ninefficiency by introducing a communication strategy applicable to any task\nwithin a given environment. We pre-train the communication strategy without\ntask-specific reward guidance in a self-supervised manner using a set\nautoencoder. Our objective is to learn a fixed-size latent Markov state from a\nvariable number of agent observations. Under mild assumptions, we prove that\npolicies using our latent representations are guaranteed to converge, and upper\nbound the value error introduced by our Markov state approximation. Our method\nenables seamless adaptation to novel tasks without fine-tuning the\ncommunication strategy, gracefully supports scaling to more agents than present\nduring training, and detects out-of-distribution events in an environment.\nEmpirical results on diverse MARL scenarios validate the effectiveness of our\napproach, surpassing task-specific communication strategies in unseen tasks.\nOur implementation of this work is available at\nhttps://github.com/proroklab/task-agnostic-comms.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.06750v1"
    },
    {
        "title": "Ensembling Prioritized Hybrid Policies for Multi-agent Pathfinding",
        "authors": [
            "Huijie Tang",
            "Federico Berto",
            "Jinkyoo Park"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) based Multi-Agent Path Finding\n(MAPF) has recently gained attention due to its efficiency and scalability.\nSeveral MARL-MAPF methods choose to use communication to enrich the information\none agent can perceive. However, existing works still struggle in structured\nenvironments with high obstacle density and a high number of agents. To further\nimprove the performance of the communication-based MARL-MAPF solvers, we\npropose a new method, Ensembling Prioritized Hybrid Policies (EPH). We first\npropose a selective communication block to gather richer information for better\nagent coordination within multi-agent environments and train the model with a Q\nlearning-based algorithm. We further introduce three advanced inference\nstrategies aimed at bolstering performance during the execution phase. First,\nwe hybridize the neural policy with single-agent expert guidance for navigating\nconflict-free zones. Secondly, we propose Q value-based methods for prioritized\nresolution of conflicts as well as deadlock situations. Finally, we introduce a\nrobust ensemble method that can efficiently collect the best out of multiple\npossible solutions. We empirically evaluate EPH in complex multi-agent\nenvironments and demonstrate competitive performance against state-of-the-art\nneural methods for MAPF. We open-source our code at\nhttps://github.com/ai4co/eph-mapf.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.07559v2"
    },
    {
        "title": "Asynchronous Approximate Byzantine Consensus: A Multi-hop Relay Method\n  and Tight Graph Conditions",
        "authors": [
            "Liwei Yuan",
            "Hideaki Ishii"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We study a multi-agent resilient consensus problem, where some agents are of\nthe Byzantine type and try to prevent the normal ones from reaching consensus.\nIn our setting, normal agents communicate with each other asynchronously over\nmulti-hop relay channels with delays. To solve this asynchronous Byzantine\nconsensus problem, we develop the multi-hop weighted mean subsequence reduced\n(MW-MSR) algorithm. The main contribution is that we characterize a tight graph\ncondition for our algorithm to achieve Byzantine consensus, which is expressed\nin the novel notion of strictly robust graphs. We show that the multi-hop\ncommunication is effective for enhancing the network's resilience against\nByzantine agents. As a result, we also obtain novel conditions for resilient\nconsensus under the malicious attack model, which are tighter than those known\nin the literature. Furthermore, the proposed algorithm can be viewed as a\ngeneralization of the conventional flooding-based algorithms, with less\ncomputational complexity. Lastly, we provide numerical examples to show the\neffectiveness of the proposed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.07640v1"
    },
    {
        "title": "Emergence of Social Norms in Generative Agent Societies: Principles and\n  Architecture",
        "authors": [
            "Siyue Ren",
            "Zhiyao Cui",
            "Ruiqi Song",
            "Zhen Wang",
            "Shuyue Hu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Social norms play a crucial role in guiding agents towards understanding and\nadhering to standards of behavior, thus reducing social conflicts within\nmulti-agent systems (MASs). However, current LLM-based (or generative) MASs\nlack the capability to be normative. In this paper, we propose a novel\narchitecture, named CRSEC, to empower the emergence of social norms within\ngenerative MASs. Our architecture consists of four modules: Creation &\nRepresentation, Spreading, Evaluation, and Compliance. This addresses several\nimportant aspects of the emergent processes all in one: (i) where social norms\ncome from, (ii) how they are formally represented, (iii) how they spread\nthrough agents' communications and observations, (iv) how they are examined\nwith a sanity check and synthesized in the long term, and (v) how they are\nincorporated into agents' planning and actions. Our experiments deployed in the\nSmallville sandbox game environment demonstrate the capability of our\narchitecture to establish social norms and reduce social conflicts within\ngenerative MASs. The positive outcomes of our human evaluation, conducted with\n30 evaluators, further affirm the effectiveness of our approach. Our project\ncan be accessed via the following link: https://github.com/sxswz213/CRSEC.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08251v4"
    },
    {
        "title": "Autonomous Underground Freight Transport Systems -- The Future of Urban\n  Logistics?",
        "authors": [
            "Lasse Bienzeisler",
            "Torben Lelke",
            "Bernhard Friedrich"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We design a concept for an autonomous underground freight transport system\nfor Hanover, Germany. To evaluate the resulting system changes in overall\ntraffic flows from an environmental perspective, we carried out an agent-based\ntraffic simulation with MATSim. Our simulations indicate comparatively low\nimpacts on network-wide traffic volumes. Local CO2 emissions, on the other\nhand, could be reduced by up to 32 %. In total, the shuttle system can replace\nmore than 18 % of the vehicles in use with conventional combustion engines.\nThus, an autonomous underground freight transportation system can contribute to\nenvironmentally friendly and economical transportation of urban goods on the\ncondition of cooperative use of the system.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08841v1"
    },
    {
        "title": "Cultural evolution in populations of Large Language Models",
        "authors": [
            "Jérémy Perez",
            "Corentin Léger",
            "Marcela Ovando-Tellez",
            "Chris Foulon",
            "Joan Dussauld",
            "Pierre-Yves Oudeyer",
            "Clément Moulin-Frier"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Research in cultural evolution aims at providing causal explanations for the\nchange of culture over time. Over the past decades, this field has generated an\nimportant body of knowledge, using experimental, historical, and computational\nmethods. While computational models have been very successful at generating\ntestable hypotheses about the effects of several factors, such as population\nstructure or transmission biases, some phenomena have so far been more complex\nto capture using agent-based and formal models. This is in particular the case\nfor the effect of the transformations of social information induced by evolved\ncognitive mechanisms. We here propose that leveraging the capacity of Large\nLanguage Models (LLMs) to mimic human behavior may be fruitful to address this\ngap. On top of being an useful approximation of human cultural dynamics,\nmulti-agents models featuring generative agents are also important to study for\ntheir own sake. Indeed, as artificial agents are bound to participate more and\nmore to the evolution of culture, it is crucial to better understand the\ndynamics of machine-generated cultural evolution. We here present a framework\nfor simulating cultural evolution in populations of LLMs, allowing the\nmanipulation of variables known to be important in cultural evolution, such as\nnetwork structure, personality, and the way social information is aggregated\nand transformed. The software we developed for conducting these simulations is\nopen-source and features an intuitive user-interface, which we hope will help\nto build bridges between the fields of cultural evolution and generative\nartificial intelligence.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08882v1"
    },
    {
        "title": "Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Peihong Yu",
            "Manav Mishra",
            "Alec Koppel",
            "Carl Busart",
            "Priya Narayan",
            "Dinesh Manocha",
            "Amrit Bedi",
            "Pratap Tokekar"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Reinforcement Learning (MARL) algorithms face the challenge of\nefficient exploration due to the exponential increase in the size of the joint\nstate-action space. While demonstration-guided learning has proven beneficial\nin single-agent settings, its direct applicability to MARL is hindered by the\npractical difficulty of obtaining joint expert demonstrations. In this work, we\nintroduce a novel concept of personalized expert demonstrations, tailored for\neach individual agent or, more broadly, each individual type of agent within a\nheterogeneous team. These demonstrations solely pertain to single-agent\nbehaviors and how each agent can achieve personal goals without encompassing\nany cooperative elements, thus naively imitating them will not achieve\ncooperation due to potential conflicts. To this end, we propose an approach\nthat selectively utilizes personalized expert demonstrations as guidance and\nallows agents to learn to cooperate, namely personalized expert-guided MARL\n(PegMARL). This algorithm utilizes two discriminators: the first provides\nincentives based on the alignment of individual agent behavior with\ndemonstrations, and the second regulates incentives based on whether the\nbehaviors lead to the desired outcome. We evaluate PegMARL using personalized\ndemonstrations in both discrete and continuous environments. The experimental\nresults demonstrate that PegMARL outperforms state-of-the-art MARL algorithms\nin solving coordinated tasks, achieving strong performance even when provided\nwith suboptimal personalized demonstrations. We also showcase PegMARL's\ncapability of leveraging joint demonstrations in the StarCraft scenario and\nconverging effectively even with demonstrations from non-co-trained policies.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.08936v3"
    },
    {
        "title": "Conformal Off-Policy Prediction for Multi-Agent Systems",
        "authors": [
            "Tom Kuipers",
            "Renukanandan Tumu",
            "Shuo Yang",
            "Milad Kazemi",
            "Rahul Mangharam",
            "Nicola Paoletti"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Off-Policy Prediction (OPP), i.e., predicting the outcomes of a target policy\nusing only data collected under a nominal (behavioural) policy, is a paramount\nproblem in data-driven analysis of safety-critical systems where the deployment\nof a new policy may be unsafe. To achieve dependable off-policy predictions,\nrecent work on Conformal Off-Policy Prediction (COPP) leverage the conformal\nprediction framework to derive prediction regions with probabilistic guarantees\nunder the target process. Existing COPP methods can account for the\ndistribution shifts induced by policy switching, but are limited to\nsingle-agent systems and scalar outcomes (e.g., rewards). In this work, we\nintroduce MA-COPP, the first conformal prediction method to solve OPP problems\ninvolving multi-agent systems, deriving joint prediction regions for all\nagents' trajectories when one or more ego agents change their policies. Unlike\nthe single-agent scenario, this setting introduces higher complexity as the\ndistribution shifts affect predictions for all agents, not just the ego agents,\nand the prediction task involves full multi-dimensional trajectories, not just\nreward values. A key contribution of MA-COPP is to avoid enumeration or\nexhaustive search of the output space of agent trajectories, which is instead\nrequired by existing COPP methods to construct the prediction region. We\nachieve this by showing that an over-approximation of the true joint prediction\nregion (JPR) can be constructed, without enumeration, from the maximum density\nratio of the JPR trajectories. We evaluate the effectiveness of MA-COPP in\nmulti-agent systems from the PettingZoo library and the F1TENTH autonomous\nracing environment, achieving nominal coverage in higher dimensions and various\nshift settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.16871v2"
    },
    {
        "title": "Improving Learnt Local MAPF Policies with Heuristic Search",
        "authors": [
            "Rishi Veerapaneni",
            "Qian Wang",
            "Kevin Ren",
            "Arthur Jakobsson",
            "Jiaoyang Li",
            "Maxim Likhachev"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent path finding (MAPF) is the problem of finding collision-free\npaths for a team of agents to reach their goal locations. State-of-the-art\nclassical MAPF solvers typically employ heuristic search to find solutions for\nhundreds of agents but are typically centralized and can struggle to scale when\nrun with short timeouts. Machine learning (ML) approaches that learn policies\nfor each agent are appealing as these could enable decentralized systems and\nscale well while maintaining good solution quality. Current ML approaches to\nMAPF have proposed methods that have started to scratch the surface of this\npotential. However, state-of-the-art ML approaches produce \"local\" policies\nthat only plan for a single timestep and have poor success rates and\nscalability. Our main idea is that we can improve a ML local policy by using\nheuristic search methods on the output probability distribution to resolve\ndeadlocks and enable full horizon planning. We show several model-agnostic ways\nto use heuristic search with learnt policies that significantly improve the\npolicies' success rates and scalability. To our best knowledge, we demonstrate\nthe first time ML-based MAPF approaches have scaled to high congestion\nscenarios (e.g. 20% agent density).\n",
        "pdf_link": "http://arxiv.org/pdf/2403.20300v1"
    },
    {
        "title": "OpenMines: A Light and Comprehensive Mining Simulation Environment for\n  Truck Dispatching",
        "authors": [
            "Shi Meng",
            "Bin Tian",
            "Xiaotong Zhang",
            "Shuangying Qi",
            "Caiji Zhang",
            "Qiang Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Mine fleet management algorithms can significantly reduce operational costs\nand enhance productivity in mining systems. Most current fleet management\nalgorithms are evaluated based on self-implemented or proprietary simulation\nenvironments, posing challenges for replication and comparison. This paper\nmodels the simulation environment for mine fleet management from a complex\nsystems perspective. Building upon previous work, we introduce probabilistic,\nuser-defined events for random event simulation and implement various\nevaluation metrics and baselines, effectively reflecting the robustness of\nfleet management algorithms against unforeseen incidents. We present\n``OpenMines'', an open-source framework encompassing the entire process of mine\nsystem modeling, algorithm development, and evaluation, facilitating future\nalgorithm comparison and replication in the field. Code is available in\nhttps://github.com/370025263/openmines.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.00622v1"
    },
    {
        "title": "Distributed Autonomous Swarm Formation for Dynamic Network Bridging",
        "authors": [
            "Raffaele Galliera",
            "Thies Möhlenhof",
            "Alessandro Amato",
            "Daniel Duran",
            "Kristen Brent Venable",
            "Niranjan Suri"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Effective operation and seamless cooperation of robotic systems are a\nfundamental component of next-generation technologies and applications. In\ncontexts such as disaster response, swarm operations require coordinated\nbehavior and mobility control to be handled in a distributed manner, with the\nquality of the agents' actions heavily relying on the communication between\nthem and the underlying network. In this paper, we formulate the problem of\ndynamic network bridging in a novel Decentralized Partially Observable Markov\nDecision Process (Dec-POMDP), where a swarm of agents cooperates to form a link\nbetween two distant moving targets. Furthermore, we propose a Multi-Agent\nReinforcement Learning (MARL) approach for the problem based on Graph\nConvolutional Reinforcement Learning (DGN) which naturally applies to the\nnetworked, distributed nature of the task. The proposed method is evaluated in\na simulated environment and compared to a centralized heuristic baseline\nshowing promising results. Moreover, a further step in the direction of\nsim-to-real transfer is presented, by additionally evaluating the proposed\napproach in a near Live Virtual Constructive (LVC) UAV framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.01557v1"
    },
    {
        "title": "Traffic Divergence Theory: An Analysis Formalism for Dynamic Networks",
        "authors": [
            "Matin Macktoobian",
            "Zhan Shu",
            "Qing Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Traffic dynamics is universally crucial in analyzing and designing almost any\nnetwork. This article introduces a novel theoretical approach to analyzing\nnetwork traffic dynamics. This theory's machinery is based on the notion of\ntraffic divergence, which captures the flow (im)balance of network nodes and\nlinks. It features various analytical probes to investigate both spatial and\ntemporal traffic dynamics. In particular, the maximal traffic distribution in a\nnetwork can be characterized by spatial traffic divergence rate, which reveals\nthe relative difference among node traffic divergence. To illustrate the\nusefulness, we apply the theory to two network-driven problems: throughput\nestimation of data center networks and power-optimized communication planning\nfor robot networks, and show the merits of the proposed theory through\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.03066v1"
    },
    {
        "title": "ROMA-iQSS: An Objective Alignment Approach via State-Based Value\n  Learning and ROund-Robin Multi-Agent Scheduling",
        "authors": [
            "Chi-Hui Lin",
            "Joewie J. Koh",
            "Alessandro Roncone",
            "Lijun Chen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Effective multi-agent collaboration is imperative for solving complex,\ndistributed problems. In this context, two key challenges must be addressed:\nfirst, autonomously identifying optimal objectives for collective outcomes;\nsecond, aligning these objectives among agents. Traditional frameworks, often\nreliant on centralized learning, struggle with scalability and efficiency in\nlarge multi-agent systems. To overcome these issues, we introduce a\ndecentralized state-based value learning algorithm that enables agents to\nindependently discover optimal states. Furthermore, we introduce a novel\nmechanism for multi-agent interaction, wherein less proficient agents follow\nand adopt policies from more experienced ones, thereby indirectly guiding their\nlearning process. Our theoretical analysis shows that our approach leads\ndecentralized agents to an optimal collective policy. Empirical experiments\nfurther demonstrate that our method outperforms existing decentralized\nstate-based and action-based value learning strategies by effectively\nidentifying and aligning optimal objectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.03984v1"
    },
    {
        "title": "EVLearn: Extending the CityLearn Framework with Electric Vehicle\n  Simulation",
        "authors": [
            "Tiago Fonseca",
            "Luis Ferreira",
            "Bernardo Cabral",
            "Ricardo Severino",
            "Kingsley Nweye",
            "Dipanjan Ghose",
            "Zoltan Nagy"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Intelligent energy management strategies, such as Vehicle-to-Grid (V2G) and\nGrid-to-Vehicle (G2V) emerge as a potential solution to the Electric Vehicles'\n(EVs) integration into the energy grid. These strategies promise enhanced grid\nresilience and economic benefits for both vehicle owners and grid operators.\nDespite the announced prospective, the adoption of these strategies is still\nhindered by an array of operational problems. Key among these is the lack of a\nsimulation platform that allows to validate and refine V2G and G2V strategies.\nIncluding the development, training, and testing in the context of Energy\nCommunities (ECs) incorporating multiple flexible energy assets. Addressing\nthis gap, first we introduce the EVLearn, a simulation module for researching\nin both V2G and G2V energy management strategies, that models EVs, their\ncharging infrastructure and associated energy flexibility dynamics; second,\nthis paper integrates EVLearn with the existing CityLearn framework, providing\nV2G and G2V simulation capabilities into the study of broader energy management\nstrategies. Results validated EVLearn and its integration into CityLearn, where\nthe impact of these strategies is highlighted through a comparative simulation\nscenario.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.06521v1"
    },
    {
        "title": "Multi-Agent eXperimenter (MAX)",
        "authors": [
            "Önder Gürcan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We present a novel multi-agent simulator named Multi-Agent eXperimenter (MAX)\nthat is designed to simulate blockchain experiments involving large numbers of\nagents of different types acting in one or several environments. The\narchitecture of MAX is highly modular, enabling easy addition of new models.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.08398v1"
    },
    {
        "title": "mABC: multi-Agent Blockchain-Inspired Collaboration for root cause\n  analysis in micro-services architecture",
        "authors": [
            "Wei Zhang",
            "Hongcheng Guo",
            "Jian Yang",
            "Zhoujin Tian",
            "Yi Zhang",
            "Chaoran Yan",
            "Zhoujun Li",
            "Tongliang Li",
            "Xu Shi",
            "Liangfan Zheng",
            "Bo Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Root cause analysis (RCA) in Micro-services architecture (MSA) with\nescalating complexity encounters complex challenges in maintaining system\nstability and efficiency due to fault propagation and circular dependencies\namong nodes. Diverse root cause analysis faults require multi-agents with\ndiverse expertise. To mitigate the hallucination problem of large language\nmodels (LLMs), we design blockchain-inspired voting to ensure the reliability\nof the analysis by using a decentralized decision-making process. To avoid\nnon-terminating loops led by common circular dependency in MSA, we objectively\nlimit steps and standardize task processing through Agent Workflow. We propose\na pioneering framework, multi-Agent Blockchain-inspired Collaboration for root\ncause analysis in micro-services architecture (mABC), where multiple agents\nbased on the powerful LLMs follow Agent Workflow and collaborate in\nblockchain-inspired voting. Specifically, seven specialized agents derived from\nAgent Workflow each provide valuable insights towards root cause analysis based\non their expertise and the intrinsic software knowledge of LLMs collaborating\nwithin a decentralized chain. Our experiments on the AIOps challenge dataset\nand a newly created Train-Ticket dataset demonstrate superior performance in\nidentifying root causes and generating effective resolutions. The ablation\nstudy further highlights Agent Workflow, multi-agent, and blockchain-inspired\nvoting is crucial for achieving optimal performance. mABC offers a\ncomprehensive automated root cause analysis and resolution in micro-services\narchitecture and significantly improves the IT Operation domain. The code and\ndataset are in https://github.com/zwpride/mABC.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.12135v3"
    },
    {
        "title": "Private Agent-Based Modeling",
        "authors": [
            "Ayush Chopra",
            "Arnau Quera-Bofarull",
            "Nurullah Giray-Kuru",
            "Michael Wooldridge",
            "Ramesh Raskar"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The practical utility of agent-based models in decision-making relies on\ntheir capacity to accurately replicate populations while seamlessly integrating\nreal-world data streams. Yet, the incorporation of such data poses significant\nchallenges due to privacy concerns. To address this issue, we introduce a\nparadigm for private agent-based modeling wherein the simulation, calibration,\nand analysis of agent-based models can be achieved without centralizing the\nagents attributes or interactions. The key insight is to leverage techniques\nfrom secure multi-party computation to design protocols for decentralized\ncomputation in agent-based models. This ensures the confidentiality of the\nsimulated agents without compromising on simulation accuracy. We showcase our\nprotocols on a case study with an epidemiological simulation comprising over\n150,000 agents. We believe this is a critical step towards deploying\nagent-based models to real-world applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.12983v1"
    },
    {
        "title": "Reducing Redundant Computation in Multi-Agent Coordination through\n  Locally Centralized Execution",
        "authors": [
            "Yidong Bai",
            "Toshiharu Sugawara"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In multi-agent reinforcement learning, decentralized execution is a common\napproach, yet it suffers from the redundant computation problem. This occurs\nwhen multiple agents redundantly perform the same or similar computation due to\noverlapping observations. To address this issue, this study introduces a novel\nmethod referred to as locally centralized team transformer (LCTT). LCTT\nestablishes a locally centralized execution framework where selected agents\nserve as leaders, issuing instructions, while the rest agents, designated as\nworkers, act as these instructions without activating their policy networks.\nFor LCTT, we proposed the team-transformer (T-Trans) architecture that allows\nleaders to provide specific instructions to each worker, and the leadership\nshift mechanism that allows agents autonomously decide their roles as leaders\nor workers. Our experimental results demonstrate that the proposed method\neffectively reduces redundant computation, does not decrease reward levels, and\nleads to faster learning convergence.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.13096v1"
    },
    {
        "title": "MGCBS: An Optimal and Efficient Algorithm for Solving Multi-Goal\n  Multi-Agent Path Finding Problem",
        "authors": [
            "Mingkai Tang",
            "Yuanhang Li",
            "Hongji Liu",
            "Yingbing Chen",
            "Ming Liu",
            "Lujia Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the expansion of the scale of robotics applications, the multi-goal\nmulti-agent pathfinding (MG-MAPF) problem began to gain widespread attention.\nThis problem requires each agent to visit pre-assigned multiple goal points at\nleast once without conflict. Some previous methods have been proposed to solve\nthe MG-MAPF problem based on Decoupling the goal Vertex visiting order search\nand the Single-agent pathfinding (DVS). However, this paper demonstrates that\nthe methods based on DVS cannot always obtain the optimal solution. To obtain\nthe optimal result, we propose the Multi-Goal Conflict-Based Search (MGCBS),\nwhich is based on Decoupling the goal Safe interval visiting order search and\nthe Single-agent pathfinding (DSS). Additionally, we present the\nTime-Interval-Space Forest (TIS Forest) to enhance the efficiency of MGCBS by\nmaintaining the shortest paths from any start point at any start time step to\neach safe interval at the goal points. The experiment demonstrates that our\nmethod can consistently obtain optimal results and execute up to 7 times faster\nthan the state-of-the-art method in our evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.19518v1"
    },
    {
        "title": "Learning from Evolution: Improving Collective Decision-Making Mechanisms\n  using Insights from Evolutionary Robotics",
        "authors": [
            "Tanja Katharina Kaiser"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Collective decision-making enables multi-robot systems to act autonomously in\nreal-world environments. Existing collective decision-making mechanisms suffer\nfrom the so-called speed versus accuracy trade-off or rely on high complexity,\ne.g., by including global communication. Recent work has shown that more\nefficient collective decision-making mechanisms based on artificial neural\nnetworks can be generated using methods from evolutionary computation. A major\ndrawback of these decision-making neural networks is their limited\ninterpretability. Analyzing evolved decision-making mechanisms can help us\nimprove the efficiency of hand-coded decision-making mechanisms while\nmaintaining a higher interpretability. In this paper, we analyze evolved\ncollective decision-making mechanisms in detail and hand-code two new\ndecision-making mechanisms based on the insights gained. In benchmark\nexperiments, we show that the newly implemented collective decision-making\nmechanisms are more efficient than the state-of-the-art collective\ndecision-making mechanisms voter model and majority rule.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.02133v1"
    },
    {
        "title": "Walk model that continuously generates Brownian walks to Lévy walks\n  depending on destination attractiveness",
        "authors": [
            "Shuji Shinohara",
            "Daiki Morita",
            "Hayato Hirai",
            "Ryosuke Kuribayashi",
            "Nobuhito Manome",
            "Toru Moriyama",
            "Hiroshi Okamoto",
            "Yoshihiro Nakajima",
            "Yukio-Pegio Gunji",
            "Ung-il Chung"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The L\\'evy walk, a type of random walk characterized by linear step lengths\nthat follow a power-law distribution, is observed in the migratory behaviors of\nvarious organisms, ranging from bacteria to humans. Notably, L\\'evy walks with\npower exponents close to two, also known as Cauchy walks, are frequently\nobserved, though their underlying causes remain elusive. This study proposes a\nwalk model in which agents move toward a destination in multi-dimensional space\nand their movement strategy is parameterized by the extent to which they pursue\nthe shortest path to the destination. This parameter is taken to represent the\nattractiveness of the destination to the agents. Our findings reveal that if\nthe destination is very attractive, agents intensively search the area around\nit using Brownian walks, whereas if the destination is unattractive, they\nexplore a distant region away from the point using L\\'evy walks with power\nexponents less than two. In the case where agents are unable to determine\nwhether the destination is attractive or unattractive, Cauchy walks emerge. The\nCauchy walker searches the region with a probability inversely proportional to\nthe distance from the destination. This suggests that it preferentially\nsearches the area close to the destination, while concurrently having the\npotential to extend the search area much further. Our model, which can change\nthe search method and search area depending on the attractiveness of the\ndestination, has the potential to be utilized for exploring the parameter space\nof optimization problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.07541v4"
    },
    {
        "title": "Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning",
        "authors": [
            "Matteo Bettini",
            "Ryan Kortvelesy",
            "Amanda Prorok"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The study of behavioral diversity in Multi-Agent Reinforcement Learning\n(MARL) is a nascent yet promising field. In this context, the present work\ndeals with the question of how to control the diversity of a multi-agent\nsystem. With no existing approaches to control diversity to a set value,\ncurrent solutions focus on blindly promoting it via intrinsic rewards or\nadditional loss functions, effectively changing the learning objective and\nlacking a principled measure for it. To address this, we introduce Diversity\nControl (DiCo), a method able to control diversity to an exact value of a given\nmetric by representing policies as the sum of a parameter-shared component and\ndynamically scaled per-agent components. By applying constraints directly to\nthe policy architecture, DiCo leaves the learning objective unchanged, enabling\nits applicability to any actor-critic MARL algorithm. We theoretically prove\nthat DiCo achieves the desired diversity, and we provide several experiments,\nboth in cooperative and competitive tasks, that show how DiCo can be employed\nas a novel paradigm to increase performance and sample efficiency in MARL.\nMultimedia results are available on the paper's website:\nhttps://sites.google.com/view/dico-marl.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.15054v1"
    },
    {
        "title": "Resilient Average Consensus with Adversaries via Distributed Detection\n  and Recovery",
        "authors": [
            "Liwei Yuan",
            "Hideaki Ishii"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We study the problem of resilient average consensus in multi-agent systems\nwhere some of the agents are subject to failures or attacks. The objective of\nresilient average consensus is for non-faulty/normal agents to converge to the\naverage of their initial values despite the erroneous effects from malicious\nagents. To this end, we propose a successful distributed iterative resilient\naverage consensus algorithm for the multi-agent networks with general directed\ntopologies. The proposed algorithm has two parts at each iteration: detection\nand averaging. For the detection part, we propose two distributed algorithms\nand one of them can detect malicious agents with only the information from\ndirect in-neighbors. For the averaging part, we extend the applicability of an\nexisting averaging algorithm where normal agents can remove the effects from\nmalicious agents so far, after they are detected. Another important feature of\nour method is that it can handle the case where malicious agents are\nneighboring and collaborating with each other to mislead the normal ones from\naveraging. This case cannot be solved by existing detection approaches in\nrelated literature. Moreover, our algorithm is efficient in storage usage\nespecially for large-scale networks as each agent only requires the values of\nneighbors within two hops. Lastly, numerical examples are given to verify the\nefficacy of the proposed algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.18752v1"
    },
    {
        "title": "Safe Multi-agent Reinforcement Learning with Natural Language\n  Constraints",
        "authors": [
            "Ziyan Wang",
            "Meng Fang",
            "Tristan Tomilin",
            "Fei Fang",
            "Yali Du"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The role of natural language constraints in Safe Multi-agent Reinforcement\nLearning (MARL) is crucial, yet often overlooked. While Safe MARL has vast\npotential, especially in fields like robotics and autonomous vehicles, its full\npotential is limited by the need to define constraints in pre-designed\nmathematical terms, which requires extensive domain expertise and reinforcement\nlearning knowledge, hindering its broader adoption. To address this limitation\nand make Safe MARL more accessible and adaptable, we propose a novel approach\nnamed Safe Multi-agent Reinforcement Learning with Natural Language constraints\n(SMALL). Our method leverages fine-tuned language models to interpret and\nprocess free-form textual constraints, converting them into semantic embeddings\nthat capture the essence of prohibited states and behaviours. These embeddings\nare then integrated into the multi-agent policy learning process, enabling\nagents to learn policies that minimize constraint violations while optimizing\nrewards. To evaluate the effectiveness of SMALL, we introduce the LaMaSafe, a\nmulti-task benchmark designed to assess the performance of multiple agents in\nadhering to natural language constraints. Empirical evaluations across various\nenvironments demonstrate that SMALL achieves comparable rewards and\nsignificantly fewer constraint violations, highlighting its effectiveness in\nunderstanding and enforcing natural language constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.20018v1"
    },
    {
        "title": "Congestion-Aware Path Re-routing Strategy for Dense Urban Airspace",
        "authors": [
            "Sajid Ahamed Mohammed Abdul",
            "Prathyush P Menon",
            "Debasish Ghose"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Existing UAS Traffic Management (UTM) frameworks designate preplanned flight\npaths to uncrewed aircraft systems (UAS), enabling the UAS to deliver payloads.\nHowever, with increasing delivery demand between the source-destination pairs\nin the urban airspace, UAS will likely experience considerable congestion on\nthe nominal paths. We propose a rule-based congestion mitigation strategy that\nimproves UAS safety and airspace utilization in congested traffic streams. The\nstrategy relies on nominal path information from the UTM and positional\ninformation of other UAS in the vicinity. Following the strategy, UAS opts for\nalternative local paths in the unoccupied airspace surrounding the nominal path\nand avoids congested regions. The strategy results in UAS traffic exploring and\nspreading to alternative adjacent routes on encountering congestion. The paper\npresents queuing models to estimate the expected traffic spread for varying\nstochastic delivery demand at the source, thus helping to reserve the airspace\naround the nominal path beforehand to accommodate any foreseen congestion.\nSimulations are presented to validate the queuing results in the presence of\nstatic obstacles and intersecting UAS streams.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.20972v2"
    },
    {
        "title": "FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Wenzhe Li",
            "Zihan Ding",
            "Seth Karten",
            "Chi Jin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Recent advances in reinforcement learning (RL) heavily rely on a variety of\nwell-designed benchmarks, which provide environmental platforms and consistent\ncriteria to evaluate existing and novel algorithms. Specifically, in\nmulti-agent RL (MARL), a plethora of benchmarks based on cooperative games have\nspurred the development of algorithms that improve the scalability of\ncooperative multi-agent systems. However, for the competitive setting, a\nlightweight and open-sourced benchmark with challenging gaming dynamics and\nvisual inputs has not yet been established. In this work, we present\nFightLadder, a real-time fighting game platform, to empower competitive MARL\nresearch. Along with the platform, we provide implementations of\nstate-of-the-art MARL algorithms for competitive games, as well as a set of\nevaluation metrics to characterize the performance and exploitability of\nagents. We demonstrate the feasibility of this platform by training a general\nagent that consistently defeats 12 built-in characters in single-player mode,\nand expose the difficulty of training a non-exploitable agent without human\nknowledge and demonstrations in two-player mode. FightLadder provides\nmeticulously designed environments to address critical challenges in\ncompetitive MARL research, aiming to catalyze a new era of discovery and\nadvancement in the field. Videos and code at\nhttps://sites.google.com/view/fightladder/home.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.02081v2"
    },
    {
        "title": "Representation Learning For Efficient Deep Multi-Agent Reinforcement\n  Learning",
        "authors": [
            "Dom Huh",
            "Prasant Mohapatra"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Sample efficiency remains a key challenge in multi-agent reinforcement\nlearning (MARL). A promising approach is to learn a meaningful latent\nrepresentation space through auxiliary learning objectives alongside the MARL\nobjective to aid in learning a successful control policy. In our work, we\npresent MAPO-LSO (Multi-Agent Policy Optimization with Latent Space\nOptimization) which applies a form of comprehensive representation learning\ndevised to supplement MARL training. Specifically, MAPO-LSO proposes a\nmulti-agent extension of transition dynamics reconstruction and self-predictive\nlearning that constructs a latent state optimization scheme that can be\ntrivially extended to current state-of-the-art MARL algorithms. Empirical\nresults demonstrate MAPO-LSO to show notable improvements in sample efficiency\nand learning performance compared to its vanilla MARL counterpart without any\nadditional MARL hyperparameter tuning on a diverse suite of MARL tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.02890v1"
    },
    {
        "title": "Task-Oriented Wireless Communications for Collaborative Perception in\n  Intelligent Unmanned Systems",
        "authors": [
            "Sheng Zhou",
            "Yukuan Jia",
            "Ruiqing Mao",
            "Zhaojun Nan",
            "Yuxuan Sun",
            "Zhisheng Niu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Collaborative Perception (CP) has shown great potential to achieve more\nholistic and reliable environmental perception in intelligent unmanned systems\n(IUSs). However, implementing CP still faces key challenges due to the\ncharacteristics of the CP task and the dynamics of wireless channels. In this\narticle, a task-oriented wireless communication framework is proposed to\njointly optimize the communication scheme and the CP procedure. We first\npropose channel-adaptive compression and robust fusion approaches to extract\nand exploit the most valuable semantic information under wireless communication\nconstraints. We then propose a task-oriented distributed scheduling algorithm\nto identify the best collaborators for CP under dynamic environments. The main\nidea is learning while scheduling, where the collaboration utility is\neffectively learned with low computation and communication overhead. Case\nstudies are carried out in connected autonomous driving scenarios to verify the\nproposed framework. Finally, we identify several future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.03086v1"
    },
    {
        "title": "Deception Analysis with Artificial Intelligence: An Interdisciplinary\n  Perspective",
        "authors": [
            "Stefan Sarkadi"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Humans and machines interact more frequently than ever and our societies are\nbecoming increasingly hybrid. A consequence of this hybridisation is the\ndegradation of societal trust due to the prevalence of AI-enabled deception.\nYet, despite our understanding of the role of trust in AI in the recent years,\nwe still do not have a computational theory to be able to fully understand and\nexplain the role deception plays in this context. This is a problem because\nwhile our ability to explain deception in hybrid societies is delayed, the\ndesign of AI agents may keep advancing towards fully autonomous deceptive\nmachines, which would pose new challenges to dealing with deception. In this\npaper we build a timely and meaningful interdisciplinary perspective on\ndeceptive AI and reinforce a 20 year old socio-cognitive perspective on trust\nand deception, by proposing the development of DAMAS -- a holistic Multi-Agent\nSystems (MAS) framework for the socio-cognitive modelling and analysis of\ndeception. In a nutshell this paper covers the topic of modelling and\nexplaining deception using AI approaches from the perspectives of Computer\nScience, Philosophy, Psychology, Ethics, and Intelligence Analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.05724v2"
    },
    {
        "title": "A Simulation Environment for the Neuroevolution of Ant Colony Dynamics",
        "authors": [
            "Michael Crosscombe",
            "Ilya Horiguchi",
            "Norihiro Maruyama",
            "Shigeto Dobata",
            "Takashi Ikegami"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We introduce a simulation environment to facilitate research into emergent\ncollective behaviour, with a focus on replicating the dynamics of ant colonies.\nBy leveraging real-world data, the environment simulates a target ant trail\nthat a controllable agent must learn to replicate, using sensory data observed\nby the target ant. This work aims to contribute to the neuroevolution of models\nfor collective behaviour, focusing on evolving neural architectures that encode\ndomain-specific behaviours in the network topology. By evolving models that can\nbe modified and studied in a controlled environment, we can uncover the\nnecessary conditions required for collective behaviours to emerge. We hope this\nenvironment will be useful to those studying the role of interactions in\nemergent behaviour within collective systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.13147v3"
    },
    {
        "title": "Robust Cooperative Multi-Agent Reinforcement Learning:A Mean-Field Type\n  Game Perspective",
        "authors": [
            "Muhammad Aneeq uz Zaman",
            "Mathieu Laurière",
            "Alec Koppel",
            "Tamer Başar"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper, we study the problem of robust cooperative multi-agent\nreinforcement learning (RL) where a large number of cooperative agents with\ndistributed information aim to learn policies in the presence of\n\\emph{stochastic} and \\emph{non-stochastic} uncertainties whose distributions\nare respectively known and unknown. Focusing on policy optimization that\naccounts for both types of uncertainties, we formulate the problem in a\nworst-case (minimax) framework, which is is intractable in general. Thus, we\nfocus on the Linear Quadratic setting to derive benchmark solutions. First,\nsince no standard theory exists for this problem due to the distributed\ninformation structure, we utilize the Mean-Field Type Game (MFTG) paradigm to\nestablish guarantees on the solution quality in the sense of achieved Nash\nequilibrium of the MFTG. This in turn allows us to compare the performance\nagainst the corresponding original robust multi-agent control problem. Then, we\npropose a Receding-horizon Gradient Descent Ascent RL algorithm to find the\nMFTG Nash equilibrium and we prove a non-asymptotic rate of convergence.\nFinally, we provide numerical experiments to demonstrate the efficacy of our\napproach relative to a baseline algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.13992v1"
    },
    {
        "title": "Singular knee identification to support emergence recognition in\n  physical swarm and cellular automata trajectories",
        "authors": [
            "Imraan A. Faruque",
            "Ishriak Ahmed"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  After decades of attention, emergence continues to lack a centralized\nmathematical definition that leads to a rigorous emergence test applicable to\nphysical flocks and swarms, particularly those containing both deterministic\nelements (eg, interactions) and stochastic perturbations like measurement\nnoise. This study develops a heuristic test based on singular value curve\nanalysis of data matrices containing deterministic and Gaussian noise signals.\nThe minimum detection criteria are identified, and statistical and matrix space\nanalysis developed to determine upper and lower bounds. This study applies the\nanalysis to representative examples by using recorded trajectories of mixed\ndeterministic and stochastic trajectories for multi-agent, cellular automata,\nand biological video. Examples include Cucker Smale and Vicsek flocking,\nGaussian noise and its integration, recorded observations of bird flocking, and\n1D cellular automata. Ensemble simulations including measurement noise are\nperformed to compute statistical variation and discussed relative to random\nmatrix theory noise bounds. The results indicate singular knee analysis of\nrecorded trajectories can detect gradated levels on a continuum of structure\nand noise. Across the eight singular value decay metrics considered, the angle\nsubtended at the singular value knee emerges with the most potential for\nsupporting cross-embodiment emergence detection, the size of noise bounds is\nused as an indication of required sample size, and the presence of a large\nfraction of singular values inside noise bounds as an indication of noise.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14652v1"
    },
    {
        "title": "On the Principles behind Opinion Dynamics in Multi-Agent Systems of\n  Large Language Models",
        "authors": [
            "Pedro Cisneros-Velarde"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We study the evolution of opinions inside a population of interacting large\nlanguage models (LLMs). Every LLM needs to decide how much funding to allocate\nto an item with three initial possibilities: full, partial, or no funding. We\nidentify biases that drive the exchange of opinions based on the LLM's tendency\nto find consensus with the other LLM's opinion, display caution when specifying\nfunding, and consider ethical concerns in its opinion. We find these biases are\naffected by the perceived absence of compelling reasons for opinion change, the\nperceived willingness to engage in discussion, and the distribution of\nallocation values. Moreover, tensions among biases can lead to the survival of\nfunding for items with negative connotations. We also find that the final\ndistribution of full, partial, and no funding opinions is more diverse when an\nLLM freely forms its opinion after an interaction than when its opinion is a\nmultiple-choice selection among the three allocation options. In the latter\ncase, consensus is mostly attained. When agents are aware of past opinions,\nthey seek to maintain consistency with them, changing the opinion dynamics. Our\nstudy is performed using Llama 3 and Mistral LLMs.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.15492v2"
    },
    {
        "title": "Differential error feedback for communication-efficient decentralized\n  learning",
        "authors": [
            "Roula Nassif",
            "Stefan Vlaski",
            "Marco Carpentiero",
            "Vincenzo Matta",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Communication-constrained algorithms for decentralized learning and\noptimization rely on local updates coupled with the exchange of compressed\nsignals. In this context, differential quantization is an effective technique\nto mitigate the negative impact of compression by leveraging correlations\nbetween successive iterates. In addition, the use of error feedback, which\nconsists of incorporating the compression error into subsequent steps, is a\npowerful mechanism to compensate for the bias caused by the compression. Under\nerror feedback, performance guarantees in the literature have so far focused on\nalgorithms employing a fusion center or a special class of contractive\ncompressors that cannot be implemented with a finite number of bits. In this\nwork, we propose a new decentralized communication-efficient learning approach\nthat blends differential quantization with error feedback. The approach is\nspecifically tailored for decentralized learning problems where agents have\nindividual risk functions to minimize subject to subspace constraints that\nrequire the minimizers across the network to lie in low-dimensional subspaces.\nThis constrained formulation includes consensus or single-task optimization as\nspecial cases, and allows for more general task relatedness models such as\nmultitask smoothness and coupled optimization. We show that, under some general\nconditions on the compression noise, and for sufficiently small step-sizes\n$\\mu$, the resulting communication-efficient strategy is stable both in terms\nof mean-square error and average bit rate: by reducing $\\mu$, it is possible to\nkeep the estimation errors small (on the order of $\\mu$) without increasing\nindefinitely the bit rate as $\\mu\\rightarrow 0$. The results establish that, in\nthe small step-size regime and with a finite number of bits, it is possible to\nattain the performance achievable in the absence of compression.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.18418v1"
    },
    {
        "title": "Learning to Control Unknown Strongly Monotone Games",
        "authors": [
            "Siddharth Chandak",
            "Ilai Bistritz",
            "Nicholas Bambos"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Consider a game where the players' utility functions include a reward\nfunction and a linear term for each dimension, with coefficients that are\ncontrolled by the manager. We assume that the game is strongly monotone, so\ngradient play converges to a unique Nash equilibrium (NE). The NE is typically\nglobally inefficient. The global performance at NE can be improved by imposing\nlinear constraints on the NE. We therefore want the manager to pick the\ncontrolled coefficients that impose the desired constraint on the NE. However,\nthis requires knowing the players' reward functions and action sets. Obtaining\nthis game information is infeasible in a large-scale network and violates user\nprivacy. To overcome this, we propose a simple algorithm that learns to shift\nthe NE to meet the linear constraints by adjusting the controlled coefficients\nonline. Our algorithm only requires the linear constraints violation as\nfeedback and does not need to know the reward functions or the action sets. We\nprove that our algorithm converges with probability 1 to the set of NE that\nsatisfy target linear constraints. We then prove an L2 convergence rate of\nnear-$O(t^{-1/4})$.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.00575v2"
    },
    {
        "title": "Online Learning of Temporal Dependencies for Sustainable Foraging\n  Problem",
        "authors": [
            "John Payne",
            " Aishwaryaprajna",
            "Peter R. Lewis"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The sustainable foraging problem is a dynamic environment testbed for\nexploring the forms of agent cognition in dealing with social dilemmas in a\nmulti-agent setting. The agents need to resist the temptation of individual\nrewards through foraging and choose the collective long-term goal of\nsustainability. We investigate methods of online learning in Neuro-Evolution\nand Deep Recurrent Q-Networks to enable agents to attempt the problem one-shot\nas is often required by wicked social problems. We further explore if learning\ntemporal dependencies with Long Short-Term Memory may be able to aid the agents\nin developing sustainable foraging strategies in the long term. It was found\nthat the integration of Long Short-Term Memory assisted agents in developing\nsustainable strategies for a single agent, however failed to assist agents in\nmanaging the social dilemma that arises in the multi-agent scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.01501v2"
    },
    {
        "title": "Learning Equilibrium with Estimated Payoffs in Population Games",
        "authors": [
            "Shinkyu Park"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We study a multi-agent decision problem in population games, where agents\nselect from multiple available strategies and continually revise their\nselections based on the payoffs associated with these strategies. Unlike\nconventional population game formulations, we consider a scenario where agents\nmust estimate the payoffs through local measurements and communication with\ntheir neighbors. By employing task allocation games -- dynamic extensions of\nconventional population games -- we examine how errors in payoff estimation by\nindividual agents affect the convergence of the strategy revision process. Our\nmain contribution is an analysis of how estimation errors impact the\nconvergence of the agents' strategy profile to equilibrium. Based on the\nanalytical results, we propose a design for a time-varying strategy revision\nrate to guarantee convergence. Simulation studies illustrate how the proposed\nmethod for updating the revision rate facilitates convergence to equilibrium.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.06328v2"
    },
    {
        "title": "GuideLight: \"Industrial Solution\" Guidance for More Practical Traffic\n  Signal Control Agents",
        "authors": [
            "Haoyuan Jiang",
            "Xuantang Xiong",
            "Ziyue Li",
            "Hangyu Mao",
            "Guanghu Sui",
            "Jingqing Ruan",
            "Yuheng Cheng",
            "Hua Wei",
            "Wolfgang Ketter",
            "Rui Zhao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Currently, traffic signal control (TSC) methods based on reinforcement\nlearning (RL) have proven superior to traditional methods. However, most RL\nmethods face difficulties when applied in the real world due to three factors:\ninput, output, and the cycle-flow relation. The industry's observable input is\nmuch more limited than simulation-based RL methods. For real-world solutions,\nonly flow can be reliably collected, whereas common RL methods need more. For\nthe output action, most RL methods focus on acyclic control, which real-world\nsignal controllers do not support. Most importantly, industry standards require\na consistent cycle-flow relationship: non-decreasing and different response\nstrategies for low, medium, and high-level flows, which is ignored by the RL\nmethods. To narrow the gap between RL methods and industry standards, we\ninnovatively propose to use industry solutions to guide the RL agent.\nSpecifically, we design behavior cloning and curriculum learning to guide the\nagent to mimic and meet industry requirements and, at the same time, leverage\nthe power of exploration and exploitation in RL for better performance. We\ntheoretically prove that such guidance can largely decrease the sample\ncomplexity to polynomials in the horizon when searching for an optimal policy.\nOur rigid experiments show that our method has good cycle-flow relation and\nsuperior performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.10811v1"
    },
    {
        "title": "Matching-Driven Deep Reinforcement Learning for Energy-Efficient\n  Transmission Parameter Allocation in Multi-Gateway LoRa Networks",
        "authors": [
            "Ziqi Lin",
            "Xu Zhang",
            "Shimin Gong",
            "Lanhua Li",
            "Zhou Su",
            "Bo Gu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Long-range (LoRa) communication technology, distinguished by its low power\nconsumption and long communication range, is widely used in the Internet of\nThings. Nevertheless, the LoRa MAC layer adopts pure ALOHA for medium access\ncontrol, which may suffer from severe packet collisions as the network scale\nexpands, consequently reducing the system energy efficiency (EE). To address\nthis issue, it is critical to carefully allocate transmission parameters such\nas the channel (CH), transmission power (TP) and spreading factor (SF) to each\nend device (ED). Owing to the low duty cycle and sporadic traffic of LoRa\nnetworks, evaluating the system EE under various parameter settings proves to\nbe time-consuming. Consequently, we propose an analytical model aimed at\ncalculating the system EE while fully considering the impact of multiple\ngateways, duty cycling, quasi-orthogonal SFs and capture effects. On this\nbasis, we investigate a joint CH, SF and TP allocation problem, with the\nobjective of optimizing the system EE for uplink transmissions. Due to the\nNP-hard complexity of the problem, the optimization problem is decomposed into\ntwo subproblems: CH assignment and SF/TP assignment. First, a matching-based\nalgorithm is introduced to address the CH assignment subproblem. Then, an\nattention-based multiagent reinforcement learning technique is employed to\naddress the SF/TP assignment subproblem for EDs allocated to the same CH, which\nreduces the number of learning agents to achieve fast convergence. The\nsimulation outcomes indicate that the proposed approach converges quickly under\nvarious parameter settings and obtains significantly better system EE than\nbaseline algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.13076v1"
    },
    {
        "title": "Self-Emotion Blended Dialogue Generation in Social Simulation Agents",
        "authors": [
            "Qiang Zhang",
            "Jason Naradowsky",
            "Yusuke Miyao"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  When engaging in conversations, dialogue agents in a virtual simulation\nenvironment may exhibit their own emotional states that are unrelated to the\nimmediate conversational context, a phenomenon known as self-emotion. This\nstudy explores how such self-emotion affects the agents' behaviors in dialogue\nstrategies and decision-making within a large language model (LLM)-driven\nsimulation framework. In a dialogue strategy prediction experiment, we analyze\nthe dialogue strategy choices employed by agents both with and without\nself-emotion, comparing them to those of humans. The results show that\nincorporating self-emotion helps agents exhibit more human-like dialogue\nstrategies. In an independent experiment comparing the performance of models\nfine-tuned on GPT-4 generated dialogue datasets, we demonstrate that\nself-emotion can lead to better overall naturalness and humanness. Finally, in\na virtual simulation environment where agents have discussions on multiple\ntopics, we show that self-emotion of agents can significantly influence the\ndecision-making process of the agents, leading to approximately a 50% change in\ndecisions.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01633v1"
    },
    {
        "title": "Value-Based Rationales Improve Social Experience: A Multiagent\n  Simulation Study",
        "authors": [
            "Sz-Ting Tzeng",
            "Nirav Ajmeri",
            "Munindar P. Singh"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We propose Exanna, a framework to realize agents that incorporate values in\ndecision making. An Exannaagent considers the values of itself and others when\nproviding rationales for its actions and evaluating the rationales provided by\nothers. Via multiagent simulation, we demonstrate that considering values in\ndecision making and producing rationales, especially for norm-deviating\nactions, leads to (1) higher conflict resolution, (2) better social experience,\n(3) higher privacy, and (4) higher flexibility.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.02117v2"
    },
    {
        "title": "Combining Diverse Information for Coordinated Action: Stochastic Bandit\n  Algorithms for Heterogeneous Agents",
        "authors": [
            "Lucia Gordon",
            "Esther Rolf",
            "Milind Tambe"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Stochastic multi-agent multi-armed bandits typically assume that the rewards\nfrom each arm follow a fixed distribution, regardless of which agent pulls the\narm. However, in many real-world settings, rewards can depend on the\nsensitivity of each agent to their environment. In medical screening, disease\ndetection rates can vary by test type; in preference matching, rewards can\ndepend on user preferences; and in environmental sensing, observation quality\ncan vary across sensors. Since past work does not specify how to allocate\nagents of heterogeneous but known sensitivity of these types in a stochastic\nbandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates\ninformation from diverse agents. In doing so, we address the joint challenges\nof (i) aggregating the rewards, which follow different distributions for each\nagent-arm pair, and (ii) coordinating the assignments of agents to arms.\nMin-Width facilitates efficient collaboration among heterogeneous agents,\nexploiting the known structure in the agents' reward functions to weight their\nrewards accordingly. We analyze the regret of Min-Width and conduct\npseudo-synthetic and fully synthetic experiments to study the performance of\ndifferent levels of information sharing. Our results confirm that the gains to\nmodeling agent heterogeneity tend to be greater when the sensitivities are more\nvaried across agents, while combining more information does not always improve\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.03405v1"
    },
    {
        "title": "Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal\n  Policy Optimization",
        "authors": [
            "Aditya Kapoor",
            "Benjamin Freed",
            "Howie Choset",
            "Jeff Schneider"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent proximal policy optimization (MAPPO) has recently demonstrated\nstate-of-the-art performance on challenging multi-agent reinforcement learning\ntasks. However, MAPPO still struggles with the credit assignment problem,\nwherein the sheer difficulty in ascribing credit to individual agents' actions\nscales poorly with team size. In this paper, we propose a multi-agent\nreinforcement learning algorithm that adapts recent developments in credit\nassignment to improve upon MAPPO. Our approach leverages partial reward\ndecoupling (PRD), which uses a learned attention mechanism to estimate which of\na particular agent's teammates are relevant to its learning updates. We use\nthis estimate to dynamically decompose large groups of agents into smaller,\nmore manageable subgroups. We empirically demonstrate that our approach,\nPRD-MAPPO, decouples agents from teammates that do not influence their expected\nfuture reward, thereby streamlining credit assignment. We additionally show\nthat PRD-MAPPO yields significantly higher data efficiency and asymptotic\nperformance compared to both MAPPO and other state-of-the-art methods across\nseveral multi-agent tasks, including StarCraft II. Finally, we propose a\nversion of PRD-MAPPO that is applicable to \\textit{shared} reward settings,\nwhere PRD was previously not applicable, and empirically show that this also\nleads to performance improvements over MAPPO.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.04295v2"
    },
    {
        "title": "Performance Prediction of Hub-Based Swarms",
        "authors": [
            "Puneet Jain",
            "Chaitanya Dwivedi",
            "Vigynesh Bhatt",
            "Nick Smith",
            "Michael A Goodrich"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  A hub-based colony consists of multiple agents who share a common nest site\ncalled the hub. Agents perform tasks away from the hub like foraging for food\nor gathering information about future nest sites. Modeling hub-based colonies\nis challenging because the size of the collective state space grows rapidly as\nthe number of agents grows. This paper presents a graph-based representation of\nthe colony that can be combined with graph-based encoders to create\nlow-dimensional representations of collective state that can scale to many\nagents for a best-of-N colony problem. We demonstrate how the information in\nthe low-dimensional embedding can be used with two experiments. First, we show\nhow the information in the tensor can be used to cluster collective states by\nthe probability of choosing the best site for a very small problem. Second, we\nshow how structured collective trajectories emerge when a graph encoder is used\nto learn the low-dimensional embedding, and these trajectories have information\nthat can be used to predict swarm performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.04822v1"
    },
    {
        "title": "Enhancing Heterogeneous Multi-Agent Cooperation in Decentralized MARL\n  via GNN-driven Intrinsic Rewards",
        "authors": [
            "Jahir Sadik Monon",
            "Deeparghya Dutta Barua",
            "Md. Mosaddek Khan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent Reinforcement Learning (MARL) is emerging as a key framework for\nvarious sequential decision-making and control tasks. Unlike their single-agent\ncounterparts, multi-agent systems necessitate successful cooperation among the\nagents. The deployment of these systems in real-world scenarios often requires\ndecentralized training, a diverse set of agents, and learning from infrequent\nenvironmental reward signals. These challenges become more pronounced under\npartial observability and the lack of prior knowledge about agent\nheterogeneity. While notable studies use intrinsic motivation (IM) to address\nreward sparsity or cooperation in decentralized settings, those dealing with\nheterogeneity typically assume centralized training, parameter sharing, and\nagent indexing. To overcome these limitations, we propose the CoHet algorithm,\nwhich utilizes a novel Graph Neural Network (GNN) based intrinsic motivation to\nfacilitate the learning of heterogeneous agent policies in decentralized\nsettings, under the challenges of partial observability and reward sparsity.\nEvaluation of CoHet in the Multi-agent Particle Environment (MPE) and\nVectorized Multi-Agent Simulator (VMAS) benchmarks demonstrates superior\nperformance compared to the state-of-the-art in a range of cooperative\nmulti-agent scenarios. Our research is supplemented by an analysis of the\nimpact of the agent dynamics model on the intrinsic motivation module, insights\ninto the performance of different CoHet variants, and its robustness to an\nincreasing number of heterogeneous agents.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.06503v2"
    },
    {
        "title": "The computational power of a human society: a new model of social\n  evolution",
        "authors": [
            "David H. Wolpert",
            "Kyle Harper"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Social evolutionary theory seeks to explain increases in the scale and\ncomplexity of human societies, from origins to present. Over the course of the\ntwentieth century, social evolutionary theory largely fell out of favor as a\nway of investigating human history, just as advances in complex systems science\nand computer science saw the emergence of powerful new conceptions of complex\nsystems, and in particular new methods of measuring complexity. We propose that\nthese advances in our understanding of complex systems and computer science\nshould be brought to bear on our investigations into human history. To that\nend, we present a new framework for modeling how human societies co-evolve with\ntheir biotic environments, recognizing that both a society and its environment\nare computers. This leads us to model the dynamics of each of those two systems\nusing the same, new kind of computational machine, which we define here. For\nsimplicity, we construe a society as a set of interacting occupations and\ntechnologies. Similarly, under such a model, a biotic environment is a set of\ninteracting distinct ecological and climatic processes. This provides novel\nways to characterize social complexity, which we hope will cast new light on\nthe archaeological and historical records. Our framework also provides a\nnatural way to formalize both the energetic (thermodynamic) costs required by a\nsociety as it runs, and the ways it can extract thermodynamic resources from\nthe environment in order to pay for those costs -- and perhaps to grow with any\nleft-over resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.08861v1"
    },
    {
        "title": "Tax Credits and Household Behavior: The Roles of Myopic Decision-Making\n  and Liquidity in a Simulated Economy",
        "authors": [
            "Kshama Dwarakanath",
            "Jialin Dong",
            "Svitlana Vyetrenko"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  There has been a growing interest in multi-agent simulators in the domain of\neconomic modeling. However, contemporary research often involves developing\nreinforcement learning (RL) based models that focus solely on a single type of\nagents, such as households, firms, or the government. Such an approach\noverlooks the adaptation of interacting agents thereby failing to capture the\ncomplexity of real-world economic systems. In this work, we consider a\nmulti-agent simulator comprised of RL agents of numerous types, including\nheterogeneous households, firm, central bank and government. In particular, we\nfocus on the crucial role of the government in distributing tax credits to\nhouseholds. We conduct two broad categories of comprehensive experiments\ndealing with the impact of tax credits on 1) households with varied degrees of\nmyopia (short-sightedness in spending and saving decisions), and 2) households\nwith diverse liquidity profiles. The first category of experiments examines the\nimpact of the frequency of tax credits (e.g. annual vs quarterly) on\nconsumption patterns of myopic households. The second category of experiments\nfocuses on the impact of varying tax credit distribution strategies on\nhouseholds with differing liquidities. We validate our simulation model by\nreproducing trends observed in real households upon receipt of unforeseen,\nuniform tax credits, as documented in a JPMorgan Chase report. Based on the\nresults of the latter, we propose an innovative tax credit distribution\nstrategy for the government to reduce inequality among households. We\ndemonstrate the efficacy of this strategy in improving social welfare in our\nsimulation results.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.10391v2"
    },
    {
        "title": "Sequential Resource Trading Using Comparison-Based Gradient Estimation",
        "authors": [
            "Surya Murthy",
            "Mustafa O. Karabag",
            "Ufuk Topcu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Autonomous agents interact with other agents of unknown preferences to share\nresources in their environment. We explore sequential trading for resource\nallocation in a setting where two greedily rational agents sequentially trade\nresources from a finite set of categories. Each agent has a utility function\nthat depends on the amount of resources it possesses in each category. The\noffering agent makes trade offers to improve its utility without knowing the\nresponding agent's utility function, and the responding agent only accepts\noffers that improve its utility. We present an algorithm for the offering agent\nto estimate the responding agent's gradient (preferences) and make offers based\non previous acceptance or rejection responses. The algorithm's goal is to reach\na Pareto-optimal resource allocation state while ensuring that the utilities of\nboth agents improve after every accepted trade. We show that, after a finite\nnumber of consecutively rejected offers, the responding agent is at a\nnear-optimal state, or the agents' gradients are closely aligned. We compare\nthe proposed algorithm against various baselines in continuous and discrete\ntrading scenarios and show that it improves the societal benefit with fewer\noffers.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.11186v2"
    },
    {
        "title": "3D Topological Modeling and Multi-Agent Movement Simulation for Viral\n  Infection Risk Analysis",
        "authors": [
            "Wassim Jabi",
            "Yidan Xue",
            "Thomas E. Woolley",
            "Katerina Kaouri"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper, a method to study how the design of indoor spaces and people's\nmovement within them affect disease spread is proposed by integrating\ncomputer-aided modeling, multi-agent movement simulation, and airborne viral\ntransmission modeling. Topologicpy spatial design and analysis software is used\nto model indoor environments, connect spaces, and construct a navigation graph.\nPathways for agents, each with unique characteristics such as walking speed,\ninfection status, and activities, are computed using this graph. Agents follow\na schedule of events with specific locations and times. The software calculates\n\"time-to-leave\" based on walking speed and event start times, and agents are\nmoved along the shortest path within the navigation graph, accurately\nconsidering obstacles, doorways, and walls. Precise distance calculations\nbetween agents are enabled by this setup. Viral aerosol concentration is then\ncomputed and visualized using a reaction-diffusion equation, and each agent's\ninfection risk is determined with an extension of the Wells-Riley ansatz.\nInfection risk simulations are improved by this spatio-temporal and topological\napproach, incorporating realistic human behavior and spatial dynamics. The\nresulting software is designed as a rapid decision-support tool for\npolicymakers, facility managers, stakeholders, architects, and engineers to\nmitigate disease spread in existing buildings and inform the design of new\nones. The software's effectiveness is demonstrated through a comparative\nanalysis of cellular and open commercial office plan layouts.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.16417v1"
    },
    {
        "title": "MAPF-GPT: Imitation Learning for Multi-Agent Pathfinding at Scale",
        "authors": [
            "Anton Andreychuk",
            "Konstantin Yakovlev",
            "Aleksandr Panov",
            "Alexey Skrynnik"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent pathfinding (MAPF) is a challenging computational problem that\ntypically requires to find collision-free paths for multiple agents in a shared\nenvironment. Solving MAPF optimally is NP-hard, yet efficient solutions are\ncritical for numerous applications, including automated warehouses and\ntransportation systems. Recently, learning-based approaches to MAPF have gained\nattention, particularly those leveraging deep reinforcement learning. Following\ncurrent trends in machine learning, we have created a foundation model for the\nMAPF problems called MAPF-GPT. Using imitation learning, we have trained a\npolicy on a set of pre-collected sub-optimal expert trajectories that can\ngenerate actions in conditions of partial observability without additional\nheuristics, reward functions, or communication with other agents. The resulting\nMAPF-GPT model demonstrates zero-shot learning abilities when solving the MAPF\nproblem instances that were not present in the training dataset. We show that\nMAPF-GPT notably outperforms the current best-performing learnable-MAPF solvers\non a diverse range of problem instances and is efficient in terms of\ncomputation (in the inference mode).\n",
        "pdf_link": "http://arxiv.org/pdf/2409.00134v3"
    },
    {
        "title": "Simulation of Social Media-Driven Bubble Formation in Financial Markets\n  using an Agent-Based Model with Hierarchical Influence Network",
        "authors": [
            "Gonzalo Bohorquez",
            "John Cartlidge"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We propose that a tree-like hierarchical structure represents a simple and\neffective way to model the emergent behaviour of financial markets, especially\nmarkets where there exists a pronounced intersection between social media\ninfluences and investor behaviour. To explore this hypothesis, we introduce an\nagent-based model of financial markets, where trading agents are embedded in a\nhierarchical network of communities, and communities influence the strategies\nand opinions of traders. Empirical analysis of the model shows that its\nbehaviour conforms to several stylized facts observed in real financial\nmarkets; and the model is able to realistically simulate the effects that\nsocial media-driven phenomena, such as echo chambers and pump-and-dump schemes,\nhave on financial markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.00742v1"
    },
    {
        "title": "Responsible Blockchain: STEADI Principles and the Actor-Network\n  Theory-based Development Methodology (ANT-RDM)",
        "authors": [
            "Yibai Li",
            "Ahmed Gomaa",
            "Xiaobing Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper provides a comprehensive analysis of the challenges and\ncontroversies associated with blockchain technology. It identifies technical\nchallenges such as scalability, security, privacy, and interoperability, as\nwell as business and adoption challenges, and the social, economic, ethical,\nand environmental controversies present in current blockchain systems. We argue\nthat responsible blockchain development is key to overcoming these challenges\nand achieving mass adoption. This paper defines Responsible Blockchain and\nintroduces the STEADI principles (sustainable, transparent, ethical, adaptive,\ndecentralized, and inclusive) for responsible blockchain development.\nAdditionally, it presents the Actor-Network Theory-based Responsible\nDevelopment Methodology (ANT-RDM) for blockchains, which includes the steps of\nproblematization, interessement, enrollment, and mobilization.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06179v1"
    },
    {
        "title": "Data-Driven Cooperative Output Regulation of Continuous-Time Multi-Agent\n  Systems with Unknown Network Topology",
        "authors": [
            "Peng Ren",
            "Yuqing Hao",
            "Zhiyong Sun",
            "Qingyun Wang",
            "Guanrong Chen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper investigates data-driven cooperative output regulation for\ncontinuous-time multi-agent systems with unknown network topology. Unlike\nexisting studies that typically assume a known network topology to directly\ncompute controller parameters, a novel approach is proposed that allows for the\ncomputation of the parameter without prior knowledge of the topology. A lower\nbound on the minimum non-zero eigenvalue of the Laplacian matrix is estimated\nusing only edge weight bounds, enabling the output regulation controller design\nto be independent of global network information. Additionally, the common need\nfor state derivative measurements is eliminated, reducing the amount of data\nrequirements. Furthermore, necessary and sufficient conditions are established\nto ensure that the data are informative for cooperative output regulation,\nleading to the design of a distributed output regulation controller. For the\ncase with noisy data, the bound of the output error is provided, which is\npositively correlated with the noise bound, and a distributed controller is\nconstructed for the approximate cooperative output regulation. Finally, the\neffectiveness of the proposed methods is verified through numerical\nsimulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.12824v1"
    },
    {
        "title": "A novel load distribution strategy for aggregators using IoT-enabled\n  mobile devices",
        "authors": [
            "Nitin Shivaraman",
            "Jakob Fittler",
            "Saravanan Ramanathan",
            "Arvind Easwaran",
            "Sebastian Steinhorst"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The rapid proliferation of Internet-of-things (IoT) as well as mobile devices\nsuch as Electric Vehicles (EVs), has led to unpredictable load at the grid. The\ndemand to supply ratio is particularly exacerbated at a few grid aggregators\n(charging stations) with excessive demand due to the geographic location, peak\ntime, etc. Existing solutions on demand response cannot achieve significant\nimprovements based only on time-shifting the loads without considering the\ndevice properties such as charging modes and movement capabilities to enable\ngeographic migration. Additionally, the information on the spare capacity at a\nfew aggregators can aid in re-channeling the load from other aggregators facing\nexcess demand to allow migration of devices. In this paper, we model these\nflexible properties of the devices as a mixed-integer non-linear problem\n(MINLP) to minimize excess load and the improve the utility (benefit) across\nall devices. We propose an online distributed low-complexity heuristic that\nprioritizes devices based on demand and deadlines to minimize the cumulative\nloss in utility. The proposed heuristic is tested on an exhaustive set of\nsynthetic data and compared with solutions from a solver/optimization tool for\nthe same runtime to show the impracticality of using a solver. A real-world EV\ntestbed data is also tested with our proposed solution and other scheduling\nsolutions to show the practicality of generating a feasible schedule and a loss\nimprovement of at least 57.23%.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.14293v2"
    },
    {
        "title": "Learning Strategy Representation for Imitation Learning in Multi-Agent\n  Games",
        "authors": [
            "Shiqi Lei",
            "Kanghon Lee",
            "Linjing Li",
            "Jinkyoo Park"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The offline datasets for imitation learning (IL) in multi-agent games\ntypically contain player trajectories exhibiting diverse strategies, which\nnecessitate measures to prevent learning algorithms from acquiring undesirable\nbehaviors. Learning representations for these trajectories is an effective\napproach to depicting the strategies employed by each demonstrator. However,\nexisting learning strategies often require player identification or rely on\nstrong assumptions, which are not appropriate for multi-agent games. Therefore,\nin this paper, we introduce the Strategy Representation for Imitation Learning\n(STRIL) framework, which (1) effectively learns strategy representations in\nmulti-agent games, (2) estimates proposed indicators based on these\nrepresentations, and (3) filters out sub-optimal data using the indicators.\nSTRIL is a plug-in method that can be integrated into existing IL algorithms.\nWe demonstrate the effectiveness of STRIL across competitive multi-agent\nscenarios, including Two-player Pong, Limit Texas Hold'em, and Connect Four.\nOur approach successfully acquires strategy representations and indicators,\nthereby identifying dominant trajectories and significantly enhancing existing\nIL performance across these environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.19363v1"
    },
    {
        "title": "Fuel tax loss in a world of electric mobility: A window of opportunity\n  for congestion pricing",
        "authors": [
            "Thi Ngoc Nguyen",
            "Felix Muesgens"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The continued transition towards electric mobility will decrease energy tax\nrevenues worldwide, which has substantial implications for government funds. At\nthe same time, demand for transportation is ever increasing, which in turn\nincreases congestion problems. Combining both challenges, this paper assesses\nthe effectiveness of congestion pricing as a sustainable revenue stream to\noffset fuel tax loss in 2030 while simultaneously enhancing efficiency in the\ntransport sector. A congestion-based toll that is road-and-time-variant is\nsimulated for the greater Berlin area in Germany using the multi-agent\ntransport simulation (MATSim) software. Through the simulation results, this\npaper quantifies the impacts of the toll on the governmental revenue, traffic\nmanagement, environment, social welfare, and the distribution effects. We find\nthat the revenue from congestion tolls in a metropolitan area can compensate\nthe reduction in passenger car fuel tax. Furthermore, a remarkable welfare\nsurplus is observed. The toll also successfully incentivises transport users to\nadjust their travel behaviour, which reduces traffic delay time by 28%. CO2\nemissions as a key metric for decarbonisation of the transport sector decrease\nby more than 5%. The analysis of the distribution effects suggests that a\nredistribution plan with a focus on the middle-low-income residents and the\nouter boroughs could help the policy gain more public acceptance.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.20033v1"
    },
    {
        "title": "Windowed MAPF with Completeness Guarantees",
        "authors": [
            "Rishi Veerapaneni",
            "Muhammad Suhail Saleem",
            "Jiaoyang Li",
            "Maxim Likhachev"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Traditional multi-agent path finding (MAPF) methods try to compute entire\nstart-goal paths which are collision free. However, computing an entire path\ncan take too long for MAPF systems where agents need to replan fast. Methods\nthat address this typically employ a \"windowed\" approach and only try to find\ncollision free paths for a small windowed timestep horizon. This adaptation\ncomes at the cost of incompleteness; all current windowed approaches can become\nstuck in deadlock or livelock. Our main contribution is to introduce our\nframework, WinC-MAPF, for Windowed MAPF that enables completeness. Our\nframework uses heuristic update insights from single-agent real-time heuristic\nsearch algorithms as well as agent independence ideas from MAPF algorithms. We\nalso develop Single-Step CBS (SS-CBS), an instantiation of this framework using\na novel modification to CBS. We show how SS-CBS, which only plans a single step\nand updates heuristics, can effectively solve tough scenarios where existing\nwindowed approaches fail.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.01798v1"
    },
    {
        "title": "Distributed Detection of Adversarial Attacks for Resilient Cooperation\n  of Multi-Robot Systems with Intermittent Communication",
        "authors": [
            "Rayan Bahrami",
            "Hamidreza Jafarnejadsani"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper concerns the consensus and formation of a network of mobile\nautonomous agents in adversarial settings where a group of malicious\n(compromised) agents are subject to deception attacks. In addition, the\ncommunication network is arbitrarily time-varying and subject to intermittent\nconnections, possibly imposed by denial-of-service (DoS) attacks. We provide\nexplicit bounds for network connectivity in an integral sense, enabling the\ncharacterization of the system's resilience to specific classes of adversarial\nattacks. We also show that under the condition of connectivity in an integral\nsense uniformly in time, the system is finite-gain $\\mathcal{L}_{p}$ stable and\nuniformly exponentially fast consensus and formation are achievable, provided\nmalicious agents are detected and isolated from the network. We present a\ndistributed and reconfigurable framework with theoretical guarantees for\ndetecting malicious agents, allowing for the resilient cooperation of the\nremaining cooperative agents. Simulation studies are provided to illustrate the\ntheoretical findings.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.04547v1"
    },
    {
        "title": "Prompt Infection: LLM-to-LLM Prompt Injection within Multi-Agent Systems",
        "authors": [
            "Donghyun Lee",
            "Mo Tiwari"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  As Large Language Models (LLMs) grow increasingly powerful, multi-agent\nsystems are becoming more prevalent in modern AI applications. Most safety\nresearch, however, has focused on vulnerabilities in single-agent LLMs. These\ninclude prompt injection attacks, where malicious prompts embedded in external\ncontent trick the LLM into executing unintended or harmful actions,\ncompromising the victim's application. In this paper, we reveal a more\ndangerous vector: LLM-to-LLM prompt injection within multi-agent systems. We\nintroduce Prompt Infection, a novel attack where malicious prompts\nself-replicate across interconnected agents, behaving much like a computer\nvirus. This attack poses severe threats, including data theft, scams,\nmisinformation, and system-wide disruption, all while propagating silently\nthrough the system. Our extensive experiments demonstrate that multi-agent\nsystems are highly susceptible, even when agents do not publicly share all\ncommunications. To address this, we propose LLM Tagging, a defense mechanism\nthat, when combined with existing safeguards, significantly mitigates infection\nspread. This work underscores the urgent need for advanced security measures as\nmulti-agent LLM systems become more widely adopted.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.07283v1"
    },
    {
        "title": "A Hate Speech Moderated Chat Application: Use Case for GDPR and DSA\n  Compliance",
        "authors": [
            "Jan Fillies",
            "Theodoros Mitsikas",
            "Ralph Schäfermeier",
            "Adrian Paschke"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The detection of hate speech or toxic content online is a complex and\nsensitive issue. While the identification itself is highly dependent on the\ncontext of the situation, sensitive personal attributes such as age, language,\nand nationality are rarely available due to privacy concerns. Additionally,\nplatforms struggle with a wide range of local jurisdictions regarding online\nhate speech and the evaluation of content based on their internal ethical\nnorms. This research presents a novel approach that demonstrates a\nGDPR-compliant application capable of implementing legal and ethical reasoning\ninto the content moderation process. The application increases the\nexplainability of moderation decisions by utilizing user information. Two use\ncases fundamental to online communication are presented and implemented using\ntechnologies such as GPT-3.5, Solid Pods, and the rule language Prova. The\nfirst use case demonstrates the scenario of a platform aiming to protect\nadolescents from potentially harmful content by limiting the ability to post\ncertain content when minors are present. The second use case aims to identify\nand counter problematic statements online by providing counter hate speech. The\ncounter hate speech is generated using personal attributes to appeal to the\nuser. This research lays the groundwork for future DSA compliance of online\nplatforms. The work proposes a novel approach to reason within different legal\nand ethical definitions of hate speech and plan the fitting counter hate\nspeech. Overall, the platform provides a fitted protection to users and a more\nexplainable and individualized response. The hate speech detection service, the\nchat platform, and the reasoning in Prova are discussed, and the potential\nbenefits for content moderation and algorithmic hate speech detection are\noutlined. A selection of important aspects for DSA compliance is outlined.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.07713v1"
    },
    {
        "title": "Agent-based modeling for realistic reproduction of human mobility and\n  contact behavior to evaluate test and isolation strategies in epidemic\n  infectious disease spread",
        "authors": [
            "David Kerkmann",
            "Sascha Korf",
            "Khoa Nguyen",
            "Daniel Abele",
            "Alain Schengen",
            "Carlotta Gerstein",
            "Jens Henrik Göbbert",
            "Achim Basermann",
            "Martin J. Kühn",
            "Michael Meyer-Hermann"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Agent-based models have proven to be useful tools in supporting\ndecision-making processes in different application domains. The advent of\nmodern computers and supercomputers has enabled these bottom-up approaches to\nrealistically model human mobility and contact behavior. The COVID-19 pandemic\nshowcased the urgent need for detailed and informative models that can answer\nresearch questions on transmission dynamics. We present a sophisticated\nagent-based model to simulate the spread of respiratory diseases. The model is\nhighly modularized and can be used on various scales, from a small collection\nof buildings up to cities or countries. Although not being the focus of this\npaper, the model has undergone performance engineering on a single core and\nprovides an efficient intra- and inter-simulation parallelization for\ntime-critical decision-making processes.\n  In order to allow answering research questions on individual level\nresolution, nonpharmaceutical intervention strategies such as face masks or\nvenue closures can be implemented for particular locations or agents. In\nparticular, we allow for sophisticated testing and isolation strategies to\nstudy the effects of minimal-invasive infectious disease mitigation. With\nrealistic human mobility patterns for the region of Brunswick, Germany, we\nstudy the effects of different interventions between March 1st and May 30, 2021\nin the SARS-CoV-2 pandemic. Our analyses suggest that symptom-independent\ntesting has limited impact on the mitigation of disease dynamics if the dark\nfigure in symptomatic cases is high. Furthermore, we found that quarantine\nlength is more important than quarantine efficiency but that, with sufficient\nsymptomatic control, also short quarantines can have a substantial effect.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.08050v1"
    },
    {
        "title": "The Dynamics of Social Conventions in LLM populations: Spontaneous\n  Emergence, Collective Biases and Tipping Points",
        "authors": [
            "Ariel Flint Ashery",
            "Luca Maria Aiello",
            "Andrea Baronchelli"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Social conventions are the foundation for social and economic life. As\nlegions of AI agents increasingly interact with each other and with humans,\ntheir ability to form shared conventions will determine how effectively they\nwill coordinate behaviors, integrate into society and influence it. Here, we\ninvestigate the dynamics of conventions within populations of Large Language\nModel (LLM) agents using simulated interactions. First, we show that globally\naccepted social conventions can spontaneously arise from local interactions\nbetween communicating LLMs. Second, we demonstrate how strong collective biases\ncan emerge during this process, even when individual agents appear to be\nunbiased. Third, we examine how minority groups of committed LLMs can drive\nsocial change by establishing new social conventions. We show that once these\nminority groups reach a critical size, they can consistently overturn\nestablished behaviors. In all cases, contrasting the experimental results with\npredictions from a minimal multi-agent model allows us to isolate the specific\nrole of LLM agents. Our results clarify how AI systems can autonomously develop\nnorms without explicit programming and have implications for designing AI\nsystems that align with human values and societal goals.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.08948v1"
    },
    {
        "title": "HEnRY: A Multi-Agent System Framework for Multi-Domain Contexts",
        "authors": [
            "Emmanuele Lacavalla",
            "Shuyi Yang",
            "Riccardo Crupi",
            "Joseph E. Gonzalez"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This project, named HEnRY, aims to introduce a Multi-Agent System (MAS) into\nIntesa Sanpaolo. The name HEnRY summarizes the project's core principles: the\nHierarchical organization of agents in a layered structure for efficient\nresource management; Efficient optimization of resources and operations to\nenhance overall performance; Reactive ability of agents to quickly respond to\nenvironmental stimuli; and Yielding adaptability and flexibility of agents to\nhandle unexpected situations. The discussion covers two distinct research\npaths: the first focuses on the system architecture, and the second on the\ncollaboration between agents. This work is not limited to the specific\nstructure of the Intesa Sanpaolo context; instead, it leverages existing\nresearch in MAS to introduce a new solution. Since Intesa Sanpaolo is organized\naccording to a model that aligns with international corporate governance best\npractices, this approach could also be relevant to similar scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.12720v1"
    },
    {
        "title": "Cooperation and Fairness in Multi-Agent Reinforcement Learning",
        "authors": [
            "Jasmine Jerry Aloor",
            "Siddharth Nayak",
            "Sydney Dolan",
            "Hamsa Balakrishnan"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-agent systems are trained to maximize shared cost objectives, which\ntypically reflect system-level efficiency. However, in the resource-constrained\nenvironments of mobility and transportation systems, efficiency may be achieved\nat the expense of fairness -- certain agents may incur significantly greater\ncosts or lower rewards compared to others. Tasks could be distributed\ninequitably, leading to some agents receiving an unfair advantage while others\nincur disproportionately high costs. It is important to consider the tradeoffs\nbetween efficiency and fairness. We consider the problem of fair multi-agent\nnavigation for a group of decentralized agents using multi-agent reinforcement\nlearning (MARL). We consider the reciprocal of the coefficient of variation of\nthe distances traveled by different agents as a measure of fairness and\ninvestigate whether agents can learn to be fair without significantly\nsacrificing efficiency (i.e., increasing the total distance traveled). We find\nthat by training agents using min-max fair distance goal assignments along with\na reward term that incentivizes fairness as they move towards their goals, the\nagents (1) learn a fair assignment of goals and (2) achieve almost perfect goal\ncoverage in navigation scenarios using only local observations. For goal\ncoverage scenarios, we find that, on average, our model yields a 14%\nimprovement in efficiency and a 5% improvement in fairness over a baseline\ntrained using random assignments. Furthermore, an average of 21% improvement in\nfairness can be achieved compared to a model trained on optimally efficient\nassignments; this increase in fairness comes at the expense of only a 7%\ndecrease in efficiency. Finally, we extend our method to environments in which\nagents must complete coverage tasks in prescribed formations and show that it\nis possible to do so without tailoring the models to specific formation shapes.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.14916v1"
    },
    {
        "title": "OPTIMA: Optimized Policy for Intelligent Multi-Agent Systems Enables\n  Coordination-Aware Autonomous Vehicles",
        "authors": [
            "Rui Du",
            "Kai Zhao",
            "Jinlong Hou",
            "Qiang Zhang",
            "Peter Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Coordination among connected and autonomous vehicles (CAVs) is advancing due\nto developments in control and communication technologies. However, much of the\ncurrent work is based on oversimplified and unrealistic task-specific\nassumptions, which may introduce vulnerabilities. This is critical because CAVs\nnot only interact with their environment but are also integral parts of it.\nInsufficient exploration can result in policies that carry latent risks,\nhighlighting the need for methods that explore the environment both extensively\nand efficiently. This work introduces OPTIMA, a novel distributed reinforcement\nlearning framework for cooperative autonomous vehicle tasks. OPTIMA alternates\nbetween thorough data sampling from environmental interactions and multi-agent\nreinforcement learning algorithms to optimize CAV cooperation, emphasizing both\nsafety and efficiency. Our goal is to improve the generality and performance of\nCAVs in highly complex and crowded scenarios. Furthermore, the industrial-scale\ndistributed training system easily adapts to different algorithms, reward\nfunctions, and strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.18112v1"
    },
    {
        "title": "FairStream: Fair Multimedia Streaming Benchmark for Reinforcement\n  Learning Agents",
        "authors": [
            "Jannis Weil",
            "Jonas Ringsdorf",
            "Julian Barthel",
            "Yi-Ping Phoebe Chen",
            "Tobias Meuser"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multimedia streaming accounts for the majority of traffic in today's\ninternet. Mechanisms like adaptive bitrate streaming control the bitrate of a\nstream based on the estimated bandwidth, ideally resulting in smooth playback\nand a good Quality of Experience (QoE). However, selecting the optimal bitrate\nis challenging under volatile network conditions. This motivated researchers to\ntrain Reinforcement Learning (RL) agents for multimedia streaming. The\nconsidered training environments are often simplified, leading to promising\nresults with limited applicability. Additionally, the QoE fairness across\nmultiple streams is seldom considered by recent RL approaches. With this work,\nwe propose a novel multi-agent environment that comprises multiple challenges\nof fair multimedia streaming: partial observability, multiple objectives, agent\nheterogeneity and asynchronicity. We provide and analyze baseline approaches\nacross five different traffic classes to gain detailed insights into the\nbehavior of the considered agents, and show that the commonly used Proximal\nPolicy Optimization (PPO) algorithm is outperformed by a simple greedy\nheuristic. Future work includes the adaptation of multi-agent RL algorithms and\nfurther expansions of the environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.21029v1"
    },
    {
        "title": "Deploying Ten Thousand Robots: Scalable Imitation Learning for Lifelong\n  Multi-Agent Path Finding",
        "authors": [
            "He Jiang",
            "Yutong Wang",
            "Rishi Veerapaneni",
            "Tanishq Duhan",
            "Guillaume Sartoretti",
            "Jiaoyang Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Lifelong Multi-Agent Path Finding (LMAPF) is a variant of MAPF where agents\nare continually assigned new goals, necessitating frequent re-planning to\naccommodate these dynamic changes. Recently, this field has embraced\nlearning-based methods, which reactively generate single-step actions based on\nindividual local observations. However, it is still challenging for them to\nmatch the performance of the best search-based algorithms, especially in\nlarge-scale settings. This work proposes an imitation-learning-based LMAPF\nsolver that introduces a novel communication module and systematic single-step\ncollision resolution and global guidance techniques. Our proposed solver,\nScalable Imitation Learning for LMAPF (SILLM), inherits the fast reasoning\nspeed of learning-based methods and the high solution quality of search-based\nmethods with the help of modern GPUs. Across six large-scale maps with up to\n10,000 agents and varying obstacle structures, SILLM surpasses the best\nlearning- and search-based baselines, achieving average throughput improvements\nof 137.7% and 16.0%, respectively. Furthermore, SILLM also beats the winning\nsolution of the 2023 League of Robot Runners, an international LMAPF\ncompetition sponsored by Amazon Robotics. Finally, we validated SILLM with 10\nreal robots and 100 virtual robots in a mockup warehouse environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.21415v1"
    },
    {
        "title": "EconoJax: A Fast & Scalable Economic Simulation in Jax",
        "authors": [
            "Koen Ponse",
            "Aske Plaat",
            "Niki van Stein",
            "Thomas M. Moerland"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Accurate economic simulations often require many experimental runs,\nparticularly when combined with reinforcement learning. Unfortunately, training\nreinforcement learning agents in multi-agent economic environments can be slow.\nThis paper introduces EconoJax, a fast simulated economy, based on the AI\neconomist. EconoJax, and its training pipeline, are completely written in JAX.\nThis allows EconoJax to scale to large population sizes and perform large\nexperiments, while keeping training times within minutes. Through experiments\nwith populations of 100 agents, we show how real-world economic behavior\nemerges through training within 15 minutes, in contrast to previous work that\nrequired several days. To aid and inspire researchers to build more rich and\ndynamic economic simulations, we open-source EconoJax on Github at:\nhttps://github.com/ponseko/econojax.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.22165v1"
    },
    {
        "title": "Simulate and Optimise: A two-layer mortgage simulator for designing\n  novel mortgage assistance products",
        "authors": [
            "Leo Ardon",
            "Benjamin Patrick Evans",
            "Deepeka Garg",
            "Annapoorani Lakshmi Narayanan",
            "Makada Henry-Nickie",
            "Sumitra Ganesh"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We develop a novel two-layer approach for optimising mortgage relief products\nthrough a simulated multi-agent mortgage environment. While the approach is\ngeneric, here the environment is calibrated to the US mortgage market based on\npublicly available census data and regulatory guidelines. Through the\nsimulation layer, we assess the resilience of households to exogenous income\nshocks, while the optimisation layer explores strategies to improve the\nrobustness of households to these shocks by making novel mortgage assistance\nproducts available to households. Households in the simulation are adaptive,\nlearning to make mortgage-related decisions (such as product enrolment or\nstrategic foreclosures) that maximize their utility, balancing their available\nliquidity and equity. We show how this novel two-layer simulation approach can\nsuccessfully design novel mortgage assistance products to improve household\nresilience to exogenous shocks, and balance the costs of providing such\nproducts through post-hoc analysis. Previously, such analysis could only be\nconducted through expensive pilot studies involving real participants,\ndemonstrating the benefit of the approach for designing and evaluating\nfinancial products.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.00563v1"
    },
    {
        "title": "Incentive-based Platoon Formation: Optimizing the Personal Benefit for\n  Drivers",
        "authors": [
            "Julian Heinovski",
            "Doğanalp Ergenç",
            "Kirsten Thommes",
            "Falko Dressler"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Platooning or cooperative adaptive cruise control (CACC) has been\ninvestigated for decades, but debate about its lasting impact is still ongoing.\nEven though platooning benefits and platoon formation are rather well\nunderstood for trucks, this is less clear for passenger cars, which have a\nhigher heterogeneity in trips and drivers' preferences. Most importantly, it\nremains unclear how to form platoons of passenger cars in order to optimize the\npersonal benefit for the individual driver. To this end, in this paper, we\npropose a novel platoon formation algorithm that optimizes the personal benefit\nfor drivers of individual passenger cars. For computing vehicle-to-platoon\nassignments, the algorithm utilizes a new metric that we propose to evaluate\nthe personal benefits of various driving systems, including platooning. By\ncombining fuel and travel time costs into a single monetary value, drivers can\nestimate overall trip costs according to a personal monetary value for time\nspent. This provides an intuitive way for drivers to understand and compare the\nbenefits of driving systems like human driving, adaptive cruise control (ACC),\nand, of course, platooning. Unlike previous similarity-based methods, our\nproposed algorithm forms platoons only when beneficial for the driver, rather\nthan for the sake of platooning only. Results of a large-scale simulation study\ndemonstrate that our proposed algorithm outperforms normal ACC as well as\nprevious similarity-based platooning approaches by balancing fuel savings and\ntravel time, independent of traffic and drivers' time cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.00570v1"
    },
    {
        "title": "Multi-Agent Deep Q-Network with Layer-based Communication Channel for\n  Autonomous Internal Logistics Vehicle Scheduling in Smart Manufacturing",
        "authors": [
            "Mohammad Feizabadi",
            "Arman Hosseini",
            "Zakaria Yahouni"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In smart manufacturing, scheduling autonomous internal logistic vehicles is\ncrucial for optimizing operational efficiency. This paper proposes a\nmulti-agent deep Q-network (MADQN) with a layer-based communication channel\n(LBCC) to address this challenge. The main goals are to minimize total job\ntardiness, reduce the number of tardy jobs, and lower vehicle energy\nconsumption. The method is evaluated against nine well-known scheduling\nheuristics, demonstrating its effectiveness in handling dynamic job shop\nbehaviors like job arrivals and workstation unavailabilities. The approach also\nproves scalable, maintaining performance across different layouts and larger\nproblem instances, highlighting the robustness and adaptability of MADQN with\nLBCC in smart manufacturing.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.00728v1"
    },
    {
        "title": "Role Play: Learning Adaptive Role-Specific Strategies in Multi-Agent\n  Interactions",
        "authors": [
            "Weifan Long",
            "Wen Wen",
            "Peng Zhai",
            "Lihua Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Zero-shot coordination problem in multi-agent reinforcement learning (MARL),\nwhich requires agents to adapt to unseen agents, has attracted increasing\nattention. Traditional approaches often rely on the Self-Play (SP) framework to\ngenerate a diverse set of policies in a policy pool, which serves to improve\nthe generalization capability of the final agent. However, these frameworks may\nstruggle to capture the full spectrum of potential strategies, especially in\nreal-world scenarios that demand agents balance cooperation with competition.\nIn such settings, agents need strategies that can adapt to varying and often\nconflicting goals. Drawing inspiration from Social Value Orientation\n(SVO)-where individuals maintain stable value orientations during interactions\nwith others-we propose a novel framework called \\emph{Role Play} (RP). RP\nemploys role embeddings to transform the challenge of policy diversity into a\nmore manageable diversity of roles. It trains a common policy with role\nembedding observations and employs a role predictor to estimate the joint role\nembeddings of other agents, helping the learning agent adapt to its assigned\nrole. We theoretically prove that an approximate optimal policy can be achieved\nby optimizing the expected cumulative reward relative to an approximate\nrole-based policy. Experimental results in both cooperative (Overcooked) and\nmixed-motive games (Harvest, CleanUp) reveal that RP consistently outperforms\nstrong baselines when interacting with unseen agents, highlighting its\nrobustness and adaptability in complex environments.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.01166v1"
    },
    {
        "title": "Learning to Construct Implicit Communication Channel",
        "authors": [
            "Han Wang",
            "Binbin Chen",
            "Tieying Zhang",
            "Baoxiang Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Effective communication is an essential component in collaborative\nmulti-agent systems. Situations where explicit messaging is not feasible have\nbeen common in human society throughout history, which motivate the study of\nimplicit communication. Previous works on learning implicit communication\nmostly rely on theory of mind (ToM), where agents infer the mental states and\nintentions of others by interpreting their actions. However, ToM-based methods\nbecome less effective in making accurate inferences in complex tasks. In this\nwork, we propose the Implicit Channel Protocol (ICP) framework, which allows\nagents to construct implicit communication channels similar to the explicit\nones. ICP leverages a subset of actions, denoted as the scouting actions, and a\nmapping between information and these scouting actions that encodes and decodes\nthe messages. We propose training algorithms for agents to message and act,\nincluding learning with a randomly initialized information map and with a\ndelayed information map. The efficacy of ICP has been tested on the tasks of\nGuessing Number, Revealing Goals, and Hanabi, where ICP significantly\noutperforms baseline methods through more efficient information transmission.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.01553v1"
    },
    {
        "title": "DroidSpeak: KV Cache Sharing for Cross-LLM Communication and Multi-LLM\n  Serving",
        "authors": [
            "Yuhan Liu",
            "Yuyang Huang",
            "Jiayi Yao",
            "Zhuohan Gu",
            "Kuntai Du",
            "Hanchen Li",
            "Yihua Cheng",
            "Junchen Jiang",
            "Shan Lu",
            "Madan Musuvathi",
            "Esha Choukse"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large Language Models (LLMs) are increasingly employed in complex workflows,\nwhere different LLMs and fine-tuned variants collaboratively address complex\ntasks. However, these systems face significant inefficiencies due to redundant\ncontext processing of the shared context. We propose DroidSpeak, a framework\nthat optimizes context sharing between fine-tuned LLMs derived from the same\nfoundational model. DroidSpeak identifies critical layers in the KV cache and\nselectively recomputes them, enabling effective reuse of intermediate data\nwhile maintaining high accuracy.\n  Our approach balances computational efficiency and task fidelity,\nsignificantly reducing inference latency and throughput bottlenecks.\nExperiments on diverse datasets and model pairs demonstrate that DroidSpeak\nachieves up to 3x higher throughputs and 2.6x faster prefill times with\nnegligible accuracy loss compared to full recomputation.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.02820v3"
    },
    {
        "title": "Autonomous Industrial Control using an Agentic Framework with Large\n  Language Models",
        "authors": [
            "Javal Vyas",
            "Mehmet Mercangöz"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  As chemical plants evolve towards full autonomy, the need for effective fault\nhandling and control in dynamic, unpredictable environments becomes\nincreasingly critical. This paper proposes an innovative approach to industrial\nautomation, introducing validation and reprompting architectures utilizing\nlarge language model (LLM)-based autonomous control agents. The proposed\nagentic system, comprising of operator, validator, and reprompter agents,\nenables autonomous management of control tasks, adapting to unforeseen\ndisturbances without human intervention. By utilizing validation and\nreprompting architectures, the framework allows agents to recover from errors\nand continuously improve decision-making in real-time industrial scenarios. We\nhypothesize that this mechanism will enhance performance and reliability across\na variety of LLMs, offering a path toward fully autonomous systems capable of\nhandling unexpected challenges, paving the way for robust, adaptive control in\ncomplex industrial environments. To demonstrate the concept's effectiveness, we\ncreated a simple case study involving a temperature control experiment embedded\non a microcontroller device, validating the proposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05904v1"
    },
    {
        "title": "Merit-Based Sortition in Decentralized Systems",
        "authors": [
            "J. M. Diederik Kruijssen",
            "Renata Valieva",
            "Kenneth Peluso",
            "Nicholas Emmons",
            "Steven N. Longmore"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In decentralized systems, it is often necessary to select an 'active' subset\nof participants from the total participant pool, with the goal of satisfying\ncomputational limitations or optimizing resource efficiency. This selection can\nsometimes be made at random, mirroring the sortition practice invented in\nclassical antiquity aimed at achieving a high degree of statistical\nrepresentativeness. However, the recent emergence of specialized decentralized\nnetworks that solve concrete coordination problems and are characterized by\nmeasurable success metrics often requires prioritizing performance optimization\nover representativeness. We introduce a simple algorithm for 'merit-based\nsortition', in which the quality of each participant influences its probability\nof being drafted into the active set, while simultaneously retaining\nrepresentativeness by allowing inactive participants an infinite number of\nchances to be drafted into the active set with non-zero probability. Using a\nsuite of numerical experiments, we demonstrate that our algorithm boosts the\nquality metric describing the performance of the active set by $>2$ times the\nintrinsic stochasticity. This implies that merit-based sortition ensures a\nstatistically significant performance boost to the drafted, 'active' set, while\nretaining the property of classical, random sortition that it enables upward\nmobility from a much larger 'inactive' set. This way, merit-based sortition\nfulfils a key requirement for decentralized systems in need of performance\noptimization.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.07302v1"
    },
    {
        "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating\n  Machine Learning Tasks",
        "authors": [
            "Shubham Gandhi",
            "Manasi Patwardhan",
            "Lovekesh Vig",
            "Gautam Shroff"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Large Language Models (LLMs) excel in diverse applications including\ngeneration of code snippets, but often struggle with generating code for\ncomplex Machine Learning (ML) tasks. Although existing LLM single-agent based\nsystems give varying performance depending on the task complexity, they purely\nrely on larger and expensive models such as GPT-4. Our investigation reveals\nthat no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama\nperform far worse than GPT-4 in a single-agent setting. With the motivation of\ndeveloping a cost-efficient LLM based solution for solving ML tasks, we propose\nan LLM Multi-Agent based system which leverages combination of experts using\nprofiling, efficient retrieval of past observations, LLM cascades, and\nask-the-expert calls. Through empirical analysis on ML engineering tasks in the\nMLAgentBench benchmark, we demonstrate the effectiveness of our system, using\nno-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and\nexpert to serve occasional ask-the-expert calls for planning. With 94.2\\%\nreduction in the cost (from \\$0.931 per run cost averaged over all tasks for\nGPT-4 single agent system to \\$0.054), our system is able to yield better\naverage success rate of 32.95\\% as compared to GPT-4 single-agent system\nyielding 22.72\\% success rate averaged over all the tasks of MLAgentBench.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.07464v2"
    },
    {
        "title": "Reaching Resilient Leader-Follower Consensus in Time-Varying Networks\n  via Multi-Hop Relays",
        "authors": [
            "Liwei Yuan",
            "Hideaki Ishii"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We study resilient leader-follower consensus of multi-agent systems (MASs) in\nthe presence of adversarial agents, where agents' communication is modeled by\ntime-varying topologies. The objective is to develop distributed algorithms for\nthe nonfaulty/normal followers to track an arbitrary reference value propagated\nby a set of leaders while they are in interaction with the unknown adversarial\nagents. Our approaches are based on the weighted mean subsequence reduced\n(W-MSR) algorithms with agents being capable to communicate with multi-hop\nneighbors. Our algorithms can handle agents possessing first-order and\nsecond-order dynamics. Moreover, we characterize necessary and sufficient graph\nconditions for our algorithms to succeed by the novel notion of jointly robust\nfollowing graphs. Our graph condition is tighter than the sufficient conditions\nin the literature when agents use only one-hop communication (without relays).\nUsing multi-hop relays, we can enhance robustness of leader-follower networks\nwithout increasing communication links and obtain further relaxed graph\nrequirements for our algorithms to succeed. Numerical examples are given to\nverify the efficacy of our algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.09954v1"
    },
    {
        "title": "Learning Two-agent Motion Planning Strategies from Generalized Nash\n  Equilibrium for Model Predictive Control",
        "authors": [
            "Hansung Kim",
            "Edward L. Zhu",
            "Chang Seok Lim",
            "Francesco Borrelli"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We introduce an Implicit Game-Theoretic MPC (IGT-MPC), a decentralized\nalgorithm for two-agent motion planning that uses a learned value function that\npredicts the game-theoretic interaction outcomes as the terminal cost-to-go\nfunction in a model predictive control (MPC) framework, guiding agents to\nimplicitly account for interactions with other agents and maximize their\nreward. This approach applies to competitive and cooperative multi-agent motion\nplanning problems which we formulate as constrained dynamic games. Given a\nconstrained dynamic game, we randomly sample initial conditions and solve for\nthe generalized Nash equilibrium (GNE) to generate a dataset of GNE solutions,\ncomputing the reward outcome of each game-theoretic interaction from the GNE.\nThe data is used to train a simple neural network to predict the reward\noutcome, which we use as the terminal cost-to-go function in an MPC scheme. We\nshowcase emerging competitive and coordinated behaviors using IGT-MPC in\nscenarios such as two-vehicle head-to-head racing and un-signalized\nintersection navigation. IGT-MPC offers a novel method integrating machine\nlearning and game-theoretic reasoning into model-based decentralized\nmulti-agent motion planning.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.13983v2"
    },
    {
        "title": "Synthesising Robust Controllers for Robot Collectives with Recurrent\n  Tasks: A Case Study",
        "authors": [
            "Till Schnittka",
            "Mario Gleirscher"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  When designing correct-by-construction controllers for autonomous\ncollectives, three key challenges are the task specification, the modelling,\nand its use at practical scale. In this paper, we focus on a simple yet useful\nabstraction for high-level controller synthesis for robot collectives with\noptimisation goals (e.g., maximum cleanliness, minimum energy consumption) and\nrecurrence (e.g., re-establish contamination and charge thresholds) and safety\n(e.g., avoid full discharge, mutually exclusive room occupation) constraints.\nDue to technical limitations (related to scalability and using constraints in\nthe synthesis), we simplify our graph-based setting from a stochastic\ntwo-player game into a single-player game on a partially observable Markov\ndecision process (POMDP). Robustness against environmental uncertainty is\nencoded via partial observability. Linear-time correctness properties are\nverified separately after synthesising the POMDP strategy. We contribute\nat-scale guidance on POMDP modelling and controller synthesis for tasked robot\ncollectives exemplified by the scenario of battery-driven robots responsible\nfor cleaning public buildings with utilisation constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.14371v1"
    },
    {
        "title": "Two Heads Are Better Than One: Collaborative LLM Embodied Agents for\n  Human-Robot Interaction",
        "authors": [
            "Mitchell Rosser",
            "Marc. G Carmichael"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  With the recent development of natural language generation models - termed as\nlarge language models (LLMs) - a potential use case has opened up to improve\nthe way that humans interact with robot assistants. These LLMs should be able\nto leverage their large breadth of understanding to interpret natural language\ncommands into effective, task appropriate and safe robot task executions.\nHowever, in reality, these models suffer from hallucinations, which may cause\nsafety issues or deviations from the task. In other domains, these issues have\nbeen improved through the use of collaborative AI systems where multiple LLM\nagents can work together to collectively plan, code and self-check outputs. In\nthis research, multiple collaborative AI systems were tested against a single\nindependent AI agent to determine whether the success in other domains would\ntranslate into improved human-robot interaction performance. The results show\nthat there is no defined trend between the number of agents and the success of\nthe model. However, it is clear that some collaborative AI agent architectures\ncan exhibit a greatly improved capacity to produce error-free code and to solve\nabstract problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.16723v1"
    },
    {
        "title": "Opinion Dynamic Under Malicious Agent Influence in Multi-Agent Systems:\n  From the Perspective of Opinion Evolution Cost",
        "authors": [
            "Yuhan Suo",
            "Runqi Chai",
            "Senchun Chai",
            "Ishrak MD Farhan",
            "Xudong Zhao",
            "Yuanqing Xia"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In human social systems, debates are often seen as a means to resolve\ndifferences of opinion. However, in reality, debates frequently incur\nsignificant communication costs, especially when dealing with stubborn\nopponents. Inspired by this phenomenon, this paper examines the impact of\nmalicious agents on the evolution of normal agents' opinions from the\nperspective of opinion evolution cost, and proposes corresponding solutions for\nthe scenario in which malicious agents hold different opinions in multi-agent\nsystems(MASs). First, this paper analyzes the negative impact of malicious\nagents on the opinion evolution process, reveals the additional evolution cost\nit brings, and provides a theoretical basis for the subsequent solutions.\nSecondly, based on the characteristics of opinion evolution, the malicious\nagent isolation algorithm based on opinion evolution direction vector is\nproposed, which does not strongly restrict the proportion of malicious agents.\nAdditionally, an evolution rate adjustment mechanism is introduced, allowing\nthe system to flexibly regulate the evolution process in complex situations,\neffectively achieving the trade-off between opinion evolution rate and cost.\nExtensive numerical simulations demonstrate that the algorithm can effectively\neliminate the negative influence of malicious agents and achieve a balance\nbetween opinion evolution costs and convergence speed.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.01524v2"
    },
    {
        "title": "Interaction Identification of a Heterogeneous NDS with\n  Quadratic-Bilinear Subsystems",
        "authors": [
            "Tong Zhou"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper attacks time-domain identification for the interaction parameters\nof a heterogeneous networked dynamic system (NDS), with each of its subsystems\nbeing described by a continuous-time descriptor quadratic-bilinear\ntime-invariant (QBTI) model. No restrictions are put on the sampling rate.\nExplicit formulas are derived respectively for the transient and steady-state\nresponses of the NDS, provided that the probing signal is generated by a linear\ntime invariant (LTI) system. Some relations have been derived between the NDS\nsteady-state response and its frequency domain input-output mappings. These\nrelations reveal that the value of some NDS associated TFMs can in principle be\nestimated at almost any interested point of the imaginary axis from\ninput-output experimental data, as well as its derivatives and a right\ntangential interpolation along an arbitrary direction. Based on these\nrelations, an estimation algorithm is suggested respectively for the parameters\nof the NDS and the values of these TFMs.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.02547v1"
    },
    {
        "title": "Transient Multi-Agent Path Finding for Lifelong Navigation in Dense\n  Environments",
        "authors": [
            "Jonathan Morag",
            "Noy Gabay",
            "Daniel koyfman",
            "Roni Stern"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Path Finding (MAPF) deals with finding conflict-free paths for a\nset of agents from an initial configuration to a given target configuration.\nThe Lifelong MAPF (LMAPF) problem is a well-studied online version of MAPF in\nwhich an agent receives a new target when it reaches its current target. The\ncommon approach for solving LMAPF is to treat it as a sequence of MAPF\nproblems, periodically replanning from the agents' current configurations to\ntheir current targets. A significant drawback in this approach is that in MAPF\nthe agents must reach a configuration in which all agents are at their targets\nsimultaneously, which is needlessly restrictive for LMAPF. Techniques have been\nproposed to indirectly mitigate this drawback. We describe cases where these\nmitigation techniques fail. As an alternative, we propose to solve LMAPF\nproblems by solving a sequence of modified MAPF problems, in which the\nobjective is for each agent to eventually visit its target, but not necessarily\nfor all agents to do so simultaneously. We refer to this MAPF variant as\nTransient MAPF (TMAPF) and propose several algorithms for solving it based on\nexisting MAPF algorithms. A limited experimental evaluation identifies some\ncases where using a TMAPF algorithm instead of a MAPF algorithm with an LMAPF\nframework can improve the system throughput significantly.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.04256v1"
    },
    {
        "title": "Augmenting the action space with conventions to improve multi-agent\n  cooperation in Hanabi",
        "authors": [
            "F. Bredell",
            "H. A. Engelbrecht",
            "J. C. Schoeman"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The card game Hanabi is considered a strong medium for the testing and\ndevelopment of multi-agent reinforcement learning (MARL) algorithms, due to its\ncooperative nature, hidden information, limited communication and remarkable\ncomplexity. Previous research efforts have explored the capabilities of MARL\nalgorithms within Hanabi, focusing largely on advanced architecture design and\nalgorithmic manipulations to achieve state-of-the-art performance for a various\nnumber of cooperators. However, this often leads to complex solution strategies\nwith high computational cost and requiring large amounts of training data. For\nhumans to solve the Hanabi game effectively, they require the use of\nconventions, which often allows for a means to implicitly convey ideas or\nknowledge based on a predefined, and mutually agreed upon, set of ``rules''.\nMulti-agent problems containing partial observability, especially when limited\ncommunication is present, can benefit greatly from the use of implicit\nknowledge sharing. In this paper, we propose a novel approach to augmenting the\naction space using conventions, which act as special cooperative actions that\nspan over multiple time steps and multiple agents, requiring agents to actively\nopt in for it to reach fruition. These conventions are based on existing human\nconventions, and result in a significant improvement on the performance of\nexisting techniques for self-play and cross-play across a various number of\ncooperators within Hanabi.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.06333v1"
    },
    {
        "title": "Investigating social alignment via mirroring in a system of interacting\n  language models",
        "authors": [
            "Harvey McGuinness",
            "Tianyu Wang",
            "Carey E. Priebe",
            "Hayden Helm"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Alignment is a social phenomenon wherein individuals share a common goal or\nperspective. Mirroring, or mimicking the behaviors and opinions of another\nindividual, is one mechanism by which individuals can become aligned. Large\nscale investigations of the effect of mirroring on alignment have been limited\ndue to the scalability of traditional experimental designs in sociology. In\nthis paper, we introduce a simple computational framework that enables studying\nthe effect of mirroring behavior on alignment in multi-agent systems. We\nsimulate systems of interacting large language models in this framework and\ncharacterize overall system behavior and alignment with quantitative measures\nof agent dynamics. We find that system behavior is strongly influenced by the\nrange of communication of each agent and that these effects are exacerbated by\nincreased rates of mirroring. We discuss the observed simulated system behavior\nin the context of known human social dynamics.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.06834v1"
    },
    {
        "title": "From Intention To Implementation: Automating Biomedical Research via\n  LLMs",
        "authors": [
            "Yi Luo",
            "Linghang Shi",
            "Yihao Li",
            "Aobo Zhuang",
            "Yeyun Gong",
            "Ling Liu",
            "Chen Lin"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Conventional biomedical research is increasingly labor-intensive due to the\nexponential growth of scientific literature and datasets. Artificial\nintelligence (AI), particularly Large Language Models (LLMs), has the potential\nto revolutionize this process by automating various steps. Still, significant\nchallenges remain, including the need for multidisciplinary expertise,\nlogicality of experimental design, and performance measurements. This paper\nintroduces BioResearcher, the first end-to-end automated system designed to\nstreamline the entire biomedical research process involving dry lab\nexperiments. BioResearcher employs a modular multi-agent architecture,\nintegrating specialized agents for search, literature processing, experimental\ndesign, and programming. By decomposing complex tasks into logically related\nsub-tasks and utilizing a hierarchical learning approach, BioResearcher\neffectively addresses the challenges of multidisciplinary requirements and\nlogical complexity. Furthermore, BioResearcher incorporates an LLM-based\nreviewer for in-process quality control and introduces novel evaluation metrics\nto assess the quality and automation of experimental protocols. BioResearcher\nsuccessfully achieves an average execution success rate of 63.07% across eight\npreviously unmet research objectives. The generated protocols averagely\noutperform typical agent systems by 22.0% on five quality metrics. The system\ndemonstrates significant potential to reduce researchers' workloads and\naccelerate biomedical discoveries, paving the way for future innovations in\nautomated research systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.09429v2"
    },
    {
        "title": "Cluster-Based Multi-Agent Task Scheduling for Space-Air-Ground\n  Integrated Networks",
        "authors": [
            "Zhiying Wang",
            "Gang Sun",
            "Yuhui Wang",
            "Hongfang Yu",
            "Dusit Niyato"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The Space-Air-Ground Integrated Network (SAGIN) framework is a crucial\nfoundation for future networks, where satellites and aerial nodes assist in\ncomputational task offloading. The low-altitude economy, leveraging the\nflexibility and multifunctionality of Unmanned Aerial Vehicles (UAVs) in SAGIN,\nholds significant potential for development in areas such as communication and\nsensing. However, effective coordination is needed to streamline information\nexchange and enable efficient system resource allocation. In this paper, we\npropose a Clustering-based Multi-agent Deep Deterministic Policy Gradient\n(CMADDPG) algorithm to address the multi-UAV cooperative task scheduling\nchallenges in SAGIN. The CMADDPG algorithm leverages dynamic UAV clustering to\npartition UAVs into clusters, each managed by a Cluster Head (CH) UAV,\nfacilitating a distributed-centralized control approach. Within each cluster,\nUAVs delegate offloading decisions to the CH UAV, reducing intra-cluster\ncommunication costs and decision conflicts, thereby enhancing task scheduling\nefficiency. Additionally, by employing a multi-agent reinforcement learning\nframework, the algorithm leverages the extensive coverage of satellites to\nachieve centralized training and distributed execution of multi-agent tasks,\nwhile maximizing overall system profit through optimized task offloading\ndecision-making. Simulation results reveal that the CMADDPG algorithm\neffectively optimizes resource allocation, minimizes queue delays, maintains\nbalanced load distribution, and surpasses existing methods by achieving at\nleast a 25\\% improvement in system profit, showcasing its robustness and\nadaptability across diverse scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.10700v1"
    },
    {
        "title": "Empathic Coupling of Homeostatic States for Intrinsic Prosociality",
        "authors": [
            "Naoto Yoshida",
            "Kingson Man"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  When regarding the suffering of others, we often experience personal distress\nand feel compelled to help. Inspired by living systems, we investigate the\nemergence of prosocial behavior among autonomous agents that are motivated by\nhomeostatic self-regulation. We perform multi-agent reinforcement learning,\ntreating each agent as a vulnerable homeostat charged with maintaining its own\nwell-being. We introduce an empathy-like mechanism to share homeostatic states\nbetween agents: an agent can either \\emph{observe} their partner's internal\nstate (cognitive empathy) or the agent's internal state can be \\emph{directly\ncoupled} to that of their partner's (affective empathy). In three simple\nmulti-agent environments, we show that prosocial behavior arises only under\nhomeostatic coupling - when the distress of a partner can affect one's own\nwell-being. Our findings specify the type and role of empathy in artificial\nagents capable of prosocial behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12103v1"
    },
    {
        "title": "Achieving Collective Welfare in Multi-Agent Reinforcement Learning via\n  Suggestion Sharing",
        "authors": [
            "Yue Jin",
            "Shuangqing Wei",
            "Giovanni Montana"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In human society, the conflict between self-interest and collective\nwell-being often obstructs efforts to achieve shared welfare. Related concepts\nlike the Tragedy of the Commons and Social Dilemmas frequently manifest in our\ndaily lives. As artificial agents increasingly serve as autonomous proxies for\nhumans, we propose using multi-agent reinforcement learning (MARL) to address\nthis issue - learning policies to maximise collective returns even when\nindividual agents' interests conflict with the collective one. Traditional MARL\nsolutions involve sharing rewards, values, and policies or designing intrinsic\nrewards to encourage agents to learn collectively optimal policies. We\nintroduce a novel MARL approach based on Suggestion Sharing (SS), where agents\nexchange only action suggestions. This method enables effective cooperation\nwithout the need to design intrinsic rewards, achieving strong performance\nwhile revealing less private information compared to sharing rewards, values,\nor policies. Our theoretical analysis establishes a bound on the discrepancy\nbetween collective and individual objectives, demonstrating how sharing\nsuggestions can align agents' behaviours with the collective objective.\nExperimental results demonstrate that SS performs competitively with baselines\nthat rely on value or policy sharing or intrinsic rewards.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12326v1"
    },
    {
        "title": "Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents",
        "authors": [
            "Jessica Woodgate",
            "Paul Marshall",
            "Nirav Ajmeri"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Social norms are standards of behaviour common in a society. However, when\nagents make decisions without considering how others are impacted, norms can\nemerge that lead to the subjugation of certain agents. We present RAWL-E, a\nmethod to create ethical norm-learning agents. RAWL-E agents operationalise\nmaximin, a fairness principle from Rawlsian ethics, in their decision-making\nprocesses to promote ethical norms by balancing societal well-being with\nindividual goals. We evaluate RAWL-E agents in simulated harvesting scenarios.\nWe find that norms emerging in RAWL-E agent societies enhance social welfare,\nfairness, and robustness, and yield higher minimum experience compared to those\nthat emerge in agent societies that do not implement Rawlsian ethics.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15163v1"
    },
    {
        "title": "Tacit Learning with Adaptive Information Selection for Cooperative\n  Multi-Agent Reinforcement Learning",
        "authors": [
            "Lunjun Liu",
            "Weilai Jiang",
            "Yaonan Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In multi-agent reinforcement learning (MARL), the centralized training with\ndecentralized execution (CTDE) framework has gained widespread adoption due to\nits strong performance. However, the further development of CTDE faces two key\nchallenges. First, agents struggle to autonomously assess the relevance of\ninput information for cooperative tasks, impairing their decision-making\nabilities. Second, in communication-limited scenarios with partial\nobservability, agents are unable to access global information, restricting\ntheir ability to collaborate effectively from a global perspective. To address\nthese challenges, we introduce a novel cooperative MARL framework based on\ninformation selection and tacit learning. In this framework, agents gradually\ndevelop implicit coordination during training, enabling them to infer the\ncooperative behavior of others in a discrete space without communication,\nrelying solely on local information. Moreover, we integrate gating and\nselection mechanisms, allowing agents to adaptively filter information based on\nenvironmental changes, thereby enhancing their decision-making capabilities.\nExperiments on popular MARL benchmarks show that our framework can be\nseamlessly integrated with state-of-the-art algorithms, leading to significant\nperformance improvements.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15639v2"
    },
    {
        "title": "MacLight: Multi-scene Aggregation Convolutional Learning for Traffic\n  Signal Control",
        "authors": [
            "Sunbowen Lee",
            "Hongqin Lyu",
            "Yicheng Gong",
            "Yingying Sun",
            "Chao Deng"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Reinforcement learning methods have proposed promising traffic signal control\npolicy that can be trained on large road networks. Current SOTA methods model\nroad networks as topological graph structures, incorporate graph attention into\ndeep Q-learning, and merge local and global embeddings to improve policy.\nHowever, graph-based methods are difficult to parallelize, resulting in huge\ntime overhead. Moreover, none of the current peer studies have deployed dynamic\ntraffic systems for experiments, which is far from the actual situation.\n  In this context, we propose Multi-Scene Aggregation Convolutional Learning\nfor traffic signal control (MacLight), which offers faster training speeds and\nmore stable performance. Our approach consists of two main components. The\nfirst is the global representation, where we utilize variational autoencoders\nto compactly compress and extract the global representation. The second\ncomponent employs the proximal policy optimization algorithm as the backbone,\nallowing value evaluation to consider both local features and global embedding\nrepresentations. This backbone model significantly reduces time overhead and\nensures stability in policy updates. We validated our method across multiple\ntraffic scenarios under both static and dynamic traffic systems. Experimental\nresults demonstrate that, compared to general and domian SOTA methods, our\napproach achieves superior stability, optimized convergence levels and the\nhighest time efficiency. The code is under\nhttps://github.com/Aegis1863/MacLight.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15703v3"
    },
    {
        "title": "Speedup Techniques for Switchable Temporal Plan Graph Optimization",
        "authors": [
            "He Jiang",
            "Muhan Lin",
            "Jiaoyang Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Path Finding (MAPF) focuses on planning collision-free paths for\nmultiple agents. However, during the execution of a MAPF plan, agents may\nencounter unexpected delays, which can lead to inefficiencies, deadlocks, or\neven collisions. To address these issues, the Switchable Temporal Plan Graph\nprovides a framework for finding an acyclic Temporal Plan Graph with the\nminimum execution cost under delays, ensuring deadlock- and collision-free\nexecution. Unfortunately, existing optimal algorithms, such as Mixed Integer\nLinear Programming and Graph-Based Switchable Edge Search (GSES), are often too\nslow for practical use. This paper introduces Improved GSES, which\nsignificantly accelerates GSES through four speedup techniques: stronger\nadmissible heuristics, edge grouping, prioritized branching, and incremental\nimplementation. Experiments conducted on four different map types with varying\nnumbers of agents demonstrate that Improved GSES consistently achieves over\ntwice the success rate of GSES and delivers up to a 30-fold speedup on\ninstances where both methods successfully find solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.15908v2"
    },
    {
        "title": "Self-guided Knowledgeable Network of Thoughts: Amplifying Reasoning with\n  Large Language Models",
        "authors": [
            "Chao-Chi Chen",
            "Chin-Yuan Yeh",
            "Hsi-Wen Chen",
            "De-Nian Yang",
            "Ming-Syan Chen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We introduce Knowledgeable Network of Thoughts (kNoT): a prompt scheme that\nadvances the capabilities of large language models (LLMs) beyond existing\nparadigms like Chain-of-Thought (CoT), Tree of Thoughts (ToT), and Graph of\nThoughts (GoT). The key innovation of kNoT is the LLM Workflow Template (LWT),\nwhich allows for an executable plan to be specified by LLMs for LLMs. LWT\nallows these plans to be arbitrary networks, where single-step LLM operations\nare nodes, and edges correspond to message passing between these steps.\nFurthermore, LWT supports selection of individual elements through indexing,\nfacilitating kNoT to produce intricate plans where each LLM operation can be\nlimited to elementary operations, greatly enhancing reliability over extended\ntask sequences. We demonstrate that kNoT significantly outperforms the state of\nthe art on six use cases, while reducing the need for extensive prompt\nengineering. For instance, kNoT finds 92% accuracy for sorting 32 numbers over\n12% and 31% for ToT and GoT, while utilizing up to 84.4% and 87.3% less\ntask-specific prompts, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.16533v1"
    },
    {
        "title": "Safe Multiagent Coordination via Entropic Exploration",
        "authors": [
            "Ayhan Alp Aydeniz",
            "Enrico Marchesini",
            "Robert Loftin",
            "Christopher Amato",
            "Kagan Tumer"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Many real-world multiagent learning problems involve safety concerns. In\nthese setups, typical safe reinforcement learning algorithms constrain agents'\nbehavior, limiting exploration -- a crucial component for discovering effective\ncooperative multiagent behaviors. Moreover, the multiagent literature typically\nmodels individual constraints for each agent and has yet to investigate the\nbenefits of using joint team constraints. In this work, we analyze these team\nconstraints from a theoretical and practical perspective and propose entropic\nexploration for constrained multiagent reinforcement learning (E2C) to address\nthe exploration issue. E2C leverages observation entropy maximization to\nincentivize exploration and facilitate learning safe and effective cooperative\nbehaviors. Experiments across increasingly complex domains show that E2C agents\nmatch or surpass common unconstrained and constrained baselines in task\nperformance while reducing unsafe behaviors by up to $50\\%$.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.20361v1"
    },
    {
        "title": "AI Agent for Education: von Neumann Multi-Agent System Framework",
        "authors": [
            "Yuan-Hao Jiang",
            "Ruijia Li",
            "Yizhou Zhou",
            "Changyong Qi",
            "Hanglei Hu",
            "Yuang Wei",
            "Bo Jiang",
            "Yonghe Wu"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The development of large language models has ushered in new paradigms for\neducation. This paper centers on the multi-Agent system in education and\nproposes the von Neumann multi-Agent system framework. It breaks down each AI\nAgent into four modules: control unit, logic unit, storage unit, and\ninput-output devices, defining four types of operations: task deconstruction,\nself-reflection, memory processing, and tool invocation. Furthermore, it\nintroduces related technologies such as Chain-of-Thought, Reson+Act, and\nMulti-Agent Debate associated with these four types of operations. The paper\nalso discusses the ability enhancement cycle of a multi-Agent system for\neducation, including the outer circulation for human learners to promote\nknowledge construction and the inner circulation for LLM-based-Agents to\nenhance swarm intelligence. Through collaboration and reflection, the\nmulti-Agent system can better facilitate human learners' learning and enhance\ntheir teaching abilities in this process.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00083v1"
    },
    {
        "title": "Deterministic Model of Incremental Multi-Agent Boltzmann Q-Learning:\n  Transient Cooperation, Metastability, and Oscillations",
        "authors": [
            "David Goll",
            "Jobst Heitzig",
            "Wolfram Barfuss"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Multi-Agent Reinforcement Learning involves agents that learn together in a\nshared environment, leading to emergent dynamics sensitive to initial\nconditions and parameter variations. A Dynamical Systems approach, which\nstudies the evolution of multi-component systems over time, has uncovered some\nof the underlying dynamics by constructing deterministic approximation models\nof stochastic algorithms. In this work, we demonstrate that even in the\nsimplest case of independent Q-learning with a Boltzmann exploration policy,\nsignificant discrepancies arise between the actual algorithm and previous\napproximations. We elaborate why these models actually approximate interesting\nvariants rather than the original incremental algorithm. To explain the\ndiscrepancies, we introduce a new discrete-time approximation model that\nexplicitly accounts for agents' update frequencies within the learning process\nand show that its dynamics fundamentally differ from the simplified dynamics of\nprior models. We illustrate the usefulness of our approach by applying it to\nthe question of spontaneous cooperation in social dilemmas, specifically the\nPrisoner's Dilemma as the simplest case study. We identify conditions under\nwhich the learning behaviour appears as long-term stable cooperation from an\nexternal perspective. However, our model shows that this behaviour is merely a\nmetastable transient phase and not a true equilibrium, making it exploitable.\nWe further exemplify how specific parameter settings can significantly\nexacerbate the moving target problem in independent learning. Through a\nsystematic analysis of our model, we show that increasing the discount factor\ninduces oscillations, preventing convergence to a joint policy. These\noscillations arise from a supercritical Neimark-Sacker bifurcation, which\ntransforms the unique stable fixed point into an unstable focus surrounded by a\nstable limit cycle.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00160v1"
    },
    {
        "title": "Large Language Model Based Multi-Agent System Augmented Complex Event\n  Processing Pipeline for Internet of Multimedia Things",
        "authors": [
            "Talha Zeeshan",
            "Abhishek Kumar",
            "Susanna Pirttikangas",
            "Sasu Tarkoma"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  This paper presents the development and evaluation of a Large Language Model\n(LLM), also known as foundation models, based multi-agent system framework for\ncomplex event processing (CEP) with a focus on video query processing use\ncases. The primary goal is to create a proof-of-concept (POC) that integrates\nstate-of-the-art LLM orchestration frameworks with publish/subscribe (pub/sub)\ntools to address the integration of LLMs with current CEP systems. Utilizing\nthe Autogen framework in conjunction with Kafka message brokers, the system\ndemonstrates an autonomous CEP pipeline capable of handling complex workflows.\nExtensive experiments evaluate the system's performance across varying\nconfigurations, complexities, and video resolutions, revealing the trade-offs\nbetween functionality and latency. The results show that while higher agent\ncount and video complexities increase latency, the system maintains high\nconsistency in narrative coherence. This research builds upon and contributes\nto, existing novel approaches to distributed AI systems, offering detailed\ninsights into integrating such systems into existing infrastructures.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00906v2"
    },
    {
        "title": "Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A\n  Framework for Senior Design Projects",
        "authors": [
            "Abdullah Mushtaq",
            "Muhammad Rafay Naeem",
            "Ibrahim Ghaznavi",
            "Muhammad Imran Taj",
            "Imran Hashmi",
            "Junaid Qadir"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Multi-Agent Large Language Models (LLMs) are gaining significant attention\nfor their ability to harness collective intelligence in complex\nproblem-solving, decision-making, and planning tasks. This aligns with the\nconcept of the wisdom of crowds, where diverse agents contribute collectively\nto generating effective solutions, making it particularly suitable for\neducational settings. Senior design projects, also known as capstone or final\nyear projects, are pivotal in engineering education as they integrate\ntheoretical knowledge with practical application, fostering critical thinking,\nteamwork, and real-world problem-solving skills. In this paper, we explore the\nuse of Multi-Agent LLMs in supporting these senior design projects undertaken\nby engineering students, which often involve multidisciplinary considerations\nand conflicting objectives, such as optimizing technical performance while\naddressing ethical, social, and environmental concerns. We propose a framework\nwhere distinct LLM agents represent different expert perspectives, such as\nproblem formulation agents, system complexity agents, societal and ethical\nagents, or project managers, thus facilitating a holistic problem-solving\napproach. This implementation leverages standard multi-agent system (MAS)\nconcepts such as coordination, cooperation, and negotiation, incorporating\nprompt engineering to develop diverse personas for each agent. These agents\nengage in rich, collaborative dialogues to simulate human engineering teams,\nguided by principles from swarm AI to efficiently balance individual\ncontributions towards a unified solution. We adapt these techniques to create a\ncollaboration structure for LLM agents, encouraging interdisciplinary reasoning\nand negotiation similar to real-world senior design projects. To assess the\nefficacy of this framework, we collected six proposals of engineering and\ncomputer science of...\n",
        "pdf_link": "http://arxiv.org/pdf/2501.01205v1"
    },
    {
        "title": "Applying Large Language Models in Knowledge Graph-based Enterprise\n  Modeling: Challenges and Opportunities",
        "authors": [
            "Benedikt Reitemeyer",
            "Hans-Georg Fill"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  The role of large language models (LLMs) in enterprise modeling has recently\nstarted to shift from academic research to that of industrial applications.\nThereby, LLMs represent a further building block for the machine-supported\ngeneration of enterprise models. In this paper we employ a knowledge\ngraph-based approach for enterprise modeling and investigate the potential\nbenefits of LLMs in this context. In addition, the findings of an expert survey\nand ChatGPT-4o-based experiments demonstrate that LLM-based model generations\nexhibit minimal variability, yet remain constrained to specific tasks, with\nreliability declining for more intricate tasks. The survey results further\nsuggest that the supervision and intervention of human modeling experts are\nessential to ensure the accuracy and integrity of the generated models.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.03566v1"
    },
    {
        "title": "Towards resilient cities: A hybrid simulation framework for risk\n  mitigation through data driven decision making",
        "authors": [
            "David Carraminana",
            "Ana M. Bernardos",
            "Juan A. Besada",
            "Jose R. Casar"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Providing a comprehensive view of the city operation and offering useful\nmetrics for decision making is a well known challenge for urban risk analysis\nsystems. Existing systems are, in many cases, generalizations of previous\ndomain specific tools and or methodologies that may not cover all urban\ninterdependencies and makes it difficult to have homogeneous indicators. In\norder to overcome this limitation while seeking for effective support to\ndecision makers, this article introduces a novel hybrid simulation framework\nfor risk mitigation. The framework is built on a proposed city concept that\nconsiders urban space as a Complex Adaptive System composed by interconnected\nCritical Infrastructures. In this concept, a Social System, which models daily\npatterns and social interactions of the citizens in the Urban Landscape, drives\nthe CIs demand to configure the full city picture. The frameworks hybrid design\nintegrates agent based and network based modeling by breaking down city agents\ninto system dependent subagents, to enable both inter and intra system\ninteraction simulation, respectively. A layered structure of indicators at\ndifferent aggregation levels is also developed, to ensure that decisions are\nnot only data driven but also explainable. Therefore, the proposed simulation\nframework can serve as a DSS tool that allows the quantitative analysis of the\nimpact of threats at different levels. First, system level metrics can be used\nto get a broad view on the city resilience. Then, agent level metrics back\nthose figures and provide better explainability. On implementation, the\nproposed framework enables component reusability (for eased coding), simulation\nfederation (enabling the integration of existing system oriented simulators),\ndiscrete simulation in accelerated time (for rapid scenario simulation) and\ndecision oriented visualization (for informed outputs).\n",
        "pdf_link": "http://arxiv.org/pdf/2501.04746v1"
    },
    {
        "title": "Talk to Right Specialists: Routing and Planning in Multi-agent System\n  for Question Answering",
        "authors": [
            "Feijie Wu",
            "Zitao Li",
            "Fei Wei",
            "Yaliang Li",
            "Bolin Ding",
            "Jing Gao"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Leveraging large language models (LLMs), an agent can utilize\nretrieval-augmented generation (RAG) techniques to integrate external knowledge\nand increase the reliability of its responses. Current RAG-based agents\nintegrate single, domain-specific knowledge sources, limiting their ability and\nleading to hallucinated or inaccurate responses when addressing cross-domain\nqueries. Integrating multiple knowledge bases into a unified RAG-based agent\nraises significant challenges, including increased retrieval overhead and data\nsovereignty when sensitive data is involved. In this work, we propose RopMura,\na novel multi-agent system that addresses these limitations by incorporating\nhighly efficient routing and planning mechanisms. RopMura features two key\ncomponents: a router that intelligently selects the most relevant agents based\non knowledge boundaries and a planner that decomposes complex multi-hop queries\ninto manageable steps, allowing for coordinating cross-domain responses.\nExperimental results demonstrate that RopMura effectively handles both\nsingle-hop and multi-hop queries, with the routing mechanism enabling precise\nanswers for single-hop queries and the combined routing and planning mechanisms\nachieving accurate, multi-step resolutions for complex queries.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.07813v1"
    },
    {
        "title": "A Reinforcement Learning Approach to Quiet and Safe UAM Traffic\n  Management",
        "authors": [
            "Surya Murthy",
            "John-Paul Clarke",
            "Ufuk Topcu",
            "Zhenyu Gao"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Urban air mobility (UAM) is a transformative system that operates various\nsmall aerial vehicles in urban environments to reshape urban transportation.\nHowever, integrating UAM into existing urban environments presents a variety of\ncomplex challenges. Recent analyses of UAM's operational constraints highlight\naircraft noise and system safety as key hurdles to UAM system implementation.\nFuture UAM air traffic management schemes must ensure that the system is both\nquiet and safe. We propose a multi-agent reinforcement learning approach to\nmanage UAM traffic, aiming at both vertical separation assurance and noise\nmitigation. Through extensive training, the reinforcement learning agent learns\nto balance the two primary objectives by employing altitude adjustments in a\nmulti-layer UAM network. The results reveal the tradeoffs among noise impact,\ntraffic congestion, and separation. Overall, our findings demonstrate the\npotential of reinforcement learning in mitigating UAM's noise impact while\nmaintaining safe separation using altitude adjustments\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08941v1"
    },
    {
        "title": "Subexponential convergence for information aggregation on regular trees",
        "authors": [
            "Yashodhan Kanoria",
            "Andrea Montanari"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  We consider the decentralized binary hypothesis testing problem on trees of\nbounded degree and increasing depth. For a regular tree of depth t and\nbranching factor k>=2, we assume that the leaves have access to independent and\nidentically distributed noisy observations of the 'state of the world' s.\nStarting with the leaves, each node makes a decision in a finite alphabet M,\nthat it sends to its parent in the tree. Finally, the root decides between the\ntwo possible states of the world based on the information it receives.\n  We prove that the error probability vanishes only subexponentially in the\nnumber of available observations, under quite general hypotheses. More\nprecisely the case of binary messages, decay is subexponential for any decision\nrule. For general (finite) message alphabet M, decay is subexponential for\n'node-oblivious' decision rules, that satisfy a mild irreducibility condition.\nIn the latter case, we propose a family of decision rules with close-to-optimal\nasymptotic behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.2939v1"
    },
    {
        "title": "Voting in a Stochastic Environment: The Case of Two Groups",
        "authors": [
            "P. Yu. Chebotarev",
            "A. K. Loginov",
            "Ya. Yu. Tsodikova",
            "Z. M. Lezina",
            "V. I. Borzenko"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  Social dynamics determined by voting in a stochastic environment is analyzed\nfor a society composed of two cohesive groups of similar size. Within the model\nof random walks determined by voting, explicit formulas are derived for the\ncapital increments of the groups against the parameters of the environment and\n\"claim thresholds\" of the groups. The \"unanimous acceptance\" and \"unanimous\nrejection\" group rules are considered as the voting procedures. Claim\nthresholds are evaluated that are most beneficial to the participants of the\ngroups and to the society as a whole.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.0510v1"
    },
    {
        "title": "A Dynamic Framework of Reputation Systems for an Agent Mediated e-market",
        "authors": [
            "Vibha Gaur",
            "Neeraj Kumar Sharma"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  The success of an agent mediated e-market system lies in the underlying\nreputation management system to improve the quality of services in an\ninformation asymmetric e-market. Reputation provides an operatable metric for\nestablishing trustworthiness between mutually unknown online entities.\nReputation systems encourage honest behaviour and discourage malicious\nbehaviour of participating agents in the e-market. A dynamic reputation model\nwould provide virtually instantaneous knowledge about the changing e-market\nenvironment and would utilise Internets' capacity for continuous interactivity\nfor reputation computation. This paper proposes a dynamic reputation framework\nusing reinforcement learning and fuzzy set theory that ensures judicious use of\ninformation sharing for inter-agent cooperation. This framework is sensitive to\nthe changing parameters of e-market like the value of transaction and the\nvarying experience of agents with the purpose of improving inbuilt defense\nmechanism of the reputation system against various attacks so that e-market\nreaches an equilibrium state and dishonest agents are weeded out of the market.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.3961v1"
    },
    {
        "title": "In-network Sparsity-regularized Rank Minimization: Algorithms and\n  Applications",
        "authors": [
            "Morteza Mardani",
            "Gonzalo Mateos",
            "Georgios B. Giannakis"
        ],
        "category": "cs.MA",
        "published_year": "2012",
        "summary": "  Given a limited number of entries from the superposition of a low-rank matrix\nplus the product of a known fat compression matrix times a sparse matrix,\nrecovery of the low-rank and sparse components is a fundamental task subsuming\ncompressed sensing, matrix completion, and principal components pursuit. This\npaper develops algorithms for distributed sparsity-regularized rank\nminimization over networks, when the nuclear- and $\\ell_1$-norm are used as\nsurrogates to the rank and nonzero entry counts of the sought matrices,\nrespectively. While nuclear-norm minimization has well-documented merits when\ncentralized processing is viable, non-separability of the singular-value sum\nchallenges its distributed minimization. To overcome this limitation, an\nalternative characterization of the nuclear norm is adopted which leads to a\nseparable, yet non-convex cost minimized via the alternating-direction method\nof multipliers. The novel distributed iterations entail reduced-complexity\nper-node tasks, and affordable message passing among single-hop neighbors.\nInterestingly, upon convergence the distributed (non-convex) estimator provably\nattains the global optimum of its centralized counterpart, regardless of\ninitialization. Several application domains are outlined to highlight the\ngenerality and impact of the proposed framework. These include unveiling\ntraffic anomalies in backbone networks, predicting networkwide path latencies,\nand mapping the RF ambiance using wireless cognitive radios. Simulations with\nsynthetic and real network data corroborate the convergence of the novel\ndistributed algorithm, and its centralized performance guarantees.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.1570v1"
    },
    {
        "title": "A variant of the multi-agent rendezvous problem",
        "authors": [
            "Peter Hegarty",
            "Anders Martinsson",
            "Dmitry Zhelezov"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  The classical multi-agent rendezvous problem asks for a deterministic\nalgorithm by which $n$ points scattered in a plane can move about at constant\nspeed and merge at a single point, assuming each point can use only the\nlocations of the others it sees when making decisions and that the visibility\ngraph as a whole is connected. In time complexity analyses of such algorithms,\nonly the number of rounds of computation required are usually considered, not\nthe amount of computation done per round. In this paper, we consider\n$\\Omega(n^2 \\log n)$ points distributed independently and uniformly at random\nin a disc of radius $n$ and, assuming each point can not only see but also, in\nprinciple, communicate with others within unit distance, seek a randomised\nmerging algorithm which asymptotically almost surely (a.a.s.) runs in time\nO(n), in other words in time linear in the radius of the disc rather than in\nthe number of points. Under a precise set of assumptions concerning the\ncommunication capabilities of neighboring points, we describe an algorithm\nwhich a.a.s. runs in time O(n) provided the number of points is $o(n^3)$.\nSeveral questions are posed for future work.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.5166v1"
    },
    {
        "title": "Complexity of Manipulation with Partial Information in Voting",
        "authors": [
            "Palash Dey",
            "Neeldhara Misra",
            "Y. Narahari"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  The Coalitional Manipulation problem has been studied extensively in the\nliterature for many voting rules. However, most studies have focused on the\ncomplete information setting, wherein the manipulators know the votes of the\nnon-manipulators. While this assumption is reasonable for purposes of showing\nintractability, it is unrealistic for algorithmic considerations. In most\nreal-world scenarios, it is impractical for the manipulators to have accurate\nknowledge of all the other votes. In this paper, we investigate manipulation\nwith incomplete information. In our framework, the manipulators know a partial\norder for each voter that is consistent with the true preference of that voter.\nIn this setting, we formulate three natural computational notions of\nmanipulation, namely weak, opportunistic, and strong manipulation. We say that\nan extension of a partial order is if there exists a manipulative vote for that\nextension.\n  1. Weak Manipulation (WM): the manipulators seek to vote in a way that makes\ntheir preferred candidate win in at least one extension of the partial votes of\nthe non-manipulators.\n  2. Opportunistic Manipulation (OM): the manipulators seek to vote in a way\nthat makes their preferred candidate win in every viable extension of the\npartial votes of the non-manipulators.\n  3. Strong Manipulation (SM): the manipulators seek to vote in a way that\nmakes their preferred candidate win in every extension of the partial votes of\nthe non-manipulators.\n  We consider several scenarios for which the traditional manipulation problems\nare easy (for instance, Borda with a single manipulator). For many of them, the\ncorresponding manipulative questions that we propose turn out to be\ncomputationally intractable. Our hardness results often hold even when very\nlittle information is missing, or in other words, even when the instances are\nquite close to the complete information setting.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.04359v2"
    },
    {
        "title": "Network learning via multi-agent inverse transportation problems",
        "authors": [
            "Susan Jia Xu",
            "Mehdi Nourinejad",
            "Xuebo Lai",
            "Joseph Y. J. Chow"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  Despite the ubiquity of transportation data, methods to infer the state\nparameters of a network either ignore sensitivity of route decisions, require\nroute enumeration for parameterizing descriptive models of route selection, or\nrequire complex bilevel models of route assignment behavior. These limitations\nprevent modelers from fully exploiting ubiquitous data in monitoring\ntransportation networks. Inverse optimization methods that capture network\nroute choice behavior can address this gap, but they are designed to take\nobservations of the same model to learn the parameters of that model, which is\nstatistically inefficient (e.g. requires estimating population route and link\nflows). New inverse optimization models and supporting algorithms are proposed\nto learn the parameters of heterogeneous travelers' route behavior to infer\nshared network state parameters (e.g. link capacity dual prices). The inferred\nvalues are consistent with observations of each agent's optimization behavior.\nWe prove that the method can obtain unique dual prices for a network shared by\nthese agents in polynomial time. Four experiments are conducted. The first one,\nconducted on a 4-node network, verifies the methodology to obtain heterogeneous\nlink cost parameters even when multinomial or mixed logit models would not be\nmeaningfully estimated. The second is a parameter recovery test on the\nNguyen-Dupuis network that shows that unique latent link capacity dual prices\ncan be inferred using the proposed method. The third test on the same network\ndemonstrates how a monitoring system in an online learning environment can be\ndesigned using this method. The last test demonstrates this learning on real\ndata obtained from a freeway network in Queens, New York, using only real-time\nGoogle Maps queries.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.04117v4"
    },
    {
        "title": "Designing Autonomous Vehicles: Evaluating the Role of Human Emotions and\n  Social Norms",
        "authors": [
            "Faisal Riaz",
            "Muaz A. Niazi"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Humans are going to delegate the rights of driving to the autonomous vehicles\nin near future. However, to fulfill this complicated task, there is a need for\na mechanism, which enforces the autonomous vehicles to obey the road and social\nrules that have been practiced by well-behaved drivers. This task can be\nachieved by introducing social norms compliance mechanism in the autonomous\nvehicles. This research paper is proposing an artificial society of autonomous\nvehicles as an analogy of human social society. Each AV has been assigned a\nsocial personality having different social influence. Social norms have been\nintroduced which help the AVs in making the decisions, influenced by emotions,\nregarding road collision avoidance. Furthermore, social norms compliance\nmechanism, by artificial social AVs, has been proposed using prospect based\nemotion i.e. fear, which is conceived from OCC model. Fuzzy logic has been\nemployed to compute the emotions quantitatively. Then, using SimConnect\napproach, fuzzy values of fear has been provided to the Netlogo simulation\nenvironment to simulate artificial society of AVs. Extensive testing has been\nperformed using the behavior space tool to find out the performance of the\nproposed approach in terms of the number of collisions. For comparison, the\nrandom-walk model based artificial society of AVs has been proposed as well. A\ncomparative study with a random walk, prove that proposed approach provides a\nbetter option to tailor the autopilots of future AVS, Which will be more\nsocially acceptable and trustworthy by their riders in terms of safe road\ntravel.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.01925v1"
    },
    {
        "title": "Towards A Novel Unified Framework for Developing Formal, Network and\n  Validated Agent-Based Simulation Models of Complex Adaptive Systems",
        "authors": [
            "Muaz A. Niazi"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Literature on the modeling and simulation of complex adaptive systems (cas)\nhas primarily advanced vertically in different scientific domains with\nscientists developing a variety of domain-specific approaches and applications.\nHowever, while cas researchers are inher-ently interested in an\ninterdisciplinary comparison of models, to the best of our knowledge, there is\ncurrently no single unified framework for facilitating the development,\ncomparison, communication and validation of models across different scientific\ndomains. In this thesis, we propose first steps towards such a unified\nframework using a combination of agent-based and complex network-based modeling\napproaches and guidelines formulated in the form of a set of four levels of\nusage, which allow multidisciplinary researchers to adopt a suitable framework\nlevel on the basis of available data types, their research study objectives and\nexpected outcomes, thus allowing them to better plan and conduct their\nrespective re-search case studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.02357v1"
    },
    {
        "title": "Verification & Validation of Agent Based Simulations using the VOMAS\n  (Virtual Overlay Multi-agent System) approach",
        "authors": [
            "Muaz A. Niazi",
            "Amir Hussain",
            "Mario Kolberg"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Agent Based Models are very popular in a number of different areas. For\nexample, they have been used in a range of domains ranging from modeling of\ntumor growth, immune systems, molecules to models of social networks, crowds\nand computer and mobile self-organizing networks. One reason for their success\nis their intuitiveness and similarity to human cognition. However, with this\npower of abstraction, in spite of being easily applicable to such a wide number\nof domains, it is hard to validate agent-based models. In addition, building\nvalid and credible simulations is not just a challenging task but also a\ncrucial exercise to ensure that what we are modeling is, at some level of\nabstraction, a model of our conceptual system; the system that we have in mind.\nIn this paper, we address this important area of validation of agent based\nmodels by presenting a novel technique which has broad applicability and can be\napplied to all kinds of agent-based models. We present a framework, where a\nvirtual overlay multi-agent system can be used to validate simulation models.\nIn addition, since agent-based models have been typically growing, in parallel,\nin multiple domains, to cater for all of these, we present a new single\nvalidation technique applicable to all agent based models. Our technique, which\nallows for the validation of agent based simulations uses VOMAS: a Virtual\nOverlay Multi-agent System. This overlay multi-agent system can comprise\nvarious types of agents, which form an overlay on top of the agent based\nsimulation model that needs to be validated. Other than being able to watch and\nlog, each of these agents contains clearly defined constraints, which, if\nviolated, can be logged in real time. To demonstrate its effectiveness, we show\nits broad applicability in a wide variety of simulation models ranging from\nsocial sciences to computer networks in spatial and non-spatial conceptual\nmodels.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.02361v1"
    },
    {
        "title": "Guided Deep Reinforcement Learning for Swarm Systems",
        "authors": [
            "Maximilian Hüttenrauch",
            "Adrian Šošić",
            "Gerhard Neumann"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In this paper, we investigate how to learn to control a group of cooperative\nagents with limited sensing capabilities such as robot swarms. The agents have\nonly very basic sensor capabilities, yet in a group they can accomplish\nsophisticated tasks, such as distributed assembly or search and rescue tasks.\nLearning a policy for a group of agents is difficult due to distributed partial\nobservability of the state. Here, we follow a guided approach where a critic\nhas central access to the global state during learning, which simplifies the\npolicy evaluation problem from a reinforcement learning point of view. For\nexample, we can get the positions of all robots of the swarm using a camera\nimage of a scene. This camera image is only available to the critic and not to\nthe control policies of the robots. We follow an actor-critic approach, where\nthe actors base their decisions only on locally sensed information. In\ncontrast, the critic is learned based on the true global state. Our algorithm\nuses deep reinforcement learning to approximate both the Q-function and the\npolicy. The performance of the algorithm is evaluated on two tasks with simple\nsimulated 2D agents: 1) finding and maintaining a certain distance to each\nothers and 2) locating a target.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.06011v1"
    },
    {
        "title": "Local Communication Protocols for Learning Complex Swarm Behaviors with\n  Deep Reinforcement Learning",
        "authors": [
            "Maximilian Hüttenrauch",
            "Adrian Šošić",
            "Gerhard Neumann"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  Swarm systems constitute a challenging problem for reinforcement learning\n(RL) as the algorithm needs to learn decentralized control policies that can\ncope with limited local sensing and communication abilities of the agents.\nWhile it is often difficult to directly define the behavior of the agents,\nsimple communication protocols can be defined more easily using prior knowledge\nabout the given task. In this paper, we propose a number of simple\ncommunication protocols that can be exploited by deep reinforcement learning to\nfind decentralized control policies in a multi-robot swarm environment. The\nprotocols are based on histograms that encode the local neighborhood relations\nof the agents and can also transmit task-specific information, such as the\nshortest distance and direction to a desired target. In our framework, we use\nan adaptation of Trust Region Policy Optimization to learn complex\ncollaborative tasks, such as formation building and building a communication\nlink. We evaluate our findings in a simulated 2D-physics environment, and\ncompare the implications of different communication protocols.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.07224v2"
    },
    {
        "title": "Bio-Inspired Local Information-Based Control for Probabilistic Swarm\n  Distribution Guidance",
        "authors": [
            "Inmo Jang",
            "Hyo-Sang Shin",
            "Antonios Tsourdos"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  This paper addresses a task allocation problem for a large-scale robotic\nswarm, namely swarm distribution guidance problem. Unlike most of the existing\nframeworks handling this problem, the proposed framework suggests utilising\nlocal information available to generate its time-varying stochastic policies.\nAs each agent requires only local consistency on information with neighbouring\nagents, rather than the global consistency, the proposed framework offers\nvarious advantages, e.g., a shorter timescale for using new information and\npotential to incorporate an asynchronous decision-making process. We perform\ntheoretical analysis on the properties of the proposed framework. From the\nanalysis, it is proved that the framework can guarantee the convergence to the\ndesired density distribution even using local information while maintaining\nadvantages of global-information-based approaches. The design requirements for\nthese advantages are explicitly listed in this paper. This paper also provides\nspecific examples of how to implement the framework developed. The results of\nnumerical experiments confirm the effectiveness and comparability of the\nproposed framework, compared with the global-information-based framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.06869v1"
    },
    {
        "title": "Modeling the Multiple Sclerosis Brain Disease Using Agents: What Works\n  and What Doesn't?",
        "authors": [
            "Ayesha Muqaddas",
            "Muaz A. Niazi"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  The human brain is one of the most complex living structures in the known\nUniverse. It consists of billions of neurons and synapses. Due to its intrinsic\ncomplexity, it can be a formidable task to accurately depict brain's structure\nand functionality. In the past, numerous studies have been conducted on\nmodeling brain disease, structure, and functionality. Some of these studies\nhave employed Agent-based approaches including multiagent-based simulation\nmodels as well as brain complex networks. While these models have all been\ndeveloped using agent-based computing, however, to our best knowledge, none of\nthem have employed the use of Agent-Oriented Software Engineering (AOSE)\nmethodologies in developing the brain or disease model. This is a problem\nbecause without due process, developed models can miss out on important\nrequirements. AOSE has the unique capability of merging concepts from\nmultiagent systems, agent-based modeling, artificial intelligence, besides\nconcepts from distributed systems. AOSE involves the various tested software\nengineering principles in various phases of the model development ranging from\nanalysis, design, implementation, and testing phases. In this paper, we employ\nthe use of three different AOSE methodologies for modeling the Multiple\nSclerosis brain disease namely GAIA, TROPOS, and MASE. After developing the\nmodels, we further employ the use of Exploratory Agent-based Modeling (EABM) to\ndevelop an actual model replicating previous results as a proof of concept. The\nkey objective of this study is to demonstrate and explore the viability and\neffectiveness of AOSE methodologies in the development of complex brain\nstructure and cognitive process models. Our key finding include demonstration\nthat AOSE methodologies can be considerably helpful in modeling various living\ncomplex systems, in general, and the human brain, in particular.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.00190v1"
    },
    {
        "title": "The effectiveness of altruistic lobbying: A model study",
        "authors": [
            "Pavel Chebotarev",
            "Zoya Lezina",
            "Anton Loginov",
            "Yana Tsodikova"
        ],
        "category": "cs.MA",
        "published_year": "2013",
        "summary": "  Altruistic lobbying is lobbying in the public interest or in the interest of\nthe least protected part of the society. In fact, an altruist has a wide range\nof strategies, from behaving in the interest of the society as a whole to the\nsupport of the most disadvantaged ones. How can we compare the effectiveness of\nsuch strategies? Another question is: \"Given a strategy, is it possible to\nestimate the optimal number of participants choosing it?\" Finally, do the\nanswers to these questions depend on the level of well-being in the society?\nCan we say that the poorer the society, the more important is to focus on the\nsupport of the poorest? We answer these questions within the framework of the\nmodel of social dynamics determined by voting in a stochastic environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.0284v2"
    },
    {
        "title": "DRLE: Decentralized Reinforcement Learning at the Edge for Traffic Light\n  Control in the IoV",
        "authors": [
            "Pengyuan Zhou",
            "Xianfu Chen",
            "Zhi Liu",
            "Tristan Braud",
            "Pan Hui",
            "Jussi Kangasharju"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  The Internet of Vehicles (IoV) enables real-time data exchange among vehicles\nand roadside units and thus provides a promising solution to alleviate traffic\njams in the urban area. Meanwhile, better traffic management via efficient\ntraffic light control can benefit the IoV as well by enabling a better\ncommunication environment and decreasing the network load. As such, IoV and\nefficient traffic light control can formulate a virtuous cycle. Edge computing,\nan emerging technology to provide low-latency computation capabilities at the\nedge of the network, can further improve the performance of this cycle.\nHowever, while the collected information is valuable, an efficient solution for\nbetter utilization and faster feedback has yet to be developed for\nedge-empowered IoV. To this end, we propose a Decentralized Reinforcement\nLearning at the Edge for traffic light control in the IoV (DRLE). DRLE exploits\nthe ubiquity of the IoV to accelerate the collection of traffic data and its\ninterpretation towards alleviating congestion and providing better traffic\nlight control. DRLE operates within the coverage of the edge servers and uses\naggregated data from neighboring edge servers to provide city-scale traffic\nlight control. DRLE decomposes the highly complex problem of large area\ncontrol. into a decentralized multi-agent problem. We prove its global optima\nwith concrete mathematical reasoning. The proposed decentralized reinforcement\nlearning algorithm running at each edge node adapts the traffic lights in real\ntime. We conduct extensive evaluations and demonstrate the superiority of this\napproach over several state-of-the-art algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.01502v2"
    },
    {
        "title": "Learning Policy Representations in Multiagent Systems",
        "authors": [
            "Aditya Grover",
            "Maruan Al-Shedivat",
            "Jayesh K. Gupta",
            "Yura Burda",
            "Harrison Edwards"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Modeling agent behavior is central to understanding the emergence of complex\nphenomena in multiagent systems. Prior work in agent modeling has largely been\ntask-specific and driven by hand-engineering domain-specific prior knowledge.\nWe propose a general learning framework for modeling agent behavior in any\nmultiagent system using only a handful of interaction data. Our framework casts\nagent modeling as a representation learning problem. Consequently, we construct\na novel objective inspired by imitation learning and agent identification and\ndesign an algorithm for unsupervised learning of representations of agent\npolicies. We demonstrate empirically the utility of the proposed framework in\n(i) a challenging high-dimensional competitive environment for continuous\ncontrol and (ii) a cooperative environment for communication, on supervised\npredictive tasks, unsupervised clustering, and policy optimization using deep\nreinforcement learning.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.06464v2"
    },
    {
        "title": "Physically-interpretable classification of biological network dynamics\n  for complex collective motions",
        "authors": [
            "Keisuke Fujii",
            "Naoya Takeishi",
            "Motokazu Hojo",
            "Yuki Inaba",
            "Yoshinobu Kawahara"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Understanding biological network dynamics is a fundamental issue in various\nscientific and engineering fields. Network theory is capable of revealing the\nrelationship between elements and their propagation; however, for complex\ncollective motions, the network properties often transiently and complexly\nchange. A fundamental question addressed here pertains to the classification of\ncollective motion network based on physically-interpretable dynamical\nproperties. Here we apply a data-driven spectral analysis called graph dynamic\nmode decomposition, which obtains the dynamical properties for collective\nmotion classification. Using a ballgame as an example, we classified the\nstrategic collective motions in different global behaviours and discovered\nthat, in addition to the physical properties, the contextual node information\nwas critical for classification. Furthermore, we discovered the label-specific\nstronger spectra in the relationship among the nearest agents, providing\nphysical and semantic interpretations. Our approach contributes to the\nunderstanding of principles of biological complex network dynamics from the\nperspective of nonlinear dynamical systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04859v2"
    },
    {
        "title": "The Projection Method for Reaching Consensus and the Regularized Power\n  Limit of a Stochastic Matrix",
        "authors": [
            "R. P. Agaev",
            "P. Yu. Chebotarev"
        ],
        "category": "cs.MA",
        "published_year": "2011",
        "summary": "  In the coordination/consensus problem for multi-agent systems, a well-known\ncondition of achieving consensus is the presence of a spanning arborescence in\nthe communication digraph. The paper deals with the discrete consensus problem\nin the case where this condition is not satisfied. A characterization of the\nsubspace $T_P$ of initial opinions (where $P$ is the influence matrix) that\n\\emph{ensure} consensus in the DeGroot model is given. We propose a method of\ncoordination that consists of: (1) the transformation of the vector of initial\nopinions into a vector belonging to $T_P$ by orthogonal projection and (2)\nsubsequent iterations of the transformation $P.$ The properties of this method\nare studied. It is shown that for any non-periodic stochastic matrix $P,$ the\nresulting matrix of the orthogonal projection method can be treated as a\nregularized power limit of $P.$\n",
        "pdf_link": "http://arxiv.org/pdf/1109.3948v2"
    },
    {
        "title": "Asynchronous Decentralized 20 Questions for Adaptive Search",
        "authors": [
            "Theodoros Tsiligkaridis"
        ],
        "category": "cs.MA",
        "published_year": "2015",
        "summary": "  This paper considers the problem of adaptively searching for an unknown\ntarget using multiple agents connected through a time-varying network topology.\nAgents are equipped with sensors capable of fast information processing, and we\npropose a decentralized collaborative algorithm for controlling their search\ngiven noisy observations. Specifically, we propose decentralized extensions of\nthe adaptive query-based search strategy that combines elements from the 20\nquestions approach and social learning. Under standard assumptions on the\ntime-varying network dynamics, we prove convergence to correct consensus on the\nvalue of the parameter as the number of iterations go to infinity. The\nconvergence analysis takes a novel approach using martingale-based techniques\ncombined with spectral graph theory. Our results establish that stability and\nconsistency can be maintained even with one-way updating and randomized\npairwise averaging, thus providing a scalable low complexity method with\nperformance guarantees. We illustrate the effectiveness of our algorithm for\nrandom network topologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.03144v2"
    },
    {
        "title": "Deep Reinforcement Learning for Swarm Systems",
        "authors": [
            "Maximilian Hüttenrauch",
            "Adrian Šošić",
            "Gerhard Neumann"
        ],
        "category": "cs.MA",
        "published_year": "2018",
        "summary": "  Recently, deep reinforcement learning (RL) methods have been applied\nsuccessfully to multi-agent scenarios. Typically, these methods rely on a\nconcatenation of agent states to represent the information content required for\ndecentralized decision making. However, concatenation scales poorly to swarm\nsystems with a large number of homogeneous agents as it does not exploit the\nfundamental properties inherent to these systems: (i) the agents in the swarm\nare interchangeable and (ii) the exact number of agents in the swarm is\nirrelevant. Therefore, we propose a new state representation for deep\nmulti-agent RL based on mean embeddings of distributions. We treat the agents\nas samples of a distribution and use the empirical mean embedding as input for\na decentralized policy. We define different feature spaces of the mean\nembedding using histograms, radial basis functions and a neural network learned\nend-to-end. We evaluate the representation on two well known problems from the\nswarm literature (rendezvous and pursuit evasion), in a globally and locally\nobservable setup. For the local setup we furthermore introduce simple\ncommunication protocols. Of all approaches, the mean embedding representation\nusing neural network features enables the richest information exchange between\nneighboring agents facilitating the development of more complex collective\nstrategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.06613v3"
    },
    {
        "title": "Cognitive swarming in complex environments with attractor dynamics and\n  oscillatory computing",
        "authors": [
            "Joseph D. Monaco",
            "Grace M. Hwang",
            "Kevin M. Schultz",
            "Kechen Zhang"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Neurobiological theories of spatial cognition developed with respect to\nrecording data from relatively small and/or simplistic environments compared to\nanimals' natural habitats. It has been unclear how to extend theoretical models\nto large or complex spaces. Complementarily, in autonomous systems technology,\napplications have been growing for distributed control methods that scale to\nlarge numbers of low-footprint mobile platforms. Animals and many-robot groups\nmust solve common problems of navigating complex and uncertain environments.\nHere, we introduce the 'NeuroSwarms' control framework to investigate whether\nadaptive, autonomous swarm control of minimal artificial agents can be achieved\nby direct analogy to neural circuits of rodent spatial cognition. NeuroSwarms\nanalogizes agents to neurons and swarming groups to recurrent networks. We\nimplemented neuron-like agent interactions in which mutually visible agents\noperate as if they were reciprocally-connected place cells in an attractor\nnetwork. We attributed a phase state to agents to enable patterns of\noscillatory synchronization similar to hippocampal models of theta-rhythmic\n(5-12 Hz) sequence generation. We demonstrate that multi-agent swarming and\nreward-approach dynamics can be expressed as a mobile form of Hebbian learning\nand that NeuroSwarms supports a single-entity paradigm that directly informs\ntheoretical models of animal cognition. We present emergent behaviors including\nphase-organized rings and trajectory sequences that interact with environmental\ncues and geometry in large, fragmented mazes. Thus, NeuroSwarms is a model\nartificial spatial system that integrates autonomous control and theoretical\nneuroscience to potentially uncover common principles to advance both domains.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.06711v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Fast-Timescale Demand Response of\n  Residential Loads",
        "authors": [
            "Vincent Mai",
            "Philippe Maisonneuve",
            "Tianyu Zhang",
            "Hadi Nekoei",
            "Liam Paull",
            "Antoine Lesage-Landry"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  To integrate high amounts of renewable energy resources, electrical power\ngrids must be able to cope with high amplitude, fast timescale variations in\npower generation. Frequency regulation through demand response has the\npotential to coordinate temporally flexible loads, such as air conditioners, to\ncounteract these variations. Existing approaches for discrete control with\ndynamic constraints struggle to provide satisfactory performance for fast\ntimescale action selection with hundreds of agents. We propose a decentralized\nagent trained with multi-agent proximal policy optimization with localized\ncommunication. We explore two communication frameworks: hand-engineered, or\nlearned through targeted multi-agent communication. The resulting policies\nperform well and robustly for frequency regulation, and scale seamlessly to\narbitrary numbers of houses for constant processing times.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.02593v1"
    },
    {
        "title": "Distributed Consensus in Wireless Networks with Probabilistic Broadcast\n  Scheduling",
        "authors": [
            "Daniel Pérez Herrera",
            "Zheng Chen",
            "Erik G. Larsson"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We consider distributed average consensus in a wireless network with partial\ncommunication to reduce the number of transmissions in every iteration/round.\nConsidering the broadcast nature of wireless channels, we propose a\nprobabilistic approach that schedules a subset of nodes for broadcasting\ninformation to their neighbors in every round. We compare several heuristic\nmethods for assigning the node broadcast probabilities under a fixed number of\ntransmissions per round. Furthermore, we introduce a pre-compensation method to\ncorrect the bias between the consensus value and the average of the initial\nvalues, and suggest possible extensions for our design. Our results are\nparticularly relevant for developing communication-efficient consensus\nprotocols in a wireless environment with limited frequency/time resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.11714v1"
    },
    {
        "title": "The Probabilistic Structure of Discrete Agent-Based Models",
        "authors": [
            "Sven Banisch"
        ],
        "category": "cs.MA",
        "published_year": "2014",
        "summary": "  This paper describes a formalization of agent-based models (ABMs) as random\nwalks on regular graphs and relates the symmetry group of those graphs to a\ncoarse-graining of the ABM that is still Markovian. An ABM in which $N$ agents\ncan be in $\\delta$ different states leads to a Markov chain with $\\delta^N$\nstates. In ABMs with a sequential update scheme by which one agent is chosen to\nupdate its state at a time, transitions are only allowed between system\nconfigurations that differ with respect to a single agent. This characterizes\nABMs as random walks on regular graphs. The non-trivial automorphisms of those\ngraphs make visible the dynamical symmetries that an ABM gives rise to because\nsets of micro configurations can be interchanged without changing the\nprobability structure of the random walk. This allows for a systematic\nloss-less reduction of the state space of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.6277v1"
    },
    {
        "title": "Collaborative vehicle routing: a survey",
        "authors": [
            "Margaretha Gansterer",
            "Richard F. Hartl"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  In horizontal collaborations, carriers form coalitions in order to perform\nparts of their logistics operations jointly. By exchanging transportation\nrequests among each other, they can operate more efficiently and in a more\nsustainable way. Collaborative vehicle routing has been extensively discussed\nin the literature. We identify three major streams of research: (i) centralized\ncollaborative planning, (ii) decentralized planning without auctions, and (ii)\nauction-based decentralized planning. For each of them we give a structured\noverview on the state of knowledge and discuss future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.05254v1"
    },
    {
        "title": "On Optimal Group Claims at Voting in a Stochastic Environment",
        "authors": [
            "V. A. Malyshev",
            "P. Yu. Chebotarev"
        ],
        "category": "cs.MA",
        "published_year": "2017",
        "summary": "  There is a paradox in the model of social dynamics determined by voting in a\nstochastic environment (the ViSE model) called \"pit of losses.\" It consists in\nthe fact that a series of democratic decisions may systematically lead the\nsociety to the states unacceptable for all the voters. The paper examines how\nthis paradox can be neutralized by the presence in society of a group that\nvotes for its benefit and can regulate the threshold of its claims. We obtain\nand analyze analytical results characterizing the welfare of the whole society,\nthe group, and the other participants as functions of the said claims\nthreshold.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.05839v1"
    },
    {
        "title": "From Observability to Significance in Distributed Information Systems",
        "authors": [
            "Mark Burgess"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  To understand and explain process behaviour we need to be able to see it, and\ndecide its significance, i.e. be able to tell a story about its behaviours.\nThis paper describes a few of the modelling challenges that underlie monitoring\nand observation of processes in IT, by human or by software. The topic of the\nobservability of systems has been elevated recently in connection with computer\nmonitoring and tracing of processes for debugging and forensics. It raises the\nissue of well-known principles of measurement, in bounded contexts, but these\nissues have been left implicit in the Computer Science literature. This paper\naims to remedy this omission, by laying out a simple promise theoretic model,\nsummarizing a long standing trail of work on the observation of distributed\nsystems, based on elementary distinguishability of observations, and classical\ncausality, with history. Three distinct views of a system are sought, across a\nnumber of scales, that described how information is transmitted (and lost) as\nit moves around the system, aggregated into journals and logs.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.05636v2"
    },
    {
        "title": "Dynamic multi-agent assignment via discrete optimal transport",
        "authors": [
            "Koray G. Kachar",
            "Alex A. Gorodetsky"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  We propose an optimal solution to a deterministic dynamic assignment problem\nby leveraging connections to the theory of discrete optimal transport to\nconvert the combinatorial assignment problem into a tractable linear program.\nWe seek to allow a multi-vehicle swarm to accomplish a dynamically changing\ntask, for example tracking a multi-target swarm. Our approach simultaneously\ndetermines the optimal assignment and the control of the individual agents. As\na result, the assignment policy accounts for the dynamics and capabilities of a\nheterogeneous set of agents and targets. In contrast to a majority of existing\nassignment schemes, this approach improves upon distance-based metrics for\nassignments by considering cost metrics that account for the underlying\ndynamics manifold. We provide a theoretical justification for the reformulation\nof this problem, and show that the minimizer of the dynamic assignment problem\nis equivalent to the minimizer of the associated Monge problem arising in\noptimal transport. We prove that by accounting for dynamics, we only require\ncomputing an assignment once over the operating lifetime --- significantly\ndecreasing computational expense. Furthermore, we show that the cost benefits\nachieved by our approach increase as the swarm size increases, achieving almost\n50\\% cost reduction compared with distance-based metrics. We demonstrate our\napproach through simulation on several linear and linearized problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.10748v1"
    },
    {
        "title": "Second-Order Guarantees in Centralized, Federated and Decentralized\n  Nonconvex Optimization",
        "authors": [
            "Stefan Vlaski",
            "Ali H. Sayed"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Rapid advances in data collection and processing capabilities have allowed\nfor the use of increasingly complex models that give rise to nonconvex\noptimization problems. These formulations, however, can be arbitrarily\ndifficult to solve in general, in the sense that even simply verifying that a\ngiven point is a local minimum can be NP-hard [1]. Still, some relatively\nsimple algorithms have been shown to lead to surprisingly good empirical\nresults in many contexts of interest. Perhaps the most prominent example is the\nsuccess of the backpropagation algorithm for training neural networks. Several\nrecent works have pursued rigorous analytical justification for this phenomenon\nby studying the structure of the nonconvex optimization problems and\nestablishing that simple algorithms, such as gradient descent and its\nvariations, perform well in converging towards local minima and avoiding\nsaddle-points. A key insight in these analyses is that gradient perturbations\nplay a critical role in allowing local descent algorithms to efficiently\ndistinguish desirable from undesirable stationary points and escape from the\nlatter. In this article, we cover recent results on second-order guarantees for\nstochastic first-order optimization algorithms in centralized, federated, and\ndecentralized architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.14366v1"
    },
    {
        "title": "Reinforcement Learning in Linear Quadratic Deep Structured Teams: Global\n  Convergence of Policy Gradient Methods",
        "authors": [
            "Vida Fathi",
            "Jalal Arabneydi",
            "Amir G. Aghdam"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In this paper, we study the global convergence of model-based and model-free\npolicy gradient descent and natural policy gradient descent algorithms for\nlinear quadratic deep structured teams. In such systems, agents are partitioned\ninto a few sub-populations wherein the agents in each sub-population are\ncoupled in the dynamics and cost function through a set of linear regressions\nof the states and actions of all agents. Every agent observes its local state\nand the linear regressions of states, called deep states. For a sufficiently\nsmall risk factor and/or sufficiently large population, we prove that\nmodel-based policy gradient methods globally converge to the optimal solution.\nGiven an arbitrary number of agents, we develop model-free policy gradient and\nnatural policy gradient algorithms for the special case of risk-neutral cost\nfunction. The proposed algorithms are scalable with respect to the number of\nagents due to the fact that the dimension of their policy space is independent\nof the number of agents in each sub-population. Simulations are provided to\nverify the theoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.14393v2"
    },
    {
        "title": "The Confluence of Networks, Games and Learning",
        "authors": [
            "Tao Li",
            "Guanze Peng",
            "Quanyan Zhu",
            "Tamer Basar"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Recent years have witnessed significant advances in technologies and services\nin modern network applications, including smart grid management, wireless\ncommunication, cybersecurity as well as multi-agent autonomous systems.\nConsidering the heterogeneous nature of networked entities, emerging network\napplications call for game-theoretic models and learning-based approaches in\norder to create distributed network intelligence that responds to uncertainties\nand disruptions in a dynamic or an adversarial environment. This paper\narticulates the confluence of networks, games and learning, which establishes a\ntheoretical underpinning for understanding multi-agent decision-making over\nnetworks. We provide an selective overview of game-theoretic learning\nalgorithms within the framework of stochastic approximation theory, and\nassociated applications in some representative contexts of modern network\nsystems, such as the next generation wireless communication networks, the smart\ngrid and distributed machine learning. In addition to existing research works\non game-theoretic learning over networks, we highlight several new angles and\nresearch endeavors on learning in games that are related to recent developments\nin artificial intelligence. Some of the new angles extrapolate from our own\nresearch interests. The overall objective of the paper is to provide the reader\na clear picture of the strengths and challenges of adopting game-theoretic\nlearning methods within the context of network systems, and further to identify\nfruitful future research directions on both theoretical and applied studies.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08158v2"
    },
    {
        "title": "BBE: Simulating the Microstructural Dynamics of an In-Play Betting\n  Exchange via Agent-Based Modelling",
        "authors": [
            "Dave Cliff"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  I describe the rationale for, and design of, an agent-based simulation model\nof a contemporary online sports-betting exchange: such exchanges, closely\nrelated to the exchange mechanisms at the heart of major financial markets,\nhave revolutionized the gambling industry in the past 20 years, but gathering\nsufficiently large quantities of rich and temporally high-resolution data from\nreal exchanges - i.e., the sort of data that is needed in large quantities for\nDeep Learning - is often very expensive, and sometimes simply impossible; this\ncreates a need for a plausibly realistic synthetic data generator, which is\nwhat this simulation now provides. The simulator, named the \"Bristol Betting\nExchange\" (BBE), is intended as a common platform, a data-source and\nexperimental test-bed, for researchers studying the application of AI and\nmachine learning (ML) techniques to issues arising in betting exchanges; and,\nas far as I have been able to determine, BBE is the first of its kind: a free\nopen-source agent-based simulation model consisting not only of a\nsports-betting exchange, but also a minimal simulation model of racetrack\nsporting events (e.g., horse-races or car-races) about which bets may be made,\nand a population of simulated bettors who each form their own private\nevaluation of odds and place bets on the exchange before and - crucially -\nduring the race itself (i.e., so-called \"in-play\" betting) and whose betting\nopinions change second-by-second as each race event unfolds. BBE is offered as\na proof-of-concept system that enables the generation of large high-resolution\ndata-sets for automated discovery or improvement of profitable strategies for\nbetting on sporting events via the application of AI/ML and advanced data\nanalytics techniques. This paper offers an extensive survey of relevant\nliterature and explains the motivation and design of BBE, and presents brief\nillustrative results.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.08310v1"
    },
    {
        "title": "Bayesian optimization of distributed neurodynamical controller models\n  for spatial navigation",
        "authors": [
            "Armin Hadzic",
            "Grace M. Hwang",
            "Kechen Zhang",
            "Kevin M. Schultz",
            "Joseph D. Monaco"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  Dynamical systems models for controlling multi-agent swarms have demonstrated\nadvances toward resilient, decentralized navigation algorithms. We previously\nintroduced the NeuroSwarms controller, in which agent-based interactions were\nmodeled by analogy to neuronal network interactions, including attractor\ndynamics and phase synchrony, that have been theorized to operate within\nhippocampal place-cell circuits in navigating rodents. This complexity\nprecludes linear analyses of stability, controllability, and performance\ntypically used to study conventional swarm models. Further, tuning dynamical\ncontrollers by hand or grid search is often inadequate due to the complexity of\nobjectives, dimensionality of model parameters, and computational costs of\nsimulation-based sampling. Here, we present a framework for tuning dynamical\ncontroller models of autonomous multi-agent systems based on Bayesian\nOptimization (BayesOpt). Our approach utilizes a task-dependent objective\nfunction to train Gaussian Processes (GPs) as surrogate models to achieve\nadaptive and efficient exploration of a dynamical controller model's parameter\nspace. We demonstrate this approach by studying an objective function selecting\nfor NeuroSwarms behaviors that cooperatively localize and capture spatially\ndistributed rewards under time pressure. We generalized task performance across\nenvironments by combining scores for simulations in distinct geometries. To\nvalidate search performance, we compared high-dimensional clustering for high-\nvs. low-likelihood parameter points by visualizing sample trajectories in\nUniform Manifold Approximation and Projection (UMAP) embeddings. Our findings\nshow that adaptive, sample-efficient evaluation of the self-organizing\nbehavioral capacities of complex systems, including dynamical swarm\ncontrollers, can accelerate the translation of neuroscientific theory to\napplied domains.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.00599v1"
    },
    {
        "title": "Renewable energy integration and microgrid energy trading using\n  multi-agent deep reinforcement learning",
        "authors": [
            "Daniel J. B. Harrold",
            "Jun Cao",
            "Zhong Fan"
        ],
        "category": "cs.MA",
        "published_year": "2021",
        "summary": "  In this paper, multi-agent reinforcement learning is used to control a hybrid\nenergy storage system working collaboratively to reduce the energy costs of a\nmicrogrid through maximising the value of renewable energy and trading. The\nagents must learn to control three different types of energy storage system\nsuited for short, medium, and long-term storage under fluctuating demand,\ndynamic wholesale energy prices, and unpredictable renewable energy generation.\nTwo case studies are considered: the first looking at how the energy storage\nsystems can better integrate renewable energy generation under dynamic pricing,\nand the second with how those same agents can be used alongside an aggregator\nagent to sell energy to self-interested external microgrids looking to reduce\ntheir own energy bills. This work found that the centralised learning with\ndecentralised execution of the multi-agent deep deterministic policy gradient\nand its state-of-the-art variants allowed the multi-agent methods to perform\nsignificantly better than the control from a single global agent. It was also\nfound that using separate reward functions in the multi-agent approach\nperformed much better than using a single control agent. Being able to trade\nwith the other microgrids, rather than just selling back to the utility grid,\nalso was found to greatly increase the grid's savings.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.10898v2"
    },
    {
        "title": "CTMSTOU driven markets: simulated environment for regime-awareness in\n  trading policies",
        "authors": [
            "Selim Amrouni",
            "Aymeric Moulin",
            "Tucker Balch"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Market regimes is a popular topic in quantitative finance even though there\nis little consensus on the details of how they should be defined. They arise as\na feature both in financial market prediction problems and financial market\ntask performing problems.\n  In this work we use discrete event time multi-agent market simulation to\nfreely experiment in a reproducible and understandable environment where\nregimes can be explicitly switched and enforced.\n  We introduce a novel stochastic process to model the fundamental value\nperceived by market participants: Continuous-Time Markov Switching Trending\nOrnstein-Uhlenbeck (CTMSTOU), which facilitates the study of trading policies\nin regime switching markets.\n  We define the notion of regime-awareness for a trading agent as well and\nillustrate its importance through the study of different order placement\nstrategies in the context of order execution problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.00941v2"
    },
    {
        "title": "HCMD-zero: Learning Value Aligned Mechanisms from Data",
        "authors": [
            "Jan Balaguer",
            "Raphael Koster",
            "Ari Weinstein",
            "Lucy Campbell-Gillingham",
            "Christopher Summerfield",
            "Matthew Botvinick",
            "Andrea Tacchetti"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Artificial learning agents are mediating a larger and larger number of\ninteractions among humans, firms, and organizations, and the intersection\nbetween mechanism design and machine learning has been heavily investigated in\nrecent years. However, mechanism design methods often make strong assumptions\non how participants behave (e.g. rationality), on the kind of knowledge\ndesigners have access to a priori (e.g. access to strong baseline mechanisms),\nor on what the goal of the mechanism should be (e.g. total welfare). Here we\nintroduce HCMD-zero, a general purpose method to construct mechanisms making\nnone of these three assumptions. HCMD-zero learns to mediate interactions among\nparticipants and adjusts the mechanism parameters to make itself more likely to\nbe preferred by participants. It does so by remaining engaged in an electoral\ncontest with copies of itself, thereby accessing direct feedback from\nparticipants. We test our method on a stylized resource allocation game that\nhighlights the tension between productivity, equality and the temptation to\nfree ride. HCMD-zero produces a mechanism that is preferred by human\nparticipants over a strong baseline, it does so automatically, without\nrequiring prior knowledge, and using human behavioral trajectories sparingly\nand effectively. Our analysis shows HCMD-zero consistently makes the mechanism\npolicy more and more likely to be preferred by human participants over the\ncourse of training, and that it results in a mechanism with an interpretable\nand intuitive policy.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10122v2"
    },
    {
        "title": "The Good Shepherd: An Oracle Agent for Mechanism Design",
        "authors": [
            "Jan Balaguer",
            "Raphael Koster",
            "Christopher Summerfield",
            "Andrea Tacchetti"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  From social networks to traffic routing, artificial learning agents are\nplaying a central role in modern institutions. We must therefore understand how\nto leverage these systems to foster outcomes and behaviors that align with our\nown values and aspirations. While multiagent learning has received considerable\nattention in recent years, artificial agents have been primarily evaluated when\ninteracting with fixed, non-learning co-players. While this evaluation scheme\nhas merit, it fails to capture the dynamics faced by institutions that must\ndeal with adaptive and continually learning constituents. Here we address this\nlimitation, and construct agents (\"mechanisms\") that perform well when\nevaluated over the learning trajectory of their adaptive co-players\n(\"participants\"). The algorithm we propose consists of two nested learning\nloops: an inner loop where participants learn to best respond to fixed\nmechanisms; and an outer loop where the mechanism agent updates its policy\nbased on experience. We report the performance of our mechanism agents when\npaired with both artificial learning agents and humans as co-players. Our\nresults show that our mechanisms are able to shepherd the participants\nstrategies towards favorable outcomes, indicating a path for modern\ninstitutions to effectively and automatically influence the strategies and\nbehaviors of their constituents.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10135v1"
    },
    {
        "title": "Decentralized Safe Multi-agent Stochastic Optimal Control using Deep\n  FBSDEs and ADMM",
        "authors": [
            "Marcus A. Pereira",
            "Augustinos D. Saravanos",
            "Oswin So",
            "Evangelos A. Theodorou"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In this work, we propose a novel safe and scalable decentralized solution for\nmulti-agent control in the presence of stochastic disturbances. Safety is\nmathematically encoded using stochastic control barrier functions and safe\ncontrols are computed by solving quadratic programs. Decentralization is\nachieved by augmenting to each agent's optimization variables, copy variables,\nfor its neighbors. This allows us to decouple the centralized multi-agent\noptimization problem. However, to ensure safety, neighboring agents must agree\non \"what is safe for both of us\" and this creates a need for consensus. To\nenable safe consensus solutions, we incorporate an ADMM-based approach.\nSpecifically, we propose a Merged CADMM-OSQP implicit neural network layer,\nthat solves a mini-batch of both, local quadratic programs as well as the\noverall consensus problem, as a single optimization problem. This layer is\nembedded within a Deep FBSDEs network architecture at every time step, to\nfacilitate end-to-end differentiable, safe and decentralized stochastic optimal\ncontrol. The efficacy of the proposed approach is demonstrated on several\nchallenging multi-robot tasks in simulation. By imposing requirements on safety\nspecified by collision avoidance constraints, the safe operation of all agents\nis ensured during the entire training process. We also demonstrate superior\nscalability in terms of computational and memory savings as compared to a\ncentralized approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.10658v2"
    },
    {
        "title": "Secure Distributed/Federated Learning: Prediction-Privacy Trade-Off for\n  Multi-Agent System",
        "authors": [
            "Mohamed Ridha Znaidi",
            "Gaurav Gupta",
            "Paul Bogdan"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Decentralized learning is an efficient emerging paradigm for boosting the\ncomputing capability of multiple bounded computing agents. In the big data era,\nperforming inference within the distributed and federated learning (DL and FL)\nframeworks, the central server needs to process a large amount of data while\nrelying on various agents to perform multiple distributed training tasks.\nConsidering the decentralized computing topology, privacy has become a\nfirst-class concern. Moreover, assuming limited information processing\ncapability for the agents calls for a sophisticated \\textit{privacy-preserving\ndecentralization} that ensures efficient computation. Towards this end, we\nstudy the \\textit{privacy-aware server to multi-agent assignment} problem\nsubject to information processing constraints associated with each agent, while\nmaintaining the privacy and assuring learning informative messages received by\nagents about a global terminal through the distributed private federated\nlearning (DPFL) approach. To find a decentralized scheme for a two-agent\nsystem, we formulate an optimization problem that balances privacy and\naccuracy, taking into account the quality of compression constraints associated\nwith each agent. We propose an iterative converging algorithm by alternating\nover self-consistent equations. We also numerically evaluate the proposed\nsolution to show the privacy-prediction trade-off and demonstrate the efficacy\nof the novel approach in ensuring privacy in DL and FL.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.04855v1"
    },
    {
        "title": "A general framework for optimising cost-effectiveness of pandemic\n  response under partial intervention measures",
        "authors": [
            "Quang Dang Nguyen",
            "Mikhail Prokopenko"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  The COVID-19 pandemic created enormous public health and socioeconomic\nchallenges. The health effects of vaccination and non-pharmaceutical\ninterventions (NPIs) were often contrasted with significant social and economic\ncosts. We describe a general framework aimed to derive adaptive cost-effective\ninterventions, adequate for both recent and emerging pandemic threats. We also\nquantify the net health benefits and propose a reinforcement learning approach\nto optimise adaptive NPIs. The approach utilises an agent-based model\nsimulating pandemic responses in Australia, and accounts for a heterogeneous\npopulation with variable levels of compliance fluctuating over time and across\nindividuals. Our analysis shows that a significant net health benefit may be\nattained by adaptive NPIs formed by partial social distancing measures, coupled\nwith moderate levels of the society's willingness to pay for health gains\n(health losses averted). We demonstrate that a socially acceptable balance\nbetween health effects and incurred economic costs is achievable over a long\nterm, despite possible early setbacks.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08996v2"
    },
    {
        "title": "Multi-Scale Asset Distribution Model for Dynamic Environments",
        "authors": [
            "Payam Zahadat",
            "Ada Diaconescu"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  In many self-organising systems the ability to extract necessary resources\nfrom the external environment is essential to the system's growth and survival.\nExamples include the extraction of sunlight and nutrients in organic plants, of\nmonetary income in business organisations and of mobile robots in swarm\nintelligence actions. When operating within competitive, ever-changing\nenvironments, such systems must distribute their internal assets wisely so as\nto improve and adapt their ability to extract available resources. As the\nsystem size increases, the asset-distribution process often gets organised\naround a multi-scale control topology. This topology may be static (fixed) or\ndynamic (enabling growth and structural adaptation) depending on the system's\ninternal constraints and adaptive mechanisms. In this paper, we expand on a\nplant-inspired asset-distribution model and introduce a more general\nmulti-scale model applicable across a wider range of natural and artificial\nsystem domains. We study the impact that the topology of the multi-scale\ncontrol process has upon the system's ability to self-adapt asset distribution\nwhen resource availability changes within the environment. Results show how\ndifferent topological characteristics and different competition levels between\nsystem branches impact overall system profitability, adaptation delays and\ndisturbances when environmental changes occur. These findings provide a basis\nfor system designers to select the most suitable topology and configuration for\ntheir particular application and execution environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.12063v1"
    },
    {
        "title": "A Robust and Constrained Multi-Agent Reinforcement Learning Electric\n  Vehicle Rebalancing Method in AMoD Systems",
        "authors": [
            "Sihong He",
            "Yue Wang",
            "Shuo Han",
            "Shaofeng Zou",
            "Fei Miao"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Electric vehicles (EVs) play critical roles in autonomous mobility-on-demand\n(AMoD) systems, but their unique charging patterns increase the model\nuncertainties in AMoD systems (e.g. state transition probability). Since there\nusually exists a mismatch between the training and test/true environments,\nincorporating model uncertainty into system design is of critical importance in\nreal-world applications. However, model uncertainties have not been considered\nexplicitly in EV AMoD system rebalancing by existing literature yet, and the\ncoexistence of model uncertainties and constraints that the decision should\nsatisfy makes the problem even more challenging. In this work, we design a\nrobust and constrained multi-agent reinforcement learning (MARL) framework with\nstate transition kernel uncertainty for EV AMoD systems. We then propose a\nrobust and constrained MARL algorithm (ROCOMA) with robust natural policy\ngradients (RNPG) that trains a robust EV rebalancing policy to balance the\nsupply-demand ratio and the charging utilization rate across the city under\nmodel uncertainty. Experiments show that the ROCOMA can learn an effective and\nrobust rebalancing policy. It outperforms non-robust MARL methods in the\npresence of model uncertainties. It increases the system fairness by 19.6% and\ndecreases the rebalancing costs by 75.8%.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.08230v2"
    },
    {
        "title": "Social Diversity Reduces the Complexity and Cost of Fostering Fairness",
        "authors": [
            "Theodor Cimpeanu",
            "Alessandro Di Stefano",
            "Cedric Perret",
            "The Anh Han"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Institutions and investors are constantly faced with the challenge of\nappropriately distributing endowments. No budget is limitless and optimising\noverall spending without sacrificing positive outcomes has been approached and\nresolved using several heuristics. To date, prior works have failed to consider\nhow to encourage fairness in a population where social diversity is ubiquitous,\nand in which investors can only partially observe the population. Herein, by\nincorporating social diversity in the Ultimatum game through heterogeneous\ngraphs, we investigate the effects of several interference mechanisms which\nassume incomplete information and flexible standards of fairness. We quantify\nthe role of diversity and show how it reduces the need for information\ngathering, allowing us to relax a strict, costly interference process.\nFurthermore, we find that the influence of certain individuals, expressed by\ndifferent network centrality measures, can be exploited to further reduce\nspending if minimal fairness requirements are lowered. Our results indicate\nthat diversity changes and opens up novel mechanisms available to institutions\nwishing to promote fairness. Overall, our analysis provides novel insights to\nguide institutional policies in socially diverse complex systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.10517v1"
    },
    {
        "title": "Co-evolution of Social and Non-Social Guilt",
        "authors": [
            "Theodor Cimpeanu",
            "Luis Moniz Pereira",
            "The Anh Han"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Building ethical machines may involve bestowing upon them the emotional\ncapacity to self-evaluate and repent on their actions. While reparative\nmeasures, such as apologies, are often considered as possible strategic\ninteractions, the explicit evolution of the emotion of guilt as a behavioural\nphenotype is not yet well understood. Here, we study the co-evolution of social\nand non-social guilt of homogeneous or heterogeneous populations, including\nwell-mixed, lattice and scale-free networks. Socially aware guilt comes at a\ncost, as it requires agents to make demanding efforts to observe and understand\nthe internal state and behaviour of others, while non-social guilt only\nrequires the awareness of the agents' own state and hence incurs no social\ncost. Those choosing to be non-social are however more sensitive to\nexploitation by other agents due to their social unawareness. Resorting to\nmethods from evolutionary game theory, we study analytically, and through\nextensive numerical and agent-based simulations, whether and how such social\nand non-social guilt can evolve and deploy, depending on the underlying\nstructure of the populations, or systems, of agents. The results show that, in\nboth lattice and scale-free networks, emotional guilt prone strategies are\ndominant for a larger range of the guilt and social costs incurred, compared to\nthe well-mixed population setting, leading therefore to significantly higher\nlevels of cooperation for a wider range of the costs. In structured population\nsettings, both social and non-social guilt can evolve and deploy through\nclustering with emotional prone strategies, allowing them to be protected from\nexploiters, especially in case of non-social (less costly) strategies. Overall,\nour findings provide important insights into the design and engineering of\nself-organised and distributed cooperative multi-agent systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09859v1"
    },
    {
        "title": "A Communication-efficient Local Differentially Private Algorithm in\n  Federated Optimization",
        "authors": [
            "Syed Eqbal Alam",
            "Dhirendra Shukla",
            "Shrisha Rao"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Federated optimization, wherein several agents in a network collaborate with\na central server to achieve optimal social cost over the network with no\nrequirement for exchanging information among agents, has attracted significant\ninterest from the research community. In this context, agents demand resources\nbased on their local computation. Due to the exchange of optimization\nparameters such as states, constraints, or objective functions with a central\nserver, an adversary may infer sensitive information of agents. We develop a\ndifferentially-private additive-increase and multiplicative-decrease algorithm\nto allocate multiple divisible shared heterogeneous resources to agents in a\nnetwork. The developed algorithm provides a differential privacy guarantee to\neach agent in the network. The algorithm does not require inter-agent\ncommunication, and the agents do not need to share their cost function or their\nderivatives with other agents or a central server; however, they share their\nallocation states with a central server that keeps track of the aggregate\nconsumption of resources. The algorithm incurs very little communication\noverhead; for m heterogeneous resources in the system, the asymptotic upper\nbound on the communication complexity is O(m) bits at a time step. Furthermore,\nif the algorithm converges in K time steps, then the upper bound communication\ncomplexity will be O(mK) bits. The algorithm can find applications in several\nareas, including smart cities, smart energy systems, resource management in the\nsixth generation (6G) wireless networks with privacy guarantees, etc. We\npresent experimental results to check the efficacy of the algorithm.\nFurthermore, we present empirical analyses for the trade-off between privacy\nand algorithm efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01510v2"
    },
    {
        "title": "Collective Reasoning for Safe Autonomous Systems",
        "authors": [
            "Selma Saidi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Collaboration in multi-agent autonomous systems is critical to increase\nperformance while ensuring safety. However, due to heterogeneity of their\nfeatures in, e.g., perception qualities, some autonomous systems have to be\nconsidered more trustworthy than others when contributing to collaboratively\nbuild a common environmental model, especially under uncertainty. In this\npaper, we introduce the idea of increasing the reliability of autonomous\nsystems by relying on collective intelligence. We borrow concepts from social\nepistemology to exploit individual characteristics of autonomous systems, and\ndefine and formalize at design rules for collective reasoning to achieve\ncollaboratively increased safety, trustworthiness and good decision making.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11295v1"
    },
    {
        "title": "Discriminatory or Samaritan -- which AI is needed for humanity? An\n  Evolutionary Game Theory Analysis of Hybrid Human-AI populations",
        "authors": [
            "Tim Booker",
            "Manuel Miranda",
            "Jesús A. Moreno López",
            "José María Ramos Fernández",
            "Max Reddel",
            "Valeria Widler",
            "Filippo Zimmaro",
            "Alberto Antonioni",
            "The Anh Han"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  As artificial intelligence (AI) systems are increasingly embedded in our\nlives, their presence leads to interactions that shape our behaviour,\ndecision-making, and social interactions. Existing theoretical research has\nprimarily focused on human-to-human interactions, overlooking the unique\ndynamics triggered by the presence of AI. In this paper, resorting to methods\nfrom evolutionary game theory, we study how different forms of AI influence the\nevolution of cooperation in a human population playing the one-shot Prisoner's\nDilemma game in both well-mixed and structured populations. We found that\nSamaritan AI agents that help everyone unconditionally, including defectors,\ncan promote higher levels of cooperation in humans than Discriminatory AI that\nonly help those considered worthy/cooperative, especially in slow-moving\nsocieties where change is viewed with caution or resistance (small intensities\nof selection). Intuitively, in fast-moving societies (high intensities of\nselection), Discriminatory AIs promote higher levels of cooperation than\nSamaritan AIs.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.17747v2"
    },
    {
        "title": "Robust Electric Vehicle Balancing of Autonomous Mobility-On-Demand\n  System: A Multi-Agent Reinforcement Learning Approach",
        "authors": [
            "Sihong He",
            "Shuo Han",
            "Fei Miao"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Electric autonomous vehicles (EAVs) are getting attention in future\nautonomous mobility-on-demand (AMoD) systems due to their economic and societal\nbenefits. However, EAVs' unique charging patterns (long charging time, high\ncharging frequency, unpredictable charging behaviors, etc.) make it challenging\nto accurately predict the EAVs supply in E-AMoD systems. Furthermore, the\nmobility demand's prediction uncertainty makes it an urgent and challenging\ntask to design an integrated vehicle balancing solution under supply and demand\nuncertainties. Despite the success of reinforcement learning-based E-AMoD\nbalancing algorithms, state uncertainties under the EV supply or mobility\ndemand remain unexplored. In this work, we design a multi-agent reinforcement\nlearning (MARL)-based framework for EAVs balancing in E-AMoD systems, with\nadversarial agents to model both the EAVs supply and mobility demand\nuncertainties that may undermine the vehicle balancing solutions. We then\npropose a robust E-AMoD Balancing MARL (REBAMA) algorithm to train a robust\nEAVs balancing policy to balance both the supply-demand ratio and charging\nutilization rate across the whole city. Experiments show that our proposed\nrobust method performs better compared with a non-robust MARL method that does\nnot consider state uncertainties; it improves the reward, charging utilization\nfairness, and supply-demand fairness by 19.28%, 28.18%, and 3.97%,\nrespectively. Compared with a robust optimization-based method, the proposed\nMARL algorithm can improve the reward, charging utilization fairness, and\nsupply-demand fairness by 8.21%, 8.29%, and 9.42%, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.16228v1"
    },
    {
        "title": "An Efficient Distributed Multi-Agent Reinforcement Learning for EV\n  Charging Network Control",
        "authors": [
            "Amin Shojaeighadikolaei",
            "Morteza Hashemi"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The increasing trend in adopting electric vehicles (EVs) will significantly\nimpact the residential electricity demand, which results in an increased risk\nof transformer overload in the distribution grid. To mitigate such risks, there\nare urgent needs to develop effective EV charging controllers. Currently, the\nmajority of the EV charge controllers are based on a centralized approach for\nmanaging individual EVs or a group of EVs. In this paper, we introduce a\ndecentralized Multi-agent Reinforcement Learning (MARL) charging framework that\nprioritizes the preservation of privacy for EV owners. We employ the\nCentralized Training Decentralized Execution-Deep Deterministic Policy Gradient\n(CTDE-DDPG) scheme, which provides valuable information to users during\ntraining while maintaining privacy during execution. Our results demonstrate\nthat the CTDE framework improves the performance of the charging network by\nreducing the network costs. Moreover, we show that the Peak-to-Average Ratio\n(PAR) of the total demand is reduced, which, in turn, reduces the risk of\ntransformer overload during the peak hours.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.12921v1"
    },
    {
        "title": "Collaborative Optimization of the Age of Information under Partial\n  Observability",
        "authors": [
            "Anam Tahir",
            "Kai Cui",
            "Bastian Alt",
            "Amr Rizk",
            "Heinz Koeppl"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  The significance of the freshness of sensor and control data at the receiver\nside, often referred to as Age of Information (AoI), is fundamentally\nconstrained by contention for limited network resources. Evidently, network\ncongestion is detrimental for AoI, where this congestion is partly self-induced\nby the sensor transmission process in addition to the contention from other\ntransmitting sensors. In this work, we devise a decentralized AoI-minimizing\ntransmission policy for a number of sensor agents sharing capacity-limited,\nnon-FIFO duplex channels that introduce random delays in communication with a\ncommon receiver. By implementing the same policy, however with no explicit\ninter-agent communication, the agents minimize the expected AoI in this\npartially observable system. We cater to the partial observability due to\nrandom channel delays by designing a bootstrap particle filter that\nindependently maintains a belief over the AoI of each agent. We also leverage\nmean-field control approximations and reinforcement learning to derive scalable\nand optimal solutions for minimizing the expected AoI collaboratively.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.12977v1"
    },
    {
        "title": "Multi-agent deep reinforcement learning with centralized training and\n  decentralized execution for transportation infrastructure management",
        "authors": [
            "M. Saifullah",
            "K. G. Papakonstantinou",
            "C. P. Andriotis",
            "S. M. Stoffels"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We present a multi-agent Deep Reinforcement Learning (DRL) framework for\nmanaging large transportation infrastructure systems over their life-cycle.\nLife-cycle management of such engineering systems is a computationally\nintensive task, requiring appropriate sequential inspection and maintenance\ndecisions able to reduce long-term risks and costs, while dealing with\ndifferent uncertainties and constraints that lie in high-dimensional spaces. To\ndate, static age- or condition-based maintenance methods and risk-based or\nperiodic inspection plans have mostly addressed this class of optimization\nproblems. However, optimality, scalability, and uncertainty limitations are\noften manifested under such approaches. The optimization problem in this work\nis cast in the framework of constrained Partially Observable Markov Decision\nProcesses (POMDPs), which provides a comprehensive mathematical basis for\nstochastic sequential decision settings with observation uncertainties, risk\nconsiderations, and limited resources. To address significantly large state and\naction spaces, a Deep Decentralized Multi-agent Actor-Critic (DDMAC) DRL method\nwith Centralized Training and Decentralized Execution (CTDE), termed as\nDDMAC-CTDE is developed. The performance strengths of the DDMAC-CTDE method are\ndemonstrated in a generally representative and realistic example application of\nan existing transportation network in Virginia, USA. The network includes\nseveral bridge and pavement components with nonstationary degradation,\nagency-imposed constraints, and traffic delay and risk considerations. Compared\nto traditional management policies for transportation networks, the proposed\nDDMAC-CTDE method vastly outperforms its counterparts. Overall, the proposed\nalgorithmic framework provides near optimal solutions for transportation\ninfrastructure management under real-world constraints and complexities.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.12455v1"
    },
    {
        "title": "Distributed Policy Gradient for Linear Quadratic Networked Control with\n  Limited Communication Range",
        "authors": [
            "Yuzi Yan",
            "Yuan Shen"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper proposes a scalable distributed policy gradient method and proves\nits convergence to near-optimal solution in multi-agent linear quadratic\nnetworked systems. The agents engage within a specified network under local\ncommunication constraints, implying that each agent can only exchange\ninformation with a limited number of neighboring agents. On the underlying\ngraph of the network, each agent implements its control input depending on its\nnearby neighbors' states in the linear quadratic control setting. We show that\nit is possible to approximate the exact gradient only using local information.\nCompared with the centralized optimal controller, the performance gap decreases\nto zero exponentially as the communication and control ranges increase. We also\ndemonstrate how increasing the communication range enhances system stability in\nthe gradient descent process, thereby elucidating a critical trade-off. The\nsimulation results verify our theoretical findings.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.03055v1"
    },
    {
        "title": "The Role of Confidence for Trust-based Resilient Consensus (Extended\n  Version)",
        "authors": [
            "Luca Ballotta",
            "Michal Yemini"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  We consider a multi-agent system where agents aim to achieve a consensus\ndespite interactions with malicious agents that communicate misleading\ninformation. Physical channels supporting communication in cyberphysical\nsystems offer attractive opportunities to detect malicious agents,\nnevertheless, trustworthiness indications coming from the channel are subject\nto uncertainty and need to be treated with this in mind. We propose a resilient\nconsensus protocol that incorporates trust observations from the channel and\nweighs them with a parameter that accounts for how confident an agent is\nregarding its understanding of the legitimacy of other agents in the network,\nwith no need for the initial observation window $T_0$ that has been utilized in\nprevious works. Analytical and numerical results show that (i) our protocol\nachieves a resilient consensus in the presence of malicious agents and (ii) the\nsteady-state deviation from nominal consensus can be minimized by a suitable\nchoice of the confidence parameter that depends on the statistics of trust\nobservations.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.07838v1"
    },
    {
        "title": "Distributed Model Predictive Control for Heterogeneous Platoons with\n  Affine Spacing Policies and Arbitrary Communication Topologies",
        "authors": [
            "Michael H. Shaham",
            "Taskin Padir"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper presents a distributed model predictive control (DMPC) algorithm\nfor a heterogeneous platoon using arbitrary communication topologies, provided\neach vehicle can communicate with a preceding vehicle in the platoon. The\nproposed DMPC algorithm can accommodate any spacing policy that is affine in a\nvehicle's velocity, which includes constant distance or constant time headway\nspacing policies. By analyzing the total cost for the entire platoon, a\nsufficient condition is derived to ensure platoon asymptotic stability.\nSimulation experiments with a platoon of 50 vehicles and hardware experiments\nwith a platoon of four 1/10th-scale vehicles validate the algorithm and compare\nperformance under different spacing policies and communication topologies.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.12441v2"
    },
    {
        "title": "LLM-based Multi-Agent Reinforcement Learning: Current and Future\n  Directions",
        "authors": [
            "Chuanneng Sun",
            "Songjun Huang",
            "Dario Pompili"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In recent years, Large Language Models (LLMs) have shown great abilities in\nvarious tasks, including question answering, arithmetic problem solving, and\npoem writing, among others. Although research on LLM-as-an-agent has shown that\nLLM can be applied to Reinforcement Learning (RL) and achieve decent results,\nthe extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as\nmany aspects, such as coordination and communication between agents, are not\nconsidered in the RL frameworks of a single agent. To inspire more research on\nLLM-based MARL, in this letter, we survey the existing LLM-based single-agent\nand multi-agent RL frameworks and provide potential research directions for\nfuture research. In particular, we focus on the cooperative tasks of multiple\nagents with a common goal and communication among them. We also consider\nhuman-in/on-the-loop scenarios enabled by the language component in the\nframework.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.11106v1"
    },
    {
        "title": "Reconfigurable Intelligent Surface Assisted VEC Based on Multi-Agent\n  Reinforcement Learning",
        "authors": [
            "Kangwei Qi",
            "Qiong Wu",
            "Pingyi Fan",
            "Nan Cheng",
            "Qiang Fan",
            "Jiangzhou Wang"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Vehicular edge computing (VEC) is an emerging technology that enables\nvehicles to perform high-intensity tasks by executing tasks locally or\noffloading them to nearby edge devices. However, obstacles such as buildings\nmay degrade the communications and incur communication interruptions, and thus\nthe vehicle may not meet the requirement for task offloading. Reconfigurable\nintelligent surfaces (RIS) is introduced to support vehicle communication and\nprovide an alternative communication path. The system performance can be\nimproved by flexibly adjusting the phase-shift of the RIS. For RIS-assisted VEC\nsystem where tasks arrive randomly, we design a control scheme that considers\noffloading power, local power allocation and phase-shift optimization. To solve\nthis non-convex problem, we propose a new deep reinforcement learning (DRL)\nframework that employs modified multi-agent deep deterministic policy gradient\n(MADDPG) approach to optimize the power allocation for vehicle users (VUs) and\nblock coordinate descent (BCD) algorithm to optimize the phase-shift of the\nRIS. Simulation results show that our proposed scheme outperforms the\ncentralized deep deterministic policy gradient (DDPG) scheme and random scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.11318v1"
    },
    {
        "title": "Self-Supervised Inference of Agents in Trustless Environments",
        "authors": [
            "Vladyslav Larin",
            "Ivan Nikitin",
            "Alexander Firsov"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  In this paper, we propose a novel approach where agents can form swarms to\nproduce high-quality responses effectively. This is accomplished by utilizing\nagents capable of data inference and ranking, which can be effectively\nimplemented using LLMs as response classifiers. We assess existing approaches\nfor trustless agent inference, define our methodology, estimate practical\nparameters, and model various types of malicious agent attacks. Our method\nleverages the collective intelligence of swarms, ensuring robust and efficient\ndecentralized AI inference with better accuracy, security, and reliability. We\nshow that our approach is an order of magnitude faster than other trustless\ninference strategies reaching less than 125 ms validation latency.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.08386v1"
    },
    {
        "title": "Scalable spectral representations for multi-agent reinforcement learning\n  in network MDPs",
        "authors": [
            "Zhaolin Ren",
            "Runyu Zhang",
            "Bo Dai",
            "Na Li"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Network Markov Decision Processes (MDPs), a popular model for multi-agent\ncontrol, pose a significant challenge to efficient learning due to the\nexponential growth of the global state-action space with the number of agents.\nIn this work, utilizing the exponential decay property of network dynamics, we\nfirst derive scalable spectral local representations for network MDPs, which\ninduces a network linear subspace for the local $Q$-function of each agent.\nBuilding on these local spectral representations, we design a scalable\nalgorithmic framework for continuous state-action network MDPs, and provide\nend-to-end guarantees for the convergence of our algorithm. Empirically, we\nvalidate the effectiveness of our scalable representation-based approach on two\nbenchmark problems, and demonstrate the advantages of our approach over generic\nfunction approximation approaches to representing the local $Q$-functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.17221v2"
    },
    {
        "title": "Cooperative Cruising: Reinforcement Learning based Time-Headway Control\n  for Increased Traffic Efficiency",
        "authors": [
            "Yaron Veksler",
            "Sharon Hornstein",
            "Han Wang",
            "Maria Laura Delle Monache",
            "Daniel Urieli"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  The proliferation of Connected Automated Vehicles represents an unprecedented\nopportunity for improving driving efficiency and alleviating traffic\ncongestion. However, existing research fails to address realistic multi-lane\nhighway scenarios without assuming connectivity, perception, and control\ncapabilities that are typically unavailable in current vehicles. This paper\nproposes a novel AI system that is the first to improve highway traffic\nefficiency compared with human-like traffic in realistic, simulated multi-lane\nscenarios, while relying on existing connectivity, perception, and control\ncapabilities. At the core of our approach is a reinforcement learning based\ncontroller that dynamically communicates time-headways to automated vehicles\nnear bottlenecks based on real-time traffic conditions. These desired\ntime-headways are then used by Adaptive Cruise Control (ACC) systems to adjust\ntheir following distance. By (i) integrating existing traffic estimation\ntechnology and low-bandwidth vehicle-to-infrastructure connectivity, (ii)\nleveraging safety-certified ACC systems, and (iii) targeting localized\nbottleneck challenges that can be addressed independently in different\nlocations, we propose a practical, safe, and scalable system that can\npositively impact numerous road users.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.02520v1"
    },
    {
        "title": "General Principles of Learning-Based Multi-Agent Systems",
        "authors": [
            "David H. Wolpert",
            "Kevin R. Wheeler",
            "Kagan Tumer"
        ],
        "category": "cs.MA",
        "published_year": "1999",
        "summary": "  We consider the problem of how to design large decentralized multi-agent\nsystems (MAS's) in an automated fashion, with little or no hand-tuning. Our\napproach has each agent run a reinforcement learning algorithm. This converts\nthe problem into one of how to automatically set/update the reward functions\nfor each of the agents so that the global goal is achieved. In particular we do\nnot want the agents to ``work at cross-purposes'' as far as the global goal is\nconcerned. We use the term artificial COllective INtelligence (COIN) to refer\nto systems that embody solutions to this problem. In this paper we present a\nsummary of a mathematical framework for COINs. We then investigate the\nreal-world applicability of the core concepts of that framework via two\ncomputer experiments: we show that our COINs perform near optimally in a\ndifficult variant of Arthur's bar problem (and in particular avoid the tragedy\nof the commons for that problem), and we also illustrate optimal performance\nfor our COINs in the leader-follower problem.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9905005v1"
    },
    {
        "title": "Bayesian Heuristics for Group Decisions",
        "authors": [
            "M. Amin Rahimian",
            "Ali Jadbabaie"
        ],
        "category": "cs.MA",
        "published_year": "2016",
        "summary": "  We propose a model of inference and heuristic decision-making in groups that\nis rooted in the Bayes rule but avoids the complexities of rational inference\nin partially observed environments with incomplete information, which are\ncharacteristic of group interactions. Our model is also consistent with a\ndual-process psychological theory of thinking: the group members behave\nrationally at the initiation of their interactions with each other (the slow\nand deliberative mode); however, in the ensuing decision epochs, they rely on a\nheuristic that replicates their experiences from the first stage (the fast\nautomatic mode). We specialize this model to a group decision scenario where\nprivate observations are received at the beginning, and agents aim to take the\nbest action given the aggregate observations of all group members. We study the\nimplications of the information structure together with the properties of the\nprobability distributions which determine the structure of the so-called\n\"Bayesian heuristics\" that the agents follow in our model. We also analyze the\ngroup decision outcomes in two classes of linear action updates and log-linear\nbelief updates and show that many inefficiencies arise in group decisions as a\nresult of repeated interactions between individuals, leading to overconfident\nbeliefs as well as choice-shifts toward extremes. Nevertheless, balanced\nregular structures demonstrate a measure of efficiency in terms of aggregating\nthe initial information of individuals. These results not only verify some\nwell-known insights about group decision-making but also complement these\ninsights by revealing additional mechanistic interpretations for the group\ndeclension-process, as well as psychological and cognitive intuitions about the\ngroup interaction model.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.01006v1"
    },
    {
        "title": "Distributed Adaptive Control: An ideal Cognitive Architecture candidate\n  for managing a robotic recycling plant",
        "authors": [
            "Oscar Guerrero-Rosado",
            "Paul Verschure"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  In the past decade, society has experienced notable growth in a variety of\ntechnological areas. However, the Fourth Industrial Revolution has not been\nembraced yet. Industry 4.0 imposes several challenges which include the\nnecessity of new architectural models to tackle the uncertainty that open\nenvironments represent to cyber-physical systems (CPS). Waste Electrical and\nElectronic Equipment (WEEE) recycling plants stand for one of such open\nenvironments. Here, CPSs must work harmoniously in a changing environment,\ninteracting with similar and not so similar CPSs, and adaptively collaborating\nwith human workers. In this paper, we support the Distributed Adaptive Control\n(DAC) theory as a suitable Cognitive Architecture for managing a recycling\nplant. Specifically, a recursive implementation of DAC (between both\nsingle-agent and large-scale levels) is proposed to meet the expected demands\nof the European Project HR-Recycler. Additionally, with the aim of having a\nrealistic benchmark for future implementations of the recursive DAC, a\nmicro-recycling plant prototype is presented.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.12586v1"
    },
    {
        "title": "Emergence of Writing Systems Through Multi-Agent Cooperation",
        "authors": [
            "Shresth Verma",
            "Joydip Dhar"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  Learning to communicate is considered an essential task to develop a general\nAI. While recent literature in language evolution has studied emergent language\nthrough discrete or continuous message symbols, there has been little work in\nthe emergence of writing systems in artificial agents. In this paper, we\npresent a referential game setup with two agents, where the mode of\ncommunication is a written language system that emerges during the play. We\nshow that the agents can learn to coordinate successfully using this mode of\ncommunication. Further, we study how the game rules affect the writing system\ntaxonomy by proposing a consistency metric.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.00741v1"
    },
    {
        "title": "Distributed interference cancellation in multi-agent scenarios",
        "authors": [
            "Mahdi Shamsi",
            "Alireza Moslemi Haghighi",
            "Farokh Marvasti"
        ],
        "category": "cs.MA",
        "published_year": "2019",
        "summary": "  This paper considers the problem of detecting impaired and noisy nodes over\nnetwork. In a distributed algorithm, lots of processing units are incorporating\nand communicating with each other to reach a global goal. Due to each one's\nstate in the shared environment, they can help the other nodes or mislead them\n(due to noise or a deliberate attempt). Previous works mainly focused on proper\nlocating agents and weight assignment based on initial environment state to\nminimize malfunctioning of noisy nodes. We propose an algorithm to be able to\nadapt sharing weights according to behavior of the agents. Applying the\nintroduced algorithm to a multi-agent RL scenario and the well-known diffusion\nLMS demonstrates its capability and generality.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.10109v1"
    },
    {
        "title": "Multi-UAV Path Planning for Wireless Data Harvesting with Deep\n  Reinforcement Learning",
        "authors": [
            "Harald Bayerlein",
            "Mirco Theile",
            "Marco Caccamo",
            "David Gesbert"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  Harvesting data from distributed Internet of Things (IoT) devices with\nmultiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem\nrequiring flexible path planning methods. We propose a multi-agent\nreinforcement learning (MARL) approach that, in contrast to previous work, can\nadapt to profound changes in the scenario parameters defining the data\nharvesting mission, such as the number of deployed UAVs, number, position and\ndata amount of IoT devices, or the maximum flying time, without the need to\nperform expensive recomputations or relearn control policies. We formulate the\npath planning problem for a cooperative, non-communicating, and homogeneous\nteam of UAVs tasked with maximizing collected data from distributed IoT sensor\nnodes subject to flying time and collision avoidance constraints. The path\nplanning problem is translated into a decentralized partially observable Markov\ndecision process (Dec-POMDP), which we solve through a deep reinforcement\nlearning (DRL) approach, approximating the optimal UAV control policy without\nprior knowledge of the challenging wireless channel characteristics in dense\nurban environments. By exploiting a combination of centered global and local\nmap representations of the environment that are fed into convolutional layers\nof the agents, we show that our proposed network architecture enables the\nagents to cooperate effectively by carefully dividing the data collection task\namong themselves, adapt to large complex environments and state spaces, and\nmake movement decisions that balance data collection goals, flight-time\nefficiency, and navigation constraints. Finally, learning a control policy that\ngeneralizes over the scenario parameter space enables us to analyze the\ninfluence of individual parameters on collection performance and provide some\nintuition about system-level benefits.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.12461v3"
    },
    {
        "title": "Pooling for First and Last Mile: Integrating Carpooling and Transit",
        "authors": [
            "Andrea Araldo",
            "André de Palma",
            "Souhila Arib",
            "Vincent Gauthier",
            "Romain Sere",
            "Youssef Chaabouni",
            "Oussama Kharouaa",
            "Ado Adamou Abba Ari"
        ],
        "category": "cs.MA",
        "published_year": "2020",
        "summary": "  While carpooling is widely adopted for long travels, it is by construction\ninefficient for daily commuting, where it is difficult to match drivers and\nriders, sharing similar origin, destination and time. To overcome this\nlimitation, we present an Integrated system, which integrates carpooling into\ntransit, in the line of the philosophy of Mobility as a Service. Carpooling\nacts as feeder to transit and transit stations act as consolidation points,\nwhere trips of riders and drivers meet, increasing potential matching. We\npresent algorithms to construct multimodal rider trips (including transit and\ncarpooling legs) and driver detours. Simulation shows that our Integrated\nsystem increases transit ridership and reduces auto-dependency, with respect to\ncurrent practice, in which carpooling and transit are operated separately.\nIndeed, the Integrated system decreases the number of riders who are left with\nno feasible travel option and would thus be forced to use private cars. The\nsimulation code is available as open source.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.13438v2"
    },
    {
        "title": "Distributed Cooperative Multi-Agent Reinforcement Learning with Directed\n  Coordination Graph",
        "authors": [
            "Gangshan Jing",
            "He Bai",
            "Jemin George",
            "Aranya Chakrabortty",
            "Piyush. K. Sharma"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  Existing distributed cooperative multi-agent reinforcement learning (MARL)\nframeworks usually assume undirected coordination graphs and communication\ngraphs while estimating a global reward via consensus algorithms for policy\nevaluation. Such a framework may induce expensive communication costs and\nexhibit poor scalability due to requirement of global consensus. In this work,\nwe study MARLs with directed coordination graphs, and propose a distributed RL\nalgorithm where the local policy evaluations are based on local value\nfunctions. The local value function of each agent is obtained by local\ncommunication with its neighbors through a directed learning-induced\ncommunication graph, without using any consensus algorithm. A zeroth-order\noptimization (ZOO) approach based on parameter perturbation is employed to\nachieve gradient estimation. By comparing with existing ZOO-based RL\nalgorithms, we show that our proposed distributed RL algorithm guarantees high\nscalability. A distributed resource allocation example is shown to illustrate\nthe effectiveness of our algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.04962v1"
    },
    {
        "title": "Multi-Agent Shape Control with Optimal Transport",
        "authors": [
            "Alex Tong Lin",
            "Stanley J. Osher"
        ],
        "category": "cs.MA",
        "published_year": "2022",
        "summary": "  We introduce a method called MASCOT (Multi-Agent Shape Control with Optimal\nTransport) to compute optimal control solutions of agents with\nshape/formation/density constraints. For example, we might want to apply shape\nconstraints on the agents -- perhaps we desire the agents to hold a particular\nshape along the path, or we want agents to spread out in order to minimize\ncollisions. We might also want a proportion of agents to move to one\ndestination, while the other agents move to another, and to do this in the\noptimal way, i.e. the source-destination assignments should be optimal. In\norder to achieve this, we utilize the Earth Mover's Distance from Optimal\nTransport to distribute the agents into their proper positions so that certain\nshapes can be satisfied. This cost is both introduced in the terminal cost and\nin the running cost of the optimal control problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.00129v2"
    },
    {
        "title": "A Hierarchical Game-Theoretic Decision-Making for Cooperative\n  Multi-Agent Systems Under the Presence of Adversarial Agents",
        "authors": [
            "Qin Yang",
            "Ramviyas Parasuraman"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  Underlying relationships among Multi-Agent Systems (MAS) in hazardous\nscenarios can be represented as Game-theoretic models. This paper proposes a\nnew hierarchical network-based model called Game-theoretic Utility Tree (GUT),\nwhich decomposes high-level strategies into executable low-level actions for\ncooperative MAS decisions. It combines with a new payoff measure based on agent\nneeds for real-time strategy games. We present an Explore game domain, where we\nmeasure the performance of MAS achieving tasks from the perspective of\nbalancing the success probability and system costs. We evaluate the GUT\napproach against state-of-the-art methods that greedily rely on rewards of the\ncomposite actions. Conclusive results on extensive numerical simulations\nindicate that GUT can organize more complex relationships among MAS\ncooperation, helping the group achieve challenging tasks with lower costs and\nhigher winning rates. Furthermore, we demonstrated the applicability of the GUT\nusing the simulator-hardware testbed - Robotarium. The performances verified\nthe effectiveness of the GUT in the real robot application and validated that\nthe GUT could effectively organize MAS cooperation strategies, helping the\ngroup with fewer advantages achieve higher performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.16641v1"
    },
    {
        "title": "Networked Communication for Decentralised Agents in Mean-Field Games",
        "authors": [
            "Patrick Benjamin",
            "Alessandro Abate"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We introduce networked communication to the mean-field game framework, in\nparticular to oracle-free settings where $N$ decentralised agents learn along a\nsingle, non-episodic run of the empirical system. We prove that our\narchitecture has sample guarantees bounded between those of the centralised-\nand independent-learning cases. We provide the order of the difference in these\nbounds in terms of network structure and number of communication rounds, and\nalso contribute a policy-update stability guarantee. We discuss how the sample\nguarantees of the three theoretical algorithms do not actually result in\npractical convergence. We therefore show that in practical settings where the\ntheoretical parameters are not observed (leading to poor estimation of the\nQ-function), our communication scheme significantly accelerates convergence\nover the independent case (and sometimes even the centralised case), without\nrelying on the assumption of a centralised learner. We contribute further\npractical enhancements to all three theoretical algorithms, allowing us to\npresent their first empirical demonstrations. Our experiments confirm that we\ncan remove several of the theoretical assumptions of the algorithms, and\ndisplay the empirical convergence benefits brought by our new networked\ncommunication. We additionally show that the networked approach has significant\nadvantages, over both the centralised and independent alternatives, in terms of\nrobustness to unexpected learning failures and to changes in population size.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.02766v4"
    },
    {
        "title": "Evolutionary game theory: the mathematics of evolution and collective\n  behaviours",
        "authors": [
            "The Anh Han"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  This brief discusses evolutionary game theory as a powerful and unified\nmathematical tool to study evolution of collective behaviours. It summarises\nsome of my recent research directions using evolutionary game theory methods,\nwhich include i) the analysis of statistical properties of the number of\n(stable) equilibria in a random evolutionary game, and ii) the modelling of\nsafety behaviours' evolution and the risk posed by advanced Artificial\nIntelligence technologies in a technology development race. Finally, it\nincludes an outlook and some suggestions for future researchers.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.14480v1"
    },
    {
        "title": "A Polarization Opinion Model Inspired by Bounded Confidence\n  Communications",
        "authors": [
            "Jacek Cyranka",
            "Piotr B. Mucha"
        ],
        "category": "cs.MA",
        "published_year": "2023",
        "summary": "  We present an opinion model founded upon the principles of the bounded\nconfidence interaction among agents. Our objective is to explain the\npolarization effects inherent to vector-valued opinions. The evolutionary\nprocess adheres to the rule where each agent aspires to increase polarization\nthrough communication with a single friend during each discrete time step. The\ndynamics ensure that agents' ultimate (temporal) configuration will encompass a\nfinite number of outlier states. We introduce deterministic and stochastic\nmodels, accompanied by a comprehensive mathematical analysis of their inherent\nproperties. Additionally, we provide compelling illustrative examples and\nintroduce a stochastic solver tailored for scenarios featuring an extensive set\nof agents. Furthermore, in the context of smaller agent populations, we\nscrutinize the suitability of neural networks for the rapid inference of limit\nconfigurations.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.14599v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning with Control-Theoretic Safety\n  Guarantees for Dynamic Network Bridging",
        "authors": [
            "Raffaele Galliera",
            "Konstantinos Mitsopoulos",
            "Niranjan Suri",
            "Raffaele Romagnoli"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Addressing complex cooperative tasks in safety-critical environments poses\nsignificant challenges for Multi-Agent Systems, especially under conditions of\npartial observability. This work introduces a hybrid approach that integrates\nMulti-Agent Reinforcement Learning with control-theoretic methods to ensure\nsafe and efficient distributed strategies. Our contributions include a novel\nsetpoint update algorithm that dynamically adjusts agents' positions to\npreserve safety conditions without compromising the mission's objectives.\nThrough experimental validation, we demonstrate significant advantages over\nconventional MARL strategies, achieving comparable task performance with zero\nsafety violations. Our findings indicate that integrating safe control with\nlearning approaches not only enhances safety compliance but also achieves good\nperformance in mission objectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.01551v1"
    },
    {
        "title": "Opinion Dynamics with Set-Based Confidence: Convergence Criteria and\n  Periodic Solutions",
        "authors": [
            "Iryna Zabarianska",
            "Anton V. Proskurnikov"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  This paper introduces a new multidimensional extension of the\nHegselmann-Krause (HK) opinion dynamics model, where opinion proximity is not\ndetermined by a norm or metric. Instead, each agent trusts opinions within the\nMinkowski sum $\\xi+\\mathcal{O}$, where $\\xi$ is the agent's current opinion and\n$\\mathcal{O}$ is the confidence set defining acceptable deviations. During each\niteration, agents update their opinions by simultaneously averaging the trusted\nopinions. Unlike traditional HK systems, where $\\mathcal{O}$ is a ball in some\nnorm, our model allows the confidence set to be non-convex and even unbounded.\n  We demonstrate that the new model, referred to as SCOD (Set-based Confidence\nOpinion Dynamics), can exhibit properties absent in the conventional HK model.\nSome solutions may converge to non-equilibrium points in the state space, while\nothers oscillate periodically. These ``pathologies'' disappear if the set\n$\\mathcal{O}$ is symmetric and contains zero in its interior: similar to the\nusual HK model, SCOD then converges in a finite number of iterations to one of\nthe equilibrium points. The latter property is also preserved if one agent is\n\"stubborn\" and resists changing their opinion, yet still influences the others;\nhowever, two stubborn agents can lead to oscillations.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.01753v1"
    },
    {
        "title": "Decentralized Mobile Target Tracking Using Consensus-Based Estimation\n  with Nearly-Constant-Velocity Modeling",
        "authors": [
            "Amir Ahmad Ghods",
            "Mohammadreza Doostmohammadian"
        ],
        "category": "cs.MA",
        "published_year": "2024",
        "summary": "  Mobile target tracking is crucial in various applications such as\nsurveillance and autonomous navigation. This study presents a decentralized\ntracking framework utilizing a Consensus-Based Estimation Filter (CBEF)\nintegrated with the Nearly-Constant-Velocity (NCV) model to predict a moving\ntarget's state. The framework facilitates agents in a network to\ncollaboratively estimate the target's position by sharing local observations\nand achieving consensus despite communication constraints and measurement\nnoise. A saturation-based filtering technique is employed to enhance robustness\nby mitigating the impact of noisy sensor data. Simulation results demonstrate\nthat the proposed method effectively reduces the Mean Squared Estimation Error\n(MSEE) over time, indicating improved estimation accuracy and reliability. The\nfindings underscore the effectiveness of the CBEF in decentralized\nenvironments, highlighting its scalability and resilience in the presence of\nuncertainties.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.03095v1"
    },
    {
        "title": "ADAGE: A generic two-layer framework for adaptive agent based modelling",
        "authors": [
            "Benjamin Patrick Evans",
            "Sihan Zeng",
            "Sumitra Ganesh",
            "Leo Ardon"
        ],
        "category": "cs.MA",
        "published_year": "2025",
        "summary": "  Agent-based models (ABMs) are valuable for modelling complex, potentially\nout-of-equilibria scenarios. However, ABMs have long suffered from the Lucas\ncritique, stating that agent behaviour should adapt to environmental changes.\nFurthermore, the environment itself often adapts to these behavioural changes,\ncreating a complex bi-level adaptation problem. Recent progress integrating\nmulti-agent reinforcement learning into ABMs introduces adaptive agent\nbehaviour, beginning to address the first part of this critique, however, the\napproaches are still relatively ad hoc, lacking a general formulation, and\nfurthermore, do not tackle the second aspect of simultaneously adapting\nenvironmental level characteristics in addition to the agent behaviours. In\nthis work, we develop a generic two-layer framework for ADaptive AGEnt based\nmodelling (ADAGE) for addressing these problems. This framework formalises the\nbi-level problem as a Stackelberg game with conditional behavioural policies,\nproviding a consolidated framework for adaptive agent-based modelling based on\nsolving a coupled set of non-linear equations. We demonstrate how this generic\napproach encapsulates several common (previously viewed as distinct) ABM tasks,\nsuch as policy design, calibration, scenario generation, and robust behavioural\nlearning under one unified framework. We provide example simulations on\nmultiple complex economic and financial environments, showing the strength of\nthe novel framework under these canonical settings, addressing long-standing\ncritiques of traditional ABMs.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.09429v1"
    }
]