[
    {
        "title": "Developing numerical libraries in Java",
        "authors": [
            "Ronald F. Boisvert",
            "Jack J. Dongarra",
            "Roldan Pozo",
            "Karin Remington",
            "G. W. Stewart"
        ],
        "category": "cs.MS",
        "published_year": "1998",
        "summary": "  The rapid and widespread adoption of Java has created a demand for reliable\nand reusable mathematical software components to support the growing number of\ncompute-intensive applications now under development, particularly in science\nand engineering. In this paper we address practical issues of the Java language\nand environment which have an effect on numerical library design and\ndevelopment. Benchmarks which illustrate the current levels of performance of\nkey numerical kernels on a variety of Java platforms are presented. Finally, a\nstrategy for the development of a fundamental numerical toolkit for Java is\nproposed and its current status is described.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9809009v1"
    },
    {
        "title": "Hyper-Systolic Matrix Multiplication",
        "authors": [
            "Thomas Lippert",
            "Nikolay Petkov",
            "Paolo Palazzari",
            "Klaus Schilling"
        ],
        "category": "cs.MS",
        "published_year": "1998",
        "summary": "  A novel parallel algorithm for matrix multiplication is presented. The\nhyper-systolic algorithm makes use of a one-dimensional processor abstraction.\nThe procedure can be implemented on all types of parallel systems. It can\nhandle matrix-vector multiplications as well as transposed matrix products.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9809105v1"
    },
    {
        "title": "Mathematical Software: Past, Present, and Future",
        "authors": [
            "Ronald F. Boisvert"
        ],
        "category": "cs.MS",
        "published_year": "2000",
        "summary": "  This paper provides some reflections on the field of mathematical software on\nthe occasion of John Rice's 65th birthday. I describe some of the common themes\nof research in this field and recall some significant events in its evolution.\nFinally, I raise a number of issues that are of concern to future developments.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0004004v1"
    },
    {
        "title": "Automatic Differentiation Tools in Optimization Software",
        "authors": [
            "Jorge J. Moré"
        ],
        "category": "cs.MS",
        "published_year": "2001",
        "summary": "  We discuss the role of automatic differentiation tools in optimization\nsoftware. We emphasize issues that are important to large-scale optimization\nand that have proved useful in the installation of nonlinear solvers in the\nNEOS Server. Our discussion centers on the computation of the gradient and\nHessian matrix for partially separable functions and shows that the gradient\nand Hessian matrix can be computed with guaranteed bounds in time and memory\nrequirements\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0101001v1"
    },
    {
        "title": "GPCG: A Case Study in the Performance and Scalability of Optimization\n  Algorithms",
        "authors": [
            "Steven J. Benson",
            "Lois Curfman McInnes",
            "Jorge J. Moré"
        ],
        "category": "cs.MS",
        "published_year": "2001",
        "summary": "  GPCG is an algorithm within the Toolkit for Advanced Optimization (TAO) for\nsolving bound constrained, convex quadratic problems. Originally developed by\nMore' and Toraldo, this algorithm was designed for large-scale problems but had\nbeen implemented only for a single processor. The TAO implementation is\navailable for a wide range of high-performance architecture, and has been\ntested on up to 64 processors to solve problems with over 2.5 million\nvariables.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0101018v1"
    },
    {
        "title": "Benchmarking Optimization Software with Performance Profiles",
        "authors": [
            "Elizabeth D. Dolan",
            "Jorge J. Moré"
        ],
        "category": "cs.MS",
        "published_year": "2001",
        "summary": "  We propose performance profiles-distribution functions for a performance\nmetric-as a tool for benchmarking and comparing optimization software. We show\nthat performance profiles combine the best features of other tools for\nperformance evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0102001v2"
    },
    {
        "title": "Users Guide for SnadiOpt: A Package Adding Automatic Differentiation to\n  Snopt",
        "authors": [
            "E. Michael Gertz",
            "Philip E. Gill",
            "Julia Muetherig"
        ],
        "category": "cs.MS",
        "published_year": "2001",
        "summary": "  SnadiOpt is a package that supports the use of the automatic differentiation\npackage ADIFOR with the optimization package Snopt. Snopt is a general-purpose\nsystem for solving optimization problems with many variables and constraints.\nIt minimizes a linear or nonlinear function subject to bounds on the variables\nand sparse linear or nonlinear constraints. It is suitable for large-scale\nlinear and quadratic programming and for linearly constrained optimization, as\nwell as for general nonlinear programs. The method used by Snopt requires the\nfirst derivatives of the objective and constraint functions to be available.\nThe SnadiOpt package allows users to avoid the time-consuming and error-prone\nprocess of evaluating and coding these derivatives. Given Fortran code for\nevaluating only the values of the objective and constraints, SnadiOpt\nautomatically generates the code for evaluating the derivatives and builds the\nrelevant Snopt input files and sparse data structures.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0106051v1"
    },
    {
        "title": "Computer validated proofs of a toolset for adaptable arithmetic",
        "authors": [
            "Sylvie Boldo",
            "Marc Daumas",
            "Claire Moreau-Finot",
            "Laurent Thery"
        ],
        "category": "cs.MS",
        "published_year": "2001",
        "summary": "  Most existing implementations of multiple precision arithmetic demand that\nthe user sets the precision {\\em a priori}. Some libraries are said adaptable\nin the sense that they dynamically change the precision of each intermediate\noperation individually to deliver the target accuracy according to the actual\ninputs. We present in this text a new adaptable numeric core inspired both from\nfloating point expansions and from on-line arithmetic.\n  The numeric core is cut down to four tools. The tool that contains arithmetic\noperations is proved to be correct. The proofs have been formally checked by\nthe Coq assistant. Developing the proofs, we have formally proved many results\npublished in the literature and we have extended a few of them. This work may\nlet users (i) develop application specific adaptable libraries based on the\ntoolset and / or (ii) write new formal proofs based on the set of validated\nfacts.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0107025v2"
    },
    {
        "title": "Development of a Java Package for Matrix Programming",
        "authors": [
            "Ngee-Peng Lim",
            "Maurice HT Ling",
            "Shawn YC Lim",
            "Ji-Hee Choi",
            "Henry BK Teo"
        ],
        "category": "cs.MS",
        "published_year": "2003",
        "summary": "  We had assembled a Java package, known as MatrixPak, of four classes for the\npurpose of numerical matrix computation. The classes are matrix,\nmatrix_operations, StrToMatrix, and MatrixToStr; all of which are inherited\nfrom java.lang.Object class. Class matrix defines a matrix as a two-dimensional\narray of float types, and contains the following mathematical methods:\ntranspose, adjoint, determinant, inverse, minor and cofactor. Class\nmatrix_operations contains the following mathematical methods: matrix addition,\nmatrix subtraction, matrix multiplication, and matrix exponential. Class\nStrToMatrix contains methods necessary to parse a string representation (for\nexample, [[2 3 4]-[5 6 7]]) of a matrix into a matrix definition, whereas class\nMatrixToStr does the reverse.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0306127v1"
    },
    {
        "title": "Finding the \"truncated\" polynomial that is closest to a function",
        "authors": [
            "Nicolas Brisebarre",
            "Jean-Michel Muller"
        ],
        "category": "cs.MS",
        "published_year": "2003",
        "summary": "  When implementing regular enough functions (e.g., elementary or special\nfunctions) on a computing system, we frequently use polynomial approximations.\nIn most cases, the polynomial that best approximates (for a given distance and\nin a given interval) a function has coefficients that are not exactly\nrepresentable with a finite number of bits. And yet, the polynomial\napproximations that are actually implemented do have coefficients that are\nrepresented with a finite - and sometimes small - number of bits: this is due\nto the finiteness of the floating-point representations (for software\nimplementations), and to the need to have small, hence fast and/or inexpensive,\nmultipliers (for hardware implementations). We then have to consider polynomial\napproximations for which the degree-$i$ coefficient has at most $m_i$\nfractional bits (in other words, it is a rational number with denominator\n$2^{m_i}$). We provide a general method for finding the best polynomial\napproximation under this constraint. Then, we suggest refinements than can be\nused to accelerate our method.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0307009v1"
    },
    {
        "title": "An Introduction to Using Software Tools for Automatic Differentiation",
        "authors": [
            "Uwe Naumann",
            "Andrea Walther"
        ],
        "category": "cs.MS",
        "published_year": "2003",
        "summary": "  We give a gentle introduction to using various software tools for automatic\ndifferentiation (AD). Ready-to-use examples are discussed, and links to further\ninformation are presented. Our target audience includes all those who are\nlooking for a straightforward way to get started using the available AD\ntechnology. The document is dynamic in the sense that its content will be\nupdated as the AD software evolves.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0310057v1"
    },
    {
        "title": "A Fast, Vectorizable Algorithm for Producing Single-Precision\n  Sine-Cosine Pairs",
        "authors": [
            "Marcus H. Mendenhall"
        ],
        "category": "cs.MS",
        "published_year": "2004",
        "summary": "  This paper presents an algorithm for computing Sine-Cosine pairs to modest\naccuracy, but in a manner which contains no conditional tests or branching,\nmaking it highly amenable to vectorization. An exemplary implementation for\nPowerPC AltiVec processors is included, but the algorithm should be easily\nportable to other achitectures, such as Intel SSE.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0406049v1"
    },
    {
        "title": "M@th Desktop and MD Tools - Mathematics and Mathematica Made Easy for\n  Students",
        "authors": [
            "Reinhold Kainhofer",
            "Reinhard V. Simonovits"
        ],
        "category": "cs.MS",
        "published_year": "2004",
        "summary": "  We present two add-ons for Mathematica for teaching mathematics to\nundergraduate and high school students. These two applications, M@th Desktop\n(MD) and M@th Desktop Tools (MDTools), include several palettes and notebooks\ncovering almost every field. The underlying didactic concept is so-called\n\"blended learning\", in which these tools are meant to be used as a complement\nto the professor or teacher rather than as a replacement, which other\ne-learning applications do. They enable students to avoid the usual problem of\ncomputer-based learning, namely that too large an amount of time is wasted\nstruggling with computer and program errors instead of actually learning the\nmathematical concepts.\n  M@th Desktop Tools is palette-based and provides easily accessible and\nuser-friendly templates for the most important functions in the fields of\nAnalysis, Algebra, Linear Algebra and Statistics. M@th Desktop, in contrast, is\na modern, interactive teaching and learning software package for mathematics\nclasses. It is comprised of modules for Differentiation, Integration, and\nStatistics, and each module presents its topic with a combination of\ninteractive notebooks and palettes.\n  Both packages can be obtained from Deltasoft's homepage at\nhttp://www.deltasoft.at/ .\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0407052v1"
    },
    {
        "title": "Tsnnls: A solver for large sparse least squares problems with\n  non-negative variables",
        "authors": [
            "Jason Cantarella",
            "Michael Piatek"
        ],
        "category": "cs.MS",
        "published_year": "2004",
        "summary": "  The solution of large, sparse constrained least-squares problems is a staple\nin scientific and engineering applications. However, currently available codes\nfor such problems are proprietary or based on MATLAB. We announce a freely\navailable C implementation of the fast block pivoting algorithm of Portugal,\nJudice, and Vicente. Our version is several times faster than Matstoms' MATLAB\nimplementation of the same algorithm. Further, our code matches the accuracy of\nMATLAB's built-in lsqnonneg function.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0408029v1"
    },
    {
        "title": "ADF95: Tool for automatic differentiation of a FORTRAN code designed for\n  large numbers of independent variables",
        "authors": [
            "Christian W. Straka"
        ],
        "category": "cs.MS",
        "published_year": "2005",
        "summary": "  ADF95 is a tool to automatically calculate numerical first derivatives for\nany mathematical expression as a function of user defined independent\nvariables. Accuracy of derivatives is achieved within machine precision. ADF95\nmay be applied to any FORTRAN 77/90/95 conforming code and requires minimal\nchanges by the user. It provides a new derived data type that holds the value\nand derivatives and applies forward differencing by overloading all FORTRAN\noperators and intrinsic functions. An efficient indexing technique leads to a\nreduced memory usage and a substantially increased performance gain over other\navailable tools with operator overloading. This gain is especially pronounced\nfor sparse systems with large number of independent variables. A wide class of\nnumerical simulations, e.g., those employing implicit solvers, can profit from\nADF95.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0503014v1"
    },
    {
        "title": "A library of Taylor models for PVS automatic proof checker",
        "authors": [
            "Francisco Cháves",
            "Marc Daumas"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  We present in this paper a library to compute with Taylor models, a technique\nextending interval arithmetic to reduce decorrelation and to solve differential\nequations. Numerical software usually produces only numerical results. Our\nlibrary can be used to produce both results and proofs. As seen during the\ndevelopment of Fermat's last theorem reported by Aczel 1996, providing a proof\nis not sufficient. Our library provides a proof that has been thoroughly\nscrutinized by a trustworthy and tireless assistant. PVS is an automatic proof\nassistant that has been fairly developed and used and that has no internal\nconnection with interval arithmetic or Taylor models. We built our library so\nthat PVS validates each result as it is produced. As producing and validating a\nproof, is and will certainly remain a bigger task than just producing a\nnumerical result our library will never be a replacement to imperative\nimplementations of Taylor models such as Cosy Infinity. Our library should\nmainly be used to validate small to medium size results that are involved in\nsafety or life critical applications.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0602005v1"
    },
    {
        "title": "BioSig - An application of Octave",
        "authors": [
            "Alois Schlögl"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  BioSig is an open source software library for biomedical signal processing.\nMost users in the field are using Matlab; however, significant effort was\nundertaken to provide compatibility to Octave, too. This effort has been widely\nsuccessful, only some non-critical components relying on a graphical user\ninterface are missing. Now, installing BioSig on Octave is as easy as on\nMatlab. Moreover, a benchmark test based on BioSig has been developed and the\nbenchmark results of several platforms are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603001v1"
    },
    {
        "title": "Evaluation of interval extension of the power function by graph\n  decomposition",
        "authors": [
            "Evgueni Petrov"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  The subject of our talk is the correct evaluation of interval extension of\nthe function specified by the expression x^y without any constraints on the\nvalues of x and y. The core of our approach is a decomposition of the graph of\nx^y into a small number of parts which can be transformed into subsets of the\ngraph of x^y for non-negative bases x. Because of this fact, evaluation of\ninterval extension of x^y, without any constraints on x and y, is not much\nharder than evaluation of interval extension of x^y for non-negative bases x.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603052v2"
    },
    {
        "title": "Sparse Matrix Implementation in Octave",
        "authors": [
            "David Bateman",
            "Andy Adler"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  There are many classes of mathematical problems which give rise to matrices,\nwhere a large number of the elements are zero. In this case it makes sense to\nhave a special matrix type to handle this class of problems where only the\nnon-zero elements of the matrix are stored. Not only does this reduce the\namount of memory to store the matrix, but it also means that operations on this\ntype of matrix can take advantage of the a-priori knowledge of the positions of\nthe non-zero elements to accelerate their calculations. A matrix type that\nstores only the non-zero elements is generally called sparse.\n  Until recently Octave has lacked a full implementation of sparse matrices.\nThis article address the implementation of sparse matrices within Octave,\nincluding their storage, creation, fundamental algorithms used, their\nimplementations and the basic operations and functions implemented for sparse\nmatrices. Mathematical issues such as the return types of sparse operations,\nmatrix fill-in and reordering for sparse matrix factorization is discussed in\nthe context of a real example.\n  Benchmarking of Octave's implementation of sparse operations compared to\ntheir equivalent in Matlab are given and their implications discussed. Results\nare presented for multiplication and linear algebra operations for various\nmatrix orders and densities. Furthermore, the use of Octave's sparse matrix\nimplementation is demonstrated using a real example of a finite element model\n(FEM) problem. Finally, the method of using sparse matrices with Octave's\noct-files is discussed. The means of creating, using and returning sparse\nmatrices within oct-files is discussed as well as the differences between\nOctave's Sparse and Array classes.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604006v1"
    },
    {
        "title": "A Fixed-Point Type for Octave",
        "authors": [
            "David Bateman",
            "Laurent Mazet",
            "Veronique Buzenac-Settineri",
            "Markus Muck"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  This paper announces the availability of a fixed point toolbox for the Matlab\ncompatible software package Octave. This toolbox is released under the GNU\nPublic License, and can be used to model the losses in algorithms implemented\nin hardware. Furthermore, this paper presents as an example of the use of this\ntoolbox, the effects of a fixed point implementation on the precision of an\nOFDM modulator.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604039v1"
    },
    {
        "title": "How to Run Mathematica Batch-files in Background ?",
        "authors": [
            "Santanu K. Maiti"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  Mathematica is a versatile equipment for doing numeric and symbolic\ncomputations and it has wide spread applications in all branches of science.\nMathematica has a complete consistency to design it at every stage that gives\nit multilevel capability and helps advanced usage evolve naturally. Mathematica\nfunctions work for any precision of number and it can be easily computed with\nsymbols, represented graphically to get the best answer. Mathematica is a\nrobust software development that can be used in any popular operating systems\nand it can be communicated with external programs by using proper mathlink\ncommands.\n  Sometimes it is quite desirable to run jobs in background of a computer which\ncan take considerable amount of time to finish, and this allows us to do work\non other tasks, while keeping the jobs running. Most of us are very familiar to\nrun jobs in background for the programs written in the languages like C, C++,\nF77, F90, F95, etc. But the way of running jobs, written in a mathematica\nnotebook, in background is quite different from the conventional method. In\nthis article, we explore how to create a mathematica batch-file from a\nmathematica notebook and run it in background. Here we concentrate our study\nonly for the Unix version, but one can run mathematica programs in background\nfor the Windows version as well by using proper mathematica batch-file.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604088v3"
    },
    {
        "title": "Caractéristiques arithmétiques des processeurs graphiques",
        "authors": [
            "Marc Daumas",
            "Guillaume Da Graça",
            "David Defour"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  Les unit\\'{e}s graphiques (Graphic Processing Units- GPU) sont d\\'{e}sormais\ndes processeurs puissants et flexibles. Les derni\\`{e}res g\\'{e}n\\'{e}rations\nde GPU contiennent des unit\\'{e}s programmables de traitement des sommets\n(vertex shader) et des pixels (pixel shader) supportant des op\\'{e}rations en\nvirgule flottante sur 8, 16 ou 32 bits. La repr\\'{e}sentation flottante sur 32\nbits correspond \\`{a} la simple pr\\'{e}cision de la norme IEEE sur\nl'arithm\\'{e}tique en virgule flottante (IEEE-754). Les GPU sont bien\nadapt\\'{e}s aux applications avec un fort parall\\'{e}lisme de donn\\'{e}es.\nCependant ils ne sont que peu utilis\\'{e}s en dehors des calculs graphiques\n(General Purpose computation on GPU -- GPGPU). Une des raisons de cet \\'{e}tat\nde faits est la pauvret\\'{e} des documentations techniques fournies par les\nfabricants (ATI et Nvidia), particuli\\`{e}rement en ce qui concerne\nl'implantation des diff\\'{e}rents op\\'{e}rateurs arithm\\'{e}tiques\nembarqu\\'{e}s dans les diff\\'{e}rentes unit\\'{e}s de traitement. Or ces\ninformations sont essentielles pour estimer et contr\\^{o}ler les erreurs\nd'arrondi ou pour mettre en oeuvre des techniques de r\\'{e}duction ou de\ncompensation afin de travailler en pr\\'{e}cision double, quadruple ou\narbitrairement \\'{e}tendue. Nous proposons dans cet article un ensemble de\nprogrammes qui permettent de d\\'{e}couvrir les caract\\'{e}ristiques principales\ndes GPU en ce qui concerne l'arithm\\'{e}tique \\`{a} virgule flottante. Nous\ndonnons les r\\'{e}sultats obtenus sur deux cartes graphiques r\\'{e}centes: la\nNvidia 7800GTX et l'ATI RX1800XL.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605081v1"
    },
    {
        "title": "Stochastic Formal Methods: An application to accuracy of numeric\n  software",
        "authors": [
            "Marc Daumas",
            "David Lester"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  This paper provides a bound on the number of numeric operations (fixed or\nfloating point) that can safely be performed before accuracy is lost. This work\nhas important implications for control systems with safety-critical software,\nas these systems are now running fast enough and long enough for their errors\nto impact on their functionality. Furthermore, worst-case analysis would\nblindly advise the replacement of existing systems that have been successfully\nrunning for years. We present here a set of formal theorems validated by the\nPVS proof assistant. These theorems will allow code analyzing tools to produce\nformal certificates of accurate behavior. For example, FAA regulations for\naircraft require that the probability of an error be below $10^{-9}$ for a 10\nhour flight.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0606101v4"
    },
    {
        "title": "Stochastic Formal Methods for Hybrid Systems",
        "authors": [
            "Marc Daumas",
            "David Lester",
            "Erik Martin-Dorel",
            "Annick Truffert"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  We provide a framework to bound the probability that accumulated errors were\nnever above a given threshold on hybrid systems. Such systems are used for\nexample to model an aircraft or a nuclear power plant on one side and its\nsoftware on the other side. This report contains simple formulas based on\nL\\'evy's and Markov's inequalities and it presents a formal theory of random\nvariables with a special focus on producing concrete results. We selected four\nvery common applications that fit in our framework and cover the common\npractices of hybrid systems that evolve for a long time. We compute the number\nof bits that remain continuously significant in the first two applications with\na probability of failure around one against a billion, where worst case\nanalysis considers that no significant bit remains. We are using PVS as such\nformal tools force explicit statement of all hypotheses and prevent incorrect\nuses of theorems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0610110v4"
    },
    {
        "title": "Certification of bounds on expressions involving rounded operators",
        "authors": [
            "Marc Daumas",
            "Guillaume Melquiond"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  Gappa uses interval arithmetic to certify bounds on mathematical expressions\nthat involve rounded as well as exact operators. Gappa generates a theorem with\nits proof for each bound treated. The proof can be checked with a higher order\nlogic automatic proof checker, either Coq or HOL Light, and we have developed a\nlarge companion library of verified facts for Coq dealing with the addition,\nmultiplication, division, and square root, in fixed- and floating-point\narithmetics. Gappa uses multiple-precision dyadic fractions for the endpoints\nof intervals and performs forward error analysis on rounded operators when\nnecessary. When asked, Gappa reports the best bounds it is able to reach for a\ngiven expression in a given context. This feature is used to quickly obtain\ncoarse bounds. It can also be used to identify where the set of facts and\nautomatic techniques implemented in Gappa becomes insufficient. Gappa handles\nseamlessly additional properties expressed as interval properties or rewriting\nrules in order to establish more intricate bounds. Recent work showed that\nGappa is perfectly suited to the proof of correctness of small pieces of\nsoftware. Proof obligations can be written by designers, produced by\nthird-party tools or obtained by overloading arithmetic operators.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0701186v2"
    },
    {
        "title": "Why the Standard Data Processing should be changed",
        "authors": [
            "Yefim Bakman"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  The basic statistical methods of data representation did not change since\ntheir emergence. Their simplicity was dictated by the intricacies of\ncomputations in the before computers epoch. It turns out that such approach is\nnot uniquely possible in the presence of quick computers. The suggested here\nmethod improves significantly the reliability of data processing and their\ngraphical representation. In this paper we show problems of the standard data\nprocessing which can bring to incorrect results. A method solving these\nproblems is proposed. It is based on modification of data representation. The\nmethod was implemented in a computer program Consensus5. The program\nperformances are illustrated through varied examples.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0703040v1"
    },
    {
        "title": "Algorithm for Evaluation of the Interval Power Function of Unconstrained\n  Arguments",
        "authors": [
            "Evgueni Petrov"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  We describe an algorithm for evaluation of the interval extension of the\npower function of variables x and y given by the expression x^y. Our algorithm\nreduces the general case to the case of non-negative bases.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.3141v1"
    },
    {
        "title": "GraphStream: A Tool for bridging the gap between Complex Systems and\n  Dynamic Graphs",
        "authors": [
            "Yoann Pigné",
            "Antoine Dutot",
            "Frédéric Guinand",
            "Damien Olivier"
        ],
        "category": "cs.MS",
        "published_year": "2008",
        "summary": "  The notion of complex systems is common to many domains, from Biology to\nEconomy, Computer Science, Physics, etc. Often, these systems are made of sets\nof entities moving in an evolving environment. One of their major\ncharacteristics is the emergence of some global properties stemmed from local\ninteractions between the entities themselves and between the entities and the\nenvironment. The structure of these systems as sets of interacting entities\nleads researchers to model them as graphs. However, their understanding\nrequires most often to consider the dynamics of their evolution. It is indeed\nnot relevant to study some properties out of any temporal consideration. Thus,\ndynamic graphs seem to be a very suitable model for investigating the emergence\nand the conservation of some properties. GraphStream is a Java-based library\nwhose main purpose is to help researchers and developers in their daily tasks\nof dynamic problem modeling and of classical graph management tasks: creation,\nprocessing, display, etc. It may also be used, and is indeed already used, for\nteaching purpose. GraphStream relies on an event-based engine allowing several\nevent sources. Events may be included in the core of the application, read from\na file or received from an event handler.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.2093v1"
    },
    {
        "title": "Conformal Computing: Algebraically connecting the hardware/software\n  boundary using a uniform approach to high-performance computation for\n  software and hardware applications",
        "authors": [
            "Lenore R. Mullin",
            "James E. Raynolds"
        ],
        "category": "cs.MS",
        "published_year": "2008",
        "summary": "  We present a systematic, algebraically based, design methodology for\nefficient implementation of computer programs optimized over multiple levels of\nthe processor/memory and network hierarchy. Using a common formalism to\ndescribe the problem and the partitioning of data over processors and memory\nlevels allows one to mathematically prove the efficiency and correctness of a\ngiven algorithm as measured in terms of a set of metrics (such as\nprocessor/network speeds, etc.). The approach allows the average programmer to\nachieve high-level optimizations similar to those used by compiler writers\n(e.g. the notion of \"tiling\").\n  The approach presented in this monograph makes use of A Mathematics of Arrays\n(MoA, Mullin 1988) and an indexing calculus (i.e. the psi-calculus) to enable\nthe programmer to develop algorithms using high-level compiler-like\noptimizations through the ability to algebraically compose and reduce sequences\nof array operations. Extensive discussion and benchmark results are presented\nfor the Fast Fourier Transform and other important algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.2386v1"
    },
    {
        "title": "Accelerating Scientific Computations with Mixed Precision Algorithms",
        "authors": [
            "Marc Baboulin",
            "Alfredo Buttari",
            "Jack Dongarra",
            "Jakub Kurzak",
            "Julie Langou",
            "Julien Langou",
            "Piotr Luszczek",
            "Stanimire Tomov"
        ],
        "category": "cs.MS",
        "published_year": "2008",
        "summary": "  On modern architectures, the performance of 32-bit operations is often at\nleast twice as fast as the performance of 64-bit operations. By using a\ncombination of 32-bit and 64-bit floating point arithmetic, the performance of\nmany dense and sparse linear algebra algorithms can be significantly enhanced\nwhile maintaining the 64-bit accuracy of the resulting solution. The approach\npresented here can apply not only to conventional processors but also to other\ntechnologies such as Field Programmable Gate Arrays (FPGA), Graphical\nProcessing Units (GPU), and the STI Cell BE processor. Results on modern\nprocessor architectures and the STI Cell BE are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0808.2794v1"
    },
    {
        "title": "Efficient Multiplication of Dense Matrices over GF(2)",
        "authors": [
            "Martin Albrecht",
            "Gregory Bard",
            "William Hart"
        ],
        "category": "cs.MS",
        "published_year": "2008",
        "summary": "  We describe an efficient implementation of a hierarchy of algorithms for\nmultiplication of dense matrices over the field with two elements (GF(2)). In\nparticular we present our implementation -- in the M4RI library -- of\nStrassen-Winograd matrix multiplication and the \"Method of the Four Russians\"\nmultiplication (M4RM) and compare it against other available implementations.\nGood performance is demonstrated on on AMD's Opteron and particulary good\nperformance on Intel's Core 2 Duo. The open-source M4RI library is available\nstand-alone as well as part of the Sage mathematics software.\n  In machine terms, addition in GF(2) is logical-XOR, and multiplication is\nlogical-AND, thus a machine word of 64-bits allows one to operate on 64\nelements of GF(2) in parallel: at most one CPU cycle for 64 parallel additions\nor multiplications. As such, element-wise operations over GF(2) are relatively\ncheap. In fact, in this paper, we conclude that the actual bottlenecks are\nmemory reads and writes and issues of data locality. We present our empirical\nfindings in relation to minimizing these and give an analysis thereof.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.1714v1"
    },
    {
        "title": "Bitslicing and the Method of Four Russians Over Larger Finite Fields",
        "authors": [
            "Tomas J. Boothby",
            "Robert W. Bradshaw"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  We present a method of computing with matrices over very small finite fields\nof size larger than 2. Specifically, we show how the Method of Four Russians\ncan be efficiently adapted to these larger fields, and introduce a row-wise\nmatrix compression scheme that both reduces memory requirements and allows one\nto vectorize element operations. We also present timings which confirm the\nefficiency of these methods and exceed the speed of the fastest implementations\nthe authors are aware of.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.1413v1"
    },
    {
        "title": "The generating of Fractal Images Using MathCAD Program",
        "authors": [
            "Laura Stefan"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  This paper presents the graphic representation in the z-plane of the first\nthree iterations of the algorithm that generates the Sierpinski Gasket. It\nanalyzes the influence of the f(z) map when we represent fractal images.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4053v1"
    },
    {
        "title": "FISLAB - the Fuzzy Inference Tool-box for SCILAB",
        "authors": [
            "Simona Apostol"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  The present study represents \"The Fislab package of programs meant to develop\nthe fuzzy regulators in the Scilab environment\" in which we present some\ngeneral issues, usage requirements and the working mode of the Fislab\nenvironment. In the second part of the article some features of the Scilab\nfunctions from the Fislab package are described.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4307v1"
    },
    {
        "title": "The development of a fuzzy regulator with an entry and an output in\n  Fislab",
        "authors": [
            "Simona Apostol"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  The present article is a sequel of the article \"Fislab the Fuzzy Inference\nTool-Box for Scilab\" and it represents the practical application of:\"The\ndevelopment of the Fuzzy regulator with an input and an output in Fislab\". The\narticle contains, besides this application, some functions to be used in the\nprogram, namely Scilab functions for the fuzzification of the firm information,\nfunctions for the operation of de-fuzzification and functions for the\nimplementation of.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4313v1"
    },
    {
        "title": "HONEI: A collection of libraries for numerical computations targeting\n  multiple processor architectures",
        "authors": [
            "Danny van Dyk",
            "Markus Geveler",
            "Sven Mallach",
            "Dirk Ribbrock",
            "Dominik Goeddeke",
            "Carsten Gutwenger"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  We present HONEI, an open-source collection of libraries offering a hardware\noriented approach to numerical calculations. HONEI abstracts the hardware, and\napplications written on top of HONEI can be executed on a wide range of\ncomputer architectures such as CPUs, GPUs and the Cell processor. We\ndemonstrate the flexibility and performance of our approach with two test\napplications, a Finite Element multigrid solver for the Poisson problem and a\nrobust and fast simulation of shallow water waves. By linking against HONEI's\nlibraries, we achieve a twofold speedup over straight forward C++ code using\nHONEI's SSE backend, and additional 3-4 and 4-16 times faster execution on the\nCell and a GPU. A second important aspect of our approach is that the full\nperformance capabilities of the hardware under consideration can be exploited\nby adding optimised application-specific operations to the HONEI libraries.\nHONEI provides all necessary infrastructure for development and evaluation of\nsuch kernels, significantly simplifying their development.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.4152v1"
    },
    {
        "title": "Limits of Educational Soft \"GeoGebra\" in a Critical Constructive Review",
        "authors": [
            "Valerian Antohe"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  Mathematical educational soft explore, investigating in a dynamical way, some\nalgebraically, geometrically problems, the expected results being used to\ninvolve a lot of mathematical results. One such software soft is GeoGebra. The\nsoftware is free and multi-platform dynamic mathematics software for learning\nand teaching, awards in Europe and the USA. This paper describes some critical\nbut constructive investigation using the platform for graph functions and\ndynamic geometry.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4430v1"
    },
    {
        "title": "Iterative Methods for Systems' Solving - a C# approach",
        "authors": [
            "Claudiu Chirilov"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  This work wishes to support various mathematical issues concerning the\niterative methods with the help of new programming languages. We consider a way\nto show how problems in math have an answer by using different academic\nresources and different thoughts. Here we treat methods like Gauss-Seidel's,\nCramer's and Gauss-Jordan's.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4598v1"
    },
    {
        "title": "Parallel Computation of Finite Element Navier-Stokes codes using MUMPS\n  Solver",
        "authors": [
            "Mandhapati P. Raju"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  The study deals with the parallelization of 2D and 3D finite element based\nNavier-Stokes codes using direct solvers. Development of sparse direct solvers\nusing multifrontal solvers has significantly reduced the computational time of\ndirect solution methods. Although limited by its stringent memory requirements,\nmultifrontal solvers can be computationally efficient. First the performance of\nMUltifrontal Massively Parallel Solver (MUMPS) is evaluated for both 2D and 3D\ncodes in terms of memory requirements and CPU times. The scalability of both\nNewton and modified Newton algorithms is tested.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.1845v1"
    },
    {
        "title": "NetEvo: A computational framework for the evolution of dynamical complex\n  networks",
        "authors": [
            "Thomas E. Gorochowski",
            "Mario di Bernardo",
            "Claire S. Grierson"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  NetEvo is a computational framework designed to help understand the evolution\nof dynamical complex networks. It provides flexible tools for the simulation of\ndynamical processes on networks and methods for the evolution of underlying\ntopological structures. The concept of a supervisor is used to bring together\nboth these aspects in a coherent way. It is the job of the supervisor to rewire\nthe network topology and alter model parameters such that a user specified\nperformance measure is minimised. This performance measure can make use of\ncurrent topological information and simulated dynamical output from the system.\nSuch an abstraction provides a suitable basis in which to study many\noutstanding questions related to complex system design and evolution.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3398v1"
    },
    {
        "title": "An OpenMath Content Dictionary for Tensor Concepts",
        "authors": [
            "Joseph B. Collins"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  We introduce a new OpenMath content dictionary, named tensor1, containing\nsymbols for the expression of tensor formulas. These symbols support the\nexpression of non-Cartesian coordinates and invariant, multilinear expressions\nin the context of coordinate transformations. While current OpenMath symbols\nsupport the expression of linear algebra formulas using matrices and vectors,\nwe find that there is an underlying assumption of Cartesian, or standard,\ncoordinates that makes the expression of general tensor formulas difficult, if\nnot impossible. In introducing these new OpenMath symbols for the expression of\ntensor formulas, we attempt to maintain, as much as possible, consistency with\nprior OpenMath symbol definitions for linear algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4395v1"
    },
    {
        "title": "Adapting Mathematical Domain Reasoners",
        "authors": [
            "Bastiaan Heeren",
            "Johan Jeuring"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  Mathematical learning environments help students in mastering mathematical\nknowledge. Mature environments typically offer thousands of interactive\nexercises. Providing feedback to students solving interactive exercises\nrequires domain reasoners for doing the exercise-specific calculations. Since a\ndomain reasoner has to solve an exercise in the same way a student should solve\nit, the structure of domain reasoners should follow the layered structure of\nthe mathematical domains. Furthermore, learners, teachers, and environment\nbuilders have different requirements for adapting domain reasoners, such as\nproviding more details, disallowing or enforcing certain solutions, and\ncombining multiple mathematical domains in a new domain. In previous work we\nhave shown how domain reasoners for solving interactive exercises can be\nexpressed in terms of rewrite strategies, rewrite rules, and views. This paper\nshows how users can adapt and configure such domain reasoners to their own\nneeds. This is achieved by enabling users to explicitly communicate the\ncomponents that are used for solving an exercise.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4762v1"
    },
    {
        "title": "Variants of Mersenne Twister Suitable for Graphic Processors",
        "authors": [
            "Mutsuo Saito",
            "Makoto Matsumoto"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  This paper proposes a type of pseudorandom number generator, Mersenne Twister\nfor Graphic Processor (MTGP), for efficient generation on graphic processessing\nunits (GPUs). MTGP supports large state sizes such as 11213 bits, and uses the\nhigh parallelism of GPUs in computing many steps of the recursion in parallel.\nThe second proposal is a parameter-set generator for MTGP, named MTGP Dynamic\nCreator (MTGPDC). MT- GPDC creates up to 2^32 distinct parameter sets which\ngenerate sequences with high-dimensional uniformity. This facility is suitable\nfor a large grid of GPUs where each GPU requires separate random number\nstreams. MTGP is based on linear recursion over the two-element field, and has\nbetter high-dimensional equidistribution than the Mersenne Twister pseudorandom\nnumber generator.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4973v3"
    },
    {
        "title": "Computational Complexity of Iterated Maps on the Interval (Extended\n  Abstract)",
        "authors": [
            "Christoph Spandl"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  The exact computation of orbits of discrete dynamical systems on the interval\nis considered. Therefore, a multiple-precision floating point approach based on\nerror analysis is chosen and a general algorithm is presented. The correctness\nof the algorithm is shown and the computational complexity is analyzed. As a\nmain result, the computational complexity measure considered here is related to\nthe Ljapunow exponent of the dynamical system under consideration.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0404v1"
    },
    {
        "title": "Genbit Compress Tool(GBC): A Java-Based Tool to Compress DNA Sequences\n  and Compute Compression Ratio(bits/base) of Genomes",
        "authors": [
            "P. Raja Rajeswari",
            "Allam Apparo",
            "V. K. Kumar"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  We present a Compression Tool, \"GenBit Compress\", for genetic sequences based\non our new proposed \"GenBit Compress Algorithm\". Our Tool achieves the best\ncompression ratios for Entire Genome (DNA sequences) . Significantly better\ncompression results show that GenBit compress algorithm is the best among the\nremaining Genome compression algorithms for non-repetitive DNA sequences in\nGenomes. The standard Compression algorithms such as gzip or compress cannot\ncompress DNA sequences but only expand them in size. In this paper we consider\nthe problem of DNA compression. It is well known that one of the main features\nof DNA Sequences is that they contain substrings which are duplicated except\nfor a few random Mutations. For this reason most DNA compressors work by\nsearching and encoding approximate repeats. We depart from this strategy by\nsearching and encoding only exact repeats. our proposed algorithm achieves the\nbest compression ratio for DNA sequences for larger genome. As long as 8 lakh\ncharacters can be given as input While achieving the best compression ratios\nfor DNA sequences, our new GenBit Compress program significantly improves the\nrunning time of all previous DNA compressors. Assigning binary bits for\nfragments of DNA sequence is also a unique concept introduced in this program\nfor the first time in DNA compression.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.1193v1"
    },
    {
        "title": "Efficient Decomposition of Dense Matrices over GF(2)",
        "authors": [
            "Martin R. Albrecht",
            "Clément Pernet"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  In this work we describe an efficient implementation of a hierarchy of\nalgorithms for the decomposition of dense matrices over the field with two\nelements (GF(2)). Matrix decomposition is an essential building block for\nsolving dense systems of linear and non-linear equations and thus much research\nhas been devoted to improve the asymptotic complexity of such algorithms. In\nthis work we discuss an implementation of both well-known and improved\nalgorithms in the M4RI library. The focus of our discussion is on a new variant\nof the M4RI algorithm - denoted MMPF in this work -- which allows for\nconsiderable performance gains in practice when compared to the previously\nfastest implementation. We provide performance figures on x86_64 CPUs to\ndemonstrate the viability of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.1744v1"
    },
    {
        "title": "How to obtain efficient GPU kernels: an illustration using FMM & FGT\n  algorithms",
        "authors": [
            "Felipe A. Cruz",
            "Simon K. Layton",
            "Lorena A. Barba"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  Computing on graphics processors is maybe one of the most important\ndevelopments in computational science to happen in decades. Not since the\narrival of the Beowulf cluster, which combined open source software with\ncommodity hardware to truly democratize high-performance computing, has the\ncommunity been so electrified. Like then, the opportunity comes with\nchallenges. The formulation of scientific algorithms to take advantage of the\nperformance offered by the new architecture requires rethinking core methods.\nHere, we have tackled fast summation algorithms (fast multipole method and fast\nGauss transform), and applied algorithmic redesign for attaining performance on\ngpus. The progression of performance improvements attained illustrates the\nexercise of formulating algorithms for the massively parallel architecture of\nthe gpu. The end result has been gpu kernels that run at over 500 Gigaflops on\none nvidia Tesla C1060 card, thereby reaching close to practical peak. We can\nconfidently say that gpu computing is not just a vogue, it is truly an\nirresistible trend in high-performance computing.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.3457v2"
    },
    {
        "title": "The NumPy array: a structure for efficient numerical computation",
        "authors": [
            "Stefan Van Der Walt",
            "S. Chris Colbert",
            "Gaël Varoquaux"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  In the Python world, NumPy arrays are the standard representation for\nnumerical data. Here, we show how these arrays enable efficient implementation\nof numerical computations in a high-level language. Overall, three techniques\nare applied to improve performance: vectorizing calculations, avoiding copying\ndata in memory, and minimizing operation counts. We first present the NumPy\narray structure, then show how to use it for efficient computation, and finally\nhow to share array data with other libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.1523v1"
    },
    {
        "title": "XMLlab : multimedia publication of simulations applets using XML and\n  Scilab",
        "authors": [
            "Stéphane Mottelet",
            "André Pauss"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  We present an XML-based simulation authoring environment. The proposed\ndescription language allows to describe mathematical objects such as systems of\nordinary differential equations, partial differential equations in two\ndimensions, or simple curves and surfaces. It also allows to describe the\nparameters on which these objects depend. This language is independent of the\ntarget software and allows to ensure the perennity of author's work, as well as\ncollaborative work and content reuse. The actual implementation of XMLlab\nallows to run the generated simulations within the open source mathematical\nsoftware Scilab, either locally when Scilab is installed on the client\nmachines, or on thin clients running a simple web browser, when XMLlab and\nScilab are installed on a distant server running a standard HTTP server.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.5711v1"
    },
    {
        "title": "Optimisations for quadrature representations of finite element tensors\n  through automated code generation",
        "authors": [
            "Kristian B. Ølgaard",
            "Garth N. Wells"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  We examine aspects of the computation of finite element matrices and vectors\nwhich are made possible by automated code generation. Given a variational form\nin a syntax which resembles standard mathematical notation, the low-level\ncomputer code for building finite element tensors, typically matrices, vectors\nand scalars, can be generated automatically via a form compiler. In particular,\nthe generation of code for computing finite element matrices using a quadrature\napproach is addressed. For quadrature representations, a number of optimisation\nstrategies which are made possible by automated code generation are presented.\nThe relative performance of two different automatically generated\nrepresentations of finite element matrices is examined, with a particular\nemphasis on complicated variational forms. It is shown that approaches which\nperform best for simple forms are not tractable for more complicated problems\nin terms of run time performance, the time required to generate the code or the\nsize of the generated code. The approach and optimisations elaborated here are\neffective for a range of variational forms.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.0199v1"
    },
    {
        "title": "Automated code generation for discontinuous Galerkin methods",
        "authors": [
            "Kristian B. Ølgaard",
            "Anders Logg",
            "Garth N. Wells"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  A compiler approach for generating low-level computer code from high-level\ninput for discontinuous Galerkin finite element forms is presented. The input\nlanguage mirrors conventional mathematical notation, and the compiler generates\nefficient code in a standard programming language. This facilitates the rapid\ngeneration of efficient code for general equations in varying spatial\ndimensions. Key concepts underlying the compiler approach and the automated\ngeneration of computer code are elaborated. The approach is demonstrated for a\nrange of common problems, including the Poisson, biharmonic,\nadvection--diffusion and Stokes equations.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.0628v1"
    },
    {
        "title": "Operand Folding Hardware Multipliers",
        "authors": [
            "Byungchun Chung",
            "Sandra Marcello",
            "Amir-Pasha Mirbaha",
            "David Naccache",
            "Karim Sabeg"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  This paper describes a new accumulate-and-add multiplication algorithm. The\nmethod partitions one of the operands and re-combines the results of\ncomputations done with each of the partitions. The resulting design turns-out\nto be both compact and fast.\n  When the operands' bit-length $m$ is 1024, the new algorithm requires only\n$0.194m+56$ additions (on average), this is about half the number of additions\nrequired by the classical accumulate-and-add multiplication algorithm\n($\\frac{m}2$).\n",
        "pdf_link": "http://arxiv.org/pdf/1104.1533v1"
    },
    {
        "title": "Methods of Matrix Multiplication: An Overview of Several Methods and\n  their Implementation",
        "authors": [
            "Ivo Hedtke"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  In this overview article we present several methods for multiplying matrices\nand the implementation of these methods in C. Also a little test program is\ngiven to compare their running time and the numerical stability.\n  The methods are: naive method, naive method working on arrays, naive method\nwith the \\textsc{Kahan} trick, three methods with loop unrolling, winograd\nmethod and the scaled variant, original \\textsc{Strassen} method and the\n\\textsc{Strassen}-\\textsc{Winograd} variant.\n  Please note, that this is the FIRST version. The algorithms are not well\ntested and the implementation is not optimized. If you like to join the\nproject, please contact me.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.1347v1"
    },
    {
        "title": "Matrix Inversion Using Cholesky Decomposition",
        "authors": [
            "Aravindh Krishnamoorthy",
            "Deepak Menon"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  In this paper we present a method for matrix inversion based on Cholesky\ndecomposition with reduced number of operations by avoiding computation of\nintermediate results; further, we use fixed point simulations to compare the\nnumerical accuracy of the method.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.4144v2"
    },
    {
        "title": "The M4RIE library for dense linear algebra over small fields with even\n  characteristic",
        "authors": [
            "Martin R. Albrecht"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  In this work, we present the M4RIE library which implements efficient\nalgorithms for linear algebra with dense matrices over GF(2^e) for 2 <= 2 <=\n10. As the name of the library indicates, it makes heavy use of the M4RI\nlibrary both directly (i.e., by calling it) and indirectly (i.e., by using its\nconcepts). We provide an open-source GPLv2+ C library for efficient linear\nalgebra over GF(2^e) for e small. In this library we implemented an idea due to\nBradshaw and Boothby which reduces matrix multiplication over GF(p^k) to a\nseries of matrix multiplications over GF(p). Furthermore, we propose a caching\ntechnique - Newton-John tables - to avoid finite field multiplications which is\ninspired by Kronrod's method (\"M4RM\") for matrix multiplication over GF(2).\nUsing these two techniques we provide asymptotically fast triangular solving\nwith matrices (TRSM) and PLE-based Gaussian elimination. As a result, we are\nable to significantly improve upon the state of the art in dense linear algebra\nover GF(2^e) with 2 <= e <= 10.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.6900v1"
    },
    {
        "title": "Technique detection software for Sparse Matrices",
        "authors": [
            "Muhammad Taimoor Khan",
            "Anila Usman"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Sparse storage formats are techniques for storing and processing the sparse\nmatrix data efficiently. The performance of these storage formats depend upon\nthe distribution of non-zeros, within the matrix in different dimensions. In\norder to have better results we need a technique that suits best the\norganization of data in a particular matrix. So the decision of selecting a\nbetter technique is the main step towards improving the system's results\notherwise the efficiency can be decreased. The purpose of this research is to\nhelp identify the best storage format in case of reduced storage size and high\nprocessing efficiency for a sparse matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.5964v1"
    },
    {
        "title": "The Kernel Quantum Probabilities (KQP) Library",
        "authors": [
            "Benjamin Piwowarski"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In this document, we show how the different quantities necessary to compute\nkernel quantum probabilities can be computed. This document form the basis of\nthe implementation of the Kernel Quantum Probability (KQP) open source project\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6005v2"
    },
    {
        "title": "TeXmacs-Reduce interface",
        "authors": [
            "Andrey Grozin"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  This tutorial (based on the talk at the TeXmacs workshop in Faro, Portugal,\nFebruary 26 - March 2, 2012) describes the new and improved Reduce plugin in\nGNU TeXmacs.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3020v1"
    },
    {
        "title": "Automated derivation of the adjoint of high-level transient finite\n  element programs",
        "authors": [
            "Patrick E. Farrell",
            "David A. Ham",
            "Simon F. Funke",
            "Marie E. Rognes"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In this paper we demonstrate a new technique for deriving discrete adjoint\nand tangent linear models of finite element models. The technique is\nsignificantly more efficient and automatic than standard algorithmic\ndifferentiation techniques. The approach relies on a high-level symbolic\nrepresentation of the forward problem. In contrast to developing a model\ndirectly in Fortran or C++, high-level systems allow the developer to express\nthe variational problems to be solved in near-mathematical notation. As such,\nthese systems have a key advantage: since the mathematical structure of the\nproblem is preserved, they are more amenable to automated analysis and\nmanipulation. The framework introduced here is implemented in a freely\navailable software package named dolfin-adjoint, based on the FEniCS Project.\nOur approach to automated adjoint derivation relies on run-time annotation of\nthe temporal structure of the model, and employs the FEniCS finite element form\ncompiler to automatically generate the low-level code for the derived models.\nThe approach requires only trivial changes to a large class of forward models,\nincluding complicated time-dependent nonlinear models. The adjoint model\nautomatically employs optimal checkpointing schemes to mitigate storage\nrequirements for nonlinear models, without any user management or intervention.\nFurthermore, both the tangent linear and adjoint models naturally work in\nparallel, without any need to differentiate through calls to MPI or to parse\nOpenMP directives. The generality, applicability and efficiency of the approach\nare demonstrated with examples from a wide range of scientific applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.5577v2"
    },
    {
        "title": "A Heterogeneous Accelerated Matrix Multiplication: OpenCL + APU + GPU+\n  Fast Matrix Multiply",
        "authors": [
            "Paolo D'Alberto"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  As users and developers, we are witnessing the opening of a new computing\nscenario: the introduction of hybrid processors into a single die, such as an\naccelerated processing unit (APU) processor, and the plug-and-play of\nadditional graphics processing units (GPUs) onto a single motherboard. These\nAPU processors provide multiple symmetric cores with their memory hierarchies\nand an integrated GPU. Moreover, these processors are designed to work with\nexternal GPUs that can push the peak performance towards the TeraFLOPS\nboundary. We present a case study for the development of dense Matrix\nMultiplication (MM) codes for matrix sizes up to 19K\\times19K, thus using all\nof the above computational engines, and an achievable peak performance of 200\nGFLOPS for, literally, a made- at-home built. We present the results of our\nexperience, the quirks, the pitfalls, the achieved performance, and the\nachievable peak performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.2927v1"
    },
    {
        "title": "User Manual for the Complex Conjugate Gradient Methods Library CCGPAK\n  2.0",
        "authors": [
            "Piotr J. Flatau"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  This manual describes the library of conjugate gradients codes CCGPAK, which\nsolves system of complex linear system of equations. The library is written in\nFORTRAN90 and is highly portable. The codes are general and provide mechanism\nfor matrix times vector multiplication which is separated from the conjugate\ngradient iterations itself. It is simple to switch between single and double\nprecisions. All codes follow the same naming conventions.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.4869v1"
    },
    {
        "title": "A framework for the automation of generalised stability theory",
        "authors": [
            "Patrick E. Farrell",
            "Colin J. Cotter",
            "Simon W. Funke"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  The traditional approach to investigating the stability of a physical system\nis to linearise the equations about a steady base solution, and to examine the\neigenvalues of the linearised operator. Over the past several decades, it has\nbeen recognised that this approach only determines the asymptotic stability of\nthe system, and neglects the possibility of transient perturbation growth\narising due to the nonnormality of the system. This observation motivated the\ndevelopment of a more powerful generalised stability theory (GST), which\nfocusses instead on the singular value decomposition of the linearised\npropagator of the system. While GST has had significant successes in\nunderstanding the stability of phenomena in geophysical fluid dynamics, its\nmore widespread applicability has been hampered by the fact that computing the\nSVD requires both the tangent linear operator and its adjoint: deriving the\ntangent linear and adjoint models is usually a considerable challenge, and\nmanually embedding them inside an eigensolver is laborious. In this paper, we\npresent a framework for the automation of generalised stability theory, which\novercomes these difficulties. Given a compact high-level symbolic\nrepresentation of a finite element discretisation implemented in the FEniCS\nsystem, efficient C++ code is automatically generated to assemble the forward,\ntangent linear and adjoint models; these models are then used to calculate the\noptimally growing perturbations to the forward model, and their growth rates.\nBy automating the stability computations, we hope to make these powerful tools\na more routine part of computational analysis. The efficiency and generality of\nthe framework is demonstrated with applications drawn from geophysical fluid\ndynamics, phase separation and quantum mechanics.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.6989v2"
    },
    {
        "title": "A framework for automated PDE-constrained optimisation",
        "authors": [
            "S. W. Funke",
            "P. E. Farrell"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  A generic framework for the solution of PDE-constrained optimisation problems\nbased on the FEniCS system is presented. Its main features are an intuitive\nmathematical interface, a high degree of automation, and an efficient\nimplementation of the generated adjoint model. The framework is based upon the\nextension of a domain-specific language for variational problems to cleanly\nexpress complex optimisation problems in a compact, high-level syntax. For\nexample, optimisation problems constrained by the time-dependent Navier-Stokes\nequations can be written in tens of lines of code. Based on this high-level\nrepresentation, the framework derives the associated adjoint equations in the\nsame domain-specific language, and uses the FEniCS code generation technology\nto emit parallel optimised low-level C++ code for the solution of the forward\nand adjoint systems. The functional and gradient information so computed is\nthen passed to the optimisation algorithm to update the parameter values. This\napproach works both for steady-state as well as transient, and for linear as\nwell as nonlinear governing PDEs and a wide range of functionals and control\nparameters. We demonstrate the applicability and efficiency of this approach on\nclassical textbook optimisation problems and advanced examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.3894v1"
    },
    {
        "title": "ForestClaw: Hybrid forest-of-octrees AMR for hyperbolic conservation\n  laws",
        "authors": [
            "Carsten Burstedde",
            "Donna Calhoun",
            "Kyle Mandli",
            "Andy R. Terrel"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We present a new hybrid paradigm for parallel adaptive mesh refinement (AMR)\nthat combines the scalability and lightweight architecture of tree-based AMR\nwith the computational efficiency of patch-based solvers for hyperbolic\nconservation laws. The key idea is to interpret each leaf of the AMR hierarchy\nas one uniform compute patch in $\\sR^d$ with $m^d$ degrees of freedom, where\n$m$ is customarily between 8 and 32. Thus, computation on each patch can be\noptimized for speed, while we inherit the flexibility of adaptive meshes. In\nour work we choose to integrate with the p4est AMR library since it allows us\nto compose the mesh from multiple mapped octrees and enables the cubed sphere\nand other nontrivial multiblock geometries. We describe aspects of the parallel\nimplementation and close with scalings for both MPI-only and OpenMP/MPI hybrid\nruns, where the largest MPI run executes on 16,384 CPU cores.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.1472v1"
    },
    {
        "title": "High Precision Arithmetic for Scientific Applications",
        "authors": [
            "Foster Morrison"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  All but a few digital computers used for scientific computations have\nsupported floating-point and digital arithmetic of rather limited numerical\nprecision. The underlying assumptions were that the systems being studied were\nbasically deterministic and of limited complexity. The ideal scientific\nparadigm was the orbits of the major planets, which could be observed with high\nprecision, predicted for thousands of years into the future, and extrapolated\nfor thousands of years into the past. Much the same technology that has made\ncomputers possible has also provided instrumentation that has vastly expanded\nthe scope and precision of scientific analysis. Complex nonlinear systems\nexhibiting so-called chaotic dynamics are now fair game for scientists and\nengineers in every discipline. Today it seems that computers need to enhance\nthe precision of their numerical computations to support the needs of science.\nHowever, there is no need to wait for the necessary updates in both hardware\nand software; it is easy enough to monitor numerical precision with a few minor\nmodifications to existing software.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5498v1"
    },
    {
        "title": "Numerical integration on GPUs for higher order finite elements",
        "authors": [
            "Krzysztof Banaś",
            "Przemysław Płaszewski",
            "Paweł Macioł"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  The paper considers the problem of implementation on graphics processors of\nnumerical integration routines for higher order finite element approximations.\nThe design of suitable GPU kernels is investigated in the context of general\npurpose integration procedures, as well as particular example applications. The\nmost important characteristic of the problem investigated is the large\nvariation of required processor and memory resources associated with different\ndegrees of approximating polynomials. The questions that we try to answer are\nwhether it is possible to design a single integration kernel for different GPUs\nand different orders of approximation and what performance can be expected in\nsuch a case.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.1191v1"
    },
    {
        "title": "Vectorized OpenCL implementation of numerical integration for higher\n  order finite elements",
        "authors": [
            "Filip Krużel",
            "Krzysztof Banaś"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  In our work we analyze computational aspects of the problem of numerical\nintegration in finite element calculations and consider an OpenCL\nimplementation of related algorithms for processors with wide vector registers.\n  As a platform for testing the implementation we choose the PowerXCell\nprocessor, being an example of the Cell Broadband Engine (CellBE) architecture.\nAlthough the processor is considered old for today's standards (its design\ndates back to year 2001), we investigate its performance due to two features\nthat it shares with recent Xeon Phi family of coprocessors: wide vector units\nand relatively slow connection of computing cores with main global memory. The\nperformed analysis of parallelization options can also be used for designing\nnumerical integration algorithms for other processors with vector registers,\nsuch as contemporary x86 microprocessors.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.1194v1"
    },
    {
        "title": "Radix Conversion for IEEE754-2008 Mixed Radix Floating-Point Arithmetic",
        "authors": [
            "O. Kupriianova",
            "Ch. Lauter",
            "J. -M. Muller"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Conversion between binary and decimal floating-point representations is\nubiquitous. Floating-point radix conversion means converting both the exponent\nand the mantissa. We develop an atomic operation for FP radix conversion with\nsimple straight-line algorithm, suitable for hardware design. Exponent\nconversion is performed with a small multiplication and a lookup table. It\nyields the correct result without error. Mantissa conversion uses a few\nmultiplications and a small lookup table that is shared amongst all types of\nconversions. The accuracy changes by adjusting the computing precision.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.0455v1"
    },
    {
        "title": "Polcovar: Software for Computing the Mean and Variance of Subgraph\n  Counts in Random Graphs",
        "authors": [
            "Jérôme Kunegis"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The mean and variance of the number of appearances of a given subgraph $H$ in\nan Erd\\H{o}s--R\\'enyi random graph over $n$ nodes are rational polynomials in\n$n$. We present a piece of software named Polcovar (from \"polynomial\" and\n\"covariance\") that computes the exact rational coefficients of these\npolynomials in function of $H$.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.5835v2"
    },
    {
        "title": "A modified ziggurat algorithm for generating exponentially- and\n  normally-distributed pseudorandom numbers",
        "authors": [
            "Christopher D McFarland"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The Ziggurat Algorithm is a very fast rejection sampling method for\ngenerating PseudoRandom Numbers (PRNs) from common statistical distributions.\nThe algorithm divides a distribution into rectangular layers that stack on top\nof each other (resembling a Ziggurat), subsuming the desired distribution.\nRandom values within these rectangular layers are then sampled by rejection.\nThis implementation splits layers into two types: those constituting the\nmajority that fall completely under the distribution and can be sampled\nextremely fast without a rejection test, and a few additional layers that\nencapsulate the fringe of the distribution and require a rejection test. This\nmethod offers speedups of 65% for exponentially- and 82% for\nnormally-distributed PRNs when compared to the best available C implementations\nof these generators. Even greater speedups are obtained when the algorithm is\nextended to the Python and MATLAB/OCTAVE programming environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.6870v2"
    },
    {
        "title": "A Scala Prototype to Generate Multigrid Solver Implementations for\n  Different Problems and Target Multi-Core Platforms",
        "authors": [
            "Harald Koestler",
            "Christian Schmitt",
            "Sebastian Kuckuk",
            "Frank Hannig",
            "Juergen Teich",
            "Ulrich Ruede"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Many problems in computational science and engineering involve partial\ndifferential equations and thus require the numerical solution of large, sparse\n(non)linear systems of equations. Multigrid is known to be one of the most\nefficient methods for this purpose. However, the concrete multigrid algorithm\nand its implementation highly depend on the underlying problem and hardware.\nTherefore, changes in the code or many different variants are necessary to\ncover all relevant cases. In this article we provide a prototype implementation\nin Scala for a framework that allows abstract descriptions of PDEs, their\ndiscretization, and their numerical solution via multigrid algorithms. From\nthese, one is able to generate data structures and implementations of multigrid\ncomponents required to solve elliptic PDEs on structured grids. Two different\ntest problems showcase our proposed automatic generation of multigrid solvers\nfor both CPU and GPU target platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.5369v1"
    },
    {
        "title": "Lighthouse: A User-Centered Web Service for Linear Algebra Software",
        "authors": [
            "Boyana Norris",
            "Sa-Lin Bernstein",
            "Ramya Nair",
            "Elizabeth Jessup"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Various fields of science and engineering rely on linear algebra for large\nscale data analysis, modeling and simulation, machine learning, and other\napplied problems. Linear algebra computations often dominate the execution time\nof such applications. Meanwhile, experts in these domains typically lack the\ntraining or time required to develop efficient, high-performance\nimplementations of linear algebra algorithms. In the Lighthouse project, we\nenable developers with varied backgrounds to readily discover and effectively\napply the best available numerical software for their problems. We have\ndeveloped a search-based expert system that combines expert knowledge, machine\nlearningbased classification of existing numerical software collections, and\nautomated code generation and optimization. Lighthouse provides a novel\nsoftware engineering environment aimed at maximizing both developer\nproductivity and application performance for dense and sparse linear algebra\ncomputations.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.1363v1"
    },
    {
        "title": "Algorithm xxx: RIDC Methods -- A Family of Parallel Time-Integrators",
        "authors": [
            "Benjamin Ong",
            "Ronald Haynes",
            "Kyle Ladd"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Revisionist integral deferred correction (RIDC) methods are a family of\nparallel--in--time methods to solve systems of initial values problems. The\napproach is able to bootstrap lower order time integrators to provide high\norder approximations in approximately the same wall clock time, hence providing\na multiplicative increase in the number of compute cores utilized. Here we\nprovide a C++ framework which automatically produces a parallel--in--time\nsolution of a system of initial value problems given user supplied code for the\nright hand side of the system and a sequential code for a first-order time\nstep. The user supplied time step routine may be explicit or implicit and may\nmake use of any auxiliary libraries which take care of the solution of any\nnonlinear algebraic systems which may arise or the numerical linear algebra\nrequired. The code contains six examples of increasing complexity which also\nserve as templates to solve user defined problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.3082v2"
    },
    {
        "title": "Julia: A Fresh Approach to Numerical Computing",
        "authors": [
            "Jeff Bezanson",
            "Alan Edelman",
            "Stefan Karpinski",
            "Viral B. Shah"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Bridging cultures that have often been distant, Julia combines expertise from\nthe diverse fields of computer science and computational science to create a\nnew approach to numerical computing. Julia is designed to be easy and fast.\nJulia questions notions generally held as \"laws of nature\" by practitioners of\nnumerical computing:\n  1. High-level dynamic programs have to be slow.\n  2. One must prototype in one language and then rewrite in another language\nfor speed or deployment, and\n  3. There are parts of a system for the programmer, and other parts best left\nuntouched as they are built by the experts.\n  We introduce the Julia programming language and its design --- a dance\nbetween specialization and abstraction. Specialization allows for custom\ntreatment. Multiple dispatch, a technique from computer science, picks the\nright algorithm for the right circumstance. Abstraction, what good computation\nis really about, recognizes what remains the same after differences are\nstripped away. Abstractions in mathematics are captured as code through another\ntechnique from computer science, generic programming.\n  Julia shows that one can have machine performance without sacrificing human\nconvenience.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.1607v4"
    },
    {
        "title": "Twofolds in C and C++",
        "authors": [
            "Evgeny Latkin"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Here I propose C and C++ interfaces and experimental implementation for\ntwofolds arithmetic. I introduce twofolds in my previous article entitled\n\"Twofold fast arithmetic\" for tracking floating-point inaccuracy. Testing\nshows, plain C enables high-performance computing with twofolds. C++ interface\nenables coding as easily as ordinary floating-point numbers. My goal is\nconvincing you to try twofolds; I think assuring accuracy of math computations\nis worth its cost. Code and use examples available at my web site, references\ninside.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.5316v1"
    },
    {
        "title": "Visualizing Marden's theorem with Scilab",
        "authors": [
            "Klaus Rohe"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  A theorem which is named after the American Mathematician Moris Marden states\na very surprising and interesting fact concerning the relationship between the\npoints of a triangle in the complex plane and the zeros of two complex\npolynomials related to this triangle: \"Suppose the zeroes z1, z2, and z3 of a\nthird-degree polynomial p(z) are non-collinear. There is a unique ellipse\ninscribed in the triangle with vertices z1, z2, z3 and tangent to the sides at\ntheir midpoints: the Steiner in-ellipse. The foci of that ellipse are the\nzeroes of the derivative p'(z).\" (Wikipedia contributors, \"Marden's theorem\",\nhttp://en.wikipedia.org/wiki/Marden%27s_theorem). This document describes how\nScilab, a popular and powerful open source alternative to MATLAB, can be used\nto visualize the above stated theorem for arbitrary complex numbers z1, z2, and\nz3 which are not collinear. It is further demonstrated how the equations of the\nSteiner ellipses of a triangle in the complex plane can be calculated and\nplotted by applying this theorem.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.01367v2"
    },
    {
        "title": "Twofold exp and log",
        "authors": [
            "Evgeny Latkin"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  This article is about twofold arithmetic. Here I introduce algorithms and\nexperimental code for twofold variant of C/C++ standard functions exp() and\nlog(), and expm1() and log1p(). Twofold function $y_0+y_1 \\approx f(x_0+x_1)$\nis nearly 2x-precise so can assess accuracy of standard one. Performance allows\nassessing on-fly: twofold texp() over double is ~10x times faster than expq()\nby GNU quadmath.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.05216v1"
    },
    {
        "title": "An efficient multi-core implementation of a novel HSS-structured\n  multifrontal solver using randomized sampling",
        "authors": [
            "Pieter Ghysels",
            "Xiaoye S. Li",
            "Francois-Henry Rouet",
            "Samuel Williams",
            "Artem Napov"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We present a sparse linear system solver that is based on a multifrontal\nvariant of Gaussian elimination, and exploits low-rank approximation of the\nresulting dense frontal matrices. We use hierarchically semiseparable (HSS)\nmatrices, which have low-rank off-diagonal blocks, to approximate the frontal\nmatrices. For HSS matrix construction, a randomized sampling algorithm is used\ntogether with interpolative decompositions. The combination of the randomized\ncompression with a fast ULV HSS factorization leads to a solver with lower\ncomputational complexity than the standard multifrontal method for many\napplications, resulting in speedups up to 7 fold for problems in our test\nsuite. The implementation targets many-core systems by using task parallelism\nwith dynamic runtime scheduling. Numerical experiments show performance\nimprovements over state-of-the-art sparse direct solvers. The implementation\nachieves high performance and good scalability on a range of modern shared\nmemory parallel systems, including the Intel Xeon Phi (MIC). The code is part\nof a software package called STRUMPACK -- STRUctured Matrices PACKage, which\nalso has a distributed memory component for dense rank-structured matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07405v1"
    },
    {
        "title": "Fast Multiplication of Large Integers: Implementation and Analysis of\n  the DKSS Algorithm",
        "authors": [
            "Christoph Lüders"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The Sch\\\"onhage-Strassen algorithm (SSA) is the de-facto standard for\nmultiplication of large integers. For $N$-bit numbers it has a time bound of\n$O(N \\cdot \\log N \\cdot \\log \\log N)$. De, Kurur, Saha and Saptharishi (DKSS)\npresented an asymptotically faster algorithm with a better time bound of $N\n\\cdot \\log N \\cdot 2^{O(\\log^* N)}$. In this diploma thesis, results of an\nimplementation of DKSS multiplication are presented: run-time is about 30 times\nlarger than SSA, while memory requirements are about 3.75 times higher than\nSSA. A possible crossover point is estimated to be out of reach even if we\nutilized the whole universe for computer memory.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.04955v1"
    },
    {
        "title": "A distributed-memory package for dense Hierarchically Semi-Separable\n  matrix computations using randomization",
        "authors": [
            "François-Henry Rouet",
            "Xiaoye S. Li",
            "Pieter Ghysels",
            "Artem Napov"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We present a distributed-memory library for computations with dense\nstructured matrices. A matrix is considered structured if its off-diagonal\nblocks can be approximated by a rank-deficient matrix with low numerical rank.\nHere, we use Hierarchically Semi-Separable representations (HSS). Such matrices\nappear in many applications, e.g., finite element methods, boundary element\nmethods, etc. Exploiting this structure allows for fast solution of linear\nsystems and/or fast computation of matrix-vector products, which are the two\nmain building blocks of matrix computations. The compression algorithm that we\nuse, that computes the HSS form of an input dense matrix, relies on randomized\nsampling with a novel adaptive sampling mechanism. We discuss the\nparallelization of this algorithm and also present the parallelization of\nstructured matrix-vector product, structured factorization and solution\nroutines. The efficiency of the approach is demonstrated on large problems from\ndifferent academic and industrial applications, on up to 8,000 cores.\n  This work is part of a more global effort, the STRUMPACK (STRUctured Matrices\nPACKage) software package for computations with sparse and dense structured\nmatrices. Hence, although useful on their own right, the routines also\nrepresent a step in the direction of a distributed-memory sparse solver.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05464v2"
    },
    {
        "title": "GAIL---Guaranteed Automatic Integration Library in MATLAB: Documentation\n  for Version 2.1",
        "authors": [
            "Sou-Cheng T. Choi",
            "Yuhan Ding",
            "Fred J. Hickernell",
            "Lan Jiang",
            "Lluís Antoni Jiménez Rugama",
            "Xin Tong",
            "Yizhi Zhang",
            "Xuan Zhou"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Automatic and adaptive approximation, optimization, or integration of\nfunctions in a cone with guarantee of accuracy is a relatively new paradigm.\nOur purpose is to create an open-source MATLAB package, Guaranteed Automatic\nIntegration Library (GAIL), following the philosophy of reproducible research\nand sustainable practices of robust scientific software development. For our\nconviction that true scholarship in computational sciences are characterized by\nreliable reproducibility, we employ the best practices in mathematical research\nand software engineering known to us and available in MATLAB. This document\ndescribes the key features of functions in GAIL, which includes one-dimensional\nfunction approximation and minimization using linear splines, one-dimensional\nnumerical integration using trapezoidal rule, and last but not least, mean\nestimation and multidimensional integration by Monte Carlo methods or Quasi\nMonte Carlo methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06544v2"
    },
    {
        "title": "Finite element numerical integration for first order approximations on\n  multi-core architectures",
        "authors": [
            "Krzysztof Banaś",
            "Filip Krużel",
            "Jan Bielański"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The paper presents investigations on the implementation and performance of\nthe finite element numerical integration algorithm for first order\napproximations and three processor architectures, popular in scientific\ncomputing, classical CPU, Intel Xeon Phi and NVIDIA Kepler GPU. A unifying\nprogramming model and portable OpenCL implementation is considered for all\narchitectures. Variations of the algorithm due to different problems solved and\ndifferent element types are investigated and several optimizations aimed at\nproper optimization and mapping of the algorithm to computer architectures are\ndemonstrated. Performance models of execution are developed for different\nprocessors and tested in practical experiments. The results show the varying\nlevels of performance for different architectures, but indicate that the\nalgorithm can be effectively ported to all of them. The general conclusion is\nthat the finite element numerical integration can achieve sufficient\nperformance on different multi- and many-core architectures and should not\nbecome a performance bottleneck for finite element simulation codes. Specific\nobservations lead to practical advises on how to optimize the kernels and what\nperformance can be expected for the tested architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.01023v1"
    },
    {
        "title": "Symmetric matrix inversion using modified Gaussian elimination",
        "authors": [
            "Anton Kochnev",
            "Nicolai Savelov"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  In this paper we present two different variants of method for symmetric\nmatrix inversion, based on modified Gaussian elimination. Both methods avoid\ncomputation of square roots and have a reduced machine time's spending.\nFurther, both of them can be used efficiently not only for positive (semi-)\ndefinite, but for any non-singular symmetric matrix inversion. We use\nsimulation to verify results, which represented in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06734v1"
    },
    {
        "title": "Sparse Automatic Differentiation for Complex Networks of\n  Differential-Algebraic Equations Using Abstract Elementary Algebra",
        "authors": [
            "Slaven Peles",
            "Stefan Klus"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Most numerical solvers and libraries nowadays are implemented to use\nmathematical models created with language-specific built-in data types (e.g.\nreal in Fortran or double in C) and their respective elementary algebra\nimplementations. However, the built-in elementary algebra typically has limited\nfunctionality and often restricts the flexibility of mathematical models and\nthe analysis types that can be applied to those models. To overcome this\nlimitation, a number of domain-specific languages such as gPROMS or Modelica\nwith more feature-rich built-in data types have been proposed. In this paper,\nwe argue that if numerical libraries and solvers are designed to use abstract\nelementary algebra rather than the language-specific built-in algebra, modern\nmainstream languages can be as effective as any domain-specific language. We\nillustrate our ideas using the example of sparse Jacobian matrix computation.\nWe implement an automatic differentiation method that takes advantage of sparse\nsystem structures and is straightforward to parallelize in a distributed memory\nsetting. Furthermore, we show that the computational cost scales linearly with\nthe size of the system.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.00838v2"
    },
    {
        "title": "Documentation Generator Focusing on Symbols for the HTML-ized Mizar\n  Library",
        "authors": [
            "Kazuhisa Nakasho",
            "Yasunari Shidama"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The purpose of this project is to collect symbol information in the Mizar\nMathematical Library and manipulate it into practical and organized\ndocumentation. Inspired by the MathWiki project and API reference systems for\ncomputer programs, we developed a documentation generator focusing on symbols\nfor the HTML-ized Mizar library. The system has several helpful features,\nincluding a symbol list, incremental search, and a referrer list. It targets\nthose who use proof assistance systems, the volume of whose libraries has been\nrapidly increasing year by year.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.01577v1"
    },
    {
        "title": "Flexible, Scalable Mesh and Data Management using PETSc DMPlex",
        "authors": [
            "Michael Lange",
            "Matthew G. Knepley",
            "Gerard J. Gorman"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Designing a scientific software stack to meet the needs of the\nnext-generation of mesh-based simulation demands, not only scalable and\nefficient mesh and data management on a wide range of platforms, but also an\nabstraction layer that makes it useful for a wide range of application codes.\nCommon utility tasks, such as file I/O, mesh distribution, and work\npartitioning, should be delegated to external libraries in order to promote\ncode re-use, extensibility and software interoperability. In this paper we\ndemonstrate the use of PETSc's DMPlex data management API to perform mesh input\nand domain partitioning in Fluidity, a large scale CFD application. We\ndemonstrate that raising the level of abstraction adds new functionality to the\napplication code, such as support for additional mesh file formats and mesh re-\nordering, while improving simulation startup cost through more efficient mesh\ndistribution. Moreover, the separation of concerns accomplished through this\ninterface shifts critical performance and interoperability issues, such as\nscalable I/O and file format support, to a widely used and supported open\nsource community library, improving the sustainability, performance, and\nfunctionality of Fluidity.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.04633v1"
    },
    {
        "title": "Accelerating R with high performance linear algebra libraries",
        "authors": [
            "Bogdan Oancea",
            "Tudorel Andrei",
            "Raluca Mariana Dragoescu"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Linear algebra routines are basic building blocks for the statistical\nsoftware. In this paper we analyzed how can we can improve R performance for\nmatrix computations. We benchmarked few matrix operations using the standard\nlinear algebra libraries included in the R distribution and high performance\nlibraries like OpenBLAS, GotoBLAS and MKL. Our tests showed the the best\nresults are obtained with the MKL library, the other two libraries having\nsimilar performances, but lower than MKL\n",
        "pdf_link": "http://arxiv.org/pdf/1508.00688v1"
    },
    {
        "title": "Support for Non-conformal Meshes in PETSc's DMPlex Interface",
        "authors": [
            "Tobin Isaac",
            "Matthew G. Knepley"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  PETSc's DMPlex interface for unstructured meshes has been extended to support\nnon-conformal meshes. The topological construct that DMPlex implements---the\nCW-complex---is by definition conformal, so representing non- conformal meshes\nin a way that hides complexity requires careful attention to the interface\nbetween DMPlex and numerical methods such as the finite element method. Our\napproach---which combines a tree structure for subset- superset relationships\nand a \"reference tree\" describing the types of non-conformal\ninterfaces---allows finite element code written for conformal meshes to extend\nautomatically: in particular, all \"hanging-node\" constraint calculations are\nhandled behind the scenes. We give example code demonstrating the use of this\nextension, and use it to convert forests of quadtrees and forests of octrees\nfrom the p4est library to DMPlex meshes.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.02470v1"
    },
    {
        "title": "Complex additive geometric multilevel solvers for Helmholtz equations on\n  spacetrees",
        "authors": [
            "Bram Reps",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We introduce a family of implementations of low order, additive, geometric\nmultilevel solvers for systems of Helmholtz equations. Both grid spacing and\narithmetics may comprise complex numbers and we thus can apply complex scaling\ntechniques to the indefinite Helmholtz operator. Our implementations are based\nupon the notion of a spacetree and work exclusively with a finite number of\nprecomputed local element matrices. They are globally matrix-free.\n  Combining various relaxation factors with two grid transfer operators allows\nus to switch from pure additive multigrid over a hierarchical basis method into\nBPX with several multiscale smoothing variants within one code base. Pipelining\nallows us to realise a full approximation storage (FAS) scheme within the\nadditive environment where, amortised, each grid vertex carrying degrees of\nfreedom is read/written only once per iteration. The codes thus realise a\nsingle-touch policy. Among the features facilitated by matrix-free FAS is\narbitrary dynamic mesh refinement (AMR) for all solver variants. AMR as enabler\nfor full multigrid (FMG) cycling---the grid unfolds throughout the\ncomputation---allows us to reduce the cost per unknown per order of accuracy.\n  The present paper primary contributes towards software realisation and design\nquestions. Our experiments show that the consolidation of single-touch FAS,\ndynamic AMR and vectorisation-friendly, complex scaled, matrix-free FMG cycles\ndelivers a mature implementation blueprint for solvers for a non-trivial class\nof problems such as Helmholtz equations. Besides this validation, we put\nparticular emphasis on a strict implementation formalism as well as some\nimplementation correctness proofs.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.03954v3"
    },
    {
        "title": "POLYANA - A tool for the calculation of molecular radial distribution\n  functions based on Molecular Dynamics trajectories",
        "authors": [
            "Christos Dimitroulis",
            "Theophanes Raptis",
            "Vasilios Raptis"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We present an application for the calculation of radial distribution\nfunctions for molecular centres of mass, based on trajectories generated by\nmolecular simulation methods (Molecular Dynamics, Monte Carlo). When designing\nthis application, the emphasis was placed on ease of use as well as ease of\nfurther development. In its current version, the program can read trajectories\ngenerated by the well-known DL_POLY package, but it can be easily extended to\ntreat other formats. It is also very easy to 'hack' the program so it can\ncompute intermolecular radial distribution functions for groups of interaction\nsites rather than whole molecules.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.05374v1"
    },
    {
        "title": "Clone and graft: Testing scientific applications as they are built",
        "authors": [
            "Bruno Turcksin",
            "Timo Heister",
            "Wolfgang Bangerth"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  This article describes our experience developing and maintaining automated\ntests for scientific applications. The main idea evolves around building on\nalready existing tests by cloning and grafting. The idea is demonstrated on a\nminimal model problem written in Python.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.07231v1"
    },
    {
        "title": "Rust-Bio - a fast and safe bioinformatics library",
        "authors": [
            "Johannes Köster"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We present Rust-Bio, the first general purpose bioinformatics library for the\ninnovative Rust programming language. Rust-Bio leverages the unique combination\nof speed, memory safety and high-level syntax offered by Rust to provide a fast\nand safe set of bioinformatics algorithms and data structures with a focus on\nsequence analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.02796v1"
    },
    {
        "title": "The Stan Math Library: Reverse-Mode Automatic Differentiation in C++",
        "authors": [
            "Bob Carpenter",
            "Matthew D. Hoffman",
            "Marcus Brubaker",
            "Daniel Lee",
            "Peter Li",
            "Michael Betancourt"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  As computational challenges in optimization and statistical inference grow\never harder, algorithms that utilize derivatives are becoming increasingly more\nimportant. The implementation of the derivatives that make these algorithms so\npowerful, however, is a substantial user burden and the practicality of these\nalgorithms depends critically on tools like automatic differentiation that\nremove the implementation burden entirely. The Stan Math Library is a C++,\nreverse-mode automatic differentiation library designed to be usable, extensive\nand extensible, efficient, scalable, stable, portable, and redistributable in\norder to facilitate the construction and utilization of such algorithms.\n  Usability is achieved through a simple direct interface and a cleanly\nabstracted functional interface. The extensive built-in library includes\nfunctions for matrix operations, linear algebra, differential equation solving,\nand most common probability functions. Extensibility derives from a\nstraightforward object-oriented framework for expressions, allowing users to\neasily create custom functions. Efficiency is achieved through a combination of\ncustom memory management, subexpression caching, traits-based metaprogramming,\nand expression templates. Partial derivatives for compound functions are\nevaluated lazily for improved scalability. Stability is achieved by taking care\nwith arithmetic precision in algebraic expressions and providing stable,\ncompound functions where possible. For portability, the library is\nstandards-compliant C++ (03) and has been tested for all major compilers for\nWindows, Mac OS X, and Linux.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.07164v1"
    },
    {
        "title": "A novel code generation methodology for block diagram modeler and\n  simulators Scicos and VSS",
        "authors": [
            "Jean-Philippe Chancelier",
            "Ramine Nikoukhah"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Block operations during simulation in Scicos and VSS environments can\nnaturally be described as Nsp functions. But the direct use of Nsp functions\nfor simulation leads to poor performance since the Nsp language is interpreted,\nnot compiled. The methodology presented in this paper is used to develop a tool\nfor generating efficient compilable code, such as C and ADA, for Scicos and VSS\nmodels from these block Nsp functions. Operator overloading and partial\nevaluation are the key elements of this novel approach. This methodology may be\nused in other simulation environments such as Matlab/Simulink.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.02789v1"
    },
    {
        "title": "Approximation of boundary element matrices using GPGPUs and nested cross\n  approximation",
        "authors": [
            "Steffen Börm",
            "Sven Christophersen"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The efficiency of boundary element methods depends crucially on the time\nrequired for setting up the stiffness matrix. The far-field part of the matrix\ncan be approximated by compression schemes like the fast multipole method or\n$\\mathcal{H}$-matrix techniques. The near-field part is typically approximated\nby special quadrature rules like the Sauter-Schwab technique that can handle\nthe singular integrals appearing in the diagonal and near-diagonal matrix\nelements.\n  Since computing one element of the matrix requires only a small amount of\ndata but a fairly large number of operations, we propose to use general-purpose\ngraphics processing units (GPGPUs) to handle vectorizable portions of the\ncomputation: near-field computations are ideally suited for vectorization and\ncan therefore be handled very well by GPGPUs. Modern far-field compression\nschemes can be split into a small adaptive portion that exhibits divergent\ncontrol flows, and should therefore be handled by the CPU, and a vectorizable\nportion that can again be sent to GPGPUs.\n  We propose a hybrid algorithm that splits the computation into tasks for CPUs\nand GPGPUs. Our method presented in this article is able to reduce the setup\ntime of boundary integral operators by a significant factor of 19-30 for both\nthe Laplace and the Helmholtz equation in 3D when using two consumer GPGPUs\ncompared to a quad-core CPU.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.07244v2"
    },
    {
        "title": "Oasis: a high-level/high-performance open source Navier-Stokes solver",
        "authors": [
            "Mikael Mortensen",
            "Kristian Valen-Sendstad"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Oasis is a high-level/high-performance finite element Navier-Stokes solver\nwritten from scratch in Python using building blocks from the FEniCS project\n(fenicsproject.org). The solver is unstructured and targets large-scale\napplications in complex geometries on massively parallel clusters. Oasis\nutilizes MPI and interfaces, through FEniCS, to the linear algebra backend\nPETSc. Oasis advocates a high-level, programmable user interface through the\ncreation of highly flexible Python modules for new problems. Through the\nhigh-level Python interface the user is placed in complete control of every\naspect of the solver. A version of the solver, that is using piecewise linear\nelements for both velocity and pressure, is shown reproduce very well the\nclassical, spectral, turbulent channel simulations of Moser, Kim and Mansour at\n$Re_{\\tau}=180$ [Phys. Fluids, vol 11(4), p. 964]. The computational speed is\nstrongly dominated by the iterative solvers provided by the linear algebra\nbackend, which is arguably the best performance any similar implicit solver\nusing PETSc may hope for. Higher order accuracy is also demonstrated and new\nsolvers may be easily added within the same framework.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.03643v1"
    },
    {
        "title": "A Left-Looking Selected Inversion Algorithm and Task Parallelism on\n  Shared Memory Systems",
        "authors": [
            "Mathias Jacquelin",
            "Lin Lin",
            "Weile Jia",
            "Yonghua Zhao",
            "Chao Yang"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Given a sparse matrix $A$, the selected inversion algorithm is an efficient\nmethod for computing certain selected elements of $A^{-1}$. These selected\nelements correspond to all or some nonzero elements of the LU factors of $A$.\nIn many ways, the type of matrix updates performed in the selected inversion\nalgorithm is similar to that performed in the LU factorization, although the\nsequence of operation is different. In the context of LU factorization, it is\nknown that the left-looking and right-looking algorithms exhibit different\nmemory access and data communication patterns, and hence different behavior on\nshared memory and distributed memory parallel machines. Corresponding to\nright-looking and left-looking LU factorization, selected inversion algorithm\ncan be organized as a left-looking and a right-looking algorithm. The parallel\nright-looking version of the algorithm has been developed in [1]. The sequence\nof operations performed in this version of the selected inversion algorithm is\nsimilar to those performed in a left-looking LU factorization algorithm. In\nthis paper, we describe the left-looking variant of the selected inversion\nalgorithm, and based on task parallel method, present an efficient\nimplementation of the algorithm for shared memory machines. We demonstrate that\nwith the task scheduling features provided by OpenMP 4.0, the left-looking\nselected inversion algorithm can scale well both on the Intel Haswell multicore\narchitecture and on the Intel Knights Corner (KNC) manycore architecture.\nCompared to the right-looking selected inversion algorithm, the left-looking\nformulation facilitates pipelining of work along different branches of the\nelimination tree, and can be a promising candidate for future development of\nmassively parallel selected inversion algorithms on heterogeneous architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.02528v1"
    },
    {
        "title": "An algorithm for the optimization of finite element integration loops",
        "authors": [
            "Fabio Luporini",
            "David A. Ham",
            "Paul H. J. Kelly"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present an algorithm for the optimization of a class of finite element\nintegration loop nests. This algorithm, which exploits fundamental mathematical\nproperties of finite element operators, is proven to achieve a locally optimal\noperation count. In specified circumstances the optimum achieved is global.\nExtensive numerical experiments demonstrate significant performance\nimprovements over the state of the art in finite element code generation in\nalmost all cases. This validates the effectiveness of the algorithm presented\nhere, and illustrates its limitations.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.05872v1"
    },
    {
        "title": "A structure-exploiting numbering algorithm for finite elements on\n  extruded meshes, and its performance evaluation in Firedrake",
        "authors": [
            "Gheorghe-Teodor Bercea",
            "Andrew T. T. McRae",
            "David A. Ham",
            "Lawrence Mitchell",
            "Florian Rathgeber",
            "Luigi Nardi",
            "Fabio Luporini",
            "Paul H. J. Kelly"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present a generic algorithm for numbering and then efficiently iterating\nover the data values attached to an extruded mesh. An extruded mesh is formed\nby replicating an existing mesh, assumed to be unstructured, to form layers of\nprismatic cells. Applications of extruded meshes include, but are not limited\nto, the representation of 3D high aspect ratio domains employed by geophysical\nfinite element simulations. These meshes are structured in the extruded\ndirection. The algorithm presented here exploits this structure to avoid the\nperformance penalty traditionally associated with unstructured meshes. We\nevaluate the implementation of this algorithm in the Firedrake finite element\nsystem on a range of low compute intensity operations which constitute worst\ncases for data layout performance exploration. The experiments show that having\nstructure along the extruded direction enables the cost of the indirect data\naccesses to be amortized after 10-20 layers as long as the underlying mesh is\nwell-ordered. We characterise the resulting spatial and temporal reuse in a\nrepresentative set of both continuous-Galerkin and discontinuous-Galerkin\ndiscretisations. On meshes with realistic numbers of layers the performance\nachieved is between 70% and 90% of a theoretical hardware-specific limit.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.05937v3"
    },
    {
        "title": "Convex Hull Calculations: a Matlab Implementation and Correctness Proofs\n  for the lrs-Algorithm",
        "authors": [
            "Alexander Kovačec",
            "Bernardete Ribeiro"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  This paper provides full \\Matlab-code and informal correctness proofs for the\nlexicographic reverse search algorithm for convex hull calculations. The\nimplementation was tested on a 1993 486-PC for various small and some larger,\npartially highly degenerate combinatorial polytopes, one of which (a certain\n13-dimensional 24 vertex polyhedron) occurs naturally in the study of a well\nknown problem posed by Professor Graciano de Oliveira: see end of section 1.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.06112v1"
    },
    {
        "title": "Extreme-scale Multigrid Components within PETSc",
        "authors": [
            "Dave A. May",
            "Patrick Sanan",
            "Karl Rupp",
            "Matthew G. Knepley",
            "Barry F. Smith"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Elliptic partial differential equations (PDEs) frequently arise in continuum\ndescriptions of physical processes relevant to science and engineering.\nMultilevel preconditioners represent a family of scalable techniques for\nsolving discrete PDEs of this type and thus are the method of choice for\nhigh-resolution simulations. The scalability and time-to-solution of massively\nparallel multilevel preconditioners can be adversely effected by using a\ncoarse-level solver with sub-optimal algorithmic complexity. To maintain\nscalability, agglomeration techniques applied to the coarse level have been\nshown to be necessary.\n  In this work, we present a new software component introduced within the\nPortable Extensible Toolkit for Scientific computation (PETSc) which permits\nagglomeration. We provide an overview of the design and implementation of this\nfunctionality, together with several use cases highlighting the benefits of\nagglomeration. Lastly, we demonstrate via numerical experiments employing\ngeometric multigrid with structured meshes, the flexibility and performance\ngains possible using our MPI-rank agglomeration implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.07163v1"
    },
    {
        "title": "Implementation of $hp$-adaptive discontinuous finite element methods in\n  Dune-Fem",
        "authors": [
            "Christoph Gersbacher"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  In this paper we describe generic algorithms and data structures for the\nimplementation of $hp$-adaptive discontinuous finite element methods in the\nDune-Fem library. Special attention is given to the often tedious and\nerror-prone task of transferring user data during adaptation. Simultaneously,\nwe generalize the approach to the restriction and prolongation of data\ncurrently implemented in Dune-Fem to the case of $p$- and $hp$-adaptation. The\ndune-fem-hpdg module described in this paper provides an extensible reference\nimplementation of $hp$-adaptive discontinuous discrete function spaces. We give\ndetails on its implementation and the extended adaptive interface. As proof of\nconcept we present the practical realization of an $hp$-adaptive interior\npenalty method for elliptic problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.07242v1"
    },
    {
        "title": "Benchmarking Python Tools for Automatic Differentiation",
        "authors": [
            "Andrei Turkin",
            "Aung Thu"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  In this paper we compare several Python tools for automatic differentiation.\nIn order to assess the difference in performance and precision, the problem of\nfinding the optimal geometrical structure of the cluster with identical atoms\nis used as follows. First, we compare performance of calculating gradients for\nthe objective function. We showed that the PyADOL-C and PyCppAD tools have much\nbetter performance for big clusters than the other ones. Second, we assess\nprecision of these two tools by calculating the difference between the obtained\nat the optimal configuration gradient norms. We conclude that PyCppAD has the\nbest performance among others, while having almost the same precision as the\nsecond- best performing tool - PyADOL-C.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.06311v1"
    },
    {
        "title": "jInv -- a flexible Julia package for PDE parameter estimation",
        "authors": [
            "Lars Ruthotto",
            "Eran Treister",
            "Eldad Haber"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Estimating parameters of Partial Differential Equations (PDEs) from noisy and\nindirect measurements often requires solving ill-posed inverse problems. These\nso called parameter estimation or inverse medium problems arise in a variety of\napplications such as geophysical, medical imaging, and nondestructive testing.\nTheir solution is computationally intense since the underlying PDEs need to be\nsolved numerous times until the reconstruction of the parameters is\nsufficiently accurate. Typically, the computational demand grows significantly\nwhen more measurements are available, which poses severe challenges to\ninversion algorithms as measurement devices become more powerful.\n  In this paper we present jInv, a flexible framework and open source software\nthat provides parallel algorithms for solving parameter estimation problems\nwith many measurements. Being written in the expressive programming language\nJulia, jInv is portable, easy to understand and extend, cross-platform tested,\nand well-documented. It provides novel parallelization schemes that exploit the\ninherent structure of many parameter estimation problems and can be used to\nsolve multiphysics inversion problems as is demonstrated using numerical\nexperiments motivated by geophysical imaging.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.07399v2"
    },
    {
        "title": "Using the pyMIC Offload Module in PyFR",
        "authors": [
            "Michael Klemm",
            "Freddie Witherden",
            "Peter Vincent"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  PyFR is an open-source high-order accurate computational fluid dynamics\nsolver for unstructured grids. It is designed to efficiently solve the\ncompressible Navier-Stokes equations on a range of hardware platforms,\nincluding GPUs and CPUs. In this paper we will describe how the Python Offload\nInfrastructure for the Intel Many Integrated Core Architecture (pyMIC) was used\nto enable PyFR to run with near native performance on the Intel Xeon Phi\ncoprocessor. We will introduce the architecture of both pyMIC and PyFR and\npresent a variety of examples showcasing the capabilities of pyMIC. Further, we\nwill also compare the contrast pyMIC to other approaches including native\nexecution and OpenCL. The process of adding support for pyMIC into PyFR will be\ndescribed in detail. Benchmark results show that for a standard cylinder flow\nproblem PyFR with pyMIC is able achieve 240 GFLOP/s of sustained double\nprecision floating point performance; for a 1.85 times improvement over PyFR\nwith C/OpenMP on a 12 core Intel Xeon E5-2697 v2 CPU.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.00844v1"
    },
    {
        "title": "Massively parallel implementation in Python of a pseudo-spectral DNS\n  code for turbulent flows",
        "authors": [
            "Mikael Mortensen"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Direct Numerical Simulations (DNS) of the Navier Stokes equations is a\nvaluable research tool in fluid dynamics, but there are very few publicly\navailable codes and, due to heavy number crunching, codes are usually written\nin low-level languages. In this work a \\textasciitilde{}100 line standard\nscientific Python DNS code is described that nearly matches the performance of\npure C for thousands of processors and billions of unknowns. With optimization\nof a few routines in Cython, it is found to match the performance of a more or\nless identical solver implemented from scratch in C++. Keys to the efficiency\nof the solver are the mesh decomposition and three dimensional FFT routines,\nimplemented directly in Python using MPI, wrapped through MPI for Python, and a\nserial FFT module (both numpy.fft or pyFFTW may be used). Two popular\ndecomposition strategies, slab and pencil, have been implemented and tested.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.00850v1"
    },
    {
        "title": "Form Follows Function -- Do algorithms and applications challenge or\n  drag behind the hardware evolution?",
        "authors": [
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We summarise some of the key statements made at the workshop Form Follows\nFunction at ISC High Performance 2016. The summary highlights what type of\nco-design the presented projects experience; often in the absence of an\nexplicit co-design agenda. Their software development picks up hardware trends\nbut it also influences the hardware development. Observations illustrate that\nthis cycle not always is optimal for both sides as it is not proactively\nsteered. Key statements characterise ideas how it might be possible to\nintegrate both hardware and software creation closer to the best of both\nworlds---again even without classic co-design in mind where new pieces of\nhardware are created. The workshop finally identified three development idioms\nthat might help to improve software and system design with respect to emerging\nhardware.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.02835v1"
    },
    {
        "title": "Generalized Sampling in Julia",
        "authors": [
            "Robert Dahl Jacobsen",
            "Morten Nielsen",
            "Morten Grud Rasmussen"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Generalized sampling is a numerically stable framework for obtaining\nreconstructions of signals in different bases and frames from their samples. In\nthis paper, we will introduce a carefully documented toolbox for performing\ngeneralized sampling in Julia. Julia is a new language for technical computing\nwith focus on performance, which is ideally suited to handle the large size\nproblems often encountered in generalized sampling. The toolbox provides\nspecialized solutions for the setup of Fourier bases and wavelets. The\nperformance of the toolbox is compared to existing implementations of\ngeneralized sampling in MATLAB.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.04091v2"
    },
    {
        "title": "Finite Element Integration with Quadrature on the GPU",
        "authors": [
            "Matthew G. Knepley",
            "Karl Rupp",
            "Andy R. Terrel"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present a novel, quadrature-based finite element integration method for\nlow-order elements on GPUs, using a pattern we call \\textit{thread\ntransposition} to avoid reductions while vectorizing aggressively. On the\nNVIDIA GTX580, which has a nominal single precision peak flop rate of 1.5 TF/s\nand a memory bandwidth of 192 GB/s, we achieve close to 300 GF/s for element\nintegration on first-order discretization of the Laplacian operator with\nvariable coefficients in two dimensions, and over 400 GF/s in three dimensions.\nFrom our performance model we find that this corresponds to 90\\% of our\nmeasured achievable bandwidth peak of 310 GF/s. Further experimental results\nalso match the predicted performance when used with double precision (120 GF/s\nin two dimensions, 150 GF/s in three dimensions). Results obtained for the\nlinear elasticity equations (220 GF/s and 70 GF/s in two dimensions, 180 GF/s\nand 60 GF/s in three dimensions) also demonstrate the applicability of our\nmethod to vector-valued partial differential equations.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.04245v1"
    },
    {
        "title": "Forward-Mode Automatic Differentiation in Julia",
        "authors": [
            "Jarrett Revels",
            "Miles Lubin",
            "Theodore Papamarkou"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present ForwardDiff, a Julia package for forward-mode automatic\ndifferentiation (AD) featuring performance competitive with low-level languages\nlike C++. Unlike recently developed AD tools in other popular high-level\nlanguages such as Python and MATLAB, ForwardDiff takes advantage of\njust-in-time (JIT) compilation to transparently recompile AD-unaware user code,\nenabling efficient support for higher-order differentiation and differentiation\nusing custom number types (including complex numbers). For gradient and\nJacobian calculations, ForwardDiff provides a variant of vector-forward mode\nthat avoids expensive heap allocation and makes better use of memory bandwidth\nthan traditional vector mode. In our numerical experiments, we demonstrate that\nfor nontrivially large dimensions, ForwardDiff's gradient computations can be\nfaster than a reverse-mode implementation from the Python-based autograd\npackage. We also illustrate how ForwardDiff is used effectively within JuMP, a\nmodeling language for optimization. According to our usage statistics, 41\nunique repositories on GitHub depend on ForwardDiff, with users from diverse\nfields such as astronomy, optimization, finite element analysis, and\nstatistics.\n  This document is an extended abstract that has been accepted for presentation\nat the AD2016 7th International Conference on Algorithmic Differentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.07892v1"
    },
    {
        "title": "An Asynchronous Task-based Fan-Both Sparse Cholesky Solver",
        "authors": [
            "Mathias Jacquelin",
            "Yili Zheng",
            "Esmond Ng",
            "Katherine Yelick"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Systems of linear equations arise at the heart of many scientific and\nengineering applications. Many of these linear systems are sparse; i.e., most\nof the elements in the coefficient matrix are zero. Direct methods based on\nmatrix factorizations are sometimes needed to ensure accurate solutions. For\nexample, accurate solution of sparse linear systems is needed in shift-invert\nLanczos to compute interior eigenvalues. The performance and resource usage of\nsparse matrix factorizations are critical to time-to-solution and maximum\nproblem size solvable on a given platform. In many applications, the\ncoefficient matrices are symmetric, and exploiting symmetry will reduce both\nthe amount of work and storage cost required for factorization. When the\nfactorization is performed on large-scale distributed memory platforms,\ncommunication cost is critical to the performance of the algorithm. At the same\ntime, network topologies have become increasingly complex, so that modern\nplatforms exhibit a high level of performance variability. This makes\nscheduling of computations an intricate and performance-critical task. In this\npaper, we investigate the use of an asynchronous task paradigm, one-sided\ncommunication and dynamic scheduling in implementing sparse Cholesky\nfactorization (symPACK) on large-scale distributed memory platforms. Our solver\nsymPACK relies on efficient and flexible communication primitives provided by\nthe UPC++ library. Performance evaluation shows good scalability and that\nsymPACK outperforms state-of-the-art parallel distributed memory factorization\npackages, validating our approach on practical cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.00044v2"
    },
    {
        "title": "BLISlab: A Sandbox for Optimizing GEMM",
        "authors": [
            "Jianyu Huang",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Matrix-matrix multiplication is a fundamental operation of great importance\nto scientific computing and, increasingly, machine learning. It is a simple\nenough concept to be introduced in a typical high school algebra course yet in\npractice important enough that its implementation on computers continues to be\nan active research topic. This note describes a set of exercises that use this\noperation to illustrate how high performance can be attained on modern CPUs\nwith hierarchical memories (multiple caches). It does so by building on the\ninsights that underly the BLAS-like Library Instantiation Software (BLIS)\nframework by exposing a simplified \"sandbox\" that mimics the implementation in\nBLIS. As such, it also becomes a vehicle for the \"crowd sourcing\" of the\noptimization of BLIS. We call this set of exercises BLISlab.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.00076v1"
    },
    {
        "title": "Automatic Generation of Vectorized Montgomery Algorithm",
        "authors": [
            "Lingchuan Meng"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Modular arithmetic is widely used in crytography and symbolic computation.\nThis paper presents a vectorized Montgomery algorithm for modular\nmultiplication, the key to fast modular arithmetic, that fully utilizes the\nSIMD instructions. We further show how the vectorized algorithm can be\nautomatically generated by the {\\SPIRAL} system, as part of the effort for\nautomatic generation of a modular polynomial multiplication library.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.00999v1"
    },
    {
        "title": "cesium: Open-Source Platform for Time-Series Inference",
        "authors": [
            "Brett Naul",
            "Stéfan van der Walt",
            "Arien Crellin-Quick",
            "Joshua S. Bloom",
            "Fernando Pérez"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Inference on time series data is a common requirement in many scientific\ndisciplines and internet of things (IoT) applications, yet there are few\nresources available to domain scientists to easily, robustly, and repeatably\nbuild such complex inference workflows: traditional statistical models of time\nseries are often too rigid to explain complex time domain behavior, while\npopular machine learning packages require already-featurized dataset inputs.\nMoreover, the software engineering tasks required to instantiate the\ncomputational platform are daunting. cesium is an end-to-end time series\nanalysis framework, consisting of a Python library as well as a web front-end\ninterface, that allows researchers to featurize raw data and apply modern\nmachine learning techniques in a simple, reproducible, and extensible way.\nUsers can apply out-of-the-box feature engineering workflows as well as save\nand replay their own analyses. Any steps taken in the front end can also be\nexported to a Jupyter notebook, so users can iterate between possible models\nwithin the front end and then fine-tune their analysis using the additional\ncapabilities of the back-end library. The open-source packages make us of many\nuse modern Python toolkits, including xarray, dask, Celery, Flask, and\nscikit-learn.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.04504v1"
    },
    {
        "title": "ForestClaw: A parallel algorithm for patch-based adaptive mesh\n  refinement on a forest of quadtrees",
        "authors": [
            "Donna Calhoun",
            "Carsten Burstedde"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We describe a parallel, adaptive, multi-block algorithm for explicit\nintegration of time dependent partial differential equations on two-dimensional\nCartesian grids. The grid layout we consider consists of a nested hierarchy of\nfixed size, non-overlapping, logically Cartesian grids stored as leaves in a\nquadtree. Dynamic grid refinement and parallel partitioning of the grids is\ndone through the use of the highly scalable quadtree/octree library p4est.\nBecause our concept is multi-block, we are able to easily solve on a variety of\ngeometries including the cubed sphere. In this paper, we pay special attention\nto providing details of the parallel ghost-filling algorithm needed to ensure\nthat both corner and edge ghost regions around each grid hold valid values.\n  We have implemented this algorithm in the ForestClaw code using single-grid\nsolvers from ClawPack, a software package for solving hyperbolic PDEs using\nfinite volumes methods. We show weak and strong scalability results for scalar\nadvection problems on two-dimensional manifold domains on 1 to 64Ki MPI\nprocesses, demonstrating neglible regridding overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.03116v1"
    },
    {
        "title": "BLASFEO: basic linear algebra subroutines for embedded optimization",
        "authors": [
            "Gianluca Frison",
            "Dimitris Kouzoupis",
            "Tommaso Sartor",
            "Andrea Zanelli",
            "Moritz Diehl"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  BLASFEO is a dense linear algebra library providing high-performance\nimplementations of BLAS- and LAPACK-like routines for use in embedded\noptimization. A key difference with respect to existing high-performance\nimplementations of BLAS is that the computational performance is optimized for\nsmall to medium scale matrices, i.e., for sizes up to a few hundred. BLASFEO\ncomes with three different implementations: a high-performance implementation\naiming at providing the highest performance for matrices fitting in cache, a\nreference implementation providing portability and embeddability and optimized\nfor very small matrices, and a wrapper to standard BLAS and LAPACK providing\nhigh-performance on large matrices. The three implementations of BLASFEO\ntogether provide high-performance dense linear algebra routines for matrices\nranging from very small to large. Compared to both open-source and proprietary\nhighly-tuned BLAS libraries, for matrices of size up to about one hundred the\nhigh-performance implementation of BLASFEO is about 20-30% faster than the\ncorresponding level 3 BLAS routines and 2-3 times faster than the corresponding\nLAPACK routines.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.02457v3"
    },
    {
        "title": "Strassen's Algorithm for Tensor Contraction",
        "authors": [
            "Jianyu Huang",
            "Devin A. Matthews",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Tensor contraction (TC) is an important computational kernel widely used in\nnumerous applications. It is a multi-dimensional generalization of matrix\nmultiplication (GEMM). While Strassen's algorithm for GEMM is well studied in\ntheory and practice, extending it to accelerate TC has not been previously\npursued. Thus, we believe this to be the first paper to demonstrate how one can\nin practice speed up tensor contraction with Strassen's algorithm. By adopting\na Block-Scatter-Matrix format, a novel matrix-centric tensor layout, we can\nconceptually view TC as GEMM for a general stride storage, with an implicit\ntensor-to-matrix transformation. This insight enables us to tailor a recent\nstate-of-the-art implementation of Strassen's algorithm to TC, avoiding\nexplicit transpositions (permutations) and extra workspace, and reducing the\noverhead of memory movement that is incurred. Performance benefits are\ndemonstrated with a performance model as well as in practice on modern single\ncore, multicore, and distributed memory parallel architectures, achieving up to\n1.3x speedup. The resulting implementations can serve as a drop-in replacement\nfor various applications with significant speedup.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.03092v1"
    },
    {
        "title": "DATeS: A Highly-Extensible Data Assimilation Testing Suite v1.0",
        "authors": [
            "Ahmed Attia",
            "Adrian Sandu"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  A flexible and highly-extensible data assimilation testing suite, named\nDATeS, is described in this paper. DATeS aims to offer a unified testing\nenvironment that allows researchers to compare different data assimilation\nmethodologies and understand their performance in various settings. The core of\nDATeS is implemented in Python and takes advantage of its object-oriented\ncapabilities. The main components of the package (the numerical models, the\ndata assimilation algorithms, the linear algebra solvers, and the time\ndiscretization routines) are independent of each other, which offers great\nflexibility to configure data assimilation applications. DATeS can interface\neasily with large third-party numerical models written in Fortran or in C, and\nwith a plethora of external solvers.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.05594v2"
    },
    {
        "title": "A Novel Hybrid Quicksort Algorithm Vectorized using AVX-512 on Intel\n  Skylake",
        "authors": [
            "Berenger Bramas"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The modern CPU's design, which is composed of hierarchical memory and\nSIMD/vectorization capability, governs the potential for algorithms to be\ntransformed into efficient implementations. The release of the AVX-512 changed\nthings radically, and motivated us to search for an efficient sorting algorithm\nthat can take advantage of it. In this paper, we describe the best strategy we\nhave found, which is a novel two parts hybrid sort, based on the well-known\nQuicksort algorithm. The central partitioning operation is performed by a new\nalgorithm, and small partitions/arrays are sorted using a branch-free\nBitonic-based sort. This study is also an illustration of how classical\nalgorithms can be adapted and enhanced by the AVX-512 extension. We evaluate\nthe performance of our approach on a modern Intel Xeon Skylake and assess the\ndifferent layers of our implementation by sorting/partitioning integers, double\nfloating-point numbers, and key/value pairs of integers. Our results\ndemonstrate that our approach is faster than two libraries of reference: the\nGNU \\emph{C++} sort algorithm by a speedup factor of 4, and the Intel IPP\nlibrary by a speedup factor of 1.4.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.08579v2"
    },
    {
        "title": "cuTT: A High-Performance Tensor Transpose Library for CUDA Compatible\n  GPUs",
        "authors": [
            "Antti-Pekka Hynninen",
            "Dmitry I. Lyakh"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We introduce the CUDA Tensor Transpose (cuTT) library that implements\nhigh-performance tensor transposes for NVIDIA GPUs with Kepler and above\narchitectures. cuTT achieves high performance by (a) utilizing two\nGPU-optimized transpose algorithms that both use a shared memory buffer in\norder to reduce global memory access scatter, and by (b) computing memory\npositions of tensor elements using a thread-parallel algorithm. We evaluate the\nperformance of cuTT on a variety of benchmarks with tensor ranks ranging from 2\nto 12 and show that cuTT performance is independent of the tensor rank and that\nit performs no worse than an approach based on code generation. We develop a\nheuristic scheme for choosing the optimal parameters for tensor transpose\nalgorithms by implementing an analytical GPU performance model that can be used\nat runtime without need for performance measurements or profiling. Finally, by\nintegrating cuTT into the tensor algebra library TAL-SH, we significantly\nreduce the tensor transpose overhead in tensor contractions, achieving as low\nas just one percent overhead for arithmetically intensive tensor contractions.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.01598v1"
    },
    {
        "title": "Introducing Geometric Algebra to Geometric Computing Software\n  Developers: A Computational Thinking Approach",
        "authors": [
            "Ahmad Hosny Eid"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Designing software systems for Geometric Computing applications can be a\nchallenging task. Software engineers typically use software abstractions to\nhide and manage the high complexity of such systems. Without the presence of a\nunifying algebraic system to describe geometric models, the use of software\nabstractions alone can result in many design and maintenance problems.\nGeometric Algebra (GA) can be a universal abstract algebraic language for\nsoftware engineering geometric computing applications. Few sources, however,\nprovide enough information about GA-based software implementations targeting\nthe software engineering community. In particular, successfully introducing GA\nto software engineers requires quite different approaches from introducing GA\nto mathematicians or physicists. This article provides a high-level\nintroduction to the abstract concepts and algebraic representations behind the\nelegant GA mathematical structure. The article focuses on the conceptual and\nrepresentational abstraction levels behind GA mathematics with sufficient\nreferences for more details. In addition, the article strongly recommends\napplying the methods of Computational Thinking in both introducing GA to\nsoftware engineers, and in using GA as a mathematical language for developing\nGeometric Computing software systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.06668v1"
    },
    {
        "title": "Sparse Matrix Multiplication On An Associative Processor",
        "authors": [
            "L. Yavits",
            "A. Morad",
            "R. Ginosar"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Sparse matrix multiplication is an important component of linear algebra\ncomputations. Implementing sparse matrix multiplication on an associative\nprocessor (AP) enables high level of parallelism, where a row of one matrix is\nmultiplied in parallel with the entire second matrix, and where the execution\ntime of vector dot product does not depend on the vector size. Four sparse\nmatrix multiplication algorithms are explored in this paper, combining AP and\nbaseline CPU processing to various levels. They are evaluated by simulation on\na large set of sparse matrices. The computational complexity of sparse matrix\nmultiplication on AP is shown to be an O(nnz) where nnz is the number of\nnonzero elements. The AP is found to be especially efficient in binary sparse\nmatrix multiplication. AP outperforms conventional solutions in power\nefficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.07282v1"
    },
    {
        "title": "Practically efficient methods for performing bit-reversed permutation in\n  C++11 on the x86-64 architecture",
        "authors": [
            "Christian Knauth",
            "Boran Adas",
            "Daniel Whitfield",
            "Xuesong Wang",
            "Lydia Ickler",
            "Tim Conrad",
            "Oliver Serang"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The bit-reversed permutation is a famous task in signal processing and is key\nto efficient implementation of the fast Fourier transform. This paper presents\noptimized C++11 implementations of five extant methods for computing the\nbit-reversed permutation: Stockham auto-sort, naive bitwise swapping, swapping\nvia a table of reversed bytes, local pairwise swapping of bits, and swapping\nvia a cache-localized matrix buffer. Three new strategies for performing the\nbit-reversed permutation in C++11 are proposed: an inductive method using the\nbitwise XOR operation, a template-recursive closed form, and a cache-oblivious\ntemplate-recursive approach, which reduces the bit-reversed permutation to\nsmaller bit-reversed permutations and a square matrix transposition. These new\nmethods are compared to the extant approaches in terms of theoretical runtime,\nempirical compile time, and empirical runtime. The template-recursive\ncache-oblivious method is shown to be competitive with the fastest known\nmethod; however, we demonstrate that the cache-oblivious method can more\nreadily benefit from parallelization on multiple cores and on the GPU.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.01873v1"
    },
    {
        "title": "From MPI to MPI+OpenACC: Conversion of a legacy FORTRAN PCG solver for\n  the spherical Laplace equation",
        "authors": [
            "Ronald M. Caplan",
            "Zoran Mikic",
            "Jon A. Linker"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  A real-world example of adding OpenACC to a legacy MPI FORTRAN Preconditioned\nConjugate Gradient code is described, and timing results for multi-node\nmulti-GPU runs are shown. The code is used to obtain three-dimensional\nspherical solutions to the Laplace equation. Its application is finding\npotential field solutions of the solar corona, a useful tool in space weather\nmodeling. We highlight key tips, strategies, and challenges faced when adding\nOpenACC. Performance results are shown for running the code with MPI-only on\nmultiple CPUs, and with MPI+OpenACC on multiple GPUs and CPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.01126v2"
    },
    {
        "title": "High-Performance Derivative Computations using CoDiPack",
        "authors": [
            "Max Sagebaum",
            "Tim Albring",
            "Nicolas R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  There are several AD tools available, which all implement different\nstrategies for the reverse mode of AD. The major strategies are primal value\ntaping (implemented e.g. by ADOL-c) and Jacobi taping (implemented e.g. by\nadept and dco/c++). Especially for Jacobi taping, recent advances by using\nexpression templates make this approach very attractive for large scale\nsoftware. The current implementations are either closed source or miss\nessential features and flexibility. Therefore, we present the new AD tool\nCoDiPack (Code Differentiation Package) in this paper. It is specifically\ndesigned for a minimal memory consumption and optimal runtime, such that it can\nbe used for the differentiation of large scale software. An essential part of\nthe design of CoDiPack is the modular layout and the recursive data structures,\nwhich do not only allow the efficient implementation of the Jacobi taping\napproach, but will also enable other approaches like the primal value taping or\nnew research ideas. We will also present the performance value of CoDiPack on a\ngeneric PDE example and on the SU2 code.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.07229v1"
    },
    {
        "title": "CGAlgebra: a Mathematica package for conformal geometric algebra. v.2.0",
        "authors": [
            "E. Alejandra Ortiz-Duran",
            "Jose L. Aragon"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  A tutorial of the Mathematica package CGAlgebra, for conformal geometric\nalgebra calculations is presented. Using rule-based programming, the\n5-dimensional conformal geometric algebra is implemented and defined functions\nsimplify the calculations of geometric, outer and inner products, as well as\nmany other calculations related with geometric transformations. CGAlgebra is\navailable from https://github.com/jlaragonvera/Geometric-Algebra\n",
        "pdf_link": "http://arxiv.org/pdf/1711.02513v3"
    },
    {
        "title": "PQSER: A Matlab package for spectral seriation",
        "authors": [
            "Anna Concas",
            "Caterina Fenu",
            "Giuseppe Rodriguez"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The seriation problem is an important ordering issue which consists of\nfinding the best ordering of a set of units whose interrelationship is defined\nby a bipartite graph. It has important applications in, e.g., archaeology,\nanthropology, psychology, and biology. This paper presents a Matlab\nimplementation of an algorithm for spectral seriation by Atkins et al., based\non the use of the Fiedler vector of the Laplacian matrix associated to the\nproblem, which encodes the set of admissible solutions into a PQ-tree. We\nintroduce some numerical technicalities in the original algorithm to improve\nits performance, and point out that the presence of a multiple Fiedler value\nmay have a substantial influence on the computation of an approximated\nsolution, in the presence of inconsistent data sets. Practical examples and\nnumerical experiments show how to use the toolbox to process data sets deriving\nfrom real-world applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.05677v2"
    },
    {
        "title": "Abaqus2Matlab: A suitable tool for finite element post-processing",
        "authors": [
            "George Papazafeiropoulos",
            "Miguel Muñiz-Calvente",
            "Emilio Martínez-Pañeda"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  A suitable piece of software is presented to connect Abaqus, a sophisticated\nfinite element package, with Matlab, the most comprehensive program for\nmathematical analysis. This interface between these well-known codes not only\nbenefits from the image processing and the integrated graph-plotting features\nof Matlab but also opens up new opportunities in results post-processing,\nstatistical analysis and mathematical optimization, among many other\npossibilities. The software architecture and usage are appropriately described\nand two problems of particular engineering significance are addressed to\ndemonstrate its capabilities. Firstly, the software is employed to assess\ncleavage fracture through a novel 3-parameter Weibull probabilistic framework.\nThen, its potential to create and train neural networks is used to identify\ndamage parameters through a hybrid experimental-numerical scheme, and model\ncrack propagation in structural materials by means of a cohesive zone approach.\nThe source code, detailed documentation and a large number of tutorials can be\nfreely downloaded from www.abaqus2matlab.com.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.10188v1"
    },
    {
        "title": "TLib: A Flexible C++ Tensor Framework for Numerical Tensor Calculus",
        "authors": [
            "Cem Bassoy"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Numerical tensor calculus comprise basic tensor operations such as the\nentrywise addition and contraction of higher-order tensors. We present, TLib,\nflexible tensor framework with generic tensor functions and tensor classes that\nassists users to implement generic and flexible tensor algorithms in C++. The\nnumber of dimensions, the extents of the dimensions of the tensors and the\ncontraction modes of the tensor operations can be runtime variable. Our\nframework provides tensor classes that simplify the management of\nmultidimensional data and utilization of tensor operations using\nobject-oriented and generic programming techniques. Additional stream classes\nhelp the user to verify and compare of numerical results with MATLAB. Tensor\noperations are implemented with generic tensor functions and in terms of\nmultidimensional iterator types only, decoupling data storage representation\nand computation. The user can combine tensor functions with different tensor\ntypes and extend the framework without further modification of the classes or\nfunctions. We discuss the design and implementation of the framework and\ndemonstrate its usage with examples that have been discussed in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.10912v1"
    },
    {
        "title": "CameraTransform: a Scientific Python Package for Perspective Camera\n  Corrections",
        "authors": [
            "Richard Gerum",
            "Sebastian Richter",
            "Alexander Winterl",
            "Ben Fabry",
            "Daniel Zitterbart"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Scientific applications often require an exact reconstruction of object\npositions and distances from digital images. Therefore, the images need to be\ncorrected for perspective distortions. We present \\textit{CameraTransform}, a\npython package that performs a perspective image correction whereby the height,\ntilt/roll angle and heading of the camera can be automatically obtained from\nthe images if additional information such as GPS coordinates or object sizes\nare provided. We present examples of images of penguin colonies that are\nrecorded with stationary cameras and from a helicopter.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.07438v1"
    },
    {
        "title": "Review of theory and implementation of hyper-dual numbers for first and\n  second order automatic differentiation",
        "authors": [
            "Martin Neuenhofen"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this review we present hyper-dual numbers as a tool for the automatic\ndifferentiation of computer programs via operator overloading.\n  We start with a motivational introduction into the ideas of algorithmic\ndifferentiation. Then we illuminate the concepts behind operator overloading\nand dual numbers.\n  Afterwards, we present hyper-dual numbers (and vectors) as an extension of\ndual numbers for the computation of the Jacobian and the Hessian matrices of a\ncomputer program. We review a mathematical theorem that proves the correctness\nof the derivative information that is obtained from hyper-dual numbers.\n  Finally, we refer to a freely available implementation of a hyper-dual number\nclass in Matlab. We explain an interface that can be called with a function as\nargument such that the Jacobian and Hessian of this function are returned.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.03614v2"
    },
    {
        "title": "rlsm: R package for least squares Monte Carlo",
        "authors": [
            "Jeremy Yee"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This short paper briefly describes the implementation of the least squares\nMonte Carlo method in the rlsm package. This package provides users with an\neasy manner to experiment with the large amount of R regression tools on any\nregression basis and reward functions. This package also computes lower and\nupper bounds for the true value function via duality methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05554v1"
    },
    {
        "title": "rcss: Subgradient and duality approach for dynamic programming",
        "authors": [
            "Juri Hinz",
            "Jeremy Yee"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This short paper gives an introduction to the \\emph{rcss} package. The R\npackage \\emph{rcss} provides users with a tool to approximate the value\nfunctions in the Bellman recursion using convex piecewise linear functions\nformed using operations on tangents. A pathwise method is then used to gauge\nthe quality of the numerical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.06029v1"
    },
    {
        "title": "Slate: extending Firedrake's domain-specific abstraction to hybridized\n  solvers for geoscience and beyond",
        "authors": [
            "Thomas H. Gibson",
            "Lawrence Mitchell",
            "David A. Ham",
            "Colin J. Cotter"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Within the finite element community, discontinuous Galerkin (DG) and mixed\nfinite element methods have become increasingly popular in simulating\ngeophysical flows. However, robust and efficient solvers for the resulting\nsaddle-point and elliptic systems arising from these discretizations continue\nto be an on-going challenge. One possible approach for addressing this issue is\nto employ a method known as hybridization, where the discrete equations are\ntransformed such that classic static condensation and local post-processing\nmethods can be employed. However, it is challenging to implement hybridization\nas performant parallel code within complex models, whilst maintaining\nseparation of concerns between applications scientists and software experts. In\nthis paper, we introduce a domain-specific abstraction within the Firedrake\nfinite element library that permits the rapid execution of these hybridization\ntechniques within a code-generating framework. The resulting framework composes\nnaturally with Firedrake's solver environment, allowing for the implementation\nof hybridization and static condensation as runtime-configurable\npreconditioners via the Python interface to PETSc, petsc4py. We provide\nexamples derived from second order elliptic problems and geophysical fluid\ndynamics. In addition, we demonstrate that hybridization shows great promise\nfor improving the performance of solvers for mixed finite element\ndiscretizations of equations related to large-scale geophysical flows.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.00303v4"
    },
    {
        "title": "Automatic differentiation of ODE integration",
        "authors": [
            "Johannes Willkomm"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We discuss the calculation of the derivatives of ODE systems with the\nautomatic differentiation tool ADiMat. Using the well-known Lotka-Volterra\nequations and the ode23 ODE solver as examples we show the analytic derivatives\nand detail how to differentiate a top-level function that calls ode23 somewhere\nwith ADiMat. This involves the manual construction of substitution function to\npropagate the derivatives in forward and reverse mode. We also show how to use\nthe reverse mode code to evaluate the Hessian in forward-over-reverse mode.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.02247v1"
    },
    {
        "title": "High Performance Rearrangement and Multiplication Routines for Sparse\n  Tensor Arithmetic",
        "authors": [
            "Adam P. Harrison",
            "Dileepan Joseph"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Researchers are increasingly incorporating numeric high-order data, i.e.,\nnumeric tensors, within their practice. Just like the matrix/vector (MV)\nparadigm, the development of multi-purpose, but high-performance, sparse data\nstructures and algorithms for arithmetic calculations, e.g., those found in\nEinstein-like notation, is crucial for the continued adoption of tensors. We\nuse the example of high-order differential operators to illustrate this need.\nAs sparse tensor arithmetic is an emerging research topic, with challenges\ndistinct from the MV paradigm, many aspects require further articulation. We\nfocus on three core facets. First, aligning with prominent voices in the field,\nwe emphasise the importance of data structures able to accommodate the\noperational complexity of tensor arithmetic. However, we describe a linearised\ncoordinate (LCO) data structure that provides faster and more memory-efficient\nsorting performance. Second, flexible data structures, like the LCO, rely\nheavily on sorts and permutations. We introduce an innovative permutation\nalgorithm, based on radix sort, that is tailored to rearrange already-sorted\nsparse data, producing significant performance gains. Third, we introduce a\nnovel poly-algorithm for sparse tensor products, where hyper-sparsity is a\npossibility. Different manifestations of hyper-sparsity demand their own\napproach, which our poly-algorithm is the first to provide. These developments\nare incorporated within our LibNT and NTToolbox software libraries. Benchmarks,\nfrequently drawn from the high-order differential operators example,\ndemonstrate the practical impact of our routines, with speed-ups of 40% or\nhigher compared to alternative high-performance implementations. Comparisons\nagainst the MATLAB Tensor Toolbox show over 10 times speed improvements. Thus,\nthese advancements produce significant practical improvements for sparse tensor\narithmetic.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.02619v1"
    },
    {
        "title": "Adaptive control in rollforward recovery for extreme scale multigrid",
        "authors": [
            "Markus Huber",
            "Ulrich Rüde",
            "Barbara Wohlmuth"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  With the increasing number of compute components, failures in future\nexa-scale computer systems are expected to become more frequent. This motivates\nthe study of novel resilience techniques. Here, we extend a recently proposed\nalgorithm-based recovery method for multigrid iterations by introducing an\nadaptive control. After a fault, the healthy part of the system continues the\niterative solution process, while the solution in the faulty domain is\nre-constructed by an asynchronous on-line recovery. The computations in both\nthe faulty and healthy subdomains must be coordinated in a sensitive way, in\nparticular, both under and over-solving must be avoided. Both of these waste\ncomputational resources and will therefore increase the overall\ntime-to-solution. To control the local recovery and guarantee an optimal\nre-coupling, we introduce a stopping criterion based on a mathematical error\nestimator. It involves hierarchical weighted sums of residuals within the\ncontext of uniformly refined meshes and is well-suited in the context of\nparallel high-performance computing. The re-coupling process is steered by\nlocal contributions of the error estimator. We propose and compare two criteria\nwhich differ in their weights. Failure scenarios when solving up to\n$6.9\\cdot10^{11}$ unknowns on more than 245\\,766 parallel processes will be\nreported on a state-of-the-art peta-scale supercomputer demonstrating the\nrobustness of the method.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.06373v1"
    },
    {
        "title": "A User-Friendly Hybrid Sparse Matrix Class in C++",
        "authors": [
            "Conrad Sanderson",
            "Ryan Curtin"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  When implementing functionality which requires sparse matrices, there are\nnumerous storage formats to choose from, each with advantages and\ndisadvantages. To achieve good performance, several formats may need to be used\nin one program, requiring explicit selection and conversion between the\nformats. This can be both tedious and error-prone, especially for non-expert\nusers. Motivated by this issue, we present a user-friendly sparse matrix class\nfor the C++ language, with a high-level application programming interface\ndeliberately similar to the widely used MATLAB language. The class internally\nuses two main approaches to achieve efficient execution: (i) a hybrid storage\nframework, which automatically and seamlessly switches between three underlying\nstorage formats (compressed sparse column, coordinate list, Red-Black tree)\ndepending on which format is best suited for specific operations, and (ii)\ntemplate-based meta-programming to automatically detect and optimise execution\nof common expression patterns. To facilitate relatively quick conversion of\nresearch code into production environments, the class and its associated\nfunctions provide a suite of essential sparse linear algebra functionality\n(eg., arithmetic operations, submatrix manipulation) as well as high-level\nfunctions for sparse eigendecompositions and linear equation solvers. The\nlatter are achieved by providing easy-to-use abstractions of the low-level\nARPACK and SuperLU libraries. The source code is open and provided under the\npermissive Apache 2.0 license, allowing unencumbered use in commercial\nproducts.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03380v3"
    },
    {
        "title": "Optimizing Sparse Matrix-Vector Multiplication on Emerging Many-Core\n  Architectures",
        "authors": [
            "Shizhao Chen",
            "Jianbin Fang",
            "Donglin Chen",
            "Chuanfu Xu",
            "Zheng Wang"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Sparse matrix vector multiplication (SpMV) is one of the most common\noperations in scientific and high-performance applications, and is often\nresponsible for the application performance bottleneck. While the sparse matrix\nrepresentation has a significant impact on the resulting application\nperformance, choosing the right representation typically relies on expert\nknowledge and trial and error. This paper provides the first comprehensive\nstudy on the impact of sparse matrix representations on two emerging many-core\narchitectures: the Intel's Knights Landing (KNL) XeonPhi and the ARM-based\nFT-2000Plus (FTP). Our large-scale experiments involved over 9,500 distinct\nprofiling runs performed on 956 sparse datasets and five mainstream SpMV\nrepresentations. We show that the best sparse matrix representation depends on\nthe underlying architecture and the program input. To help developers to choose\nthe optimal matrix representation, we employ machine learning to develop a\npredictive model. Our model is first trained offline using a set of training\nexamples. The learned model can be used to predict the best matrix\nrepresentation for any unseen input for a given architecture. We show that our\nmodel delivers on average 95% and 91% of the best available performance on KNL\nand FTP respectively, and it achieves this with no runtime profiling overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.11938v1"
    },
    {
        "title": "Multiscale finite element calculations in Python using SfePy",
        "authors": [
            "Robert Cimrman",
            "Vladimír Lukeš",
            "Eduard Rohan"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  SfePy (Simple finite elements in Python) is a software for solving various\nkinds of problems described by partial differential equations in one, two or\nthree spatial dimensions by the finite element method. Its source code is\nmostly (85\\%) Python and relies on fast vectorized operations provided by the\nNumPy package. For a particular problem two interfaces can be used: a\ndeclarative application programming interface (API), where problem\ndescription/definition files (Python modules) are used to define a calculation,\nand an imperative API, that can be used for interactive commands, or in scripts\nand libraries. After outlining the SfePy package development, the paper\nintroduces its implementation, structure and general features. The components\nfor defining a partial differential equation are described using an example of\na simple heat conduction problem. Specifically, the declarative API of SfePy is\npresented in the example. To illustrate one of SfePy's main assets, the\nframework for implementing complex multiscale models based on the theory of\nhomogenization, an example of a two-scale piezoelastic model is presented,\nshowing both the mathematical description of the problem and the corresponding\ncode.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.00674v1"
    },
    {
        "title": "Studies on the energy and deep memory behaviour of a cache-oblivious,\n  task-based hyperbolic PDE solver",
        "authors": [
            "Dominic E. Charrier",
            "Benjamin Hazelwood",
            "Ekaterina Tutlyaeva",
            "Michael Bader",
            "Michael Dumbser",
            "Andrey Kudryavtsev",
            "Alexander Moskovsky",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We study the performance behaviour of a seismic simulation using the ExaHyPE\nengine with a specific focus on memory characteristics and energy needs.\nExaHyPE combines dynamically adaptive mesh refinement (AMR) with ADER-DG. It is\nparallelized using tasks, and it is cache efficient. AMR plus ADER-DG yields a\ntask graph which is highly dynamic in nature and comprises both arithmetically\nexpensive tasks and tasks which challenge the memory's latency. The expensive\ntasks and thus the whole code benefit from AVX vectorization, though we suffer\nfrom memory access bursts. A frequency reduction of the chip improves the\ncode's energy-to-solution. Yet, it does not mitigate burst effects. The bursts'\nlatency penalty becomes worse once we add Intel Optane technology, increase the\ncore count significantly, or make individual, computationally heavy tasks fall\nout of close caches. Thread overbooking to hide away these latency penalties\ncontra-productive with non-inclusive caches as it destroys the cache and\nvectorization character. In cases where memory-intense and computationally\nexpensive tasks overlap, ExaHyPE's cache-oblivious implementation can exploit\ndeep, non-inclusive, heterogeneous memory effectively, as main memory misses\narise infrequently and slow down only few cores. We thus propose that upcoming\nsupercomputing simulation codes with dynamic, inhomogeneous task graphs are\nactively supported by thread runtimes in intermixing tasks of different compute\ncharacter, and we propose that future hardware actively allows codes to\ndownclock the cores running particular task types.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.03940v4"
    },
    {
        "title": "Coloured and task-based stencil codes",
        "authors": [
            "Benjamin Hazelwood",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Simple stencil codes are and remain an important building block in scientific\ncomputing. On shared memory nodes, they are traditionally parallelised through\ncolouring or (recursive) tiling. New OpenMP versions alternatively allow users\nto specify data dependencies explicitly and to outsource the decision how to\ndistribute the work to the runtime system. We evaluate traditional\nmultithreading strategies on both Broadwell and KNL, study the arising\nassignment of tasks to threads and, from there, derive two efficient ways to\nparallelise stencil codes on regular Cartesian grids that fuse colouring and\ntask-based approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.04033v1"
    },
    {
        "title": "Dynamic Automatic Differentiation of GPU Broadcast Kernels",
        "authors": [
            "Jarrett Revels",
            "Tim Besard",
            "Valentin Churavy",
            "Bjorn De Sutter",
            "Juan Pablo Vielma"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We show how forward-mode automatic differentiation (AD) can be employed\nwithin larger reverse-mode computations to dynamically differentiate broadcast\noperations in a GPU-friendly manner. Our technique fully exploits the broadcast\nJacobian's inherent sparsity structure, and unlike a pure reverse-mode\napproach, this \"mixed-mode\" approach does not require a backwards pass over the\nbroadcasted operation's subgraph, obviating the need for several\nreverse-mode-specific programmability restrictions on user-authored broadcast\noperations. Most notably, this approach allows broadcast fusion in primal code\ndespite the presence of data-dependent control flow. We discuss an experiment\nin which a Julia implementation of our technique outperformed pure reverse-mode\nTensorFlow and Julia implementations for differentiating through broadcast\noperations within an HM-LSTM cell update calculation.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.08297v3"
    },
    {
        "title": "Nonequispaced Fast Fourier Transform (NFFT) Interface for Julia",
        "authors": [
            "Michael Schmischke"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This report describes the newly added Julia interface to the NFFT3 library.\nWe explain the multidimensional NFFT algorithm and basics of the interface.\nFurthermore, we go into detail about the different parameters and how to adjust\nthem properly.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.09891v1"
    },
    {
        "title": "Probabilistic Inference on Noisy Time Series (PINTS)",
        "authors": [
            "Michael Clerx",
            "Martin Robinson",
            "Ben Lambert",
            "Chon Lok Lei",
            "Sanmitra Ghosh",
            "Gary R. Mirams",
            "David J. Gavaghan"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Time series models are ubiquitous in science, arising in any situation where\nresearchers seek to understand how a system's behaviour changes over time. A\nkey problem in time series modelling is \\emph{inference}; determining\nproperties of the underlying system based on observed time series. For both\nstatistical and mechanistic models, inference involves finding parameter\nvalues, or distributions of parameters values, for which model outputs are\nconsistent with observations. A wide variety of inference techniques are\navailable and different approaches are suitable for different classes of\nproblems. This variety presents a challenge for researchers, who may not have\nthe resources or expertise to implement and experiment with these methods.\nPINTS (Probabilistic Inference on Noisy Time Series -\nhttps://github.com/pints-team/pints is an open-source (BSD 3-clause license)\nPython library that provides researchers with a broad suite of non-linear\noptimisation and sampling methods. It allows users to wrap a model and data in\na transparent and straightforward interface, which can then be used with custom\nor pre-defined error measures for optimisation, or with likelihood functions\nfor Bayesian inference or maximum-likelihood estimation. Derivative-free\noptimisation algorithms - which work without harder-to-obtain gradient\ninformation - are included, as well as inference algorithms such as adaptive\nMarkov chain Monte Carlo and nested sampling which estimate distributions over\nparameter values. By making these statistical techniques available in an open\nand easy-to-use framework, PINTS brings the power of modern statistical\ntechniques to a wider scientific audience.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.07388v1"
    },
    {
        "title": "Pocket Guide to Solve Inverse Problems with GlobalBioIm",
        "authors": [
            "Emmanuel Soubies",
            "Ferréol Soulez",
            "Michael T. McCann",
            "Thanh-an Pham",
            "Laurène Donati",
            "Thomas Debarre",
            "Daniel Sage",
            "Michael Unser"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  GlobalBioIm is an open-source MATLAB library for solving inverse problems.\nThe library capitalizes on the strong commonalities between forward models to\nstandardize the resolution of a wide range of imaging inverse problems. Endowed\nwith an operator-algebra mechanism, GlobalBioIm allows one to easily solve\ninverse problems by combining elementary modules in a lego-like fashion. This\nuser-friendly toolbox gives access to cutting-edge reconstruction algorithms,\nwhile its high modularity makes it easily extensible to new modalities and\nnovel reconstruction methods. We expect GlobalBioIm to respond to the needs of\nimaging scientists looking for reliable and easy-to-use computational tools for\nsolving their inverse problems. In this paper, we present in detail the\nstructure and main features of the library. We also illustrate its flexibility\nwith examples from multichannel deconvolution microscopy.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.07908v2"
    },
    {
        "title": "PBBFMM3D: a parallel black-box algorithm for kernel matrix-vector\n  multiplication",
        "authors": [
            "Ruoxi Wang",
            "Chao Chen",
            "Jonghyun Lee",
            "Eric Darve"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Kernel matrix-vector product is ubiquitous in many science and engineering\napplications. However, a naive method requires $O(N^2)$ operations, which\nbecomes prohibitive for large-scale problems. We introduce a parallel method\nthat provably requires $O(N)$ operations to reduce the computation cost. The\ndistinct feature of our method is that it requires only the ability to evaluate\nthe kernel function, offering a black-box interface to users. Our parallel\napproach targets multi-core shared-memory machines and is implemented using\nOpenMP. Numerical results demonstrate up to $19\\times$ speedup on 32 cores. We\nalso present a real-world application in geostatistics, where our parallel\nmethod was used to deliver fast principle component analysis of covariance\nmatrices.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.02153v3"
    },
    {
        "title": "Performance Analysis of Effective Symbolic Methods for Solving Band\n  Matrix SLAEs",
        "authors": [
            "Milena Veneva",
            "Alexander Ayriyan"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  This paper presents an experimental performance study of implementations of\nthree symbolic algorithms for solving band matrix systems of linear algebraic\nequations with heptadiagonal, pentadiagonal, and tridiagonal coefficient\nmatrices. The only assumption on the coefficient matrix in order for the\nalgorithms to be stable is nonsingularity. These algorithms are implemented\nusing the GiNaC library of C++ and the SymPy library of Python, considering\nfive different data storing classes. Performance analysis of the\nimplementations is done using the high-performance computing (HPC) platforms\n\"HybriLIT\" and \"Avitohol\". The experimental setup and the results from the\nconducted computations on the individual computer systems are presented and\ndiscussed. An analysis of the three algorithms is performed.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.02423v1"
    },
    {
        "title": "GNA: new framework for statistical data analysis",
        "authors": [
            "Anna Fatkina",
            "Maxim Gonchar",
            "Anastasia Kalitkina",
            "Liudmila Kolupaeva",
            "Dmitry Naumov",
            "Dmitry Selivanov",
            "Konstantin Treskov"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We report on the status of GNA --- a new framework for fitting large-scale\nphysical models. GNA utilizes the data flow concept within which a model is\nrepresented by a directed acyclic graph. Each node is an operation on an array\n(matrix multiplication, derivative or cross section calculation, etc). The\nframework enables the user to create flexible and efficient large-scale lazily\nevaluated models, handle large numbers of parameters, propagate parameters'\nuncertainties while taking into account possible correlations between them, fit\nmodels, and perform statistical analysis. The main goal of the paper is to give\nan overview of the main concepts and methods as well as reasons behind their\ndesign. Detailed technical information is to be published in further works.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.05567v1"
    },
    {
        "title": "On the Efficacy and High-Performance Implementation of Quaternion Matrix\n  Multiplication",
        "authors": [
            "David Williams-Young",
            "Xiaosong Li"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Quaternion symmetry is ubiquitous in the physical sciences. As such, much\nwork has been afforded over the years to the development of efficient schemes\nto exploit this symmetry using real and complex linear algebra. Recent years\nhave also seen many advances in the formal theoretical development of\nexplicitly quaternion linear algebra with promising applications in image\nprocessing and machine learning. Despite these advances, there do not currently\nexist optimized software implementations of quaternion linear algebra. The\nleverage of optimized linear algebra software is crucial in the achievement of\nhigh levels of performance on modern computing architectures, and thus provides\na central tool in the development of high-performance scientific software. In\nthis work, a case will be made for the efficacy of high-performance quaternion\nlinear algebra software for appropriate problems. In this pursuit, an optimized\nsoftware implementation of quaternion matrix multiplication will be presented\nand will be shown to outperform a vendor tuned implementation for the analogous\ncomplex matrix operation. The results of this work pave the path for further\ndevelopment of high-performance quaternion linear algebra software which will\nimprove the performance of the next generation of applicable scientific\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.05575v1"
    },
    {
        "title": "A study of vectorization for matrix-free finite element methods",
        "authors": [
            "Tianjiao Sun",
            "Lawrence Mitchell",
            "Kaushik Kulkarni",
            "Andreas Klöckner",
            "David A. Ham",
            "Paul H. J. Kelly"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Vectorization is increasingly important to achieve high performance on modern\nhardware with SIMD instructions. Assembly of matrices and vectors in the finite\nelement method, which is characterized by iterating a local assembly kernel\nover unstructured meshes, poses difficulties to effective vectorization.\nMaintaining a user-friendly high-level interface with a suitable degree of\nabstraction while generating efficient, vectorized code for the finite element\nmethod is a challenge for numerical software systems and libraries. In this\nwork, we study cross-element vectorization in the finite element framework\nFiredrake via code transformation and demonstrate the efficacy of such an\napproach by evaluating a wide range of matrix-free operators spanning different\npolynomial degrees and discretizations on two recent CPUs using three\nmainstream compilers. Our experiments show that our approaches for\ncross-element vectorization achieve 30\\% of theoretical peak performance for\nmany examples of practical significance, and exceed 50\\% for cases with high\narithmetic intensities, with consistent speed-up over (intra-element)\nvectorization restricted to the local assembly kernels.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.08243v2"
    },
    {
        "title": "PyMGRIT: A Python Package for the parallel-in-time method MGRIT",
        "authors": [
            "Jens Hahne",
            "Stephanie Friedhoff",
            "Matthias Bolten"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper, we introduce the Python framework PyMGRIT, which implements\nthe multigrid-reduction-in-time (MGRIT) algorithm for solving the (non-)linear\nsystems arising from the discretization of time-dependent problems. The MGRIT\nalgorithm is a reduction-based iterative method that allows parallel-in-time\nsimulations, i. e., calculating multiple time steps simultaneously in a\nsimulation, by using a time-grid hierarchy. The PyMGRIT framework features many\ndifferent variants of the MGRIT algorithm, ranging from different multigrid\ncycle types and relaxation schemes, as well as various coarsening strategies,\nincluding time-only and space-time coarsening, to using different time\nintegrators on different levels in the multigrid hierachy. PyMGRIT allows\nserial runs for prototyping and testing of new approaches, as well as parallel\nruns using the Message Passing Interface (MPI). Here, we describe the\nimplementation of the MGRIT algorithm in PyMGRIT and present the usage from\nboth user and developer point of views. Three examples illustrate different\naspects of the package, including pure time parallelism as well as space-time\nparallelism by coupling PyMGRIT with PETSc or Firedrake, which enable spatial\nparallelism through MPI.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.05172v1"
    },
    {
        "title": "Computing the coefficients for the power series solution of the\n  Lane-Emden equation with the Python library SymPy",
        "authors": [
            "Klaus Rohe"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  It is shown how the Python library Sympy can be used to compute symbolically\nthe coefficients of the power series solution of the Lane-Emden equation (LEE).\nSympy is an open source Python library for symbolic mathematics. The power\nseries solutions are compared to the numerically computed solutions using\nmatplotlib. The results of a run time measurement of the implemented algorithm\nare discussed at the end.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.2008v2"
    },
    {
        "title": "$μ$-diff: an open-source Matlab toolbox for computing multiple\n  scattering problems by disks",
        "authors": [
            "Bertrand Thierry",
            "Xavier Antoine",
            "Chokri Chniti",
            "Hasan Alzubaidi"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The aim of this paper is to describe a Matlab toolbox, called $\\mu$-diff, for\nmodeling and numerically solving two-dimensional complex multiple scattering by\na large collection of circular cylinders. The approximation methods in\n$\\mu$-diff are based on the Fourier series expansions of the four basic\nintegral operators arising in scattering theory. Based on these expressions, an\nefficient spectrally accurate finite-dimensional solution of multiple\nscattering problems can be simply obtained for complex media even when many\nscatterers are considered as well as large frequencies. The solution of the\nglobal linear system to solve can use either direct solvers or preconditioned\niterative Krylov subspace solvers for block Toeplitz matrices. Based on this\napproach, this paper explains how the code is built and organized. Some\ncomplete numerical examples of applications (direct and inverse scattering) are\nprovided to show that $\\mu$-diff is a flexible, efficient and robust toolbox\nfor solving some complex multiple scattering problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.8186v1"
    },
    {
        "title": "Optimised finite difference computation from symbolic equations",
        "authors": [
            "Michael Lange",
            "Navjot Kukreja",
            "Fabio Luporini",
            "Mathias Louboutin",
            "Charles Yount",
            "Jan Hückelheim",
            "Gerard J. Gorman"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Domain-specific high-productivity environments are playing an increasingly\nimportant role in scientific computing due to the levels of abstraction and\nautomation they provide. In this paper we introduce Devito, an open-source\ndomain-specific framework for solving partial differential equations from\nsymbolic problem definitions by the finite difference method. We highlight the\ngeneration and automated execution of highly optimized stencil code from only a\nfew lines of high-level symbolic Python for a set of scientific equations,\nbefore exploring the use of Devito operators in seismic inversion problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.03776v1"
    },
    {
        "title": "FEAST Eigenvalue Solver v4.0 User Guide",
        "authors": [
            "Eric Polizzi"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The FEAST library package represents an unified framework for solving various\nfamily of eigenvalue problems and achieving accuracy, robustness,\nhigh-performance and scalability on parallel architectures. Its originality\nlies with a new transformative numerical approach to the traditional eigenvalue\nalgorithm design - the FEAST algorithm. The algorithm gathers key elements from\ncomplex analysis, numerical linear algebra and approximation theory, to\nconstruct an optimal subspace iteration technique using approximate spectral\nprojectors. FEAST can be used for solving both standard and generalized forms\nof the Hermitian or non-Hermitian problems (linear or non-linear), and it\nbelongs to the family of contour integration eigensolvers. FEAST's main\ncomputational task consists of a numerical quadrature computation that involves\nsolving independent linear systems along a complex contour, each with multiple\nright hand sides. In v4.0, FEAST has been reimplemented using an inverse\nresidual iteration algorithm which enables the linear systems to be solved with\nvery low accuracy (in single precision) with no impact on the FEAST double\nprecision convergence rate. As a result, v4.0 is on average 3-4 times faster\nthan v2.1 and v3.0 using new default optimization parameters (v2.1 has been\nfeatured as Intel-MKL's principal HPC eigensolver since 2013). v4.0 also\nimplements new important features such as IFEAST (using Inexact Iterative\nsolver), Non-linear polynomial FEAST, and PFEAST with its 3-MPI levels of\nparallelism. FEAST is both a comprehensive library package, and an easy to use\nsoftware. It includes flexible reverse communication interfaces and ready to\nuse driver interfaces for dense, banded and sparse systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.04807v1"
    },
    {
        "title": "The Space of Mathematical Software Systems -- A Survey of Paradigmatic\n  Systems",
        "authors": [
            "Katja Bercic",
            "Jacques Carette",
            "William M. Farmer",
            "Michael Kohlhase",
            "Dennis Müller",
            "Florian Rabe",
            "Yasmine Sharoda"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Mathematical software systems are becoming more and more important in pure\nand applied mathematics in order to deal with the complexity and scalability\nissues inherent in mathematics. In the last decades we have seen a cambric\nexplosion of increasingly powerful but also diverging systems. To give\nresearchers a guide to this space of systems, we devise a novel\nconceptualization of mathematical software that focuses on five aspects:\ninference covers formal logic and reasoning about mathematical statements via\nproofs and models, typically with strong emphasis on correctness; computation\ncovers algorithms and software libraries for representing and manipulating\nmathematical objects, typically with strong emphasis on efficiency;\nconcretization covers generating and maintaining collections of mathematical\nobjects conforming to a certain pattern, typically with strong emphasis on\ncomplete enumeration; narration covers describing mathematical contexts and\nrelations, typically with strong emphasis on human readability; finally,\norganization covers representing mathematical contexts and objects in\nmachine-actionable formal languages, typically with strong emphasis on\nexpressivity and system interoperability. Despite broad agreement that an ideal\nsystem would seamlessly integrate all these aspects, research has diversified\ninto families of highly specialized systems focusing on a single aspect and\npossibly partially integrating others, each with their own communities,\nchallenges, and successes. In this survey, we focus on the commonalities and\ndifferences of these systems from the perspective of a future multi-aspect\nsystem.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.04955v1"
    },
    {
        "title": "SplineLib: A Modern Multi-Purpose C++ Spline Library",
        "authors": [
            "Markus Frings",
            "Norbert Hosters",
            "Corinna Müller",
            "Max Spahn",
            "Christoph Susen",
            "Konstantin Key",
            "Stefanie Elgeti"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper provides the description of a novel, multi-purpose spline library.\nIn accordance with the increasingly diverse modes of usage of splines, it is\nmulti-purpose in the sense that it supports geometry representation, finite\nelement analysis, and optimization. The library features reading and writing\nfor various file formats and a wide range of spline manipulation algorithms.\nFurther, a new efficient and objective-oriented algorithm for B-spline basis\nfunction evaluation is included. All features are available by a spline-type\nindependent interface. The library is written in modern C++ with CMake as build\nsystem. This enables it for usage in typical scientific applications. It is\nprovided as open-source library.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.12323v1"
    },
    {
        "title": "The Declaratron, semantic specification for scientific computation using\n  MathML",
        "authors": [
            "Dave Murray-Rust",
            "Peter Murray-Rust"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We introduce the Declaratron, a system which takes a declarative approach to\nspecifying mathematically based scientific computation. This uses displayable\nmathematical notation (Content MathML) and is both executable and semantically\nwell defined. We combine domain specific representations of physical science\n(e.g. CML, Chemical Markup Language), MathML formulae and computational\nspecifications (DeXML) to create executable documents which include scientific\ndata and mathematical formulae. These documents preserve the provenance of the\ndata used, and build tight semantic links between components of mathematical\nformulae and domain objects---in effect grounding the mathematical semantics in\nthe scientific domain. The Declaratron takes these specifications and i)\ncarries out entity resolution and decoration to prepare for computation ii)\nuses a MathML execution engine to run calculations over the revised tree iii)\noutputs domain objects and the complete document to give both results and an\nencapsulated history of the computation. A short description of a case study is\ngiven to illustrate how the system can be used. Many scientific problems\nrequire frequent change of the mathematical functional form and the Declaratron\nprovides this without requiring changes to code. Additionally, it supports\nreproducible science, machine indexing and semantic search of computations,\nmakes implicit assumptions visible, and separates domain knowledge from\ncomputational techniques. We believe that the Declaratron could replace much\nconventional procedural code in science.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.3088v1"
    },
    {
        "title": "Knowledge-Based Automatic Generation of Linear Algebra Algorithms and\n  Code",
        "authors": [
            "Diego Fabregat-Traver"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  This dissertation focuses on the design and the implementation of\ndomain-specific compilers for linear algebra matrix equations. The development\nof efficient libraries for such equations, which lie at the heart of most\nsoftware for scientific computing, is a complex process that requires expertise\nin a variety of areas, including the application domain, algorithms, numerical\nanalysis and high-performance computing. Moreover, the process involves the\ncollaboration of several people for a considerable amount of time. With our\ncompilers, we aim to relieve the developers from both designing algorithms and\nwriting code, and to generate routines that match or even surpass the\nperformance of those written by human experts.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3406v1"
    },
    {
        "title": "decimalInfinite: All Decimals In Bits, No Loss, Same Order, Simple",
        "authors": [
            "Ghislain Fourny"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  This paper introduces a binary encoding that supports arbitrarily large,\nsmall and precise decimals. It completely preserves information and order. It\ndoes not rely on any arbitrary use-case-based choice of calibration and is\nreadily implementable and usable, as is. Finally, it is also simple to explain\nand understand.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.01598v2"
    },
    {
        "title": "The Peano software - parallel, automaton-based, dynamically adaptive\n  grid traversals",
        "authors": [
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We discuss the design decisions, design alternatives and rationale behind the\nthird generation of Peano, a framework for dynamically adaptive Cartesian\nmeshes derived from spacetrees. Peano ties the mesh traversal to the mesh\nstorage and supports only one element-wise traversal order resulting from\nspace-filling curves. The user is not free to choose a traversal order herself.\nThe traversal can exploit regular grid subregions and shared memory as well as\ndistributed memory systems with almost no modifications to a serial application\ncode. We formalize the software design by means of two interacting\nautomata---one automaton for the multiscale grid traversal and one for the\napplication-specific algorithmic steps. This yields a callback-based\nprogramming paradigm. We further sketch the supported application types and the\ntwo data storage schemes realized, before we detail high-performance computing\naspects and lessons learned. Special emphasis is put on observations regarding\nthe used programming idioms and algorithmic concepts. This transforms our\nreport from a \"one way to implement things\" code description into a generic\ndiscussion and summary of some alternatives, rationale and design decisions to\nbe made for any tree-based adaptive mesh refinement software.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.04496v6"
    },
    {
        "title": "Efficient mesh management in Firedrake using PETSc-DMPlex",
        "authors": [
            "Michael Lange",
            "Lawrence Mitchell",
            "Matthew G. Knepley",
            "Gerard J. Gorman"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The use of composable abstractions allows the application of new and\nestablished algorithms to a wide range of problems while automatically\ninheriting the benefits of well-known performance optimisations. This work\nhighlights the composition of the PETSc DMPlex domain topology abstraction with\nthe Firedrake automated finite element system to create a PDE solving\nenvironment that combines expressiveness, flexibility and high performance. We\ndescribe how Firedrake utilises DMPlex to provide the indirection maps required\nfor finite element assembly, while supporting various mesh input formats and\nruntime domain decomposition. In particular, we describe how DMPlex and its\naccompanying data structures allow the generic creation of user-defined\ndiscretisations, while utilising data layout optimisations that improve cache\ncoherency and ensure overlapped communication during assembly computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.07749v1"
    },
    {
        "title": "Sparse Tensor Algebra as a Parallel Programming Model",
        "authors": [
            "Edgar Solomonik",
            "Torsten Hoefler"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Dense and sparse tensors allow the representation of most bulk data\nstructures in computational science applications. We show that sparse tensor\nalgebra can also be used to express many of the transformations on these\ndatasets, especially those which are parallelizable. Tensor computations are a\nnatural generalization of matrix and graph computations. We extend the usual\nbasic operations of tensor summation and contraction to arbitrary functions,\nand further operations such as reductions and mapping. The expression of these\ntransformations in a high-level sparse linear algebra domain specific language\nallows our framework to understand their properties at runtime to select the\npreferred communication-avoiding algorithm. To demonstrate the efficacy of our\napproach, we show how key graph algorithms as well as common numerical kernels\ncan be succinctly expressed using our interface and provide performance results\nof a general library implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.00066v1"
    },
    {
        "title": "The interface for functions in the dune-functions module",
        "authors": [
            "Christian Engwer",
            "Carsten Gräser",
            "Steffen Müthing",
            "Oliver Sander"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The dune-functions dune module introduces a new programmer interface for\ndiscrete and non-discrete functions. Unlike the previous interfaces considered\nin the existing dune modules, it is based on overloading operator(), and\nreturning values by-value. This makes user code much more readable, and allows\nthe incorporation of newer C++ features such as lambda expressions. Run-time\npolymorphism is implemented not by inheritance, but by type erasure,\ngeneralizing the ideas of the std::function class from the C++11 standard\nlibrary. We describe the new interface, show its possibilities, and measure the\nperformance impact of type erasure and return-by-value.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.06136v1"
    },
    {
        "title": "Dynamic Computation of Runge Kutta Fourth Order Algorithm for First and\n  Second Order Ordinary Differential Equation Using Java",
        "authors": [
            "A. O. Anidu",
            "S. A. Arekete",
            "A. O. Adedayo",
            "A. O. Adekoya"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Differential equations arise in mathematics, physics,medicine, pharmacology,\ncommunications, image processing and animation, etc. An Ordinary Differential\nEquation (ODE) is a differential equation if it involves derivatives with\nrespect to only one independent variable which can be studied from different\nperspectives, such as: analytical methods, graphical methods and numerical\nmethods. This research paper therefore revises the standard Runge - Kutta\nfourth order algorithm by using compiler techniques to dynamically evaluate the\ninputs and implement the algorithm for both first and second order derivatives\nof the ODE. We have been able to develop and implement the software that can be\nused to evaluate inputs and compute solutions (approximately and analytically)\nfor the ODE function at a more efficient rate than the traditional method.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.08790v1"
    },
    {
        "title": "Scalable linear solvers for sparse linear systems from large-scale\n  numerical simulations",
        "authors": [
            "Hui Liu",
            "Zhangxin Chen"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  This paper presents our work on designing scalable linear solvers for\nlarge-scale reservoir simulations. The main objective is to support\nimplementation of parallel reservoir simulators on distributed-memory parallel\nsystems, where MPI (Message Passing Interface) is employed for communications\namong computation nodes. Distributed matrix and vector modules are designed,\nwhich are the base of our parallel linear systems. Commonly-used Krylov\nsubspace linear solvers are implemented, including the restarted GMRES method,\nthe LGMRES method, and the BiCGSTAB method. It also has an interface to a\nparallel algebraic multigrid solver, BoomerAMG from HYPRE. Parallel\ngeneral-purpose preconditioners and special preconditioners for reservoir\nsimulations are also developed. The numerical experiments show that our linear\nsolvers have excellent scalability using thousands of CPU cores.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.05913v1"
    },
    {
        "title": "Simflowny 2: An upgraded platform for scientific modeling and simulation",
        "authors": [
            "A. Arbona",
            "B. Miñano",
            "A. Rigo",
            "C. Bona",
            "C. Palenzuela",
            "A. Artigues",
            "C. Bona-Casas",
            "J. Massó"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Simflowny is an open platform which automatically generates parallel code of\nscientific dynamical models for different simulation frameworks. Here we\npresent major upgrades on this software to support an extended set of families\nof models, in particular: i) a new generic family for partial differential\nequations, which can include spatial derivatives of any order, ii) a new family\nfor agent based models to study complex phenomena --either on a spatial domain\nor on a graph--. Additionally we introduce a flexible graphical user interface\n(GUI) to accommodate these and future families of equations. This paper\ndescribes the new GUI architecture and summarizes the formal representation and\nimplementation of these new families, providing several validation results.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.04715v1"
    },
    {
        "title": "xSDK Foundations: Toward an Extreme-scale Scientific Software\n  Development Kit",
        "authors": [
            "Roscoe Bartlett",
            "Irina Demeshko",
            "Todd Gamblin",
            "Glenn Hammond",
            "Michael Heroux",
            "Jeffrey Johnson",
            "Alicia Klinvex",
            "Xiaoye Li",
            "Lois Curfman McInnes",
            "J. David Moulton",
            "Daniel Osei-Kuffuor",
            "Jason Sarich",
            "Barry Smith",
            "Jim Willenbring",
            "Ulrike Meier Yang"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Extreme-scale computational science increasingly demands multiscale and\nmultiphysics formulations. Combining software developed by independent groups\nis imperative: no single team has resources for all predictive science and\ndecision support capabilities. Scientific libraries provide high-quality,\nreusable software components for constructing applications with improved\nrobustness and portability. However, without coordination, many libraries\ncannot be easily composed. Namespace collisions, inconsistent arguments, lack\nof third-party software versioning, and additional difficulties make\ncomposition costly.\n  The Extreme-scale Scientific Software Development Kit (xSDK) defines\ncommunity policies to improve code quality and compatibility across\nindependently developed packages (hypre, PETSc, SuperLU, Trilinos, and\nAlquimia) and provides a foundation for addressing broader issues in software\ninteroperability, performance portability, and sustainability. The xSDK\nprovides turnkey installation of member software and seamless combination of\naggregate capabilities, and it marks first steps toward extreme-scale\nscientific software ecosystems from which future applications can be composed\nrapidly with assured quality and scalability.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.08425v1"
    },
    {
        "title": "Tuning Technique for Multiple Precision Dense Matrix Multiplication\n  using Prediction of Computational Time",
        "authors": [
            "Tomonori Kouya"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Although reliable long precision floating-point arithmetic libraries such as\nQD and MPFR/GMP are necessary to solve ill-conditioned problems in numerical\nsimulation, long precision BLAS-level computation such as matrix multiplication\nhas not been fully optimized because tuning costs are very high compared to\nIEEE float and double precision arithmetic. In this study, we develop a\ntechnique to shorten this tuning time by using prediction of computational\ntimes in several block sizes for the blocking algorithm, and then selecting the\nfastest matrix multiplication method for tuning multiple precision dense real\nmatrix multiplication in various precisions, matrix sizes, and degrees of\nparallelization.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.01839v1"
    },
    {
        "title": "Deriving Correct High-Performance Algorithms",
        "authors": [
            "Devangi N. Parikh",
            "Maggie E. Myers",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Dijkstra observed that verifying correctness of a program is difficult and\nconjectured that derivation of a program hand-in-hand with its proof of\ncorrectness was the answer. We illustrate this goal-oriented approach by\napplying it to the domain of dense linear algebra libraries for distributed\nmemory parallel computers. We show that algorithms that underlie the\nimplementation of most functionality for this domain can be systematically\nderived to be correct. The benefit is that an entire family of algorithms for\nan operation is discovered so that the best algorithm for a given architecture\ncan be chosen. This approach is very practical: Ideas inspired by it have been\nused to rewrite the dense linear algebra software stack starting below the\nBasic Linear Algebra Subprograms (BLAS) and reaching up through the Elemental\ndistributed memory library, and every level in between. The paper demonstrates\nhow formal methods and rigorous mathematical techniques for correctness impact\nHPC.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.04286v1"
    },
    {
        "title": "On Parallel Solution of Sparse Triangular Linear Systems in CUDA",
        "authors": [
            "Ruipeng Li"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The acceleration of sparse matrix computations on modern many-core\nprocessors, such as the graphics processing units (GPUs), has been recognized\nand studied over a decade. Significant performance enhancements have been\nachieved for many sparse matrix computational kernels such as sparse\nmatrix-vector products and sparse matrix-matrix products. Solving linear\nsystems with sparse triangular structured matrices is another important sparse\nkernel as demanded by a variety of scientific and engineering applications such\nas sparse linear solvers. However, the development of efficient parallel\nalgorithms in CUDA for solving sparse triangular linear systems remains a\nchallenging task due to the inherently sequential nature of the computation. In\nthis paper, we will revisit this problem by reviewing the existing\nlevel-scheduling methods and proposing algorithms with self-scheduling\ntechniques. Numerical results have indicated that the CUDA implementations of\nthe proposed algorithms can outperform the state-of-the-art solvers in cuSPARSE\nby a factor of up to $2.6$ for structured model problems and general sparse\nmatrices.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.04985v1"
    },
    {
        "title": "Fast Linear Transformations in Python",
        "authors": [
            "Christoph Wilfried Wagner",
            "Sebastian Semper",
            "Jan Kirchhof"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Scientific computing requires handling large linear models, which are often\ncomposed of structured matrices. With increasing model size, dense\nrepresentations quickly become infeasible to compute or store. Matrix-free\nimplementations are suited to mitigate this problem but usually complicate\nresearch and development effort by months, when applied to practical research\nproblems.\n  Fastmat is a framework for handling large composed or structured matrices by\noffering an easy-to-use abstraction model. It allows expressing and using\nlinear operators in a mathematically intuitive way, while maintaining a strong\nfocus on efficient computation and memory storage. The implemented user\ninterface allows for very readable code implementation with very close\nrelationship to the actual mathematical notation of a given problem. Further it\nprovides means for quickly testing new implementations and also allows for\nrun-time execution path optimization.\n  Summarizing, fastmat provides a flexible and extensible framework for\nhandling matrix-free linear structured operators efficiently, while being\nintuitive and generating easy-to-reuse results.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.09578v2"
    },
    {
        "title": "Bembel: The Fast Isogeometric Boundary Element C++ Library for Laplace,\n  Helmholtz, and Electric Wave Equation",
        "authors": [
            "J. Dölz",
            "H. Harbrecht",
            "S. Kurz",
            "M. Multerer",
            "S. Schöps",
            "F. Wolf"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  In this article, we present Bembel, the C++ library featuring higher order\nisogeometric Galerkin boundary element methods for Laplace, Helmholtz, and\nMaxwell problems. Bembel is compatible with geometries from the Octave NURBS\npackage and provides an interface to the Eigen template library for linear\nalgebra operations. For computational efficiency, it applies an embedded fast\nmultipole method tailored to the isogeometric analysis framework and a parallel\nmatrix assembly based on OpenMP.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.00785v1"
    },
    {
        "title": "Bspline solids manipulation with Mathematica",
        "authors": [
            "R. Ipanaqué",
            "R. Velezmoro",
            "R. T. Urbina"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Bspline solids are used for solid objects modeling in R3. Mathematica\nincorporates a several commands to manipulate symbolic and graphically Bspline\nbasis functions and to graphically manipulate Bsplines curves and surfaces;\nhowever, it does not incorporate any command to the graphical manipulation of\nBspline solids. In this paper, we describe a new Mathematica program to compute\nand plotting the Bspline solids. The output obtained is consistent with\nMathematica's notation. The performance of the commands are discussed by using\nsome illustrative examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.07574v1"
    },
    {
        "title": "Program Generation for Linear Algebra Using Multiple Layers of DSLs",
        "authors": [
            "Daniele G. Spampinato",
            "Diego Fabregat-Traver",
            "Markus Püschel",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Numerical software in computational science and engineering often relies on\nhighly-optimized building blocks from libraries such as BLAS and LAPACK, and\nwhile such libraries provide portable performance for a wide range of computing\narchitectures, they still present limitations in terms of flexibility. We\nadvocate a domain-specific program generator capable of producing library\nroutines tailored to the specific needs of the application in terms of sizes,\ninterface, and target architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.08613v1"
    },
    {
        "title": "Remark on Algorithm 680: evaluation of the complex error function: Cause\n  and Remedy for the Loss of Accuracy Near the Real Axis",
        "authors": [
            "Mofreh Zaghloul"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  In this remark we identify the cause of the loss of accuracy in the\ncomputation of the Faddeyeva function, w(z), near the real axis when using\nAlgorithm 680. We provide a simple correction to this problem which allows us\nto restore this code as one of the important reference routines for accuracy\ncomparisons.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.12199v1"
    },
    {
        "title": "Compressed Basis GMRES on High Performance GPUs",
        "authors": [
            "José I. Aliaga",
            "Hartwig Anzt",
            "Thomas Grützmacher",
            "Enrique S. Quintana-Ortí",
            "Andrés E. Tomás"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Krylov methods provide a fast and highly parallel numerical tool for the\niterative solution of many large-scale sparse linear systems. To a large\nextent, the performance of practical realizations of these methods is\nconstrained by the communication bandwidth in all current computer\narchitectures, motivating the recent investigation of sophisticated techniques\nto avoid, reduce, and/or hide the message-passing costs (in distributed\nplatforms) and the memory accesses (in all architectures).\n  This paper introduces a new communication-reduction strategy for the (Krylov)\nGMRES solver that advocates for decoupling the storage format (i.e., the data\nrepresentation in memory) of the orthogonal basis from the arithmetic precision\nthat is employed during the operations with that basis. Given that the\nexecution time of the GMRES solver is largely determined by the memory access,\nthe datatype transforms can be mostly hidden, resulting in the acceleration of\nthe iterative step via a lower volume of bits being retrieved from memory.\nTogether with the special properties of the orthonormal basis (whose elements\nare all bounded by 1), this paves the road toward the aggressive customization\nof the storage format, which includes some floating point as well as fixed\npoint formats with little impact on the convergence of the iterative process.\n  We develop a high performance implementation of the \"compressed basis GMRES\"\nsolver in the Ginkgo sparse linear algebra library and using a large set of\ntest problems from the SuiteSparse matrix collection we demonstrate robustness\nand performance advantages on a modern NVIDIA V100 GPU of up to 50% over the\nstandard GMRES solver that stores all data in IEEE double precision.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.12101v1"
    },
    {
        "title": "A highly scalable approach to solving linear systems using two-stage\n  multisplitting",
        "authors": [
            "Nick Brown",
            "J. Mark Bull",
            "Iain Bethune"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Iterative methods for solving large sparse systems of linear equations are\nwidely used in many HPC applications. Extreme scaling of these methods can be\ndifficult, however, since global communication to form dot products is\ntypically required at every iteration.\n  To try to overcome this limitation we propose a hybrid approach, where the\nmatrix is partitioned into blocks. Within each block, we use a highly optimised\n(parallel) conventional solver, but we then couple the blocks together using\nblock Jacobi or some other multisplitting technique that can be implemented in\neither a synchronous or an asynchronous fashion. This allows us to limit the\nblock size to the point where the conventional iterative methods no longer\nscale, and to avoid global communication (and possibly synchronisation) across\nall processes.\n  Our block framework has been built to use PETSc, a popular scientific suite\nfor solving sparse linear systems, as the synchronous intra-block solver, and\nwe demonstrate results on up to 32768 cores of a Cray XE6 system. At this\nscale, the conventional solvers are still more efficient, though trends suggest\nthat the hybrid approach may be beneficial at higher core counts.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.12638v1"
    },
    {
        "title": "Generating Families of Practical Fast Matrix Multiplication Algorithms",
        "authors": [
            "Jianyu Huang",
            "Leslie Rice",
            "Devin A. Matthews",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Matrix multiplication (GEMM) is a core operation to numerous scientific\napplications. Traditional implementations of Strassen-like fast matrix\nmultiplication (FMM) algorithms often do not perform well except for very large\nmatrix sizes, due to the increased cost of memory movement, which is\nparticularly noticeable for non-square matrices. Such implementations also\nrequire considerable workspace and modifications to the standard BLAS\ninterface. We propose a code generator framework to automatically implement a\nlarge family of FMM algorithms suitable for multiplications of arbitrary matrix\nsizes and shapes. By representing FMM with a triple of matrices [U,V,W] that\ncapture the linear combinations of submatrices that are formed, we can use the\nKronecker product to define a multi-level representation of Strassen-like\nalgorithms. Incorporating the matrix additions that must be performed for\nStrassen-like algorithms into the inherent packing and micro-kernel operations\ninside GEMM avoids extra workspace and reduces the cost of memory movement.\nAdopting the same loop structures as high-performance GEMM implementations\nallows parallelization of all FMM algorithms with simple but efficient data\nparallelism without the overhead of task parallelism. We present a simple\nperformance model for general FMM algorithms and compare actual performance of\n20+ FMM algorithms to modeled predictions. Our implementations demonstrate a\nperformance benefit over conventional GEMM on single core and multi-core\nsystems. This study shows that Strassen-like fast matrix multiplication can be\nincorporated into libraries for practical use.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.01120v1"
    },
    {
        "title": "GFA: Exploratory Analysis of Multiple Data Sources with Group Factor\n  Analysis",
        "authors": [
            "Eemeli Leppäaho",
            "Muhammad Ammad-ud-din",
            "Samuel Kaski"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  The R package GFA provides a full pipeline for factor analysis of multiple\ndata sources that are represented as matrices with co-occurring samples. It\nallows learning dependencies between subsets of the data sources, decomposed\ninto latent factors. The package also implements sparse priors for the\nfactorization, providing interpretable biclusters of the multi-source data\n",
        "pdf_link": "http://arxiv.org/pdf/1611.01534v1"
    },
    {
        "title": "Automating the Last-Mile for High Performance Dense Linear Algebra",
        "authors": [
            "Richard Michael Veras",
            "Tze Meng Low",
            "Tyler Michael Smith",
            "Robert van de Geijn",
            "Franz Franchetti"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  High performance dense linear algebra (DLA) libraries often rely on a general\nmatrix multiply (Gemm) kernel that is implemented using assembly or with vector\nintrinsics. In particular, the real-valued Gemm kernels provide the\noverwhelming fraction of performance for the complex-valued Gemm kernels, along\nwith the entire level-3 BLAS and many of the real and complex LAPACK routines.\nThus,achieving high performance for the Gemm kernel translates into a high\nperformance linear algebra stack above this kernel. However, it is a monumental\ntask for a domain expert to manually implement the kernel for every\nlibrary-supported architecture. This leads to the belief that the craft of a\nGemm kernel is more dark art than science. It is this premise that drives the\npopularity of autotuning with code generation in the domain of DLA.\n  This paper, instead, focuses on an analytical approach to code generation of\nthe Gemm kernel for different architecture, in order to shed light on the\ndetails or voo-doo required for implementing a high performance Gemm kernel. We\ndistill the implementation of the kernel into an even smaller kernel, an\nouter-product, and analytically determine how available SIMD instructions can\nbe used to compute the outer-product efficiently. We codify this approach into\na system to automatically generate a high performance SIMD implementation of\nthe Gemm kernel. Experimental results demonstrate that our approach yields\ngenerated kernels with performance that is competitive with kernels implemented\nmanually or using empirical search.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.08035v2"
    },
    {
        "title": "Moore: Interval Arithmetic in Modern C++",
        "authors": [
            "Walter F. Mascarenhas"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present the library Moore, which implements Interval Arithmetic in modern\nC++. This library is based on a new feature in the C++ language called\nconcepts, which reduces the problems caused by template meta programming, and\nleads to a new approach for implementing interval arithmetic libraries in C++.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.09567v1"
    },
    {
        "title": "Elfun18 A collection of Matlab functions for the computation of\n  Elliptical Integrals and Jacobian elliptic functions of real arguments",
        "authors": [
            "Milan Batista"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In the article we outline the set of Matlab functions that enable the\ncomputation of elliptic Integrals and Jacobian elliptic functions for real\narguments. Correctness, robustness, efficiency and accuracy of the functions\nare discussed in some details. An example from the elasticity theory\nillustrates use of the collection.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.10469v2"
    },
    {
        "title": "The BLAS API of BLASFEO: optimizing performance for small matrices",
        "authors": [
            "Gianluca Frison",
            "Tommaso Sartor",
            "Andrea Zanelli",
            "Moritz Diehl"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  BLASFEO is a dense linear algebra library providing high-performance\nimplementations of BLAS- and LAPACK-like routines for use in embedded\noptimization and other applications targeting relatively small matrices.\nBLASFEO defines an API which uses a packed matrix format as its native format.\nThis format is analogous to the internal memory buffers of optimized BLAS, but\nit is exposed to the user and it removes the packing cost from the routine\ncall. For matrices fitting in cache, BLASFEO outperforms optimized BLAS\nimplementations, both open-source and proprietary. This paper investigates the\naddition of a standard BLAS API to the BLASFEO framework, and proposes an\nimplementation switching between two or more algorithms optimized for different\nmatrix sizes. Thanks to the modular assembly framework in BLASFEO, tailored\nlinear algebra kernels with mixed column- and panel-major arguments are easily\ndeveloped. This BLAS API has lower performance than the BLASFEO API, but it\nnonetheless outperforms optimized BLAS and especially LAPACK libraries for\nmatrices fitting in cache. Therefore, it can boost a wide range of\napplications, where standard BLAS and LAPACK libraries are employed and the\nmatrix size is moderate. In particular, this paper investigates the benefits in\nscientific programming languages such as Octave, SciPy and Julia.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.08115v4"
    },
    {
        "title": "Landau: language for dynamical systems with automatic differentiation",
        "authors": [
            "Ivan Dolgakov",
            "Dmitry Pavlov"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Most numerical solvers used to determine free variables of dynamical systems\nrely on first-order derivatives of the state of the system w.r.t. the free\nvariables. The number of the free variables can be fairly large. One of the\napproaches of obtaining those derivatives is the integration of the derivatives\nsimultaneously with the dynamical equations, which is best done with the\nautomatic differentiation technique. Even though there exist many automatic\ndifferentiation tools, none have been found to be scalable and usable for\npractical purposes of dynamic systems modeling. Landau is a Turing incomplete\nstatically typed domain-specific language aimed to fill this gap. The Turing\nincompleteness provides the ability of sophisticated source code analysis and,\nas a result, a highly optimized compiled code. Among other things, the language\nsyntax supports functions, compile-time ranged for loops, if/else branching\nconstructions, real variables and arrays, and the ability to manually discard\ncalculation where the automatic derivatives values are expected to be\nnegligibly small. In spite of reasonable restrictions, the language is rich\nenough to express and differentiate any cumbersome paper-equation with\npractically no effort.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.10206v1"
    },
    {
        "title": "Replicated Computational Results (RCR) Report for \"Code Generation for\n  Generally Mapped Finite Elements\"",
        "authors": [
            "Neil Lindquist"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  \"Code Generation for Generally Mapped Finite Elements\" includes performance\nresults for the finite element methods discussed in that manuscript. The\nauthors provided a Zenodo archive with the Firedrake components and\ndependencies used, as well as the scripts that generated the results. The\nsoftware was installed on two similar platforms; then, new results were\ngathered and compared to the original results. After completing this process,\nthe results have been deemed replicable by the reviewer.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.00488v1"
    },
    {
        "title": "CheasePy",
        "authors": [
            "Ehab Hassan"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  CheasePy is code written in Python to run the CHEASE (Cubic Hermite Element\nAxisymmetric Static Equilibrium) code, which solves the Grad-Shafranov equation\nfor toroidal MHD equilibria using pressure and current profiles and fixed\nplasma boundaries that is defined by a set of experimental data points (R,Z).\nThe CheasePy code allows an iterative running of the CHEASE code either to\ncheck the preservation of MHD equilibria or converging to an experimentally\ndefined total toroidal plasma current by modifying any input quantity.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01589v1"
    },
    {
        "title": "bertha: Project Skeleton for Scientific Software",
        "authors": [
            "Michael Riesch",
            "Tien Dat Nguyen",
            "Christian Jirauschek"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Science depends heavily on reliable and easy-to-use software packages, such\nas mathematical libraries or data analysis tools. Developing such packages\nrequires a lot of effort, which is too often avoided due to the lack of funding\nor recognition. In order to reduce the efforts required to create sustainable\nsoftware packages, we present a project skeleton that ensures the best software\nengineering practices from the start of a project, or serves as reference for\nexisting projects.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01640v2"
    },
    {
        "title": "High Accuracy Low Precision QR Factorization and Least Square Solver on\n  GPU with TensorCore",
        "authors": [
            "Shaoshuai Zhang",
            "Panruo Wu"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Driven by the insatiable needs to process ever larger amount of data with\nmore complex models, modern computer processors and accelerators are beginning\nto offer half precision floating point arithmetic support, and extremely\noptimized special units such as NVIDIA TensorCore on GPU and Google Tensor\nProcessing Unit (TPU) that does half precision matrix-matrix multiplication\nexceptionally efficiently. In this paper we present a large scale mixed\nprecision linear least square solver that achieves high accuracy using the low\nprecision TensorCore GPU. The mixed precision system consists of both\ninnovative algorithms and implementations, and is shown to be up to 14x faster\nthan single precision cuSOLVER at QR matrix factorization at large scale with\nslightly lower accuracy, and up to 10x faster than double precision direct QR\nleast square solver with comparable accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05508v1"
    },
    {
        "title": "Alsvinn: A Fast multi-GPGPU finite volume solver with a strong emphasis\n  on reproducibility",
        "authors": [
            "Kjetil Lye"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present the Alsvinn simulator, a fast multi general purpose graphical\nprocessing unit (GPGPU) finite volume solver for hyperbolic conservation laws\nin multiple space dimensions. Alsvinn has native support for uncertainty\nquantifications, and exhibits excellent scaling on top tier compute clusters.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.07645v1"
    },
    {
        "title": "PETSc TSAdjoint: a discrete adjoint ODE solver for first-order and\n  second-order sensitivity analysis",
        "authors": [
            "Hong Zhang",
            "Emil M. Constantinescu",
            "Barry F. Smith"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present a new software system PETSc TSAdjoint for first-order and\nsecond-order adjoint sensitivity analysis of time-dependent nonlinear\ndifferential equations. The derivative calculation in PETSc TSAdjoint is\nessentially a high-level algorithmic differentiation process. The adjoint\nmodels are derived by differentiating the timestepping algorithms and\nimplemented based on the parallel infrastructure in PETSc. Full differentiation\nof the library code including MPI routines thus is avoided, and users do not\nneed to derive their own adjoint models for their specific applications. PETSc\nTSAdjoint can compute the first-order derivative, that is, the gradient of a\nscalar functional, and the Hessian-vector product that carries second-order\nderivative information, while requiring minimal input (a few callbacks) from\nthe users. Optimal checkpointing schemes are employed by the adjoint model in a\nmanner that is transparent to users. Usability, efficiency, and scalability are\ndemonstrated through examples from a variety of applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.07696v2"
    },
    {
        "title": "Linnea: Automatic Generation of Efficient Linear Algebra Programs",
        "authors": [
            "Henrik Barthels",
            "Christos Psarras",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The translation of linear algebra computations into efficient sequences of\nlibrary calls is a non-trivial task that requires expertise in both linear\nalgebra and high-performance computing. Almost all high-level languages and\nlibraries for matrix computations (e.g., Matlab, Eigen) internally use\noptimized kernels such as those provided by BLAS and LAPACK; however, their\ntranslation algorithms are often too simplistic and thus lead to a suboptimal\nuse of said kernels, resulting in significant performance losses. In order to\ncombine the productivity offered by high-level languages, and the performance\nof low-level kernels, we are developing Linnea, a code generator for linear\nalgebra problems. As input, Linnea takes a high-level description of a linear\nalgebra problem; as output, it returns an efficient sequence of calls to\nhigh-performance kernels. Linnea uses a custom best-first search algorithm to\nfind a first solution in less than a second, and increasingly better solutions\nwhen given more time. In 125 test problems, the code generated by Linnea almost\nalways outperforms Matlab, Julia, Eigen and Armadillo, with speedups up to and\nexceeding 10x.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.12924v1"
    },
    {
        "title": "LEoPart: a particle library for FEniCS",
        "authors": [
            "Jakob M. Maljaars",
            "Chris N. Richardson",
            "Nathan Sime"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  This paper introduces LEoPart, an add-on for the open source finite element\nsoftware library FEniCS to seamlessly integrate Lagrangian particle\nfunctionality with (Eulerian) mesh-based finite element (FE) approaches.\nLEoPart - which is so much as to say: `Lagrangian-Eulerian on Particles' -\ncontains tools for efficient, accurate and scalable advection of Lagrangian\nparticles on arbitrary polyhedral meshes. In addition, LEoPart comes with\nseveral projection operators for exchanging information between the scattered\nparticles and the mesh and \\textit{vice versa}. These projection operators are\nbased on a variational framework, which allows extension to high-order\naccuracy. In particular, by implementing a dedicated PDE-constrained\nparticle-mesh projection operator, LEoPart provides all the tools for\ndiffusion-free advection, while simultaneously achieving optimal convergence\nand ensuring conservation of the projected particle quantities on the\nunderlying mesh. A range of numerical examples that are prototypical to passive\nand active tracer methods highlight the properties and the parallel performance\nof the different tools in LEoPart. Finally, future developments are identified.\nThe source code for LEoPart is actively maintained and available under an open\nsource license at https://bitbucket.org/jakob_maljaars/leopart.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.13375v2"
    },
    {
        "title": "Issues with rounding in the GCC implementation of the ISO 18037:2008\n  standard fixed-point arithmetic",
        "authors": [
            "Mantas Mikaitis"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We describe various issues caused by the lack of round-to-nearest mode in the\n\\textit{gcc} compiler implementation of the fixed-point arithmetic data types\nand operations. We demonstrate that round-to-nearest is not performed in the\nconversion of constants, conversion from one numerical type to a less precise\ntype and results of multiplications. Furthermore, we show that mixed-precision\noperations in fixed-point arithmetic lose precision on arguments, even before\ncarrying out arithmetic operations. The ISO 18037:2008 standard was created to\nstandardize C language extensions, including fixed-point arithmetic, for\nembedded systems. Embedded systems are usually based on ARM processors, of\nwhich approximately 100 billion have been manufactured by now. Therefore, the\nobservations about numerical issues that we discuss in this paper can be rather\ndangerous and are important to address, given the wide ranging type of\napplications that these embedded systems are running.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.01496v3"
    },
    {
        "title": "Comparing Python, Go, and C++ on the N-Queens Problem",
        "authors": [
            "Pascal Fua",
            "Krzysztof Lis"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Python currently is the dominant language in the field of Machine Learning\nbut is often criticized for being slow to perform certain tasks. In this\nreport, we use the well-known $N$-queens puzzle as a benchmark to show that\nonce compiled using the Numba compiler it becomes competitive with C++ and Go\nin terms of execution speed while still allowing for very fast prototyping.\nThis is true of both sequential and parallel programs. In most cases that arise\nin an academic environment, it therefore makes sense to develop in ordinary\nPython, identify computational bottlenecks, and use Numba to remove them.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.02491v1"
    },
    {
        "title": "Fast Cubic Spline Interpolation",
        "authors": [
            "Haysn Hornbeck"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The Numerical Recipes series of books are a useful resource, but all the\nalgorithms they contain cannot be used within open-source projects. In this\npaper we develop drop-in alternatives to the two algorithms they present for\ncubic spline interpolation, showing as much of our work as possible to allow\nfor replication or criticsm. The output of the new algorithms is compared to\nthe old, and found to be no different within the limits imposed by\nfloating-point precision. Benchmarks of all these algorithms, plus variations\nwhich may run faster in certain instances, are performed. In general, all these\nalgorithms have approximately the same execution time when interpolating curves\nwith few control points on feature-rich Intel processors; as the number of\ncontrol points increases or processor features are removed, the new algorithms\nbecome consistently faster than the old. Exceptions to that generalization are\nexplored to create implementation guidelines, such as when to expect division\nto be faster than multiplication.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.09253v1"
    },
    {
        "title": "Custom-Precision Mathematical Library Explorations for Code Profiling\n  and Optimization",
        "authors": [
            "David Defour",
            "Pablo de Oliveira Castro",
            "Matei Istoan",
            "Eric Petit"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The typical processors used for scientific computing have fixed-width\ndata-paths. This implies that mathematical libraries were specifically\ndeveloped to target each of these fixed precisions (binary16, binary32,\nbinary64). However, to address the increasing energy consumption and throughput\nrequirements of scientific applications, library and hardware designers are\nmoving beyond this one-size-fits-all approach. In this article we propose to\nstudy the effects and benefits of using user-defined floating-point formats and\ntarget accuracies in calculations involving mathematical functions. Our tool\ncollects input-data profiles and iteratively explores lower precisions for each\ncall-site of a mathematical function in user applications. This profiling data\nwill be a valuable asset for specializing and fine-tuning mathematical function\nimplementations for a given application. We demonstrate the tool's capabilities\non SGP4, a satellite tracking application. The profile data shows the potential\nfor specialization and provides insight into answering where it is useful to\nprovide variable-precision designs for elementary function evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02732v1"
    },
    {
        "title": "Delayed approximate matrix assembly in multigrid with dynamic precisions",
        "authors": [
            "Charles D. Murray",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The accurate assembly of the system matrix is an important step in any code\nthat solves partial differential equations on a mesh. We either explicitly set\nup a matrix, or we work in a matrix-free environment where we have to be able\nto quickly return matrix entries upon demand. Either way, the construction can\nbecome costly due to non-trivial material parameters entering the equations,\nmultigrid codes requiring cascades of matrices that depend upon each other, or\ndynamic adaptive mesh refinement that necessitates the recomputation of matrix\nentries or the whole equation system throughout the solve. We propose that\nthese constructions can be performed concurrently with the multigrid cycles.\nInitial geometric matrices and low accuracy integrations kickstart the\nmultigrid, while improved assembly data is fed to the solver as and when it\nbecomes available. The time to solution is improved as we eliminate an\nexpensive preparation phase traditionally delaying the actual computation. We\neliminate algorithmic latency. Furthermore, we desynchronise the assembly from\nthe solution process. This anarchic increase of the concurrency level improves\nthe scalability. Assembly routines are notoriously memory- and\nbandwidth-demanding. As we work with iteratively improving operator accuracies,\nwe finally propose the use of a hierarchical, lossy compression scheme such\nthat the memory footprint is brought down aggressively where the system matrix\nentries carry little information or are not yet available with high accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.03606v1"
    },
    {
        "title": "Memory efficient scheduling of Strassen-Winograd's matrix multiplication\n  algorithm",
        "authors": [
            "Brice Boyer",
            "Jean-Guillaume Dumas",
            "Clément Pernet",
            "Wei Zhou"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  We propose several new schedules for Strassen-Winograd's matrix\nmultiplication algorithm, they reduce the extra memory allocation requirements\nby three different means: by introducing a few pre-additions, by overwriting\nthe input matrices, or by using a first recursive level of classical\nmultiplication. In particular, we show two fully in-place schedules: one having\nthe same number of operations, if the input matrices can be overwritten; the\nother one, slightly increasing the constant of the leading term of the\ncomplexity, if the input matrices are read-only. Many of these schedules have\nbeen found by an implementation of an exhaustive search algorithm based on a\npebble game.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.2347v5"
    },
    {
        "title": "Comments on the Reliability of Lawson and Hanson's Linear Distance\n  Programming Algorithm: Subroutine LDP",
        "authors": [
            "Alan Rufty"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  This brief paper: (1) Discusses strategies to generate random test cases that\ncan be used to extensively test any Linear Distance Program (LDP) software. (2)\nGives three numerical examples of input cases generated by this strategy that\ncause problems in the Lawson and Hanson LDP module. (3) Proposes, as a standard\nmatter of acceptable implementation procedures, that (unless it is done\ninternally in the software itself, but, in general, this seems to be much rarer\nthan one would expect) all users should test the returned output from any LDP\nmodule for self-consistency since it incurs only a small amount of added\ncomputational overhead and it is not hard to do.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.4651v1"
    },
    {
        "title": "A New Vectorization Technique for Expression Templates in C++",
        "authors": [
            "J. Progsch",
            "Y. Ineichen",
            "A. Adelmann"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  Vector operations play an important role in high performance computing and\nare typically provided by highly optimized libraries that implement the BLAS\n(Basic Linear Algebra Subprograms) interface. In C++ templates and operator\noverloading allow the implementation of these vector operations as expression\ntemplates which construct custom loops at compile time and providing a more\nabstract interface. Unfortunately existing expression template libraries lack\nthe performance of fast BLAS(Basic Linear Algebra Subprograms) implementations.\nThis paper presents a new approach - Statically Accelerated Loop Templates\n(SALT) - to close this performance gap by combining expression templates with\nan aggressive loop unrolling technique. Benchmarks were conducted using the\nIntel C++ compiler and GNU Compiler Collection to assess the performance of our\nlibrary relative to Intel's Math Kernel Library as well as the Eigen template\nlibrary. The results show that the approach is able to provide optimization\ncomparable to the fastest available BLAS implementations, while retaining the\nconvenience and flexibility of a template library.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.1264v1"
    },
    {
        "title": "A C++11 implementation of arbitrary-rank tensors for high-performance\n  computing",
        "authors": [
            "Alejandro M. Aragón"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  This article discusses an efficient implementation of tensors of arbitrary\nrank by using some of the idioms introduced by the recently published C++ ISO\nStandard (C++11). With the aims at providing a basic building block for\nhigh-performance computing, a single Array class template is carefully crafted,\nfrom which vectors, matrices, and even higher-order tensors can be created. An\nexpression template facility is also built around the array class template to\nprovide convenient mathematical syntax. As a result, by using templates, an\nextra high-level layer is added to the C++ language when dealing with algebraic\nobjects and their operations, without compromising performance. The\nimplementation is tested running on both CPU and GPU.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.1003v5"
    },
    {
        "title": "BOAT: a cross-platform software for data analysis and numerical\n  computing with arbitrary-precision",
        "authors": [
            "Davide Pagano"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  BOAT is a free cross-platform software for statistical data analysis and\nnumerical computing. Thanks to its multiple-precision floating point engine, it\nallows arbitrary-precision calculations, whose digits of precision are only\nlimited by the amount of memory of the host machine. At the core of the\nsoftware is a simple and efficient expression language, whose use is\nfacilitated by the assisted typing, the auto-complete engine and the built-in\nhelp for the syntax. In this paper a quick overview of the software is given.\nDetailed information, together with its applications to some case studies, is\navailable at the BOAT web page.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.03167v1"
    },
    {
        "title": "Computing with Harmonic Functions",
        "authors": [
            "Sheldon Axler"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  This document is the manual for a free Mathematica package for computing with\nharmonic functions. This package allows the user to make calculations that\nwould take a prohibitive amount of time if done without a computer. For\nexample, the Poisson integral of any polynomial can be computed exactly. This\nsoftware can find exact solutions to Dirichlet, Neumann, and biDirichlet\nproblems in R^n with polynomial data on balls, ellipsoids, and annular regions.\nIt can also find bases for spaces of spherical harmonics, compute projections\nonto the harmonic Bergman space, and perform other manipulations with harmonic\nfunctions.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.05986v2"
    },
    {
        "title": "DiffSharp: Automatic Differentiation Library",
        "authors": [
            "Atilim Gunes Baydin",
            "Barak A. Pearlmutter",
            "Jeffrey Mark Siskind"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  In this paper we introduce DiffSharp, an automatic differentiation (AD)\nlibrary designed with machine learning in mind. AD is a family of techniques\nthat evaluate derivatives at machine precision with only a small constant\nfactor of overhead, by systematically applying the chain rule of calculus at\nthe elementary operator level. DiffSharp aims to make an extensive array of AD\ntechniques available, in convenient form, to the machine learning community.\nThese including arbitrary nesting of forward/reverse AD operations, AD with\nlinear algebra primitives, and a functional API that emphasizes the use of\nhigher-order functions and composition. The library exposes this functionality\nthrough an API that provides gradients, Hessians, Jacobians, directional\nderivatives, and matrix-free Hessian- and Jacobian-vector products. Bearing the\nperformance requirements of the latest machine learning techniques in mind, the\nunderlying computations are run through a high-performance BLAS/LAPACK backend,\nusing OpenBLAS by default. GPU support is currently being implemented.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.07727v2"
    },
    {
        "title": "Algorithmic Differentiation for Domain Specific Languages",
        "authors": [
            "Max Sagebaum",
            "Nicolas R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Algorithmic Differentiation (AD) can be used to automate the generation of\nderivatives in arbitrary software projects. This will generate maintainable\nderivatives, that are always consistent with the computation of the software.\nIf a domain specific language (DSL) is used in a software the state of the art\napproach is to differentiate the DSL library with the same AD tool. The\ndrawback of this solution is the reduced performance since the compiler is no\nlonger able to optimize the e.g. SIMD operations. The new approach in this\npaper integrates the types and operations of the DSL into the AD tool. It will\nbe an operator overloading tool that is generated from an abstract definition\nof a DSL. This approach enables the compiler to optimize again e.g. for SIMD\noperation since all calculations are still performed with the original data\ntypes. This will also reduce the required memory for AD since the statements\ninside the DLS implementation are no longer seen by the AD tool. The\nimplementation is presented in the paper and first results for the performance\nof the solution are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.04154v1"
    },
    {
        "title": "Architecture and performance of Devito, a system for automated stencil\n  computation",
        "authors": [
            "Fabio Luporini",
            "Michael Lange",
            "Mathias Louboutin",
            "Navjot Kukreja",
            "Jan Hückelheim",
            "Charles Yount",
            "Philipp Witte",
            "Paul H. J. Kelly",
            "Felix J. Herrmann",
            "Gerard J. Gorman"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Stencil computations are a key part of many high-performance computing\napplications, such as image processing, convolutional neural networks, and\nfinite-difference solvers for partial differential equations. Devito is a\nframework capable of generating highly-optimized code given symbolic equations\nexpressed in Python, specialized in, but not limited to, affine (stencil)\ncodes. The lowering process---from mathematical equations down to C++ code---is\nperformed by the Devito compiler through a series of intermediate\nrepresentations. Several performance optimizations are introduced, including\nadvanced common sub-expressions elimination, tiling and parallelization. Some\nof these are obtained through well-established stencil optimizers, integrated\nin the back-end of the Devito compiler. The architecture of the Devito\ncompiler, as well as the performance optimizations that are applied when\ngenerating code, are presented. The effectiveness of such performance\noptimizations is demonstrated using operators drawn from seismic imaging\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.03032v3"
    },
    {
        "title": "The Dune Python Module",
        "authors": [
            "Andreas Dedner",
            "Martin Nolte"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this paper we present the new Dune-Python module which provides Python\nbindings for the Dune core, which is a C++ environment for solving partial\ndifferential equations. The aim of this new module is to firstly provide the\ngeneral infrastructure for exporting realizations of statically polymorphic\ninterfaces based on just-in-time compilation and secondly to provide bindings\nfor the central interfaces of the dune core modules. In the first release we\nfocus on the grid interface. Our aim is to only introduce a thin layer when\npassing objects into Python which can be removed when the object is passed back\ninto a C++ algorithm. Thus no efficiency is lost and little additional code\nmaintenance cost is incurred. To make the transition for Dune users to the\nPython environment straightforward the Python classes provide a very similar\ninterface to their C++ counterparts. In addition, vectorized versions of many\ninterfaces allow for more efficient code on the Python side. The infrastructure\nfor exporting these interfaces and the resulting bindings for a Dune grid are\nexplained in detail in this paper for both experienced Dune users and others\ninterested in a flexible Python environment for implementing grid based schemes\nfor solving partial differential equations.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.05252v1"
    },
    {
        "title": "Physical-type correctness in scientific Python",
        "authors": [
            "Marcus Foster",
            "Sean Tregeagle"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The representation of units and dimensions in informatics systems is barely\ncodified and often ignored. For instance, the major languages used in\nscientific computing (Fortran, C and Python), have no type for dimension or\nunit, and so physical quantities are represented in a program by variables of\ntype real, resulting in the possibility of unit or dimensional errors. In view\nof this danger, many authors have proposed language schemes for unit-checking\nand conversion. However, since many physical quantities have the same units, it\nis possible for a block of code to be unit-compatible, but still physically\nmeaningless. We demonstrate the limitations of three Python unit-libraries and\npresent a justification and method for checking kind-of-quantity.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.07643v3"
    },
    {
        "title": "The MOMMS Family of Matrix Multiplication Algorithms",
        "authors": [
            "Tyler M. Smith",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  As the ratio between the rate of computation and rate with which data can be\nretrieved from various layers of memory continues to deteriorate, a question\narises: Will the current best algorithms for computing matrix-matrix\nmultiplication on future CPUs continue to be (near) optimal? This paper\nprovides compelling analytical and empirical evidence that the answer is \"no\".\nThe analytical results guide us to a new family of algorithms of which the\ncurrent state-of-the-art \"Goto's algorithm\" is but one member. The empirical\nresults, on architectures that were custom built to reduce the amount of\nbandwidth to main memory, show that under different circumstances, different\nand particular members of the family become more superior. Thus, this family\nwill likely start playing a prominent role going forward.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.05717v1"
    },
    {
        "title": "A tutorial-driven introduction to the parallel finite element library\n  FEMPAR v1.0.0",
        "authors": [
            "Santiago Badia",
            "Alberto F. Martín"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  This work is a user guide to the FEMPAR scientific software library. FEMPAR\nis an open-source object-oriented framework for the simulation of partial\ndifferential equations (PDEs) using finite element methods on\ndistributed-memory platforms. It provides a rich set of tools for numerical\ndiscretization and built-in scalable solvers for the resulting linear systems\nof equations. An application expert that wants to simulate a PDE-governed\nproblem has to extend the framework with a description of the weak form of the\nPDE at hand (and additional perturbation terms for non-conforming\napproximations). We show how to use the library by going through three\ndifferent tutorials. The first tutorial simulates a linear PDE (Poisson\nequation) in a serial environment for a structured mesh using both continuous\nand discontinuous Galerkin finite element methods. The second tutorial extends\nit with adaptive mesh refinement on octree meshes. The third tutorial is a\ndistributed-memory version of the previous one that combines a scalable octree\nhandler and a scalable domain decomposition solver. The exposition is\nrestricted to linear PDEs and simple geometries to keep it concise. The\ninterested user can dive into more tutorials available in the FEMPAR public\nrepository to learn about further capabilities of the library, e.g., nonlinear\nPDEs and nonlinear solvers, time integration, multi-field PDEs, block\npreconditioning, or unstructured mesh handling.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.00891v1"
    },
    {
        "title": "SODECL: An Open Source Library for Calculating Multiple Orbits of a\n  System of Stochastic Differential Equations in Parallel",
        "authors": [
            "Eleftherios Avramidis",
            "Marta Lalik",
            "Ozgur E. Akman"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Stochastic differential equations (SDEs) are widely used to model systems\naffected by random processes. In general, the analysis of an SDE model requires\nnumerical solutions to be generated many times over multiple parameter\ncombinations. However, this process often requires considerable computational\nresources to be practicable. Due to the embarrassingly parallel nature of the\ntask, devices such as multi-core processors and graphics processing units\n(GPUs) can be employed for acceleration.\n  Here, we present {\\bf SODECL} (\\url{https://github.com/avramidis/sodecl}), a\nsoftware library that utilises such devices to calculate multiple orbits of an\nSDE model. To evaluate the acceleration provided by SODECL, we compared the\ntime required to calculate multiple orbits of an exemplar stochastic model when\none CPU core is used, to the time required when using all CPU cores or a GPU.\nIn addition, to assess scalability, we investigated how the model size affected\nexecution time on different parallel compute devices.\n  Our results show that when using all 32 CPU cores of a high-end\nhigh-performance computing node, the task is accelerated by a factor of up to\n$\\simeq$6.7, compared to when using a single CPU core. Executing the task on a\nhigh-end GPU yielded accelerations of up to $\\simeq$4.5, compared to a single\nCPU core.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.03869v2"
    },
    {
        "title": "A Low-Memory Time-Efficient Implementation of Outermorphisms for\n  Higher-Dimensional Geometric Algebras",
        "authors": [
            "Ahmad Hosny Eid"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  From the beginning of David Hestenes rediscovery of geometric algebra in the\n1960s, outermorphisms have been a cornerstone in the mathematical development\nof GA. Many important mathematical formulations in GA can be expressed as\noutermorphisms such as versor products, linear projection operators, and\nmapping between related coordinate frames. Over the last two decades, GA-based\nmathematical models and software implementations have been developed in many\nfields of science and engineering. As such, efficient implementations of\noutermorphisms are of significant importance within this context. This work\nattempts to shed some light on the problem of optimizing software\nimplementations of outermorphisms for practical prototyping applications using\ngeometric algebra. The approach we propose here for implementing outermorphisms\nrequires orders of magnitude less memory compared to other common approaches,\nwhile being comparable in time performance, especially for high-dimensional\ngeometric algebras.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.02408v1"
    },
    {
        "title": "Computing Derivatives for PETSc Adjoint Solvers using Algorithmic\n  Differentiation",
        "authors": [
            "J. G. Wallwork",
            "P. Hovland",
            "H. Zhang",
            "O. Marin"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Most nonlinear partial differential equation (PDE) solvers require the\nJacobian matrix associated to the differential operator. In PETSc, this is\ntypically achieved by either an analytic derivation or numerical approximation\nmethod such as finite differences. For complex applications, hand-coding the\nJacobian can be time-consuming and error-prone, yet computationally efficient.\nWhilst finite difference approximations are straight-forward to implement, they\nhave high arithmetic complexity and low accuracy. Alternatively, one may\ncompute Jacobians using algorithmic differentiation (AD), yielding the same\nderivatives as an analytic derivation, with the added benefit that the\nimplementation is problem independent. In this work, the operator overloading\nAD tool ADOL-C is applied to generate Jacobians for time-dependent, nonlinear\nPDEs and their adjoints. Various strategies are considered, including\ncompressed and matrix-free approaches. In numerical experiments with a 2D\ndiffusion-reaction model, the performance of these strategies has been studied\nand compared to the hand-derived version.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.02836v1"
    },
    {
        "title": "The surrogate matrix methodology: A reference implementation for\n  low-cost assembly in isogeometric analysis",
        "authors": [
            "Daniel Drzisga",
            "Brendan Keith",
            "Barbara Wohlmuth"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  A reference implementation of a new method in isogeometric analysis (IGA) is\npresented. It delivers low-cost variable-scale approximations (surrogates) of\nthe matrices which IGA conventionally requires to be computed by element-scale\nquadrature. To generate surrogate matrices, quadrature must only be performed\non a fraction of the elements in the computational domain. In this way,\nquadrature determines only a subset of the entries in the final matrix. The\nremaining matrix entries are computed by a simple B-spline interpolation\nprocedure. We present the modifications and extensions required for a reference\nimplementation in the open-source IGA software library GeoPDEs. The exposition\nis fashioned to help facilitate similar modifications in other contemporary\nsoftware libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.04029v1"
    },
    {
        "title": "The RaPID-OMEGA system: Room and Proctor Intelligent Decider for large\n  scale tests programming",
        "authors": [
            "Fernando A. Morales"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present the mathematical modeling for the problem of choosing rooms and\nproctoring crews for massive tests, together with its implementation as the\nopen-box system RaPID-Omega. The mathematical model is a binary integer\nprogramming problem: a combination of the 0-1 Knapsack problem and the\njob-assignment problem. The model makes decisions according the following\ncriteria in order of priority: minimization of labor-hours, maximization of\nequity in the distribution of duties and maximization of the proctoring\nquality. The software is a digital solution for the aforementioned problem,\nwhich is a common need in educational institutions offering large, coordinated,\nlower-division courses. The system can be downloaded from\n\\url{https://sites.google.com/a/unal.edu.co/fernando-a-morales-j/home/research/software}\n",
        "pdf_link": "http://arxiv.org/pdf/1911.06055v5"
    },
    {
        "title": "Eigen-AD: Algorithmic Differentiation of the Eigen Library",
        "authors": [
            "Patrick Peltzer",
            "Johannes Lotz",
            "Uwe Naumann"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  In this work we present useful techniques and possible enhancements when\napplying an Algorithmic Differentiation (AD) tool to the linear algebra library\nEigen using our in-house AD by overloading (AD-O) tool dco/c++ as a case study.\nAfter outlining performance and feasibility issues when calculating derivatives\nfor the official Eigen release, we propose Eigen-AD, which enables different\noptimization options for an AD-O tool by providing add-on modules for Eigen.\nThe range of features includes a better handling of expression templates for\ngeneral performance improvements, as well as implementations of symbolically\nderived expressions for calculating derivatives of certain core operations. The\nsoftware design allows an AD-O tool to provide specializations to automatically\ninclude symbolic operations and thereby keep the look and feel of plain AD by\noverloading. As a showcase, dco/c++ is provided with such a module and its\nsignificant performance improvements are validated by benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.12604v2"
    },
    {
        "title": "Assign optimization for algorithmic differentiation reuse index\n  management strategies",
        "authors": [
            "Max Sagebaum",
            "Johannes Blühdorn",
            "Nicolas R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The identification of primal variables and adjoint variables is usually done\nvia indices in operator overloading algorithmic differentiation tools. One\napproach is a linear management scheme, which is easy to implement and supports\nmemory optimization for copy statements. An alternative approach performs a\nreuse of indices, which requires more implementation effort but results in much\nsmaller adjoint vectors. Therefore, the vector mode of algorithmic\ndifferentiation scales better with the reuse management scheme. In this paper,\nwe present a novel approach that reuses the indices and allows the copy\noptimization, thus combining the advantages of the two aforementioned schemes.\nThe new approach is compared to the known approaches on a simple synthetic test\ncase and a real-world example using the computational fluid dynamics solver\nSU2.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.12992v3"
    },
    {
        "title": "Preparing Ginkgo for AMD GPUs -- A Testimonial on Porting CUDA Code to\n  HIP",
        "authors": [
            "Yuhsiang M. Tsai",
            "Terry Cojean",
            "Tobias Ribizel",
            "Hartwig Anzt"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  With AMD reinforcing their ambition in the scientific high performance\ncomputing ecosystem, we extend the hardware scope of the Ginkgo linear algebra\npackage to feature a HIP backend for AMD GPUs. In this paper, we report and\ndiscuss the porting effort from CUDA, the extension of the HIP framework to add\nmissing features such as cooperative groups, the performance price of compiling\nHIP code for AMD architectures, and the design of a library providing native\nbackends for NVIDIA and AMD GPUs while minimizing code duplication by using a\nshared code base.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.14290v1"
    },
    {
        "title": "Ginkgo: A Modern Linear Operator Algebra Framework for High Performance\n  Computing",
        "authors": [
            "Hartwig Anzt",
            "Terry Cojean",
            "Goran Flegar",
            "Fritz Göbel",
            "Thomas Grützmacher",
            "Pratik Nayak",
            "Tobias Ribizel",
            "Yuhsiang Mike Tsai",
            "Enrique S. Quintana-Ortí"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper, we present Ginkgo, a modern C++ math library for scientific\nhigh performance computing. While classical linear algebra libraries act on\nmatrix and vector objects, Ginkgo's design principle abstracts all\nfunctionality as \"linear operators\", motivating the notation of a \"linear\noperator algebra library\". Ginkgo's current focus is oriented towards providing\nsparse linear algebra functionality for high performance GPU architectures, but\ngiven the library design, this focus can be easily extended to accommodate\nother algorithms and hardware architectures. We introduce this sophisticated\nsoftware architecture that separates core algorithms from architecture-specific\nback ends and provide details on extensibility and sustainability measures. We\nalso demonstrate Ginkgo's usability by providing examples on how to use its\nfunctionality inside the MFEM and deal.ii finite element ecosystems. Finally,\nwe offer a practical demonstration of Ginkgo's high performance on\nstate-of-the-art GPU architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.16852v2"
    },
    {
        "title": "Automatic Generation of Interpolants for Lattice Samplings: Part I --\n  Theory and Analysis",
        "authors": [
            "Joshua Horacsek",
            "Usman Alim"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Interpolation is a fundamental technique in scientific computing and is at\nthe heart of many scientific visualization techniques. There is usually a\ntrade-off between the approximation capabilities of an interpolation scheme and\nits evaluation efficiency. For many applications, it is important for a user to\nbe able to navigate their data in real time. In practice, the evaluation\nefficiency (or speed) outweighs any incremental improvements in reconstruction\nfidelity. In this two-part work, we first analyze from a general standpoint the\nuse of compact piece-wise polynomial basis functions to efficiently interpolate\ndata that is sampled on a lattice. In the sequel, we detail how we generate\nefficient implementations via automatic code generation on both CPU and GPU\narchitectures. Specifically, in this paper, we propose a general framework that\ncan produce a fast evaluation scheme by analyzing the algebro-geometric\nstructure of the convolution sum for a given lattice and basis function\ncombination. We demonstrate the utility and generality of our framework by\nproviding fast implementations of various box splines on the Body Centered and\nFace Centered Cubic lattices, as well as some non-separable box splines on the\nCartesian lattice. We also provide fast implementations for certain Voronoi\nsplines that have not yet appeared in the literature. Finally, we demonstrate\nthat this framework may also be used for non-Cartesian lattices in 4D.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.08514v1"
    },
    {
        "title": "Automatic Generation of Interpolants for Lattice Samplings: Part II --\n  Implementation and Code Generation",
        "authors": [
            "Joshua Horacsek",
            "Usman Alim"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  In the prequel to this paper, we presented a systematic framework for\nprocessing spline spaces. In this paper, we take the results of that framework\nand provide a code generation pipeline that automatically generates efficient\nimplementations of spline spaces. We decompose the final algorithm from Part I\nand translate the resulting components into LLVM-IR (a low level language that\ncan be compiled to various targets/architectures). Our design provides a\nhandful of parameters for a practitioner to tune - this is one of the avenues\nthat provides us with the flexibility to target many different computational\narchitectures and tune performance on those architectures. We also provide an\nevaluation of the effect of the different parameters on performance.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.08518v1"
    },
    {
        "title": "Event-Based Automatic Differentiation of OpenMP with OpDiLib",
        "authors": [
            "Johannes Blühdorn",
            "Max Sagebaum",
            "Nicolas R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We present the new software OpDiLib, a universal add-on for classical\noperator overloading AD tools that enables the automatic differentiation (AD)\nof OpenMP parallelized code. With it, we establish support for OpenMP features\nin a reverse mode operator overloading AD tool to an extent that was previously\nonly reported on in source transformation tools. We achieve this with an\nevent-based implementation ansatz that is unprecedented in AD. Combined with\nmodern OpenMP features around OMPT, we demonstrate how it can be used to\nachieve differentiation without any additional modifications of the source\ncode; neither do we impose a priori restrictions on the data access patterns,\nwhich makes OpDiLib highly applicable. For further performance optimizations,\nrestrictions like atomic updates on adjoint variables can be lifted in a\nfine-grained manner. OpDiLib can also be applied in a semi-automatic fashion\nvia a macro interface, which supports compilers that do not implement OMPT. We\ndemonstrate the applicability of OpDiLib for a pure operator overloading\napproach in a hybrid parallel environment. We quantify the cost of atomic\nupdates on adjoint variables and showcase the speedup and scaling that can be\nachieved with the different configurations of OpDiLib in both the forward and\nthe reverse pass.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.11572v3"
    },
    {
        "title": "An open-source ABAQUS implementation of the scaled boundary finite\n  element method to study interfacial problems using polyhedral meshes",
        "authors": [
            "Shukai Ya",
            "Sascha Eisenträger",
            "Chongmin Song",
            "Jianbo Li"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The scaled boundary finite element method (SBFEM) is capable of generating\npolyhedral elements with an arbitrary number of surfaces. This salient feature\nsignificantly alleviates the meshing burden being a bottleneck in the analysis\npipeline in the standard finite element method (FEM). In this paper, we\nimplement polyhedral elements based on the SBFEM into the commercial finite\nelement software ABAQUS. To this end, user elements are provided through the\nuser subroutine UEL. Detailed explanations regarding the data structures and\nimplementational aspects of the procedures are given. The focus of the current\nimplementation is on interfacial problems and therefore, element-based surfaces\nare created on polyhedral user elements to establish interactions. This is\nachieved by an overlay of standard finite elements with negligible stiffness,\nprovided in the ABAQUS element library, with polyhedral user elements. By means\nof several numerical examples, the advantages of polyhedral elements regarding\nthe treatment of non-matching interfaces and automatic mesh generation are\nclearly demonstrated. Thus, the performance of ABAQUS for problems involving\ninterfaces is augmented based on the availability of polyhedral meshes. Due to\nthe implementation of polyhedral user elements, ABAQUS can directly handle\ncomplex geometries given in the form of digital images or stereolithography\n(STL) files. In order to facilitate the use of the proposed approach, the code\nof the UEL is published open-source and can be downloaded from\nhttps://github.com/ShukaiYa/SBFEM-UEL.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.09663v1"
    },
    {
        "title": "FEniCS-preCICE: Coupling FEniCS to other Simulation Software",
        "authors": [
            "Benjamin Rodenberg",
            "Ishaan Desai",
            "Richard Hertrich",
            "Alexander Jaust",
            "Benjamin Uekermann"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The new software FEniCS-preCICE is a middle software layer, sitting in\nbetween the existing finite-element library FEniCS and the coupling library\npreCICE. The middle layer simplifies coupling (existing) FEniCS application\ncodes to other simulation software via preCICE. To this end, FEniCS-preCICE\nconverts between FEniCS and preCICE mesh and data structures, provides\neasy-to-use coupling conditions, and manages data checkpointing for implicit\ncoupling. The new software is a library itself and follows a FEniCS-native\nstyle. Only a few lines of additional code are necessary to prepare a FEniCS\napplication code for coupling. We illustrate the functionality of\nFEniCS-preCICE by two examples: a FEniCS heat conduction code coupled to\nOpenFOAM and a FEniCS linear elasticity code coupled to SU2. The results of\nboth scenarios are compared with other simulation software showing good\nagreement.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.11191v2"
    },
    {
        "title": "Kokkos Kernels: Performance Portable Sparse/Dense Linear Algebra and\n  Graph Kernels",
        "authors": [
            "Sivasankaran Rajamanickam",
            "Seher Acer",
            "Luc Berger-Vergiat",
            "Vinh Dang",
            "Nathan Ellingwood",
            "Evan Harvey",
            "Brian Kelley",
            "Christian R. Trott",
            "Jeremiah Wilke",
            "Ichitaro Yamazaki"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  As hardware architectures are evolving in the push towards exascale,\ndeveloping Computational Science and Engineering (CSE) applications depend on\nperformance portable approaches for sustainable software development. This\npaper describes one aspect of performance portability with respect to\ndeveloping a portable library of kernels that serve the needs of several CSE\napplications and software frameworks. We describe Kokkos Kernels, a library of\nkernels for sparse linear algebra, dense linear algebra and graph kernels. We\ndescribe the design principles of such a library and demonstrate portable\nperformance of the library using some selected kernels. Specifically, we\ndemonstrate the performance of four sparse kernels, three dense batched\nkernels, two graph kernels and one team level algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.11991v1"
    },
    {
        "title": "Understanding performance variability in standard and pipelined parallel\n  Krylov solvers",
        "authors": [
            "Hannah Morgan",
            "Patrick Sanan",
            "Matthew G. Knepley",
            "Richard Tran Mills"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  In this work, we collect data from runs of Krylov subspace methods and\npipelined Krylov algorithms in an effort to understand and model the impact of\nmachine noise and other sources of variability on performance. We find large\nvariability of Krylov iterations between compute nodes for standard methods\nthat is reduced in pipelined algorithms, directly supporting conjecture, as\nwell as large variation between statistical distributions of runtimes across\niterations. Based on these results, we improve upon a previously introduced\nnondeterministic performance model by allowing iterations to fluctuate over\ntime. We present our data from runs of various Krylov algorithms across\nmultiple platforms as well as our updated non-stationary model that provides\ngood agreement with observations. We also suggest how it can be used as a\npredictive tool.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.12067v1"
    },
    {
        "title": "The landscape of software for tensor computations",
        "authors": [
            "Christos Psarras",
            "Lars Karlsson",
            "Jiajia Li",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Tensors (also commonly seen as multi-linear operators or as multi-dimensional\narrays) are ubiquitous in scientific computing and in data science, and so are\nthe software efforts for tensor operations. Particularly in recent years, we\nhave observed an explosion in libraries, compilers, packages, and toolboxes;\nunfortunately these efforts are very much scattered among the different\nscientific domains, and inevitably suffer from replication, suboptimal\nimplementations, and in many cases, limited visibility. As a first step towards\ncountering these inefficiencies, here we survey and loosely classify software\npackages related to tensor computations. Our aim is to assemble a comprehensive\nand up-to-date snapshot of the tensor software landscape, with the intention of\nhelping both users and developers. Aware of the difficulties inherent in any\nmulti-discipline survey, we very much welcome the reader's help in amending and\nexpanding our software list, which currently features 80 projects.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.13756v3"
    },
    {
        "title": "Implementation of hyperbolic complex numbers in Julia language",
        "authors": [
            "Anna V. Korolkova",
            "Migran N. Gevorkyan",
            "Dmitry S. Kulyabov"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Background: Hyperbolic complex numbers are used in the description of\nhyperbolic spaces. One of the well-known examples of such spaces is the\nMinkowski space, which plays a leading role in the problems of the special\ntheory of relativity and electrodynamics. However, such numbers are not very\ncommon in different programming languages. Purpose: Of interest is the\nimplementation of hyperbolic complex in scientific programming languages, in\nparticular, in the Julia language. Methods: The Julia language is based on the\nconcept of multiple dispatch. This concept is an extension of the concept of\npolymorphism for object-oriented programming languages. To implement hyperbolic\ncomplex numbers, the multiple dispatching approach of the Julia language was\nused. Results: The result is a library that implements hyperbolic numbers.\nConclusions: Based on the results of the study, we can conclude that the\nconcept of multiple dispatching in scientific programming languages is\nconvenient and natural.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01707v1"
    },
    {
        "title": "DarSIA: An open-source Python toolbox for two-scale image processing of\n  dynamics in porous media",
        "authors": [
            "Jan Martin Nordbotten",
            "Benyamine Benali",
            "Jakub Wiktor Both",
            "Bergit Brattekås",
            "Erlend Storvik",
            "Martin A. Fernø"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Understanding porous media flow is inherently a multi-scale challenge, where\nat the core lies the aggregation of pore-level processes to a continuum, or\nDarcy-scale, description. This challenge is directly mirrored in image\nprocessing, where grains and interfaces may be clearly visible, yet continuous\nparameters are desirable to measure. Classical image processing is poorly\nadapted to this setting, as most techniques do not explicitly utilize the fact\nthat the image contains explicit physical processes.\n  Here, we adapt classical image processing concepts to what we define as\nphysical images of porous materials and processes within them. This is realized\nthrough the development of a new open-source image analysis toolbox\nspecifically adapted to time-series of images of porous materials.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.05455v1"
    },
    {
        "title": "PyOED: An Extensible Suite for Data Assimilation and Model-Constrained\n  Optimal Design of Experiments",
        "authors": [
            "Abhijit Chowdhary",
            "Shady E. Ahmed",
            "Ahmed Attia"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  This paper describes PyOED, a highly extensible scientific package that\nenables developing and testing model-constrained optimal experimental design\n(OED) for inverse problems. Specifically, PyOED aims to be a comprehensive\nPython toolkit for model-constrained OED. The package targets scientists and\nresearchers interested in understanding the details of OED formulations and\napproaches. It is also meant to enable researchers to experiment with standard\nand innovative OED technologies with a wide range of test problems (e.g.,\nsimulation models). OED, inverse problems (e.g., Bayesian inversion), and data\nassimilation (DA) are closely related research fields, and their formulations\noverlap significantly. Thus, PyOED is continuously being expanded with a\nplethora of Bayesian inversion, DA, and OED methods as well as new scientific\nsimulation models, observation error models, and observation operators. These\npieces are added such that they can be permuted to enable testing OED methods\nin various settings of varying complexities. The PyOED core is completely\nwritten in Python and utilizes the inherent object-oriented capabilities;\nhowever, the current version of PyOED is meant to be extensible rather than\nscalable. Specifically, PyOED is developed to enable rapid development and\nbenchmarking of OED methods with minimal coding effort and to maximize code\nreutilization. This paper provides a brief description of the PyOED layout and\nphilosophy and provides a set of exemplary test cases and tutorials to\ndemonstrate the potential of the package.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.08336v3"
    },
    {
        "title": "A Representation of Binary Matrices",
        "authors": [
            "Hristina Kostadinova",
            "Krasimir Yordzhev"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In this article we discuss the presentation of a random binary matrix using\nsequence of whole nonnegative numbers. We examine some advantages and\ndisadvantages of this presentation as an alternative of the standard\npresentation using two-dimensional array. It is shown that the presentation of\nbinary matrices using ordered n-tuples of natural numbers makes the algorithms\nfaster and saves a lot of memory. In this work we use object-oriented\nprogramming using the syntax and the semantic of C++ programming language.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1473v1"
    },
    {
        "title": "Test Problem Construction for Single-Objective Bilevel Optimization",
        "authors": [
            "Ankur Sinha",
            "Pekka Malo",
            "Kalyanmoy Deb"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  In this paper, we propose a procedure for designing controlled test problems\nfor single-objective bilevel optimization. The construction procedure is\nflexible and allows its user to control the different complexities that are to\nbe included in the test problems independently of each other. In addition to\nproperties that control the difficulty in convergence, the procedure also\nallows the user to introduce difficulties caused by interaction of the two\nlevels. As a companion to the test problem construction framework, the paper\npresents a standard test suite of twelve problems, which includes eight\nunconstrained and four constrained problems. Most of the problems are scalable\nin terms of variables and constraints. To provide baseline results, we have\nsolved the proposed test problems using a nested bilevel evolutionary\nalgorithm. The results can be used for comparison, while evaluating the\nperformance of any other bilevel optimization algorithm. The codes related to\nthe paper may be accessed from the website \\url{http://bilevel.org}.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1942v3"
    },
    {
        "title": "Numerical application and Turbo C program using the Gauss-Jordan Method",
        "authors": [
            "Anghel Drugarin",
            "Cornelia Victoria"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The article presents the general notions and algorithm about the Gauss-Jordan\nmethod. An eloquent example is given and the Turbo C program illustrated this\nmethod. We conclude that we can obtain by this method the determinant, by\nsimple calculations and reducing the rounding errors\n",
        "pdf_link": "http://arxiv.org/pdf/1401.7962v1"
    },
    {
        "title": "A data porting tool for coupling models with different discretization\n  needs",
        "authors": [
            "Stelian Ion",
            "Dorin Marinescu",
            "Stefan-Gicu Cruceanu",
            "Virgil Iordache"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The presented work is part of a larger research program dealing with\ndeveloping tools for coupling biogeochemical models in contaminated landscapes.\nThe specific objective of this article is to provide the researchers a tool to\nbuild hexagonal raster using information from a rectangular raster data (e.g.\nGIS format), data porting. This tool involves a computational algorithm and an\nopen source software (written in C). The method of extending the reticulated\nfunctions defined on 2D networks is an essential key of this algorithm and can\nalso be used for other purposes than data porting. The algorithm allows one to\nbuild the hexagonal raster with a cell size independent from the geometry of\nthe rectangular raster. The extended function is a bi-cubic spline which can\nexactly reconstruct polynomials up to degree three in each variable. We\nvalidate the method by analyzing errors in some theoretical case studies\nfollowed by other studies with real terrain elevation data. We also introduce\nand briefly present an iterative water routing method and use it for validation\non a case with concrete terrain data.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2925v1"
    },
    {
        "title": "Modular SIMD arithmetic in Mathemagix",
        "authors": [
            "Joris van der Hoeven",
            "Grégoire Lecerf",
            "Guillaume Quintin"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Modular integer arithmetic occurs in many algorithms for computer algebra,\ncryptography, and error correcting codes. Although recent microprocessors\ntypically offer a wide range of highly optimized arithmetic functions, modular\ninteger operations still require dedicated implementations. In this article, we\nsurvey existing algorithms for modular integer arithmetic, and present detailed\nvectorized counterparts. We also present several applications, such as fast\nmodular Fourier transforms and multiplication of integer polynomials and\nmatrices. The vectorized algorithms have been implemented in C++ inside the\nfree computer algebra and analysis system Mathemagix. The performance of our\nimplementation is illustrated by various benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.3383v1"
    },
    {
        "title": "KBLAS: An Optimized Library for Dense Matrix-Vector Multiplication on\n  GPU Accelerators",
        "authors": [
            "Ahmad Abdelfattah",
            "David Keyes",
            "Hatem Ltaief"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  KBLAS is a new open source high performance library that provides optimized\nkernels for a subset of Level 2 BLAS functionalities on CUDA-enabled GPUs.\nSince performance of dense matrix-vector multiplication is hindered by the\noverhead of memory accesses, a double-buffering optimization technique is\nemployed to overlap data motion with computation. After identifying a proper\nset of tuning parameters, KBLAS is able to efficiently run on various GPU\narchitectures across different generations, avoiding the time-consuming step of\ncode rewriting, while still being compliant with the standard BLAS API. Another\nadvanced optimization technique allows to ensure coalesced memory access when\ndealing with submatrices, especially in the context of high level dense linear\nalgebra algorithms. All four precisions KBLAS kernels have been leveraged to\nmulti-GPUs environment, which requires the introduction of new APIs to ease\nusers' experiences on these challenging systems. The KBLAS performance\noutperforms existing state-of-the-art implementations on all matrix sizes,\nachieves asymptotically up to 50% and 60% speedup on single GPU and multi-GPUs\nsystems, respectively, and validates our performance model. A subset of KBLAS\nhigh performance kernels has been integrated into NVIDIA's standard BLAS\nimplementation (cuBLAS) for larger dissemination, starting version 6.0.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.1726v1"
    },
    {
        "title": "Task Parallel Incomplete Cholesky Factorization using 2D\n  Partitioned-Block Layout",
        "authors": [
            "Kyungjoo Kim",
            "Sivasankaran Rajamanickam",
            "George Stelle",
            "H. Carter Edwards",
            "Stephen L. Olivier"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We introduce a task-parallel algorithm for sparse incomplete Cholesky\nfactorization that utilizes a 2D sparse partitioned-block layout of a matrix.\nOur factorization algorithm follows the idea of algorithms-by-blocks by using\nthe block layout. The algorithm-by-blocks approach induces a task graph for the\nfactorization. These tasks are inter-related to each other through their data\ndependences in the factorization algorithm. To process the tasks on various\nmanycore architectures in a portable manner, we also present a portable tasking\nAPI that incorporates different tasking backends and device-specific features\nusing an open-source framework for manycore platforms i.e., Kokkos. A\nperformance evaluation is presented on both Intel Sandybridge and Xeon Phi\nplatforms for matrices from the University of Florida sparse matrix collection\nto illustrate merits of the proposed task-based factorization. Experimental\nresults demonstrate that our task-parallel implementation delivers about 26.6x\nspeedup (geometric mean) over single-threaded incomplete Cholesky-by-blocks and\n19.2x speedup over serial Cholesky performance which does not carry tasking\noverhead using 56 threads on the Intel Xeon Phi processor for sparse matrices\narising from various application problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.05871v1"
    },
    {
        "title": "Vectorization of Multibyte Floating Point Data Formats",
        "authors": [
            "Andrew Anderson",
            "David Gregg"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We propose a scheme for reduced-precision representation of floating point\ndata on a continuum between IEEE-754 floating point types. Our scheme enables\nthe use of lower precision formats for a reduction in storage space\nrequirements and data transfer volume. We describe how our scheme can be\naccelerated using existing hardware vector units on a general-purpose processor\n(GPP). Exploiting native vector hardware allows us to support reduced precision\nfloating point with low overhead. We demonstrate that supporting reduced\nprecision in the compiler as opposed to using a library approach can yield a\nlow overhead solution for GPPs.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.07789v3"
    },
    {
        "title": "Fast calculation of inverse square root with the use of magic constant\n  $-$ analytical approach",
        "authors": [
            "Leonid V. Moroz",
            "Cezary J. Walczyk",
            "Andriy Hrynchyshyn",
            "Vijay Holimath",
            "Jan L. Cieśliński"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present a mathematical analysis of transformations used in fast\ncalculation of inverse square root for single-precision floating-point numbers.\nOptimal values of the so called magic constants are derived in a systematic\nway, minimizing either absolute or relative errors at subsequent stages of the\ndiscussed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.04483v1"
    },
    {
        "title": "Interoperability in the OpenDreamKit Project: The Math-in-the-Middle\n  Approach",
        "authors": [
            "Paul-Olivier Dehaye",
            "Michael Kohlhase",
            "Alexander Konovalov",
            "Samuel Lelièvre",
            "Markus Pfeiffer",
            "Nicolas M. Thiéry"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  OpenDreamKit --- \"Open Digital Research Environment Toolkit for the\nAdvancement of Mathematics\" --- is an H2020 EU Research Infrastructure project\nthat aims at supporting, over the period 2015--2019, the ecosystem of\nopen-source mathematical software systems. From that, OpenDreamKit will deliver\na flexible toolkit enabling research groups to set up Virtual Research\nEnvironments, customised to meet the varied needs of research projects in pure\nmathematics and applications.\n  An important step in the OpenDreamKit endeavor is to foster the\ninteroperability between a variety of systems, ranging from computer algebra\nsystems over mathematical databases to front-ends. This is the mission of the\nintegration work package (WP6). We report on experiments and future plans with\nthe \\emph{Math-in-the-Middle} approach. This information architecture consists\nin a central mathematical ontology that documents the domain and fixes a joint\nvocabulary, combined with specifications of the functionalities of the various\nsystems. Interaction between systems can then be enriched by pivoting off this\ninformation architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.06424v1"
    },
    {
        "title": "SimOutUtils - Utilities for analyzing time series simulation output",
        "authors": [
            "Nuno Fachada",
            "Vitor V. Lopes",
            "Rui C. Martins",
            "Agostinho C. Rosa"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  SimOutUtils is a suite of MATLAB/Octave functions for studying and analyzing\ntime series-like output from stochastic simulation models. More specifically,\nSimOutUtils allows modelers to study and visualize simulation output dynamics,\nperform distributional analysis of output statistical summaries, as well as\ncompare these summaries in order to assert the statistical equivalence of two\nor more model implementations. Additionally, the provided functions are able to\nproduce publication quality figures and tables showcasing results from the\nspecified simulation output studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.06914v4"
    },
    {
        "title": "A Subdivision Solver for Systems of Large Dense Polynomials",
        "authors": [
            "Rémi Imbach"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We describe here the package {\\tt subdivision\\\\_solver} for the mathematical\nsoftware {\\tt SageMath}. It provides a solver on real numbers for square\nsystems of large dense polynomials. By large polynomials we mean multivariate\npolynomials with large degrees, which coefficients have large bit-size. While\nstaying robust, symbolic approaches to solve systems of polynomials see their\nperformances dramatically affected by high degree and bit-size of input\npolynomials.Available numeric approaches suffer from the cost of the evaluation\nof large polynomials and their derivatives.Our solver is based on interval\nanalysis and bisections of an initial compact domain of $\\R^n$ where solutions\nare sought. Evaluations on intervals with Horner scheme is performed by the\npackage {\\tt fast\\\\_polynomial} for {\\tt SageMath}.The non-existence of a\nsolution within a box is certified by an evaluation scheme that uses a Taylor\nexpansion at order 2, and existence and uniqueness of a solution within a box\nis certified with krawczyk operator.The precision of the working arithmetic is\nadapted on the fly during the subdivision process and we present a new\nheuristic criterion to decide if the arithmetic precision has to be increased.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.07916v2"
    },
    {
        "title": "Implementing Strassen's Algorithm with BLIS",
        "authors": [
            "Jianyu Huang",
            "Tyler M. Smith",
            "Greg M. Henry",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We dispel with \"street wisdom\" regarding the practical implementation of\nStrassen's algorithm for matrix-matrix multiplication (DGEMM). Conventional\nwisdom: it is only practical for very large matrices. Our implementation is\npractical for small matrices. Conventional wisdom: the matrices being\nmultiplied should be relatively square. Our implementation is practical for\nrank-k updates, where k is relatively small (a shape of importance for\nlibraries like LAPACK). Conventional wisdom: it inherently requires substantial\nworkspace. Our implementation requires no workspace beyond buffers already\nincorporated into conventional high-performance DGEMM implementations.\nConventional wisdom: a Strassen DGEMM interface must pass in workspace. Our\nimplementation requires no such workspace and can be plug-compatible with the\nstandard DGEMM interface. Conventional wisdom: it is hard to demonstrate\nspeedup on multi-core architectures. Our implementation demonstrates speedup\nover conventional DGEMM even on an Intel(R) Xeon Phi(TM) coprocessor utilizing\n240 threads. We show how a distributed memory matrix-matrix multiplication also\nbenefits from these advances.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.01078v1"
    },
    {
        "title": "The polymake XML file format",
        "authors": [
            "Ewgenij Gawrilow",
            "Simon Hampe",
            "Michael Joswig"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We describe an XML file format for storing data from computations in algebra\nand geometry. We also present a formal specification based on a RELAX-NG\nschema.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.05057v1"
    },
    {
        "title": "OPESCI-FD: Automatic Code Generation Package for Finite Difference\n  Models",
        "authors": [
            "Tianjiao Sun"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  In this project, we introduce OPESCI-FD, a Python package built on symbolic\nmathematics to automatically generate Finite Difference models from a\nhigh-level description of the model equations. We investigate applying this\nframework to generate the propagator program used in seismic imaging. We\nimplement the 3D velocity-stress FD scheme as an example and demonstrate the\nadvantages of usability, flexibility and accuracy of the framework. The design\nof OPESCI-FD aims to allow rapid development, analysis and optimisation of\nFinite Difference programs. OPESCI-FD is the foundation for continuing\ndevelopment by the OPESCI project team, building on the research presented in\nthis report. This report concludes by reviewing the further developments that\nare already under way, as well as the scope for extension to cater for other\nequations and numerical schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.06381v1"
    },
    {
        "title": "pySDC - Prototyping spectral deferred corrections",
        "authors": [
            "Robert Speck"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this paper we present the Python framework pySDC for solving collocation\nproblems with spectral deferred correction methods (SDC) and their\ntime-parallel variant PFASST, the parallel full approximation scheme in space\nand time. pySDC features many implementations of SDC and PFASST, from simple\nimplicit time-stepping to high-order implicit-explicit or multi-implicit\nsplitting and multi-level spectral deferred corrections. It comes with many\ndifferent, pre-implemented examples and has seven tutorials to help new users\nwith their first steps. Time-parallelism is implemented either in an emulated\nway for debugging and prototyping as well as using MPI for benchmarking. The\ncode is fully documented and tested using continuous integration, including\nmost results of previous publications. Here, we describe the structure of the\ncode by taking two different perspectives: the user's and the developer's\nperspective. While the first sheds light on the front-end, the examples and the\ntutorials, the second is used to describe the underlying implementation and the\ndata structures. We show three different examples to highlight various aspects\nof the implementation, the capabilities and the usage of pySDC. Also, couplings\nto the FEniCS framework and PETSc, the latter including spatial parallelism\nwith MPI, are described.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.02731v1"
    },
    {
        "title": "Implementing Strassen's Algorithm with CUTLASS on NVIDIA Volta GPUs",
        "authors": [
            "Jianyu Huang",
            "Chenhan D. Yu",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Conventional GPU implementations of Strassen's algorithm (Strassen) typically\nrely on the existing high-performance matrix multiplication (GEMM), trading\nspace for time. As a result, such approaches can only achieve practical speedup\nfor relatively large, \"squarish\" matrices due to the extra memory overhead, and\ntheir usages are limited due to the considerable workspace. We present novel\nStrassen primitives for GPUs that can be composed to generate a family of\nStrassen algorithms. Our algorithms utilize both the memory and thread\nhierarchies on GPUs, reusing shared memory and register files inherited from\nGEMM, fusing additional operations, and avoiding extra workspace. We further\nexploit intra- and inter-kernel parallelism by batching, streaming, and\nemploying atomic operations. We also develop a performance model for NVIDIA\nVolta GPUs to select the appropriate blocking parameters and predict the\nperformance for GEMM and Strassen. Overall, our 1-level Strassen can achieve up\nto 1.11x speedup with a crossover point as small as 1,536 compared to\ncublasSgemm on a NVIDIA Tesla V100 GPU. With additional workspace, our 2-level\nStrassen can achieve 1.19x speedup with a crossover point at 7,680.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.07984v1"
    },
    {
        "title": "Tuning the Performance of a Computational Persistent Homology Package",
        "authors": [
            "Alan Hylton",
            "Gregory Henselman-Petrusek",
            "Janche Sang",
            "Robert Short"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In recent years, persistent homology has become an attractive method for data\nanalysis. It captures topological features, such as connected components,\nholes, and voids from point cloud data and summarizes the way in which these\nfeatures appear and disappear in a filtration sequence. In this project, we\nfocus on improving the performance of Eirene, a computational package for\npersistent homology. Eirene is a 5000-line open-source software library\nimplemented in the dynamic programming language Julia. We use the Julia\nprofiling tools to identify performance bottlenecks and develop novel methods\nto manage them, including the parallelization of some time-consuming functions\non multicore/manycore hardware. Empirical results show that performance can be\ngreatly improved.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.04424v1"
    },
    {
        "title": "Software for Sparse Tensor Decomposition on Emerging Computing\n  Architectures",
        "authors": [
            "Eric Phipps",
            "Tamara G. Kolda"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this paper, we develop software for decomposing sparse tensors that is\nportable to and performant on a variety of multicore, manycore, and GPU\ncomputing architectures. The result is a single code whose performance matches\noptimized architecture-specific implementations. The key to a portable approach\nis to determine multiple levels of parallelism that can be mapped in different\nways to different architectures, and we explain how to do this for the\nmatricized tensor times Khatri-Rao product (MTTKRP) which is the key kernel in\ncanonical polyadic tensor decomposition. Our implementation leverages the\nKokkos framework, which enables a single code to achieve high performance\nacross multiple architectures that differ in how they approach fine-grained\nparallelism. We also introduce a new construct for portable thread-local\narrays, which we call compile-time polymorphic arrays. Not only are the\nspecifics of our approaches and implementation interesting for tuning tensor\ncomputations, but they also provide a roadmap for developing other portable\nhigh-performance codes. As a last step in optimizing performance, we modify the\nMTTKRP algorithm itself to do a permuted traversal of tensor nonzeros to reduce\natomic-write contention. We test the performance of our implementation on 16-\nand 68-core Intel CPUs and the K80 and P100 NVIDIA GPUs, showing that we are\ncompetitive with state-of-the-art architecture-specific codes while having the\nadvantage of being able to run on a variety of architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.09175v2"
    },
    {
        "title": "FDBB: Fluid Dynamics Building Blocks",
        "authors": [
            "Matthias Möller",
            "Andrzej Jaeschke"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  High-performance computing platforms are becoming more and more\nheterogeneous, which makes it very difficult for researchers and scientific\nsoftware developers to keep up with the rapid changes on the hardware market.\nIn this paper, the open-source project FDBB (Fluid Dynamics Building Blocks) is\npresented, which eases the development of fluid dynamics applications for\nheterogeneous systems. It consists of a low-level API that provides a unified\ninterface to many different linear algebra back-ends and a lightweight and\nextendible high-level expression template library, which provides largely\ncustomizable fluid dynamics building blocks, like transformations between\nprimary and secondary variables as well as expressions for Riemann invariants,\nequations of state, inviscid fluxes and their flux-Jacobians. The performance\nof the developed approach is assessed both for synthetic micro-benchmarks and\nwithin mini-applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.09851v1"
    },
    {
        "title": "Optimizations of the Eigensolvers in the ELPA Library",
        "authors": [
            "P. Kus",
            "A. Marek",
            "S. S. Koecher",
            "H. -H. Kowalski",
            "C. Carbogno",
            "Ch. Scheurer",
            "K. Reuter",
            "M. Scheffler",
            "H. Lederer"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The solution of (generalized) eigenvalue problems for symmetric or Hermitian\nmatrices is a common subtask of many numerical calculations in electronic\nstructure theory or materials science. Solving the eigenvalue problem can\neasily amount to a sizeable fraction of the whole numerical calculation. For\nresearchers in the field of computational materials science, an efficient and\nscalable solution of the eigenvalue problem is thus of major importance. The\nELPA-library is a well-established dense direct eigenvalue solver library,\nwhich has proven to be very efficient and scalable up to very large core\ncounts. In this paper, we describe the latest optimizations of the ELPA-library\nfor new HPC architectures of the Intel Skylake processor family with an AVX-512\nSIMD instruction set, or for HPC systems accelerated with recent GPUs. We also\ndescribe a complete redesign of the API in a modern modular way, which, apart\nfrom a much simpler and more flexible usability, leads to a new path to access\nsystem-specific performance optimizations. In order to ensure optimal\nperformance for a particular scientific setting or a specific HPC system, the\nnew API allows the user to influence in straightforward way the internal\ndetails of the algorithms and of performance-critical parameters used in the\nELPA-library. On top of that, we introduced an autotuning functionality, which\nallows for finding the best settings in a self-contained automated way. In\nsituations where many eigenvalue problems with similar settings have to be\nsolved consecutively, the autotuning process of the ELPA-library can be done\n\"on-the-fly\". Practical applications from materials science which rely on\nso-called self-consistency iterations can profit from the autotuning. On some\nexamples of scientific interest, simulated with the FHI-aims application, the\nadvantages of the latest optimizations of the ELPA-library are demonstrated.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.01277v1"
    },
    {
        "title": "Practical Sparse Matrices in C++ with Hybrid Storage and Template-Based\n  Expression Optimisation",
        "authors": [
            "Conrad Sanderson",
            "Ryan Curtin"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Despite the importance of sparse matrices in numerous fields of science,\nsoftware implementations remain difficult to use for non-expert users,\ngenerally requiring the understanding of underlying details of the chosen\nsparse matrix storage format. In addition, to achieve good performance, several\nformats may need to be used in one program, requiring explicit selection and\nconversion between the formats. This can be both tedious and error-prone,\nespecially for non-expert users. Motivated by these issues, we present a\nuser-friendly and open-source sparse matrix class for the C++ language, with a\nhigh-level application programming interface deliberately similar to the widely\nused MATLAB language. This facilitates prototyping directly in C++ and aids the\nconversion of research code into production environments. The class internally\nuses two main approaches to achieve efficient execution: (i) a hybrid storage\nframework, which automatically and seamlessly switches between three underlying\nstorage formats (compressed sparse column, Red-Black tree, coordinate list)\ndepending on which format is best suited and/or available for specific\noperations, and (ii) a template-based meta-programming framework to\nautomatically detect and optimise execution of common expression patterns.\nEmpirical evaluations on large sparse matrices with various densities of\nnon-zero elements demonstrate the advantages of the hybrid storage framework\nand the expression optimisation mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08768v3"
    },
    {
        "title": "Supporting mixed-datatype matrix multiplication within the BLIS\n  framework",
        "authors": [
            "Field G. Van Zee",
            "Devangi N. Parikh",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We approach the problem of implementing mixed-datatype support within the\ngeneral matrix multiplication (GEMM) operation of the BLIS framework, whereby\neach matrix operand A, B, and C may be stored as single- or double-precision\nreal or complex values. Another factor of complexity, whereby the computation\nis allowed to take place in a precision different from the storage precisions\nof either A or B, is also included in the discussion. We first break the\nproblem into mostly orthogonal dimensions, considering the mixing of domains\nseparately from mixing precisions. Support for all combinations of matrix\noperands stored in either the real or complex domain is mapped out by\nenumerating the cases and describing an implementation approach for each.\nSupporting all combinations of storage and computation precisions is handled by\ntypecasting the matrices at key stages of the computation---during packing\nand/or accumulation, as needed. Several optional optimizations are also\ndocumented. Performance results gathered on a 56-core Marvell ThunderX2 and a\n52-core Intel Xeon Platinum demonstrate that high performance is mostly\npreserved, with modest slowdowns incurred from unavoidable typecast\ninstructions. The mixed-datatype implementation confirms that combinatoric\nintractability is avoided, with the framework relying on only two assembly\nmicrokernels to implement 128 datatype combinations.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.06015v2"
    },
    {
        "title": "TuckerMPI: A Parallel C++/MPI Software Package for Large-scale Data\n  Compression via the Tucker Tensor Decomposition",
        "authors": [
            "Grey Ballard",
            "Alicia Klinvex",
            "Tamara G. Kolda"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Our goal is compression of massive-scale grid-structured data, such as the\nmulti-terabyte output of a high-fidelity computational simulation. For such\ndata sets, we have developed a new software package called TuckerMPI, a\nparallel C++/MPI software package for compressing distributed data. The\napproach is based on treating the data as a tensor, i.e., a multidimensional\narray, and computing its truncated Tucker decomposition, a higher-order\nanalogue to the truncated singular value decomposition of a matrix. The result\nis a low-rank approximation of the original tensor-structured data. Compression\nefficiency is achieved by detecting latent global structure within the data,\nwhich we contrast to most compression methods that are focused on local\nstructure. In this work, we describe TuckerMPI, our implementation of the\ntruncated Tucker decomposition, including details of the data distribution and\nin-memory layouts, the parallel and serial implementations of the key kernels,\nand analysis of the storage, communication, and computational costs. We test\nthe software on 4.5 terabyte and 6.7 terabyte data sets distributed across 100s\nof nodes (1000s of MPI processes), achieving compression rates between\n100-200,000$\\times$ which equates to 99-99.999% compression (depending on the\ndesired accuracy) in substantially less time than it would take to even read\nthe same dataset from a parallel filesystem. Moreover, we show that our method\nalso allows for reconstruction of partial or down-sampled data on a single\nnode, without a parallel computer so long as the reconstructed portion is small\nenough to fit on a single machine, e.g., in the instance of\nreconstructing/visualizing a single down-sampled time step or computing summary\nstatistics.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.06043v2"
    },
    {
        "title": "Automatic Generation of Efficient Linear Algebra Programs",
        "authors": [
            "Henrik Barthels",
            "Christos Psarras",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The level of abstraction at which application experts reason about linear\nalgebra computations and the level of abstraction used by developers of\nhigh-performance numerical linear algebra libraries do not match. The former is\nconveniently captured by high-level languages and libraries such as Matlab and\nEigen, while the latter expresses the kernels included in the BLAS and LAPACK\nlibraries. Unfortunately, the translation from a high-level computation to an\nefficient sequence of kernels is a task, far from trivial, that requires\nextensive knowledge of both linear algebra and high-performance computing.\nInternally, almost all high-level languages and libraries use efficient\nkernels; however, the translation algorithms are too simplistic and thus lead\nto a suboptimal use of said kernels, with significant performance losses. In\norder to both achieve the productivity that comes with high-level languages,\nand make use of the efficiency of low level kernels, we are developing Linnea,\na code generator for linear algebra problems. As input, Linnea takes a\nhigh-level description of a linear algebra problem and produces as output an\nefficient sequence of calls to high-performance kernels. In 25 application\nproblems, the code generated by Linnea always outperforms Matlab, Julia, Eigen\nand Armadillo, with speedups up to and exceeding 10x.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.02778v3"
    },
    {
        "title": "Unveiling patterns in xorshift128+ pseudorandom number generators",
        "authors": [
            "Hiroshi Haramoto",
            "Makoto Matsumoto",
            "Mutsuo Saito"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Xorshift128+ is a newly proposed pseudorandom number generator (PRNG), which\nis now the standard PRNG on a number of platforms. We demonstrate that\nthree-dimensional plots of the random points generated by the generator have\nvisible structures: they concentrate on particular planes in the cube. We\nprovide a mathematical analysis of this phenomenon.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.03251v3"
    },
    {
        "title": "PyLops -- A Linear-Operator Python Library for large scale optimization",
        "authors": [
            "Matteo Ravasi",
            "Ivan Vasconcelos"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Linear operators and optimisation are at the core of many algorithms used in\nsignal and image processing, remote sensing, and inverse problems. For small to\nmedium-scale problems, existing software packages (e.g., MATLAB, Python numpy\nand scipy) allow for explicitly building dense (or sparse) matrices and\nperforming algebraic operations (e.g., computation of matrix-vector products\nand manipulation of matrices) with syntax that closely represents their\ncorresponding analytical forms. However, many real application, large-scale\noperators do not lend themselves to explicit matrix representations, usually\nforcing practitioners to forego of the convenient linear-algebra syntax\navailable for their explicit-matrix counterparts. PyLops is an open-source\nPython library providing a flexible and scalable framework for the creation and\ncombination of so-called linear operators, class-based entities that represent\nmatrices and inherit their associated syntax convenience, but do not rely on\nthe creation of explicit matrices. We show that PyLops operators can\ndramatically reduce the memory load and CPU computations compared to\nexplicit-matrix calculations, while still allowing users to seamlessly use\ntheir existing knowledge of compact matrix-based syntax that scales to any\nproblem size because no explicit matrices are required.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12349v1"
    },
    {
        "title": "Characteristics-based Simulink implementation of first-order quasilinear\n  partial differential equations",
        "authors": [
            "Anton Ponomarev",
            "Julian Hofmann",
            "Lutz Gröll"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The paper deals with solving first-order quasilinear partial differential\nequations in an online simulation environment, such as Simulink, utilizing the\nwell-known and well-recommended method of characteristics. Compared to the\ncommonly applied space discretization methods on static grids, the\ncharacteristics-based approach provides better numerical stability. Simulink\nsubsystem implementing the method of characteristics is developed. It employs\nSimulink's built-in solver and its zero-crossing detection algorithm to perform\nsimultaneous integration of a pool of characteristics as well as to create new\ncharacteristics dynamically and discard the old ones. Numerical accuracy of the\nsolution thus obtained is established. The subsystem has been tested on a\nfull-state feedback example and produced better results than the space\ndiscretization-based \"method of lines\". The implementation is available for\ndownload and can be used in a wide range of models.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.13419v2"
    },
    {
        "title": "A user-guide to Gridap -- grid-based approximation of partial\n  differential equations in Julia",
        "authors": [
            "Francesc Verdugo",
            "Santiago Badia"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present Gridap, a new scientific software library for the numerical\napproximation of partial differential equations (PDEs) using grid-based\napproximations. Gridap is an open-source software project exclusively written\nin the Julia programming language. The main motivation behind the development\nof this library is to provide an easy-to-use framework for the development of\ncomplex PDE solvers in a dynamically typed style without sacrificing the\nperformance of statically typed languages. This work is a tutorial-driven user\nguide to the library. It covers some popular linear and nonlinear PDE systems\nfor scalar and vector fields, single and multi-field problems, conforming and\nnonconforming finite element discretizations, on structured and unstructured\nmeshes of simplices and hexahedra.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.01412v2"
    },
    {
        "title": "The deal.II finite element library: design, features, and insights",
        "authors": [
            "Daniel Arndt",
            "Wolfgang Bangerth",
            "Denis Davydov",
            "Timo Heister",
            "Luca Heltai",
            "Martin Kronbichler",
            "Matthias Maier",
            "Jean-Paul Pelteret",
            "Bruno Turcksin",
            "David Wells"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  deal.II is a state-of-the-art finite element library focused on generality,\ndimension-independent programming, parallelism, and extensibility. Herein, we\noutline its primary design considerations and its sophisticated features such\nas distributed meshes, $hp$-adaptivity, support for complex geometries, and\nmatrix-free algorithms. But deal.II is more than just a software library: It is\nalso a diverse and worldwide community of developers and users, as well as an\neducational platform. We therefore also discuss some of the technical and\nsocial challenges and lessons learned in running a large community software\nproject over the course of two decades.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13247v2"
    },
    {
        "title": "An R Package for generating covariance matrices for maximum-entropy\n  sampling from precipitation chemistry data",
        "authors": [
            "Hessa Al-Thani",
            "Jon Lee"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We present an open-source R package (MESgenCov v 0.1.0) for temporally\nfitting multivariate precipitation chemistry data and extracting a covariance\nmatrix for use in the MESP (maximum-entropy sampling problem). We provide\nmultiple functionalities for modeling and model assessment. The package is\ntightly coupled with NADP/NTN (National Atmospheric Deposition Program /\nNational Trends Network) data from their set of 379 monitoring sites,\n1978--present. The user specifies the sites, chemicals, and time period\ndesired, fits an appropriate user-specified univariate model for each site and\nchemical selected, and the package produces a covariance matrix for use by MESP\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.06316v2"
    },
    {
        "title": "Vectorization and Minimization of Memory Footprint for Linear High-Order\n  Discontinuous Galerkin Schemes",
        "authors": [
            "Jean-Matthieu Gallard",
            "Leonhard Rannabauer",
            "Anne Reinarz",
            "Michael Bader"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We present a sequence of optimizations to the performance-critical compute\nkernels of the high-order discontinuous Galerkin solver of the hyperbolic PDE\nengine ExaHyPE -- successively tackling bottlenecks due to SIMD operations,\ncache hierarchies and restrictions in the software design.\n  Starting from a generic scalar implementation of the numerical scheme, our\nfirst optimized variant applies state-of-the-art optimization techniques by\nvectorizing loops, improving the data layout and using Loop-over-GEMM to\nperform tensor contractions via highly optimized matrix multiplication\nfunctions provided by the LIBXSMM library. We show that memory stalls due to a\nmemory footprint exceeding our L2 cache size hindered the vectorization gains.\nWe therefore introduce a new kernel that applies a sum factorization approach\nto reduce the kernel's memory footprint and improve its cache locality. With\nthe L2 cache bottleneck removed, we were able to exploit additional\nvectorization opportunities, by introducing a hybrid\nArray-of-Structure-of-Array data layout that solves the data layout conflict\nbetween matrix multiplications kernels and the point-wise functions to\nimplement PDE-specific terms.\n  With this last kernel, evaluated in a benchmark simulation at high polynomial\norder, only 2\\% of the floating point operations are still performed using\nscalar instructions and 22.5\\% of the available performance is achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.12787v1"
    },
    {
        "title": "SParSH-AMG: A library for hybrid CPU-GPU algebraic multigrid and\n  preconditioned iterative methods",
        "authors": [
            "Sashikumaar Ganesan",
            "Manan Shah"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Hybrid CPU-GPU algorithms for Algebraic Multigrid methods (AMG) to\nefficiently utilize both CPU and GPU resources are presented. In particular,\nhybrid AMG framework focusing on minimal utilization of GPU memory with\nperformance on par with GPU-only implementations is developed. The hybrid AMG\nframework can be tuned to operate at a significantly lower GPU-memory,\nconsequently, enables to solve large algebraic systems. Combining the hybrid\nAMG framework as a preconditioner with Krylov Subspace solvers like Conjugate\nGradient, BiCG methods provides a solver stack to solve a large class of\nproblems. The performance of the proposed hybrid AMG framework is analysed for\nan array of matrices with different properties and size. Further, the\nperformance of CPU-GPU algorithms are compared with the GPU-only\nimplementations to illustrate the significantly lower memory requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.00056v1"
    },
    {
        "title": "Blends in Maple",
        "authors": [
            "Robert M. Corless",
            "Erik Postma"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  A blend of two Taylor series for the same smooth real- or complex-valued\nfunction of a single variable can be useful for approximation. We use an\nexplicit formula for a two-point Hermite interpolational polynomial to\nconstruct such blends. We show a robust Maple implementation that can stably\nand efficiently evaluate blends using linear-cost Horner form, evaluate their\nderivatives to arbitrary order at the same time, or integrate a blend exactly.\nThe implementation is suited for use with evalhf. We provide a top-level user\ninterface and efficient module exports for programmatic use. This work was\npresented at the Maple Conference 2020. See www.maplesoft.com/mapleconference\n",
        "pdf_link": "http://arxiv.org/pdf/2007.05041v2"
    },
    {
        "title": "A Novel Approach to Generate Correctly Rounded Math Libraries for New\n  Floating Point Representations",
        "authors": [
            "Jay P. Lim",
            "Mridul Aanjaneya",
            "John Gustafson",
            "Santosh Nagarakatte"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Given the importance of floating-point~(FP) performance in numerous domains,\nseveral new variants of FP and its alternatives have been proposed (e.g.,\nBfloat16, TensorFloat32, and Posits). These representations do not have\ncorrectly rounded math libraries. Further, the use of existing FP libraries for\nthese new representations can produce incorrect results. This paper proposes a\nnovel approach for generating polynomial approximations that can be used to\nimplement correctly rounded math libraries. Existing methods generate\npolynomials that approximate the real value of an elementary function $f(x)$\nand produce wrong results due to approximation errors and rounding errors in\nthe implementation. In contrast, our approach generates polynomials that\napproximate the correctly rounded value of $f(x)$ (i.e., the value of $f(x)$\nrounded to the target representation). It provides more margin to identify\nefficient polynomials that produce correctly rounded results for all inputs. We\nframe the problem of generating efficient polynomials that produce correctly\nrounded results as a linear programming problem. Our approach guarantees that\nwe produce the correct result even with range reduction techniques. Using our\napproach, we have developed correctly rounded, yet faster, implementations of\nelementary functions for multiple target representations.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.05344v3"
    },
    {
        "title": "Approaches to the implementation of generalized complex numbers in the\n  Julia language",
        "authors": [
            "Migran N. Gevorkyan",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In problems of mathematical physics, to study the structures of spaces using\nthe Cayley-Klein models in theoretical calculations, the use of generalized\ncomplex numbers is required. In the case of computational experiments, such\ntasks require their high-quality implementation in a programming language. The\nproposed small implementation of generalized complex numbers in modern\nprogramming languages have several disadvantages. In this article, we propose\nusing the Julia language as the language for implementing generalized complex\nnumbers, not least because it supports the multiple dispatch mechanism. The\npaper demonstrates the approach to the implementation of one of the types of\ngeneralized complex numbers, namely dual numbers. We place particular emphasis\non the description of the use of the multiple dispatch mechanism to implement a\nnew numerical type. The resulting implementation of dual numbers can be\nconsidered as a prototype for a complete software module for supporting\ngeneralized complex numbers.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.09737v1"
    },
    {
        "title": "An Adaptive Solver for Systems of Linear Equations",
        "authors": [
            "Conrad Sanderson",
            "Ryan Curtin"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Computational implementations for solving systems of linear equations often\nrely on a one-size-fits-all approach based on LU decomposition of dense\nmatrices stored in column-major format. Such solvers are typically implemented\nwith the aid of the xGESV set of functions available in the low-level LAPACK\nsoftware, with the aim of reducing development time by taking advantage of\nwell-tested routines. However, this straightforward approach does not take into\naccount various matrix properties which can be exploited to reduce the\ncomputational effort and/or to increase numerical stability. Furthermore,\ndirect use of LAPACK functions can be error-prone for non-expert users and\nresults in source code that has little resemblance to originating mathematical\nexpressions. We describe an adaptive solver that we have implemented inside\nrecent versions of the high-level Armadillo C++ library for linear algebra. The\nsolver automatically detects several common properties of a given system\n(banded, triangular, symmetric positive definite), followed by solving the\nsystem via mapping to a set of suitable LAPACK functions best matched to each\nproperty. The solver also detects poorly conditioned systems and automatically\nseeks a solution via singular value decomposition as a fallback. We show that\nthe adaptive solver leads to notable speedups, while also freeing the user from\nusing direct calls to cumbersome LAPACK functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11208v2"
    },
    {
        "title": "VECMAtk: A Scalable Verification, Validation and Uncertainty\n  Quantification Toolkit for Scientific Simulations",
        "authors": [
            "D. Groen",
            "H. Arabnejad",
            "V. Jancauskas",
            "W. N. Edeling",
            "F. Jansson",
            "R. A. Richardson",
            "J. Lakhlili",
            "L. Veen",
            "B. Bosak",
            "P. Kopta",
            "D. W. Wright",
            "N. Monnier",
            "P. Karlshoefer",
            "D. Suleimenova",
            "R. Sinclair",
            "M. Vassaux",
            "A. Nikishova",
            "M. Bieniek",
            "O. O. Luk",
            "M. Kulczewski",
            "E. Raffin",
            "D. Crommelin",
            "O. Hoenen",
            "D. P. Coster",
            "T. Piontek",
            "P. V. Coveney"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We present the VECMA toolkit (VECMAtk), a flexible software environment for\nsingle and multiscale simulations that introduces directly applicable and\nreusable procedures for verification, validation (V&V), sensitivity analysis\n(SA) and uncertainty quantification (UQ). It enables users to verify key\naspects of their applications, systematically compare and validate the\nsimulation outputs against observational or benchmark data, and run simulations\nconveniently on any platform from the desktop to current multi-petascale\ncomputers. In this sequel to our paper on VECMAtk which we presented last year,\nwe focus on a range of functional and performance improvements that we have\nintroduced, cover newly introduced components, and applications examples from\nseven different domains such as conflict modelling and environmental sciences.\nWe also present several implemented patterns for UQ/SA and V&V, and guide the\nreader through one example concerning COVID-19 modelling in detail.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.03923v2"
    },
    {
        "title": "Enabling New Flexibility in the SUNDIALS Suite of Nonlinear and\n  Differential/Algebraic Equation Solvers",
        "authors": [
            "David J. Gardner",
            "Daniel R. Reynolds",
            "Carol S. Woodward",
            "Cody J. Balos"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In recent years, the SUite of Nonlinear and DIfferential/ALgebraic equation\nSolvers (SUNDIALS) has been redesigned to better enable the use of\napplication-specific and third-party algebraic solvers and data structures.\nThroughout this work, we have adhered to specific guiding principles that\nminimized the impact to current users while providing maximum flexibility for\nlater evolution of solvers and data structures. The redesign was done through\nthe addition of new linear and nonlinear solvers classes, enhancements to the\nvector class, and the creation of modern Fortran interfaces. The vast majority\nof this work has been performed \"behind-the-scenes,\" with minimal changes to\nthe user interface and no reduction in solver capabilities or performance.\nThese changes allow SUNDIALS users to more easily utilize external solver\nlibraries and create highly customized solvers, enabling greater flexibility on\nextreme-scale, heterogeneous computational architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10073v2"
    },
    {
        "title": "Scalable Local Timestepping on Octree Grids",
        "authors": [
            "Milinda Fernando",
            "Hari Sundar"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Numerical solutions of hyperbolic partial differential equations(PDEs) are\nubiquitous in science and engineering. Method of lines is a popular approach to\ndiscretize PDEs defined in spacetime, where space and time are discretized\nindependently. When using explicit timesteppers on adaptive grids, the use of a\nglobal timestep-size dictated by the finest grid-spacing leads to\ninefficiencies in the coarser regions. Even though adaptive space\ndiscretizations are widely used in computational sciences, temporal adaptivity\nis less common due to its sophisticated nature. In this paper, we present\nhighly scalable algorithms to enable local timestepping (LTS) for explicit\ntimestepping schemes on fully adaptive octrees. We demonstrate the accuracy of\nour methods as well as the scalability of our framework across 16K cores in\nTACC's Frontera. We also present a speed up estimation model for LTS, which\npredicts the speedup compared to global timestepping (GTS) with an average of\n0.1 relative error.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10570v1"
    },
    {
        "title": "Robust level-3 BLAS Inverse Iteration from the Hessenberg Matrix",
        "authors": [
            "Angelika Schwarz"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Inverse iteration is known to be an effective method for computing\neigenvectors corresponding to simple and well-separated eigenvalues. In the\nnon-symmetric case, the solution of shifted Hessenberg systems is a central\nstep. Existing inverse iteration solvers approach the solution of the shifted\nHessenberg systems with either RQ or LU factorizations and, once factored,\nsolve the corresponding systems. This approach has limited level-3 BLAS\npotential since distinct shifts have distinct factorizations. This paper\nrearranges the RQ approach such that data shared between distinct shifts is\nexposed. Thereby the backward substitution with the triangular R factor can be\nexpressed mostly with matrix-matrix multiplications (level-3 BLAS). The\nresulting algorithm computes eigenvectors in a tiled, overflow-free, and\ntask-parallel fashion. The numerical experiments show that the new algorithm\noutperforms existing inverse iteration solvers for the computation of both real\nand complex eigenvectors.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05063v1"
    },
    {
        "title": "UFL Dual Spaces, a proposal",
        "authors": [
            "David A. Ham"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This white paper highlights current limitations in the algebraic closure\nUnified Form Language (UFL). UFL currently represents forms over finite element\nspaces, however finite element problems naturally result in objects in the dual\nto a finite element space, and operators mapping between primal and dual finite\nelement spaces. This document sketches the relevant mathematical areas and\nproposes changes to the UFL language to support dual spaces as first class\ntypes in UFL.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.05158v1"
    },
    {
        "title": "lrsarith: a small fixed/hybrid arithmetic C library",
        "authors": [
            "David Avis",
            "Charles Jordan"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We describe lrsarith which is a small fixed precision and hybrid arithmetic C\nlibrary for integers and rationals that we developed for use in the lrslib\nlibrary for polyhedral computation. Using a generic set of operations, a\nprogram can be compiled with either 64-bit or 128-bit (if available) fixed\nprecision, with an extended precision library such as GMP or the built-in MP\nroutines. A simple scheme checks for overflow and either terminates the program\nor, in hybrid mode, changes to a higher precision arithmetic. Implementing\nthese arithmetics in lrslib resulted in only minimal changes to the original\ncode. We give computational results using lrs and mplrs, vertex/facet\nenumeration codes in lrslib, using 64 and 128 bit fixed integer arithmetic with\nand without overflow checking, GMP arithmetic, lrsarith hybrid arithmetic with\nboth GMP and MP, and FLINT hybrid arithmetic. We give a small self-contained\nexample C program using the lrsarith package in both fixed precision and hybrid\nmode.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.12425v1"
    },
    {
        "title": "RLIBM-32: High Performance Correctly Rounded Math Libraries for 32-bit\n  Floating Point Representations",
        "authors": [
            "Jay P. Lim",
            "Santosh Nagarakatte"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper proposes a set of techniques to develop correctly rounded math\nlibraries for 32-bit float and posit types. It enhances our RLibm approach that\nframes the problem of generating correctly rounded libraries as a linear\nprogramming problem in the context of 16-bit types to scale to 32-bit types.\nSpecifically, this paper proposes new algorithms to (1) generate polynomials\nthat produce correctly rounded outputs for all inputs using counterexample\nguided polynomial generation, (2) generate efficient piecewise polynomials with\nbit-pattern based domain splitting, and (3) deduce the amount of freedom\navailable to produce correct results when range reduction involves multiple\nelementary functions. The resultant math library for the 32-bit float type is\nfaster than state-of-the-art math libraries while producing the correct output\nfor all inputs. We have also developed a set of correctly rounded elementary\nfunctions for 32-bit posits.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.04043v1"
    },
    {
        "title": "MIPROT: A Medical Image Processing Toolbox for MATLAB",
        "authors": [
            "Alberto Gomez"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper presents a Matlab toolbox to perform basic image processing and\nvisualization tasks, particularly designed for medical image processing. The\nfunctionalities available are similar to basic functions found in other\nnon-Matlab widely used libraries such as the Insight Toolkit (ITK). The toolbox\nis entirely written in native Matlab code, but is fast and flexible.\n  Main use cases for the toolbox are illustrated here, including image\ninput/output, pre-processing, filtering, image registration and visualisation.\nBoth the code and sample data are made publicly available and open source.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.04771v1"
    },
    {
        "title": "Efficient algorithms for computing a rank-revealing UTV factorization on\n  parallel computing architectures",
        "authors": [
            "N. Heavner",
            "F. D. Igual",
            "G. Quintana-Ortí",
            "P. G. Martinsson"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The randomized singular value decomposition (RSVD) is by now a well\nestablished technique for efficiently computing an approximate singular value\ndecomposition of a matrix. Building on the ideas that underpin the RSVD, the\nrecently proposed algorithm \"randUTV\" computes a FULL factorization of a given\nmatrix that provides low-rank approximations with near-optimal error. Because\nthe bulk of randUTV is cast in terms of communication-efficient operations like\nmatrix-matrix multiplication and unpivoted QR factorizations, it is faster than\ncompeting rank-revealing factorization methods like column pivoted QR in most\nhigh performance computational settings. In this article, optimized randUTV\nimplementations are presented for both shared memory and distributed memory\ncomputing environments. For shared memory, randUTV is redesigned in terms of an\n\"algorithm-by-blocks\" that, together with a runtime task scheduler, eliminates\nbottlenecks from data synchronization points to achieve acceleration over the\nstandard \"blocked algorithm\", based on a purely fork-join approach. The\ndistributed memory implementation is based on the ScaLAPACK library. The\nperformances of our new codes compare favorably with competing factorizations\navailable on both shared memory and distributed memory architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.05782v1"
    },
    {
        "title": "A systematic review of Python packages for time series analysis",
        "authors": [
            "Julien Siebert",
            "Janek Groß",
            "Christof Schroth"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper presents a systematic review of Python packages with a focus on\ntime series analysis. The objective is to provide (1) an overview of the\ndifferent time series analysis tasks and preprocessing methods implemented, and\n(2) an overview of the development characteristics of the packages (e.g.,\ndocumentation, dependencies, and community size). This review is based on a\nsearch of literature databases as well as GitHub repositories. Following the\nfiltering process, 40 packages were analyzed. We classified the packages\naccording to the analysis tasks implemented, the methods related to data\npreparation, and the means for evaluating the results produced (methods and\naccess to evaluation data). We also reviewed documentation aspects, the\nlicenses, the size of the packages' community, and the dependencies used. Among\nother things, our results show that forecasting is by far the most frequently\nimplemented task, that half of the packages provide access to real datasets or\nallow generating synthetic data, and that many packages depend on a few\nlibraries (the most used ones being numpy, scipy and pandas). We hope that this\nreview can help practitioners and researchers navigate the space of Python\npackages dedicated to time series analysis. We will provide an updated list of\nthe reviewed packages online at\nhttps://siebert-julien.github.io/time-series-analysis-python/.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.07406v2"
    },
    {
        "title": "Code generation for productive portable scalable finite element\n  simulation in Firedrake",
        "authors": [
            "Jack D. Betteridge",
            "Patrick E. Farrell",
            "David A. Ham"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Creating scalable, high performance PDE-based simulations requires a suitable\ncombination of discretizations, differential operators, preconditioners and\nsolvers. The required combination changes with the application and with the\navailable hardware, yet software development time is a severely limited\nresource for most scientists and engineers. Here we demonstrate that generating\nsimulation code from a high-level Python interface provides an effective\nmechanism for creating high performance simulations from very few lines of user\ncode. We demonstrate that moving from one supercomputer to another can require\nsignificant algorithmic changes to achieve scalable performance, but that the\ncode generation approach enables these algorithmic changes to be achieved with\nminimal development effort.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.08012v1"
    },
    {
        "title": "PyArmadillo: a streamlined linear algebra library for Python",
        "authors": [
            "Jason Rumengan",
            "Terry Yue Zhuo",
            "Conrad Sanderson"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  PyArmadillo is a linear algebra library for the Python language, with the aim\nof closely mirroring the programming interface of the widely used Armadillo C++\nlibrary, which in turn is deliberately similar to Matlab. PyArmadillo hence\nfacilitates algorithm prototyping with Matlab-like syntax directly in Python,\nand relatively straightforward conversion of PyArmadillo-based Python code into\nperformant Armadillo-based C++ code. The converted code can be used for\npurposes such as speeding up Python-based programs in conjunction with\npybind11, or the integration of algorithms originally prototyped in Python into\nlarger C++ codebases. PyArmadillo provides objects for matrices and cubes, as\nwell as over 200 associated functions for manipulating data stored in the\nobjects. Integer, floating point and complex numbers are supported. Various\nmatrix factorisations are provided through integration with LAPACK, or one of\nits high performance drop-in replacements such as Intel MKL or OpenBLAS.\nPyArmadillo is open-source software, distributed under the Apache 2.0 license;\nit can be obtained at https://pyarma.sourceforge.io or via the Python Package\nIndex in precompiled form.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.11120v4"
    },
    {
        "title": "Manifolds.jl: An Extensible Julia Framework for Data Analysis on\n  Manifolds",
        "authors": [
            "Seth D. Axen",
            "Mateusz Baran",
            "Ronny Bergmann",
            "Krzysztof Rzecki"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We present the Julia package Manifolds.jl, providing a fast and easy-to-use\nlibrary of Riemannian manifolds and Lie groups. This package enables working\nwith data defined on a Riemannian manifold, such as the circle, the sphere,\nsymmetric positive definite matrices, or one of the models for hyperbolic\nspaces. We introduce a common interface, available in ManifoldsBase.jl, with\nwhich new manifolds, applications, and algorithms can be implemented. We\ndemonstrate the utility of Manifolds.jl using B\\'ezier splines, an optimization\ntask on manifolds, and principal component analysis on nonlinear data. In a\nbenchmark, Manifolds.jl outperforms all comparable packages for low-dimensional\nmanifolds in speed; over Python and Matlab packages, the improvement is often\nseveral orders of magnitude, while over C/C++ packages, the improvement is\ntwo-fold. For high-dimensional manifolds, it outperforms all packages except\nfor Tensorflow-Riemopt, which is specifically tailored for high-dimensional\nmanifolds.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.08777v3"
    },
    {
        "title": "Efficient recursive least squares solver for rank-deficient matrices",
        "authors": [
            "Ruben Staub",
            "Stephan N. Steinmann"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Updating a linear least squares solution can be critical for near real-time\nsignalprocessing applications. The Greville algorithm proposes a simple formula\nfor updating the pseudoinverse of a matrix A $\\in$ R nxm with rank r. In this\npaper, we explicitly derive a similar formula by maintaining a general rank\nfactorization, which we call rank-Greville. Based on this formula, we\nimplemented a recursive least squares algorithm exploiting the rank-deficiency\nof A, achieving the update of the minimum-norm least-squares solution in O(mr)\noperations and, therefore, solving the linear least-squares problem from\nscratch in O(nmr) operations. We empirically confirmed that this algorithm\ndisplays a better asymptotic time complexity than LAPACK solvers for\nrank-deficient matrices. The numerical stability of rank-Greville was found to\nbe comparable to Cholesky-based solvers. Nonetheless, our implementation\nsupports exact numerical representations of rationals, due to its remarkable\nalgebraic simplicity.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.11594v1"
    },
    {
        "title": "Optimal Checkpointing for Adjoint Multistage Time-Stepping Schemes",
        "authors": [
            "Hong Zhang",
            "Emil Constantinescu"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We consider checkpointing strategies that minimize the number of\nrecomputations needed when performing discrete adjoint computations using\nmultistage time-stepping schemes, which requires computing several substeps\nwithin one complete time step. In this case we propose two algorithms that can\ngenerate optimal checkpointing schedules under weak assumptions. The first is\nan extension of the seminal Revolve algorithm adapted to multistage schemes.\nThe second algorithm, named CAMS, is developed based on dynamic programming,\nand it requires the least number of recomputations when compared with other\nalgorithms. The CAMS algorithm is made publicly available in a library with\nbindings to C and Python. Numerical results illustrate that the proposed\nalgorithms can deliver up to two times the speedup compared with that of\nclassical Revolve. Moreover, we discuss a tailored implementation of an adjoint\ncomputation that is arguably better suited for mature scientific computing\nlibraries by avoiding the central control assumed by the original checkpointing\nstrategy. The proposed algorithms have been adopted by the PETSc TSAdjoint\nlibrary. Their performance has been demonstrated with a large-scale\nPDE-constrained optimization problem on a leadership-class supercomputer.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.13879v2"
    },
    {
        "title": "Neko: A Modern, Portable, and Scalable Framework for High-Fidelity\n  Computational Fluid Dynamics",
        "authors": [
            "Niclas Jansson",
            "Martin Karp",
            "Artur Podobas",
            "Stefano Markidis",
            "Philipp Schlatter"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Recent trends and advancement in including more diverse and heterogeneous\nhardware in High-Performance Computing is challenging software developers in\ntheir pursuit for good performance and numerical stability. The well-known\nmaxim \"software outlives hardware\" may no longer necessarily hold true, and\ndevelopers are today forced to re-factor their codebases to leverage these\npowerful new systems. CFD is one of the many application domains affected. In\nthis paper, we present Neko, a portable framework for high-order spectral\nelement flow simulations. Unlike prior works, Neko adopts a modern\nobject-oriented approach, allowing multi-tier abstractions of the solver stack\nand facilitating hardware backends ranging from general-purpose processors down\nto exotic vector processors and FPGAs. We show that Neko's performance and\naccuracy are comparable to NekRS, and thus on-par with Nek5000's successor on\nmodern CPU machines. Furthermore, we develop a performance model, which we use\nto discuss challenges and opportunities for high-order solvers on emerging\nhardware.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.01243v1"
    },
    {
        "title": "ATC: an Advanced Tucker Compression library for multidimensional data",
        "authors": [
            "Wouter Baert",
            "Nick Vannieuwenhoven"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We present ATC, a C++ library for advanced Tucker-based lossy compression of\ndense multidimensional numerical data in a shared-memory parallel setting,\nbased on the sequentially truncated higher-order singular value decomposition\n(ST-HOSVD) and bit plane truncation. Several techniques are proposed to improve\nspeed, memory usage, error control and compression rate. First, a hybrid\ntruncation scheme is described which combines Tucker rank truncation and\nTTHRESH quantization [Ballester-Ripoll et al., IEEE Trans. Visual. Comput.\nGraph., 2020]. We derive a novel expression to approximate the error of\ntruncated Tucker decompositions in the case of core and factor perturbations.\nFurthermore, we parallelize the quantization and encoding scheme and adjust\nthis phase to improve error control. Moreover, implementation aspects are\ndescribed, such as an ST-HOSVD procedure using only a single transposition. We\nalso discuss several usability features of ATC, including the presence of\nmultiple interfaces, extensive data type support and integrated downsampling of\nthe decompressed data. Numerical results show that ATC maintains\nstate-of-the-art Tucker compression rates, while providing average speed-up\nfactors of 2.2-3.5 and halving memory usage. Furthermore, our compressor\nprovides precise error control, only deviating 1.4% from the requested error on\naverage. Finally, ATC often achieves higher compression than non-Tucker-based\ncompressors in the high-error domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.01384v4"
    },
    {
        "title": "Comparing OpenMP Implementations With Applications Across A64FX\n  Platforms",
        "authors": [
            "Benjamin Michalowicz",
            "Eric Raut",
            "Yan Kang",
            "Tony Curtis",
            "Barbara Chapman",
            "Dossay Oryspayev"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The development of the A64FX processor by Fujitsu has created a massive\ninnovation in High-Performance Computing and the birth of Fugaku: the current\nworld's fastest supercomputer. A variety of tools are used to analyze the\nrun-times and performances of several applications, and in particular, how\nthese applications scale on the A64FX processor. We examine the performance and\nbehavior of applications through OpenMP scaling and how their performance\ndiffers across different compilers on the new Ookami cluster at Stony Brook\nUniversity as well as the Fugaku supercomputer at RIKEN in Japan.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.10346v1"
    },
    {
        "title": "Partial Reuse AMG Setup Cost Amortization Strategy for the Solution of\n  Non-Steady State Problems",
        "authors": [
            "D. E. Demidov"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The partial reuse algebraic multigrid (AMG) setup cost amortization strategy\nis presented for the solution of non-steady state problems. The transfer\noperators are reused from the previous time steps, and the system matrices and\nthe smoother operators are rebuilt on each of the AMG hierarchy levels. It is\nshown on the example of modelling a two-fluid dam break scenario that the\nstrategy may decrease the AMG preconditioner setup cost by 40% to 200%. The\ntotal compute time is decreased by up to 20%, but the specific outcome depends\non the fraction of time that the setup step initially takes.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.02054v1"
    },
    {
        "title": "Grassland: A Rapid Algebraic Modeling System for Million-variable\n  Optimization",
        "authors": [
            "Xihan Li",
            "Xiongwei Han",
            "Zhishuo Zhou",
            "Mingxuan Yuan",
            "Jia Zeng",
            "Jun Wang"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  An algebraic modeling system (AMS) is a type of mathematical software for\noptimization problems, which allows users to define symbolic mathematical\nmodels in a specific language, instantiate them with given source of data, and\nsolve them with the aid of external solver engines. With the bursting scale of\nbusiness models and increasing need for timeliness, traditional AMSs are not\nsufficient to meet the following industry needs: 1) million-variable models\nneed to be instantiated from raw data very efficiently; 2) Strictly feasible\nsolution of million-variable models need to be delivered in a rapid manner to\nmake up-to-date decisions against highly dynamic environments. Grassland is a\nrapid AMS that provides an end-to-end solution to tackle these emerged new\nchallenges. It integrates a parallelized instantiation scheme for large-scale\nlinear constraints, and a sequential decomposition method that accelerates\nmodel solving exponentially with an acceptable loss of optimality. Extensive\nbenchmarks on both classical models and real enterprise scenario demonstrate 6\n~ 10x speedup of Grassland over state-of-the-art solutions on model\ninstantiation. Our proposed system has been deployed in the large-scale real\nproduction planning scenario of Huawei. With the aid of our decomposition\nmethod, Grassland successfully accelerated Huawei's million-variable production\nplanning simulation pipeline from hours to 3 ~ 5 minutes, supporting\nnear-real-time production plan decision making against highly dynamic\nsupply-demand environment.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.04586v1"
    },
    {
        "title": "RLIBM-ALL: A Novel Polynomial Approximation Method to Produce Correctly\n  Rounded Results for Multiple Representations and Rounding Modes",
        "authors": [
            "Jay P. Lim",
            "Santosh Nagarakatte"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Mainstream math libraries for floating point (FP) do not produce correctly\nrounded results for all inputs. In contrast, CR-LIBM and RLIBM provide\ncorrectly rounded implementations for a specific FP representation with one\nrounding mode. Using such libraries for a representation with a new rounding\nmode or with different precision will result in wrong results due to double\nrounding. This paper proposes a novel method to generate a single polynomial\napproximation that produces correctly rounded results for all inputs for\nmultiple rounding modes and multiple precision configurations. To generate a\ncorrectly rounded library for $n$-bits, our key idea is to generate such a\npolynomial approximation for a representation with $n+2$-bits using the\n\\emph{round-to-odd} mode. We prove that the resulting polynomial approximation\nwill produce correctly rounded results for all five rounding modes in the\nstandard and for multiple representations with $k$-bits such that $|E| +1 < k\n\\leq n$, where $|E|$ is the number of exponent bits in the representation.\nBuilding on our prior work in the RLIBM project, we also approximate the\ncorrectly rounded result when we generate the library with $n+2$-bits using the\nround-to-odd mode. We also generate polynomial approximations by structuring it\nas a linear programming problem but propose enhancements to polynomial\ngeneration to handle the round-to-odd mode. Our prototype is the first 32-bit\nfloat library that produces correctly rounded results with all rounding modes\nin the IEEE standard for all inputs with a single polynomial approximation. It\nalso produces correctly rounded results for any FP configuration ranging from\n10-bits to 32-bits while also being faster than mainstream libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.06756v2"
    },
    {
        "title": "Fast MATLAB evaluation of nonlinear energies using FEM in 2D and 3D:\n  nodal elements",
        "authors": [
            "Alexej Moskovka",
            "Jan Valdman"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Nonlinear energy functionals appearing in the calculus of variations can be\ndiscretized by the finite element (FE) method and formulated as a sum of energy\ncontributions from local elements. A fast evaluation of energy functionals\ncontaining the first order gradient terms is a central part of this\ncontribution. We describe a vectorized implementation using the simplest linear\nnodal (P1) elements in which all energy contributions are evaluated all at once\nwithout the loop over triangular or tetrahedral elements. Furthermore, in\nconnection to the first-order optimization methods, the discrete gradient of\nenergy functional is assembled in a way that the gradient components are\nevaluated over all degrees of freedom all at once. The key ingredient is the\nvectorization of exact or approximate energy gradients over nodal patches. It\nleads to a time-efficient implementation at higher memory-cost. Provided codes\nin MATLAB related to 2D/3D hyperelasticity and 2D p-Laplacian problem are\navailable for download and structured in a way it can be easily extended to\nother types of vector or scalar forms of energies.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.01158v2"
    },
    {
        "title": "The software design of Gridap: a Finite Element package based on the\n  Julia JIT compiler",
        "authors": [
            "Francesc Verdugo",
            "Santiago Badia"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We present the software design of Gridap, a novel finite element library\nwritten exclusively in the Julia programming language, which is being used by\nseveral research groups world-wide to simulate complex physical phenomena such\nas magnetohydrodynamics, photonics, weather modeling, non-linear solid\nmechanics, and fluid-structure interaction problems. The library provides a\nfeature-rich set of discretization techniques for the numerical approximation\nof a wide range of PDEs, including linear, nonlinear, single-field, and\nmulti-field equations. An expressive API allows users to define PDEs in weak\nform by a syntax close to the mathematical notation. While this is also\navailable in previous codes, the main novelty of Gridap is that it implements\nthis API without introducing a DSL plus a compiler of variational forms.\nInstead, it leverages the Julia just-in-time compiler to build efficient code,\nspecialized for the concrete problem at hand. As a result, there is no need to\nuse different languages for the computational back-end and the user front-end\nanymore, thus eliminating the so-called two-language problem. Gridap also\nprovides a low-level API that is modular and extensible via the\nmultiple-dispatch paradigm of Julia and provides easy access to the main\nbuilding blocks of the library. The main contribution of this paper is the\ndetailed presentation of the novel software abstractions behind the Gridap\ndesign that leverages the new software possibilities provided by the Julia\nlanguage. The second main contribution of the article is a performance\ncomparison against FEniCS. We measure CPU times needed to assemble discrete\nsystems of linear equations for different problem types and show that the\nperformance of Gridap is comparable to FEniCS, demonstrating that the new\nsoftware design does not compromise performance. Gridap is freely available at\nGithub and distributed under an MIT license.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.12818v1"
    },
    {
        "title": "MPLAPACK version 2.0.1 user manual",
        "authors": [
            "Maho Nakata"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The MPLAPACK (formerly MPACK) is a multiple-precision version of LAPACK\n(https://www.netlib.org/lapack/). MPLAPACK version 2.0.1 is based on LAPACK\nversion 3.9.1 and translated from Fortran 90 to C++ using FABLE, a Fortran to\nC++ source-to-source conversion tool\n(https://github.com/cctbx/cctbx_project/tree/master/fable/). MPLAPACK version\n2.0.1 provides the real and complex version of MPBLAS, and the real and complex\nversions of MPLAPACK support all LAPACK features: solvers for systems of\nsimultaneous linear equations, least-squares solutions of linear systems of\nequations, eigenvalue problems, and singular value problems, and related matrix\nfactorizations except for mixed-precision routines. The MPLAPACK defines an API\nfor numerical linear algebra, similar to LAPACK. It is easy to port legacy\nC/C++ numerical codes using MPLAPACK. MPLAPACK supports binary64, binary128,\nFP80 (extended double), MPFR, GMP, and QD libraries (double-double and\nquad-double). Users can choose MPFR or GMP for arbitrary accurate calculations,\ndouble-double or quad-double for fast 32 or 64-decimal calculations. We can\nconsider the binary64 version as the C++ version of LAPACK. Moreover, it comes\nwith an OpenMP accelerated version of MPBLAS for some routines and CUDA (A100\nand V100 support) for double-double versions of Rgemm and Rsyrk. The peak\nperformances of the OpenMP version are almost proportional to the number of\ncores, and the performances of the CUDA version are impressive, and\napproximately 400-600 GFlops. MPLAPACK is available at GitHub\n(https://github.com/nakatamaho/mplapack/) under the 2-clause BSD license.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.13406v2"
    },
    {
        "title": "preCICE v2: A Sustainable and User-Friendly Coupling Library",
        "authors": [
            "Gerasimos Chourdakis",
            "Kyle Davis",
            "Benjamin Rodenberg",
            "Miriam Schulte",
            "Frédéric Simonis",
            "Benjamin Uekermann",
            "Georg Abrams",
            "Hans-Joachim Bungartz",
            "Lucia Cheung Yau",
            "Ishaan Desai",
            "Konrad Eder",
            "Richard Hertrich",
            "Florian Lindner",
            "Alexander Rusch",
            "Dmytro Sashko",
            "David Schneider",
            "Amin Totounferoush",
            "Dominik Volland",
            "Peter Vollmer",
            "Oguz Ziya Koseomur"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  preCICE is a free/open-source coupling library. It enables creating\npartitioned multi-physics simulations by gluing together separate software\npackages. This paper summarizes the development efforts in preCICE of the past\nfive years. During this time span, we have turned the software from a working\nprototype -- sophisticated numerical coupling methods and scalability on ten\nthousands of compute cores -- to a sustainable and user-friendly software\nproject with a steadily-growing community. Today, we know through forum\ndiscussions, conferences, workshops, and publications of more than 100 research\ngroups using preCICE. We cover the fundamentals of the software alongside a\nperformance and accuracy analysis of different data mapping methods.\nAfterwards, we describe ready-to-use integration with widely-used external\nsimulation software packages, tests and continuous integration from unit to\nsystem level, and community building measures, drawing an overview of the\ncurrent preCICE ecosystem.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.14470v2"
    },
    {
        "title": "RLIBM-PROG: Progressive Polynomial Approximations for Fast Correctly\n  Rounded Math Libraries",
        "authors": [
            "Mridul Aanjaneya",
            "Jay P. Lim",
            "Santosh Nagarakatte"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper presents a novel method for generating a single polynomial\napproximation that produces correctly rounded results for all inputs of an\nelementary function for multiple representations. The generated polynomial\napproximation has the nice property that the first few lower degree terms\nproduce correctly rounded results for specific representations of smaller\nbitwidths, which we call progressive performance. To generate such progressive\npolynomial approximations, we approximate the correctly rounded result and\nformulate the computation of correctly rounded polynomial approximations as a\nlinear program similar to our prior work on the RLibm project. To enable the\nuse of resulting polynomial approximations in mainstream libraries, we want to\navoid piecewise polynomials with large lookup tables. We observe that the\nproblem of computing polynomial approximations for elementary functions is a\nlinear programming problem in low dimensions, i.e., with a small number of\nunknowns. We design a fast randomized algorithm for computing polynomial\napproximations with progressive performance. Our method produces correct and\nfast polynomials that require a small amount of storage. A few polynomial\napproximations from our prototype have already been incorporated into LLVM's\nmath library.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.12852v2"
    },
    {
        "title": "Differentiable Scripting",
        "authors": [
            "Uwe Naumann"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  In Computational Science, Engineering and Finance (CSEF) scripts typically\nserve as the \"glue\" between potentially highly complex and computationally\nexpensive external subprograms. Differentiability of the resulting programs\nturns out to be essential in the context of derivative-based methods for error\nanalysis, uncertainty quantification, optimization or training of surrogates.\nWe argue that it should be enforced by the scripting language itself through\nexclusive support of differentiable (smoothed) external subprograms and\ndifferentiable intrinsics combined with prohibition of nondifferentiable\nbranches in the data flow. Illustration is provided by a prototype adjoint code\ncompiler for a simple Python-like scripting language.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.03036v1"
    },
    {
        "title": "Matrix-free approaches for GPU acceleration of a high-order finite\n  element hydrodynamics application using MFEM, Umpire, and RAJA",
        "authors": [
            "Arturo Vargas",
            "Thomas M. Stitt",
            "Kenneth Weiss",
            "Vladimir Z. Tomov",
            "Jean-Sylvain Camier",
            "Tzanio Kolev",
            "Robert N. Rieben"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  With the introduction of advanced heterogeneous computing architectures based\non GPU accelerators, large-scale production codes have had to rethink their\nnumerical algorithms and incorporate new programming models and memory\nmanagement strategies in order to run efficiently on the latest supercomputers.\nIn this work we discuss our co-design strategy to address these challenges and\nachieve performance and portability with MARBL, a next-generation multi-physics\ncode in development at Lawrence Livermore National Laboratory. We present a\ntwo-fold approach, wherein new hardware is used to motivate both new algorithms\nand new abstraction layers, resulting in a single source application code\nsuitable for a variety of platforms. Focusing on MARBL's ALE hydrodynamics\npackage, we demonstrate scalability on different platforms and highlight that\nmany of our innovations have been contributed back to open-source software\nlibraries, such as MFEM (finite element algorithms) and RAJA (kernel\nabstractions).\n",
        "pdf_link": "http://arxiv.org/pdf/2112.07075v1"
    },
    {
        "title": "MUPen2DTool: a Matlab Tool for 2D Nuclear Magnetic Resonance relaxation\n  data inversion",
        "authors": [
            "Villiam Bortolotti",
            "Leonardo Brizi",
            "Germana Landi",
            "Anastasiia Nagmutdinova",
            "Fabiana Zama"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Accurate and efficient analysis of materials properties from Nuclear Magnetic\nResonance (NMR) relaxation data requires robust and efficient inversion\nprocedures. Despite the great variety of applications requiring to process\ntwo-dimensional NMR data (2DNMR), a few software tools are freely available.\nThe aim of this paper is to present MUPen2DTool, an open-source MATLAB based\nsoftware tool for 2DNMR data inversion. The user can choose among several types\nof NMR experiments, and the software provides codes that can be used and\nextended easily. Furthermore, a MATLAB interface makes it easier to include\nusers own data. The practical use is demonstrated in the reported examples of\nboth synthetic and real NMR data.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06504v1"
    },
    {
        "title": "Solidfmm: A highly optimised library of operations on the solid\n  harmonics for use in fast multipole methods",
        "authors": [
            "Matthias Kirchhart"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  We present solidfmm, a highly optimised C++ library for the solid harmonics\nas they are needed in fast multipole methods. The library provides efficient,\nvectorised implementations of the translation operations M2M, M2L, and L2L, and\nis available as free software. While asymptotically of complexity $O(P^3)$, for\nall practically relevant expansion orders, the translation operators display an\nempirical complexity of $O(P^2)$, outperforming the na\\\"ive implementation by\norders of magnitude.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.02847v1"
    },
    {
        "title": "GPU Accelerated Automatic Differentiation With Clad",
        "authors": [
            "Ioana Ifrim",
            "Vassil Vassilev",
            "David J Lange"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Automatic Differentiation (AD) is instrumental for science and industry. It\nis a tool to evaluate the derivative of a function specified through a computer\nprogram. The range of AD application domain spans from Machine Learning to\nRobotics to High Energy Physics. Computing gradients with the help of AD is\nguaranteed to be more precise than the numerical alternative and have a low,\nconstant factor more arithmetical operations compared to the original function.\nMoreover, AD applications to domain problems typically are computationally\nbound. They are often limited by the computational requirements of\nhigh-dimensional parameters and thus can benefit from parallel implementations\non graphics processing units (GPUs). Clad aims to enable differential analysis\nfor C/C++ and CUDA and is a compiler-assisted AD tool available both as a\ncompiler extension and in ROOT. Moreover, Clad works as a plugin extending the\nClang compiler; as a plugin extending the interactive interpreter Cling; and as\na Jupyter kernel extension based on xeus-cling. We demonstrate the advantages\nof parallel gradient computations on GPUs with Clad. We explain how to bring\nforth a new layer of optimization and a proportional speed up by extending Clad\nto support CUDA. The gradients of well-behaved C++ functions can be\nautomatically executed on a GPU. The library can be easily integrated into\nexisting frameworks or used interactively. Furthermore, we demonstrate the\nachieved application performance improvements, including (~10x) in ROOT\nhistogram fitting and corresponding performance gains from offloading to GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.06139v2"
    },
    {
        "title": "Massively scalable stencil algorithm",
        "authors": [
            "Mathias Jacquelin",
            "Mauricio Araya-Polo",
            "Jie Meng"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Stencil computations lie at the heart of many scientific and industrial\napplications. Unfortunately, stencil algorithms perform poorly on machines with\ncache based memory hierarchy, due to low re-use of memory accesses. This work\nshows that for stencil computation a novel algorithm that leverages a localized\ncommunication strategy effectively exploits the Cerebras WSE-2, which has no\ncache hierarchy. This study focuses on a 25-point stencil finite-difference\nmethod for the 3D wave equation, a kernel frequently used in earth modeling as\nnumerical simulation. In essence, the algorithm trades memory accesses for data\ncommunication and takes advantage of the fast communication fabric provided by\nthe architecture. The algorithm -- historically memory bound -- becomes compute\nbound. This allows the implementation to achieve near perfect weak scaling,\nreaching up to 503 TFLOPs on WSE-2, a figure that only full clusters can\neventually yield.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.03775v1"
    },
    {
        "title": "MATLAB implementation of hp finite elements on rectangles",
        "authors": [
            "Alexej Moskovka",
            "Jan Valdman"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  A simple MATLAB implementation of hierarchical shape functions on 2D\nrectangles is explained and available for download. Global shape functions are\nordered for a given polynomial degree according to the indices of the nodes,\nedges, or elements to which they belong. For a uniform p-refinement, the\nhierarchical structure enables an effective assembly of mass and stiffness\nmatrices. A solution of a boundary value problem is approximated for various\nlevels of uniform h and p refinements.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.07637v1"
    },
    {
        "title": "Reduction of the Random Access Memory Size in Adjoint Algorithmic\n  Differentiation by Overloading",
        "authors": [
            "Uwe Naumann"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Adjoint algorithmic differentiation by operator and function overloading is\nbased on the interpretation of directed acyclic graphs resulting from\nevaluations of numerical simulation programs. The size of the computer system\nmemory required to store the graph grows proportional to the number of\nfloating-point operations executed by the underlying program. It quickly\nexceeds the available memory resources. Naive adjoint algorithmic\ndifferentiation often becomes infeasible except for relatively simple numerical\nsimulations.\n  Access to the data associated with the graph can be classified as sequential\nand random. The latter refers to memory access patterns defined by the\nadjacency relationship between vertices within the graph. Sequentially accessed\ndata can be decomposed into blocks. The blocks can be streamed across the\nsystem memory hierarchy thus extending the amount of available memory, for\nexample, to hard discs. Asynchronous i/o can help to mitigate the increased\ncost due to accesses to slower memory. Much larger problem instances can thus\nbe solved without resorting to technically challenging user intervention such\nas checkpointing. Randomly accessed data should not have to be decomposed. Its\nblock-wise streaming is likely to yield a substantial overhead in computational\ncost due to data accesses across blocks. Consequently, the size of the randomly\naccessed memory required by an adjoint should be kept minimal in order to\neliminate the need for decomposition. We propose a combination of dedicated\nmemory for adjoint $L$-values with the exploitation of remainder bandwidth as a\npossible solution. Test results indicate significant savings in random access\nmemory size while preserving overall computational efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.07018v1"
    },
    {
        "title": "Proposed Consistent Exception Handling for the BLAS and LAPACK",
        "authors": [
            "James Demmel",
            "Jack Dongarra",
            "Mark Gates",
            "Greg Henry",
            "Julien Langou",
            "Xiaoye Li",
            "Piotr Luszczek",
            "Weslley Pereira",
            "Jason Riedy",
            "Cindy Rubio-González"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Numerical exceptions, which may be caused by overflow, operations like\ndivision by 0 or sqrt(-1), or convergence failures, are unavoidable in many\ncases, in particular when software is used on unforeseen and difficult inputs.\nAs more aspects of society become automated, e.g., self-driving cars, health\nmonitors, and cyber-physical systems more generally, it is becoming\nincreasingly important to design software that is resilient to exceptions, and\nthat responds to them in a consistent way. Consistency is needed to allow users\nto build higher-level software that is also resilient and consistent (and so on\nrecursively). In this paper we explore the design space of consistent exception\nhandling for the widely used BLAS and LAPACK linear algebra libraries, pointing\nout a variety of instances of inconsistent exception handling in the current\nversions, and propose a new design that balances consistency, complexity, ease\nof use, and performance. Some compromises are needed, because there are\npreexisting inconsistencies that are outside our control, including in or\nbetween existing vendor BLAS implementations, different programming languages,\nand even compilers for the same programming language. And user requests from\nour surveys are quite diverse. We also propose our design as a possible model\nfor other numerical software, and welcome comments on our design choices.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.09281v1"
    },
    {
        "title": "Survey of Methods for Solving Systems of Nonlinear Equations, Part I:\n  Root-finding Approaches",
        "authors": [
            "Ilias S. Kotsireas",
            "Panos M. Pardalos",
            "Alexander Semenov",
            "William T. Trevena",
            "Michael N. Vrahatis"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  This paper presents a comprehensive survey of methods which can be utilized\nto search for solutions to systems of nonlinear equations (SNEs). Our\nobjectives with this survey are to synthesize pertinent literature in this\nfield by presenting a thorough description and analysis of the known methods\ncapable of finding one or many solutions to SNEs, and to assist interested\nreaders seeking to identify solution techniques which are well suited for\nsolving the various classes of SNEs which one may encounter in real world\napplications.\n  To accomplish these objectives, we present a multi-part survey. In part one,\nwe focus on root-finding approaches which can be used to search for solutions\nto a SNE without transforming it into an optimization problem. In part two, we\nwill introduce the various transformations which have been utilized to\ntransform a SNE into an optimization problem, and we discuss optimization\nalgorithms which can then be used to search for solutions. In part three, we\nwill present a robust quantitative comparative analysis of methods capable of\nsearching for solutions to SNEs.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.08530v1"
    },
    {
        "title": "Survey of Methods for Solving Systems of Nonlinear Equations, Part II:\n  Optimization Based Approaches",
        "authors": [
            "Ilias S. Kotsireas",
            "Panos M. Pardalos",
            "Alexander Semenov",
            "William T. Trevena",
            "Michael N. Vrahatis"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  This paper presents a comprehensive survey of methods which can be utilized\nto search for solutions to systems of nonlinear equations (SNEs). Our\nobjectives with this survey are to synthesize pertinent literature in this\nfield by presenting a thorough description and analysis of the known methods\ncapable of finding one or many solutions to SNEs, and to assist interested\nreaders seeking to identify solution techniques which are well suited for\nsolving the various classes of SNEs which one may encounter in real world\napplications.\n  To accomplish these objectives, we present a multi-part survey. In part one,\nwe focused on root-finding approaches which can be used to search for solutions\nto a SNE without transforming it into an optimization problem. In part two, we\nintroduce the various transformations which have been utilized to transform a\nSNE into an optimization problem, and we discuss optimization algorithms which\ncan then be used to search for solutions. We emphasize the important\ncharacteristics of each method, and we discuss promising directions for future\nresearch. In part three, we will present a robust quantitative comparative\nanalysis of methods capable of searching for solutions to SNEs.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.08532v1"
    },
    {
        "title": "Forward-Mode Automatic Differentiation of Compiled Programs",
        "authors": [
            "Max Aehle",
            "Johannes Blühdorn",
            "Max Sagebaum",
            "Nicolas R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Algorithmic differentiation (AD) is a set of techniques that provide partial\nderivatives of computer-implemented functions. Such a function can be supplied\nto state-of-the-art AD tools via its source code, or via an intermediate\nrepresentation produced while compiling its source code.\n  We present the novel AD tool Derivgrind, which augments the machine code of\ncompiled programs with forward-mode AD logic. Derivgrind leverages the Valgrind\ninstrumentation framework for a structured access to the machine code, and a\nshadow memory tool to store dot values. Access to the source code is required\nat most for the files in which input and output variables are defined.\n  Derivgrind's versatility comes at the price of scaling the run-time by a\nfactor between 30 and 75, measured on a benchmark based on a numerical solver\nfor a partial differential equation. Results of our extensive regression test\nsuite indicate that Derivgrind produces correct results on GCC- and\nClang-compiled programs, including a Python interpreter, with a small number of\nexceptions. While we provide a list of scenarios that Derivgrind does not\nhandle correctly, nearly all of them are academic counterexamples or originate\nfrom highly optimized math libraries. As long as differentiating those is\navoided, Derivgrind can be applied to an unprecedentedly wide range of\ncross-language or partially closed-source software with little integration\nefforts.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01895v2"
    },
    {
        "title": "Parallelism detection using graph labelling",
        "authors": [
            "Pavel Telegin",
            "Anton Baranov",
            "Boris Shabanov",
            "Artem Tikhomirov"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Usage of multiprocessor and multicore computers implies parallel programming.\nTools for preparing parallel programs include parallel languages and libraries\nas well as parallelizing compilers and convertors that can perform automatic\nparallelization. The basic approach for parallelism detection is analysis of\ndata dependencies and properties of program components, including data use and\npredicates. In this article a suite of used data and predicates sets for\nprogram components is proposed and an algorithm for computing these sets is\nsuggested. The algorithm is based on wave propagation on graphs with cycles and\nlabelling. This method allows analyzing complex program components, improving\ndata localization and thus providing enhanced data parallelism detection.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.04818v1"
    },
    {
        "title": "Reverse-Mode Automatic Differentiation of Compiled Programs",
        "authors": [
            "Max Aehle",
            "Johannes Blühdorn",
            "Max Sagebaum",
            "Nicolas R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Tools for algorithmic differentiation (AD) provide accurate derivatives of\ncomputer-implemented functions for use in, e. g., optimization and machine\nlearning (ML). However, they often require the source code of the function to\nbe available in a restricted set of programming languages. As a step towards\nmaking AD accessible for code bases with cross-language or closed-source\ncomponents, we recently presented the forward-mode AD tool Derivgrind. It\ninserts forward-mode AD logic into the machine code of a compiled program using\nthe Valgrind dynamic binary instrumentation framework. This work extends\nDerivgrind, adding the capability to record the real-arithmetic evaluation\ntree, and thus enabling operator overloading style reverse-mode AD for compiled\nprograms. We maintain the high level of correctness reported for Derivgrind's\nforward mode, failing the same few testcases in an extensive test suite for the\nsame well-understood reasons. Runtime-wise, the recording slows down the\nexecution of a compiled 64-bit benchmark program by a factor of about 180.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.13760v1"
    },
    {
        "title": "mlpack 4: a fast, header-only C++ machine learning library",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel",
            "Omar Shrit",
            "Shubham Agrawal",
            "Suryoday Basak",
            "James J. Balamuta",
            "Ryan Birmingham",
            "Kartik Dutt",
            "Dirk Eddelbuettel",
            "Rishabh Garg",
            "Shikhar Jaiswal",
            "Aakash Kaushik",
            "Sangyeon Kim",
            "Anjishnu Mukherjee",
            "Nanubala Gnana Sai",
            "Nippun Sharma",
            "Yashwant Singh Parihar",
            "Roshan Swain",
            "Conrad Sanderson"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  For over 15 years, the mlpack machine learning library has served as a \"swiss\narmy knife\" for C++-based machine learning. Its efficient implementations of\ncommon and cutting-edge machine learning algorithms have been used in a wide\nvariety of scientific and industrial applications. This paper overviews mlpack\n4, a significant upgrade over its predecessor. The library has been\nsignificantly refactored and redesigned to facilitate an easier\nprototyping-to-deployment pipeline, including bindings to other languages\n(Python, Julia, R, Go, and the command line) that allow prototyping to be\nseamlessly performed in environments other than C++. mlpack is open-source\nsoftware, distributed under the permissive 3-clause BSD license; it can be\nobtained at https://mlpack.org\n",
        "pdf_link": "http://arxiv.org/pdf/2302.00820v1"
    },
    {
        "title": "A note on the standard diffusion curve of TAP analysis",
        "authors": [
            "Toby Isaac"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The standard diffusion curve used in models of TAP reactors, as it is usually\ndefined, is numerically unstable for small values. We use a functional equation\nsatisfied by the curve to define a numerically stable way of computing it for\nall values.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03772v1"
    },
    {
        "title": "GEMMFIP: Unifying GEMM in BLIS",
        "authors": [
            "RuQing G. Xu",
            "Field G. Van Zee",
            "Robert A. van de Geijn"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Matrix libraries often focus on achieving high performance for problems\nconsidered to be either \"small\" or \"large\", as these two scenarios tend to\nrespond best to different optimization strategies. We propose a unified\ntechnique for implementing matrix operations like general matrix multiplication\n(GEMM) that can achieve high performance for both small and large problem\nsizes. The key is to fuse packing -- an operation that copies data to a\ncontiguous layout in memory and which is critical for large matrix performance\n-- with the first computational \"pass\" over that data. This boosts performance\nacross the problem size spectrum. As a result, tuning general-purpose libraries\nbecomes simpler since it obviates the need to carefully express and\nparameterize logic that chooses between a \"small matrix\" strategy and a \"large\nmatrix\" strategy. A prototype implementation of the technique built with the\nBLAS-like Library Instantiation Software (BLIS) framework is described and\nperformance on a range of architectures is reported.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.08417v2"
    },
    {
        "title": "GPU Offloading in ExaHyPE Through C++ Standard Algorithms",
        "authors": [
            "Uzmar Gomez",
            "Gonzalo Brito Gadeschi",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The ISO C++17 standard introduces \\emph{parallel algorithms}, a parallel\nprogramming model promising portability across a wide variety of parallel\nhardware including multi-core CPUs, GPUs, and FPGAs. Since 2019, the NVIDIA HPC\nSDK compiler suite supports this programming model for multi-core CPUs and\nGPUs. ExaHyPE is a solver engine for hyperbolic partial differential equations\nfor complex wave phenomena. It supports multiple numerical methods including\nFinite Volumes and ADER-DG, and employs adaptive mesh refinement with dynamic\nload balancing via space-filling curves as well as task-based parallelism and\noffloading to GPUs. This study ports ExaHyPE's tasks over blocks of Finite\nVolumes to the ISO C++ parallel algorithms programming model, and compares its\nperformance and usability against an OpenMP implementation with offloading via\nOpenMP target directives. It shows that ISO C++ is a feasible programming model\nfor non-trivial applications like our task-based AMR code. The realisation is\nbare of vendor-specific or non-C++ extensions. It however is slower than its\nOpenMP counterpart. \\vspace{-1cm}\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09005v1"
    },
    {
        "title": "PNet: A Python Library for Petri Net Modeling and Simulation",
        "authors": [
            "Zhu En Chay",
            "Bing Feng Goh",
            "Maurice HT Ling"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Petri Net is a formalism to describe changes between 2 or more states across\ndiscrete time and has been used to model many systems. We present PNet - a pure\nPython library for Petri Net modeling and simulation in Python programming\nlanguage. The design of PNet focuses on reducing the learning curve needed to\ndefine a Petri Net by using a text-based language rather than programming\nconstructs to define transition rules. Complex transition rules can be refined\nas regular Python functions. To demonstrate the simplicity of PNet, we present\n2 examples - bread baking, and epidemiological models.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12054v1"
    },
    {
        "title": "Cascading GEMM: High Precision from Low Precision",
        "authors": [
            "Devangi N. Parikh",
            "Robert A. van de Geijn",
            "Greg M. Henry"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  This paper lays out insights and opportunities for implementing\nhigher-precision matrix-matrix multiplication (GEMM) from (in terms of)\nlower-precision high-performance GEMM. The driving case study approximates\ndouble-double precision (FP64x2) GEMM in terms of double precision (FP64) GEMM,\nleveraging how the BLAS-like Library Instantiation Software (BLIS) framework\nrefactors the Goto Algorithm. With this, it is shown how approximate FP64x2\nGEMM accuracy can be cast in terms of ten ``cascading'' FP64 GEMMs. Promising\nresults from preliminary performance and accuracy experiments are reported. The\ndemonstrated techniques open up new research directions for more general\ncascading of higher-precision computation in terms of lower-precision\ncomputation for GEMM-like functionality.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.04353v2"
    },
    {
        "title": "Formal Derivation of LU Factorization with Pivoting",
        "authors": [
            "Robert van de Geijn",
            "Maggie Myers"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The FLAME methodology for deriving linear algebra algorithms from\nspecification, first introduced around 2000, has been successfully applied to a\nbroad cross section of operations. An open question has been whether it can\nyield algorithms for the best-known operation in linear algebra, LU\nfactorization with partial pivoting (Gaussian elimination with row swapping).\nThis paper shows that it can.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.03068v1"
    },
    {
        "title": "Massively Distributed Finite-Volume Flux Computation",
        "authors": [
            "Ryuichi Sai",
            "Mathias Jacquelin",
            "François P. Hamon",
            "Mauricio Araya-Polo",
            "Randolph R. Settgast"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Designing large-scale geological carbon capture and storage projects and\nensuring safe long-term CO2 containment - as a climate change mitigation\nstrategy - requires fast and accurate numerical simulations. These simulations\ninvolve solving complex PDEs governing subsurface fluid flow using implicit\nfinite-volume schemes widely based on Two-Point Flux Approximation (TPFA). This\ntask is computationally and memory expensive, especially when performed on\nhighly detailed geomodels. In most current HPC architectures, memory hierarchy\nand data management mechanism are insufficient to overcome the challenges of\nlarge scale numerical simulations. Therefore, it is crucial to design\nalgorithms that can exploit alternative and more balanced paradigms, such as\ndataflow and in-memory computing. This work introduces an algorithm for TPFA\ncomputations that leverages effectively a dataflow architecture, such as\nCerebras CS2, which helps to significantly minimize memory bottlenecks. Our\nimplementation achieves two orders of magnitude speedup compared to multiple\nreference implementations running on NVIDIA A100 GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.11274v1"
    },
    {
        "title": "Rigorous Function Calculi in Ariadne",
        "authors": [
            "Pieter Collins",
            "Luca Geretti",
            "Sanja Zivanovic Gonzalez",
            "Davide Bresolin",
            "Tiziano Villa"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Almost all problems in applied mathematics, including the analysis of\ndynamical systems, deal with spaces of real-valued functions on Euclidean\ndomains in their formulation and solution. In this paper, we describe the the\ntool Ariadne, which provides a rigorous calculus for working with Euclidean\nfunctions. We first introduce the Ariadne framework, which is based on a clean\nseparation of objects as providing exact, effective, validated and approximate\ninformation. We then discuss the function calculus as implemented in \\Ariadne,\nincluding polynomial function models which are the fundamental class for\nconcrete computations. We then consider solution of some core problems of\nfunctional analysis, namely solution of algebraic equations and differential\nequations, and briefly discuss their use for the analysis of hybrid systems. We\nwill give examples of C++ and Python code for performing the various\ncalculations. Finally, we will discuss progress on extensions, including\nimprovements to the function calculus and extensions to more complicated\nclasses of system.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.17541v1"
    },
    {
        "title": "Towards a Benchmark Framework for Model Order Reduction in the\n  Mathematical Research Data Initiative (MaRDI)",
        "authors": [
            "Peter Benner",
            "Kathryn Lund",
            "Jens Saak"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The race for the most efficient, accurate, and universal algorithm in\nscientific computing drives innovation. At the same time, this healthy\ncompetition is only beneficial if the research output is actually comparable to\nprior results. Fairly comparing algorithms can be a complex endeavor, as the\nimplementation, configuration, compute environment, and test problems need to\nbe well-defined. Due to the increase in computer-based experiments, new\ninfrastructure for facilitating the exchange and comparison of new algorithms\nis also needed. To this end, we propose a benchmark framework, as a set of\ngeneric specifications for comparing implementations of algorithms using test\ncases native to a community. Its value lies in its ability to fairly compare\nand validate existing methods for new applications, as well as compare newly\ndeveloped methods with existing ones. As a prototype for a more general\nframework, we have begun building a benchmark tool for the model order\nreduction (MOR) community. The data basis of the tool is the collection of the\nModel Order Reduction Wiki (MORWiki). The wiki features three main categories:\nbenchmarks, methods, and software. An editorial board curates submissions and\npatrols edited entries. Data sets for linear and parametric-linear models are\nalready well represented in the existing collection. Data sets for non-linear\nor procedural models, for which only evaluation data, or codes / algorithmic\ndescriptions, rather than equations, are available, are being added and\nextended. Properties and interesting characteristics used for benchmark\nselection and later assessments are recorded in the model metadata. Our tool,\nthe Model Order Reduction Benchmarker (MORB) is under active development for\nlinear time-invariant systems and solvers.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.00137v1"
    },
    {
        "title": "Integrating Enzyme-generated functions into CoDiPack",
        "authors": [
            "M. Sagebaum",
            "M. Aehle",
            "N. R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  In operator overloading algorithmic differentiation, it can be beneficial to\ncreate custom derivative functions for some parts of the code base. For manual\nimplementations of the derivative functions, it can be quite cumbersome to\nderive, implement, test, and maintain these. The process can be automated with\nsource transformation algorithmic differentiation tools like Tapenade or\ncompiler-based algorithmic differentiation tools like Enzyme. This eliminates\nmost of the work required from a manual implementation but usually has the same\nefficiency with respect to timing and memory. We present a new helper in\nCoDiPack that allows Enzyme-generated derivative functions to be automatically\nadded during the recording process of CoDiPack. The validity of the approach is\ndemonstrated on a synthetic benchmark, which shows promising results.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06075v1"
    },
    {
        "title": "SpComp: A Sparsity Structure-Specific Compilation of Matrix Operations",
        "authors": [
            "Barnali Basak",
            "Uday P. Khedker",
            "Supratim Biswas"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Sparse matrix operations involve a large number of zero operands which makes\nmost of the operations redundant. The amount of redundancy magnifies when a\nmatrix operation repeatedly executes on sparse data. Optimizing matrix\noperations for sparsity involves either reorganization of data or\nreorganization of computations, performed either at compile-time or run-time.\nAlthough compile-time techniques avert from introducing run-time overhead,\ntheir application either is limited to simple sparse matrix operations\ngenerating dense output and handling immutable sparse matrices or requires\nmanual intervention to customize the technique to different matrix operations.\nWe contribute a compile time technique called SpComp that optimizes a sparse\nmatrix operation by automatically customizing its computations to the positions\nof non-zero values of the data. Our approach neither incurs any run-time\noverhead nor requires any manual intervention. It is also applicable to complex\nmatrix operations generating sparse output and handling mutable sparse\nmatrices. We introduce a data-flow analysis, named Essential Indices Analysis,\nthat statically collects the symbolic information about the computations and\nhelps the code generator to reorganize the computations. The generated code\nincludes piecewise-regular loops, free from indirect references and amenable to\nfurther optimization. We see a substantial performance gain by SpComp-generated\nSpMSpV code when compared against the state-of-the-art TACO compiler and\npiecewise-regular code generator. On average, we achieve 79% performance gain\nagainst TACO and 83% performance gain against the piecewise-regular code\ngenerator. When compared against the CHOLMOD library, SpComp generated sparse\nCholesky decomposition code showcases 65% performance gain on average.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06109v1"
    },
    {
        "title": "A framework to test interval arithmetic libraries and their IEEE\n  1788-2015 compliance",
        "authors": [
            "Luis Benet",
            "Luca Ferranti",
            "Nathalie Revol"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  As developers of libraries implementing interval arithmetic, we faced the\nsame difficulties when it comes to testing our libraries. What must be tested?\nHow can we devise relevant test cases for unit testing? How can we ensure a\nhigh (and possibly 100%) test coverage? Before considering these questions, we\nbriefly recall the main features of interval arithmetic and of the IEEE\n1788-2015 standard for interval arithmetic. After listing the different aspects\nthat, in our opinion, must be tested, we contribute a first step towards\noffering a test suite for an interval arithmetic library. First we define a\nformat that enables the exchange of test cases, so that they can be read and\ntried easily. Then we offer a first set of test cases, for a selected set of\nmathematical functions. Next, we examine how the Julia interval arithmetic\nlibrary, IntervalArithmetic.jl, actually performs to these tests. As this is an\nongoing work, we list extra tests that we deem important to perform.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06953v1"
    },
    {
        "title": "ProtoX: A First Look",
        "authors": [
            "Het Mankad",
            "Sanil Rao",
            "Brian Van Straalen",
            "Phillip Colella",
            "Franz Franchetti"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present a first look at ProtoX, a code generation framework for stencil\nand pointwise operations that occur frequently in the numerical solution of\npartial differential equations. ProtoX has Proto as its library frontend and\nSPIRAL as the backend. Proto is a C++ based domain specific library which\noptimizes the algorithms used to compute the numerical solution of partial\ndifferential equations. Meanwhile, SPIRAL is a code generation system that\nfocuses on generating highly optimized target code. Although the current design\nlayout of Proto and its high level of abstractions provide a user friendly set\nup, there is still a room for improving it's performance by applying various\ntechniques either at a compiler level or at an algorithmic level. Hence, in\nthis paper we propose adding SPIRAL as the library backend for Proto enabling\nabstraction fusion, which is usually difficult to perform by any compiler. We\ndemonstrate the construction of ProtoX by considering the 2D Poisson equation\nas a model problem from Proto. We provide the final generated code for CPU,\nMulti-core CPU, and GPU as well as some performance numbers for CPU.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.07931v1"
    },
    {
        "title": "MindOpt Tuner: Boost the Performance of Numerical Software by Automatic\n  Parameter Tuning",
        "authors": [
            "Mengyuan Zhang",
            "Wotao Yin",
            "Mengchang Wang",
            "Yangbin Shen",
            "Peng Xiang",
            "You Wu",
            "Liang Zhao",
            "Junqiu Pan",
            "Hu Jiang",
            "KuoLing Huang"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Numerical software is usually shipped with built-in hyperparameters. By\ncarefully tuning those hyperparameters, significant performance enhancements\ncan be achieved for specific applications. We developed MindOpt Tuner, a new\nautomatic tuning tool that supports a wide range of numerical software,\nincluding optimization and other solvers. MindOpt Tuner uses elastic cloud\nresources, features a web-based task management panel and integration with\nipython notebook with both command-line tools and Python APIs. Our experiments\nwith COIN-OR Cbc, an open-source mixed-integer optimization solver, demonstrate\nremarkable improvements with the tuned parameters compared to the default ones\non the MIPLIB2017 test set, resulting in over 100x acceleration on several\nproblem instances. Additionally, the results demonstrate that Tuner has a\nhigher tuning efficiency compared to the state-of-the-art automatic tuning tool\nSMAC3.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.08085v1"
    },
    {
        "title": "Leveraging MLIR for Loop Vectorization and GPU Porting of FFT Libraries",
        "authors": [
            "Yifei He",
            "Artur Podobas",
            "Stefano Markidis"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  FFTc is a Domain-Specific Language (DSL) for designing and generating Fast\nFourier Transforms (FFT) libraries. The FFTc uniqueness is that it leverages\nand extend Multi-Level Intermediate Representation (MLIR) dialects to optimize\nFFT code generation. In this work, we present FFTc extensions and improvements\nsuch as the possibility of using different data layout for complex-value\narrays, and sparsification to enable efficient vectorization, and a seamless\nporting of FFT libraries to GPU systems. We show that, on CPUs, thanks to\nvectorization, the performance of the FFTc-generated FFT is comparable to\nperformance of FFTW, a state-of-the-art FFT libraries. We also present the\ninitial performance results for FFTc on Nvidia GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.00497v1"
    },
    {
        "title": "Bandicoot: C++ Library for GPU Linear Algebra and Scientific Computing",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel",
            "Conrad Sanderson"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  This report provides an introduction to the Bandicoot C++ library for linear\nalgebra and scientific computing on GPUs, overviewing its user interface and\nperformance characteristics, as well as the technical details of its internal\ndesign. Bandicoot is the GPU-enabled counterpart to the well-known Armadillo\nC++ linear algebra library, aiming to allow users to take advantage of\nGPU-accelerated computation for their existing codebases without significant\nchanges. Adapting the same internal template meta-programming techniques that\nArmadillo uses, Bandicoot is able to provide compile-time optimisation of\nmathematical expressions within user code. The library is ready for production\nuse and is available at https://coot.sourceforge.io. Bandicoot is distributed\nunder the Apache 2.0 License.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.03120v1"
    },
    {
        "title": "Alternative quadrant representations with Morton index and AVX2\n  vectorization for AMR algorithms within the p4est software library",
        "authors": [
            "Mikhail Kirilin",
            "Carsten Burstedde"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present a technical enhancement within the p4est software for parallel\nadaptive mesh refinement. In p4est primitives are stored as octants in three\nand quadrants in two dimensions. While, classically, they are encoded by the\nnative approach using its spatial and refinement level, any other\nmathematically equivalent encoding might be used instead.\n  Recognizing this, we add two alternative representations to the classical,\nexplicit version, based on a long monotonic index and 128-bit AVX quad\nintegers, respectively. The first one requires changes in logic for low-level\nquadrant manipulating algorithms, while the other exploits data level\nparallelism and requires algorithms to be adapted to SIMD instructions. The\nresultant algorithms and data structures lead to higher performance and lesser\nmemory usage in comparison with the standard baseline.\n  We benchmark selected algorithms on a cluster with two Intel(R) Xeon(R) Gold\n6130 Skylake family CPUs per node, which provides support for AVX2 extensions,\n192 GB RAM per node, and up to 512 computational cores in total.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.13615v1"
    },
    {
        "title": "A FAIR File Format for Mathematical Software",
        "authors": [
            "Antony Della Vecchia",
            "Michael Joswig",
            "Benjamin Lorenz"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We describe a generic JSON based file format which is suitable for\ncomputations in computer algebra. This is implemented in the computer algebra\nsystem OSCAR, but we also indicate how it can be used in a different context.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.00465v1"
    },
    {
        "title": "CDL: A fast and flexible library for the study of permutation sets with\n  structural restrictions",
        "authors": [
            "Bei Zhou",
            "Klas Markstrōm",
            "Søren Riis"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  In this paper, we introduce CDL, a software library designed for the analysis\nof permutations and linear orders subject to various structural restrictions.\nProminent examples of these restrictions include pattern avoidance, a topic of\ninterest in both computer science and combinatorics, and \"never conditions\"\nutilized in social choice and voting theory.\n  CDL offers a range of fundamental functionalities, including identifying the\npermutations that meet specific restrictions and determining the isomorphism of\nsuch sets. To facilitate exploration of large permutation sets or domains, CDL\nincorporates multiple search strategies and heuristics.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.06306v2"
    },
    {
        "title": "Parallel local time stepping for rigid bodies represented by\n  triangulated meshes",
        "authors": [
            "Peter Noble",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Discrete Element Methods (DEM), i.e.~the simulation of many rigid particles,\nsuffer from very stiff differential equations plus multiscale challenges in\nspace and time. The particles move smoothly through space until they interact\nalmost instantaneously due to collisions. Dense particle packings hence require\ntiny time step sizes, while free particles can advance with large time steps.\nAdmissible time step sizes can span multiple orders of magnitudes. We propose\nan adaptive local time stepping algorithm which identifies clusters of\nparticles that can be updated independently, advances them optimistically and\nindependently in time, determines collision time stamps in space-time such that\nwe maximise the time step sizes used, and resolves the momentum exchange\nimplicitly. It is combined with various acceleration techniques which exploit\nmultiscale geometry representations and multiscale behaviour in time. The\ncollision time stamp detection in space-time in combination with the implicit\nsolve of the actual collision equations avoids that particles get locked into\ntiny time step sizes, the clustering yields a high concurrency level, and the\nacceleration techniques plus local time stepping avoid unnecessary\ncomputations. This brings a scaling, adaptive time stepping for DEM for\nreal-world challenges into reach.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.15417v1"
    },
    {
        "title": "AsaPy: A Python Library for Aerospace Simulation Analysis",
        "authors": [
            "Joao P. A. Dantas",
            "Samara R. Silva",
            "Vitor C. F. Gomes",
            "Andre N. Costa",
            "Adrisson R. Samersla",
            "Diego Geraldo",
            "Marcos R. O. A. Maximo",
            "Takashi Yoneyama"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  AsaPy is a custom-made Python library designed to simplify and optimize the\nanalysis of aerospace simulation data. Instead of introducing new\nmethodologies, it excels in combining various established techniques, creating\na unified, specialized platform. It offers a range of features, including the\ndesign of experiment methods, statistical analysis techniques, machine learning\nalgorithms, and data visualization tools. AsaPy's flexibility and\ncustomizability make it a viable solution for engineers and researchers who\nneed to quickly gain insights into aerospace simulations. AsaPy is built on top\nof popular scientific computing libraries, ensuring high performance and\nscalability. In this work, we provide an overview of the key features and\ncapabilities of AsaPy, followed by an exposition of its architecture and\ndemonstrations of its effectiveness through some use cases applied in military\noperational simulations. We also evaluate how other simulation tools deal with\ndata science, highlighting AsaPy's strengths and advantages. Finally, we\ndiscuss potential use cases and applications of AsaPy and outline future\ndirections for the development and improvement of the library.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.00001v2"
    },
    {
        "title": "HyperNetX: A Python package for modeling complex network data as\n  hypergraphs",
        "authors": [
            "Brenda Praggastis",
            "Sinan Aksoy",
            "Dustin Arendt",
            "Mark Bonicillo",
            "Cliff Joslyn",
            "Emilie Purvine",
            "Madelyn Shapiro",
            "Ji Young Yun"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  HyperNetX (HNX) is an open source Python library for the analysis and\nvisualization of complex network data modeled as hypergraphs. Initially\nreleased in 2019, HNX facilitates exploratory data analysis of complex networks\nusing algebraic topology, combinatorics, and generalized hypergraph and graph\ntheoretical methods on structured data inputs. With its 2023 release, the\nlibrary supports attaching metadata, numerical and categorical, to nodes\n(vertices) and hyperedges, as well as to node-hyperedge pairings (incidences).\nHNX has a customizable Matplotlib-based visualization module as well as\nHypernetX-Widget, its JavaScript addon for interactive exploration and\nvisualization of hypergraphs within Jupyter Notebooks. Both packages are\navailable on GitHub and PyPI. With a growing community of users and\ncollaborators, HNX has become a preeminent tool for hypergraph analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.11626v1"
    },
    {
        "title": "Deriving Algorithms for Triangular Tridiagonalization a (Skew-)Symmetric\n  Matrix",
        "authors": [
            "Robert van de Geijn",
            "Maggie Myers",
            "RuQing G. Xu",
            "Devin Matthews"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We apply the FLAME methodology to derive algorithms hand in hand with their\nproofs of correctness for the computation of the $ L T L^T $ decomposition\n(with and without pivoting) of a skew-symmetric matrix. The approach yields\nknown as well as new algorithms, presented using the FLAME notation. A number\nof BLAS-like primitives are exposed at the core of blocked algorithms that can\nattain high performance. The insights can be easily extended to yield\nalgorithms for computing the $ L T L^T $ decomposition of a symmetric matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.10700v1"
    },
    {
        "title": "Lineax: unified linear solves and linear least-squares in JAX and\n  Equinox",
        "authors": [
            "Jason Rader",
            "Terry Lyons",
            "Patrick Kidger"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We introduce Lineax, a library bringing linear solves and linear\nleast-squares to the JAX+Equinox scientific computing ecosystem. Lineax uses\ngeneral linear operators, and unifies linear solves and least-squares into a\nsingle, autodifferentiable API. Solvers and operators are user-extensible,\nwithout requiring the user to implement any custom derivative rules to get\ndifferentiability. Lineax is available at https://github.com/google/lineax.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.17283v1"
    },
    {
        "title": "Toward a comprehensive simulation framework for hypergraphs: a\n  Python-base approach",
        "authors": [
            "Quoc Chuong Nguyen",
            "Trung Kien Le"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Hypergraphs, or generalization of graphs such that edges can contain more\nthan two nodes, have become increasingly prominent in understanding complex\nnetwork analysis. Unlike graphs, hypergraphs have relatively few supporting\nplatforms, and such dearth presents a barrier to more widespread adaptation of\nhypergraph computational toolboxes that could enable further research in\nseveral areas. Here, we introduce HyperRD, a Python package for hypergraph\ncomputation, simulation, and interoperability with other powerful Python\npackages in graph and hypergraph research. Then, we will introduce two models\non hypergraph, the general Schelling's model and the SIR model, and simulate\nthem with HyperRD.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.03917v1"
    },
    {
        "title": "Efficient Calculations for Inverse of $k$-diagonal Circulant Matrices\n  and Cyclic Banded Matrices",
        "authors": [
            "Chen Wang",
            "Hailong Yu",
            "Chao Wang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  $k$-diagonal circulant matrices and cyclic banded matrices are widely used in\nnumerical simulations and signal processing of circular linear systems.\nAlgorithms that directly involve or specify linear or quadratic complexity for\nthe inverses of these two types of matrices are rare. We find that the inverse\nof a $k$-diagonal circulant matrix can be uniquely determined by a recursive\nformula, which can be derived within $O(k^3 \\log n+k^4)$. Similarly for the\ninverse of a cyclic banded matrix, its inverse can be uniquely determined by a\nseries of recursive formulas, with the initial terms of these recursions\ncomputable within $O(k^3 n+k^5)$. The additional costs for solving the complete\ninverses of these two types of matrices are $kn$ and $kn^2$. Our calculations\nenable rapid representation with most processes defined by explicit formulas.\nAdditionally, most algorithms for inverting $k$-diagonal circulant matrices\nrely on the Fast Fourier Transform, which is not applicable to finite fields,\nwhile our algorithms can be applied to computations in finite fields.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.05048v2"
    },
    {
        "title": "Predefined Software Environment Runtimes As A Measure For\n  Reproducibility",
        "authors": [
            "Aaruni Kaushik"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  As part of Mathematical Research Data Initiative (MaRDI), we have developed a\nway to preserve a software package into an easy to deploy and use sandbox\nenvironment we call a \"runtime\", via a program we developed called MaPS : MaRDI\nPackaging System. The program relies on Linux user namespaces to isolate a\nlibrary environment from the host system, making the sandboxed software\nreproducible on other systems, with minimal effort. Moreover an overlay\nfilesystem makes local edits persistent. This project will aid reproducibility\nefforts of research papers: both mathematical and from other disciplines. As a\nproof of concept, we provide runtimes for the OSCAR Computer Algebra System,\npolymake software for research in polyhedral geometry, and VIBRANT Virus\nIdentification By iteRative ANnoTation. The software is in a prerelease state:\nthe interface for creating, deploying, and executing runtimes is final, and an\ninterface for easily publishing runtimes is under active development. We thus\npropose publishing predefined, distributable software environment runtimes\nalong with research papers in an effort to make research with software based\nresults reproducible.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.05563v1"
    },
    {
        "title": "Confirmable Workflows in OSCAR",
        "authors": [
            "Michael Joswig",
            "Lars Kastner",
            "Benjamin Lorenz"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  We discuss what is special about the reproducibility of workflows in computer\nalgebra. It is emphasized how the programming language Julia and the new\ncomputer algebra system OSCAR support such a reproducibility, and how users can\nbenefit for their own work.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.06241v1"
    },
    {
        "title": "Conversion of Boolean and Integer FlatZinc Builtins to Quadratic or\n  Linear Integer Problems",
        "authors": [
            "Armin Wolf"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Constraint satisfaction or optimisation models -- even if they are formulated\nin high-level modelling languages -- need to be reduced into an equivalent\nformat before they can be solved by the use of Quantum Computing. In this paper\nwe show how Boolean and integer FlatZinc builtins over finite-domain integer\nvariables can be equivalently reformulated as linear equations, linear\ninequalities or binary products of those variables, i.e. as finite-domain\nquadratic integer programs. Those quadratic integer programs can be further\ntransformed into equivalent Quadratic Unconstrained Binary Optimisation problem\nmodels, i.e. a general format for optimisation problems to be solved on Quantum\nComputers especially on Quantum Annealers.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.12797v1"
    },
    {
        "title": "On a vectorized basic linear algebra package for prototyping codes in\n  MATLAB",
        "authors": [
            "Alexej Moskovka",
            "Talal Rahman",
            "Jan Valdman",
            "Jon Eivind Vatne"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  When writing high-performance code for numerical computation in a scripting\nlanguage like MATLAB, it is crucial to have the operations in a large for-loop\nvectorized. If not, the code becomes too slow to use, even for a moderately\nlarge problem. However, in the process of vectorizing, the code often loses its\noriginal structure and becomes less readable. This is particularly true in the\ncase of a finite element implementation, even though finite element methods are\ninherently structured. A basic remedy to this is the separation of the\nvectorization part from the mathematics part of the code, which is easily\nachieved through building the code on top of the basic linear algebra\nsubprograms that are already vectorized codes, an idea that has been used in a\nseries of papers over the last fifteen years, developing codes that are fast\nand still structured and readable. We discuss the vectorized basic linear\nalgebra package and introduce a formalism using multi-linear algebra to explain\nand define formally the functions in the package, as well as MATLAB pagetime\nfunctions. We provide examples from computations of varying complexity,\nincluding the computation of normal vectors, volumes, and finite element\nmethods. Benchmarking shows that we also get fast computations. Using the\nlibrary, we can write codes that closely follow our mathematical thinking,\nmaking writing, following, reusing, and extending the code easier.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.16039v1"
    },
    {
        "title": "Finch: Sparse and Structured Array Programming with Control Flow",
        "authors": [
            "Willow Ahrens",
            "Teodoro Fields Collin",
            "Radha Patel",
            "Kyle Deeds",
            "Changwan Hong",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  From FORTRAN to NumPy, arrays have revolutionized how we express computation.\nHowever, arrays in these, and almost all prominent systems, can only handle\ndense rectilinear integer grids. Real world arrays often contain underlying\nstructure, such as sparsity, runs of repeated values, or symmetry. Support for\nstructured data is fragmented and incomplete. Existing frameworks limit the\narray structures and program control flow they support to better simplify the\nproblem.\n  In this work, we propose a new programming language, Finch, which supports\nboth flexible control flow and diverse data structures. Finch facilitates a\nprogramming model which resolves the challenges of computing over structured\narrays by combining control flow and data structures into a common\nrepresentation where they can be co-optimized. Finch automatically specializes\ncontrol flow to data so that performance engineers can focus on experimenting\nwith many algorithms. Finch supports a familiar programming language of loops,\nstatements, ifs, breaks, etc., over a wide variety of array structures, such as\nsparsity, run-length-encoding, symmetry, triangles, padding, or blocks. Finch\nreliably utilizes the key properties of structure, such as structural zeros,\nrepeated values, or clustered non-zeros. We show that this leads to dramatic\nspeedups in operations such as SpMV and SpGEMM, image processing, graph\nanalytics, and a high-level tensor operator fusion interface.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.16730v1"
    },
    {
        "title": "Hybrid parallel discrete adjoints in SU2",
        "authors": [
            "Johannes Blühdorn",
            "Pedro Gomes",
            "Max Aehle",
            "Nicolas R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The open-source multiphysics suite SU2 features discrete adjoints by means of\noperator overloading automatic differentiation (AD). While both primal and\ndiscrete adjoint solvers support MPI parallelism, hybrid parallelism using both\nMPI and OpenMP has only been introduced for the primal solvers so far. In this\nwork, we enable hybrid parallel discrete adjoint solvers. Coupling SU2 with\nOpDiLib, an add-on for operator overloading AD tools that extends AD to OpenMP\nparallelism, marks a key step in this endeavour. We identify the affected parts\nof SU2's advanced AD workflow and discuss the required changes and their\ntradeoffs. Detailed performance studies compare MPI parallel and hybrid\nparallel discrete adjoints in terms of memory and runtime and unveil key\nperformance characteristics. We showcase the effectiveness of performance\noptimizations and highlight perspectives for future improvements. At the same\ntime, this study demonstrates the applicability of OpDiLib in a large code base\nand its scalability on large test cases, providing valuable insights for future\napplications both within and beyond SU2.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.06056v2"
    },
    {
        "title": "Local Adjoints for Simultaneous Preaccumulations with Shared Inputs",
        "authors": [
            "Johannes Blühdorn",
            "Nicolas R. Gauger"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In shared-memory parallel automatic differentiation, inputs that are shared\namong simultaneous thread-local preaccumulations lead to data races if\nJacobians are accumulated with a single, shared vector of adjoint variables. In\nthis work, we discuss the benefits and tradeoffs of re-enabling such\npreaccumulations by a transition to suitable local adjoints. We propose\ndifferent vector- and map-based approaches for storing local adjoint variables\nand analyze them with respect to memory consumption, memory allocation, and\nadjoint variable access times in the context of simultaneous preaccumulations\nin multiple threads. We implement the approaches in CoDiPack and benchmark them\nin parallel discrete adjoint computations in the multiphysics simulation suite\nSU2.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.07819v2"
    },
    {
        "title": "PyOptInterface: Design and implementation of an efficient modeling\n  language for mathematical optimization",
        "authors": [
            "Yue Yang",
            "Chenhui Lin",
            "Luo Xu",
            "Wenchuan Wu"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This paper introduces the design and implementation of PyOptInterface, a\nmodeling language for mathematical optimization embedded in Python programming\nlanguage. PyOptInterface uses lightweight and compact data structure to bridge\nhigh-level entities in optimization models like variables and constraints to\ninternal indices of optimizers efficiently. It supports a variety of\noptimization solvers and a range of common problem classes. We provide\nbenchmarks to exhibit the competitive performance of PyOptInterface compared\nwith other state-of-the-art modeling languages.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.10130v1"
    },
    {
        "title": "GridapTopOpt.jl: A scalable Julia toolbox for level set-based topology\n  optimisation",
        "authors": [
            "Zachary J. Wegert",
            "Jordi Manyer",
            "Connor Mallon",
            "Santiago Badia",
            "Vivien J. Challis"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In this paper we present GridapTopOpt, an extendable framework for level\nset-based topology optimisation that can be readily distributed across a\npersonal computer or high-performance computing cluster. The package is written\nin Julia and uses the Gridap package ecosystem for parallel finite element\nassembly from arbitrary weak formulations of partial differential equation\n(PDEs) along with the scalable solvers from the Portable and Extendable Toolkit\nfor Scientific Computing (PETSc). The resulting user interface is intuitive and\neasy-to-use, allowing for the implementation of a wide range of topology\noptimisation problems with a syntax that is near one-to-one with the\nmathematical notation. Furthermore, we implement automatic differentiation to\nhelp mitigate the bottleneck associated with the analytic derivation of\nsensitivities for complex problems. GridapTopOpt is capable of solving a range\nof benchmark and research topology optimisation problems with large numbers of\ndegrees of freedom. This educational article demonstrates the usability and\nversatility of the package by describing the formulation and step-by-step\nimplementation of several distinct topology optimisation problems. The driver\nscripts for these problems are provided and the package source code is\navailable at https://github$.$com/zjwegert/GridapTopOpt.jl.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.10478v2"
    },
    {
        "title": "svds-C: A Multi-Thread C Code for Computing Truncated Singular Value\n  Decomposition",
        "authors": [
            "Xu Feng",
            "Wenjian Yu",
            "Yuyang Xie"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This article presents svds-C, an open-source and high-performance C program\nfor accurately and robustly computing truncated SVD, e.g. computing several\nlargest singular values and corresponding singular vectors. We have\nre-implemented the algorithm of svds in Matlab in C based on MKL or OpenBLAS\nand multi-thread computing to obtain the parallel program named svds-C. svds-C\nrunning on shared-memory computer consumes less time and memory than svds\nthanks to careful implementation of multi-thread parallelization and memory\nmanagement. Numerical experiments on different test cases which are\nsynthetically generated or directly from real world datasets show that, svds-C\nruns remarkably faster than svds with averagely 4.7X and at most 12X speedup\nfor 16-thread parallel computing on a computer with Intel CPU, while preserving\nsame accuracy and consuming about half memory space. Experimental results also\ndemonstrate that svds-C has similar advantages over svds on the computer with\nAMD CPU, and outperforms other state-of-the-art algorithms for truncated SVD on\ncomputing time and robustness.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.18966v1"
    },
    {
        "title": "An extension of C++ with memory-centric specifications for HPC to reduce\n  memory footprints and streamline MPI development",
        "authors": [
            "Pawel K. Radtke",
            "Cristian G. Barrera-Hinojosa",
            "Mladen Ivkovic",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The C++ programming language and its cousins lean towards a\nmemory-inefficient storage of structs: The compiler inserts helper bits into\nthe struct such that individual attributes align with bytes, and it adds\nadditional bytes aligning attributes with cache lines, while it is not able to\nexploit knowledge about the range of integers, enums or bitsets to bring the\nmemory footprint down. Furthermore, the language provides neither support for\ndata exchange via MPI nor for arbitrary floating-point precision formats. If\ndevelopers need to have a low memory footprint and MPI datatypes over structs\nwhich exchange only minimal data, they have to manipulate the data and to write\nMPI datatypes manually. We propose a C++ language extension based upon C++\nattributes through which developers can guide the compiler what memory\narrangements would be beneficial: Can multiple booleans be squeezed into one\nbit field, do floats hold fewer significant bits than in the IEEE standard, or\ndoes the code require a user-defined MPI datatype for certain subsets of\nattributes? The extension offers the opportunity to fall back to normal\nalignment and padding rules via plain C++ assignments, no dependencies upon\nexternal libraries are introduced, and the resulting code remains standard C++.\nOur work implements the language annotations within LLVM and demonstrates their\npotential impact, both upon the runtime and the memory footprint, through\nsmoothed particle hydrodynamics (SPH) benchmarks. They uncover the potential\ngains in terms of performance and development productivity.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.06095v2"
    },
    {
        "title": "SySTeC: A Symmetric Sparse Tensor Compiler",
        "authors": [
            "Radha Patel",
            "Willow Ahrens",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Symmetric and sparse tensors arise naturally in many domains including linear\nalgebra, statistics, physics, chemistry, and graph theory. Symmetric tensors\nare equal to their transposes, so in the $n$-dimensional case we can save up to\na factor of $n!$ by avoiding redundant operations. Sparse tensors, on the other\nhand, are mostly zero, and we can save asymptotically by processing only\nnonzeros. Unfortunately, specializing for both symmetry and sparsity at the\nsame time is uniquely challenging. Optimizing for symmetry requires\nconsideration of $n!$ transpositions of a triangular kernel, which can be\ncomplex and error prone. Considering multiple transposed iteration orders and\ntriangular loop bounds also complicates iteration through intricate sparse\ntensor formats. Additionally, since each combination of symmetry and sparse\ntensor formats requires a specialized implementation, this leads to a\ncombinatorial number of cases. A compiler is needed, but existing compilers\ncannot take advantage of both symmetry and sparsity within the same kernel. In\nthis paper, we describe the first compiler which can automatically generate\nsymmetry-aware code for sparse or structured tensor kernels. We introduce a\ntaxonomy for symmetry in tensor kernels, and show how to target each kind of\nsymmetry. Our implementation demonstrates significant speedups ranging from\n1.36x for SSYMV to 30.4x for a 5-dimensional MTTKRP over the non-symmetric\nstate of the art.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.09266v1"
    },
    {
        "title": "OpenCAEPoro: A Parallel Simulation Framework for Multiphase and\n  Multicomponent Porous Media Flows",
        "authors": [
            "Shizhe Li",
            "Chen-Song Zhang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  OpenCAEPoro is a parallel numerical simulation software developed in C++ for\nsimulating multiphase and multicomponent flows in porous media. The software\nutilizes a set of general-purpose compositional model equations, enabling it to\nhandle a diverse range of fluid dynamics, including the black oil model,\ncompositional model, and thermal recovery models. OpenCAEPoro establishes a\nunified solving framework that integrates many widely used methods, such as\nIMPEC, FIM, and AIM. This framework allows dynamic collaboration between\ndifferent methods. Specifically, based on this framework, we have developed an\nadaptively coupled domain decomposition method, which can provide initial\nsolutions for global methods to accelerate the simulation. The reliability of\nOpenCAEPoro has been validated through benchmark testing with the SPE\ncomparative solution project. Furthermore, its robust parallel efficiency has\nbeen tested in distributed parallel environments, demonstrating its suitability\nfor large-scale simulation problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.10862v1"
    },
    {
        "title": "Minimization of Nonlinear Energies in Python Using FEM and Automatic\n  Differentiation Tools",
        "authors": [
            "Michal Béreš",
            "Jan Valdman"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This contribution examines the capabilities of the Python ecosystem to solve\nnonlinear energy minimization problems, with a particular focus on\ntransitioning from traditional MATLAB methods to Python's advanced\ncomputational tools, such as automatic differentiation. We demonstrate Python's\nstreamlined approach to minimizing nonlinear energies by analyzing three\nproblem benchmarks - the p-Laplacian, the Ginzburg-Landau model, and the\nNeo-Hookean hyperelasticity. This approach merely requires the provision of the\nenergy functional itself, making it a simple and efficient way to solve this\ncategory of problems. The results show that the implementation is about ten\ntimes faster than the MATLAB implementation for large-scale problems. Our\nfindings highlight Python's efficiency and ease of use in scientific computing,\nestablishing it as a preferable choice for implementing sophisticated\nmathematical models and accelerating the development of numerical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.04706v1"
    },
    {
        "title": "MPAT: Modular Petri Net Assembly Toolkit",
        "authors": [
            "Stefano Chiaradonna",
            "Petar Jevtic",
            "Beckett Sterner"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  We present a Python package called Modular Petri Net Assembly Toolkit (MPAT)\nthat empowers users to easily create large-scale, modular Petri Nets for\nvarious spatial configurations, including extensive spatial grids or those\nderived from shape files, augmented with heterogeneous information layers.\nPetri Nets are powerful discrete event system modeling tools in computational\nbiology and engineering. However, their utility for automated construction of\nlarge-scale spatial models has been limited by gaps in existing modeling\nsoftware packages. MPAT addresses this gap by supporting the development of\nmodular Petri Net models with flexible spatial geometries.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.10372v1"
    },
    {
        "title": "A prony method variant which surpasses the Adaptive LMS filter in the\n  output signal's representation of input",
        "authors": [
            "Parthasarathy Srinivasan"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The Prony method for approximating signals comprising sinusoidal/exponential\ncomponents is known through the pioneering work of Prony in his seminal\ndissertation in the year 1795. However, the Prony method saw the light of real\nworld application only upon the advent of the computational era, which made\nfeasible the extensive numerical intricacies and labor which the method demands\ninherently. The Adaptive LMS Filter which has been the most pervasive method\nfor signal filtration and approximation since its inception in 1965 does not\nprovide a consistently assured level of highly precise results as the extended\nexperiment in this work proves. As a remedy this study improvises upon the\nProny method by observing that a better (more precise) computational\napproximation can be obtained under the premise that adjustment can be made for\ncomputational error , in the autoregressive model setup in the initial step of\nthe Prony computation itself. This adjustment is in proportion to the deviation\nof the coefficients in the same autoregressive model. The results obtained by\nthis improvisation live up to the expectations of obtaining consistency and\nhigher value in the precision of the output (recovered signal) approximations\nas shown in this current work and as compared with the results obtained using\nthe Adaptive LMS Filter.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.01272v1"
    },
    {
        "title": "QHyper: an integration library for hybrid quantum-classical optimization",
        "authors": [
            "Tomasz Lamża",
            "Justyna Zawalska",
            "Kacper Jurek",
            "Mariusz Sterzel",
            "Katarzyna Rycerz"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  We propose the QHyper library, which is aimed at researchers working on\ncomputational experiments with a variety of quantum combinatorial optimization\nsolvers. The library offers a simple and extensible interface for formulating\ncombinatorial optimization problems, selecting and running solvers, and\noptimizing hyperparameters. The supported solver set includes variational\ngate-based algorithms, quantum annealers, and classical solutions. The solvers\ncan be combined with provided local and global (hyper)optimizers. The main\nfeatures of the library are its extensibility on different levels of use as\nwell as a straightforward and flexible experiment configuration format\npresented in the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.15926v1"
    },
    {
        "title": "BLAS-like Interface for Binary Tensor Contractions",
        "authors": [
            "Niklas Hörnblad"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In the world of linear algebra computation, a well-established standard\nexists called BLAS(Basic Linear Algebra Subprograms). This standard has been\ncrucial for the development of software using linear algebra operations. Its\nbenefits include portability with efficiency and mitigation of suboptimal\nre-implementations of linear algebra operations. Multilinear algebra is an\nextension of linear algebra in which the central objects are tensors, which are\ngeneralizations of vectors and matrices. Though tensor operations are becoming\nmore common, they do not have a standard like BLAS. Such standardization would\nbe beneficial and decrease the now-visible replication of work, as many\nlibraries nowadays use their own implementations. This master thesis aims to\nwork towards such a standard by discovering whether or not a BLAS-like\ninterface is possible for the operation binary tensor contraction. To answer\nthis, an interface has been developed in the programming language C together\nwith an implementation and tested to see if it would be sufficient. The\ninterface developed is:\n  xGETT(RANKA, EXTA, INCA, A, RANKB, EXTB, INCB, B, CONTS, CONTA, CONTB, PERM,\nINCC, C)\n  with the implementation and tests, it has been deemed sufficient as a\nBLAS-like interface for binary tensor contractions and possible to use in a\nBLAS-like standardization for tensor operations.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.06770v1"
    },
    {
        "title": "Skew-Symmetric Matrix Decompositions on Shared-Memory Architectures",
        "authors": [
            "Ishna Satyarth",
            "Chao Yin",
            "RuQing G. Xu",
            "Devin A. Matthews"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The factorization of skew-symmetric matrices is a critically understudied\narea of dense linear algebra (DLA), particularly in comparison to that of\nsymmetric matrices. While some algorithms can be adapted from the symmetric\ncase, the cost of algorithms can be reduced by exploiting skew-symmetry. A\nmotivating example is the factorization $X=LTL^T$ of a skew-symmetric matrix\n$X$, which is used in practical applications as a means of determining the\ndeterminant of $X$ as the square of the (cheaply-computed) Pfaffian of the\nskew-symmetric tridiagonal matrix $T$, for example in fields such as quantum\nelectronic structure and machine learning. Such applications also often require\npivoting in order to improve numerical stability. In this work we explore a\ncombination of known literature algorithms and new algorithms recently derived\nusing formal methods. High-performance parallel CPU implementations are\ncreated, leveraging the concept of fusion at multiple levels in order to reduce\nmemory traffic overhead, as well as the BLIS framework which provides\nhigh-performance GEMM kernels, hierarchical parallelism, and cache blocking. We\nfind that operation fusion and improved use of available bandwidth via\nparallelization of bandwidth-bound (level-2 BLAS) operations are essential for\nobtaining high performance, while a concise C++ implementation provides a clear\nand close connection to the formal derivation process without sacrificing\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.09859v1"
    },
    {
        "title": "Interface for Sparse Linear Algebra Operations",
        "authors": [
            "Ahmad Abdelfattah",
            "Willow Ahrens",
            "Hartwig Anzt",
            "Chris Armstrong",
            "Ben Brock",
            "Aydin Buluc",
            "Federico Busato",
            "Terry Cojean",
            "Tim Davis",
            "Jim Demmel",
            "Grace Dinh",
            "David Gardener",
            "Jan Fiala",
            "Mark Gates",
            "Azzam Haider",
            "Toshiyuki Imamura",
            "Pedro Valero Lara",
            "Jose Moreira",
            "Sherry Li",
            "Piotr Luszczek",
            "Max Melichenko",
            "Jose Moeira",
            "Yvan Mokwinski",
            "Riley Murray",
            "Spencer Patty",
            "Slaven Peles",
            "Tobias Ribizel",
            "Jason Riedy",
            "Siva Rajamanickam",
            "Piyush Sao",
            "Manu Shantharam",
            "Keita Teranishi",
            "Stan Tomov",
            "Yu-Hsiang Tsai",
            "Heiko Weichelt"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The standardization of an interface for dense linear algebra operations in\nthe BLAS standard has enabled interoperability between different linear algebra\nlibraries, thereby boosting the success of scientific computing, in particular\nin scientific HPC. Despite numerous efforts in the past, the community has not\nyet agreed on a standardization for sparse linear algebra operations due to\nnumerous reasons. One is the fact that sparse linear algebra objects allow for\nmany different storage formats, and different hardware may favor different\nstorage formats. This makes the definition of a FORTRAN-style all-circumventing\ninterface extremely challenging. Another reason is that opposed to dense linear\nalgebra functionality, in sparse linear algebra, the size of the sparse data\nstructure for the operation result is not always known prior to the\ninformation. Furthermore, as opposed to the standardization effort for dense\nlinear algebra, we are late in the technology readiness cycle, and many\nproduction-ready software libraries using sparse linear algebra routines have\nimplemented and committed to their own sparse BLAS interface. At the same time,\nthere exists a demand for standardization that would improve interoperability,\nand sustainability, and allow for easier integration of building blocks. In an\ninclusive, cross-institutional effort involving numerous academic institutions,\nUS National Labs, and industry, we spent two years designing a\nhardware-portable interface for basic sparse linear algebra functionality that\nserves the user needs and is compatible with the different interfaces currently\nused by different vendors. In this paper, we present a C++ API for sparse\nlinear algebra functionality, discuss the design choices, and detail how\nsoftware developers preserve a lot of freedom in terms of how to implement\nfunctionality behind this API.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.13259v1"
    },
    {
        "title": "Efficient Computation of Collatz Sequence Stopping Times: A Novel\n  Algorithmic Approach",
        "authors": [
            "Eyob Solomon Getachew",
            "Beakal Gizachew Assefa"
        ],
        "category": "cs.MS",
        "published_year": "2025",
        "summary": "  The Collatz conjecture, which posits that any positive integer will\neventually reach 1 through a specific iterative process, is a classic unsolved\nproblem in mathematics. This research focuses on designing an efficient\nalgorithm to compute the stopping time of numbers in the Collatz sequence,\nachieving significant computational improvements. By leveraging structural\npatterns in the Collatz tree, the proposed algorithm minimizes redundant\noperations and optimizes computational steps. Unlike prior methods, it\nefficiently handles extremely large numbers without requiring advanced\ntechniques such as memoization or parallelization. Experimental evaluations\nconfirm computational efficiency improvements of approximately 28% over\nstate-of-the-art methods. These findings underscore the algorithm's scalability\nand robustness, providing a foundation for future large-scale verification of\nthe conjecture and potential applications in computational mathematics.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.04032v1"
    },
    {
        "title": "A comparison of two effective methods for reordering columns within\n  supernodes",
        "authors": [
            "M. Ozan Karsavuran",
            "Esmond G. Ng",
            "Barry W. Peyton"
        ],
        "category": "cs.MS",
        "published_year": "2025",
        "summary": "  In some recent papers, researchers have found two very good methods for\nreordering columns within supernodes in sparse Cholesky factors; these\nreorderings can be very useful for certain factorization methods. The first of\nthese reordering methods is based on modeling the underlying problem as a\ntraveling salesman problem (TSP), and the second of these methods is based on\npartition refinement (PR). In this paper, we devise a fair way to compare the\ntwo methods. While the two methods are virtually the same in the quality of the\nreorderings that they produce, PR should be the method of choice because PR\nreorderings can be computed using far less time and storage than TSP\nreorderings.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.08395v1"
    },
    {
        "title": "Fast Computational Algorithms for the Discrete Wavelet Transform and\n  Applications of Localized Orthonormal Bases in Signal Classification",
        "authors": [
            "Eirik Fossgaard"
        ],
        "category": "cs.MS",
        "published_year": "1999",
        "summary": "  We construct an algorithm for implementing the discrete wavelet transform by\nmeans of matrices in SO_2(R) for orthonormal compactly supported wavelets and\nmatrices in SL_m(R), m > = 2, for compactly supported biorthogonal wavelets. We\nshow that in 1 dimension the total operation count using this algorithm can be\nreduced to about 50% of the conventional convolution and downsampling by\n2-operation for both orthonormal and biorthogonal filters. In the special case\nof biorthogonal symmetric odd-odd filters, we show an implementation yielding a\ntotal operation count of about 38% of the conventional method. In 2 dimensions\nwe show an implementation of this algorithm yielding a reduction in the total\noperation count of about 70% when the filters are orthonormal, a reduction of\nabout 62% for general biorthogonal filters, and a reduction of about 70% if the\nfilters are symmetric odd-odd length filters. We further extend these results\nto 3 dimensions. We also show how the SO_2(R)-method for implementing the\ndiscrete wavelet transform may be exploited to compute short FIR filters, and\nwe construct edge mappings where we try to improve upon the degree of\npreservation of regularity in the conventional methods. We also consider a\ntwo-class waveform discrimination problem. A statistical space-frequency\nanalysis is performed on a training data set using the LDB-algorithm of N.Saito\nand R.Coifman. The success of the algorithm on this particular problem is\nevaluated on a disjoint test data set.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9901008v1"
    },
    {
        "title": "Seeing the Forest in the Tree: Applying VRML to Mathematical Problems in\n  Number Theory",
        "authors": [
            "Neil J. Gunther"
        ],
        "category": "cs.MS",
        "published_year": "1999",
        "summary": "  We show how VRML (Virtual Reality Modeling Language) can provide potentially\npowerful insight into the 3x + 1 problem via the introduction of a unique\ngeometrical object, called the 'G-cell', akin to a fractal generator. We\npresent an example of a VRML world developed programmatically with the G-cell.\nThe role of VRML as a tool for furthering the understanding the 3x+1 problem is\npotentially significant for several reasons: a) VRML permits the observer to\nzoom into the geometric structure at all scales (up to limitations of the\ncomputing platform). b) VRML enables rotation to alter comparative visual\nperspective (similar to Tukey's data-spinning concept). c) VRML facilitates the\ndemonstration of interesting tree features between collaborators on the\ninternet who might otherwise have difficulty conveying their ideas\nunambiguously. d) VRML promises to reveal any dimensional dependencies among\n3x+1 sequences.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9912021v2"
    },
    {
        "title": "Adaptive simulated annealing (ASA): Lessons learned",
        "authors": [
            "Lester Ingber"
        ],
        "category": "cs.MS",
        "published_year": "2000",
        "summary": "  Adaptive simulated annealing (ASA) is a global optimization algorithm based\non an associated proof that the parameter space can be sampled much more\nefficiently than by using other previous simulated annealing algorithms. The\nauthor's ASA code has been publicly available for over two years. During this\ntime the author has volunteered to help people via e-mail, and the feedback\nobtained has been used to further develop the code. Some lessons learned, in\nparticular some which are relevant to other simulated annealing algorithms, are\ndescribed.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0001018v1"
    },
    {
        "title": "Recursive function templates as a solution of linear algebra expressions\n  in C++",
        "authors": [
            "Volodymyr Myrnyy"
        ],
        "category": "cs.MS",
        "published_year": "2003",
        "summary": "  The article deals with a kind of recursive function templates in C++, where\nthe recursion is realized corresponding template parameters to achieve better\ncomputational performance. Some specialization of these template functions ends\nthe recursion and can be implemented using optimized hardware dependent or\nindependent routines. The method is applied in addition to the known expression\ntemplates technique to solve linear algebra expressions with the help of the\nBLAS library. The whole implementation produces a new library, which keeps\nobject-oriented benefits and has a higher computational speed represented in\nthe tests.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0302026v1"
    },
    {
        "title": "PURRS: Towards Computer Algebra Support for Fully Automatic Worst-Case\n  Complexity Analysis",
        "authors": [
            "Roberto Bagnara",
            "Andrea Pescetti",
            "Alessandro Zaccagnini",
            "Enea Zaffanella"
        ],
        "category": "cs.MS",
        "published_year": "2005",
        "summary": "  Fully automatic worst-case complexity analysis has a number of applications\nin computer-assisted program manipulation. A classical and powerful approach to\ncomplexity analysis consists in formally deriving, from the program syntax, a\nset of constraints expressing bounds on the resources required by the program,\nwhich are then solved, possibly applying safe approximations. In several\ninteresting cases, these constraints take the form of recurrence relations.\nWhile techniques for solving recurrences are known and implemented in several\ncomputer algebra systems, these do not completely fulfill the needs of fully\nautomatic complexity analysis: they only deal with a somewhat restricted class\nof recurrence relations, or sometimes require user intervention, or they are\nrestricted to the computation of exact solutions that are often so complex to\nbe unmanageable, and thus useless in practice. In this paper we briefly\ndescribe PURRS, a system and software library aimed at providing all the\ncomputer algebra services needed by applications performing or exploiting the\nresults of worst-case complexity analyses. The capabilities of the system are\nillustrated by means of examples derived from the analysis of programs written\nin a domain-specific functional programming language for real-time embedded\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0512056v1"
    },
    {
        "title": "A Basic Introduction on Math-Link in Mathematica",
        "authors": [
            "Santanu K. Maiti"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  Starting from the basic ideas of mathematica, we give a detailed description\nabout the way of linking of external programs with mathematica through proper\nmathlink commands. This article may be quite helpful for the beginners to start\nwith and write programs in mathematica.\n  In the first part, we illustrate how to use a mathemtica notebook and write a\ncomplete program in the notebook. Following with this, we also mention\nelaborately about the utility of the local and global variables those are very\nessential for writing a program in mathematica. All the commands needed for\ndoing different mathematical operations can be found with some proper examples\nin the mathematica book written by Stephen Wolfram \\cite{wolfram}.\n  In the rest of this article, we concentrate our study on the most significant\nissue which is the process of linking of {\\em external programs} with\nmathematica, so-called the mathlink operation. By using proper mathlink\ncommands one can run very tedious jobs efficiently and the operations become\nextremely fast.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603005v4"
    },
    {
        "title": "UniCalc.LIN: a linear constraint solver for the UniCalc system",
        "authors": [
            "E. Petrov",
            "Yu. Kostov",
            "E. Botoeva"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  In this short paper we present a linear constraint solver for the UniCalc\nsystem, an environment for reliable solution of mathematical modeling problems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0604038v1"
    },
    {
        "title": "Mathematica: A System of Computer Programs",
        "authors": [
            "Santanu K. Maiti"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  Starting from the basic level of mathematica here we illustrate how to use a\nmathematica notebook and write a program in the notebook. Next, we investigate\nelaborately the way of linking of external programs with mathematica, so-called\nthe mathlink operation. Using this technique we can run very tedious jobs quite\nefficiently, and the operations become extremely fast. Sometimes it is quite\ndesirable to run jobs in background of a computer which can take considerable\namount of time to finish, and this allows us to do work on other tasks, while\nkeeping the jobs running. The way of running jobs, written in a mathematica\nnotebook, in background is quite different from the conventional methods i.e.,\nthe techniques for the programs written in other languages like C, C++, F77,\nF90, F95, etc. To illustrate it, in the present article we study how to create\na mathematica batch-file from a mathematica notebook and run it in the\nbackground. Finally, we explore the most significant issue of this article.\nHere we describe the basic ideas for parallelizing a mathematica program by\nsharing its independent parts into all other remote computers available in the\nnetwork. Doing the parallelization, we can perform large computational\noperations within a very short period of time, and therefore, the efficiency of\nthe numerical works can be achieved. Parallel computation supports any version\nof mathematica and it also works significantly well even if different versions\nof mathematica are installed in different computers. All the operations studied\nin this article run under any supported operating system like Unix, Windows,\nMacintosh, etc. For the sake of our illustrations, here we concentrate all the\ndiscussions only for the Unix based operating system.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605090v4"
    },
    {
        "title": "Parallel Evaluation of Mathematica Programs in Remote Computers\n  Available in Network",
        "authors": [
            "Santanu K. Maiti"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  Mathematica is a powerful application package for doing mathematics and is\nused almost in all branches of science. It has widespread applications ranging\nfrom quantum computation, statistical analysis, number theory, zoology,\nastronomy, and many more. Mathematica gives a rich set of programming\nextensions to its end-user language, and it permits us to write programs in\nprocedural, functional, or logic (rule-based) style, or a mixture of all three.\nFor tasks requiring interfaces to the external environment, mathematica\nprovides mathlink, which allows us to communicate mathematica programs with\nexternal programs written in C, C++, F77, F90, F95, Java, or other languages.\nIt has also extensive capabilities for editing graphics, equations, text, etc.\n  In this article, we explore the basic mechanisms of parallelization of a\nmathematica program by sharing different parts of the program into all other\ncomputers available in the network. Doing the parallelization, we can perform\nlarge computational operations within a very short period of time, and\ntherefore, the efficiency of the numerical works can be achieved. Parallel\ncomputation supports any version of mathematica and it also works as well even\nif different versions of mathematica are installed in different computers. The\nwhole operation can run under any supported operating system like Unix,\nWindows, Macintosh, etc. Here we focus our study only for the Unix based\noperating system, but this method works as well for all other cases.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0606023v3"
    },
    {
        "title": "One approach to the digital visualization of hedgehogs in holomorphic\n  dynamics",
        "authors": [
            "Alessandro Rosa"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  In the field of holomorphic dynamics in one complex variable, hedgehog is the\nlocal invariant set arising about a Cremer point and endowed with a very\ncomplicate shape as well as relating to very weak numerical conditions. We give\na solution to the open problem of its digital visualization, featuring either a\ntime saving approach and a far-reaching insight.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0609129v2"
    },
    {
        "title": "Coupling Methodology within the Software Platform Alliances",
        "authors": [
            "Philippe Montarnal",
            "Alain Dimier",
            "Estelle Deville",
            "Erwan Adam",
            "Jérôme Gaombalet",
            "Alain Bengaouer",
            "Laurent Loth",
            "Clément Chavant"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  CEA, ANDRA and EDF are jointly developing the software platform ALLIANCES\nwhich aim is to produce a tool for the simulation of nuclear waste storage and\ndisposal repository. This type of simulations deals with highly coupled\nthermo-hydro-mechanical and chemical (T-H-M-C) processes. A key objective of\nAlliances is to give the capability for coupling algorithms development between\nexisting codes. The aim of this paper is to present coupling methodology use in\nthe context of this software platform.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0611127v1"
    },
    {
        "title": "The Parma Polyhedra Library: Toward a Complete Set of Numerical\n  Abstractions for the Analysis and Verification of Hardware and Software\n  Systems",
        "authors": [
            "Roberto Bagnara",
            "Patricia M. Hill",
            "Enea Zaffanella"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  Since its inception as a student project in 2001, initially just for the\nhandling (as the name implies) of convex polyhedra, the Parma Polyhedra Library\nhas been continuously improved and extended by joining scrupulous research on\nthe theoretical foundations of (possibly non-convex) numerical abstractions to\na total adherence to the best available practices in software development. Even\nthough it is still not fully mature and functionally complete, the Parma\nPolyhedra Library already offers a combination of functionality, reliability,\nusability and performance that is not matched by similar, freely available\nlibraries. In this paper, we present the main features of the current version\nof the library, emphasizing those that distinguish it from other similar\nlibraries and those that are important for applications in the field of\nanalysis and verification of hardware and software systems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0612085v1"
    },
    {
        "title": "Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in\n  hypre and PETSc",
        "authors": [
            "A. V. Knyazev",
            "M. E. Argentati",
            "I. Lashuk",
            "E. E. Ovtchinnikov"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  We describe our software package Block Locally Optimal Preconditioned\nEigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as\na stand-alone serial library, as an external package to PETSc (``Portable,\nExtensible Toolkit for Scientific Computation'', a general purpose suite of\ntools for the scalable solution of partial differential equations and related\nproblems developed by Argonne National Laboratory), and is also built into {\\it\nhypre} (``High Performance Preconditioners'', scalable linear solvers package\ndeveloped by Lawrence Livermore National Laboratory). The present BLOPEX\nrelease includes only one solver--the Locally Optimal Block Preconditioned\nConjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\\it\nhypre} provides users with advanced high-quality parallel preconditioners for\nlinear systems, in particular, with domain decomposition and multigrid\npreconditioners. With BLOPEX, the same preconditioners can now be efficiently\nused for symmetric eigenvalue problems. PETSc facilitates the integration of\nindependently developed application modules with strict attention to component\ninteroperability, and makes BLOPEX extremely easy to compile and use with\npreconditioners that are available via PETSc. We present the LOBPCG algorithm\nin BLOPEX for {\\it hypre} and PETSc. We demonstrate numerically the scalability\nof BLOPEX by testing it on a number of distributed and shared memory parallel\nsystems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron\nworkstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition\nand {\\it hypre} multigrid preconditioning. We test BLOPEX on a model problem,\nthe standard 7-point finite-difference approximation of the 3-D Laplacian, with\nthe problem size in the range $10^5-10^8$.\n",
        "pdf_link": "http://arxiv.org/pdf/0705.2626v1"
    },
    {
        "title": "Formally Verified Argument Reduction with a Fused-Multiply-Add",
        "authors": [
            "Sylvie Boldo",
            "Marc Daumas",
            "Ren Cang Li"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  Cody & Waite argument reduction technique works perfectly for reasonably\nlarge arguments but as the input grows there are no bit left to approximate the\nconstant with enough accuracy. Under mild assumptions, we show that the result\ncomputed with a fused-multiply-add provides a fully accurate result for many\npossible values of the input with a constant almost accurate to the full\nworking precision. We also present an algorithm for a fully accurate second\nreduction step to reach double full accuracy (all the significand bits of two\nnumbers are significant) even in the worst cases of argument reduction. Our\nwork recalls the common algorithms and presents proofs of correctness. All the\nproofs are formally verified using the Coq automatic proof checker.\n",
        "pdf_link": "http://arxiv.org/pdf/0708.3722v1"
    },
    {
        "title": "A Class of Parallel Tiled Linear Algebra Algorithms for Multicore\n  Architectures",
        "authors": [
            "Alfredo Buttari",
            "Julien Langou",
            "Jakub Kurzak",
            "Jack Dongarra"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  As multicore systems continue to gain ground in the High Performance\nComputing world, linear algebra algorithms have to be reformulated or new\nalgorithms have to be developed in order to take advantage of the architectural\nfeatures on these new processors. Fine grain parallelism becomes a major\nrequirement and introduces the necessity of loose synchronization in the\nparallel execution of an operation. This paper presents an algorithm for the\nCholesky, LU and QR factorization where the operations can be represented as a\nsequence of small tasks that operate on square blocks of data. These tasks can\nbe dynamically scheduled for execution based on the dependencies among them and\non the availability of computational resources. This may result in an out of\norder execution of the tasks which will completely hide the presence of\nintrinsically sequential tasks in the factorization. Performance comparisons\nare presented with the LAPACK algorithms where parallelism can only be\nexploited at the level of the BLAS operations and vendor implementations.\n",
        "pdf_link": "http://arxiv.org/pdf/0709.1272v3"
    },
    {
        "title": "Building the Tangent and Adjoint codes of the Ocean General Circulation\n  Model OPA with the Automatic Differentiation tool TAPENADE",
        "authors": [
            "Moulay Hicham Tber",
            "Laurent Hascoet",
            "Arthur Vidard",
            "Benjamin Dauvergne"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  The ocean general circulation model OPA is developed by the LODYC team at\nParis VI university. OPA has recently undergone a major rewriting, migrating to\nFORTRAN95, and its adjoint code needs to be rebuilt. For earlier versions, the\nadjoint of OPA was written by hand at a high development cost. We use the\nAutomatic Differentiation tool TAPENADE to build mechanicaly the tangent and\nadjoint codes of OPA. We validate the differentiated codes by comparison with\ndivided differences, and also with an identical twin experiment. We apply\nstate-of-the-art methods to improve the performance of the adjoint code. In\nparticular we implement the Griewank and Walther's binomial checkpointing\nalgorithm which gives us an optimal trade-off between time and memory\nconsumption. We apply a specific strategy to differentiate the iterative linear\nsolver that comes from the implicit time stepping scheme\n",
        "pdf_link": "http://arxiv.org/pdf/0711.4444v2"
    },
    {
        "title": "A Method for Solving Cyclic Block Penta-diagonal Systems of Linear\n  Equations",
        "authors": [
            "Milan Batista"
        ],
        "category": "cs.MS",
        "published_year": "2008",
        "summary": "  A method for solving cyclic block three-diagonal systems of equations is\ngeneralized for solving a block cyclic penta-diagonal system of equations.\nIntroducing a special form of two new variables the original system is split\ninto three block pentagonal systems, which can be solved by the known methods.\nAs such method belongs to class of direct methods without pivoting.\nImplementation of the algorithm is discussed in some details and the numerical\nexamples are present.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.0874v3"
    },
    {
        "title": "Geometric scaling: a simple preconditioner for certain linear systems\n  with discontinuous coefficients",
        "authors": [
            "Dan Gordon",
            "Rachel Gordon"
        ],
        "category": "cs.MS",
        "published_year": "2008",
        "summary": "  Linear systems with large differences between coefficients (\"discontinuous\ncoefficients\") arise in many cases in which partial differential\nequations(PDEs) model physical phenomena involving heterogeneous media. The\nstandard approach to solving such problems is to use domain decomposition\ntechniques, with domain boundaries conforming to the boundaries between the\ndifferent media. This approach can be difficult to implement when the geometry\nof the domain boundaries is complicated or the grid is unstructured. This work\nexamines the simple preconditioning technique of scaling the equations by\ndividing each equation by the Lp-norm of its coefficients. This preconditioning\nis called geometric scaling (GS). It has long been known that diagonal scaling\ncan be useful in improving convergence, but there is no study on the general\nusefulness of this approach for discontinuous coefficients. GS was tested on\nseveral nonsymmetric linear systems with discontinuous coefficients derived\nfrom convection-diffusion elliptic PDEs with small to moderate convection\nterms. It is shown that GS improved the convergence properties of restarted\nGMRES and Bi-CGSTAB, with and without the ILUT preconditioner. GS was also\nshown to improve the distribution of the eigenvalues by reducing their\nconcentration around the origin very significantly.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.2769v2"
    },
    {
        "title": "Fast solving of Weighted Pairing Least-Squares systems",
        "authors": [
            "Pierre Courrieu"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  This paper presents a generalization of the \"weighted least-squares\" (WLS),\nnamed \"weighted pairing least-squares\" (WPLS), which uses a rectangular weight\nmatrix and is suitable for data alignment problems. Two fast solving methods,\nsuitable for solving full rank systems as well as rank deficient systems, are\nstudied. Computational experiments clearly show that the best method, in terms\nof speed, accuracy, and numerical stability, is based on a special {1, 2,\n3}-inverse, whose computation reduces to a very simple generalization of the\nusual \"Cholesky factorization-backward substitution\" method for solving linear\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.1040v2"
    },
    {
        "title": "Automatic generation of non-uniform random variates for arbitrary\n  pointwise computable probability densities by tiling",
        "authors": [
            "Daniel Fulger",
            "Guido Germano"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  We present a rejection method based on recursive covering of the probability\ndensity function with equal tiles. The concept works for any probability\ndensity function that is pointwise computable or representable by tabular data.\nBy the implicit construction of piecewise constant majorizing and minorizing\nfunctions that are arbitrarily close to the density function the production of\nrandom variates is arbitrarily independent of the computation of the density\nfunction and extremely fast. The method works unattended for probability\ndensities with discontinuities (jumps and poles). The setup time is short,\nmarginally independent of the shape of the probability density and linear in\ntable size. Recently formulated requirements to a general and automatic\nnon-uniform random number generator are topped. We give benchmarks together\nwith a similar rejection method and with a transformation method.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.3088v1"
    },
    {
        "title": "Random numbers from the tails of probability distributions using the\n  transformation method",
        "authors": [
            "Daniel Fulger",
            "Enrico Scalas",
            "Guido Germano"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  The speed of many one-line transformation methods for the production of, for\nexample, Levy alpha-stable random numbers, which generalize Gaussian ones, and\nMittag-Leffler random numbers, which generalize exponential ones, is very high\nand satisfactory for most purposes. However, for the class of decreasing\nprobability densities fast rejection implementations like the Ziggurat by\nMarsaglia and Tsang promise a significant speed-up if it is possible to\ncomplement them with a method that samples the tails of the infinite support.\nThis requires the fast generation of random numbers greater or smaller than a\ncertain value. We present a method to achieve this, and also to generate random\nnumbers within any arbitrary interval. We demonstrate the method showing the\nproperties of the transform maps of the above mentioned distributions as\nexamples of stable and geometric stable random numbers used for the stochastic\nsolution of the space-time fractional diffusion equation.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.3207v1"
    },
    {
        "title": "Approximating Mathematical Semantic Web Services Using Approximation\n  Formulas and Numerical Methods",
        "authors": [
            "Andrei-Horia Mogos",
            "Mugurel Ionut Andreica"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  Mathematical semantic web services are very useful in practice, but only a\nsmall number of research results are reported in this area. In this paper we\npresent a method of obtaining an approximation of a mathematical semantic web\nservice, from its semantic description, using existing mathematical semantic\nweb services, approximation formulas, and numerical methods techniques. We also\ngive a method for automatic comparison of two complexity functions. In\naddition, we present a method for classifying the numerical methods\nmathematical semantic web services from a library.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.4888v1"
    },
    {
        "title": "Factorization of Non-Commutative Polynomials",
        "authors": [
            "Fabrizio Caruso"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  We describe an algorithm for the factorization of non-commutative polynomials\nover a field. The first sketch of this algorithm appeared in an unpublished\nmanuscript (literally hand written notes) by James H. Davenport more than 20\nyears ago. This version of the algorithm contains some improvements with\nrespect to the original sketch. An improved version of the algorithm has been\nfully implemented in the Axiom computer algebra system.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3180v1"
    },
    {
        "title": "Towards an Efficient Tile Matrix Inversion of Symmetric Positive\n  Definite Matrices on Multicore Architectures",
        "authors": [
            "Emmanuel Agullo",
            "Henricus Bouwmeester",
            "Jack Dongarra",
            "Jakub Kurzak",
            "Julien Langou",
            "Lee Rosenberg"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  The algorithms in the current sequential numerical linear algebra libraries\n(e.g. LAPACK) do not parallelize well on multicore architectures. A new family\nof algorithms, the tile algorithms, has recently been introduced. Previous\nresearch has shown that it is possible to write efficient and scalable tile\nalgorithms for performing a Cholesky factorization, a (pseudo) LU\nfactorization, and a QR factorization. In this extended abstract, we attack the\nproblem of the computation of the inverse of a symmetric positive definite\nmatrix. We observe that, using a dynamic task scheduler, it is relatively\npainless to translate existing LAPACK code to obtain a ready-to-be-executed\ntile algorithm. However we demonstrate that non trivial compiler techniques\n(array renaming, loop reversal and pipelining) need then to be applied to\nfurther increase the parallelism of our application. We present preliminary\nexperimental results.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.4057v1"
    },
    {
        "title": "Transferring a symbolic polynomial expression from \\emph{Mathematica} to\n  \\emph{Matlab}",
        "authors": [
            "A. Bret"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  A \\emph{Mathematica} Notebook is presented which allows for the transfer or\nany kind of polynomial expression to \\emph{Matlab}. The output is formatted in\nsuch a way that \\emph{Matlab} routines such as \"Root\" can be readily\nimplemented. Once the Notebook has been executed, only one copy-paste operation\nin necessary.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.4725v1"
    },
    {
        "title": "Some comments on C. S. Wallace's random number generators",
        "authors": [
            "Richard P. Brent"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  We outline some of Chris Wallace's contributions to pseudo-random number\ngeneration. In particular, we consider his idea for generating normally\ndistributed variates without relying on a source of uniform random numbers, and\ncompare it with more conventional methods for generating normal random numbers.\nImplementations of Wallace's idea can be very fast (approximately as fast as\ngood uniform generators). We discuss the statistical quality of the output, and\nmention how certain pitfalls can be avoided.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.2314v1"
    },
    {
        "title": "Making big steps in trajectories",
        "authors": [
            "Norbert Th. Müller",
            "Margarita Korovina"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  We consider the solution of initial value problems within the context of\nhybrid systems and emphasise the use of high precision approximations (in\nsoftware for exact real arithmetic). We propose a novel algorithm for the\ncomputation of trajectories up to the area where discontinuous jumps appear,\napplicable for holomorphic flow functions. Examples with a prototypical\nimplementation illustrate that the algorithm might provide results with higher\nprecision than well-known ODE solvers at a similar computation time.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0401v1"
    },
    {
        "title": "LSMR: An iterative algorithm for sparse least-squares problems",
        "authors": [
            "David Fong",
            "Michael Saunders"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  An iterative method LSMR is presented for solving linear systems $Ax=b$ and\nleast-squares problem $\\min \\norm{Ax-b}_2$, with $A$ being sparse or a fast\nlinear operator. LSMR is based on the Golub-Kahan bidiagonalization process. It\nis analytically equivalent to the MINRES method applied to the normal equation\n$A\\T Ax = A\\T b$, so that the quantities $\\norm{A\\T r_k}$ are monotonically\ndecreasing (where $r_k = b - Ax_k$ is the residual for the current iterate\n$x_k$). In practice we observe that $\\norm{r_k}$ also decreases monotonically.\nCompared to LSQR, for which only $\\norm{r_k}$ is monotonic, it is safer to\nterminate LSMR early. Improvements for the new iterative method in the presence\nof extra available memory are also explored.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0758v2"
    },
    {
        "title": "Simulation of Self-Assembly in the Abstract Tile Assembly Model with ISU\n  TAS",
        "authors": [
            "Matthew J. Patitz"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  Since its introduction by Erik Winfree in 1998, the abstract Tile Assembly\nModel (aTAM) has inspired a wealth of research. As an abstract model for tile\nbased self-assembly, it has proven to be remarkably powerful and expressive in\nterms of the structures which can self-assemble within it. As research has\nprogressed in the aTAM, the self-assembling structures being studied have\nbecome progressively more complex. This increasing complexity, along with a\nneed for standardization of definitions and tools among researchers, motivated\nthe development of the Iowa State University Tile Assembly Simulator (ISU TAS).\nISU TAS is a graphical simulator and tile set editor for designing and building\n2-D and 3-D aTAM tile assembly systems and simulating their self-assembly. This\npaper reviews the features and functionality of ISU TAS and describes how it\ncan be used to further research into the complexities of the aTAM. Software and\nsource code are available at http://www.cs.iastate.edu/~lnsa.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.5151v1"
    },
    {
        "title": "Quantum Anticipation Explorer",
        "authors": [
            "Hans-Rudolf Thomann"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  Quantum anticipation explorer is a computer program allowing the numerical\nexploration of quantum anticipation which has been analyzed in arXiv:0810.183v1\nand arXiv:1003.1090v1 for H-Atom, equidistant, random and custom spectra. This\ntool determines the anticipation strength at those times orthogonal evolution\nis possible. This paper is the user's guide explaining its capabilities,\ninstallation and usage, and documenting the mathematics and algorithms\nimplemented in the software. A zip file containing the setup and documentation\ncan be downloaded from\nhttp://www.thomannconsulting.ch/public/aboutus/aboutus-en.htm free of cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.3774v1"
    },
    {
        "title": "Finite Element Integration on GPUs",
        "authors": [
            "Matthew G. Knepley",
            "Andy R. Terrel"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  We present a novel finite element integration method for low order elements\non GPUs. We achieve more than 100GF for element integration on first order\ndiscretizations of both the Laplacian and Elasticity operators.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.0066v1"
    },
    {
        "title": "Data sets of very large linear feasibility problems solved by projection\n  methods",
        "authors": [
            "Wei Chen"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  We give a link to a page on the Web on which we deposited a set of eight huge\nLinear Programming (LP) problems for Intensity-Modulated Proton Therapy (IMPT)\ntreatment planning. These huge LP problems were employed in our recent research\nand we were asked to make them public.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.2952v1"
    },
    {
        "title": "A study of the existing linear algebra libraries that you can use from\n  C++ (Une étude des bibliothèques d'algèbre linéaire utilisables en\n  C++)",
        "authors": [
            "Claire Mouton"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  A study of the existing linear algebra libraries that you can use from C++\n",
        "pdf_link": "http://arxiv.org/pdf/1103.3020v1"
    },
    {
        "title": "DOLFIN: Automated Finite Element Computing",
        "authors": [
            "Anders Logg",
            "Garth N. Wells"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  We describe here a library aimed at automating the solution of partial\ndifferential equations using the finite element method. By employing novel\ntechniques for automated code generation, the library combines a high level of\nexpressiveness with efficient computation. Finite element variational forms may\nbe expressed in near mathematical notation, from which low-level code is\nautomatically generated, compiled and seamlessly integrated with efficient\nimplementations of computational meshes and high-performance linear algebra.\nEasy-to-use object-oriented interfaces to the library are provided in the form\nof a C++ library and a Python module. This paper discusses the mathematical\nabstractions and methods used in the design of the library and its\nimplementation. A number of examples are presented to demonstrate the use of\nthe library in application code.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.6248v1"
    },
    {
        "title": "Throughput-Distortion Computation Of Generic Matrix Multiplication:\n  Toward A Computation Channel For Digital Signal Processing Systems",
        "authors": [
            "Davide Anastasia",
            "Yiannis Andreopoulos"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  The generic matrix multiply (GEMM) function is the core element of\nhigh-performance linear algebra libraries used in many\ncomputationally-demanding digital signal processing (DSP) systems. We propose\nan acceleration technique for GEMM based on dynamically adjusting the\nimprecision (distortion) of computation. Our technique employs adaptive scalar\ncompanding and rounding to input matrix blocks followed by two forms of packing\nin floating-point that allow for concurrent calculation of multiple results.\nSince the adaptive companding process controls the increase of concurrency (via\npacking), the increase in processing throughput (and the corresponding increase\nin distortion) depends on the input data statistics. To demonstrate this, we\nderive the optimal throughput-distortion control framework for GEMM for the\nbroad class of zero-mean, independent identically distributed, input sources.\nOur approach converts matrix multiplication in programmable processors into a\ncomputation channel: when increasing the processing throughput, the output\nnoise (error) increases due to (i) coarser quantization and (ii) computational\nerrors caused by exceeding the machine-precision limitations. We show that,\nunder certain distortion in the GEMM computation, the proposed framework can\nsignificantly surpass 100% of the peak performance of a given processor. The\npractical benefits of our proposal are shown in a face recognition system and a\nmulti-layer perceptron system trained for metadata learning from a large music\nfeature database.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.5765v1"
    },
    {
        "title": "A multiprecision matrix calculation library and its extension library\n  for a matrix-product-state simulation of quantum computing",
        "authors": [
            "Akira SaiToh"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  A C++ library, named ZKCM, has been developed for the purpose of\nmultiprecision matrix calculations, which is based on the GNU MP and MPFR\nlibraries. It is especially convenient for writing programs involving\ntensor-product operations, tracing-out operations, and singular-value\ndecompositions. Its extension library, ZKCM_QC, for simulating quantum\ncomputing has been developed using the time-dependent matrix-product-state\nsimulation method. This report gives a brief introduction to the libraries with\nsample programs.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.3124v1"
    },
    {
        "title": "Efficient Dense Gaussian Elimination over the Finite Field with Two\n  Elements",
        "authors": [
            "Martin R. Albrecht",
            "Gregory V. Bard",
            "Clément Pernet"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  In this work we describe an efficient implementation of a hierarchy of\nalgorithms for Gaussian elimination upon dense matrices over the field with two\nelements. We discuss both well-known and new algorithms as well as our\nimplementations in the M4RI library, which has been adopted into Sage. The\nfocus of our discussion is a block iterative algorithm for PLE decomposition\nwhich is inspired by the M4RI algorithm. The implementation presented in this\nwork provides considerable performance gains in practice when compared to the\npreviously fastest implementation. We provide performance figures on x86_64\nCPUs to demonstrate the alacrity of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.6549v1"
    },
    {
        "title": "Rank-profile revealing Gaussian elimination and the CUP matrix\n  decomposition",
        "authors": [
            "Claude-Pierre Jeannerod",
            "Clément Pernet",
            "Arne Storjohann"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  Transforming a matrix over a field to echelon form, or decomposing the matrix\nas a product of structured matrices that reveal the rank profile, is a\nfundamental building block of computational exact linear algebra. This paper\nsurveys the well known variations of such decompositions and transformations\nthat have been proposed in the literature. We present an algorithm to compute\nthe CUP decomposition of a matrix, adapted from the LSP algorithm of Ibarra,\nMoran and Hui (1982), and show reductions from the other most common Gaussian\nelimination based matrix transformations and decompositions to the CUP\ndecomposition. We discuss the advantages of the CUP algorithm over other\nexisting algorithms by studying time and space complexities: the asymptotic\ntime complexity is rank sensitive, and comparing the constants of the leading\nterms, the algorithms for computing matrix invariants based on the CUP\ndecomposition are always at least as good except in one case. We also show that\nthe CUP algorithm, as well as the computation of other invariants such as\ntransformation to reduced column echelon form using the CUP algorithm, all work\nin place, allowing for example to compute the inverse of a matrix on the same\nstorage as the input matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.5717v2"
    },
    {
        "title": "Singular Values using Cholesky Decomposition",
        "authors": [
            "Aravindh Krishnamoorthy",
            "Kenan Kocagoez"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In this paper two ways to compute singular values are presented which use\nCholesky decomposition as their basic operation.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.1490v1"
    },
    {
        "title": "Automatic Deduction in Dynamic Geometry using Sage",
        "authors": [
            "Francisco Botana",
            "Miguel A. Abánades"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  We present a symbolic tool that provides robust algebraic methods to handle\nautomatic deduction tasks for a dynamic geometry construction. The main\nprototype has been developed as two different worksheets for the open source\ncomputer algebra system Sage, corresponding to two different ways of coding a\ngeometric construction. In one worksheet, diagrams constructed with the open\nsource dynamic geometry system GeoGebra are accepted. In this worksheet,\nGroebner bases are used to either compute the equation of a geometric locus in\nthe case of a locus construction or to determine the truth of a general\ngeometric statement included in the GeoGebra construction as a boolean\nvariable. In the second worksheet, locus constructions coded using the common\nfile format for dynamic geometry developed by the Intergeo project are accepted\nfor computation. The prototype and several examples are provided for testing.\nMoreover, a third Sage worksheet is presented in which a novel algorithm to\neliminate extraneous parts in symbolically computed loci has been implemented.\nThe algorithm, based on a recent work on the Groebner cover of parametric\nsystems, identifies degenerate components and extraneous adherence points in\nloci, both natural byproducts of general polynomial algebraic methods. Detailed\nexamples are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.4830v1"
    },
    {
        "title": "The GF Mathematics Library",
        "authors": [
            "Jordi Saludes",
            "Sebastian Xambó"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  This paper is devoted to present the Mathematics Grammar Library, a system\nfor multilingual mathematical text processing. We explain the context in which\nit originated, its current design and functionality and the current development\ngoals. We also present two prototype services and comment on possible future\napplications in the area of artificial mathematics assistants.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.4837v1"
    },
    {
        "title": "Can the Eureqa symbolic regression program, computer algebra and\n  numerical analysis help each other?",
        "authors": [
            "David R. Stoutemyer"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  The Eureqa symbolic regression program has recently received extensive press\npraise. A representative quote is\n  \"There are very clever 'thinking machines' in existence today, such as\nWatson, the IBM computer that conquered Jeopardy! last year. But next to\nEureqa, Watson is merely a glorified search engine.\"\n  The program was designed to work with noisy experimental data. However, if\nthe data is generated from an expression for which there exists more concise\nequivalent expressions, sometimes some of the Eureqa results are one or more of\nthose more concise equivalents. If not, perhaps one or more of the returned\nEureqa results might be a sufficiently accurate approximation that is more\nconcise than the given expression. Moreover, when there is no known closed form\nexpression, the data points can be generated by numerical methods, enabling\nEureqa to find expressions that concisely fit those data points with sufficient\naccuracy. In contrast to typical regression software, the user does not have to\nexplicitly or implicitly provide a specific expression or class of expressions\ncontainiing unknown constants for the software to determine.\n  Is Eureqa useful enough in these regards to provide an additional tool for\nexperimental mathematics, computer algebra users and numerical analysis? Yes if\nused carefully. Can computer algebra and numerical methods help Eureqa?\nDefinitely.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.1023v1"
    },
    {
        "title": "Scilab and SIP for Image Processing",
        "authors": [
            "Ricardo Fabbri",
            "Odemir Martinez Bruno",
            "Luciano da Fontoura Costa"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  This paper is an overview of Image Processing and Analysis using Scilab, a\nfree prototyping environment for numerical calculations similar to Matlab. We\ndemonstrate the capabilities of SIP -- the Scilab Image Processing Toolbox --\nwhich extends Scilab with many functions to read and write images in over 100\nmajor file formats, including PNG, JPEG, BMP, and TIFF. It also provides\nroutines for image filtering, edge detection, blurring, segmentation, shape\nanalysis, and image recognition. Basic directions to install Scilab and SIP are\ngiven, and also a mini-tutorial on Scilab. Three practical examples of image\nanalysis are presented, in increasing degrees of complexity, showing how\nadvanced image analysis techniques seems uncomplicated in this environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.4009v1"
    },
    {
        "title": "Block-Structured Adaptive Mesh Refinement Algorithms for Vlasov\n  Simulation",
        "authors": [
            "J. A. F. Hittinger",
            "J. W. Banks"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Direct discretization of continuum kinetic equations, like the Vlasov\nequation, are under-utilized because the distribution function generally exists\nin a high-dimensional (>3D) space and computational cost increases\ngeometrically with dimension. We propose to use high-order finite-volume\ntechniques with block-structured adaptive mesh refinement (AMR) to reduce the\ncomputational cost. The primary complication comes from a solution state\ncomprised of variables of different dimensions. We develop the algorithms\nrequired to extend standard single-dimension block structured AMR to the\nmulti-dimension case. Specifically, algorithms for reduction and injection\noperations that transfer data between mesh hierarchies of different dimensions\nare explained in detail. In addition, modifications to the basic AMR algorithm\nthat enable the use of high-order spatial and temporal discretizations are\ndiscussed. Preliminary results for a standard 1D+1V Vlasov-Poisson test problem\nare presented. Results indicate that there is potential for significant savings\nfor some classes of Vlasov problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3853v2"
    },
    {
        "title": "Automating embedded analysis capabilities and managing software\n  complexity in multiphysics simulation part I: template-based generic\n  programming",
        "authors": [
            "Roger P. Pawlowski",
            "Eric T. Phipps",
            "Andrew G. Salinger"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  An approach for incorporating embedded simulation and analysis capabilities\nin complex simulation codes through template-based generic programming is\npresented. This approach relies on templating and operator overloading within\nthe C++ language to transform a given calculation into one that can compute a\nvariety of additional quantities that are necessary for many state-of-the-art\nsimulation and analysis algorithms. An approach for incorporating these ideas\ninto complex simulation codes through general graph-based assembly is also\npresented. These ideas have been implemented within a set of packages in the\nTrilinos framework and are demonstrated on a simple problem from chemical\nengineering.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.0790v2"
    },
    {
        "title": "High-Performance Solvers for Dense Hermitian Eigenproblems",
        "authors": [
            "Matthias Petschow",
            "Elmar Peise",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  We introduce a new collection of solvers - subsequently called EleMRRR - for\nlarge-scale dense Hermitian eigenproblems. EleMRRR solves various types of\nproblems: generalized, standard, and tridiagonal eigenproblems. Among these,\nthe last is of particular importance as it is a solver on its own right, as\nwell as the computational kernel for the first two; we present a fast and\nscalable tridiagonal solver based on the Algorithm of Multiple Relatively\nRobust Representations - referred to as PMRRR. Like the other EleMRRR solvers,\nPMRRR is part of the freely available Elemental library, and is designed to\nfully support both message-passing (MPI) and multithreading parallelism (SMP).\nAs a result, the solvers can equally be used in pure MPI or in hybrid MPI-SMP\nfashion. We conducted a thorough performance study of EleMRRR and ScaLAPACK's\nsolvers on two supercomputers. Such a study, performed with up to 8,192 cores,\nprovides precise guidelines to assemble the fastest solver within the ScaLAPACK\nframework; it also indicates that EleMRRR outperforms even the fastest solvers\nbuilt from ScaLAPACK's components.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.2107v2"
    },
    {
        "title": "Efficient Expression Templates for Operator Overloading-based Automatic\n  Differentiation",
        "authors": [
            "Eric Phipps",
            "Roger Pawlowski"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Expression templates are a well-known set of techniques for improving the\nefficiency of operator overloading-based forward mode automatic differentiation\nschemes in the C++ programming language by translating the differentiation from\nindividual operators to whole expressions. However standard expression template\napproaches result in a large amount of duplicate computation, particularly for\nlarge expression trees, degrading their performance. In this paper we describe\nseveral techniques for improving the efficiency of expression templates and\ntheir implementation in the automatic differentiation package Sacado. We\ndemonstrate their improved efficiency through test functions as well as their\napplication to differentiation of a large-scale fluid dynamics simulation code.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.3506v1"
    },
    {
        "title": "Automating embedded analysis capabilities and managing software\n  complexity in multiphysics simulation part II: application to partial\n  differential equations",
        "authors": [
            "Roger P. Pawlowski",
            "Eric T. Phipps",
            "Andrew G. Salinger",
            "Steven J. Owen",
            "Christopher M. Siefert",
            "Matthew L. Staten"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  A template-based generic programming approach was presented in a previous\npaper that separates the development effort of programming a physical model\nfrom that of computing additional quantities, such as derivatives, needed for\nembedded analysis algorithms. In this paper, we describe the implementation\ndetails for using the template-based generic programming approach for\nsimulation and analysis of partial differential equations (PDEs). We detail\nseveral of the hurdles that we have encountered, and some of the software\ninfrastructure developed to overcome them. We end with a demonstration where we\npresent shape optimization and uncertainty quantification results for a 3D PDE\napplication.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.3952v1"
    },
    {
        "title": "Sample programs in C++ for matrix computations in max plus algebra",
        "authors": [
            "Mihai Ivan",
            "Gheorghe Ivan"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  The main purpose of this paper is to propose five programs in C++ for matrix\ncomputations and solving recurrent equations systems with entries in max plus\nalgebra.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.4212v1"
    },
    {
        "title": "How good are MatLab, Octave and Scilab for Computational Modelling?",
        "authors": [
            "Eliana S. de Almeida",
            "Antonio C. Medeiros",
            "Alejandro C. Frery"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In this article we test the accuracy of three platforms used in computational\nmodelling: MatLab, Octave and Scilab, running on i386 architecture and three\noperating systems (Windows, Ubuntu and Mac OS). We submitted them to numerical\ntests using standard data sets and using the functions provided by each\nplatform. A Monte Carlo study was conducted in some of the datasets in order to\nverify the stability of the results with respect to small departures from the\noriginal input. We propose a set of operations which include the computation of\nmatrix determinants and eigenvalues, whose results are known. We also used data\nprovided by NIST (National Institute of Standards and Technology), a protocol\nwhich includes the computation of basic univariate statistics (mean, standard\ndeviation and first-lag correlation), linear regression and extremes of\nprobability distributions. The assessment was made comparing the results\ncomputed by the platforms with certified values, that is, known results,\ncomputing the number of correct significant digits.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.1916v1"
    },
    {
        "title": "On Formal Specification of Maple Programs",
        "authors": [
            "Muhammad Taimoor Khan",
            "Wolfgang Schreiner"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  This paper is an example-based demonstration of our initial results on the\nformal specification of programs written in the computer algebra language\nMiniMaple (a substantial subset of Maple with slight extensions). The main goal\nof this work is to define a verification framework for MiniMaple. Formal\nspecification of MiniMaple programs is rather complex task as it supports\nnon-standard types of objects, e.g. symbols and unevaluated expressions, and\nadditional functions and predicates, e.g. runtime type tests etc. We have used\nthe specification language to specify various computer algebra concepts\nrespective objects of the Maple package DifferenceDifferential developed at our\ninstitute.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.2291v1"
    },
    {
        "title": "Best Practices for Scientific Computing",
        "authors": [
            "Greg Wilson",
            "D. A. Aruliah",
            "C. Titus Brown",
            "Neil P. Chue Hong",
            "Matt Davis",
            "Richard T. Guy",
            "Steven H. D. Haddock",
            "Katy Huff",
            "Ian M. Mitchell",
            "Mark Plumbley",
            "Ben Waugh",
            "Ethan P. White",
            "Paul Wilson"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Scientists spend an increasing amount of time building and using software.\nHowever, most scientists are never taught how to do this efficiently. As a\nresult, many are unaware of tools and practices that would allow them to write\nmore reliable and maintainable code with less effort. We describe a set of best\npractices for scientific software development that have solid foundations in\nresearch and experience, and that improve scientists' productivity and the\nreliability of their software.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.0530v4"
    },
    {
        "title": "SMAT: An Input Adaptive Sparse Matrix-Vector Multiplication Auto-Tuner",
        "authors": [
            "Jiajia Li",
            "Xiuxia Zhang",
            "Guangming Tan",
            "Mingyu Chen"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Sparse matrix vector multiplication (SpMV) is an important kernel in\nscientific and engineering applications. The previous optimizations are sparse\nmatrix format specific and expose the choice of the best format to application\nprogrammers. In this work we develop an auto-tuning framework to bridge gap\nbetween the specific optimized kernels and their general-purpose use. We\npropose an SpMV auto-tuner (SMAT) that provides an unified interface based on\ncompressed sparse row (CSR) to programmers by implicitly choosing the best\nformat and the fastest implementation of any input sparse matrix in runtime.\nSMAT leverage a data mining model, which is formulated based on a set of\nperformance parameters extracted from 2373 matrices in UF sparse matrix\ncollection, to fast search the best combination. The experiments show that SMAT\nachieves the maximum performance of 75 GFLOP/s in single-precision and 33\nGFLOP/s in double-precision on Intel, and 41 GFLOP/s in single-precision and 34\nGFLOP/s in double-precision on AMD. Compared with the sparse functions in MKL\nlibrary, SMAT runs faster by more than 3 times.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2536v1"
    },
    {
        "title": "A Robust Complex Division in Scilab",
        "authors": [
            "Michael Baudin",
            "Robert L. Smith"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  The most widely used algorithm for floating point complex division, known as\nSmith's method, may fail more often than expected. This document presents two\nimproved complex division algorithms. We present a proof of the robustness of\nthe first improved algorithm. Numerical simulations show that this algorithm\nperforms well in practice and is significantly more robust than other known\nimplementations. By combining additionnal scaling methods with this first\nalgorithm, we were able to create a second algorithm, which rarely fails.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.4539v2"
    },
    {
        "title": "High-Order Discontinuous Galerkin Methods by GPU Metaprogramming",
        "authors": [
            "Andreas Klöckner",
            "Timothy Warburton",
            "Jan S. Hesthaven"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Discontinuous Galerkin (DG) methods for the numerical solution of partial\ndifferential equations have enjoyed considerable success because they are both\nflexible and robust: They allow arbitrary unstructured geometries and easy\ncontrol of accuracy without compromising simulation stability. In a recent\npublication, we have shown that DG methods also adapt readily to execution on\nmodern, massively parallel graphics processors (GPUs). A number of qualities of\nthe method contribute to this suitability, reaching from locality of reference,\nthrough regularity of access patterns, to high arithmetic intensity. In this\narticle, we illuminate a few of the more practical aspects of bringing DG onto\na GPU, including the use of a Python-based metaprogramming infrastructure that\nwas created specifically to support DG, but has found many uses across all\ndisciplines of computational science.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.0582v1"
    },
    {
        "title": "Parallel Algorithms for Constructing Data Structures for Fast Multipole\n  Methods",
        "authors": [
            "Qi Hu",
            "Nail A. Gumerov",
            "Ramani Duraiswami"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We present efficient algorithms to build data structures and the lists needed\nfor fast multipole methods. The algorithms are capable of being efficiently\nimplemented on both serial, data parallel GPU and on distributed architectures.\nWith these algorithms it is possible to map the FMM efficiently on to the GPU\nor distributed heterogeneous CPU-GPU systems. Further, in dynamic problems, as\nthe distribution of the particles change, the reduced cost of building the data\nstructures improves performance. Using these algorithms, we demonstrate example\nhigh fidelity simulations with large problem sizes by using FMM on both single\nand multiple heterogeneous computing facilities equipped with multi-core CPU\nand many-core GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.1704v1"
    },
    {
        "title": "Solving Wave Equations on Unstructured Geometries",
        "authors": [
            "Andreas Klöckner",
            "Timothy Warburton",
            "Jan S. Hesthaven"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Waves are all around us--be it in the form of sound, electromagnetic\nradiation, water waves, or earthquakes. Their study is an important basic tool\nacross engineering and science disciplines. Every wave solver serving the\ncomputational study of waves meets a trade-off of two figures of merit--its\ncomputational speed and its accuracy. Discontinuous Galerkin (DG) methods fall\non the high-accuracy end of this spectrum. Fortuitously, their computational\nstructure is so ideally suited to GPUs that they also achieve very high\ncomputational speeds. In other words, the use of DG methods on GPUs\nsignificantly lowers the cost of obtaining accurate solutions. This article\naims to give the reader an easy on-ramp to the use of this technology, based on\na sample implementation which demonstrates a highly accurate, GPU-capable,\nreal-time visualizing finite element solver in about 1500 lines of code.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5546v1"
    },
    {
        "title": "Minimal Residual Methods for Complex Symmetric, Skew Symmetric, and Skew\n  Hermitian Systems",
        "authors": [
            " Sou-Cheng",
            " Choi"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  While there is no lack of efficient Krylov subspace solvers for Hermitian\nsystems, there are few for complex symmetric, skew symmetric, or skew Hermitian\nsystems, which are increasingly important in modern applications including\nquantum dynamics, electromagnetics, and power systems. For a large consistent\ncomplex symmetric system, one may apply a non-Hermitian Krylov subspace method\ndisregarding the symmetry of $A$, or a Hermitian Krylov solver on the\nequivalent normal equation or an augmented system twice the original dimension.\nThese have the disadvantages of increasing either memory, conditioning, or\ncomputational costs. An exception is a special version of QMR by Freund (1992),\nbut that may be affected by non-benign breakdowns unless look-ahead is\nimplemented; furthermore, it is designed for only consistent and nonsingular\nproblems. For skew symmetric systems, Greif and Varah (2009) adapted CG for\nnonsingular skew symmetric linear systems that are necessarily and\nrestrictively of even order.\n  We extend the symmetric and Hermitian algorithms MINRES and MINRES-QLP by\nChoi, Paige and Saunders (2011) to complex symmetric, skew symmetric, and skew\nHermitian systems. In particular, MINRES-QLP uses a rank-revealing QLP\ndecomposition of the tridiagonal matrix from a three-term recurrent\ncomplex-symmetric Lanczos process. Whether the systems are real or complex,\nsingular or invertible, compatible or inconsistent, MINRES-QLP computes the\nunique minimum-length, i.e., pseudoinverse, solutions. It is a significant\nextension of MINRES by Paige and Saunders (1975) with enhanced stability and\ncapability.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.6782v2"
    },
    {
        "title": "Understanding Branch Cuts of Expressions",
        "authors": [
            "Matthew England",
            "Russell Bradford",
            "James H. Davenport",
            "David Wilson"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We assume some standard choices for the branch cuts of a group of functions\nand consider the problem of then calculating the branch cuts of expressions\ninvolving those functions. Typical examples include the addition formulae for\ninverse trigonometric functions. Understanding these cuts is essential for\nworking with the single-valued counterparts, the common approach to encoding\nmulti-valued functions in computer algebra systems. While the defining choices\nare usually simple (typically portions of either the real or imaginary axes)\nthe cuts induced by the expression may be surprisingly complicated. We have\nmade explicit and implemented techniques for calculating the cuts in the\ncomputer algebra programme Maple. We discuss the issues raised, classifying the\ndifferent cuts produced. The techniques have been gathered in the BranchCuts\npackage, along with tools for visualising the cuts. The package is included in\nMaple 17 as part of the FunctionAdvisor tool.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7223v3"
    },
    {
        "title": "Achieving High Performance with Unified Residual Evaluation",
        "authors": [
            "Matthew G. Knepley",
            "Jed Brown",
            "Karl Rupp",
            "Barry F. Smith"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We examine residual evaluation, perhaps the most basic operation in numerical\nsimulation. By raising the level of abstraction in this operation, we can\neliminate specialized code, enable optimization, and greatly increase the\nextensibility of existing code.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.1204v2"
    },
    {
        "title": "DUNE as an Example of Sustainable Open Source Scientific Software\n  Development",
        "authors": [
            "Makus Blatt"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  In this paper we describe how DUNE, an open source scientific software\nframework, is developed. Having a sustainable software framework for the\nsolution of partial differential equations is the main driver of DUNE's\ndevelopment. We take a look how DUNE strives to stay sustainable software.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.1783v2"
    },
    {
        "title": "Computation of the Marcum Q-function",
        "authors": [
            "A. Gil",
            "J. Segura",
            "N. M. Temme"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Methods and an algorithm for computing the generalized Marcum $Q-$function\n($Q_{\\mu}(x,y)$) and the complementary function ($P_{\\mu}(x,y)$) are described.\nThese functions appear in problems of different technical and scientific areas\nsuch as, for example, radar detection and communications, statistics and\nprobability theory, where they are called the non-central chi-square or the non\ncentral gamma cumulative distribution functions.\n  The algorithm for computing the Marcum functions combines different methods\nof evaluation in different regions: series expansions, integral\nrepresentations, asymptotic expansions, and use of three-term homogeneous\nrecurrence relations. A relative accuracy close to $10^{-12}$ can be obtained\nin the parameter region $(x,y,\\mu) \\in [0,\\,A]\\times [0,\\,A]\\times [1,\\,A]$,\n$A=200$, while for larger parameters the accuracy decreases (close to\n$10^{-11}$ for $A=1000$ and close to $5\\times 10^{-11}$ for $A=10000$).\n",
        "pdf_link": "http://arxiv.org/pdf/1311.0681v1"
    },
    {
        "title": "Toward Resilient Algorithms and Applications",
        "authors": [
            "Michael A. Heroux"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Over the past decade, the high performance computing community has become\nincreasingly concerned that preserving the reliable, digital machine model will\nbecome too costly or infeasible. In this paper we discuss four approaches for\ndeveloping new algorithms that are resilient to hard and soft failures.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3809v2"
    },
    {
        "title": "Matrix Methods for Solving Algebraic Systems",
        "authors": [
            "Ioannis Z. Emiris"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We present our public-domain software for the following tasks in sparse (or\ntoric) elimination theory, given a well-constrained polynomial system. First, C\ncode for computing the mixed volume of the system. Second, Maple code for\ndefining an overconstrained system and constructing a Sylvester-type matrix of\nits sparse resultant. Third, C code for a Sylvester-type matrix of the sparse\nresultant and a superset of all common roots of the initial well-constrained\nsystem by computing the eigen-decomposition of a square matrix obtained from\nthe resultant matrix. We conclude with experiments in computing molecular\nconformations.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.1140v1"
    },
    {
        "title": "A SageTeX Hypermatrix Algebra Package",
        "authors": [
            "Edinah K. Gnang",
            "Ori Parzanchevski",
            "Yuval Filmus"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We describe here a rudimentary sage implementation of the Bhattacharya-Mesner\nhypermatrix algebra package.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.2630v1"
    },
    {
        "title": "Using RngStreams for Parallel Random Number Generation in C++ and R",
        "authors": [
            "Andrew T. Karl",
            "Randy Eubank",
            "Jelena Milovanovic",
            "Mark Reiser",
            "Dennis Young"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The RngStreams software package provides one viable solution to the problem\nof creating independent random number streams for simulations in parallel\nprocessing environments. Techniques are presented for effectively using\nRngStreams with C++ programs that are parallelized via OpenMP or MPI. Ways to\naccess the backbone generator from RngStreams in R through the parallel and\nrstream packages are also described. The ideas in the paper are illustrated\nwith both a simple running example and a Monte Carlo integration application.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.7645v1"
    },
    {
        "title": "ViDaExpert: user-friendly tool for nonlinear visualization and analysis\n  of multidimensional vectorial data",
        "authors": [
            "Alexander N. Gorban",
            "Alexander Pitenko",
            "Andrei Zinovyev"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  ViDaExpert is a tool for visualization and analysis of multidimensional\nvectorial data. ViDaExpert is able to work with data tables of \"object-feature\"\ntype that might contain numerical feature values as well as textual labels for\nrows (objects) and columns (features). ViDaExpert implements several\nstatistical methods such as standard and weighted Principal Component Analysis\n(PCA) and the method of elastic maps (non-linear version of PCA), Linear\nDiscriminant Analysis (LDA), multilinear regression, K-Means clustering, a\nvariant of decision tree construction algorithm. Equipped with several\nuser-friendly dialogs for configuring data point representations (size, shape,\ncolor) and fast 3D viewer, ViDaExpert is a handy tool allowing to construct an\ninteractive 3D-scene representing a table of data in multidimensional space and\nperform its quick and insightfull statistical analysis, from basic to advanced\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.5550v2"
    },
    {
        "title": "Software for Computing the Spheroidal Wave Functions Using Arbitrary\n  Precision Arithmetic",
        "authors": [
            "Ross Adelman",
            "Nail A. Gumerov",
            "Ramani Duraiswami"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The spheroidal wave functions, which are the solutions to the Helmholtz\nequation in spheroidal coordinates, are notoriously difficult to compute.\nBecause of this, practically no programming language comes equipped with the\nmeans to compute them. This makes problems that require their use hard to\ntackle. We have developed computational software for calculating these special\nfunctions. Our software is called spheroidal and includes several novel\nfeatures, such as: using arbitrary precision arithmetic; adaptively choosing\nthe number of expansion coefficients to compute and use; and using the\nWronskian to choose from several different methods for computing the spheroidal\nradial functions to improve their accuracy. There are two types of spheroidal\nwave functions: the prolate kind when prolate spheroidal coordinates are used;\nand the oblate kind when oblate spheroidal coordinate are used. In this paper,\nwe describe both, methods for computing them, and our software. We have made\nour software freely available on our webpage.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.0074v1"
    },
    {
        "title": "GPTIPS 2: an open-source software platform for symbolic data mining",
        "authors": [
            "Dominic P. Searson"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  GPTIPS is a free, open source MATLAB based software platform for symbolic\ndata mining (SDM). It uses a multigene variant of the biologically inspired\nmachine learning method of genetic programming (MGGP) as the engine that drives\nthe automatic model discovery process. Symbolic data mining is the process of\nextracting hidden, meaningful relationships from data in the form of symbolic\nequations. In contrast to other data-mining methods, the structural\ntransparency of the generated predictive equations can give new insights into\nthe physical systems or processes that generated the data. Furthermore, this\ntransparency makes the models very easy to deploy outside of MATLAB. The\nrationale behind GPTIPS is to reduce the technical barriers to using,\nunderstanding, visualising and deploying GP based symbolic models of data,\nwhilst at the same time remaining highly customisable and delivering robust\nnumerical performance for power users. In this chapter, notable new features of\nthe latest version of the software are discussed with these aims in mind.\nAdditionally, a simplified variant of the MGGP high level gene crossover\nmechanism is proposed. It is demonstrated that the new functionality of GPTIPS\n2 (a) facilitates the discovery of compact symbolic relationships from data\nusing multiple approaches, e.g. using novel gene-centric visualisation analysis\nto mitigate horizontal bloat and reduce complexity in multigene symbolic\nregression models (b) provides numerous methods for visualising the properties\nof symbolic models (c) emphasises the generation of graphically navigable\nlibraries of models that are optimal in terms of the Pareto trade off surface\nof model performance and complexity and (d) expedites real world applications\nby the simple, rapid and robust deployment of symbolic models outside the\nsoftware environment they were developed in.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.4690v2"
    },
    {
        "title": "FlexDM: Enabling robust and reliable parallel data mining using WEKA",
        "authors": [
            "Madison Flannery",
            "David M Budden",
            "Alexandre Mendes"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Performing massive data mining experiments with multiple datasets and methods\nis a common task faced by most bioinformatics and computational biology\nlaboratories. WEKA is a machine learning package designed to facilitate this\ntask by providing tools that allow researchers to select from several\nclassification methods and specific test strategies. Despite its popularity,\nthe current WEKA environment for batch experiments, namely Experimenter, has\nfour limitations that impact its usability: the selection of value ranges for\nmethods options lacks flexibility and is not intuitive; there is no support for\nparallelisation when running large-scale data mining tasks; the XML schema is\ndifficult to read, necessitating the use of the Experimenter's graphical user\ninterface for generation and modification; and robustness is limited by the\nfact that results are not saved until the last test has concluded.\n  FlexDM implements an interface to WEKA to run batch processing tasks in a\nsimple and intuitive way. In a short and easy-to-understand XML file, one can\ndefine hundreds of tests to be performed on several datasets. FlexDM also\nallows those tests to be executed asynchronously in parallel to take advantage\nof multi-core processors, significantly increasing usability and productivity.\nResults are saved incrementally for better robustness and reliability.\n  FlexDM is implemented in Java and runs on Windows, Linux and OSX. As we\nencourage other researchers to explore and adopt our software, FlexDM is made\navailable as a pre-configured bootable reference environment. All code,\nsupporting documentation and usage examples are also available for download at\nhttp://sourceforge.net/projects/flexdm.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.5720v1"
    },
    {
        "title": "SClib, a hack for straightforward embedded C functions in Python",
        "authors": [
            "Esteban Fuentes",
            "Hector E. Martinez"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We present SClib, a simple hack that allows easy and straightforward\nevaluation of C functions within Python code, boosting flexibility for better\ntrade-off between computation power and feature availability, such as\nvisualization and existing computation routines in SciPy. We also present two\ncases were SClib has been used. In the first set of applications we use SClib\nto write a port to Python of a Schr\\\"odinger equation solver that has been\nextensively used the literature, the resulting script presents a speed-up of\nabout 150x with respect to the original one. A review of the situations where\nthe speeded-up script has been used is presented. We also describe the solution\nto the related problem of solving a set of coupled Schr\\\"odinger-like equations\nwhere SClib is used to implement the speed-critical parts of the code. We argue\nthat when using SClib within IPython we can use NumPy and Matplotlib for the\nmanipulation and visualization of the solutions in an interactive environment\nwith no performance compromise. The second case is an engineering application.\nWe use SClib to evaluate the control and system derivatives in a feedback\ncontrol loop for electrical motors. With this and the integration routines\navailable in SciPy, we can run simulations of the control loop a la Simulink.\nThe use of C code not only boosts the speed of the simulations, but also\nenables to test the exact same code that we use in the test rig to get\nexperimental results. Again, integration with IPython gives us the flexibility\nto analyze and visualize the data.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.6395v1"
    },
    {
        "title": "Construction and implementation of asymptotic expansions for\n  Jacobi--type orthogonal polynomials",
        "authors": [
            "Alfredo Deaño",
            "Daan Huybrechs",
            "Peter Opsomer"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We are interested in the asymptotic behavior of orthogonal polynomials of the\ngeneralized Jacobi type as their degree $n$ goes to $\\infty$. These are defined\non the interval $[-1,1]$ with weight function\n$w(x)=(1-x)^{\\alpha}(1+x)^{\\beta}h(x)$, $\\alpha,\\beta>-1$ and $h(x)$ a real,\nanalytic and strictly positive function on $[-1,1]$. This information is\navailable in the work of Kuijlaars, McLaughlin, Van Assche and Vanlessen, where\nthe authors use the Riemann--Hilbert formulation and the Deift--Zhou non-linear\nsteepest descent method. We show that computing higher-order terms can be\nsimplified, leading to their efficient construction. The resulting asymptotic\nexpansions in every region of the complex plane are implemented both\nsymbolically and numerically, and the code is made publicly available. The main\nadvantage of these expansions is that they lead to increasing accuracy for\nincreasing degree of the polynomials, at a computational cost that is actually\nindependent of the degree. In contrast, the typical use of the recurrence\nrelation for orthogonal polynomials in computations leads to a cost that is at\nleast linear in the degree. Furthermore, the expansions may be used to compute\nGaussian quadrature rules in $\\mathcal{O}(n)$ operations, rather than\n$\\mathcal{O}(n^2)$ based on the recurrence relation.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07191v4"
    },
    {
        "title": "Assessing Excel VBA Suitability for Monte Carlo Simulation",
        "authors": [
            "Alexei Botchkarev"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Monte Carlo (MC) simulation includes a wide range of stochastic techniques\nused to quantitatively evaluate the behavior of complex systems or processes.\nMicrosoft Excel spreadsheets with Visual Basic for Applications (VBA) software\nis, arguably, the most commonly employed general purpose tool for MC\nsimulation. Despite the popularity of the Excel in many industries and\neducational institutions, it has been repeatedly criticized for its flaws and\noften described as questionable, if not completely unsuitable, for statistical\nproblems. The purpose of this study is to assess suitability of the Excel\n(specifically its 2010 and 2013 versions) with VBA programming as a tool for MC\nsimulation. The results of the study indicate that Microsoft Excel (versions\n2010 and 2013) is a strong Monte Carlo simulation application offering a solid\nframework of core simulation components including spreadsheets for data input\nand output, VBA development environment and summary statistics functions. This\nframework should be complemented with an external high-quality pseudo-random\nnumber generator added as a VBA module. A large and diverse category of Excel\nincidental simulation components that includes statistical distributions,\nlinear and non-linear regression and other statistical, engineering and\nbusiness functions require execution of due diligence to determine their\nsuitability for a specific MC project.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.08376v1"
    },
    {
        "title": "A parallel edge orientation algorithm for quadrilateral meshes",
        "authors": [
            "Miklós Homolya",
            "David A. Ham"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  One approach to achieving correct finite element assembly is to ensure that\nthe local orientation of facets relative to each cell in the mesh is consistent\nwith the global orientation of that facet. Rognes et al. have shown how to\nachieve this for any mesh composed of simplex elements, and deal.II contains a\nserial algorithm to construct a consistent orientation of any quadrilateral\nmesh of an orientable manifold.\n  The core contribution of this paper is the extension of this algorithm for\ndistributed memory parallel computers, which facilitates its seamless\napplication as part of a parallel simulation system.\n  Furthermore, our analysis establishes a link between the well-known\nUnion-Find algorithm and the construction of a consistent orientation of a\nquadrilateral mesh. As a result, existing work on the parallelisation of the\nUnion-Find algorithm can be easily adapted to construct further parallel\nalgorithms for mesh orientations.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.03357v3"
    },
    {
        "title": "A Practical Guide to Randomized Matrix Computations with MATLAB\n  Implementations",
        "authors": [
            "Shusen Wang"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Matrix operations such as matrix inversion, eigenvalue decomposition,\nsingular value decomposition are ubiquitous in real-world applications.\nUnfortunately, many of these matrix operations so time and memory expensive\nthat they are prohibitive when the scale of data is large. In real-world\napplications, since the data themselves are noisy, machine-precision matrix\noperations are not necessary at all, and one can sacrifice a reasonable amount\nof accuracy for computational efficiency.\n  In recent years, a bunch of randomized algorithms have been devised to make\nmatrix computations more scalable. Mahoney (2011) and Woodruff (2014) have\nwritten excellent but very technical reviews of the randomized algorithms.\nDifferently, the focus of this manuscript is on intuition, algorithm\nderivation, and implementation. This manuscript should be accessible to people\nwith knowledge in elementary matrix algebra but unfamiliar with randomized\nmatrix computations. The algorithms introduced in this manuscript are all\nsummarized in a user-friendly way, and they can be implemented in lines of\nMATLAB code. The readers can easily follow the implementations even if they do\nnot understand the maths and algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.07570v6"
    },
    {
        "title": "Research on the fast Fourier transform of image based on GPU",
        "authors": [
            "Feifei Shen",
            "Zhenjian Song",
            "Congrui Wu",
            "Jiaqi Geng",
            "Qingyun Wang"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Study of general purpose computation by GPU (Graphics Processing Unit) can\nimprove the image processing capability of micro-computer system. This paper\nstudies the parallelism of the different stages of decimation in time radix 2\nFFT algorithm, designs the butterfly and scramble kernels and implements 2D FFT\non GPU. The experiment result demonstrates the validity and advantage over\ngeneral CPU, especially in the condition of large input size. The approach can\nalso be generalized to other transforms alike.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.08019v1"
    },
    {
        "title": "Verificarlo: checking floating point accuracy through Monte Carlo\n  Arithmetic",
        "authors": [
            "Christophe Denis",
            "Pablo De Oliveira Castro",
            "Eric Petit"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Numerical accuracy of floating point computation is a well studied topic\nwhich has not made its way to the end-user in scientific computing. Yet, it has\nbecome a critical issue with the recent requirements for code modernization to\nharness new highly parallel hardware and perform higher resolution computation.\nTo democratize numerical accuracy analysis, it is important to propose tools\nand methodologies to study large use cases in a reliable and automatic way. In\nthis paper, we propose verificarlo, an extension to the LLVM compiler to\nautomatically use Monte Carlo Arithmetic in a transparent way for the end-user.\nIt supports all the major languages including C, C++, and Fortran. Unlike\nsource-to-source approaches, our implementation captures the influence of\ncompiler optimizations on the numerical accuracy. We illustrate how Monte Carlo\nArithmetic using the verificarlo tool outperforms the existing approaches on\nvarious use cases and is a step toward automatic numerical analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.01347v4"
    },
    {
        "title": "Comparative computational results for some vertex and facet enumeration\n  codes",
        "authors": [
            "David Avis",
            "Charles Jordan"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We report some computational results comparing parallel and sequential codes\nfor vertex/facet enumeration problems for convex polyhedra. The problems chosen\nspan the range from simple to highly degenerate polytopes. We tested one code\n(lrs) based on pivoting and four codes (cddr+, ppl, normaliz, PORTA) based on\nthe double description method. normaliz employs parallelization as do the codes\nplrs and mplrs which are based on lrs. We tested these codes using various\nhardware configurations with up to 1200 cores. Major speedups were obtained by\nparallelization, particularly by the code mplrs which uses MPI and can operate\non clusters of machines.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.02545v3"
    },
    {
        "title": "High performance Python for direct numerical simulations of turbulent\n  flows",
        "authors": [
            "Mikael Mortensen",
            "Hans Petter Langtangen"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Direct Numerical Simulations (DNS) of the Navier Stokes equations is an\ninvaluable research tool in fluid dynamics. Still, there are few publicly\navailable research codes and, due to the heavy number crunching implied,\navailable codes are usually written in low-level languages such as C/C++ or\nFortran. In this paper we describe a pure scientific Python pseudo-spectral DNS\ncode that nearly matches the performance of C++ for thousands of processors and\nbillions of unknowns. We also describe a version optimized through Cython, that\nis found to match the speed of C++. The solvers are written from scratch in\nPython, both the mesh, the MPI domain decomposition, and the temporal\nintegrators. The solvers have been verified and benchmarked on the Shaheen\nsupercomputer at the KAUST supercomputing laboratory, and we are able to show\nvery good scaling up to several thousand cores.\n  A very important part of the implementation is the mesh decomposition (we\nimplement both slab and pencil decompositions) and 3D parallel Fast Fourier\nTransforms (FFT). The mesh decomposition and FFT routines have been implemented\nin Python using serial FFT routines (either NumPy, pyFFTW or any other serial\nFFT module), NumPy array manipulations and with MPI communications handled by\nMPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT\nin Python for a slab mesh decomposition using 4 lines of compact Python code,\nfor which the parallel performance on Shaheen is found to be slightly better\nthan similar routines provided through the FFTW library. For a pencil mesh\ndecomposition 7 lines of code is required to execute a transform.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.03638v1"
    },
    {
        "title": "Algorithm 979: Recursive Algorithms for Dense Linear Algebra -- The\n  ReLAPACK Collection",
        "authors": [
            "Elmar Peise",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  To exploit both memory locality and the full performance potential of highly\ntuned kernels, dense linear algebra libraries such as LAPACK commonly implement\noperations as blocked algorithms. However, to achieve next-to-optimal\nperformance with such algorithms, significant tuning is required. On the other\nhand, recursive algorithms are virtually tuning free, and yet attain similar\nperformance. In this paper, we first analyze and compare blocked and recursive\nalgorithms in terms of performance, and then introduce ReLAPACK, an open-source\nlibrary of recursive algorithms to seamlessly replace most of LAPACK's blocked\nalgorithms. In many scenarios, ReLAPACK clearly outperforms reference LAPACK,\nand even improves upon the performance of optimizes libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.06763v2"
    },
    {
        "title": "Extending DUNE: The dune-xt modules",
        "authors": [
            "Tobias Leibner",
            "René Milk",
            "Felix Schindler"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present our effort to extend and complement the core modules of the\nDistributed and Unified Numerics Environment DUNE (http://dune-project.org) by\na well tested and structured collection of utilities and concepts. We describe\nkey elements of our four modules dune-xt-common, dune-xt-grid, dune-xt-la and\ndune-xt-functions, which aim at further enabling the programming of generic\nalgorithms within DUNE as well as adding an extra layer of usability and\nconvenience.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.08991v1"
    },
    {
        "title": "BoxLib with Tiling: An AMR Software Framework",
        "authors": [
            "Weiqun Zhang",
            "Ann Almgren",
            "Marcus Day",
            "Tan Nguyen",
            "John Shalf",
            "Didem Unat"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  In this paper we introduce a block-structured adaptive mesh refinement (AMR)\nsoftware framework that incorporates tiling, a well-known loop transformation.\nBecause the multiscale, multiphysics codes built in BoxLib are designed to\nsolve complex systems at high resolution, performance on current and next\ngeneration architectures is essential. With the expectation of many more cores\nper node on next generation architectures, the ability to effectively utilize\nthreads within a node is essential, and the current model for parallelization\nwill not be sufficient. We describe a new version of BoxLib in which the tiling\nconstructs are embedded so that BoxLib-based applications can easily realize\nexpected performance gains without extra effort on the part of the application\ndeveloper. We also discuss a path forward to enable future versions of BoxLib\nto take advantage of NUMA-aware optimizations using the TiDA portable library.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.03570v1"
    },
    {
        "title": "Parallel Triangular Solvers on GPU",
        "authors": [
            "Zhangxin Chen",
            "Hui Liu",
            "Bo Yang"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  In this paper, we investigate GPU based parallel triangular solvers\nsystematically. The parallel triangular solvers are fundamental to incomplete\nLU factorization family preconditioners and algebraic multigrid solvers. We\ndevelop a new matrix format suitable for GPU devices. Parallel lower triangular\nsolvers and upper triangular solvers are developed for this new data structure.\nWith these solvers, ILU preconditioners and domain decomposition\npreconditioners are developed. Numerical results show that we can speed\ntriangular solvers around seven times faster.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.00541v1"
    },
    {
        "title": "Development of Krylov and AMG linear solvers for large-scale sparse\n  matrices on GPUs",
        "authors": [
            "Bo Yang",
            "Hui Liu",
            "Zhangxin Chen"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  This research introduce our work on developing Krylov subspace and AMG\nsolvers on NVIDIA GPUs. As SpMV is a crucial part for these iterative methods,\nSpMV algorithms for single GPU and multiple GPUs are implemented. A HEC matrix\nformat and a communication mechanism are established. And also, a set of\nspecific algorithms for solving preconditioned systems in parallel environments\nare designed, including ILU(k), RAS and parallel triangular solvers. Based on\nthese work, several Krylov solvers and AMG solvers are developed. According to\nnumerical experiments, favorable acceleration performance is acquired from our\nKrylov solver and AMG solver under various parameter conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.00545v1"
    },
    {
        "title": "D2O - a distributed data object for parallel high-performance computing\n  in Python",
        "authors": [
            "T. Steininger",
            "M. Greiner",
            "F. Beaujean",
            "T. Enßlin"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We introduce D2O, a Python module for cluster-distributed multi-dimensional\nnumerical arrays. It acts as a layer of abstraction between the algorithm code\nand the data-distribution logic. The main goal is to achieve usability without\nlosing numerical performance and scalability. D2O's global interface is similar\nto the one of a numpy.ndarray, whereas the cluster node's local data is\ndirectly accessible for use in customized high-performance modules. D2O is\nwritten in pure Python which makes it portable and easy to use and modify.\nExpensive operations are carried out by dedicated external libraries like numpy\nand mpi4py. The performance of D2O is on a par with numpy for serial\napplications and scales well when moving to an MPI cluster. D2O is open-source\nsoftware available under the GNU General Public License v3 (GPL-3) at\nhttps://gitlab.mpcdf.mpg.de/ift/D2O\n",
        "pdf_link": "http://arxiv.org/pdf/1606.05385v2"
    },
    {
        "title": "Design of a high-performance GEMM-like Tensor-Tensor Multiplication",
        "authors": [
            "Paul Springer",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present \"GEMM-like Tensor-Tensor multiplication\" (GETT), a novel approach\nto tensor contractions that mirrors the design of a high-performance general\nmatrix-matrix multiplication (GEMM). The critical insight behind GETT is the\nidentification of three index sets, involved in the tensor contraction, which\nenable us to systematically reduce an arbitrary tensor contraction to loops\naround a highly tuned \"macro-kernel\". This macro-kernel operates on suitably\nprepared (\"packed\") sub-tensors that reside in a specified level of the cache\nhierarchy. In contrast to previous approaches to tensor contractions, GETT\nexhibits desirable features such as unit-stride memory accesses,\ncache-awareness, as well as full vectorization, without requiring auxiliary\nmemory. To compare our technique with other modern tensor contractions, we\nintegrate GETT alongside the so called Transpose-Transpose-GEMM-Transpose and\nLoops-over-GEMM approaches into an open source \"Tensor Contraction Code\nGenerator\" (TCCG). The performance results for a wide range of tensor\ncontractions suggest that GETT has the potential of becoming the method of\nchoice: While GETT exhibits excellent performance across the board, its\neffectiveness for bandwidth-bound tensor contractions is especially impressive,\noutperforming existing approaches by up to $12.4\\times$. More precisely, GETT\nachieves speedups of up to $1.41\\times$ over an equivalent-sized GEMM for\nbandwidth-bound tensor contractions while attaining up to $91.3\\%$ of peak\nfloating-point performance for compute-bound tensor contractions.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.00145v3"
    },
    {
        "title": "Best Practices for Replicability, Reproducibility and Reusability of\n  Computer-Based Experiments Exemplified by Model Reduction Software",
        "authors": [
            "Jörg Fehr",
            "Jan Heiland",
            "Christian Himpe",
            "Jens Saak"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Over the recent years the importance of numerical experiments has gradually\nbeen more recognized. Nonetheless, sufficient documentation of how\ncomputational results have been obtained is often not available. Especially in\nthe scientific computing and applied mathematics domain this is crucial, since\nnumerical experiments are usually employed to verify the proposed hypothesis in\na publication. This work aims to propose standards and best practices for the\nsetup and publication of numerical experiments. Naturally, this amounts to a\nguideline for development, maintenance, and publication of numerical research\nsoftware. Such a primer will enable the replicability and reproducibility of\ncomputer-based experiments and published results and also promote the\nreusability of the associated software.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.01191v1"
    },
    {
        "title": "TTC: A Tensor Transposition Compiler for Multiple Architectures",
        "authors": [
            "Paul Springer",
            "Aravind Sankaran",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We consider the problem of transposing tensors of arbitrary dimension and\ndescribe TTC, an open source domain-specific parallel compiler. TTC generates\noptimized parallel C++/CUDA C code that achieves a significant fraction of the\nsystem's peak memory bandwidth. TTC exhibits high performance across multiple\narchitectures, including modern AVX-based systems (e.g.,~Intel Haswell, AMD\nSteamroller), Intel's Knights Corner as well as different CUDA-based GPUs such\nas NVIDIA's Kepler and Maxwell architectures. We report speedups of TTC over a\nmeaningful baseline implementation generated by external C++ compilers; the\nresults suggest that a domain-specific compiler can outperform its general\npurpose counterpart significantly: For instance, comparing with Intel's latest\nC++ compiler on the Haswell and Knights Corner architecture, TTC yields\nspeedups of up to $8\\times$ and $32\\times$, respectively. We also showcase\nTTC's support for multiple leading dimensions, making it a suitable candidate\nfor the generation of performance-critical packing functions that are at the\ncore of the ubiquitous BLAS 3 routines.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.01249v1"
    },
    {
        "title": "TRIOT: Faster tensor manipulation in C++11",
        "authors": [
            "Florian Heyl",
            "Oliver Serang"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  [abridged] Context: Multidimensional arrays are used by many different\nalgorithms. As such, indexing and broadcasting complex operations over\nmultidimensional arrays are ubiquitous tasks and can be performance limiting.\nInquiry: Simultaneously indexing two or more multidimensional arrays with\ndifferent shapes (e.g., copying data from one tensor to another larger, zero\npadded tensor in anticipation of a convolution) is difficult to do efficiently:\nHard-coded nested for loops in C, Fortran, and Go cannot be applied when the\ndimension of a tensor is unknown at compile time. Likewise, boost::multi_array\ncannot be used unless the dimensions of the array are known at compile time,\nand the style of implementation restricts the user from using the index tuple\ninside a vectorized operation (as would be required to compute an expected\nvalue of a multidimensional distribution). On the other hand, iteration methods\nthat do not require the dimensionality or shape to be known at compile time\n(e.g., incrementing and applying carry operations to index tuples or remapping\ninteger indices in the flat array), can be substantially slower than hard-coded\nnested for loops. ... Importance: Manipulation of multidimensional arrays is a\ncommon task in software, especially in high performance numerical methods. This\npaper proposes a novel way to leverage template recursion to iterate over and\napply operations to multidimensional arrays, and then demonstrates the superior\nperformance and flexibility of operations that can be achieved using this new\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.00099v2"
    },
    {
        "title": "Computation of the incomplete gamma function for negative values of the\n  argument",
        "authors": [
            "A. Gil",
            "D. Ruiz-Antolín",
            "J. Segura",
            "N. M. Temme"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  An algorithm for computing the incomplete gamma function $\\gamma^*(a,z)$ for\nreal values of the parameter $a$ and negative real values of the argument $z$\nis presented. The algorithm combines the use of series expansions,\nPoincar\\'e-type expansions, uniform asymptotic expansions and recurrence\nrelations, depending on the parameter region. A relative accuracy $\\sim\n10^{-13}$ in the parameter region $(a,z) \\in [-500,\\,500] \\times [-500,\\,0)$\ncan be obtained when computing the function $\\gamma^*(a,z)$ with the Fortran 90\nmodule IncgamNEG implementing the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.04152v1"
    },
    {
        "title": "A Functional Package for Automatic Solution of Ordinary Differential\n  Equations with Spectral Methods",
        "authors": [
            "Shaohui Liu",
            "Tianshi Wang",
            "Youran Zhang"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present a Python module named PyCheb, to solve the ordinary differential\nequations by using spectral collocation method. PyCheb incorporates\ndiscretization using Chebyshev points, barycentric interpolation and iterate\nmethods. With this Python module, users can initialize the ODEsolver class by\npassing attributes, including the both sides of a given differential equation,\nboundary conditions, and the number of Chebyshev points, which can also be\ngenerated automatically by the ideal precision, to the constructor of ODEsolver\nclass. Then, the instance of the ODEsolver class can be used to automatically\ndetermine the resolution of the differential equation as well as generate the\ngraph of the high-precision approximate solution. (If you have any questions,\nplease send me an email and I will reply ASAP.\ne-mail:shaohui_liu@qq.com/2013141482143@stu.scu.edu.cn)\n",
        "pdf_link": "http://arxiv.org/pdf/1608.04815v3"
    },
    {
        "title": "Devito: automated fast finite difference computation",
        "authors": [
            "Navjot Kukreja",
            "Mathias Louboutin",
            "Felippe Vieira",
            "Fabio Luporini",
            "Michael Lange",
            "Gerard Gorman"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Domain specific languages have successfully been used in a variety of fields\nto cleanly express scientific problems as well as to simplify implementation\nand performance opti- mization on different computer architectures. Although a\nlarge number of stencil languages are available, finite differ- ence domain\nspecific languages have proved challenging to design because most practical use\ncases require additional features that fall outside the finite difference\nabstraction. Inspired by the complexity of real-world seismic imaging problems,\nwe introduce Devito, a domain specific language in which high level equations\nare expressed using symbolic expressions from the SymPy package. Complex\nequations are automatically manipulated, optimized, and translated into highly\noptimized C code that aims to perform compa- rably or better than hand-tuned\ncode. All this is transpar- ent to users, who only see concise symbolic\nmathematical expressions.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.08658v2"
    },
    {
        "title": "Devito: Towards a generic Finite Difference DSL using Symbolic Python",
        "authors": [
            "Michael Lange",
            "Navjot Kukreja",
            "Mathias Louboutin",
            "Fabio Luporini",
            "Felippe Vieira",
            "Vincenzo Pandolfo",
            "Paulius Velesko",
            "Paulius Kazakas",
            "Gerard Gorman"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Domain specific languages (DSL) have been used in a variety of fields to\nexpress complex scientific problems in a concise manner and provide automated\nperformance optimization for a range of computational architectures. As such\nDSLs provide a powerful mechanism to speed up scientific Python computation\nthat goes beyond traditional vectorization and pre-compilation approaches,\nwhile allowing domain scientists to build applications within the comforts of\nthe Python software ecosystem. In this paper we present Devito, a new finite\ndifference DSL that provides optimized stencil computation from high-level\nproblem specifications based on symbolic Python expressions. We demonstrate\nDevito's symbolic API and performance advantages over traditional Python\nacceleration methods before highlighting its use in the scientific context of\nseismic inversion problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.03361v1"
    },
    {
        "title": "An object oriented parallel finite element scheme for computations of\n  PDEs: Design and implementation",
        "authors": [
            "Sashikumaar Ganesan",
            "Volker John",
            "Gunar Matthies",
            "Raviteja Meesala",
            "Shamim Abdus",
            "Ulrich Wilbrandt"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Parallel finite element algorithms based on object-oriented concepts are\npresented. Moreover, the design and implementation of a data structure proposed\nare utilized in realizing a parallel geometric multigrid method. The\nParFEMapper and the ParFECommunicator are the key components of the data\nstructure in the proposed parallel scheme. These classes are constructed based\non the type of finite elements (continuous or nonconforming or discontinuous)\nused. The proposed solver is compared with the open source direct solvers,\nMUMPS and PasTiX. Further, the performance of the parallel multigrid solver is\nanalyzed up to 1080 processors. The solver shows a very good speedup up to 960\nprocessors and the problem size has to be increased in order to maintain the\ngood speedup when the number of processors are increased further. As a result,\nthe parallel solver is able to handle large scale problems on massively\nparallel supercomputers. The proposed parallel finite element algorithms and\nmultigrid solver are implemented in our in-house package ParMooN.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.04809v1"
    },
    {
        "title": "A Unified 2D/3D Large Scale Software Environment for Nonlinear Inverse\n  Problems",
        "authors": [
            "Curt Da Silva",
            "Felix J. Herrmann"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Large scale parameter estimation problems are among some of the most\ncomputationally demanding problems in numerical analysis. An academic\nresearcher's domain-specific knowledge often precludes that of software design,\nwhich results in inversion frameworks that are technically correct, but not\nscalable to realistically-sized problems. On the other hand, the computational\ndemands for realistic problems result in industrial codebases that are geared\nsolely for high performance, rather than comprehensibility or flexibility. We\npropose a new software design for inverse problems constrained by partial\ndifferential equations that bridges the gap between these two seemingly\ndisparate worlds. A hierarchical and modular design allows a user to delve into\nas much detail as she desires, while exploiting high performance primitives at\nthe lower levels. Our code has the added benefit of actually reflecting the\nunderlying mathematics of the problem, which lowers the cognitive load on user\nusing it and reduces the initial startup period before a researcher can be\nfully productive. We also introduce a new preconditioner for the 3D Helmholtz\nequation that is suitable for fault-tolerant distributed systems. Numerical\nexperiments on a variety of 2D and 3D test problems demonstrate the\neffectiveness of this approach on scaling algorithms from small to large scale\nproblems with minimal code changes.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.09268v2"
    },
    {
        "title": "The Stochastic Processes Generation in OpenModelica",
        "authors": [
            "M. N. Gevorkyan",
            "A. V. Demidova",
            "A. V. Korolkova",
            "D. S. Kulyabov",
            "L. A. Sevastianov"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Background: Component-based modeling language Modelica (OpenModelica is open\nsource implementation) is used for the numerical simulation of complex\nprocesses of different nature represented by ODE system. However, in\nOpenModelica standard library there is no routines for pseudo-random numbers\ngeneration, which makes it impossible to use for stochastic modeling processes.\nPurpose: The goal of this article is a brief overview of a number of algorithms\nfor generation a sequence of uniformly distributed pseudo random numbers and\nquality assessment of the sequence given by them, as well as the ways to\nimplement some of these algorithms in OpenModelica system. Methods: All the\nalgorithms are implemented in C language, and the results of their work tested\nusing open source package DieHarder. For those algorithms that do not use bit\noperations, we describe there realisation using OpwnModelica. The other\nalgorithms can be called in OpenModelica as C functions Results: We have\nimplemented and tested about nine algorithms. DieHarder testing revealed the\nhighest quality pseudo-random number generators. Also we have reviewed\nlibraries Noise and AdvancedNoise, who claim to be adding to the Modelica\nStandard Library. Conclusions: In OpenModelica system can be implemented\ngenerators of uniformly distributed pseudo-random numbers, which is the first\nstep towards to make OpenModelica suitable for simulation of stochastic\nprocesses.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.00206v1"
    },
    {
        "title": "Faster Base64 Encoding and Decoding Using AVX2 Instructions",
        "authors": [
            "Wojciech Muła",
            "Daniel Lemire"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Web developers use base64 formats to include images, fonts, sounds and other\nresources directly inside HTML, JavaScript, JSON and XML files. We estimate\nthat billions of base64 messages are decoded every day. We are motivated to\nimprove the efficiency of base64 encoding and decoding. Compared to\nstate-of-the-art implementations, we multiply the speeds of both the encoding\n(~10x) and the decoding (~7x). We achieve these good results by using the\nsingle-instruction-multiple-data (SIMD) instructions available on recent Intel\nprocessors (AVX2). Our accelerated software abides by the specification and\nreports errors when encountering characters outside of the base64 set. It is\navailable online as free software under a liberal license.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.00605v5"
    },
    {
        "title": "Conical: an extended module for computing a numerically satisfactory\n  pair of solutions of the differential equation for conical functions",
        "authors": [
            "T. M. Dunster",
            "A. Gil",
            "J. Segura",
            "N. M. Temme"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Conical functions appear in a large number of applications in physics and\nengineering. In this paper we describe an extension of our module CONICAL for\nthe computation of conical functions. Specifically, the module includes now a\nroutine for computing the function ${{\\rm R}}^{m}_{-\\frac{1}{2}+i\\tau}(x)$, a\nreal-valued numerically satisfactory companion of the function ${\\rm\nP}^m_{-\\tfrac12+i\\tau}(x)$ for $x>1$. In this way, a natural basis for solving\nDirichlet problems bounded by conical domains is provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.01145v1"
    },
    {
        "title": "Computing the Lambert W function in arbitrary-precision complex interval\n  arithmetic",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We describe an algorithm to evaluate all the complex branches of the Lambert\nW function with rigorous error bounds in interval arithmetic, which has been\nimplemented in the Arb library. The classic 1996 paper on the Lambert W\nfunction by Corless et al. provides a thorough but partly heuristic numerical\nanalysis which needs to be complemented with some explicit inequalities and\npractical observations about managing precision and branch cuts.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.03266v1"
    },
    {
        "title": "A performance spectrum for parallel computational frameworks that solve\n  PDEs",
        "authors": [
            "J. Chang",
            "K. B. Nakshatrala",
            "M. G. Knepley",
            "L. Johnsson"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Important computational physics problems are often large-scale in nature, and\nit is highly desirable to have robust and high performing computational\nframeworks that can quickly address these problems. However, it is no trivial\ntask to determine whether a computational framework is performing efficiently\nor is scalable. The aim of this paper is to present various strategies for\nbetter understanding the performance of any parallel computational frameworks\nfor solving PDEs. Important performance issues that negatively impact\ntime-to-solution are discussed, and we propose a performance spectrum analysis\nthat can enhance one's understanding of critical aforementioned performance\nissues. As proof of concept, we examine commonly used finite element simulation\npackages and software and apply the performance spectrum to quickly analyze the\nperformance and scalability across various hardware platforms, software\nimplementations, and numerical discretizations. It is shown that the proposed\nperformance spectrum is a versatile performance model that is not only\nextendable to more complex PDEs such as hydrostatic ice sheet flow equations,\nbut also useful for understanding hardware performance in a massively parallel\ncomputing environment. Potential applications and future extensions of this\nwork are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.03625v2"
    },
    {
        "title": "TSFC: a structure-preserving form compiler",
        "authors": [
            "Miklós Homolya",
            "Lawrence Mitchell",
            "Fabio Luporini",
            "David A. Ham"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  A form compiler takes a high-level description of the weak form of partial\ndifferential equations and produces low-level code that carries out the finite\nelement assembly. In this paper we present the Two-Stage Form Compiler (TSFC),\na new form compiler with the main motivation to maintain the structure of the\ninput expression as long as possible. This facilitates the application of\noptimizations at the highest possible level of abstraction. TSFC features a\nnovel, structure-preserving method for separating the contributions of a form\nto the subblocks of the local tensor in discontinuous Galerkin problems. This\nenables us to preserve the tensor structure of expressions longer through the\ncompilation process than other form compilers. This is also achieved in part by\na two-stage approach that cleanly separates the lowering of finite element\nconstructs to tensor algebra in the first stage, from the scheduling of those\ntensor operations in the second stage. TSFC also efficiently traverses\ncomplicated expressions, and experimental evaluation demonstrates good\ncompile-time performance even for highly complex forms.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.03667v2"
    },
    {
        "title": "Nemo/Hecke: Computer Algebra and Number Theory Packages for the Julia\n  Programming Language",
        "authors": [
            "Claus Fieker",
            "William Hart",
            "Tommy Hofmann",
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We introduce two new packages, Nemo and Hecke, written in the Julia\nprogramming language for computer algebra and number theory. We demonstrate\nthat high performance generic algorithms can be implemented in Julia, without\nthe need to resort to a low-level C implementation. For specialised algorithms,\nwe use Julia's efficient native C interface to wrap existing C/C++ libraries\nsuch as Flint, Arb, Antic and Singular. We give examples of how to use Hecke\nand Nemo and discuss some algorithms that we have implemented to provide high\nperformance basic arithmetic.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.06134v1"
    },
    {
        "title": "Spin Summations: A High-Performance Perspective",
        "authors": [
            "Paul Springer",
            "Devin Matthews",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Besides tensor contractions, one of the most pronounced computational\nbottlenecks in the non-orthogonally spin-adapted forms of the quantum chemistry\nmethods CCSDT and CCSDTQ, and their approximate forms---including CCSD(T) and\nCCSDT(Q)---are spin summations. At a first sight, spin summations are\noperations similar to tensor transpositions; a closer look instead reveals\nadditional challenges to high-performance calculations, including temporal\nlocality as well as scattered memory accesses. This publication explores a\nsequence of algorithmic solutions for spin summations, each exploiting\nindividual properties of either the underlying hardware (e.g. caches,\nvectorization), or the problem itself (e.g. factorizability). The final\nalgorithm combines the advantages of all the solutions, while avoiding their\ndrawbacks; this algorithm, achieves high-performance through parallelization,\nvectorization, and by exploiting the temporal locality inherent to spin\nsummations. Combined, these optimizations result in speedups between 2.4x and\n5.5x over the NCC quantum chemistry software package. In addition to such a\nperformance boost, our algorithm can perform the spin summations in-place, thus\nreducing the memory footprint by 2x over an out-of-place variant.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.06661v1"
    },
    {
        "title": "A Unified Optimization Approach for Sparse Tensor Operations on GPUs",
        "authors": [
            "Bangtian Liu",
            "Chengyao Wen",
            "Anand D. Sarwate",
            "Maryam Mehri Dehnavi"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Sparse tensors appear in many large-scale applications with multidimensional\nand sparse data. While multidimensional sparse data often need to be processed\non manycore processors, attempts to develop highly-optimized GPU-based\nimplementations of sparse tensor operations are rare. The irregular computation\npatterns and sparsity structures as well as the large memory footprints of\nsparse tensor operations make such implementations challenging. We leverage the\nfact that sparse tensor operations share similar computation patterns to\npropose a unified tensor representation called F-COO. Combined with\nGPU-specific optimizations, F-COO provides highly-optimized implementations of\nsparse tensor computations on GPUs. The performance of the proposed unified\napproach is demonstrated for tensor-based kernels such as the Sparse Matricized\nTensor- Times-Khatri-Rao Product (SpMTTKRP) and the Sparse Tensor- Times-Matrix\nMultiply (SpTTM) and is used in tensor decomposition algorithms. Compared to\nstate-of-the-art work we improve the performance of SpTTM and SpMTTKRP up to\n3.7 and 30.6 times respectively on NVIDIA Titan-X GPUs. We implement a\nCANDECOMP/PARAFAC (CP) decomposition and achieve up to 14.9 times speedup using\nthe unified method over state-of-the-art libraries on NVIDIA Titan-X GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.09905v1"
    },
    {
        "title": "Veamy: an extensible object-oriented C++ library for the virtual element\n  method",
        "authors": [
            "Alejandro Ortiz-Bernardin",
            "Catalina Alvarez",
            "Nancy Hitschfeld-Kahler",
            "Alessandro Russo",
            "Rodrigo Silva-Valenzuela",
            "Edgardo Olate-Sanzana"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  This paper summarizes the development of Veamy, an object-oriented C++\nlibrary for the virtual element method (VEM) on general polygonal meshes, whose\nmodular design is focused on its extensibility. The linear elastostatic and\nPoisson problems in two dimensions have been chosen as the starting stage for\nthe development of this library. The theory of the VEM, upon which Veamy is\nbuilt, is presented using a notation and a terminology that resemble the\nlanguage of the finite element method (FEM) in engineering analysis. Several\nexamples are provided to demonstrate the usage of Veamy, and in particular, one\nof them features the interaction between Veamy and the polygonal mesh generator\nPolyMesher. A computational performance comparison between VEM and FEM is also\nconducted. Veamy is free and open source software.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.03438v4"
    },
    {
        "title": "The basic principles and the structure and algorithmically software of\n  computing by hypercomplex number",
        "authors": [
            "Ya. Kalinovsky",
            "Yu. Boyarinova",
            "A. Sukalo",
            "Ya. Hitsko"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  In article the basic principles put in a basis of algorithmicallysoftware of\nhypercomplex number calculations, structure of a software, structure of\nfunctional subsystems are considered. The most important procedures included in\nsubsystems are considered, program listings and examples of their application\nare given.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.04021v1"
    },
    {
        "title": "PSelInv - A Distributed Memory Parallel Algorithm for Selected\n  Inversion: the non-symmetric Case",
        "authors": [
            "Mathias Jacquelin",
            "Lin Lin",
            "Chao Yang"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  This paper generalizes the parallel selected inversion algorithm called\nPSelInv to sparse non- symmetric matrices. We assume a general sparse matrix A\nhas been decomposed as PAQ = LU on a distributed memory parallel machine, where\nL, U are lower and upper triangular matrices, and P, Q are permutation\nmatrices, respectively. The PSelInv method computes selected elements of A-1.\nThe selection is confined by the sparsity pattern of the matrix AT . Our\nalgorithm does not assume any symmetry properties of A, and our parallel\nimplementation is memory efficient, in the sense that the computed elements of\nA-T overwrites the sparse matrix L+U in situ. PSelInv involves a large number\nof collective data communication activities within different processor groups\nof various sizes. In order to minimize idle time and improve load balancing,\ntree-based asynchronous communication is used to coordinate all such collective\ncommunication. Numerical results demonstrate that PSelInv can scale efficiently\nto 6,400 cores for a variety of matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.04539v1"
    },
    {
        "title": "Parallel solver for shifted systems in a hybrid CPU-GPU framework",
        "authors": [
            "Nela Bosner",
            "Zvonimir Bujanović",
            "Zlatko Drmač"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  This paper proposes a combination of a hybrid CPU--GPU and a pure GPU\nsoftware implementation of a direct algorithm for solving shifted linear\nsystems $(A - \\sigma I)X = B$ with large number of complex shifts $\\sigma$ and\nmultiple right-hand sides. Such problems often appear e.g. in control theory\nwhen evaluating the transfer function, or as a part of an algorithm performing\ninterpolatory model reduction, as well as when computing pseudospectra and\nstructured pseudospectra, or solving large linear systems of ordinary\ndifferential equations. The proposed algorithm first jointly reduces the\ngeneral full $n\\times n$ matrix $A$ and the $n\\times m$ full right-hand side\nmatrix $B$ to the controller Hessenberg canonical form that facilitates\nefficient solution: $A$ is transformed to a so-called $m$-Hessenberg form and\n$B$ is made upper-triangular. This is implemented as blocked highly parallel\nCPU--GPU hybrid algorithm; individual blocks are reduced by the CPU, and the\nnecessary updates of the rest of the matrix are split among the cores of the\nCPU and the GPU. To enhance parallelization, the reduction and the updates are\noverlapped. In the next phase, the reduced $m$-Hessenberg--triangular systems\nare solved entirely on the GPU, with shifts divided into batches. The benefits\nof such load distribution are demonstrated by numerical experiments. In\nparticular, we show that our proposed implementation provides an excellent\nbasis for efficient implementations of computational methods in systems and\ncontrol theory, from evaluation of transfer function to the interpolatory model\nreduction.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.06290v1"
    },
    {
        "title": "Look-Ahead in the Two-Sided Reduction to Compact Band Forms for\n  Symmetric Eigenvalue Problems and the SVD",
        "authors": [
            "Rafael Rodríguez-Sánchez",
            "Sandra Catalán",
            "José R. Herrero",
            "Enrique S. Quintana-Ortí",
            "Andrés E. Tomás"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We address the reduction to compact band forms, via unitary similarity\ntransformations, for the solution of symmetric eigenvalue problems and the\ncomputation of the singular value decomposition (SVD). Concretely, in the first\ncase we revisit the reduction to symmetric band form while, for the second\ncase, we propose a similar alternative, which transforms the original matrix to\n(unsymmetric) band form, replacing the conventional reduction method that\nproduces a triangular--band output. In both cases, we describe algorithmic\nvariants of the standard Level-3 BLAS-based procedures, enhanced with\nlook-ahead, to overcome the performance bottleneck imposed by the panel\nfactorization. Furthermore, our solutions employ an algorithmic block size that\ndiffers from the target bandwidth, illustrating the important performance\nbenefits of this decision. Finally, we show that our alternative compact band\nform for the SVD is key to introduce an effective look-ahead strategy into the\ncorresponding reduction procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.00302v2"
    },
    {
        "title": "Exposing and exploiting structure: optimal code generation for\n  high-order finite element methods",
        "authors": [
            "Miklós Homolya",
            "Robert C. Kirby",
            "David A. Ham"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Code generation based software platforms, such as Firedrake, have become\npopular tools for developing complicated finite element discretisations of\npartial differential equations. We extended the code generation infrastructure\nin Firedrake with optimisations that can exploit the structure inherent to some\nfinite elements. This includes sum factorisation on cuboid cells for\ncontinuous, discontinuous, H(div) and H(curl) conforming elements. Our\nexperiments confirm optimal algorithmic complexity for high-order finite\nelement assembly. This is achieved through several novel contributions: the\nintroduction of a more powerful interface between the form compiler and the\nlibrary providing the finite elements; a more abstract, smarter library of\nfinite elements called FInAT that explicitly communicates the structure of\nelements; and form compiler algorithms to automatically exploit this exposed\nstructure.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.02473v1"
    },
    {
        "title": "Tangent: Automatic Differentiation Using Source Code Transformation in\n  Python",
        "authors": [
            "Bart van Merriënboer",
            "Alexander B. Wiltschko",
            "Dan Moldovan"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Automatic differentiation (AD) is an essential primitive for machine learning\nprogramming systems. Tangent is a new library that performs AD using source\ncode transformation (SCT) in Python. It takes numeric functions written in a\nsyntactic subset of Python and NumPy as input, and generates new Python\nfunctions which calculate a derivative. This approach to automatic\ndifferentiation is different from existing packages popular in machine\nlearning, such as TensorFlow and Autograd. Advantages are that Tangent\ngenerates gradient code in Python which is readable by the user, easy to\nunderstand and debug, and has no runtime overhead. Tangent also introduces\nabstractions for easily injecting logic into the generated gradient code,\nfurther improving usability.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.02712v1"
    },
    {
        "title": "HomotopyContinuation.jl: A package for homotopy continuation in Julia",
        "authors": [
            "Paul Breiding",
            "Sascha Timme"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We present the Julia package HomotopyContinuation.jl, which provides an\nalgorithmic framework for solving polynomial systems by numerical homotopy\ncontinuation. We introduce the basic capabilities of the package and\ndemonstrate the software on an illustrative example. We motivate our choice of\nJulia and how its features allow us to improve upon existing software packages\nwith respect to usability, modularity and performance. Furthermore, we compare\nthe performance of HomotopyContinuation.jl to the existing packages Bertini and\nPHCpack.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.10911v2"
    },
    {
        "title": "On quality of implementation of Fortran 2008 complex intrinsic functions\n  on branch cuts",
        "authors": [
            "Anton Shterenlikht"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Branch cuts in complex functions in combination with signed zero and signed\ninfinity have important uses in fracture mechanics, jet flow and aerofoil\nanalysis. We present benchmarks for validating Fortran 2008 complex functions -\nLOG, SQRT, ASIN, ACOS, ATAN, ASINH, ACOSH and ATANH - on branch cuts with\narguments of all 3 IEEE floating point binary formats: binary32, binary64 and\nbinary128. Results are reported with 8 Fortran 2008 compilers: GCC, Flang,\nCray, Oracle, PGI, Intel, NAG and IBM. Multiple test failures were revealed,\ne.g. wrong signs of results or unexpected overflow, underflow, or NaN. We\nconclude that the quality of implementation of these Fortran 2008 intrinsics in\nmany compilers is not yet sufficient to remove the need for special code for\nbranch cuts. The test results are complemented by conformal maps of the branch\ncuts and detailed derivations of the values of these functions on branch cuts,\nto be used as a reference. The benchmarks are freely available from\ncmplx.sf.net. This work will be of interest to engineers who use complex\nfunctions, as well as to compiler and maths library developers.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.10230v1"
    },
    {
        "title": "Tensor Train decomposition on TensorFlow (T3F)",
        "authors": [
            "Alexander Novikov",
            "Pavel Izmailov",
            "Valentin Khrulkov",
            "Michael Figurnov",
            "Ivan Oseledets"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Tensor Train decomposition is used across many branches of machine learning.\nWe present T3F -- a library for Tensor Train decomposition based on TensorFlow.\nT3F supports GPU execution, batch processing, automatic differentiation, and\nversatile functionality for the Riemannian optimization framework, which takes\ninto account the underlying manifold structure to construct efficient\noptimization methods. The library makes it easier to implement machine learning\npapers that rely on the Tensor Train decomposition. T3F includes documentation,\nexamples and 94% test coverage.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.01928v2"
    },
    {
        "title": "Stop talking to me -- a communication-avoiding ADER-DG realisation",
        "authors": [
            "Dominic E. Charrier",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We present a communication- and data-sensitive formulation of ADER-DG for\nhyperbolic differential equation systems. Sensitive here has multiple flavours:\nFirst, the formulation reduces the persistent memory footprint. This reduces\npressure on the memory subsystem. Second, the formulation realises the\nunderlying predictor-corrector scheme with single-touch semantics, i.e., each\ndegree of freedom is read on average only once per time step from the main\nmemory. This reduces communication through the memory controllers. Third, the\nformulation breaks up the tight coupling of the explicit time stepping's\nalgorithmic steps to mesh traversals. This averages out data access peaks.\nDifferent operations and algorithmic steps are ran on different grid entities.\nFinally, the formulation hides distributed memory data transfer behind the\ncomputation aligned with the mesh traversal. This reduces pressure on the\nmachine interconnects. All techniques applied by our formulation are elaborated\nby means of a rigorous task formalism. They break up ADER-DG's tight causal\ncoupling of compute steps and can be generalised to other predictor-corrector\nschemes.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.08682v1"
    },
    {
        "title": "High-level python abstractions for optimal checkpointing in inversion\n  problems",
        "authors": [
            "Navjot Kukreja",
            "Jan Hückelheim",
            "Michael Lange",
            "Mathias Louboutin",
            "Andrea Walther",
            "Simon W. Funke",
            "Gerard Gorman"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Inversion and PDE-constrained optimization problems often rely on solving the\nadjoint problem to calculate the gradient of the objec- tive function. This\nrequires storing large amounts of intermediate data, setting a limit to the\nlargest problem that might be solved with a given amount of memory available.\nCheckpointing is an approach that can reduce the amount of memory required by\nredoing parts of the computation instead of storing intermediate results. The\nRevolve checkpointing algorithm o ers an optimal schedule that trades\ncomputational cost for smaller memory footprints. Integrat- ing Revolve into a\nmodern python HPC code and combining it with code generation is not\nstraightforward. We present an API that makes checkpointing accessible from a\nDSL-based code generation environment along with some initial performance gures\nwith a focus on seismic applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.02474v1"
    },
    {
        "title": "GPU Accelerated Finite Element Assembly with Runtime Compilation",
        "authors": [
            "Tao Cui",
            "Xiaohu Guo",
            "Hui Liu"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In recent years, high performance scientific computing on graphics processing\nunits (GPUs) have gained widespread acceptance. These devices are designed to\noffer massively parallel threads for running code with general purpose. There\nare many researches focus on finite element method with GPUs. However, most of\nthe works are specific to certain problems and applications. Some works propose\nmethods for finite element assembly that is general for a wide range of finite\nelement models. But the development of finite element code is dependent on the\nhardware architectures. It is usually complicated and error prone using the\nlibraries provided by the hardware vendors. In this paper, we present\narchitecture and implementation of finite element assembly for partial\ndifferential equations (PDEs) based on symbolic computation and runtime\ncompilation technique on GPU. User friendly programming interface with symbolic\ncomputation is provided. At the same time, high computational efficiency is\nachieved by using runtime compilation technique. As far as we know, it is the\nfirst work using this technique to accelerate finite element assembly for\nsolving PDEs. Experiments show that a one to two orders of speedup is achieved\nfor the problems studied in the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03433v1"
    },
    {
        "title": "Achieving Efficient Realization of Kalman Filter on CGRA through\n  Algorithm-Architecture Co-design",
        "authors": [
            "Farhad Merchant",
            "Tarun Vatwani",
            "Anupam Chattopadhyay",
            "Soumyendu Raha",
            "S K Nandy",
            "Ranjani Narayan"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this paper, we present efficient realization of Kalman Filter (KF) that\ncan achieve up to 65% of the theoretical peak performance of underlying\narchitecture platform. KF is realized using Modified Faddeeva Algorithm (MFA)\nas a basic building block due to its versatility and REDEFINE Coarse Grained\nReconfigurable Architecture (CGRA) is used as a platform for experiments since\nREDEFINE is capable of supporting realization of a set algorithmic compute\nstructures at run-time on a Reconfigurable Data-path (RDP). We perform several\nhardware and software based optimizations in the realization of KF to achieve\n116% improvement in terms of Gflops over the first realization of KF. Overall,\nwith the presented approach for KF, 4-105x performance improvement in terms of\nGflops/watt over several academically and commercially available realizations\nof KF is attained. In REDEFINE, we show that our implementation is scalable and\nthe performance attained is commensurate with the underlying hardware resources\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03650v1"
    },
    {
        "title": "Locality Optimized Unstructured Mesh Algorithms on GPUs",
        "authors": [
            "András Attila Sulyok",
            "Gábor Dániel Balogh",
            "István Zoltán Reguly",
            "Gihan R. Mudalige"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Unstructured-mesh based numerical algorithms such as finite volume and finite\nelement algorithms form an important class of applications for many scientific\nand engineering domains. The key difficulty in achieving higher performance\nfrom these applications is the indirect accesses that lead to data-races when\nparallelized. Current methods for handling such data-races lead to reduced\nparallelism and suboptimal performance. Particularly on modern many-core\narchitectures, such as GPUs, that has increasing core/thread counts, reducing\ndata movement and exploiting memory locality is vital for gaining good\nperformance.\n  In this work we present novel locality-exploiting optimizations for the\nefficient execution of unstructured-mesh algorithms on GPUs. Building on a\ntwo-layered coloring strategy for handling data races, we introduce novel\nreordering and partitioning techniques to further improve efficient execution.\nThe new optimizations are then applied to several well established\nunstructured-mesh applications, investigating their performance on NVIDIA's\nlatest P100 and V100 GPUs. We demonstrate significant speedups\n($1.1\\text{--}1.75\\times$) compared to the state-of-the-art. A range of\nperformance metrics are benchmarked including runtime, memory transactions,\nachieved bandwidth performance, GPU occupancy and data reuse factors and are\nused to understand and explain the key factors impacting performance. The\noptimized algorithms are implemented as an open-source software library and we\nillustrate its use for improving performance of existing or new\nunstructured-mesh applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03749v4"
    },
    {
        "title": "Comparative study of finite element methods using the Time-Accuracy-Size\n  (TAS) spectrum analysis",
        "authors": [
            "Justin Chang",
            "Maurice S. Fabien",
            "Matthew G. Knepley",
            "Richard T. Mills"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We present a performance analysis appropriate for comparing algorithms using\ndifferent numerical discretizations. By taking into account the total\ntime-to-solution, numerical accuracy with respect to an error norm, and the\ncomputation rate, a cost-benefit analysis can be performed to determine which\nalgorithm and discretization are particularly suited for an application. This\nwork extends the performance spectrum model in Chang et. al. 2017 for\ninterpretation of hardware and algorithmic tradeoffs in numerical PDE\nsimulation. As a proof-of-concept, popular finite element software packages are\nused to illustrate this analysis for Poisson's equation.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.07832v1"
    },
    {
        "title": "Numerical integration in arbitrary-precision ball arithmetic",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We present an implementation of arbitrary-precision numerical integration\nwith rigorous error bounds in the Arb library. Rapid convergence is ensured for\npiecewise complex analytic integrals by use of the Petras algorithm, which\ncombines adaptive bisection with adaptive Gaussian quadrature where error\nbounds are determined via complex magnitudes without evaluating derivatives.\nThe code is general, easy to use, and efficient, often outperforming existing\nnon-rigorous software.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.07942v1"
    },
    {
        "title": "Moore: Interval Arithmetic in C++20",
        "authors": [
            "Walter F. Mascarenhas"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This article presents the Moore library for interval arithmetic in C++20. It\ngives examples of how the library can be used, and explains the basic\nprinciples underlying its design.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.08558v1"
    },
    {
        "title": "Sparse Tensor Algebra Optimizations with Workspaces",
        "authors": [
            "Fredrik Kjolstad",
            "Willow Ahrens",
            "Shoaib Kamil",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This paper shows how to optimize sparse tensor algebraic expressions by\nintroducing temporary tensors, called workspaces, into the resulting loop\nnests. We develop a new intermediate language for tensor operations called\nconcrete index notation that extends tensor index notation. Concrete index\nnotation expresses when and where sub-computations occur and what tensor they\nare stored into. We then describe the workspace optimization in this language,\nand how to compile it to sparse code by building on prior work in the\nliterature.\n  We demonstrate the importance of the optimization on several important sparse\ntensor kernels, including sparse matrix-matrix multiplication (SpMM), sparse\ntensor addition (SpAdd), and the matricized tensor times Khatri-Rao product\n(MTTKRP) used to factorize tensors. Our results show improvements over prior\nwork on tensor algebra compilation and brings the performance of these kernels\non par with state-of-the-art hand-optimized implementations. For example, SpMM\nwas not supported by prior tensor algebra compilers, the performance of MTTKRP\non the nell-2 data set improves by 35%, and MTTKRP can for the first time have\nsparse results.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.10574v2"
    },
    {
        "title": "Format Abstraction for Sparse Tensor Algebra Compilers",
        "authors": [
            "Stephen Chou",
            "Fredrik Kjolstad",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This paper shows how to build a sparse tensor algebra compiler that is\nagnostic to tensor formats (data layouts). We develop an interface that\ndescribes formats in terms of their capabilities and properties, and show how\nto build a modular code generator where new formats can be added as plugins. We\nthen describe six implementations of the interface that compose to form the\ndense, CSR/CSF, COO, DIA, ELL, and HASH tensor formats and countless variants\nthereof. With these implementations at hand, our code generator can generate\ncode to compute any tensor algebra expression on any combination of the\naforementioned formats.\n  To demonstrate our technique, we have implemented it in the taco tensor\nalgebra compiler. Our modular code generator design makes it simple to add\nsupport for new tensor formats, and the performance of the generated code is\ncompetitive with hand-optimized implementations. Furthermore, by extending taco\nto support a wider range of formats specialized for different application and\ndata characteristics, we can improve end-user application performance. For\nexample, if input data is provided in the COO format, our technique allows\ncomputing a single matrix-vector multiplication directly with the data in COO,\nwhich is up to 3.6$\\times$ faster than by first converting the data to CSR.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.10112v2"
    },
    {
        "title": "Automatic generation of CUDA code performing tensor manipulations using\n  C++ expression templates",
        "authors": [
            "Adam G. M. Lewis",
            "Harald P. Pfeiffer"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We present a C++ library, TLoops, which uses a hierarchy of expression\ntemplates to represent operations upon tensorial quantities in single lines of\nC++ code that resemble analytic equations. These expressions may be run as-is,\nbut may also be used to emit equivalent low-level C or CUDA code, which either\nperforms the operations more quickly on the CPU, or allows them to be rapidly\nported to run on NVIDIA GPUs. We detail the expression template and C++-class\nhierarchy that represents the expressions and which makes automatic\ncode-generation possible. We then present benchmarks of the expression-template\ncode, the automatically generated C code, and the automatically generated CUDA\ncode running on several generations of NVIDIA GPU.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.10120v1"
    },
    {
        "title": "A Scalable and Modular Software Architecture for Finite Elements on\n  Hierarchical Hybrid Grids",
        "authors": [
            "Nils Kohl",
            "Dominik Thönnes",
            "Daniel Drzisga",
            "Dominik Bartuschat",
            "Ulrich Rüde"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this article, a new generic higher-order finite-element framework for\nmassively parallel simulations is presented. The modular software architecture\nis carefully designed to exploit the resources of modern and future\nsupercomputers. Combining an unstructured topology with structured grid\nrefinement facilitates high geometric adaptability and matrix-free multigrid\nimplementations with excellent performance. Different abstraction levels and\nfully distributed data structures additionally ensure high flexibility,\nextensibility, and scalability. The software concepts support sophisticated\nload balancing and flexibly combining finite element spaces. Example scenarios\nwith coupled systems of PDEs show the applicability of the concepts to\nperforming geophysical simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10167v1"
    },
    {
        "title": "Validation of a PETSc based software implementing a 4DVAR Data\n  Assimilation algorithm: a case study related with an Oceanic Model based on\n  Shallow Water equation",
        "authors": [
            "Luisa Carracciuolo",
            "Emil M. Constantinescu",
            "Luisa D'Amore"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this work are presented and discussed some results related to the\nvalidation process of a software module based on PETSc which implements a Data\nAssimilation algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.01361v2"
    },
    {
        "title": "GPdoemd: a Python package for design of experiments for model\n  discrimination",
        "authors": [
            "Simon Olofsson",
            "Lukas Hebing",
            "Sebastian Niedenführ",
            "Marc Peter Deisenroth",
            "Ruth Misener"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Model discrimination identifies a mathematical model that usefully explains\nand predicts a given system's behaviour. Researchers will often have several\nmodels, i.e. hypotheses, about an underlying system mechanism, but insufficient\nexperimental data to discriminate between the models, i.e. discard inaccurate\nmodels. Given rival mathematical models and an initial experimental data set,\noptimal design of experiments suggests maximally informative experimental\nobservations that maximise a design criterion weighted by prediction\nuncertainty. The model uncertainty requires gradients, which may not be readily\navailable for black-box models. This paper (i) proposes a new design criterion\nusing the Jensen-R\\'enyi divergence, and (ii) develops a novel method replacing\nblack-box models with Gaussian process surrogates. Using the surrogates, we\nmarginalise out the model parameters with approximate inference. Results show\nthese contributions working well for both classical and new test instances. We\nalso (iii) introduce and discuss GPdoemd, the open-source implementation of the\nGaussian process surrogate method.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02561v3"
    },
    {
        "title": "Expressing Sparse Matrix Computations for Productive Performance on\n  Spatial Architectures",
        "authors": [
            "Hongbo Rong"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This paper addresses spatial programming of sparse matrix computations for\nproductive performance. The challenge is how to express an irregular\ncomputation and its optimizations in a regular way.\n  A sparse matrix has (non-zero) values and a structure. In this paper, we\npropose to classify the implementations of a computation on a sparse matrix\ninto two categories: (1) structure-driven, or top-down, approach, which\ntraverses the structure with given row and column indices and locates the\ncorresponding values, and (2) values-driven, or bottom-up, approach, which\nloads and processes the values in parallel streams, and decodes the structure\nfor the values' corresponding row and column indices.\n  On a spatial architecture like FPGAs, the values-driven approach is the norm.\nWe show how to express a sparse matrix computation and its optimizations for a\nvalues-driven implementation. A compiler automatically synthesizes a code to\ndecode the structure. In this way, programmers focus on optimizing the\nprocessing of the values, using familiar optimizations for dense matrices,\nwhile leaving the complex, irregular structure traversal to an automatic\ncompiler. We also attempt to regularize the optimizations of the reduction for\na dynamic number of values, which is common in a sparse matrix computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.07517v1"
    },
    {
        "title": "The Ocean Tensor Package",
        "authors": [
            "Ewout van den Berg"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Matrix and tensor operations form the basis of a wide range of fields and\napplications, and in many cases constitute a substantial part of the overall\ncomputational complexity. The ability of general-purpose GPUs to speed up many\nof these operations and enable others has resulted in a widespread adaptation\nof these devices. In order for tensor operations to take full advantage of the\ncomputational power, specialized software is required, and currently there\nexist several packages (predominantly in the area of deep learning) that\nincorporate tensor operations on both CPU and GPU. Nevertheless, a stand-alone\nframework that supports general tensor operations is still missing. In this\npaper we fill this gap and propose the Ocean Tensor Library: a modular\ntensor-support package that is designed to serve as a foundational layer for\napplications that require dense tensor operations on a variety of device types.\nThe API is carefully designed to be powerful, extensible, and at the same time\neasy to use. The package is available as open source.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.08723v1"
    },
    {
        "title": "Efficient Distributed-Memory Parallel Matrix-Vector Multiplication with\n  Wide or Tall Unstructured Sparse Matrices",
        "authors": [
            "Jonathan Eckstein",
            "Gyorgy Matyasfalvi"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This paper presents an efficient technique for matrix-vector and\nvector-transpose-matrix multiplication in distributed-memory parallel computing\nenvironments, where the matrices are unstructured, sparse, and have a\nsubstantially larger number of columns than rows or vice versa. Our method\nallows for parallel I/O, does not require extensive preprocessing, and has the\nsame communication complexity as matrix-vector multiplies with column or row\npartitioning. Our implementation of the method uses MPI. We partition the\nmatrix by individual nonzero elements, rather than by row or column, and use an\n\"overlapped\" vector representation that is matched to the matrix. The transpose\nmultiplies use matrix-specific MPI communicators and reductions that we show\ncan be set up in an efficient manner. The proposed technique achieves a good\nwork per processor balance even if some of the columns are dense, while keeping\ncommunication costs relatively low.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.00904v1"
    },
    {
        "title": "Functional Design of Computation Graph",
        "authors": [
            "Pierre Vandenhove"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Representing the control flow of a computer program as a computation graph\ncan bring many benefits in a broad variety of domains where performance is\ncritical. This technique is a core component of most major numerical libraries\n(TensorFlow, PyTorch, Theano, MXNet,...) and is successfully used to speed up\nand optimise many computationally-intensive tasks. However, different design\nchoices in each of these libraries lead to noticeable differences in efficiency\nand in the way an end user writes efficient code. In this report, we detail the\nimplementation and features of the computation graph support in OCaml's\nnumerical library Owl, a recent entry in the world of scientific computing.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.03770v1"
    },
    {
        "title": "Javelin: A Scalable Implementation for Sparse Incomplete LU\n  Factorization",
        "authors": [
            "Joshua Dennis Booth",
            "Gregory Bolet"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this work, we present a new scalable incomplete LU factorization framework\ncalled Javelin to be used as a preconditioner for solving sparse linear systems\nwith iterative methods. Javelin allows for improved parallel factorization on\nshared-memory many-core systems by packaging the coefficient matrix into a\nformat that allows for high performance sparse matrix-vector multiplication and\nsparse triangular solves with minimal overheads. The framework achieves these\ngoals by using a collection of traditional permutations, point-to-point thread\nsynchronizations, tasking, and segmented prefix scans in a conventional\ncompressed sparse row format. Moreover, this framework stresses the importance\nof co-designing dependent tasks, such as sparse factorization and triangular\nsolves, on highly-threaded architectures. Using these changes, traditional\nfill-in and drop tolerance methods can be used, while still being able to have\nobserved speedups of up to ~42x on 68 Intel Knights Landing cores and ~12x on\n14 Intel Haswell cores.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.06160v3"
    },
    {
        "title": "pyLLE: a Fast and User Friendly Lugiato-Lefever Equation Solver",
        "authors": [
            "Gregory Moille",
            "Qing Li",
            "Xiyuan Lu",
            "Kartik Srinivasan"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present the development of pyLLE, a freely accessible and cross-platform\nLugiato-Lefever equation solver programmed in Python and Julia and optimized\nfor the simulation of microresonator frequency combs. Examples illustrating its\noperation, the simplicity of use, and performance against other programming\nlanguage are presented. The documentation of the software can be found at\nhttps://gregmoille.github.io/pyLLE/\n",
        "pdf_link": "http://arxiv.org/pdf/1903.10441v2"
    },
    {
        "title": "Yet Another Tensor Toolbox for discontinuous Galerkin methods and other\n  applications",
        "authors": [
            "Carsten Uphoff",
            "Michael Bader"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The numerical solution of partial differential equations is at the heart of\nmany grand challenges in supercomputing. Solvers based on high-order\ndiscontinuous Galerkin (DG) discretisation have been shown to scale on large\nsupercomputers with excellent performance and efficiency, if the implementation\nexploits all levels of parallelism and is tailored to the specific\narchitecture. However, every year new supercomputers emerge and the list of\nhardware-specific considerations grows, simultaneously with the list of desired\nfeatures in a DG code. Thus we believe that a sustainable DG code needs an\nabstraction layer to implement the numerical scheme in a suitable language. We\nexplore the possibility to abstract the numerical scheme as small tensor\noperations, describe them in a domain-specific language (DSL) resembling the\nEinstein notation, and to map them to existing code generators which generate\nsmall matrix matrix multiplication routines. The compiler for our DSL\nimplements classic optimisations that are used for large tensor contractions,\nand we present novel optimisation techniques such as equivalent sparsity\npatterns and optimal index permutations for temporary tensors. Our application\nexamples, which include the earthquake simulation software SeisSol, show that\nthe generated kernels achieve over 50 % peak performance while the DSL\nconsiderably simplifies the implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.11521v1"
    },
    {
        "title": "COFFEE -- An MPI-parallelized Python package for the numerical evolution\n  of differential equations",
        "authors": [
            "Georgios Doulis",
            "Jörg Frauendiener",
            "Chris Stevens",
            "Ben Whale"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  COFFEE (ConFormal Field Equation Evolver) is a Python package primarily\ndeveloped to numerically evolve systems of partial differential equations over\ntime using the method of lines. It includes a variety of time integrators and\nfinite differencing stencils with the summation-by-parts property, as well as\npseudo-spectral functionality for angular derivatives of spin-weighted\nfunctions. Some additional capabilities include being MPI-parallelisable on a\nvariety of different geometries, HDF data output and post processing scripts to\nvisualize data, and an actions class that allows users to create code for\nanalysis after each timestep.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.12482v2"
    },
    {
        "title": "A parallel structured divide-and-conquer algorithm for symmetric\n  tridiagonal eigenvalue problems",
        "authors": [
            "Xia Liao",
            "Shengguo Li",
            "Yutong Lu",
            "Jose E. Roman"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper, a parallel structured divide-and-conquer (PSDC) eigensolver is\nproposed for symmetric tridiagonal matrices based on ScaLAPACK and a parallel\nstructured matrix multiplication algorithm, called PSMMA. Computing the\neigenvectors via matrix-matrix multiplications is the most computationally\nexpensive part of the divide-and-conquer algorithm, and one of the matrices\ninvolved in such multiplications is a rank-structured Cauchy-like matrix. By\nexploiting this particular property, PSMMA constructs the local matrices by\nusing generators of Cauchy-like matrices without any communication, and further\nreduces the computation costs by using a structured low-rank approximation\nalgorithm. Thus, both the communication and computation costs are reduced.\nExperimental results show that both PSMMA and PSDC are highly scalable and\nscale to 4096 processes at least. PSDC has better scalability than PHDC that\nwas proposed in [J. Comput. Appl. Math. 344 (2018) 512--520] and only scaled to\n300 processes for the same matrices. Comparing with \\texttt{PDSTEDC} in\nScaLAPACK, PSDC is always faster and achieves $1.4$x--$1.6$x speedup for some\nmatrices with few deflations. PSDC is also comparable with ELPA, with PSDC\nbeing faster than ELPA when using few processes and a little slower when using\nmany processes.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.01990v2"
    },
    {
        "title": "Randomized Projection for Rank-Revealing Matrix Factorizations and\n  Low-Rank Approximations",
        "authors": [
            "Jed A. Duersch",
            "Ming Gu"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Rank-revealing matrix decompositions provide an essential tool in spectral\nanalysis of matrices, including the Singular Value Decomposition (SVD) and\nrelated low-rank approximation techniques. QR with Column Pivoting (QRCP) is\nusually suitable for these purposes, but it can be much slower than the\nunpivoted QR algorithm. For large matrices, the difference in performance is\ndue to increased communication between the processor and slow memory, which\nQRCP needs in order to choose pivots during decomposition. Our main algorithm,\nRandomized QR with Column Pivoting (RQRCP), uses randomized projection to make\npivot decisions from a much smaller sample matrix, which we can construct to\nreside in a faster level of memory than the original matrix. This technique may\nbe understood as trading vastly reduced communication for a controlled increase\nin uncertainty during the decision process. For rank-revealing purposes, the\nselection mechanism in RQRCP produces results that are the same quality as the\nstandard algorithm, but with performance near that of unpivoted QR (often an\norder of magnitude faster for large matrices). We also propose two formulas\nthat facilitate further performance improvements. The first efficiently updates\nsample matrices to avoid computing new randomized projections. The second\navoids large trailing updates during the decomposition in truncated low-rank\napproximations. Our truncated version of RQRCP also provides a key initial step\nin our truncated SVD approximation, TUXV. These advances open up a new\nperformance domain for large matrix factorizations that will support efficient\nproblem-solving techniques for challenging applications in science,\nengineering, and data analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.04447v1"
    },
    {
        "title": "Evaluating the Performance of NVIDIA's A100 Ampere GPU for Sparse Linear\n  Algebra Computations",
        "authors": [
            "Yuhsiang Mike Tsai",
            "Terry Cojean",
            "Hartwig Anzt"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  GPU accelerators have become an important backbone for scientific high\nperformance computing, and the performance advances obtained from adopting new\nGPU hardware are significant. In this paper we take a first look at NVIDIA's\nnewest server line GPU, the A100 architecture part of the Ampere generation.\nSpecifically, we assess its performance for sparse linear algebra operations\nthat form the backbone of many scientific applications and assess the\nperformance improvements over its predecessor.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.08478v1"
    },
    {
        "title": "Fast MATLAB assembly of FEM matrices in 2D and 3D: Edge elements",
        "authors": [
            "Immanuel Anjam",
            "Jan Valdman"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We propose an effective and flexible way to assemble finite element stiffness\nand mass matrices in MATLAB. We apply this for problems discretized by edge\nfinite elements. Typical edge finite elements are Raviart-Thomas elements used\nin discretizations of H(div) spaces and Nedelec elements in discretizations of\nH(curl) spaces. We explain vectorization ideas and comment on a freely\navailable MATLAB code which is fast and scalable with respect to time.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.4618v2"
    },
    {
        "title": "On the Performance Prediction of BLAS-based Tensor Contractions",
        "authors": [
            "Elmar Peise",
            "Diego Fabregat-Traver",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Tensor operations are surging as the computational building blocks for a\nvariety of scientific simulations and the development of high-performance\nkernels for such operations is known to be a challenging task. While for\noperations on one- and two-dimensional tensors there exist standardized\ninterfaces and highly-optimized libraries (BLAS), for higher dimensional\ntensors neither standards nor highly-tuned implementations exist yet. In this\npaper, we consider contractions between two tensors of arbitrary dimensionality\nand take on the challenge of generating high-performance implementations by\nresorting to sequences of BLAS kernels. The approach consists in breaking the\ncontraction down into operations that only involve matrices or vectors. Since\nin general there are many alternative ways of decomposing a contraction, we are\nable to methodically derive a large family of algorithms. The main contribution\nof this paper is a systematic methodology to accurately identify the fastest\nalgorithms in the bunch, without executing them. The goal is instead\naccomplished with the help of a set of cache-aware micro-benchmarks for the\nunderlying BLAS kernels. The predictions we construct from such benchmarks\nallow us to reliably single out the best-performing algorithms in a tiny\nfraction of the time taken by the direct execution of the algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.8608v1"
    },
    {
        "title": "Language-based Abstractions for Dynamical Systems",
        "authors": [
            "Andrea Vandin"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Ordinary differential equations (ODEs) are the primary means to modelling\ndynamical systems in many natural and engineering sciences. The number of\nequations required to describe a system with high heterogeneity limits our\ncapability of effectively performing analyses. This has motivated a large body\nof research, across many disciplines, into abstraction techniques that provide\nsmaller ODE systems while preserving the original dynamics in some appropriate\nsense. In this paper we give an overview of a recently proposed\ncomputer-science perspective to this problem, where ODE reduction is recast to\nfinding an appropriate equivalence relation over ODE variables, akin to\nclassical models of computation based on labelled transition systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.04254v1"
    },
    {
        "title": "Example Setups of Navier-Stokes Equations with Control and Observation:\n  Spatial Discretization and Representation via Linear-quadratic Matrix\n  Coefficients",
        "authors": [
            "Maximilian Behr",
            "Peter Benner",
            "Jan Heiland"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We provide spatial discretizations of nonlinear incompressible Navier-Stokes\nequations with inputs and outputs in the form of matrices ready to use in any\nnumerical linear algebra package. We discuss the assembling of the system\noperators and the realization of boundary conditions and inputs and outputs. We\ndescribe the two benchmark problems - the driven cavity and the cylinder wake -\nand provide the corresponding data. The use of the data is illustrated by\nnumerous example setups. The test cases are provided as plain PYTHON or\nOCTAVE/MATLAB script files for immediate replication.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.08711v1"
    },
    {
        "title": "An Open Source C++ Implementation of Multi-Threaded Gaussian Mixture\n  Models, k-Means and Expectation Maximisation",
        "authors": [
            "Conrad Sanderson",
            "Ryan Curtin"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Modelling of multivariate densities is a core component in many signal\nprocessing, pattern recognition and machine learning applications. The\nmodelling is often done via Gaussian mixture models (GMMs), which use\ncomputationally expensive and potentially unstable training algorithms. We\nprovide an overview of a fast and robust implementation of GMMs in the C++\nlanguage, employing multi-threaded versions of the Expectation Maximisation\n(EM) and k-means training algorithms. Multi-threading is achieved through\nreformulation of the EM and k-means algorithms into a MapReduce-like framework.\nFurthermore, the implementation uses several techniques to improve numerical\nstability and modelling accuracy. We demonstrate that the multi-threaded\nimplementation achieves a speedup of an order of magnitude on a recent 16 core\nmachine, and that it can achieve higher modelling accuracy than a previously\nwell-established publically accessible implementation. The multi-threaded\nimplementation is included as a user-friendly class in recent releases of the\nopen source Armadillo C++ linear algebra library. The library is provided under\nthe permissive Apache~2.0 license, allowing unencumbered use in commercial\nproducts.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.09094v1"
    },
    {
        "title": "Large-Scale Discrete Fourier Transform on TPUs",
        "authors": [
            "Tianjian Lu",
            "Yi-Fan Chen",
            "Blake Hechtman",
            "Tao Wang",
            "John Anderson"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this work, we present two parallel algorithms for the large-scale discrete\nFourier transform (DFT) on Tensor Processing Unit (TPU) clusters. The two\nparallel algorithms are associated with two formulations of DFT: one is based\non the Kronecker product, to be specific, dense matrix multiplications between\nthe input data and the Vandermonde matrix, denoted as KDFT in this work; the\nother is based on the famous Cooley-Tukey algorithm and phase adjustment,\ndenoted as FFT in this work. Both KDFT and FFT formulations take full advantage\nof TPU's strength in matrix multiplications. The KDFT formulation allows direct\nuse of nonuniform inputs without additional step. In the two parallel\nalgorithms, the same strategy of data decomposition is applied to the input\ndata. Through the data decomposition, the dense matrix multiplications in KDFT\nand FFT are kept local within TPU cores, which can be performed completely in\nparallel. The communication among TPU cores is achieved through the one-shuffle\nscheme in both parallel algorithms, with which sending and receiving data takes\nplace simultaneously between two neighboring cores and along the same direction\non the interconnect network. The one-shuffle scheme is designed for the\ninterconnect topology of TPU clusters, minimizing the time required by the\ncommunication among TPU cores. Both KDFT and FFT are implemented in TensorFlow.\nThe three-dimensional complex DFT is performed on an example of dimension $8192\n\\times 8192 \\times 8192$ with a full TPU Pod: the run time of KDFT is 12.66\nseconds and that of FFT is 8.3 seconds. Scaling analysis is provided to\ndemonstrate the high parallel efficiency of the two DFT implementations on\nTPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.03260v3"
    },
    {
        "title": "Task-based, GPU-accelerated and Robust Library for Solving Dense\n  Nonsymmetric Eigenvalue Problems",
        "authors": [
            "Mirko Myllykoski",
            "Carl Christian Kjelgaard Mikkelsen"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper, we present the StarNEig library for solving dense nonsymmetric\nstandard and generalized eigenvalue problems. The library is built on top of\nthe StarPU runtime system and targets both shared and distributed memory\nmachines. Some components of the library have support for GPU acceleration. The\nlibrary is currently in an early beta state and supports only real matrices.\nSupport for complex matrices is planned for a future release. This paper is\naimed at potential users of the library. We describe the design choices and\ncapabilities of the library, and contrast them to existing software such as\nScaLAPACK. StarNEig implements a ScaLAPACK compatibility layer which should\nassist new users in the transition to StarNEig. We demonstrate the performance\nof the library with a sample of computational experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.05024v1"
    },
    {
        "title": "A unified sparse matrix data format for efficient general sparse\n  matrix-vector multiply on modern processors with wide SIMD units",
        "authors": [
            "Moritz Kreutzer",
            "Georg Hager",
            "Gerhard Wellein",
            "Holger Fehske",
            "Alan R. Bishop"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Sparse matrix-vector multiplication (spMVM) is the most time-consuming kernel\nin many numerical algorithms and has been studied extensively on all modern\nprocessor and accelerator architectures. However, the optimal sparse matrix\ndata storage format is highly hardware-specific, which could become an obstacle\nwhen using heterogeneous systems. Also, it is as yet unclear how the wide\nsingle instruction multiple data (SIMD) units in current multi- and many-core\nprocessors should be used most efficiently if there is no structure in the\nsparsity pattern of the matrix. We suggest SELL-C-sigma, a variant of Sliced\nELLPACK, as a SIMD-friendly data format which combines long-standing ideas from\nGeneral Purpose Graphics Processing Units (GPGPUs) and vector computer\nprogramming. We discuss the advantages of SELL-C-sigma compared to established\nformats like Compressed Row Storage (CRS) and ELLPACK and show its suitability\non a variety of hardware platforms (Intel Sandy Bridge, Intel Xeon Phi and\nNvidia Tesla K20) for a wide range of test matrices from different application\nareas. Using appropriate performance models we develop deep insight into the\ndata transfer properties of the SELL-C-sigma spMVM kernel. SELL-C-sigma comes\nwith two tuning parameters whose performance impact across the range of test\nmatrices is studied and for which reasonable choices are proposed. This leads\nto a hardware-independent (\"catch-all\") sparse matrix format, which achieves\nvery high efficiency for all test matrices across all hardware platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.6209v2"
    },
    {
        "title": "Python for education: permutations",
        "authors": [
            "Andrzej Kapanowski"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Python implementation of permutations is presented. Three classes are\nintroduced: Perm for permutations, Group for permutation groups, and PermError\nto report any errors for both classes. The class Perm is based on Python\ndictionaries and utilize cycle notation. The methods of calculation for the\nperm order, parity, ranking and unranking are given. A random permutation\ngeneration is also shown. The class Group is very simple and it is also based\non dictionaries. It is mainly the presentation of the permutation groups\ninterface with methods for the group order, subgroups (normalizer, centralizer,\ncenter, stabilizer), orbits, and several tests. The corresponding Python code\nis contained in the modules perms and groups.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.7042v1"
    },
    {
        "title": "Bloscpack: a compressed lightweight serialization format for numerical\n  data",
        "authors": [
            "Valentin Haenel"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  This paper introduces the Bloscpack file format and the accompanying Python\nreference implementation. Bloscpack is a lightweight, compressed binary\nfile-format based on the Blosc codec and is designed for lightweight, fast\nserialization of numerical data. This article presents the features of the\nfile-format and some some API aspects of the reference implementation, in\nparticular the ability to handle Numpy ndarrays. Furthermore, in order to\ndemonstrate its utility, the format is compared both feature- and\nperformance-wise to a few alternative lightweight serialization solutions for\nNumpy ndarrays. The performance comparisons take the form of some comprehensive\nbenchmarks over a range of different artificial datasets with varying size and\ncomplexity, the results of which are presented as the last section of this\narticle.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.6383v2"
    },
    {
        "title": "Performance of Python runtimes on a non-numeric scientific code",
        "authors": [
            "Riccardo Murri"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The Python library FatGHol FatGHoL used in Murri2012 to reckon the rational\nhomology of the moduli space of Riemann surfaces is an example of a non-numeric\nscientific code: most of the processing it does is generating graphs\n(represented by complex Python objects) and computing their isomorphisms (a\ntriple of Python lists; again a nested data structure). These operations are\nrepeated many times over: for example, the spaces and are triangulated by\n4'583'322 and 747'664 graphs, respectively. This is an opportunity for every\nPython runtime to prove its strength in optimization. The purpose of this\nexperiment was to assess the maturity of alternative Python runtimes, in terms\nof: compatibility with the language as implemented in CPython 2.7, and\nperformance speedup. This paper compares the results and experiences from\nrunning FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython\n0.19, Numba 0.11, Nuitka 0.4.4 and Falcon.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.6388v2"
    },
    {
        "title": "Lacunaryx: Computing bounded-degree factors of lacunary polynomials",
        "authors": [
            "Bruno Grenet"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  In this paper, we report on an implementation in the free software Mathemagix\nof lacunary factorization algorithms, distributed as a library called\nLacunaryx. These algorithms take as input a polynomial in sparse\nrepresentation, that is as a list of nonzero monomials, and an integer $d$, and\ncompute its irreducible degree-$\\le d$ factors. The complexity of these\nalgorithms is polynomial in the sparse size of the input polynomial and $d$.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.03726v2"
    },
    {
        "title": "Encog: Library of Interchangeable Machine Learning Models for Java and\n  C#",
        "authors": [
            "Jeff Heaton"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  This paper introduces the Encog library for Java and C#, a scalable,\nadaptable, multiplatform machine learning framework that was 1st released in\n2008. Encog allows a variety of machine learning models to be applied to\ndatasets using regression, classification, and clustering. Various supported\nmachine learning models can be used interchangeably with minimal recoding.\nEncog uses efficient multithreaded code to reduce training time by exploiting\nmodern multicore processors. The current version of Encog can be downloaded\nfrom http://www.encog.org.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.04776v1"
    },
    {
        "title": "GRINS: A Multiphysics Framework Based on the libMesh Finite Element\n  Library",
        "authors": [
            "Paul T. Bauman",
            "Roy H. Stogner"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The progression of scientific computing resources has enabled the numerical\napproximation of mathematical models describing complex physical phenomena. A\nsignificant portion of researcher time is typically dedicated to the\ndevelopment of software to compute the numerical solutions. This work describes\na flexible C++ software framework, built on the libMesh finite element library,\ndesigned to alleviate developer burden and provide easy access to modern\ncomputational algorithms, including quantity-of-interest-driven parallel\nadaptive mesh refinement on unstructured grids and adjoint-based sensitivities.\nOther software environments are highlighted and the current work motivated; in\nparticular, the present work is an attempt to balance software infrastructure\nand user flexibility. The applicable class of problems and design of the\nsoftware components is discussed in detail. Several examples demonstrate the\neffectiveness of the design, including applications that incorporate\nuncertainty. Current and planned developments are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.06102v1"
    },
    {
        "title": "Resilience for Multigrid Software at the Extreme Scale",
        "authors": [
            "Markus Huber",
            "Björn Gmeiner",
            "Ulrich Rüde",
            "Barbara Wohlmuth"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Fault tolerant algorithms for the numerical approximation of elliptic partial\ndifferential equations on modern supercomputers play a more and more important\nrole in the future design of exa-scale enabled iterative solvers. Here, we\ncombine domain partitioning with highly scalable geometric multigrid schemes to\nobtain fast and fault-robust solvers in three dimensions. The recovery strategy\nis based on a hierarchical hybrid concept where the values on lower dimensional\nprimitives such as faces are stored redundantly and thus can be recovered\neasily in case of a failure. The lost volume unknowns in the faulty region are\nre-computed approximately with multigrid cycles by solving a local Dirichlet\nproblem on the faulty subdomain. Different strategies are compared and\nevaluated with respect to performance, computational cost, and speed up.\nEspecially effective are strategies in which the local recovery in the faulty\nregion is executed in parallel with global solves and when the local recovery\nis additionally accelerated. This results in an asynchronous multigrid\niteration that can fully compensate faults. Excellent parallel performance on a\ncurrent peta-scale system is demonstrated.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.06185v1"
    },
    {
        "title": "Software realization of the complex spectra analysis algorithm in R",
        "authors": [
            "Vladimir Bakhrushin"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Software realization of the complex spectra decomposition on unknown number\nof similarcomponents is proposed.The algorithm is based on non-linear\nminimizing the sum of squared residuals of the spectrum model. For the adequacy\nchecking the complex of criteria is used.It tests the model residuals\ncorrespondence with the normal distribution, equality to zero of their mean\nvalue and autocorrelation. Also the closeness of residuals and experimental\ndata variances is checked.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.06704v1"
    },
    {
        "title": "pyMOR - Generic Algorithms and Interfaces for Model Order Reduction",
        "authors": [
            "René Milk",
            "Stephan Rave",
            "Felix Schindler"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Reduced basis methods are projection-based model order reduction techniques\nfor reducing the computational complexity of solving parametrized partial\ndifferential equation problems. In this work we discuss the design of pyMOR, a\nfreely available software library of model order reduction algorithms, in\nparticular reduced basis methods, implemented with the Python programming\nlanguage. As its main design feature, all reduction algorithms in pyMOR are\nimplemented generically via operations on well-defined vector array, operator\nand discretization interface classes. This allows for an easy integration with\nexisting open-source high-performance partial differential equation solvers\nwithout adding any model reduction specific code to these solvers. Besides an\nin-depth discussion of pyMOR's design philosophy and architecture, we present\nseveral benchmark results and numerical examples showing the feasibility of our\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.07094v3"
    },
    {
        "title": "A Java Implementation of Parameter-less Evolutionary Algorithms",
        "authors": [
            "José C. Pereira",
            "Fernando G. Lobo"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The Parameter-less Genetic Algorithm was first presented by Harik and Lobo in\n1999 as an alternative to the usual trial-and-error method of finding, for each\ngiven problem, an acceptable set-up of the parameter values of the genetic\nalgorithm. Since then, the same strategy has been successfully applied to\ncreate parameter-less versions of other population-based search algorithms such\nas the Extended Compact Genetic Algorithm and the Hierarchical Bayesian\nOptimization Algorithm. This report describes a Java implementation,\nParameter-less Evolutionary Algorithm (P-EAJava), that integrates several\nparameter-less evolutionary algorithms into a single platform. Along with a\nbrief description of P-EAJava, we also provide detailed instructions on how to\nuse it, how to implement new problems, and how to generate new parameter-less\nversions of evolutionary algorithms.\n  At present time, P-EAJava already includes parameter-less versions of the\nSimple Genetic Algorithm, the Extended Compact Genetic Algorithm, the\nUnivariate Marginal Distribution Algorithm, and the Hierarchical Bayesian\nOptimization Algorithm. The source and binary files of the Java implementation\nof P-EAJava are available for free download at\nhttps://github.com/JoseCPereira/2015ParameterlessEvolutionaryAlgorithmsJava.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.08694v1"
    },
    {
        "title": "Java Implementation of a Parameter-less Evolutionary Portfolio",
        "authors": [
            "José C. Pereira",
            "Fernando G. Lobo"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The Java implementation of a portfolio of parameter-less evolutionary\nalgorithms is presented. The Parameter-less Evolutionary Portfolio implements a\nheuristic that performs adaptive selection of parameter-less evolutionary\nalgorithms in accordance with performance criteria that are measured during\nrunning time. At present time, the portfolio includes three parameter-less\nevolutionary algorithms: Parameter-less Univariate Marginal Distribution\nAlgorithm, Parameter-less Extended Compact Genetic Algorithm, and\nParameter-less Hierarchical Bayesian Optimization Algorithm. Initial\nexperiments showed that the parameter-less portfolio can solve various classes\nof problems without the need for any prior parameter setting technique and with\nan increase in computational effort that can be considered acceptable.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.08867v1"
    },
    {
        "title": "Nauticle: a general-purpose particle-based simulation tool",
        "authors": [
            "Balazs Toth"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Nauticle is a general-purpose simulation tool for the flexible and highly\nconfigurable application of particle-based methods of either discrete or\ncontinuum phenomena. It is presented that Nauticle has three distinct layers\nfor users and developers, then the top two layers are discussed in detail. The\npaper introduces the Symbolic Form Language (SFL) of Nauticle, which\nfacilitates the formulation of user-defined numerical models at the top level\nin text-based configuration files and provides simple application examples of\nuse. On the other hand, at the intermediate level, it is shown that the SFL can\nbe intuitively extended with new particle methods without tedious recoding or\neven the knowledge of the bottom level. Finally, the efficiency of the code is\nalso tested through a performance benchmark.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.08259v2"
    },
    {
        "title": "Investigating the OPS intermediate representation to target GPUs in the\n  Devito DSL",
        "authors": [
            "Vincenzo Pandolfo"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The Devito DSL is a code generation tool for the solution of partial\ndifferential equations using the finite difference method specifically aimed at\nseismic inversion problems.\n  In this work we investigate the integration of OPS, an API to generate highly\noptimized code for applications running on structured meshes targeting various\nplatforms, within Devito as a mean of bringing it to the GPU realm by providing\nan implementation of a OPS backend in Devito, obtaining considerable speed ups\ncompared to the core Devito backend.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.10811v1"
    },
    {
        "title": "A Survey of Singular Value Decomposition Methods for Distributed\n  Tall/Skinny Data",
        "authors": [
            "Drew Schmidt"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The Singular Value Decomposition (SVD) is one of the most important matrix\nfactorizations, enjoying a wide variety of applications across numerous\napplication domains. In statistics and data analysis, the common applications\nof SVD such as Principal Components Analysis (PCA) and linear regression.\nUsually these applications arise on data that has far more rows than columns,\nso-called \"tall/skinny\" matrices. In the big data analytics context, this may\ntake the form of hundreds of millions to billions of rows with only a few\nhundred columns. There is a need, therefore, for fast, accurate, and scalable\ntall/skinny SVD implementations which can fully utilize modern computing\nresources. To that end, we present a survey of three different algorithms for\ncomputing the SVD for these kinds of tall/skinny data layouts using MPI for\ncommunication. We contextualize these with common big data analytics\ntechniques, principally PCA. Finally, we present both CPU and GPU timing\nresults from the Summit supercomputer, and discuss possible alternative\napproaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.00761v1"
    },
    {
        "title": "Dune-CurvedGrid -- A Dune module for surface parametrization",
        "authors": [
            "Simon Praetorius",
            "Florian Stenger"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper we introduce and describe an implementation of curved (surface)\ngeometries within the Dune framework for grid-based discretizations. Therefore,\nwe employ the abstraction of geometries as local-functions bound to a grid\nelement, and the abstraction of a grid as connectivity of elements together\nwith a grid-function that can be localized to the elements to provide element\nlocal parametrizations of the curved surface.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.04938v3"
    },
    {
        "title": "PetIGA: A Framework for High-Performance Isogeometric Analysis",
        "authors": [
            "Lisandro Dalcin",
            "Nathan Collier",
            "Philippe Vignal",
            "Adriano M. A. Cortes",
            "V. M. Calo"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We present PetIGA, a code framework to approximate the solution of partial\ndifferential equations using isogeometric analysis. PetIGA can be used to\nassemble matrices and vectors which come from a Galerkin weak form, discretized\nwith Non-Uniform Rational B-spline basis functions. We base our framework on\nPETSc, a high-performance library for the scalable solution of partial\ndifferential equations, which simplifies the development of large-scale\nscientific codes, provides a rich environment for prototyping, and separates\nparallelism from algorithm choice. We describe the implementation of PetIGA,\nand exemplify its use by solving a model nonlinear problem. To illustrate the\nrobustness and flexibility of PetIGA, we solve some challenging nonlinear\npartial differential equations that include problems in both solid and fluid\nmechanics. We show strong scaling results on up to 4096 cores, which confirm\nthe suitability of PetIGA for large scale simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.4452v3"
    },
    {
        "title": "DiffSharp: An AD Library for .NET Languages",
        "authors": [
            "Atılım Güneş Baydin",
            "Barak A. Pearlmutter",
            "Jeffrey Mark Siskind"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  DiffSharp is an algorithmic differentiation or automatic differentiation (AD)\nlibrary for the .NET ecosystem, which is targeted by the C# and F# languages,\namong others. The library has been designed with machine learning applications\nin mind, allowing very succinct implementations of models and optimization\nroutines. DiffSharp is implemented in F# and exposes forward and reverse AD\noperators as general nestable higher-order functions, usable by any .NET\nlanguage. It provides high-performance linear algebra primitives---scalars,\nvectors, and matrices, with a generalization to tensors underway---that are\nfully supported by all the AD operators, and which use a BLAS/LAPACK backend\nvia the highly optimized OpenBLAS library. DiffSharp currently uses operator\noverloading, but we are developing a transformation-based version of the\nlibrary using F#'s \"code quotation\" metaprogramming facility. Work on a\nCUDA-based GPU backend is also underway.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.03423v1"
    },
    {
        "title": "Implementation and evaluation of data-compression algorithms for\n  irregular-grid iterative methods on the PEZY-SC processor",
        "authors": [
            "Naoki Yoshifuji",
            "Ryo Sakamoto",
            "Keigo Nitadori",
            "Jun Makino"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Iterative methods on irregular grids have been used widely in all areas of\ncomptational science and engineering for solving partial differential equations\nwith complex geometry. They provide the flexibility to express complex shapes\nwith relatively low computational cost. However, the direction of the evolution\nof high-performance processors in the last two decades have caused serious\ndegradation of the computational efficiency of iterative methods on irregular\ngrids, because of relatively low memory bandwidth. Data compression can in\nprinciple reduce the necessary memory memory bandwidth of iterative methods and\nthus improve the efficiency. We have implemented several data compression\nalgorithms on the PEZY-SC processor, using the matrix generated for the HPCG\nbenchmark as an example. For the SpMV (Sparse Matrix-Vector multiplication)\npart of the HPCG benchmark, the best implementation without data compression\nachieved 11.6Gflops/chip, close to the theoretical limit due to the memory\nbandwidth. Our implementation with data compression has achieved 32.4Gflops.\nThis is of course rather extreme case, since the grid used in HPCG is\ngeometrically regular and thus its compression efficiency is very high.\nHowever, in real applications, it is in many cases possible to make a large\npart of the grid to have regular geometry, in particular when the resolution is\nhigh. Note that we do not need to change the structure of the program, except\nfor the addition of the data compression/decompression subroutines. Thus, we\nbelieve the data compression will be very useful way to improve the performance\nof many applications which rely on the use of irregular grids.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.00530v1"
    },
    {
        "title": "BSEPACK User's Guide",
        "authors": [
            "Meiyue Shao",
            "Chao Yang"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  This is the user manual for the software package BSEPACK (Bethe--Salpeter\nEigenvalue Solver Package).\n",
        "pdf_link": "http://arxiv.org/pdf/1612.07848v1"
    },
    {
        "title": "SIMD Vectorization for the Lennard-Jones Potential with AVX2 and AVX-512\n  instructions",
        "authors": [
            "Hiroshi Watanabe",
            "Koh M. Nakagawa"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This work describes the SIMD vectorization of the force calculation of the\nLennard-Jones potential with Intel AVX2 and AVX-512 instruction sets. Since the\nforce-calculation kernel of the molecular dynamics method involves indirect\naccess to memory, the data layout is one of the most important factors in\nvectorization. We find that the Array of Structures (AoS) with padding exhibits\nbetter performance than Structure of Arrays (SoA) with appropriate\nvectorization and optimizations. In particular, AoS with 512-bit width exhibits\nthe best performance among the architectures. While the difference in\nperformance between AoS and SoA is significant for the vectorization with AVX2,\nthat with AVX-512 is minor. The effect of other optimization techniques, such\nas software pipelining together with vectorization, is also discussed. We\npresent results for benchmarks on three CPU architectures: Intel Haswell (HSW),\nKnights Landing (KNL), and Skylake (SKL). The performance gains by\nvectorization are about 42\\% on HSW compared with the code optimized without\nvectorization. On KNL, the hand-vectorized codes exhibit 34\\% better\nperformance than the codes vectorized automatically by the Intel compiler. On\nSKL, the code vectorized with AVX2 exhibits slightly better performance than\nthat with vectorized AVX-512.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.05713v2"
    },
    {
        "title": "Enclave Tasking for Discontinuous Galerkin Methods on Dynamically\n  Adaptive Meshes",
        "authors": [
            "Dominic E. Charrier",
            "Benjamin Hazelwood",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  High-order Discontinuous Galerkin (DG) methods promise to be an excellent\ndiscretisation paradigm for partial differential equation solvers by combining\nhigh arithmetic intensity with localised data access. They also facilitate\ndynamic adaptivity without the need for conformal meshes. A parallel evaluation\nof DG's weak formulation within a mesh traversal is non-trivial, as dependency\ngraphs over dynamically adaptive meshes change, as causal constraints along\nresolution transitions have to be preserved, and as data sends along MPI domain\nboundaries have to be triggered in the correct order. We propose to process\nmesh elements subject to constraints with high priority or, where needed,\nserially throughout a traversal. The remaining cells form enclaves and are\nspawned into a task system. This introduces concurrency, mixes memory-intensive\nDG integrations with compute-bound Riemann solves, and overlaps computation and\ncommunication. We discuss implications on MPI and show that MPI parallelisation\nimproves by a factor of three through enclave tasking, while we obtain an\nadditional factor of two from shared memory if grids are dynamically adaptive.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.07984v3"
    },
    {
        "title": "Function space bases in the dune-functions module",
        "authors": [
            "Christian Engwer",
            "Carsten Gräser",
            "Steffen Müthing",
            "Oliver Sander"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The dune-functions Dune module provides interfaces for functions and function\nspace bases. It forms one abstraction level above grids, shape functions, and\nlinear algebra, and provides infrastructure for full discretization frameworks\nlike dune-pdelab and dune-fem. This document describes the function space bases\nprovided by dune-functions. These are based on an abstract description of bases\nfor product spaces as trees of simpler bases. From this description, many\ndifferent numberings of degrees of freedom by multi-indices can be derived in a\nnatural way. We describe the abstract concepts, document the programmer\ninterface, and give a complete example program that solves the stationary\nStokes equation using Taylor-Hood elements.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.09545v1"
    },
    {
        "title": "Implementation of a Near-Optimal Complex Root Clustering Algorithm",
        "authors": [
            "Rémi Imbach",
            "Victor Y. Pan",
            "Chee Yap"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We describe Ccluster, a software for computing natural $\\epsilon$-clusters of\ncomplex roots in a given box of the complex plane. This algorithm from Becker\net al.~(2016) is near-optimal when applied to the benchmark problem of\nisolating all complex roots of an integer polynomial. It is one of the first\nimplementations of a near-optimal algorithm for complex roots. We describe some\nlow level techniques for speeding up the algorithm. Its performance is compared\nwith the well-known MPSolve library and Maple.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.10584v3"
    },
    {
        "title": "Faster Remainder by Direct Computation: Applications to Compilers and\n  Software Libraries",
        "authors": [
            "Daniel Lemire",
            "Owen Kaser",
            "Nathan Kurz"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  On common processors, integer multiplication is many times faster than\ninteger division. Dividing a numerator n by a divisor d is mathematically\nequivalent to multiplication by the inverse of the divisor (n / d = n x 1/d).\nIf the divisor is known in advance---or if repeated integer divisions will be\nperformed with the same divisor---it can be beneficial to substitute a less\ncostly multiplication for an expensive division.\n  Currently, the remainder of the division by a constant is computed from the\nquotient by a multiplication and a subtraction. But if just the remainder is\ndesired and the quotient is unneeded, this may be suboptimal. We present a\ngenerally applicable algorithm to compute the remainder more directly.\nSpecifically, we use the fractional portion of the product of the numerator and\nthe inverse of the divisor. On this basis, we also present a new, simpler\ndivisibility algorithm to detect nonzero remainders.\n  We also derive new tight bounds on the precision required when representing\nthe inverse of the divisor. Furthermore, we present simple C implementations\nthat beat the optimized code produced by state-of-art C compilers on recent x64\nprocessors (e.g., Intel Skylake and AMD Ryzen), sometimes by more than 25%. On\nall tested platforms including 64-bit ARM and POWER8, our divisibility-test\nfunctions are faster than state-of-the-art Granlund-Montgomery\ndivisibility-test functions, sometimes by more than 50%.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.01961v3"
    },
    {
        "title": "Algorithms and software for projections onto intersections of convex and\n  non-convex sets with applications to inverse problems",
        "authors": [
            "Bas Peters",
            "Felix J. Herrmann"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We propose algorithms and software for computing projections onto the\nintersection of multiple convex and non-convex constraint sets. The software\npackage, called SetIntersectionProjection, is intended for the regularization\nof inverse problems in physical parameter estimation and image processing. The\nprimary design criterion is working with multiple sets, which allows us to\nsolve inverse problems with multiple pieces of prior knowledge. Our algorithms\noutperform the well known Dykstra's algorithm when individual sets are not easy\nto project onto because we exploit similarities between constraint sets. Other\ndesign choices that make the software fast and practical to use, include\nrecently developed automatic selection methods for auxiliary algorithm\nparameters, fine and coarse grained parallelism, and a multilevel acceleration\nscheme. We provide implementation details and examples that show how the\nsoftware can be used to regularize inverse problems. Results show that we\nbenefit from working with all available prior information and are not limited\nto one or two regularizers because of algorithmic, computational, or\nhyper-parameter selection issues.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.09699v2"
    },
    {
        "title": "A new object-oriented framework for solving multiphysics problems via\n  combination of different numerical methods",
        "authors": [
            "Juan Michael Sargado"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Many interesting phenomena are characterized by the complex interaction of\ndifferent physical processes, each often best modeled numerically via a\nspecific approach. In this paper, we present the design and implementation of\nan object-oriented framework for performing multiphysics simulations that\nallows for the monolithic coupling of different numerical schemes. In contrast,\nmost of the currently available simulation tools are tailored towards a\nspecific numerical model, so that one must resort to coupling different codes\nexternally based on operator splitting. The current framework has been\ndeveloped following the C++11 standard, and its main aim is to provide an\nenvironment that affords enough flexibility for developers to implement complex\nmodels while at the same time giving end users a maximum amount of control over\nfiner details of the simulation without having to write additional code. The\nmain challenges towards realizing these objectives are discussed in the paper,\ntogether with the manner in which they are addressed. Along with core objects\nrepresenting the framework skeleton, we present the various polymorphic classes\nthat may be utilized by developers to implement new formulations, material\nmodels and solution algorithms. The code architecture is designed to allow\nachievement of the aforementioned functionalities with a minimum level of\ninheritance in order to improve the learning curve for programmers who are not\nacquainted with the software. Key capabilities of the framework are\ndemonstrated via the solution of numerical examples dealing on composite\ntorsion, Biot poroelasticity (featuring a combined finite element-finite volume\nformulation), and brittle crack propagation using a phase-field approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.00104v1"
    },
    {
        "title": "An optimizing multi-platform source-to-source compiler framework for the\n  NEURON MODeling Language",
        "authors": [
            "Pramod Kumbhar",
            "Omar Awile",
            "Liam Keegan",
            "Jorge Blanco Alonso",
            "James King",
            "Michael Hines",
            "Felix Schürmann"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Domain-specific languages (DSLs) play an increasingly important role in the\ngeneration of high performing software. They allow the user to exploit specific\nknowledge encoded in the constructs for the generation of code adapted to a\nparticular hardware architecture; at the same time, they make it easier to\ngenerate optimized code for a multitude of platforms as the transformation has\nto be encoded only once. Here, we describe a new code generation framework\n(NMODL) for an existing DSL in the NEURON framework, a widely used software for\nmassively parallel simulation of biophysically detailed brain tissue models.\nExisting NMODL DSL transpilers lack either essential features to generate\noptimized code or capability to parse the diversity of existing models in the\nuser community. Our NMODL framework has been tested against a large number of\npreviously published user models and offers high-level domain-specific\noptimizations and symbolic algebraic simplifications before target code\ngeneration. Furthermore, rich analysis tools are provided allowing the\nscientist to introspect models. NMODL implements multiple SIMD and SPMD targets\noptimized for modern hardware. Benchmarks were performed on Intel Skylake,\nIntel KNL and AMD Naples platforms. When comparing NMODL-generated kernels with\nNEURON we observe a speedup of up to 20x, resulting into overall speedups of\ntwo different production simulations by $\\sim$10x. When compared to a\npreviously published SIMD optimized version that heavily relied on\nauto-vectorization by the compiler still a speedup of up to $\\sim$2x is\nobserved.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02241v1"
    },
    {
        "title": "Performance Engineering for Real and Complex Tall & Skinny Matrix\n  Multiplication Kernels on GPUs",
        "authors": [
            "Dominik Ernst",
            "Georg Hager",
            "Jonas Thies",
            "Gerhard Wellein"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  General matrix-matrix multiplications with double-precision real and complex\nentries (DGEMM and ZGEMM) in vendor-supplied BLAS libraries are best optimized\nfor square matrices but often show bad performance for tall & skinny matrices,\nwhich are much taller than wide. NVIDIA's current CUBLAS implementation\ndelivers only a fraction of the potential performance as indicated by the\nroofline model in this case. We describe the challenges and key characteristics\nof an implementation that can achieve close to optimal performance. We further\nevaluate different strategies of parallelization and thread distribution, and\ndevise a flexible, configurable mapping scheme. To ensure flexibility and allow\nfor highly tailored implementations we use code generation combined with\nautotuning. For a large range of matrix sizes in the domain of interest we\nachieve at least 2/3 of the roofline performance and often substantially\noutperform state-of-the art CUBLAS results on an NVIDIA Volta GPGPU.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03136v2"
    },
    {
        "title": "Robust Task-Parallel Solution of the Triangular Sylvester Equation",
        "authors": [
            "Angelika Schwarz",
            "Carl Christian Kjelgaard Mikkelsen"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The Bartels-Stewart algorithm is a standard approach to solving the dense\nSylvester equation. It reduces the problem to the solution of the triangular\nSylvester equation. The triangular Sylvester equation is solved with a variant\nof backward substitution. Backward substitution is prone to overflow. Overflow\ncan be avoided by dynamic scaling of the solution matrix. An algorithm which\nprevents overflow is said to be robust. The standard library LAPACK contains\nthe robust scalar sequential solver dtrsyl. This paper derives a robust,\nlevel-3 BLAS-based task-parallel solver. By adding overflow protection, our\nrobust solver closes the gap between problems solvable by LAPACK and problems\nsolvable by existing non-robust task-parallel solvers. We demonstrate that our\nrobust solver achieves a similar performance as non-robust solvers.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.10574v1"
    },
    {
        "title": "A Unified Iteration Space Transformation Framework for Sparse and Dense\n  Tensor Algebra",
        "authors": [
            "Ryan Senanayake",
            "Fredrik Kjolstad",
            "Changwan Hong",
            "Shoaib Kamil",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We address the problem of optimizing mixed sparse and dense tensor algebra in\na compiler. We show that standard loop transformations, such as strip-mining,\ntiling, collapsing, parallelization and vectorization, can be applied to\nirregular loops over sparse iteration spaces. We also show how these\ntransformations can be applied to the contiguous value arrays of sparse tensor\ndata structures, which we call their position space, to unlock load-balanced\ntiling and parallelism.\n  We have prototyped these concepts in the open-source TACO system, where they\nare exposed as a scheduling API similar to the Halide domain-specific language\nfor dense computations. Using this scheduling API, we show how to optimize\nmixed sparse/dense tensor algebra expressions, how to generate load-balanced\ncode by scheduling sparse tensor algebra in position space, and how to generate\nsparse tensor algebra GPU code. Our evaluation shows that our transformations\nlet us generate good code that is competitive with many hand-optimized\nimplementations from the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.00532v1"
    },
    {
        "title": "Automatic Generation of Efficient Sparse Tensor Format Conversion\n  Routines",
        "authors": [
            "Stephen Chou",
            "Fredrik Kjolstad",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper shows how to generate code that efficiently converts sparse\ntensors between disparate storage formats (data layouts) such as CSR, DIA, ELL,\nand many others. We decompose sparse tensor conversion into three logical\nphases: coordinate remapping, analysis, and assembly. We then develop a\nlanguage that precisely describes how different formats group together and\norder a tensor's nonzeros in memory. This lets a compiler emit code that\nperforms complex remappings of nonzeros when converting between formats. We\nalso develop a query language that can extract statistics about sparse tensors,\nand we show how to emit efficient analysis code that computes such queries.\nFinally, we define an abstract interface that captures how data structures for\nstoring a tensor can be efficiently assembled given specific statistics about\nthe tensor. Disparate formats can implement this common interface, thus letting\na compiler emit optimized sparse tensor conversion code for arbitrary\ncombinations of many formats without hard-coding for any specific combination.\n  Our evaluation shows that the technique generates sparse tensor conversion\nroutines with performance between 1.00 and 2.01$\\times$ that of hand-optimized\nversions in SPARSKIT and Intel MKL, two popular sparse linear algebra\nlibraries. And by emitting code that avoids materializing temporaries, which\nboth libraries need for many combinations of source and target formats, our\ntechnique outperforms those libraries by 1.78 to 4.01$\\times$ for CSC/COO to\nDIA/ELL conversion.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.02609v3"
    },
    {
        "title": "Awkward Arrays in Python, C++, and Numba",
        "authors": [
            "Jim Pivarski",
            "Peter Elmer",
            "David Lange"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The Awkward Array library has been an important tool for physics analysis in\nPython since September 2018. However, some interface and implementation issues\nhave been raised in Awkward Array's first year that argue for a\nreimplementation in C++ and Numba. We describe those issues, the new\narchitecture, and present some examples of how the new interface will look to\nusers. Of particular importance is the separation of kernel functions from data\nstructure management, which allows a C++ implementation and a Numba\nimplementation to share kernel functions, and the algorithm that transforms\nrecord-oriented data into columnar Awkward Arrays.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.06307v2"
    },
    {
        "title": "juSFEM: A Julia-based Open-source Package of Parallel Smoothed Finite\n  Element Method (S-FEM) for Elastic Problems",
        "authors": [
            "Zenan Huo",
            "Gang Mei",
            "Nengxiong Xu"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The Smoothed Finite Element Method (S-FEM) proposed by Liu G.R. can achieve\nmore accurate results than the conventional FEM. Currently, much commercial\nsoftware and many open-source packages have been developed to analyze various\nscience and engineering problems using the FEM. However, there is little work\nfocusing on designing and developing software or packages for the S-FEM. In\nthis paper, we design and implement an open-source package of the parallel\nS-FEM for elastic problems by utilizing the Julia language on multi-core CPU.\nThe Julia language is a fast, easy-to-use, and open-source programming language\nthat was originally designed for high-performance computing. We term our\npackage as juSFEM. To the best of the authors knowledge, juSFEM is the first\npackage of parallel S-FEM developed with the Julia language. To verify the\ncorrectness and evaluate the efficiency of juSFEM, two groups of benchmark\ntests are conducted. The benchmark results show that (1) juSFEM can achieve\naccurate results when compared to commercial FEM software ABAQUS, and (2)\njuSFEM only requires 543 seconds to calculate the displacements of a 3D elastic\ncantilever beam model which is composed of approximately 2 million tetrahedral\nelements, while in contrast the commercial FEM software needs 930 seconds for\nthe same calculation model; (3) the parallel juSFEM executed on the 24-core CPU\nis approximately 20x faster than the corresponding serial version. Moreover,\nthe structure and function of juSFEM are easily modularized, and the code in\njuSFEM is clear and readable, which is convenient for further development.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.08849v1"
    },
    {
        "title": "A modular extension for a computer algebra system",
        "authors": [
            "Migran N. Gevorkyan",
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov",
            "Leonid A. Sevastianov"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Computer algebra systems are complex software systems that cover a wide range\nof scientific and practical problems. However, the absolute coverage cannot be\nachieved. Often, it is required to create a user extension for an existing\ncomputer algebra system. In this case, the extensibility of the system should\nbe taken into account. In this paper, we consider a technology for extending\nthe SymPy computer algebra system with a low-level module that implements a\nrandom number generator.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05261v1"
    },
    {
        "title": "SymJAX: symbolic CPU/GPU/TPU programming",
        "authors": [
            "Randall Balestriero"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  SymJAX is a symbolic programming version of JAX simplifying graph\ninput/output/updates and providing additional functionalities for general\nmachine learning and deep learning applications. From an user perspective\nSymJAX provides a la Theano experience with fast graph optimization/compilation\nand broad hardware support, along with Lasagne-like deep learning\nfunctionalities.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.10635v1"
    },
    {
        "title": "Writing Reusable Digital Geometry Algorithms in a Generic Image\n  Processing Framework",
        "authors": [
            "Roland Levillain",
            "Thierry Géraud",
            "Laurent Najman"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Digital Geometry software should reflect the generality of the underlying\nmathe- matics: mapping the latter to the former requires genericity. By\ndesigning generic solutions, one can effectively reuse digital geometry data\nstructures and algorithms. We propose an image processing framework focused on\nthe Generic Programming paradigm in which an algorithm on the paper can be\nturned into a single code, written once and usable with various input types.\nThis approach enables users to design and implement new methods at a lower\ncost, try cross-domain experiments and help generalize results\n",
        "pdf_link": "http://arxiv.org/pdf/1209.4233v1"
    },
    {
        "title": "Multi-Threaded Dense Linear Algebra Libraries for Low-Power Asymmetric\n  Multicore Processors",
        "authors": [
            "Sandra Catalán",
            "José R. Herrero",
            "Francisco D. Igual",
            "Rafael Rodríguez-Sánchez",
            "Enrique S. Quintana-Ortí"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Dense linear algebra libraries, such as BLAS and LAPACK, provide a relevant\ncollection of numerical tools for many scientific and engineering applications.\nWhile there exist high performance implementations of the BLAS (and LAPACK)\nfunctionality for many current multi-threaded architectures,the adaption of\nthese libraries for asymmetric multicore processors (AMPs)is still pending. In\nthis paper we address this challenge by developing an asymmetry-aware\nimplementation of the BLAS, based on the BLIS framework, and tailored for AMPs\nequipped with two types of cores: fast/power hungry versus slow/energy\nefficient. For this purpose, we integrate coarse-grain and fine-grain\nparallelization strategies into the library routines which, respectively,\ndynamically distribute the workload between the two core types and statically\nrepartition this work among the cores of the same type.\n  Our results on an ARM big.LITTLE processor embedded in the Exynos 5422 SoC,\nusing the asymmetry-aware version of the BLAS and a plain migration of the\nlegacy version of LAPACK, experimentally assess the benefits, limitations, and\npotential of this approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.02171v1"
    },
    {
        "title": "The Dune FoamGrid implementation for surface and network grids",
        "authors": [
            "Oliver Sander",
            "Timo Koch",
            "Natalie Schröder",
            "Bernd Flemisch"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We present FoamGrid, a new implementation of the DUNE grid interface.\nFoamGrid implements one- and two-dimensional grids in a physical space of\narbitrary dimension, which allows for grids for curved domains. Even more, the\ngrids are not expected to have a manifold structure, i.e., more than two\nelements can share a common facet. This makes FoamGrid the grid data structure\nof choice for simulating structures such as foams, discrete fracture networks,\nor network flow problems. FoamGrid implements adaptive non-conforming\nrefinement with element parametrizations. As an additional feature it allows\nremoval and addition of elements in an existing grid, which makes FoamGrid\nsuitable for network growth problems. We show how to use FoamGrid, with\nparticular attention to the extensions of the grid interface needed to handle\nnon-manifold topology and grid growth. Three numerical examples demonstrate the\npossibilities offered by FoamGrid.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.03415v1"
    },
    {
        "title": "Embedded Ensemble Propagation for Improving Performance, Portability and\n  Scalability of Uncertainty Quantification on Emerging Computational\n  Architectures",
        "authors": [
            "E. Phipps",
            "M. D'Elia",
            "H. C. Edwards",
            "M. Hoemmen",
            "J. Hu",
            "S. Rajamanickam"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Quantifying simulation uncertainties is a critical component of rigorous\npredictive simulation. A key component of this is forward propagation of\nuncertainties in simulation input data to output quantities of interest.\nTypical approaches involve repeated sampling of the simulation over the\nuncertain input data, and can require numerous samples when accurately\npropagating uncertainties from large numbers of sources. Often simulation\nprocesses from sample to sample are similar and much of the data generated from\neach sample evaluation could be reused. We explore a new method for\nimplementing sampling methods that simultaneously propagates groups of samples\ntogether in an embedded fashion, which we call embedded ensemble propagation.\nWe show how this approach takes advantage of properties of modern computer\narchitectures to improve performance by enabling reuse between samples,\nreducing memory bandwidth requirements, improving memory access patterns,\nimproving opportunities for fine-grained parallelization, and reducing\ncommunication costs. We describe a software technique for implementing embedded\nensemble propagation based on the use of C++ templates and describe its\nintegration with various scientific computing libraries within Trilinos. We\ndemonstrate improved performance, portability and scalability for the approach\napplied to the simulation of partial differential equations on a variety of\nCPU, GPU, and accelerator architectures, including up to 131,072 cores on a\nCray XK7 (Titan).\n",
        "pdf_link": "http://arxiv.org/pdf/1511.03703v1"
    },
    {
        "title": "GEMMbench: a framework for reproducible and collaborative benchmarking\n  of matrix multiplication",
        "authors": [
            "Anton Lokhmotov"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The generic matrix-matrix multiplication (GEMM) is arguably the most popular\ncomputational kernel of the 20th century. Yet, surprisingly, no common\nmethodology for evaluating GEMM performance has been established over the many\ndecades of using GEMM for comparing architectures, compilers and ninja-class\nprogrammers.\n  We introduce GEMMbench, a framework and methodology for evaluating\nperformance of GEMM implementations. GEMMbench is implemented on top of\nCollective Knowledge (CK), a lightweight framework for reproducible and\ncollaborative R&D in computer systems. Using CK allows the R&D community to\ncrowdsource hand-written and compiler-generated GEMM implementations and to\nstudy their performance across multiple platforms, data sizes and data types.\n  Our initial implementation supports hand-written OpenCL kernels operating on\nmatrices consisting of single- and double-precision floating-point values, and\nproducing single or multiple output elements per work-item (via thread\ncoarsening and vectorization).\n",
        "pdf_link": "http://arxiv.org/pdf/1511.03742v2"
    },
    {
        "title": "PyGOM - A Python Package for Simplifying Modelling with Systems of\n  Ordinary Differential Equations",
        "authors": [
            "Edwin Tye",
            "Tom Finnie",
            "Ian Hall",
            "Steve Leach"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Ordinary Differential Equations (ODE) are used throughout science where the\ncapture of rates of change in states is sought. While both pieces of commercial\nand open software exist to study such systems, their efficient and accurate\nusage frequently requires deep understanding of mathematics and programming.\nThe package we present here, PyGOM, seeks to remove these obstacles for models\nbased on ODE systems. We provide a simple interface for the construction of\nsuch systems backed by a comprehensive and easy to use tool--box. This\ntool--box implements functions to easily perform common operations for ODE\nsystems such as solving, parameter estimation, and stochastic simulation. The\npackage source is freely available and organized in a way that permits easy\nextension. With both the algebraic and numeric calculations performed\nautomatically (but still accessible), the end user is freed to focus on model\ndevelopment.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.06934v1"
    },
    {
        "title": "The Implementation of the Colored Abstract Simplicial Complex and its\n  Application to Mesh Generation",
        "authors": [
            "C. T. Lee",
            "J. B. Moody",
            "R. E. Amaro",
            "J. A. McCammon",
            "M. Holst"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We introduce CASC: a new, modern, and header-only C++ library which provides\na data structure to represent arbitrary dimension abstract simplicial complexes\n(ASC) with user-defined classes stored directly on the simplices at each\ndimension. This is accomplished by using the latest C++ language features\nincluding variadic template parameters introduced in C++11 and automatic\nfunction return type deduction from C++14. Effectively CASC decouples the\nrepresentation of the topology from the interactions of user data. We present\nthe innovations and design principles of the data structure and related\nalgorithms. This includes a metadata aware decimation algorithm which is\ngeneral for collapsing simplices of any dimension. We also present an example\napplication of this library to represent an orientable surface mesh.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.01417v2"
    },
    {
        "title": "FluidFFT: common API (C++ and Python) for Fast Fourier Transform HPC\n  libraries",
        "authors": [
            "Ashwin Vishnu Mohanan",
            "Cyrille Bonamy",
            "Pierre Augier"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The Python package fluidfft provides a common Python API for performing Fast\nFourier Transforms (FFT) in sequential, in parallel and on GPU with different\nFFT libraries (FFTW, P3DFFT, PFFT, cuFFT). fluidfft is a comprehensive FFT\nframework which allows Python users to easily and efficiently perform FFT and\nthe associated tasks, such as as computing linear operators and energy spectra.\nWe describe the architecture of the package composed of C++ and Cython FFT\nclasses, Python \"operator\" classes and Pythran functions. The package supplies\nutilities to easily test itself and benchmark the different FFT solutions for a\nparticular case and on a particular machine. We present a performance scaling\nanalysis on three different computing clusters and a microbenchmark showing\nthat fluidfft is an interesting solution to write efficient Python applications\nusing FFT.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.01775v1"
    },
    {
        "title": "Computational and applied topology, tutorial",
        "authors": [
            "Paweł Dłotko"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This is a tutorial in applied and computational topology and topological data\nanalysis. It is illustrated with numerous computational examples that utilize\nGudhi library. It is under constant development, so please do not consider this\nversion as final.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.08607v2"
    },
    {
        "title": "Leveraging the bfloat16 Artificial Intelligence Datatype For\n  Higher-Precision Computations",
        "authors": [
            "Greg Henry",
            "Ping Tak Peter Tang",
            "Alexander Heinecke"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  In recent years fused-multiply-add (FMA) units with lower-precision\nmultiplications and higher-precision accumulation have proven useful in machine\nlearning/artificial intelligence applications, most notably in training deep\nneural networks due to their extreme computational intensity. Compared to\nclassical IEEE-754 32 bit (FP32) and 64 bit (FP64) arithmetic, these reduced\nprecision arithmetic can naturally be sped up disproportional to their\nshortened width. The common strategy of all major hardware vendors is to\naggressively further enhance their performance disproportionately. One\nparticular FMA operation that multiplies two BF16 numbers while accumulating in\nFP32 has been found useful in deep learning, where BF16 is the 16-bit floating\npoint datatype with IEEE FP32 numerical range but 8 significant bits of\nprecision. In this paper, we examine the use this FMA unit to implement\nhigher-precision matrix routines in terms of potential performance gain and\nimplications on accuracy. We demonstrate how a decomposition into multiple\nsmaller datatypes can be used to assemble a high-precision result, leveraging\nthe higher precision accumulation of the FMA unit. We first demonstrate that\ncomputations of vector inner products and by natural extension, matrix-matrix\nproducts can be achieved by decomposing FP32 numbers in several BF16 numbers\nfollowed by appropriate computations that can accommodate the dynamic range and\npreserve accuracy compared to standard FP32 computations, while projecting up\nto 5.2x speed-up. Furthermore, we examine solution of linear equations\nformulated in the residual form that allows for iterative refinement. We\ndemonstrate that the solution obtained to be comparable to those offered by\nFP64 under a large range of linear system condition numbers.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.06376v1"
    },
    {
        "title": "Towards whole program generation of quadrature-free discontinuous\n  Galerkin methods for the shallow water equations",
        "authors": [
            "Sara Faghih-Naini",
            "Sebastian Kuckuk",
            "Vadym Aizinger",
            "Daniel Zint",
            "Roberto Grosso",
            "Harald Köstler"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The shallow water equations (SWE) are a commonly used model to study\ntsunamis, tides, and coastal ocean circulation. However, there exist various\napproaches to discretize and solve them efficiently. Which of them is best for\na certain scenario is often not known and, in addition, depends heavily on the\nused HPC platform. From a simulation software perspective, this places a\npremium on the ability to adapt easily to different numerical methods and\nhardware architectures. One solution to this problem is to apply code\ngeneration techniques and to express methods and specific hardware-dependent\nimplementations on different levels of abstraction. This allows for a\nseparation of concerns and makes it possible, e.g., to exchange the\ndiscretization scheme without having to rewrite all low-level optimized\nroutines manually. In this paper, we show how code for an advanced\nquadrature-free discontinuous Galerkin (DG) discretized shallow water equation\nsolver can be generated. Here, we follow the multi-layered approach from the\nExaStencils project that starts from the continuous problem formulation, moves\nto the discrete scheme, spells out the numerical algorithms, and, finally, maps\nto a representation that can be transformed to a distributed memory parallel\nimplementation by our in-house Scala-based source-to-source compiler. Our\ncontributions include: A new quadrature-free discontinuous Galerkin\nformulation, an extension of the class of supported computational grids, and an\nextension of our toolchain allowing to evaluate discrete integrals stemming\nfrom the DG discretization implemented in Python. As first results we present\nthe whole toolchain and also demonstrate the convergence of our method for\nhigher order DG discretizations.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.08684v1"
    },
    {
        "title": "A Flexible Framework for Parallel Multi-Dimensional DFTs",
        "authors": [
            "Doru Thom Popovici",
            "Martin D. Schatz",
            "Franz Franchetti",
            "Tze Meng Low"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Multi-dimensional discrete Fourier transforms (DFT) are typically decomposed\ninto multiple 1D transforms. Hence, parallel implementations of any\nmulti-dimensional DFT focus on parallelizing within or across the 1D DFT.\nExisting DFT packages exploit the inherent parallelism across the 1D DFTs and\noffer rigid frameworks, that cannot be extended to incorporate both forms of\nparallelism and various data layouts to enable some of the parallelism.\nHowever, in the era of exascale, where systems have thousand of nodes and\nintricate network topologies, flexibility and parallel efficiency are key\naspects all multi-dimensional DFT frameworks need to have in order to map and\nscale the computation appropriately. In this work, we present a flexible\nframework, built on the Redistribution Operations and Tensor Expressions (ROTE)\nframework, that facilitates the development of a family of parallel\nmulti-dimensional DFT algorithms by 1) unifying the two parallelization schemes\nwithin a single framework, 2) exploiting the two different parallelization\nschemes to different degrees and 3) using different data layouts to distribute\nthe data across the compute nodes. We demonstrate the need of a versatile\nframework and thus a need for a family of parallel multi-dimensional DFT\nalgorithms on the K-Computer, where we show almost linear strong scaling\nresults for problem sizes of 1024^3 on 32k compute nodes.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.10119v2"
    },
    {
        "title": "Softmax Optimizations for Intel Xeon Processor-based Platforms",
        "authors": [
            "Jacek Czaja",
            "Michal Gallus",
            "Tomasz Patejko",
            "Jian Tang"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Softmax is popular normalization method used in machine learning. Deep\nlearning solutions like Transformer or BERT use the softmax function\nintensively, so it is worthwhile to optimize its performance. This article\npresents our methodology of optimization and its results applied to softmax. By\npresenting this methodology, we hope to increase an interest in deep learning\noptimizations for CPUs. We believe that the optimization process presented here\ncould be transferred to other deep learning frameworks such as TensorFlow or\nPyTorch.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.12380v2"
    },
    {
        "title": "OpenMP parallelization of multiple precision Taylor series method",
        "authors": [
            "S. Dimova",
            "I. Hristov",
            "R. Hristova",
            "I. Puzynin",
            "T. Puzynina",
            "Z. Sharipov",
            "N. Shegunov",
            "Z. Tukhliev"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  OpenMP parallelization of multiple precision Taylor series method is\nproposed. A very good parallel performance scalability and parallel efficiency\ninside one computation node of a CPU-cluster is observed. We explain the\ndetails of the parallelization on the classical example of the Lorentz\nequations. The same approach can be applied straightforwardly to a large class\nof chaotic dynamical systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.09301v1"
    },
    {
        "title": "The DUNE Framework: Basic Concepts and Recent Developments",
        "authors": [
            "Peter Bastian",
            "Markus Blatt",
            "Andreas Dedner",
            "Nils-Arne Dreier",
            "Christian Engwer",
            "René Fritze",
            "Carsten Gräser",
            "Christoph Grüninger",
            "Dominic Kempf",
            "Robert Klöfkorn",
            "Mario Ohlberger",
            "Oliver Sander"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  This paper presents the basic concepts and the module structure of the\nDistributed and Unified Numerics Environment and reflects on recent\ndevelopments and general changes that happened since the release of the first\nDune version in 2007 and the main papers describing that state [1, 2]. This\ndiscussion is accompanied with a description of various advanced features, such\nas coupling of domains and cut cells, grid modifications such as adaptation and\nmoving domains, high order discretizations and node level performance,\nnon-smooth multigrid methods, and multiscale methods. A brief discussion on\ncurrent and future development directions of the framework concludes the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.13672v3"
    },
    {
        "title": "Effect of Mixed Precision Computing on H-Matrix Vector Multiplication in\n  BEM Analysis",
        "authors": [
            "Rise Ooi",
            "Takeshi Iwashita",
            "Takeshi Fukaya",
            "Akihiro Ida",
            "Rio Yokota"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Hierarchical Matrix (H-matrix) is an approximation technique which splits a\ntarget dense matrix into multiple submatrices, and where a selected portion of\nsubmatrices are low-rank approximated. The technique substantially reduces both\ntime and space complexity of dense matrix vector multiplication, and hence has\nbeen applied to numerous practical problems.\n  In this paper, we aim to accelerate the H-matrix vector multiplication by\nintroducing mixed precision computing, where we employ both binary64 (FP64) and\nbinary32 (FP32) arithmetic operations. We propose three methods to introduce\nmixed precision computing to H-matrix vector multiplication, and then evaluate\nthem in a boundary element method (BEM) analysis. The numerical tests examine\nthe effects of mixed precision computing, particularly on the required\nsimulation time and rate of convergence of the iterative (BiCG-STAB) linear\nsolver. We confirm the effectiveness of the proposed methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.00093v1"
    },
    {
        "title": "MOOSE: Enabling Massively Parallel Multiphysics Simulation",
        "authors": [
            "Cody J. Permann",
            "Derek R. Gaston",
            "David Andrs",
            "Robert W. Carlsen",
            "Fande Kong",
            "Alexander D. Lindsay",
            "Jason M. Miller",
            "John W. Peterson",
            "Andrew E. Slaughter",
            "Roy H. Stogner",
            "Richard C. Martineau"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Harnessing modern parallel computing resources to achieve complex\nmulti-physics simulations is a daunting task. The Multiphysics Object Oriented\nSimulation Environment (MOOSE) aims to enable such development by providing\nsimplified interfaces for specification of partial differential equations,\nboundary conditions, material properties, and all aspects of a simulation\nwithout the need to consider the parallel, adaptive, nonlinear, finite-element\nsolve that is handled internally. Through the use of interfaces and\ninheritance, each portion of a simulation becomes reusable and composable in a\nmanner that allows disparate research groups to share code and create an\necosystem of growing capability that lowers the barrier for the creation of\nmultiphysics simulation codes. Included within the framework is a unique\ncapability for building multiscale, multiphysics simulations through\nsimultaneous execution of multiple sub-applications with data transfers between\nthe scales. Other capabilities include automatic differentiation, scaling to a\nlarge number of processors, hybrid parallelism, and mesh adaptivity. To date,\nMOOSE-based applications have been created in areas of science and engineering\nsuch as nuclear physics, geothermal science, magneto-hydrodynamics, seismic\nevents, compressible and incompressible fluid flow, microstructure evolution,\nand advanced manufacturing processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.04488v1"
    },
    {
        "title": "Role-Oriented Code Generation in an Engine for Solving Hyperbolic PDE\n  Systems",
        "authors": [
            "Jean-Matthieu Gallard",
            "Lukas Krenz",
            "Leonhard Rannabauer",
            "Anne Reinarz",
            "Michael Bader"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The development of a high performance PDE solver requires the combined\nexpertise of interdisciplinary teams with respect to application domain,\nnumerical scheme and low-level optimization. In this paper, we present how the\nExaHyPE engine facilitates the collaboration of such teams by isolating three\nroles: application, algorithms, and optimization expert. We thus support team\nmembers in letting them focus on their own area of expertise while integrating\ntheir contributions into an HPC production code. Inspired by web application\ndevelopment practices, ExaHyPE relies on two custom code generation modules,\nthe Toolkit and the Kernel Generator, which follow a Model-View-Controller\narchitectural pattern on top of the Jinja2 template engine library. Using\nJinja2's templates to abstract the critical components of the engine and\ngenerated glue code, we isolate the application development from the engine.\nThe template language also allows us to define and use custom template macros\nthat isolate low-level optimizations from the numerical scheme described in the\ntemplates. We present three use cases, each focusing on one of our user roles,\nshowcasing how the design of the code generation modules allows to easily\nexpand the solver schemes to support novel demands from applications, to add\noptimized algorithmic schemes (with reduced memory footprint, e.g.), or provide\nimproved low-level SIMD vectorization support.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.06817v2"
    },
    {
        "title": "Semi-Automatic Task Graph Construction for $\\mathcal{H}$-Matrix\n  Arithmetic",
        "authors": [
            "Steffen Börm",
            "Sven Christophersen",
            "Ronald Kriemann"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  A new method to construct task graphs for \\mcH-matrix arithmetic is\nintroduced, which uses the information associated with all tasks of the\nstandard recursive \\mcH-matrix algorithms, e.g., the block index set of the\nmatrix blocks involved in the computation. Task refinement, i.e., the\nreplacement of tasks by sub-computations, is then used to proceed in the\n\\mcH-matrix hierarchy until the matrix blocks containing the actual matrix data\nare reached. This process is a natural extension of the classical, recursive\nway in which \\mcH-matrix arithmetic is defined and thereby simplifies the\nefficient usage of many-core systems. Examples for standard and accumulator\nbased \\mcH-arithmetic are shown for model problems with different block\nstructures.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.07531v1"
    },
    {
        "title": "The Linear Algebra Mapping Problem. Current state of linear algebra\n  languages and libraries",
        "authors": [
            "Christos Psarras",
            "Henrik Barthels",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We observe a disconnect between the developers and the end users of linear\nalgebra libraries. On the one hand, the numerical linear algebra and the\nhigh-performance communities invest significant effort in the development and\noptimization of highly sophisticated numerical kernels and libraries, aiming at\nthe maximum exploitation of both the properties of the input matrices, and the\narchitectural features of the target computing platform. On the other hand, end\nusers are progressively less likely to go through the error-prone and time\nconsuming process of directly using said libraries by writing their code in C\nor Fortran; instead, languages and libraries such as Matlab, Julia, Eigen and\nArmadillo, which offer a higher level of abstraction, are becoming more and\nmore popular. Users are given the opportunity to code matrix computations with\na syntax that closely resembles the mathematical description; it is then a\ncompiler or an interpreter that internally maps the input program to lower\nlevel kernels, as provided by libraries such as BLAS and LAPACK. Unfortunately,\nour experience suggests that in terms of performance, this translation is\ntypically vastly suboptimal.\n  In this paper, we first introduce the Linear Algebra Mapping Problem, and\nthen investigate how effectively a benchmark of test problems is solved by\npopular high-level programming languages. Specifically, we consider Matlab,\nOctave, Julia, R, Armadillo (C++), Eigen (C++), and NumPy (Python); the\nbenchmark is meant to test both standard compiler optimizations such as common\nsubexpression elimination and loop-invariant code motion, as well as linear\nalgebra specific optimizations such as optimal parenthesization of a matrix\nproduct and kernel selection for matrices with properties. The aim of this\nstudy is to give concrete guidelines for the development of languages and\nlibraries that support linear algebra computations.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.09421v2"
    },
    {
        "title": "Array Programming with NumPy",
        "authors": [
            "Charles R. Harris",
            "K. Jarrod Millman",
            "Stéfan J. van der Walt",
            "Ralf Gommers",
            "Pauli Virtanen",
            "David Cournapeau",
            "Eric Wieser",
            "Julian Taylor",
            "Sebastian Berg",
            "Nathaniel J. Smith",
            "Robert Kern",
            "Matti Picus",
            "Stephan Hoyer",
            "Marten H. van Kerkwijk",
            "Matthew Brett",
            "Allan Haldane",
            "Jaime Fernández del Río",
            "Mark Wiebe",
            "Pearu Peterson",
            "Pierre Gérard-Marchant",
            "Kevin Sheppard",
            "Tyler Reddy",
            "Warren Weckesser",
            "Hameer Abbasi",
            "Christoph Gohlke",
            "Travis E. Oliphant"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Array programming provides a powerful, compact, expressive syntax for\naccessing, manipulating, and operating on data in vectors, matrices, and\nhigher-dimensional arrays. NumPy is the primary array programming library for\nthe Python language. It plays an essential role in research analysis pipelines\nin fields as diverse as physics, chemistry, astronomy, geoscience, biology,\npsychology, material science, engineering, finance, and economics. For example,\nin astronomy, NumPy was an important part of the software stack used in the\ndiscovery of gravitational waves and the first imaging of a black hole. Here we\nshow how a few fundamental array concepts lead to a simple and powerful\nprogramming paradigm for organizing, exploring, and analyzing scientific data.\nNumPy is the foundation upon which the entire scientific Python universe is\nconstructed. It is so pervasive that several projects, targeting audiences with\nspecialized needs, have developed their own NumPy-like interfaces and array\nobjects. Because of its central position in the ecosystem, NumPy increasingly\nplays the role of an interoperability layer between these new array computation\nlibraries.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.10256v1"
    },
    {
        "title": "NetworkDynamics.jl -- Composing and simulating complex networks in Julia",
        "authors": [
            "Michael Lindner",
            "Lucas Lincoln",
            "Fenja Drauschke",
            "Julia Monika Koulen",
            "Hans Würfel",
            "Anton Plietzsch",
            "Frank Hellmann"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  NetworkDynamics.jl is an easy-to-use and computationally efficient package\nfor working with heterogeneous dynamical systems on complex networks, written\nin Julia, a high-level, high-performance, dynamic programming language. By\ncombining state of the art solver algorithms from DifferentialEquations.jl with\nefficient data structures, NetworkDynamics.jl achieves top performance while\nsupporting advanced features like events, algebraic constraints, time-delays,\nnoise terms and automatic differentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.12696v3"
    },
    {
        "title": "FastAD: Expression Template-Based C++ Library for Fast and\n  Memory-Efficient Automatic Differentiation",
        "authors": [
            "James Yang"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Automatic differentiation is a set of techniques to efficiently and\naccurately compute the derivative of a function represented by a computer\nprogram. Existing C++ libraries for automatic differentiation (e.g. Adept, Stan\nMath Library), however, exhibit large memory consumptions and runtime\nperformance issues. This paper introduces FastAD, a new C++ template library\nfor automatic differentiation, that overcomes all of these challenges in\nexisting libraries by using vectorization, simpler memory management using a\nfully expression-template-based design, and other compile-time optimizations to\nremove some run-time overhead. Benchmarks show that FastAD performs 2-10 times\nfaster than Adept and 2-19 times faster than Stan across various test cases\nincluding a few real-world examples.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.03681v1"
    },
    {
        "title": "User manual for bch, a program for the fast computation of the\n  Baker-Campbell-Hausdorff and similar series",
        "authors": [
            "Harald Hofstätter"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This manual describes bch, an efficient program written in the C programming\nlanguage for the fast computation of the Baker-Campbell-Hausdorff (BCH) and\nsimilar Lie series. The Lie series can be represented in the Lyndon basis, in\nthe classical Hall basis, or in the right-normed basis of E.S. Chibrikov. In\nthe Lyndon basis, which proves to be particularly efficient for this purpose,\nthe computation of 111013 coefficients for the BCH series up to terms of degree\n20 takes less than half a second on an ordinary personal computer and requires\nnegligible 11MB of memory. Up to terms of degree 30, which is the maximum\ndegree the program can handle, the computation of 74248451 coefficients takes\n55 hours but still requires only a modest 5.5GB of memory.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.06570v3"
    },
    {
        "title": "COMET: A Domain-Specific Compilation of High-Performance Computational\n  Chemistry",
        "authors": [
            "Erdal Mutlu",
            "Ruiqin Tian",
            "Bin Ren",
            "Sriram Krishnamoorthy",
            "Roberto Gioiosa",
            "Jacques Pienaar",
            "Gokcen Kestor"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The computational power increases over the past decades havegreatly enhanced\nthe ability to simulate chemical reactions andunderstand ever more complex\ntransformations. Tensor contractions are the fundamental computational building\nblock of these simulations. These simulations have often been tied to one\nplatform and restricted in generality by the interface provided to the user.\nThe expanding prevalence of accelerators and researcher demands necessitate a\nmore general approach which is not tied to specific hardware or requires\ncontortion of algorithms to specific hardware platforms. In this paper we\npresent COMET, a domain-specific programming language and compiler\ninfrastructure for tensor contractions targeting heterogeneous accelerators. We\npresent a system of progressive lowering through multiple layers of abstraction\nand optimization that achieves up to 1.98X speedup for 30 tensor contractions\ncommonly used in computational chemistry and beyond.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.06827v1"
    },
    {
        "title": "Puiseux Series and Algebraic Solutions of First Order Autonomous AODEs\n  -- A MAPLE Package",
        "authors": [
            "Francois Boulier",
            "Jose Cano",
            "Sebastian Falkensteiner",
            "Rafael Sendra"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  There exist several methods for computing exact solutions of algebraic\ndifferential equations. Most of the methods, however, do not ensure existence\nand uniqueness of the solutions and might fail after several steps, or are\nrestricted to linear equations. The authors have presented in previous works a\nmethod to overcome this problem for autonomous first order algebraic ordinary\ndifferential equations and formal Puiseux series solutions and algebraic\nsolutions. In the first case, all solutions can uniquely be represented by a\nsufficiently large truncation and in the latter case by its minimal polynomial.\nThe main contribution of this paper is the implementation, in a MAPLE-package\nnamed FirstOrderSolve, of the algorithmic ideas presented therein. More\nprecisely, all formal Puiseux series and algebraic solutions, including the\ngeneric and singular solutions, are computed and described uniquely. The\ncomputation strategy is to reduce the given differential equation to a simpler\none by using local parametrizations and the already known degree bounds.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.03646v1"
    },
    {
        "title": "TensorDiffEq: Scalable Multi-GPU Forward and Inverse Solvers for Physics\n  Informed Neural Networks",
        "authors": [
            "Levi D. McClenny",
            "Mulugeta A. Haile",
            "Ulisses M. Braga-Neto"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Physics-Informed Neural Networks promise to revolutionize science and\nengineering practice, by introducing domain-aware deep machine learning models\ninto scientific computation. Several software suites have emerged to make the\nimplementation and usage of these architectures available to the research and\nindustry communities. Here we introduce\\linebreak TensorDiffEq, built on\nTensorflow 2.x, which presents an intuitive Keras-like interface for problem\ndomain definition, model definition, and solution of forward and inverse\nproblems using physics-aware deep learning methods. TensorDiffEq takes full\nadvantage of Tensorflow 2.x infrastructure for deployment on multiple GPUs,\nallowing the implementation of large high-dimensional and complex models.\nSimultaneously, TensorDiffEq supports the Keras API for custom neural network\narchitecture definitions. In the case of smaller or simpler models, the package\nallows for rapid deployment on smaller-scale CPU platforms with negligible\nchanges to the implementation scripts. We demonstrate the basic usage and\ncapabilities of TensorDiffEq in solving forward, inverse, and data assimilation\nproblems of varying sizes and levels of complexity. The source code is\navailable at https://github.com/tensordiffeq.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.16034v1"
    },
    {
        "title": "Evaluating polynomials in several variables and their derivatives on a\n  GPU computing processor",
        "authors": [
            "Jan Verschelde",
            "Genady Yoffe"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In order to obtain more accurate solutions of polynomial systems with\nnumerical continuation methods we use multiprecision arithmetic. Our goal is to\noffset the overhead of double double arithmetic accelerating the path trackers\nand in particular Newton's method with a general purpose graphics processing\nunit. In this paper we describe algorithms for the massively parallel\nevaluation and differentiation of sparse polynomials in several variables. We\nreport on our implementation of the algorithmic differentiation of products of\nvariables on the NVIDIA Tesla C2050 Computing Processor using the NVIDIA CUDA\ncompiler tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.0499v1"
    },
    {
        "title": "Program Verification of Numerical Computation",
        "authors": [
            "Garry Pantelis"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  These notes outline a formal method for program verification of numerical\ncomputation. It forms the basis of the software package VPC in its initial\nphase of development. Much of the style of presentation is in the form of notes\nthat outline the definitions and rules upon which VPC is based. The initial\nmotivation of this project was to address some practical issues of computation,\nespecially of numerically intensive programs that are commonplace in computer\nmodels. The project evolved into a wider area for program construction as\nproofs leading to a model of inference in a more general sense. Some basic\nresults of machine arithmetic are derived as a demonstration of VPC.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1290v1"
    },
    {
        "title": "Boolean Functions, Quantum Gates, Hamilton Operators, Spin Systems and\n  Computer Algebra",
        "authors": [
            "Yorick Hardy",
            "Willi-Hans Steeb"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We describe the construction of quantum gates (unitary operators) from\nboolean functions and give a number of applications. Both non-reversible and\nreversible boolean functions are considered. The construction of the Hamilton\noperator for a quantum gate is also described with the Hamilton operator\nexpressed as spin system. Computer algebra implementations are provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.2248v4"
    },
    {
        "title": "Changing Computing Paradigms Towards Power Efficiency",
        "authors": [
            "Pavel Klavík",
            "A. Cristiano I. Malossi",
            "Constantin Bekas",
            "Alessandro Curioni"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Power awareness is fast becoming immensely important in computing, ranging\nfrom the traditional High Performance Computing applications, to the new\ngeneration of data centric workloads.\n  In this work we describe our efforts towards a power efficient computing\nparadigm that combines low precision and high precision arithmetic. We showcase\nour ideas for the widely used kernel of solving systems of linear equations\nthat finds numerous applications in scientific and engineering disciplines as\nwell as in large scale data analytics, statistics and machine learning.\n  Towards this goal we developed tools for the seamless power profiling of\napplications at a fine grain level. In addition, we verify here previous work\non post FLOPS/Watt metrics and show that these can shed much more light in the\npower/energy profile of important applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.4644v1"
    },
    {
        "title": "Integer formula encoding SageTeX package",
        "authors": [
            "Edinah K. Gnang"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The paper describes a SageTeX implementation of an integer encoding\nprocedures.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.0039v1"
    },
    {
        "title": "scikit-image: Image processing in Python",
        "authors": [
            "Stefan van der Walt",
            "Johannes L. Schönberger",
            "Juan Nunez-Iglesias",
            "François Boulogne",
            "Joshua D. Warner",
            "Neil Yager",
            "Emmanuelle Gouillart",
            "Tony Yu",
            "the scikit-image contributors"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  scikit-image is an image processing library that implements algorithms and\nutilities for use in research, education and industry applications. It is\nreleased under the liberal \"Modified BSD\" open source license, provides a\nwell-documented API in the Python programming language, and is developed by an\nactive, international team of collaborators. In this paper we highlight the\nadvantages of open source to achieve the goals of the scikit-image library, and\nwe showcase several real-world image processing applications that use\nscikit-image.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6245v1"
    },
    {
        "title": "The DUNE-ALUGrid Module",
        "authors": [
            "Martin Alkämper",
            "Andreas Dedner",
            "Robert Klöfkorn",
            "Martin Nolte"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  In this paper we present the new DUNE-ALUGrid module. This module contains a\nmajor overhaul of the sources from the ALUgrid library and the binding to the\nDUNE software framework. The main changes include user defined load balancing,\nparallel grid construction, and an redesign of the 2d grid which can now also\nbe used for parallel computations. In addition many improvements have been\nintroduced into the code to increase the parallel efficiency and to decrease\nthe memory footprint.\n  The original ALUGrid library is widely used within the DUNE community due to\nits good parallel performance for problems requiring local adaptivity and\ndynamic load balancing. Therefore, this new model will benefit a number of DUNE\nusers. In addition we have added features to increase the range of problems for\nwhich the grid manager can be used, for example, introducing a 3d tetrahedral\ngrid using a parallel newest vertex bisection algorithm for conforming grid\nrefinement. In this paper we will discuss the new features, extensions to the\nDUNE interface, and explain for various examples how the code is used in\nparallel environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6954v3"
    },
    {
        "title": "Automatic Generation of Loop-Invariants for Matrix Operations",
        "authors": [
            "Diego Fabregat-Traver",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  In recent years it has been shown that for many linear algebra operations it\nis possible to create families of algorithms following a very systematic\nprocedure. We do not refer to the fine tuning of a known algorithm, but to a\nmethodology for the actual generation of both algorithms and routines to solve\na given target matrix equation. Although systematic, the methodology relies on\ncomplex algebraic manipulations and non-obvious pattern matching, making the\nprocedure challenging to be performed by hand, our goal is the development of a\nfully automated system that from the sole description of a target equation\ncreates multiple algorithms and routines. We present CL1ck, a symbolic system\nwritten in Mathematica, that starts with an equation, decomposes it into\nmultiple equations, and returns a set of loop-invariants for the algorithms --\nyet to be generated -- that will solve the equation. In a successive step each\nloop-invariant is then mapped to its corresponding algorithm and routine. For a\nlarge class of equations, the methodology generates known algorithms as well as\nmany previously unknown ones. Most interestingly, the methodology unifies\nalgorithms traditionally developed in isolation. As an example, the five well\nknown algorithms for the LU factorization are for the first time unified under\na common root.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.0564v1"
    },
    {
        "title": "Knowledge-Based Automatic Generation of Partitioned Matrix Expressions",
        "authors": [
            "Diego Fabregat-Traver",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  In a series of papers it has been shown that for many linear algebra\noperations it is possible to generate families of algorithms by following a\nsystematic procedure. Although powerful, such a methodology involves complex\nalgebraic manipulation, symbolic computations and pattern matching, making the\ngeneration a process challenging to be performed by hand. We aim for a fully\nautomated system that from the sole description of a target operation creates\nmultiple algorithms without any human intervention. Our approach consists of\nthree main stages. The first stage yields the core object for the entire\nprocess, the Partitioned Matrix Expression (PME), which establishes how the\ntarget problem may be decomposed in terms of simpler sub-problems. In the\nsecond stage the PME is inspected to identify predicates, the Loop-Invariants,\nto be used to set up the skeleton of a family of proofs of correctness. In the\nthird and last stage the actual algorithms are constructed so that each of them\nsatisfies its corresponding proof of correctness. In this paper we focus on the\nfirst stage of the process, the automatic generation of Partitioned Matrix\nExpressions. In particular, we discuss the steps leading to a PME and the\nknowledge necessary for a symbolic system to perform such steps. We also\nintroduce Cl1ck, a prototype system written in Mathematica that generates PMEs\nautomatically.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.0567v1"
    },
    {
        "title": "Chemora: A PDE Solving Framework for Modern HPC Architectures",
        "authors": [
            "Erik Schnetter",
            "Marek Blazewicz",
            "Steven R. Brandt",
            "David M. Koppelman",
            "Frank Löffler"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Modern HPC architectures consist of heterogeneous multi-core, many-node\nsystems with deep memory hierarchies. Modern applications employ ever more\nadvanced discretisation methods to study multi-physics problems. Developing\nsuch applications that explore cutting-edge physics on cutting-edge HPC systems\nhas become a complex task that requires significant HPC knowledge and\nexperience. Unfortunately, this combined knowledge is currently out of reach\nfor all but a few groups of application developers.\n  Chemora is a framework for solving systems of Partial Differential Equations\n(PDEs) that targets modern HPC architectures. Chemora is based on Cactus, which\nsees prominent usage in the computational relativistic astrophysics community.\nIn Chemora, PDEs are expressed either in a high-level \\LaTeX-like language or\nin Mathematica. Discretisation stencils are defined separately from equations,\nand can include Finite Differences, Discontinuous Galerkin Finite Elements\n(DGFE), Adaptive Mesh Refinement (AMR), and multi-block systems.\n  We use Chemora in the Einstein Toolkit to implement the Einstein Equations on\nCPUs and on accelerators, and study astrophysical systems such as black hole\nbinaries, neutron stars, and core-collapse supernovae.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.1764v1"
    },
    {
        "title": "Efficient implementation of elementary functions in the medium-precision\n  range",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We describe a new implementation of the elementary transcendental functions\nexp, sin, cos, log and atan for variable precision up to approximately 4096\nbits. Compared to the MPFR library, we achieve a maximum speedup ranging from a\nfactor 3 for cos to 30 for atan. Our implementation uses table-based argument\nreduction together with rectangular splitting to evaluate Taylor series. We\ncollect denominators to reduce the number of divisions in the Taylor series,\nand avoid overhead by doing all multiprecision arithmetic using the mpn layer\nof the GMP library. Our implementation provides rigorous error bounds.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.7176v2"
    },
    {
        "title": "A New Sparse Matrix Vector Multiplication GPU Algorithm Designed for\n  Finite Element Problems",
        "authors": [
            "Jonathan Wong",
            "Ellen Kuhl",
            "Eric Darve"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Recently, graphics processors (GPUs) have been increasingly leveraged in a\nvariety of scientific computing applications. However, architectural\ndifferences between CPUs and GPUs necessitate the development of algorithms\nthat take advantage of GPU hardware. As sparse matrix vector multiplication\n(SPMV) operations are commonly used in finite element analysis, a new SPMV\nalgorithm and several variations are developed for unstructured finite element\nmeshes on GPUs. The effective bandwidth of current GPU algorithms and the newly\nproposed algorithms are measured and analyzed for 15 sparse matrices of varying\nsizes and varying sparsity structures. The effects of optimization and\ndifferences between the new GPU algorithm and its variants are then\nsubsequently studied. Lastly, both new and current SPMV GPU algorithms are\nutilized in the GPU CG Solver in GPU finite element simulations of the heart.\nThese results are then compared against parallel PETSc finite element\nimplementation results. The effective bandwidth tests indicate that the new\nalgorithms compare very favorably with current algorithms for a wide variety of\nsparse matrices and can yield very notable benefits. GPU finite element\nsimulation results demonstrate the benefit of using GPUs for finite element\nanalysis, and also show that the proposed algorithms can yield speedup factors\nup to 12-fold for real finite element applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.00324v1"
    },
    {
        "title": "Performance Tuning of a Parallel 3-D FFT Package OpenFFT",
        "authors": [
            "Truong Vinh Truong Duy",
            "Taisuke Ozaki"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  The fast Fourier transform (FFT) is a primitive kernel in numerous fields of\nscience and engineering. OpenFFT is an open-source parallel package for 3-D\nFFTs, built on a communication-optimal domain decomposition method for\nachieving minimal volume of communication. In this paper, we analyze and tune\nthe performance of OpenFFT, paying a particular attention to tuning of\ncommunication that dominates the run time of large-scale calculations. We first\nanalyze its performance on different machines for an understanding of the\nbehaviors of the package and machines. Based on the performance analysis, we\ndevelop six communication methods for performing communication with the aim of\ncovering varied calculation scales on a variety of computational platforms.\nOpenFFT is then augmented with an auto-tuning of communication to select the\nbest method in run time depending on their performance. Numerical results\ndemonstrate that the optimized OpenFFT is able to deliver relatively good\nperformance in comparison with other state-of-the-art packages at different\ncomputational scales on a number of parallel machines.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.07350v2"
    },
    {
        "title": "Software for enumerative and analytic combinatorics",
        "authors": [
            "Andrew MacFie"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We survey some general-purpose symbolic software packages that implement\nalgorithms from enumerative and analytic combinatorics. Software for the\nfollowing areas is covered: basic combinatorial objects, symbolic\ncombinatorics, P\\'olya theory, combinatorial species, and asymptotics. We\ndescribe the capabilities that the packages offer as well as some of the\nalgorithms used, and provide links to original documentation. Most of the\npackages are freely downloadable from the web.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.02683v1"
    },
    {
        "title": "micompr: An R Package for Multivariate Independent Comparison of\n  Observations",
        "authors": [
            "Nuno Fachada",
            "João Rodrigues",
            "Vitor V. Lopes",
            "Rui C. Martins",
            "Agostinho C. Rosa"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  The R package micompr implements a procedure for assessing if two or more\nmultivariate samples are drawn from the same distribution. The procedure uses\nprincipal component analysis to convert multivariate observations into a set of\nlinearly uncorrelated statistical measures, which are then compared using a\nnumber of statistical methods. This technique is independent of the\ndistributional properties of samples and automatically selects features that\nbest explain their differences. The procedure is appropriate for comparing\nsamples of time series, images, spectrometric measures or similar\nhigh-dimension multivariate observations.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.06907v5"
    },
    {
        "title": "Blackbox: A procedure for parallel optimization of expensive black-box\n  functions",
        "authors": [
            "Paul Knysh",
            "Yannis Korkolis"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  This note provides a description of a procedure that is designed to\nefficiently optimize expensive black-box functions. It uses the response\nsurface methodology by incorporating radial basis functions as the response\nmodel. A simple method based on a Latin hypercube is used for initial sampling.\nA modified version of CORS algorithm with space rescaling is used for the\nsubsequent sampling. The procedure is able to scale on multicore processors by\nperforming multiple function evaluations in parallel. The source code of the\nprocedure is written in Python.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.00998v1"
    },
    {
        "title": "HLinear: Exact Dense Linear Algebra in Haskell",
        "authors": [
            "Alexandru Ghitza",
            "Martin Raum"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present an implementation in the functional programming language Haskell\nof the PLE decomposition of matrices over division rings. Our benchmarks\nindicate that it is competitive with the C-based implementation provided in\nFlint. Describing the guiding principles of our work, we introduce the reader\nto basic ideas from high-performance functional programming.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.02532v3"
    },
    {
        "title": "A general-purpose hierarchical mesh partitioning method with node\n  balancing strategies for large-scale numerical simulations",
        "authors": [
            "Fande Kong",
            "Roy H. Stogner",
            "Derek R. Gaston",
            "John W. Peterson",
            "Cody J. Permann",
            "Andrew E. Slaughter",
            "Richard C. Martineau"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Large-scale parallel numerical simulations are essential for a wide range of\nengineering problems that involve complex, coupled physical processes\ninteracting across a broad range of spatial and temporal scales. The data\nstructures involved in such simulations (meshes, sparse matrices, etc.) are\nfrequently represented as graphs, and these graphs must be optimally\npartitioned across the available computational resources in order for the\nunderlying calculations to scale efficiently. Partitions which minimize the\nnumber of graph edges that are cut (edge-cuts) while simultaneously maintaining\na balance in the amount of work (i.e. graph nodes) assigned to each processor\ncore are desirable, and the performance of most existing partitioning software\nbegins to degrade in this metric for partitions with more than than $O(10^3)$\nprocessor cores. In this work, we consider a general-purpose hierarchical\npartitioner which takes into account the existence of multiple processor cores\nand shared memory in a compute node while partitioning a graph into an\narbitrary number of subgraphs. We demonstrate that our algorithms significantly\nimprove the preconditioning efficiency and overall performance of realistic\nnumerical simulations running on up to 32,768 processor cores with nearly\n$10^9$ unknowns.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.02666v2"
    },
    {
        "title": "Random problems with R",
        "authors": [
            "Kellie Ottoboni",
            "Philip B. Stark"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  R (Version 3.5.1 patched) has an issue with its random sampling\nfunctionality. R generates random integers between $1$ and $m$ by multiplying\nrandom floats by $m$, taking the floor, and adding $1$ to the result.\nWell-known quantization effects in this approach result in a non-uniform\ndistribution on $\\{ 1, \\ldots, m\\}$. The difference, which depends on $m$, can\nbe substantial. Because the sample function in R relies on generating random\nintegers, random sampling in R is biased. There is an easy fix: construct\nrandom integers directly from random bits, rather than multiplying a random\nfloat by $m$. That is the strategy taken in Python's numpy.random.randint()\nfunction, among others. Example source code in Python is available at\nhttps://github.com/statlab/cryptorandom/blob/master/cryptorandom/cryptorandom.py\n(see functions getrandbits() and randbelow_from_randbits()).\n",
        "pdf_link": "http://arxiv.org/pdf/1809.06520v3"
    },
    {
        "title": "A Review of automatic differentiation and its efficient implementation",
        "authors": [
            "Charles C. Margossian"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Derivatives play a critical role in computational statistics, examples being\nBayesian inference using Hamiltonian Monte Carlo sampling and the training of\nneural networks. Automatic differentiation is a powerful tool to automate the\ncalculation of derivatives and is preferable to more traditional methods,\nespecially when differentiating complex algorithms and mathematical functions.\nThe implementation of automatic differentiation however requires some care to\ninsure efficiency. Modern differentiation packages deploy a broad range of\ncomputational techniques to improve applicability, run time, and memory\nmanagement. Among these techniques are operation overloading, region based\nmemory, and expression templates. There also exist several mathematical\ntechniques which can yield high performance gains when applied to complex\nalgorithms. For example, semi-analytical derivatives can reduce by orders of\nmagnitude the runtime required to numerically solve and differentiate an\nalgebraic equation. Open problems include the extension of current packages to\nprovide more specialized routines, and efficient methods to perform\nhigher-order differentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05031v2"
    },
    {
        "title": "AMGCL: an Efficient, Flexible, and Extensible Algebraic Multigrid\n  Implementation",
        "authors": [
            "Denis Demidov"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The paper presents AMGCL -- an opensource C++ library implementing the\nalgebraic multigrid method (AMG) for solution of large sparse linear systems of\nequations, usually arising from discretization of partial differential\nequations on an unstructured grid. The library supports both shared and\ndistributed memory computation, allows to utilize modern massively parallel\nprocessors via OpenMP, OpenCL, or CUDA technologies, has minimal dependencies,\nand is easily extensible. The design principles behind AMGCL are discussed and\nit is shown that the code performance is on par with alternative\nimplementations.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05704v1"
    },
    {
        "title": "Modeling Deep Learning Accelerator Enabled GPUs",
        "authors": [
            "Md Aamir Raihan",
            "Negar Goli",
            "Tor Aamodt"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The efficacy of deep learning has resulted in its use in a growing number of\napplications. The Volta graphics processor unit (GPU) architecture from NVIDIA\nintroduced a specialized functional unit, the \"tensor core\", that helps meet\nthe growing demand for higher performance for deep learning. In this paper we\nstudy the design of the tensor cores in NVIDIA's Volta and Turing\narchitectures. We further propose an architectural model for the tensor cores\nin Volta. When implemented a GPU simulator, GPGPU-Sim, our tensor core model\nachieves 99.6\\% correlation versus an NVIDIA Titan~V GPU in terms of average\ninstructions per cycle when running tensor core enabled GEMM workloads. We also\ndescribe support added to enable GPGPU-Sim to run CUTLASS, an open-source CUDA\nC++ template library providing customizable GEMM templates that utilize tensor\ncores.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08309v2"
    },
    {
        "title": "DUNEuro -- A software toolbox for forward modeling in\n  bioelectromagnetism",
        "authors": [
            "Sophie Schrader",
            "Andreas Westhoff",
            "Maria Carla Piastra",
            "Tuuli Miinalainen",
            "Sampsa Pursiainen",
            "Johannes Vorwerk",
            "Heinrich Brinck",
            "Carsten H. Wolters",
            "Christian Engwer"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Accurate and efficient source analysis in electro- and magnetoencephalography\nusing sophisticated realistic head geometries requires advanced numerical\napproaches. This paper presents DUNEuro, a free and open source C++ software\ntoolbox for forward modeling in bioelectromagnetism. Building upon the DUNE\nframework, it provides implementations of modern fitted and unfitted finite\nelement methods to efficiently solve the forward problems in electro- and\nmagnetoencephalography. The user can choose between a variety of different\nsource models that are implemented. The software's aim is to provide interfaces\nthat are extendible and easy-to-use. In order to enable a closer integration\ninto existing analysis pipelines, interfaces to Python and Matlab are provided.\nThe practical use is demonstrated by a source analysis example of somatosensory\nevoked potentials using a realistic six compartment head model.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.02874v4"
    },
    {
        "title": "Multi-dimensional interpolations in C++",
        "authors": [
            "Maarten de Jong"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  A C++ software design is presented that can be used to interpolate data in\nany number of dimensions. The design is based on a combination of templates of\nfunctional collections of elements and so-called type lists. The design allows\nfor different search methodologies and interpolation techniques in each\ndimension. It is also possible to expand and reduce the number of dimensions,\nto interpolate composite data types and to produce on-the-fly additional values\nsuch as derivatives of the interpolating function.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.02597v1"
    },
    {
        "title": "NLOptControl: A modeling language for solving optimal control problems",
        "authors": [
            "Huckleberry Febbo",
            "Paramsothy Jayakumar",
            "Jeffrey L. Stein",
            "Tulga Ersal"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Current direct-collocation-based optimal control software is either easy to\nuse or fast, but not both. This is a major limitation for users that are trying\nto formulate complex optimal control problems (OCPs) for use in on-line\napplications. This paper introduces NLOptControl, an open-source modeling\nlanguage that allows users to both easily formulate and quickly solve nonlinear\nOCPs using direct-collocation methods. To achieve these attributes,\nNLOptControl (1) is written in an efficient, dynamically-typed computing\nlanguage called Julia, (2) extends an optimization modeling language called\nJuMP to provide a natural algebraic syntax for modeling nonlinear OCPs; and (3)\nuses reverse automatic differentiation with the acrylic-coloring method to\nexploit sparsity in the Hessian matrix. This work explores the novel design\nfeatures of NLOptControl and compares its syntax and speed to those of PROPT.\nThe syntax comparisons shows that NLOptControl models OCPs more concisely than\nPROPT. The speeds of various collocation methods within PROPT and NLOptControl\nare benchmarked over a range of collocation points using performance profiles;\noverall, NLOptControl's single, two, and four interval pseudospectral methods\nare roughly $14$, $26$, and $36$ times faster than PROPT's, respectively.\nNLOptControl is well-suited to improve existing off-line and on-line control\nsystems and to engender new ones.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.00142v2"
    },
    {
        "title": "COMPLEX-IT: A Case-Based Modeling and Scenario Simulation Platform for\n  Social Inquiry",
        "authors": [
            "Corey Schimpf",
            "Brian Castellani"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  COMPLEX-IT is a case-based, mixed-methods platform for social inquiry into\ncomplex data/systems, designed to increase non-expert access to the tools of\ncomputational social science (i.e., cluster analysis, artificial intelligence,\ndata visualization, data forecasting, and scenario simulation). In particular,\nCOMPLEX-IT aids social inquiry though a heavy emphasis on learning about the\ncomplex data/system under study, which it does by (a) identifying and\nforecasting major and minor clusters/trends; (b) visualizing their complex\ncausality; and (c) simulating scenarios for potential interventions. COMPLEX-IT\nis accessible through the web or can be run locally and is powered by R and the\nShiny web framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.03099v1"
    },
    {
        "title": "Airline Crew Pairing Optimization Framework for Large Networks with\n  Multiple Crew Bases and Hub-and-Spoke Subnetworks",
        "authors": [
            "Divyam Aggarwal",
            "Dhish Kumar Saxena",
            "Thomas Bäck",
            "Michael Emmerich"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Crew Pairing Optimization aims at generating a set of flight sequences (crew\npairings), covering all flights in an airline's flight schedule, at minimum\ncost, while satisfying several legality constraints. CPO is critically\nimportant for airlines' business viability, considering that the crew operating\ncost is their second-largest expense. It poses an NP-hard combinatorial\noptimization problem, to tackle which, the state-of-the-art relies on relaxing\nthe underlying Integer Programming Problem (IPP) into a Linear Programming\nProblem (LPP), solving the latter through Column Generation (CG) technique, and\nintegerization of the resulting LPP solution. However, with the growing scale\nand complexity of the flight networks (those with a large number of flights,\nmultiple crew bases and/or multiple hub-and-spoke subnetworks), the utility of\nthe conventional CG-practices has become questionable. This paper proposed an\nAirline Crew Pairing Optimization Framework, AirCROP, whose constitutive\nmodules include the Legal Crew Pairing Generator, Initial Feasible Solution\nGenerator, and an Optimization Engine built on heuristic-based\nCG-implementation. In this paper, besides the design of AirCROP's modules,\ninsights into important questions related to how these modules interact, which\nthe literature is otherwise silent on, have been shared. These relate to the\nsensitivity of AirCROP's performance towards: sources of variability over\nmultiple runs for a given problem, initialization method, and termination\nparameters for LPP-solutioning and IPP-solutioning. The efficacy of the AirCROP\nhas been demonstrated on real-world large-scale and complex flight networks\n(with over 4200 flights, 15 crew bases, and billion-plus pairings). It is hoped\nthat with the emergence of such complex flight networks, this paper shall serve\nas an important milestone for affiliated research and applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.03994v2"
    },
    {
        "title": "FunGrim: a symbolic library for special functions",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We present the Mathematical Functions Grimoire (FunGrim), a website and\ndatabase of formulas and theorems for special functions. We also discuss the\nsymbolic computation library used as the backend and main development tool for\nFunGrim, and the Grim formula language used in these projects to represent\nmathematical content semantically.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.06181v1"
    },
    {
        "title": "A practical approach to testing random number generators in computer\n  algebra systems",
        "authors": [
            "Migran N. Gevorkyan",
            "Dmitry S. Kulyabov",
            "Anastasia V. Demidova",
            "Anna V. Korolkova"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper has a practical aim. For a long time, implementations of\npseudorandom number generators in standard libraries of programming languages\nhad poor quality. The situation started to improve only recently. Up to now, a\nlarge number of libraries and weakly supported mathematical packages use\noutdated algorithms for random number generation. Four modern sets of\nstatistical tests that can be used for verifying random number generators are\ndescribed. It is proposed to use command line utilities, which makes it\npossible to avoid low-level programming in such languages as C or C++. Only\nfree open source systems are considered.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.08913v1"
    },
    {
        "title": "Sparse Approximate Multifrontal Factorization with Butterfly Compression\n  for High Frequency Wave Equations",
        "authors": [
            "Yang Liu",
            "Pieter Ghysels",
            "Lisa Claus",
            "Xiaoye Sherry Li"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We present a fast and approximate multifrontal solver for large-scale sparse\nlinear systems arising from finite-difference, finite-volume or finite-element\ndiscretization of high-frequency wave equations. The proposed solver leverages\nthe butterfly algorithm and its hierarchical matrix extension for compressing\nand factorizing large frontal matrices via graph-distance guided entry\nevaluation or randomized matrix-vector multiplication-based schemes. Complexity\nanalysis and numerical experiments demonstrate $\\mathcal{O}(N\\log^2 N)$\ncomputation and $\\mathcal{O}(N)$ memory complexity when applied to an $N\\times\nN$ sparse system arising from 3D high-frequency Helmholtz and Maxwell problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.00202v2"
    },
    {
        "title": "ACORNS: An Easy-To-Use Code Generator for Gradients and Hessians",
        "authors": [
            "Deshana Desai",
            "Etai Shuchatowitz",
            "Zhongshi Jiang",
            "Teseo Schneider",
            "Daniele Panozzo"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The computation of first and second-order derivatives is a staple in many\ncomputing applications, ranging from machine learning to scientific computing.\nWe propose an algorithm to automatically differentiate algorithms written in a\nsubset of C99 code and its efficient implementation as a Python script. We\ndemonstrate that our algorithm enables automatic, reliable, and efficient\ndifferentiation of common algorithms used in physical simulation and geometry\nprocessing.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.05094v1"
    },
    {
        "title": "Temporal Vectorization for Stencils",
        "authors": [
            "Liang Yuan",
            "Hang Cao",
            "Yunquan Zhang",
            "Kun Li",
            "Pengqi Lu",
            "Yue Yue"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Stencil computations represent a very common class of nested loops in\nscientific and engineering applications. Exploiting vector units in modern CPUs\nis crucial to achieving peak performance. Previous vectorization approaches\noften consider the data space, in particular the innermost unit-strided loop.\nIt leads to the well-known data alignment conflict problem that vector loads\nare overlapped due to the data sharing between continuous stencil computations.\nThis paper proposes a novel temporal vectorization scheme for stencils. It\nvectorizes the stencil computation in the iteration space and assembles points\nwith different time coordinates in one vector. The temporal vectorization leads\nto a small fixed number of vector reorganizations that is irrelevant to the\nvector length, stencil order, and dimension. Furthermore, it is also applicable\nto Gauss-Seidel stencils, whose vectorization is not well-studied. The\neffectiveness of the temporal vectorization is demonstrated by various Jacobi\nand Gauss-Seidel stencils.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.04868v1"
    },
    {
        "title": "DSLib: An open source library for the dominant set clustering method",
        "authors": [
            "Sebastiano Vascon",
            "Samuel Rota Bulò",
            "Vittorio Murino",
            "Marcello Pelillo"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  DSLib is an open-source implementation of the Dominant Set (DS) clustering\nalgorithm written entirely in Matlab. The DS method is a graph-based clustering\ntechnique rooted in the evolutionary game theory that starts gaining lots of\ninterest in the computer science community. Thanks to its duality with game\ntheory and its strict relation to the notion of maximal clique, has been\nexplored in several directions not only related to clustering problems.\nApplications in graph matching, segmentation, classification and medical\nimaging are common in literature. This package provides an implementation of\nthe original DS clustering algorithm since no code has been officially released\nyet, together with a still growing collection of methods and variants related\nto it. Our library is integrable into a Matlab pipeline without dependencies,\nit is simple to use and easily extendable for upcoming works. The latest source\ncode, the documentation and some examples can be downloaded from\nhttps://xwasco.github.io/DominantSetLibrary.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.07906v1"
    },
    {
        "title": "LightSeq: A High Performance Inference Library for Transformers",
        "authors": [
            "Xiaohui Wang",
            "Ying Xiong",
            "Yang Wei",
            "Mingxuan Wang",
            "Lei Li"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Transformer, BERT and their variants have achieved great success in natural\nlanguage processing. Since Transformer models are huge in size, serving these\nmodels is a challenge for real industrial applications. In this paper, we\npropose LightSeq, a highly efficient inference library for models in the\nTransformer family. LightSeq includes a series of GPU optimization techniques\nto to streamline the computation of neural layers and to reduce memory\nfootprint. LightSeq can easily import models trained using PyTorch and\nTensorflow. Experimental results on machine translation benchmarks show that\nLightSeq achieves up to 14x speedup compared with TensorFlow and 1.4x compared\nwith FasterTransformer, a concurrent CUDA implementation. The code is available\nat https://github.com/bytedance/lightseq.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.13887v4"
    },
    {
        "title": "Toward Performance-Portable PETSc for GPU-based Exascale Systems",
        "authors": [
            "Richard Tran Mills",
            "Mark F. Adams",
            "Satish Balay",
            "Jed Brown",
            "Alp Dener",
            "Matthew Knepley",
            "Scott E. Kruger",
            "Hannah Morgan",
            "Todd Munson",
            "Karl Rupp",
            "Barry F. Smith",
            "Stefano Zampini",
            "Hong Zhang",
            "Junchao Zhang"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The Portable Extensible Toolkit for Scientific computation (PETSc) library\ndelivers scalable solvers for nonlinear time-dependent differential and\nalgebraic equations and for numerical optimization.The PETSc design for\nperformance portability addresses fundamental GPU accelerator challenges and\nstresses flexibility and extensibility by separating the programming model used\nby the application from that used by the library, and it enables application\ndevelopers to use their preferred programming model, such as Kokkos, RAJA,\nSYCL, HIP, CUDA, or OpenCL, on upcoming exascale systems. A blueprint for using\nGPUs from PETSc-based codes is provided, and case studies emphasize the\nflexibility and high performance achieved on current GPU-based systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.00715v2"
    },
    {
        "title": "Calcium: computing in exact real and complex fields",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Calcium is a C library for real and complex numbers in a form suitable for\nexact algebraic and symbolic computation. Numbers are represented as elements\nof fields $\\mathbb{Q}(a_1,\\ldots,a_n)$ where the extensions numbers $a_k$ may\nbe algebraic or transcendental. The system combines efficient field operations\nwith automatic discovery and certification of algebraic relations, resulting in\na practical computational model of $\\mathbb{R}$ and $\\mathbb{C}$ in which\nequality is rigorously decidable for a large class of numbers.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.01728v1"
    },
    {
        "title": "Deep Learning Framework From Scratch Using Numpy",
        "authors": [
            "Andrei Nicolae"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This work is a rigorous development of a complete and general-purpose deep\nlearning framework from the ground up. The fundamental components of deep\nlearning - automatic differentiation and gradient methods of optimizing\nmultivariable scalar functions - are developed from elementary calculus and\nimplemented in a sensible object-oriented approach using only Python and the\nNumpy library. Demonstrations of solved problems using the framework, named\nArrayFlow, include a computer vision classification task, solving for the shape\nof a catenary, and a 2nd order differential equation.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.08461v1"
    },
    {
        "title": "PIFE-PIC: Parallel Immersed-Finite-Element Particle-In-Cell For 3-D\n  Kinetic Simulations of Plasma-Material Interactions",
        "authors": [
            "Daoru Han",
            "Xiaoming He",
            "David Lund",
            "Xu Zhang"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper presents a recently developed particle simulation code package\nPIFE-PIC, which is a novel three-dimensional (3-D) Parallel\nImmersed-Finite-Element (IFE) Particle-in-Cell (PIC) simulation model for\nparticle simulations of plasma-material interactions. This framework is based\non the recently developed non-homogeneous electrostatic IFE-PIC algorithm,\nwhich is designed to handle complex plasma-material interface conditions\nassociated with irregular geometries using a Cartesian-mesh-based PIC.\nThree-dimensional domain decomposition is utilized for both the electrostatic\nfield solver with IFE and the particle operations in PIC to distribute the\ncomputation among multiple processors. A simulation of the\norbital-motion-limited (OML) sheath of a dielectric sphere immersed in a\nstationary plasma is carried out to validate PIFE-PIC and profile the parallel\nperformance of the code package. Furthermore, a large-scale simulation of\nplasma charging at a lunar crater containing 2 million PIC cells (10 million\nFE/IFE cells) and about 520 million particles, running for 20,000 PIC steps in\nabout 109 wall-clock hours, is presented to demonstrate the high-performance\ncomputing capability of PIFE-PIC.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.10214v1"
    },
    {
        "title": "Parallelized Discrete Exterior Calculus for Three-Dimensional Elliptic\n  Problems",
        "authors": [
            "Pieter D. Boom",
            "Ashley Seepujak",
            "Odysseas Kosmas",
            "Lee Margetts",
            "Andrey Jivkov"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  A formulation of elliptic boundary value problems is used to develop the\nfirst discrete exterior calculus (DEC) library for massively parallel\ncomputations with 3D domains. This can be used for steady-state analysis of any\nphysical process driven by the gradient of a scalar quantity, e.g. temperature,\nconcentration, pressure or electric potential, and is easily extendable to\ntransient analysis. In addition to offering this library to the community, we\ndemonstrate one important benefit from the DEC formulation: effortless\nintroduction of strong heterogeneities and discontinuities. These are typical\nfor real materials, but challenging for widely used domain discretization\nschemes, such as finite elements. Specifically, we demonstrate the efficiency\nof the method for calculating the evolution of thermal conductivity of a solid\nwith a growing crack population. Future development of the library will deal\nwith transient problems, and more importantly with processes driven by\ngradients of vector quantities.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.05999v1"
    },
    {
        "title": "Faster Math Functions, Soundly",
        "authors": [
            "Ian Briggs",
            "Pavel Panchekha"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Standard library implementations of functions like sin and exp optimize for\naccuracy, not speed, because they are intended for general-purpose use. But\napplications tolerate inaccuracy from cancellation, rounding error, and\nsingularities-sometimes even very high error-and many application could\ntolerate error in function implementations as well. This raises an intriguing\npossibility: speeding up numerical code by tuning standard function\nimplementations. This paper thus introduces OpTuner, an automatic method for\nselecting the best implementation of mathematical functions at each use site.\nOpTuner assembles dozens of implementations for the standard mathematical\nfunctions from across the speed-accuracy spectrum. OpTuner then uses error\nTaylor series and integer linear programming to compute optimal assignments of\nfunction implementation to use site and presents the user with a speed-accuracy\nPareto curve they can use to speed up their code. In a case study on the\nPOV-Ray ray tracer, OpTuner speeds up a critical computation, leading to a\nwhole program speedup of 9% with no change in the program output (whereas human\nefforts result in slower code and lower-quality output). On a broader study of\n37 standard benchmarks, OpTuner matches 216 implementations to 89 use sites and\ndemonstrates speed-ups of 107% for negligible decreases in accuracy and of up\nto 438% for error-tolerant applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.05761v1"
    },
    {
        "title": "NeuralPDE: Automating Physics-Informed Neural Networks (PINNs) with\n  Error Approximations",
        "authors": [
            "Kirill Zubov",
            "Zoe McCarthy",
            "Yingbo Ma",
            "Francesco Calisto",
            "Valerio Pagliarino",
            "Simone Azeglio",
            "Luca Bottero",
            "Emmanuel Luján",
            "Valentin Sulzer",
            "Ashutosh Bharambe",
            "Nand Vinchhi",
            "Kaushik Balakrishnan",
            "Devesh Upadhyay",
            "Chris Rackauckas"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Physics-informed neural networks (PINNs) are an increasingly powerful way to\nsolve partial differential equations, generate digital twins, and create neural\nsurrogates of physical models. In this manuscript we detail the inner workings\nof NeuralPDE.jl and show how a formulation structured around numerical\nquadrature gives rise to new loss functions which allow for adaptivity towards\nbounded error tolerances. We describe the various ways one can use the tool,\ndetailing mathematical techniques like using extended loss functions for\nparameter estimation and operator discovery, to help potential users adopt\nthese PINN-based techniques into their workflow. We showcase how NeuralPDE uses\na purely symbolic formulation so that all of the underlying training code is\ngenerated from an abstract formulation, and show how to make use of GPUs and\nsolve systems of PDEs. Afterwards we give a detailed performance analysis which\nshowcases the trade-off between training techniques on a large set of PDEs. We\nend by focusing on a complex multiphysics example, the Doyle-Fuller-Newman\n(DFN) Model, and showcase how this PDE can be formulated and solved with\nNeuralPDE. Together this manuscript is meant to be a detailed and approachable\ntechnical report to help potential users of the technique quickly get a sense\nof the real-world performance trade-offs and use cases of the PINN techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.09443v1"
    },
    {
        "title": "Hyperbolic Diffusion in Flux Reconstruction: Optimisation through Kernel\n  Fusion within Tensor-Product Elements",
        "authors": [
            "Will Trojak",
            "Rob Watson",
            "Freddie Witherden"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Novel methods are presented in this initial study for the fusion of GPU\nkernels in the artificial compressibility method (ACM), using tensor product\nelements with constant Jacobians and flux reconstruction. This is made possible\nthrough the hyperbolisation of the diffusion terms, which eliminates the\nexpensive algorithmic steps needed to form the viscous stresses. Two fusion\napproaches are presented, which offer differing levels of parallelism. This is\nfound to be necessary for the change in workload as the order of accuracy of\nthe elements is increased. Several further optimisations of these approaches\nare demonstrated, including a generation time memory manager which maximises\nresource usage. The fused kernels are able to achieve 3-4 times speedup, which\ncompares favourably with a theoretical maximum speedup of 4. In three\ndimensional test cases, the generated fused kernels are found to reduce total\nruntime by ${\\sim}25\\%$, and, when compared to the standard ACM formulation,\nsimulations demonstrate that a speedup of $2.3$ times can be achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.14027v2"
    },
    {
        "title": "High-Performance Level-1 and Level-2 BLAS",
        "authors": [
            "Amit Singh",
            "Cem Bassoy"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The introduction of the Basic Linear Algebra Subroutine (BLAS) in the 1970s\npaved the way for different libraries to solve the same problem with an\nimproved approach and hardware. The new BLAS implementation led to\nHigh-Performance Computing (HPC) innovation. All the love went to the level 3\nBLAS due to its humongous application in different fields, not bounded by\ncomputer science. However, level 1 and level 2 got neglected; we tried to solve\nthe problem by introducing the new algorithm for the Vector-Vector dot product,\nVector-Vector outer product and Matrix-Vector product, which improves the\nperformance of these operations in a significant way. We are not introducing\nany library but algorithms, which improves upon the current state of art\nalgorithms. Also, we rely on the FMA instruction, OpenMP, and the compiler to\noptimize the code rather than implementing the algorithm in assembly.\nTherefore, our current implementation is machine oblivious and depends on the\ncompilers ability to optimize the code.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.02025v1"
    },
    {
        "title": "dbcsp: User-friendly R package for Distance-Based Common Spacial\n  Patterns",
        "authors": [
            "Itsaso Rodriguez",
            "Itziar Irigoien",
            "Basilio Sierra",
            "Concepcion Arenas"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Common Spacial Patterns (CSP) is a widely used method to analyse\nelectroencephalography (EEG) data, concerning the supervised classification of\nbrain's activity. More generally, it can be useful to distinguish between\nmultivariate signals recorded during a time span for two different classes. CSP\nis based on the simultaneous diagonalization of the average covariance matrices\nof signals from both classes and it allows to project the data into a\nlow-dimensional subspace. Once data are represented in a low-dimensional\nsubspace, a classification step must be carried out. The original CSP method is\nbased on the Euclidean distance between signals and here, we extend it so that\nit can be applied on any appropriate distance for data at hand. Both, the\nclassical CSP and the new Distance-Based CSP (DB-CSP) are implemented in an R\npackage, called dbcsp.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.00740v1"
    },
    {
        "title": "Arbitrary-precision computation of the gamma function",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We discuss the best methods available for computing the gamma function\n$\\Gamma(z)$ in arbitrary-precision arithmetic with rigorous error bounds. We\naddress different cases: rational, algebraic, real or complex arguments; large\nor small arguments; low or high precision; with or without precomputation. The\nmethods also cover the log-gamma function $\\log \\Gamma(z)$, the digamma\nfunction $\\psi(z)$, and derivatives $\\Gamma^{(n)}(z)$ and $\\psi^{(n)}(z)$.\nBesides attempting to summarize the existing state of the art, we present some\nnew formulas, estimates, bounds and algorithmic improvements and discuss\nimplementation results.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.08392v1"
    },
    {
        "title": "An Attempt to Generate Code for Symmetric Tensor Computations",
        "authors": [
            "Jessica Shi",
            "Stephen Chou",
            "Fredrik Kjolstad",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This document describes an attempt to develop a compiler-based approach for\ncomputations with symmetric tensors. Given a computation and the symmetries of\nits input tensors, we derive formulas for random access under a storage scheme\nthat eliminates redundancies; construct intermediate representations to\ndescribe the loop structure; and translate this information, using the taco\ntensor algebra compiler, into code. While we achieve a framework for reasoning\nabout a fairly general class of symmetric computations, the resulting code is\nnot performant when the symmetries are misaligned.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.00186v1"
    },
    {
        "title": "pyFFS: A Python Library for Fast Fourier Series Computation and\n  Interpolation with GPU Acceleration",
        "authors": [
            "Eric Bezzam",
            "Sepand Kashani",
            "Paul Hurley",
            "Martin Vetterli",
            "Matthieu Simeoni"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Fourier transforms are an often necessary component in many computational\ntasks, and can be computed efficiently through the fast Fourier transform (FFT)\nalgorithm. However, many applications involve an underlying continuous signal,\nand a more natural choice would be to work with e.g. the Fourier series (FS)\ncoefficients in order to avoid the additional overhead of translating between\nthe analog and discrete domains. Unfortunately, there exists very little\nliterature and tools for the manipulation of FS coefficients from discrete\nsamples. This paper introduces a Python library called pyFFS for efficient FS\ncoefficient computation, convolution, and interpolation. While the libraries\nSciPy and NumPy provide efficient functionality for discrete Fourier transform\ncoefficients via the FFT algorithm, pyFFS addresses the computation of FS\ncoefficients through what we call the fast Fourier series (FFS). Moreover,\npyFFS includes an FS interpolation method based on the chirp Z-transform that\ncan make it more than an order of magnitude faster than the SciPy equivalent\nwhen one wishes to perform interpolation. GPU support through the CuPy library\nallows for further acceleration, e.g. an order of magnitude faster for\ncomputing the 2-D FS coefficients of 1000 x 1000 samples and nearly two orders\nof magnitude faster for 2-D interpolation. As an application, we discuss the\nuse of pyFFS in Fourier optics. pyFFS is available as an open source package at\nhttps://github.com/imagingofthings/pyFFS, with documentation at\nhttps://pyffs.readthedocs.io.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.00262v3"
    },
    {
        "title": "A Cross-Platform Benchmark for Interval Computation Libraries",
        "authors": [
            "Xuan Tang",
            "Zachary Ferguson",
            "Teseo Schneider",
            "Denis Zorin",
            "Shoaib Kamil",
            "Daniele Panozzo"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Interval computation is widely used to certify computations that use floating\npoint operations to avoid pitfalls related to rounding error introduced by\ninaccurate operations. Despite its popularity and practical benefits, support\nfor interval arithmetic is not standardized nor available in mainstream\nprogramming languages. We propose the first benchmark for interval\ncomputations, coupled with reference solutions computed with exact arithmetic,\nand compare popular C and C++ libraries over different architectures, operating\nsystems, and compilers. The benchmark allows identifying limitations in\nexisting implementations, and provides a reliable guide on which library to use\non each system. We believe that our benchmark will be useful for developers of\nfuture interval libraries, as a way to test the correctness and performance of\ntheir algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.06215v1"
    },
    {
        "title": "Can Fortran's 'do concurrent' replace directives for accelerated\n  computing?",
        "authors": [
            "Miko M. Stulajter",
            "Ronald M. Caplan",
            "Jon A. Linker"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Recently, there has been growing interest in using standard language\nconstructs (e.g. C++'s Parallel Algorithms and Fortran's do concurrent) for\naccelerated computing as an alternative to directive-based APIs (e.g. OpenMP\nand OpenACC). These constructs have the potential to be more portable, and some\ncompilers already (or have plans to) support such standards. Here, we look at\nthe current capabilities, portability, and performance of replacing directives\nwith Fortran's do concurrent using a mini-app that currently implements OpenACC\nfor GPU-acceleration and OpenMP for multi-core CPU parallelism. We replace as\nmany directives as possible with do concurrent, testing various configurations\nand compiler options within three major compilers: GNU's gfortran, NVIDIA's\nnvfortran, and Intel's ifort. We find that with the right compiler versions and\nflags, many directives can be replaced without loss of performance or\nportability, and, in the case of nvfortran, they can all be replaced. We\ndiscuss limitations that may apply to more complicated codes and future\nlanguage additions that may mitigate them. The software and Singularity\ncontainers are publicly provided to allow the results to be reproduced.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.10151v1"
    },
    {
        "title": "The Creation of Puffin, the Automatic Uncertainty Compiler",
        "authors": [
            "Nicholas Gray",
            "Marco De Angelis",
            "Scott Ferson"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  An uncertainty compiler is a tool that automatically translates original\ncomputer source code lacking explicit uncertainty analysis into code containing\nappropriate uncertainty representations and uncertainty propagation algorithms.\nWe have developed an prototype uncertainty compiler along with an associated\nobject-oriented uncertainty language in the form of a stand-alone Python\nlibrary. It handles the specifications of input uncertainties and inserts calls\nto intrusive uncertainty quantification algorithms in the library. The\nuncertainty compiler can apply intrusive uncertainty propagation methods to\ncodes or parts of codes and therefore more comprehensively and flexibly address\nboth epistemic and aleatory uncertainties.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.10153v2"
    },
    {
        "title": "Two-dimensional mesh generator in generalized coordinates implemented in\n  Python",
        "authors": [
            "Gustavo Taiji Naozuka",
            "Saulo Martiello Mastelini",
            "Eliandro Rodrigues Cirilo",
            "Neyva Maria Lopes Romeiro",
            "Paulo Laerte Natti"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Through mathematical models, it is possible to turn a problem of the physical\ndomain into the computational domain. In this context, the paper presents a\ntwo-dimensional mesh generator in generalized coordinates, which uses the\nParametric Linear Spline method and partial differential equations. The\ngenerator is automated and able to treat real complex domains. The code was\nimplemented in Python, applying the Numpy and Matplotlib libraries to matrix\nmanipulations and graphical plots, respectively. Applications are made for\nmonoblock meshes (two-dimensional shape of a bottle) and multi-block meshes\n(geometry of Igap\\'o I lake, Londrina, Paran\\'a, Brazil).\n",
        "pdf_link": "http://arxiv.org/pdf/2110.12875v1"
    },
    {
        "title": "A Massively Parallel Implementation of Multilevel Monte Carlo for Finite\n  Element Models",
        "authors": [
            "Santiago Badia",
            "Jerrad Hampton",
            "Javier Principe"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The Multilevel Monte Carlo (MLMC) method has proven to be an effective\nvariance-reduction statistical method for Uncertainty Quantification (UQ) in\nPartial Differential Equation (PDE) models, combining model computations at\ndifferent levels to create an accurate estimate. Still, the computational\ncomplexity of the resulting method is extremely high, particularly for 3D\nmodels, which requires advanced algorithms for the efficient exploitation of\nHigh Performance Computing (HPC). In this article we present a new\nimplementation of the MLMC in massively parallel computer architectures,\nexploiting parallelism within and between each level of the hierarchy. The\nnumerical approximation of the PDE is performed using the finite element method\nbut the algorithm is quite general and could be applied to other discretization\nmethods as well, although the focus is on parallel sampling. The two key\ningredients of an efficient parallel implementation are a good processor\npartition scheme together with a good scheduling algorithm to assign work to\ndifferent processors. We introduce a multiple partition of the set of\nprocessors that permits the simultaneous execution of different levels and we\ndevelop a dynamic scheduling algorithm to exploit it. The problem of finding\nthe optimal scheduling of distributed tasks in a parallel computer is an\nNP-complete problem. We propose and analyze a new greedy scheduling algorithm\nto assign samples and we show that it is a 2-approximation, which is the best\nthat may be expected under general assumptions. On top of this result we design\na distributed memory implementation using the Message Passing Interface (MPI)\nstandard. Finally we present a set of numerical experiments illustrating its\nscalability properties.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.11788v2"
    },
    {
        "title": "FCMpy: A Python Module for Constructing and Analyzing Fuzzy Cognitive\n  Maps",
        "authors": [
            "Samvel Mkhitaryan",
            "Philippe J. Giabbanelli",
            "Maciej K. Wozniak",
            "Gonzalo Napoles",
            "Nanne K. de Vries",
            "Rik Crutzen"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  FCMpy is an open source package in Python for building and analyzing Fuzzy\nCognitive Maps. More specifically, the package allows 1) deriving fuzzy causal\nweights from qualitative data, 2) simulating the system behavior, 3) applying\nmachine learning algorithms (e.g., Nonlinear Hebbian Learning, Active Hebbian\nLearning, Genetic Algorithms and Deterministic Learning) to adjust the FCM\ncausal weight matrix and to solve classification problems, and 4) implementing\nscenario analysis by simulating hypothetical interventions (i.e., analyzing\nwhat-if scenarios).\n",
        "pdf_link": "http://arxiv.org/pdf/2111.12749v1"
    },
    {
        "title": "An Asymptotic Cost Model for Autoscheduling Sparse Tensor Programs",
        "authors": [
            "Willow Ahrens",
            "Fredrik Kjolstad",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  While loop reordering and fusion can make big impacts on the constant-factor\nperformance of dense tensor programs, the effects on sparse tensor programs are\nasymptotic, often leading to orders of magnitude performance differences in\npractice. Sparse tensors also introduce a choice of compressed storage formats\nthat can have asymptotic effects. Research into sparse tensor compilers has led\nto simplified languages that express these tradeoffs, but the user is expected\nto provide a schedule that makes the decisions. This is challenging because\nschedulers must anticipate the interaction between sparse formats, loop\nstructure, potential sparsity patterns, and the compiler itself. Automating\nthis decision making process stands to finally make sparse tensor compilers\naccessible to end users.\n  We present, to the best of our knowledge, the first automatic asymptotic\nscheduler for sparse tensor programs. We provide an approach to abstractly\nrepresent the asymptotic cost of schedules and to choose between them. We\nnarrow down the search space to a manageably small \"Pareto frontier\" of\nasymptotically undominated kernels. We test our approach by compiling these\nkernels with the TACO sparse tensor compiler and comparing them with those\ngenerated with the default TACO schedules. Our results show that our approach\nreduces the scheduling space by orders of magnitude and that the generated\nkernels perform asymptotically better than those generated using the default\nschedules.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.14947v1"
    },
    {
        "title": "HOTTBOX: Higher Order Tensor ToolBOX",
        "authors": [
            "Ilya Kisil",
            "Giuseppe G. Calvi",
            "Bruno S. Dees",
            "Danilo P. Mandic"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  HOTTBOX is a Python library for exploratory analysis and visualisation of\nmulti-dimensional arrays of data, also known as tensors. The library includes\nmethods ranging from standard multi-way operations and data manipulation\nthrough to multi-linear algebra based tensor decompositions. HOTTBOX also\ncomprises sophisticated algorithms for generalised multi-linear classification\nand data fusion, such as Support Tensor Machine (STM) and Tensor Ensemble\nLearning (TEL). For user convenience, HOTTBOX offers a unifying API which\nestablishes a self-sufficient ecosystem for various forms of efficient\nrepresentation of multi-way data and the corresponding decomposition and\nassociation algorithms. Particular emphasis is placed on scalability and\ninteractive visualisation, to support multidisciplinary data analysis\ncommunities working on big data and tensors. HOTTBOX also provides means for\nintegration with other popular data science libraries for visualisation and\ndata manipulation. The source code, examples and documentation ca be found at\nhttps://github.com/hottbox/hottbox.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.15662v1"
    },
    {
        "title": "Dynamic Sparse Tensor Algebra Compilation",
        "authors": [
            "Stephen Chou",
            "Saman Amarasinghe"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper shows how to generate efficient tensor algebra code that compute\non dynamic sparse tensors, which have sparsity structures that evolve over\ntime. We propose a language for precisely specifying recursive, pointer-based\ndata structures, and we show how this language can express a wide range of\ndynamic data structures that support efficient modification, such as linked\nlists, binary search trees, and B-trees. We then describe how, given high-level\nspecifications of such data structures, a compiler can generate code to\nefficiently iterate over and compute with dynamic sparse tensors that are\nstored in the aforementioned data structures. Furthermore, we define an\nabstract interface that captures how nonzeros can be inserted into dynamic data\nstructures, and we show how this abstraction guides a compiler to emit\nefficient code that store the results of sparse tensor algebra computations in\ndynamic data structures.\n  We evaluate our technique and find that it generates efficient dynamic sparse\ntensor algebra kernels. Code that our technique emits to compute the main\nkernel of the PageRank algorithm is 1.05$\\times$ as fast as Aspen, a\nstate-of-the-art dynamic graph processing framework. Furthermore, our technique\noutperforms PAM, a parallel ordered (key-value) maps library, by 7.40$\\times$\nwhen used to implement element-wise addition of a dynamic sparse matrix to a\nstatic sparse matrix.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.01394v1"
    },
    {
        "title": "An eXtended Finite Element Method Implementation in COMSOL Multiphysics:\n  Thermo-Hydro-Mechanical Modeling of Fluid Flow in Discontinuous Porous Media",
        "authors": [
            "Ahmad Jafari",
            "Mohammad Vahab",
            "Pooyan Broumand",
            "Nasser Khalili"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper presents the implementation of the eXtended Finite Element Method\n(XFEM) in the general-purpose commercial software package COMSOL Multiphysics\nfor multi-field thermo-hydro-mechanical problems in discontinuous porous media.\nTo this end, an exclusive enrichment strategy is proposed in compliance with\nthe COMSOL modeling structure. COMSOL modules and physics interfaces are\nadopted to take account of the relevant physical processes involved in\nthermo-hydro-mechanical coupling analysis, namely: the mechanical deformation,\nfluid flow in porous media and heat transfer. Essential changes are made to the\ninternal variables of the physics interfaces to ensure consistency in the\nevaluation of enriched solution fields. The model preprocessing, level-set\nupdates, coupling of the relevant physics and postprocessing procedures are\nperformed adopting a coherent utilization of the COMSOL built-in features along\nwith the COMSOL LiveLink for MATLAB functions. The implementation process,\nremedies for the treatment of the enriched zones, XFEM framework setup,\nmultiphysics coupling, numerical integration and numerical solution strategy\nare described in detail. The capabilities and performance of the proposed\napproach are investigated by examining several multi-field\nthermo-hydro-mechanical simulations involving single/multiple discontinuities\nin 2D/3D porous rock settings.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.11918v1"
    },
    {
        "title": "Batched Second-Order Adjoint Sensitivity for Reduced Space Methods",
        "authors": [
            "François Pacaud",
            "Michel Schanen",
            "Daniel Adrian Maldonado",
            "Alexis Montoison",
            "Valentin Churavy",
            "Julian Samaroo",
            "Mihai Anitescu"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  This paper presents an efficient method for extracting the second-order\nsensitivities from a system of implicit nonlinear equations on upcoming\ngraphical processing units (GPU) dominated computer systems. We design a custom\nautomatic differentiation (AutoDiff) backend that targets highly parallel\narchitectures by extracting the second-order information in batch. When the\nnonlinear equations are associated to a reduced space optimization problem, we\nleverage the parallel reverse-mode accumulation in a batched adjoint-adjoint\nalgorithm to compute efficiently the reduced Hessian of the problem. We apply\nthe method to extract the reduced Hessian associated to the balance equations\nof a power network, and show on the largest instances that a parallel GPU\nimplementation is 30 times faster than a sequential CPU reference based on\nUMFPACK.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.00241v1"
    },
    {
        "title": "ParticLS: Object-oriented software for discrete element methods and\n  peridynamics",
        "authors": [
            "Andrew D. Davis",
            "Brendan A. West",
            "Nathanael J. Frisch",
            "Devin T. O'Connor",
            "Matthew D. Parno"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  ParticLS (\\emph{Partic}le \\emph{L}evel \\emph{S}ets) is a software library\nthat implements the discrete element method (DEM) and meshfree methods.\nParticLS tracks the interaction between individual particles whose geometries\nare defined by level sets capable of capturing complex shapes. These particles\neither represent rigid bodies or material points within a continuum.\nParticle-particle interactions using various contact laws numerically\napproximate solutions to energy and mass conservation equations, simulating\nrigid body dynamics or deformation/fracture. By leveraging multiple contact\nlaws, ParticLS can simulate interacting bodies that deform, fracture, and are\ncomposed of many particles. In the continuum setting, we numerically solve the\nperidynamic equations -- integro-differential equations capable of modeling\nobjects with discontinuous displacement fields and complex fracture dynamics.\nWe show that the discretized peridynamic equations can be solved using the same\nsoftware infrastructure that implements the DEM. Therefore, we design a unique\nsoftware library where users can easily add particles with arbitrary geometries\nand new contact laws that model either rigid-body interaction or peridynamic\nconstitutive relationships. We demonstrate ParticLS' versatility on test\nproblems meant to showcase features applicable to a broad selection of fields\nsuch as tectonics, granular media, multiscale simulations, glacier calving, and\nsea ice.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.10855v1"
    },
    {
        "title": "FFTc: An MLIR Dialect for Developing HPC Fast Fourier Transform\n  Libraries",
        "authors": [
            "Yifei He",
            "Artur Podobas",
            "Måns I. Andersson",
            "Stefano Markidis"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Discrete Fourier Transform (DFT) libraries are one of the most critical\nsoftware components for scientific computing. Inspired by FFTW, a widely used\nlibrary for DFT HPC calculations, we apply compiler technologies for the\ndevelopment of HPC Fourier transform libraries. In this work, we introduce\nFFTc, a domain-specific language, based on Multi-Level Intermediate\nRepresentation (MLIR), for expressing Fourier Transform algorithms. We present\nthe initial design, implementation, and preliminary results of FFTc.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.06803v2"
    },
    {
        "title": "HDSDP: Software for Semidefinite Programming",
        "authors": [
            "Wenzhi Gao",
            "Dongdong Ge",
            "Yinyu Ye"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  HDSDP is a numerical software solving the semidefinite programming problems.\nThe main framework of HDSDP resembles the dual-scaling interior point solver\nDSDP [BY2008] and several new features, including a dual method based on the\nsimplified homogeneous self-dual embedding, have been implemented. The\nembedding technique enhances stability of the dual method and several new\nheuristics and computational techniques are designed to accelerate its\nconvergence. HDSDP aims to show how dual-scaling algorithm benefits from the\nself-dual embedding and it is developed in parallel to DSDP5.8. Numerical\nexperiments over several classical benchmark datasets exhibit its robustness\nand efficiency, and particularly its advantages on SDP instances featuring\nlow-rank structure and sparsity. HDSDP is open-sourced under MIT license and\navailable at https://github.com/COPT-Public/HDSDP.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.13862v2"
    },
    {
        "title": "Distributed Objective Function Evaluation for Optimization of Radiation\n  Therapy Treatment Plans",
        "authors": [
            "Felix Liu",
            "Måns I. Andersson",
            "Albin Fredriksson",
            "Stefano Markidis"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  The modern workflow for radiation therapy treatment planning involves\nmathematical optimization to determine optimal treatment machine parameters for\neach patient case. The optimization problems can be computationally expensive,\nrequiring iterative optimization algorithms to solve. In this work, we\ninvestigate a method for distributing the calculation of objective functions\nand gradients for radiation therapy optimization problems across computational\nnodes. We test our approach on the TROTS dataset -- which consists of\noptimization problems from real clinical patient cases -- using the IPOPT\noptimization solver in a leader/follower type approach for parallelization. We\nshow that our approach can utilize multiple computational nodes efficiently,\nwith a speedup of approximately 2-3.5 times compared to the serial version.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.11395v1"
    },
    {
        "title": "JAX-FEM: A differentiable GPU-accelerated 3D finite element solver for\n  automatic inverse design and mechanistic data science",
        "authors": [
            "Tianju Xue",
            "Shuheng Liao",
            "Zhengtao Gan",
            "Chanwook Park",
            "Xiaoyu Xie",
            "Wing Kam Liu",
            "Jian Cao"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  This paper introduces JAX-FEM, an open-source differentiable finite element\nmethod (FEM) library. Constructed on top of Google JAX, a rising machine\nlearning library focusing on high-performance numerical computing, JAX-FEM is\nimplemented with pure Python while scalable to efficiently solve problems with\nmoderate to large sizes. For example, in a 3D tensile loading problem with 7.7\nmillion degrees of freedom, JAX-FEM with GPU achieves around 10$\\times$\nacceleration compared to a commercial FEM code depending on platform. Beyond\nefficiently solving forward problems, JAX-FEM employs the automatic\ndifferentiation technique so that inverse problems are solved in a fully\nautomatic manner without the need to manually derive sensitivities. Examples of\n3D topology optimization of nonlinear materials are shown to achieve optimal\ncompliance. Finally, JAX-FEM is an integrated platform for machine\nlearning-aided computational mechanics. We show an example of data-driven\nmulti-scale computations of a composite material where JAX-FEM provides an\nall-in-one solution from microscopic data generation and model training to\nmacroscopic FE computations. The source code of the library and these examples\nare shared with the community to facilitate computational mechanics research.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.00964v1"
    },
    {
        "title": "General framework for re-assuring numerical reliability in parallel\n  Krylov solvers: A case of BiCGStab methods",
        "authors": [
            "Roman Iakymchuk",
            "Jose I. Aliaga"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Parallel implementations of Krylov subspace methods often help to accelerate\nthe procedure of finding an approximate solution of a linear system. However,\nsuch parallelization coupled with asynchronous and out-of-order execution often\nenlarge the non-associativity impact in floating-point operations. These\nproblems are even amplified when communication-hiding pipelined algorithms are\nused to improve the parallelization of Krylov subspace methods. Introducing\nreproducibility in the implementations avoids these problems by getting more\nrobust and correct solutions. This paper proposes a general framework for\nderiving reproducible and accurate variants of Krylov subspace methods. The\nproposed algorithmic strategies are reinforced by programmability suggestions\nto assure deterministic and accurate executions. The framework is illustrated\non the preconditioned BiCGStab method and its pipelined modification, which in\nfact is a distinctive method from the Krylov subspace family, for the solution\nof non-symmetric linear systems with message-passing. Finally, we verify the\nnumerical behaviour of the two reproducible variants of BiCGStab on a set of\nmatrices from the SuiteSparse Matrix Collection and a 3D Poisson's equation.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.04180v1"
    },
    {
        "title": "TAPPS Release 1: Plugin-Extensible Platform for Technical Analysis and\n  Applied Statistics",
        "authors": [
            "Justin Sam Chew",
            "Maurice HT Ling"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present the first release of TAPPS (Technical Analysis and Applied\nStatistics System); a Python implementation of a thin software platform aimed\ntowards technical analyses and applied statistics. The core of TAPPS is a\ncontainer for 2-dimensional data frame objects and a TAPPS command language.\nTAPPS language is not meant to be a programming language for script and plugin\ndevelopment but for the operational purposes. In this aspect, TAPPS language\ntakes on the flavor of SQL rather than R, resulting in a shallower learning\ncurve. All analytical functions are implemented as plugins. This results in a\ndefined plugin system, which enables rapid development and incorporation of\nanalysis functions. TAPPS Release 1 is released under GNU General Public\nLicense 3 for academic and non-commercial use. TAPPS code repository can be\nfound at http://github.com/mauriceling/tapps.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.12056v1"
    },
    {
        "title": "The Awkward World of Python and C++",
        "authors": [
            "Manasvi Goyal",
            "Ianna Osborne",
            "Jim Pivarski"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  There are undeniable benefits of binding Python and C++ to take advantage of\nthe best features of both languages. This is especially relevant to the HEP and\nother scientific communities that have invested heavily in the C++ frameworks\nand are rapidly moving their data analyses to Python. Version 2 of Awkward\nArray, a Scikit-HEP Python library, introduces a set of header-only C++\nlibraries that do not depend on any application binary interface. Users can\ndirectly include these libraries in their compilation instead of linking\nagainst platform-specific libraries. This new development makes the integration\nof Awkward Arrays into other projects easier and more portable, as the\nimplementation is easily separable from the rest of the Awkward Array codebase.\nThe code is minimal; it does not include all of the code needed to use Awkward\nArrays in Python, nor does it include references to Python or pybind11. The C++\nusers can use it to make arrays and then copy them to Python without any\nspecialized data types - only raw buffers, strings, and integers. This C++ code\nalso simplifies the process of just-in-time (JIT) compilation in ROOT. This\nimplementation approach solves some of the drawbacks, like packaging projects\nwhere native dependencies can be challenging. In this paper, we demonstrate the\ntechnique to integrate C++ and Python using a header-only approach. We also\ndescribe the implementation of a new LayoutBuilder and a GrowableBuffer.\nFurthermore, examples of wrapping the C++ data into Awkward Arrays and exposing\nAwkward Arrays to C++ without copying them are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.02205v2"
    },
    {
        "title": "SMaLL: A Software Framework for portable Machine Learning Libraries",
        "authors": [
            "Upasana Sridhar",
            "Nicholai Tukanov",
            "Elliott Binder",
            "Tze Meng Low",
            "Scott McMillan",
            "Martin D. Schatz"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Interest in deploying Deep Neural Network (DNN) inference on edge devices has\nresulted in an explosion of the number and types of hardware platforms to use.\nWhile the high-level programming interface, such as TensorFlow, can be readily\nported across different devices, high-performance inference implementations\nrely on a good mapping of the high-level interface to the target hardware\nplatform. Commonly, this mapping may use optimizing compilers to generate code\nat compile time or high-performance vendor libraries that have been specialized\nto the target platform. Both approaches rely on expert knowledge to produce the\nmapping, which may be time-consuming and difficult to extend to new\narchitectures.\n  In this work, we present a DNN library framework, SMaLL, that is easily\nextensible to new architectures. The framework uses a unified loop structure\nand shared, cache-friendly data format across all intermediate layers,\neliminating the time and memory overheads incurred by data transformation\nbetween layers. Layers are implemented by simply specifying the layer's\ndimensions and a kernel -- the key computing operations of each layer. The\nunified loop structure and kernel abstraction allows us to reuse code across\nlayers and computing platforms. New architectures only require the 100s of\nlines in the kernel to be redesigned. To show the benefits of our approach, we\nhave developed software that supports a range of layer types and computing\nplatforms, which is easily extensible for rapidly instantiating high\nperformance DNN libraries.\n  We evaluate our software by instantiating networks from the TinyMLPerf\nbenchmark suite on 5 ARM platforms and 1 x86 platform ( an AMD Zen 2). Our\nframework shows end-to-end performance that is comparable to or better than ML\nFrameworks such as TensorFlow, TVM and LibTorch.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.04769v1"
    },
    {
        "title": "TOPress: a MATLAB implementation for topology optimization of structures\n  subjected to design-dependent pressure loads",
        "authors": [
            "Prabhat Kumar"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  In a topology optimization setting, design-dependent fluidic pressure loads\npose several challenges as their direction, magnitude, and location alter with\ntopology evolution. This paper offers a compact 100-line MATLAB code, TOPress,\nfor topology optimization of structures subjected to fluidic pressure loads\nusing the method of moving asymptotes. The code is intended for pedagogical\npurposes and aims to ease the beginners' and students' learning toward topology\noptimization with design-dependent fluidic pressure loads. TOPress is developed\nper the approach first reported in Kumar et al. (Struct Multidisc Optim\n61(4):1637-1655, 2020). The Darcy law, in conjunction with the drainage term,\nis used to model the applied pressure load. The consistent nodal loads are\ndetermined from the obtained pressure field. The employed approach facilitates\ninexpensive computation of the load sensitivities using the adjoint-variable\nmethod. Compliance minimization subject to volume constraint optimization\nproblems are solved. The success and efficacy of the code are demonstrated by\nsolving benchmark numerical examples involving pressure loads, wherein the\nimportance of load sensitivities is also demonstrated. TOPress contains six\nmain parts, is described in detail, and is extended to solve different\nproblems. Steps to include a projection filter are provided to achieve\nloadbearing designs close to~0-1. The code is provided in Appendix~B and can\nalso be downloaded along with its extensions from\n\\url{https://github.com/PrabhatIn/TOPress}.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.14690v4"
    },
    {
        "title": "Automatic Differentiation of Binned Likelihoods With Roofit and Clad",
        "authors": [
            "Garima Singh",
            "Jonas Rembser",
            "Lorenzo Moneta",
            "David Lange",
            "Vassil Vassilev"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  RooFit is a toolkit for statistical modeling and fitting used by most\nexperiments in particle physics. Just as data sets from next-generation\nexperiments grow, processing requirements for physics analysis become more\ncomputationally demanding, necessitating performance optimizations for RooFit.\nOne possibility to speed-up minimization and add stability is the use of\nAutomatic Differentiation (AD). Unlike for numerical differentiation, the\ncomputation cost scales linearly with the number of parameters, making AD\nparticularly appealing for statistical models with many parameters. In this\npaper, we report on one possible way to implement AD in RooFit. Our approach is\nto add a facility to generate C++ code for a full RooFit model automatically.\nUnlike the original RooFit model, this generated code is free of virtual\nfunction calls and other RooFit-specific overhead. In particular, this code is\nthen used to produce the gradient automatically with Clad. Clad is a source\ntransformation AD tool implemented as a plugin to the clang compiler, which\nautomatically generates the derivative code for input C++ functions. We show\nresults demonstrating the improvements observed when applying this code\ngeneration strategy to HistFactory and other commonly used RooFit models.\nHistFactory is the subcomponent of RooFit that implements binned likelihood\nmodels with probability densities based on histogram templates. These models\nfrequently have a very large number of free parameters and are thus an\ninteresting first target for AD support in RooFit.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02650v1"
    },
    {
        "title": "R-Shiny Applications for Local Clustering to be Included in the\n  growclusters for R Package",
        "authors": [
            "Randall Powers",
            "Wendy Martinez",
            "Terrance Savitsky"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  growclusters for R is a package that estimates a partition structure for\nmultivariate data. It does this by implementing a hierarchical version of\nk-means clustering that accounts for possible known dependencies in a\ncollection of datasets, where each set draws its cluster means from a single,\nglobal partition. Each component data set in the collection corresponds to a\nknown group in the data. This paper focuses on R Shiny applications that\nimplement the clustering methodology and simulate data sets with known group\nstructures. These Shiny applications implement novel ways of visualizing the\nresults of the clustering. These visualizations include scatterplots of\nindividual data sets in the context of the entire collection and cluster\ndistributions versus component (or sub-domain) datasets. Data obtained from a\ncollection of 2000-2013 articles from the Bureau of Labor Statistics (BLS)\nMonthly Labor Review (MLR) will be used to illustrate the R-Shiny applications.\nHere, the known grouping in the collection is the year of publication.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.06145v2"
    },
    {
        "title": "An open-source pipeline for solving continuous reaction-diffusion models\n  in image-based geometries of porous media",
        "authors": [
            "Justina Stark",
            "Ivo F. Sbalzarini"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present a versatile open-source pipeline for simulating inhomogeneous\nreaction-diffusion processes in highly resolved, image-based geometries of\nporous media with reactive boundaries. Resolving realistic pore-scale\ngeometries in numerical models is challenging and computationally demanding, as\nthe scale differences between the sizes of the interstitia and the whole system\ncan lead to prohibitive memory requirements. The present pipeline combines a\nlevel-set method with geometry-adapted sparse block grids on GPUs to\nefficiently simulate reaction-diffusion processes in image-based geometries. We\nshowcase the method by applying it to fertilizer diffusion in soil, heat\ntransfer in porous ceramics, and determining effective diffusion coefficients\nand tortuosity. The present approach enables solving reaction-diffusion partial\ndifferential equations in real-world geometries applicable to porous media\nacross fields such as engineering, environmental science, and biology.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.11165v2"
    },
    {
        "title": "Collective-Optimized FFTs",
        "authors": [
            "Evelyn Namugwanya",
            "Amanda Bienz",
            "Derek Schafer",
            "Anthony Skjellum"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  This paper measures the impact of the various alltoallv methods. Results are\nanalyzed within Beatnik, a Z-model solver that is bottlenecked by HeFFTe and\nrepresentative of applications that rely on FFTs.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.16589v2"
    },
    {
        "title": "SYCL compute kernels for ExaHyPE",
        "authors": [
            "Chung Ming Loi",
            "Heinrich Bockhorst",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We discuss three SYCL realisations of a simple Finite Volume scheme over\nmultiple Cartesian patches. The realisation flavours differ in the way how they\nmap the compute steps onto loops and tasks: We compare an implementation that\nis exclusively using a sequence of for-loops to a version that uses nested\nparallelism, and finally benchmark these against a version modelling the\ncalculations as task graph. Our work proposes realisation idioms to realise\nthese flavours within SYCL. The results suggest that a mixture of classic task\nand data parallelism performs if we map this hybrid onto a solely data-parallel\nSYCL implementation, taking into account SYCL specifics and the problem size.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.16731v5"
    },
    {
        "title": "Automatic Conversion of MiniZinc Programs to QUBO",
        "authors": [
            "Armin Wolf",
            "Cristian Grozea"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Obtaining Quadratic Unconstrained Binary Optimisation models for various\noptimisation problems, in order to solve those on physical quantum computers\n(such as the the DWave annealers) is nowadays a lengthy and tedious process\nthat requires one to remodel all problem variables as binary variables and\nsqueeze the target function and the constraints into a single quadratic\npolynomial into these new variables.\n  We report here on the basis of our automatic converter from MiniZinc to QUBO,\nwhich is able to process a large set of constraint optimisation and constraint\nsatisfaction problems and turn them into equivalent QUBOs, effectively\noptimising the whole process.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.10032v1"
    },
    {
        "title": "PyPartMC: A Pythonic interface to a particle-resolved, Monte Carlo\n  aerosol simulation framework",
        "authors": [
            "Zachary D'Aquino",
            "Sylwester Arabas",
            "Jeffrey Curtis",
            "Akshunna Vaishnav",
            "Nicole Riemer",
            "Matthew West"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  PyPartMC is a Pythonic interface to PartMC, a stochastic, particle-resolved\naerosol model implemented in Fortran. Both PyPartMC and PartMC are free, libre,\nand open-source. PyPartMC reduces the number of steps and mitigates the effort\nnecessary to install and utilize the resources of PartMC. Without PyPartMC,\nsetting up PartMC requires: working with UNIX shell, providing Fortran and C\nlibraries, and performing standard Fortran and C source code configuration,\ncompilation and linking. This can be challenging for those less experienced\nwith computational research or those intending to use PartMC in environments\nwhere provision of UNIX tools is less straightforward (e.g., on Windows).\nPyPartMC offers a single-step installation/upgrade process of PartMC and all\ndependencies through the pip Python package manager on Linux, macOS, and\nWindows. This allows streamlined access to the unmodified and versioned Fortran\ninternals of the PartMC codebase from both Python and other interoperable\nenvironments (e.g., Julia through PyCall). Consequently, users of PyPartMC can\nsetup, run, process and visualize output of PartMC simulations using a single\ngeneral-purpose programming language.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.02052v3"
    },
    {
        "title": "A Distributed Algebra System for Time Integration on Parallel Computers",
        "authors": [
            "Abhinav Singh",
            "Landfried Kraatz",
            "Pietro Incardona",
            "Ivo F. Sbalzarini"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present a distributed algebra system for efficient and compact\nimplementation of numerical time integration schemes on parallel computers and\ngraphics processing units (GPU). The software implementation combines the time\nintegration library Odeint from Boost with the OpenFPM framework for scalable\nscientific computing. Implementing multi-stage, multi-step, or adaptive time\nintegration methods in distributed-memory parallel codes or on GPUs is\nchallenging. The present algebra system addresses this by making the time\nintegration methods from Odeint available in a concise template-expression\nlanguage for numerical simulations distributed and parallelized using OpenFPM.\nThis allows using state-of-the-art time integration schemes, or switching\nbetween schemes, by changing one line of code, while maintaining parallel\nscalability. This enables scalable time integration with compact code and\nfacilitates rapid rewriting and deployment of simulation algorithms. We\nbenchmark the present software for exponential and sigmoidal dynamics and\npresent an application example to the 3D Gray-Scott reaction-diffusion problem\non both CPUs and GPUs in only 60 lines of code.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.05331v1"
    },
    {
        "title": "p-adaptive discontinuous Galerkin method for the shallow water equations\n  on heterogeneous computing architectures",
        "authors": [
            "Sara Faghih-Naini",
            "Vadym Aizinger",
            "Sebastian Kuckuk",
            "Richard Angersbach",
            "Harald Köstler"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Heterogeneous computing and exploiting integrated CPU-GPU architectures has\nbecome a clear current trend since the flattening of Moore's Law. In this work,\nwe propose a numerical and algorithmic re-design of a p-adaptive\nquadrature-free discontinuous Galerkin method (DG) for the shallow water\nequations (SWE). Our new approach separates the computations of the\nnon-adaptive (lower-order) and adaptive (higher-order) parts of the\ndiscretization form each other. Thereby, we can overlap computations of the\nlower-order and the higher-order DG solution components. Furthermore, we\ninvestigate execution times of main computational kernels and use automatic\ncode generation to optimize their distribution between the CPU and GPU. Several\nsetups, including a prototype of a tsunami simulation in a tide-driven flow\nscenario, are investigated, and the results show that significant performance\nimprovements can be achieved in suitable setups.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.11348v1"
    },
    {
        "title": "Impact of parallel code optimization on computer power consumption",
        "authors": [
            "E. A. Kiselev",
            "P. N. Telegin",
            "A. V. Baranov"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The increase in performance and power of computing systems requires the wider\nuse of program optimizations. The goal of performing optimizations is not only\nto reduce program runtime, but also to reduce other computer resources\nincluding power consumption. The goal of the study was to evaluate the impact\nof different optimization levels and various optimization strategies on power\nconsumption. In a series of experiments, it was established that the average\npower consumption tends to peak for the programs with optimized source code.\nThe articles also describes the impact of changing computer architecture on\npower consumption graphs. The relationships between the average and median\nvalues of power consumption by example programs are considered. The possibility\nof creating program energy consumption profile for a parallel program is shown.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.03315v1"
    },
    {
        "title": "Strassen's Matrix Multiplication Algorithm Is Still Faster",
        "authors": [
            "Paolo D'Alberto"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Recently, reinforcement algorithms discovered new algorithms that really\njump-started a wave of excitements and a flourishing of publications. However,\nthere is little on implementations, applications, and, especially, no absolute\nperformance and, we show here they are not here to replace Strassen's original\nfast matrix multiplication yet. We present Matrix Flow, this is a simple Python\nproject for the automatic formulation, design, implementation, code generation,\nand execution of fast matrix multiplication algorithms for CPUs, using BLAS\ninterface GPUs, and in the future other accelerators. We shall not play with\nmodule-2 (Z2) algorithms and, for simplicity, we present only square\ndouble-precision matrices. By means of factorizing the operand matrices we can\nexpress many algorithms and prove them correct. These algorithms are\nrepresented by Data Flows and matrix data partitions: a Directed Acyclic Graph.\nWe show that Strassen's original algorithm is still the top choice even for\nmodern GPUs. We also address error analysis in double precision, because\ninteger computations are correct, always\n",
        "pdf_link": "http://arxiv.org/pdf/2312.12732v1"
    },
    {
        "title": "MindOpt Adapter for CPLEX Benchmarking Performance Analysis",
        "authors": [
            "Mou Sun",
            "Tao Li",
            "Wotao Yin"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  This report provides a comprehensive analysis of the performance of MindOpt\nAdapter for CPLEX 12.9 in benchmark testing. CPLEX, recognized as a robust\nMixed Integer Programming (MIP) solver, has faced some scrutiny regarding its\nperformance on MIPLIB 2017 when configured to default settings. MindOpt Adapter\naims to enhance CPLEX's performance by automatically applying improved\nconfigurations for solving optimization problems. Our testing demonstrates that\nMindOpt Adapter for CPLEX yields successfully solved 232 of the 240 problems in\nthe MIPLIB 2017 benchmark set. This performance surpasses all the other solvers\nin terms of the number of problems solved and the geometric mean of running\ntimes. The report provides a comparison of the benchmark results against the\noutcomes achieved by CPLEX under its default configuration.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.13527v4"
    },
    {
        "title": "The Cytnx Library for Tensor Networks",
        "authors": [
            "Kai-Hsin Wu",
            "Chang-Teng Lin",
            "Ke Hsu",
            "Hao-Ti Hung",
            "Manuel Schneider",
            "Chia-Min Chung",
            "Ying-Jer Kao",
            "Pochung Chen"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  We introduce a tensor network library designed for classical and quantum\nphysics simulations called Cytnx (pronounced as sci-tens). This library\nprovides almost an identical interface and syntax for both C++ and Python,\nallowing users to effortlessly switch between two languages. Aiming at a quick\nlearning process for new users of tensor network algorithms, the interfaces\nresemble the popular Python scientific libraries like NumPy, Scipy, and\nPyTorch. Not only multiple global Abelian symmetries can be easily defined and\nimplemented, Cytnx also provides a new tool called Network that allows users to\nstore large tensor networks and perform tensor network contractions in an\noptimal order automatically. With the integration of cuQuantum, tensor\ncalculations can also be executed efficiently on GPUs. We present benchmark\nresults for tensor operations on both devices, CPU and GPU. We also discuss\nfeatures and higher-level interfaces to be added in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.01921v1"
    },
    {
        "title": "PlasmoData.jl -- A Julia Framework for Modeling and Analyzing Complex\n  Data as Graphs",
        "authors": [
            "David L Cole",
            "Victor M Zavala"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Datasets encountered in scientific and engineering applications appear in\ncomplex formats (e.g., images, multivariate time series, molecules, video, text\nstrings, networks). Graph theory provides a unifying framework to model such\ndatasets and enables the use of powerful tools that can help analyze,\nvisualize, and extract value from data. In this work, we present\nPlasmoData$.$jl, an open-source, Julia framework that uses concepts of graph\ntheory to facilitate the modeling and analysis of complex datasets. The core of\nour framework is a general data modeling abstraction, which we call a\nDataGraph. We show how the abstraction and software implementation can be used\nto represent diverse data objects as graphs and to enable the use of tools from\ntopology, graph theory, and machine learning (e.g., graph neural networks) to\nconduct a variety of tasks. We illustrate the versatility of the framework by\nusing real datasets: i) an image classification problem using topological data\nanalysis to extract features from the graph model to train machine learning\nmodels; ii) a disease outbreak problem where we model multivariate time series\nas graphs to detect abnormal events; and iii) a technology pathway analysis\nproblem where we highlight how we can use graphs to navigate connectivity. Our\ndiscussion also highlights how PlasmoData$.$jl leverages native Julia\ncapabilities to enable compact syntax, scalable computations, and interfaces\nwith diverse packages.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11404v2"
    },
    {
        "title": "LongMemory.jl: Generating, Estimating, and Forecasting Long Memory\n  Models in Julia",
        "authors": [
            "J. Eduardo Vera-Valdés"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  LongMemory.jl is a package for time series long memory modelling in Julia.\nThe package provides functions to generate long memory, estimate model\nparameters, and forecast. Generating methods include fractional differencing,\nstochastic error duration, and cross-sectional aggregation. Estimators include\nthe classic ones used to estimate the Hurst effect, those inspired by\nlog-periodogram regression, and parametric ones. Forecasting is provided for\nall parametric estimators. Moreover, the package adds plotting capabilities to\nillustrate long memory dynamics and forecasting. This article presents the\ntheoretical developments for long memory modelling, show examples using the\ndata included with the package, and compares the properties of LongMemory.jl\nwith current alternatives, including benchmarks. For some of the theoretical\ndevelopments, LongMemory.jl provides the first publicly available\nimplementation in any programming language. A notable feature of this package\nis that all functions are implemented in the same programming language, taking\nadvantage of the ease of use and speed provided by Julia. Therefore, all code\nis accessible to the user. Multiple dispatch, a novel feature of the language,\nis used to speed computations and provide consistent calls to related methods.\nThe package is related to the R packages LongMemoryTS and fracdiff.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.14077v1"
    },
    {
        "title": "Reproducibility, energy efficiency and performance of pseudorandom\n  number generators in machine learning: a comparative study of python, numpy,\n  tensorflow, and pytorch implementations",
        "authors": [
            "Benjamin Antunes",
            "David R. C Hill"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Pseudo-Random Number Generators (PRNGs) have become ubiquitous in machine\nlearning technologies because they are interesting for numerous methods. The\nfield of machine learning holds the potential for substantial advancements\nacross various domains, as exemplified by recent breakthroughs in Large\nLanguage Models (LLMs). However, despite the growing interest, persistent\nconcerns include issues related to reproducibility and energy consumption.\nReproducibility is crucial for robust scientific inquiry and explainability,\nwhile energy efficiency underscores the imperative to conserve finite global\nresources. This study delves into the investigation of whether the leading\nPseudo-Random Number Generators (PRNGs) employed in machine learning languages,\nlibraries, and frameworks uphold statistical quality and numerical\nreproducibility when compared to the original C implementation of the\nrespective PRNG algorithms. Additionally, we aim to evaluate the time\nefficiency and energy consumption of various implementations. Our experiments\nencompass Python, NumPy, TensorFlow, and PyTorch, utilizing the Mersenne\nTwister, PCG, and Philox algorithms. Remarkably, we verified that the temporal\nperformance of machine learning technologies closely aligns with that of\nC-based implementations, with instances of achieving even superior\nperformances. On the other hand, it is noteworthy that ML technologies consumed\nonly 10% more energy than their C-implementation counterparts. However, while\nstatistical quality was found to be comparable, achieving numerical\nreproducibility across different platforms for identical seeds and algorithms\nwas not achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.17345v2"
    },
    {
        "title": "Democratizing Uncertainty Quantification",
        "authors": [
            "Linus Seelinger",
            "Anne Reinarz",
            "Mikkel B. Lykkegaard",
            "Robert Akers",
            "Amal M. A. Alghamdi",
            "David Aristoff",
            "Wolfgang Bangerth",
            "Jean Bénézech",
            "Matteo Diez",
            "Kurt Frey",
            "John D. Jakeman",
            "Jakob S. Jørgensen",
            "Ki-Tae Kim",
            "Benjamin M. Kent",
            "Massimiliano Martinelli",
            "Matthew Parno",
            "Riccardo Pellegrini",
            "Noemi Petra",
            "Nicolai A. B. Riis",
            "Katherine Rosenfeld",
            "Andrea Serani",
            "Lorenzo Tamellini",
            "Umberto Villa",
            "Tim J. Dodwell",
            "Robert Scheichl"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Uncertainty Quantification (UQ) is vital to safety-critical model-based\nanalyses, but the widespread adoption of sophisticated UQ methods is limited by\ntechnical complexity. In this paper, we introduce UM-Bridge (the UQ and\nModeling Bridge), a high-level abstraction and software protocol that\nfacilitates universal interoperability of UQ software with simulation codes. It\nbreaks down the technical complexity of advanced UQ applications and enables\nseparation of concerns between experts. UM-Bridge democratizes UQ by allowing\neffective interdisciplinary collaboration, accelerating the development of\nadvanced UQ methods, and making it easy to perform UQ analyses from prototype\nto High Performance Computing (HPC) scale.\n  In addition, we present a library of ready-to-run UQ benchmark problems, all\neasily accessible through UM-Bridge. These benchmarks support UQ methodology\nresearch, enabling reproducible performance comparisons. We demonstrate\nUM-Bridge with several scientific applications, harnessing HPC resources even\nusing UQ codes not designed with HPC support.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.13768v5"
    },
    {
        "title": "Inexactness and Correction of Floating-Point Reciprocal, Division and\n  Square Root",
        "authors": [
            "Lucas M. Dutton",
            "Christopher Kumar Anand",
            "Robert Enenkel",
            "Silvia Melitta Müller"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Floating-point arithmetic performance determines the overall performance of\nimportant applications, from graphics to AI. Meeting the IEEE-754 specification\nfor floating-point requires that final results of addition, subtraction,\nmultiplication, division, and square root are correctly rounded based on the\nuser-selected rounding mode. A frustrating fact for implementers is that naive\nrounding methods will not produce correctly rounded results even when\nintermediate results with greater accuracy and precision are available. In\ncontrast, our novel algorithm can correct approximations of reciprocal,\ndivision and square root, even ones with slightly lower than target precision.\nIn this paper, we present a family of algorithms that can both increase the\naccuracy (and potentially the precision) of an estimate and correctly round it\naccording to all binary IEEE-754 rounding modes. We explain how it may be\nefficiently implemented in hardware, and for completeness, we present proofs\nthat it is not necessary to include equality tests associated with\nround-to-nearest-even mode for reciprocal, division and square root functions,\nbecause it is impossible for input(s) in a given precision to have exact\nanswers exactly midway between representable floating-point numbers in that\nprecision. In fact, our simpler proofs are sometimes stronger.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.00387v1"
    },
    {
        "title": "SARIS: Accelerating Stencil Computations on Energy-Efficient RISC-V\n  Compute Clusters with Indirect Stream Registers",
        "authors": [
            "Paul Scheffler",
            "Luca Colagrande",
            "Luca Benini"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Stencil codes are performance-critical in many compute-intensive\napplications, but suffer from significant address calculation and irregular\nmemory access overheads. This work presents SARIS, a general and highly\nflexible methodology for stencil acceleration using register-mapped indirect\nstreams. We demonstrate SARIS for various stencil codes on an eight-core RISC-V\ncompute cluster with indirect stream registers, achieving significant speedups\nof 2.72x, near-ideal FPU utilizations of 81%, and energy efficiency\nimprovements of 1.58x over an RV32G baseline on average. Scaling out to a\n256-core manycore system, we estimate an average FPU utilization of 64%, an\naverage speedup of 2.14x, and up to 15% higher fractions of peak compute than a\nleading GPU code generator.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.05303v1"
    },
    {
        "title": "GALÆXI: Solving complex compressible flows with high-order\n  discontinuous Galerkin methods on accelerator-based systems",
        "authors": [
            "Daniel Kempf",
            "Marius Kurz",
            "Marcel Blind",
            "Patrick Kopper",
            "Philipp Offenhäuser",
            "Anna Schwarz",
            "Spencer Starr",
            "Jens Keim",
            "Andrea Beck"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This work presents GALAEXI as a novel, energy-efficient flow solver for the\nsimulation of compressible flows on unstructured meshes leveraging the parallel\ncomputing power of modern Graphics Processing Units (GPUs). GALAEXI implements\nthe high-order Discontinuous Galerkin Spectral Element Method (DGSEM) using\nshock capturing with a finite-volume subcell approach to ensure the stability\nof the high-order scheme near shocks. This work provides details on the general\ncode design, the parallelization strategy, and the implementation approach for\nthe compute kernels with a focus on the element local mappings between volume\nand surface data due to the unstructured mesh. GALAEXI exhibits excellent\nstrong scaling properties up to 1024 GPUs if each GPU is assigned a minimum of\none million degrees of freedom degrees of freedom. To verify its\nimplementation, a convergence study is performed that recovers the theoretical\norder of convergence of the implemented numerical schemes. Moreover, the solver\nis validated using both the incompressible and compressible formulation of the\nTaylor-Green-Vortex at a Mach number of 0.1 and 1.25, respectively. A mesh\nconvergence study shows that the results converge to the high-fidelity\nreference solution and that the results match the original CPU implementation.\nFinally, GALAEXI is applied to a large-scale wall-resolved large eddy\nsimulation of a linear cascade of the NASA Rotor 37. Here, the supersonic\nregion and shocks at the leading edge are captured accurately and robustly by\nthe implemented shock-capturing approach. It is demonstrated that GALAEXI\nrequires less than half of the energy to carry out this simulation in\ncomparison to the reference CPU implementation. This renders GALAEXI as a\npotent tool for accurate and efficient simulations of compressible flows in the\nrealm of exascale computing and the associated new HPC architectures.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.12703v2"
    },
    {
        "title": "Robustness and Accuracy in Pipelined Bi-Conjugate Gradient Stabilized\n  Method: A Comparative Study",
        "authors": [
            "Mykhailo Havdiak",
            "Jose I. Aliaga",
            "Roman Iakymchuk"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In this article, we propose an accuracy-assuring technique for finding a\nsolution for unsymmetric linear systems. Such problems are related to different\nareas such as image processing, computer vision, and computational fluid\ndynamics. Parallel implementation of Krylov subspace methods speeds up finding\napproximate solutions for linear systems. In this context, the refined approach\nin pipelined BiCGStab enhances scalability on distributed memory machines,\nyielding to substantial speed improvements compared to the standard BiCGStab\nmethod. However, it's worth noting that the pipelined BiCGStab algorithm\nsacrifices some accuracy, which is stabilized with the residual replacement\ntechnique. This paper aims to address this issue by employing the ExBLAS-based\nreproducible approach. We validate the idea on a set of matrices from the\nSuiteSparse Matrix Collection.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.13216v1"
    },
    {
        "title": "A Sparse Tensor Generator with Efficient Feature Extraction",
        "authors": [
            "Tugba Torun",
            "Eren Yenigul",
            "Ameer Taweel",
            "Didem Unat"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Sparse tensor operations are gaining attention in emerging applications such\nas social networks, deep learning, diagnosis, crime, and review analysis.\nHowever, a major obstacle for research in sparse tensor operations is the\ndeficiency of a broad-scale sparse tensor dataset. Another challenge in sparse\ntensor operations is examining the sparse tensor features, which are not only\nimportant for revealing its nonzero pattern but also have a significant impact\non determining the best-suited storage format, the decomposition algorithm, and\nthe reordering methods. However, due to the large sizes of real tensors, even\nextracting these features becomes costly without caution. To address these gaps\nin the literature, we have developed a smart sparse tensor generator that\nmimics the substantial features of real sparse tensors. Moreover, we propose\nvarious methods for efficiently extracting an extensive set of features for\nsparse tensors. The effectiveness of our generator is validated through the\nquality of features and the performance of decomposition in the generated\ntensors. Both the sparse tensor feature extractor and the tensor generator are\nopen source with all the artifacts available at\nhttps://github.com/sparcityeu/feaTen and https://github.com/sparcityeu/genTen,\nrespectively.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.04944v1"
    },
    {
        "title": "PETSc/TAO Developments for GPU-Based Early Exascale Systems",
        "authors": [
            "Richard Tran Mills",
            "Mark Adams",
            "Satish Balay",
            "Jed Brown",
            "Jacob Faibussowitsch",
            "Toby Isaac",
            "Matthew Knepley",
            "Todd Munson",
            "Hansol Suh",
            "Stefano Zampini",
            "Hong Zhang",
            "Junchao Zhang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The Portable Extensible Toolkit for Scientific Computation (PETSc) library\nprovides scalable solvers for nonlinear time-dependent differential and\nalgebraic equations and for numerical optimization via the Toolkit for Advanced\nOptimization (TAO). PETSc is used in dozens of scientific fields and is an\nimportant building block for many simulation codes. During the U.S. Department\nof Energy's Exascale Computing Project, the PETSc team has made substantial\nefforts to enable efficient utilization of the massive fine-grain parallelism\npresent within exascale compute nodes and to enable performance portability\nacross exascale architectures. We recap some of the challenges that designers\nof numerical libraries face in such an endeavor, and then discuss the many\ndevelopments we have made, which include the addition of new GPU backends,\nfeatures supporting efficient on-device matrix assembly, better support for\nasynchronicity and GPU kernel concurrency, and new communication\ninfrastructure. We evaluate the performance of these developments on some\npre-exascale systems as well the early exascale systems Frontier and Aurora,\nusing compute kernel, communication layer, solver, and mini-application\nbenchmark studies, and then close with a few observations drawn from our\nexperiences on the tension between portable performance and other goals of\nnumerical libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.08646v2"
    },
    {
        "title": "Enhancing non-Perl bioinformatic applications with Perl: Building novel,\n  component based applications using Object Orientation, PDL, Alien, FFI,\n  Inline and OpenMP",
        "authors": [
            "Christos Argyropoulos"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Component-Based Software Engineering (CBSE) is a methodology that assembles\npre-existing, re-usable software components into new applications, which is\nparticularly relevant for fast moving, data-intensive fields such as\nbioinformatics. While Perl was used extensively in this field until a decade\nago, more recent applications opt for a Bioconductor/R or Python. This trend\nrepresents a significantly missed opportunity for the rapid generation of novel\nbioinformatic applications out of pre-existing components since Perl offers a\nvariety of abstractions that can facilitate composition. In this paper, we\nillustrate the utility of Perl for CBSE through a combination of Object\nOriented frameworks, the Perl Data Language and facilities for interfacing with\nnon-Perl code through Foreign Function Interfaces and inlining of foreign\nsource code. To do so, we enhance Polyester, a RNA sequencing simulator written\nin R, and edlib a fast sequence similarity search library based on the edit\ndistance. The first case study illustrates the near effortless authoring of\nnew, highly performant Perl modules for the simulation of random numbers using\nthe GNU Scientific Library and PDL, and proposes Perl and Perl/C alternatives\nto the Python tool cutadapt that is used to \"trim\" polyA tails from biological\nsequences. For the edlib case, we leverage the power of metaclass programming\nto endow edlib with coarse, process based parallelism, through the Many Core\nEngine (MCE) module and fine grained parallelism through OpenMP, a\nC/C++/Fortran Application Programming Interface for shared memory multithreaded\nprocessing. These use cases provide proof-of-concept for the Bio::SeqAlignment\nframework, which can organize heterogeneous components in complex memory and\ncommand-line based workflows for the construction of novel bionformatic tools\nto analyze data from long-read sequencing, e.g. Nanopore, sequencing platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.10271v1"
    },
    {
        "title": "ASTERIX: Module for modelling the water flow on vegetated hillslopes",
        "authors": [
            "Stelian Ion",
            "Dorin Marinescu",
            "Stefan-Gicu Cruceanu"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The paper presents ASTERIX, an open source software for numerical integration\nof an extended Saint-Venant system of equations used as a mathematical tool to\nmodel the water flow from laboratory up to large-scale spatial domains applying\nphysically-based principles of fluid mechanics. Many in-situ observations have\nshown that the plant cover plays a key roll in controlling the hydrological\nflux at a catchment scale. The plant roots facilitate the infiltration\nprocesses, the canopy intercept some proportion of rain, and plant stems slow\ndown the flow. In case of heavy rains, the infiltration and interception\nprocesses cease in a short time, the remaining rainfall gives rise to the\nHortonian overland flow and the flash flood is thus initiated. In this context,\nthe following problem is also addressed in the article: how do the gradient of\nsoil surface and the density of the plant cover influence the water dynamics in\nthe Hortonian flow? The mathematical model and ASTERIX were kept as simple as\npossible in order to be accessible to a wide range of stakeholders interested\nin understanding the complex processes behind the water flow on hillslopes\ncovered by plants.\n  The software is written in C programming language and it is free under GNU\nlicense. It was tested on a series of benchmark problems, laboratory\nexperiments, and theoretical problems; and the results have shown a good\nagreement with the theoretical or measured data.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.14933v1"
    },
    {
        "title": "HOBOTAN: Efficient Higher Order Binary Optimization Solver with Tensor\n  Networks and PyTorch",
        "authors": [
            "Shoya Yasuda",
            "Shunsuke Sotobayashi",
            "Yuichiro Minato"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In this study, we introduce HOBOTAN, a new solver designed for Higher Order\nBinary Optimization (HOBO). HOBOTAN supports both CPU and GPU, with the GPU\nversion developed based on PyTorch, offering a fast and scalable system. This\nsolver utilizes tensor networks to solve combinatorial optimization problems,\nemploying a HOBO tensor that maps the problem and performs tensor contractions\nas needed. Additionally, by combining techniques such as batch processing for\ntensor optimization and binary-based integer encoding, we significantly enhance\nthe efficiency of combinatorial optimization. In the future, the utilization of\nincreased GPU numbers is expected to harness greater computational power,\nenabling efficient collaboration between multiple GPUs for high scalability.\nMoreover, HOBOTAN is designed within the framework of quantum computing, thus\nproviding insights for future quantum computer applications. This paper details\nthe design, implementation, performance evaluation, and scalability of HOBOTAN,\ndemonstrating its effectiveness.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.19987v1"
    },
    {
        "title": "JAX-SSO: Differentiable Finite Element Analysis Solver for Structural\n  Optimization and Seamless Integration with Neural Networks",
        "authors": [
            "Gaoyuan Wu"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Differentiable numerical simulations of physical systems have gained rising\nattention in the past few years with the development of automatic\ndifferentiation tools. This paper presents JAX-SSO, a differentiable finite\nelement analysis solver built with JAX, Google's high-performance computing\nlibrary, to assist efficient structural design in the built environment. With\nthe adjoint method and automatic differentiation feature, JAX-SSO can\nefficiently evaluate gradients of physical quantities in an automatic way,\nenabling accurate sensitivity calculation in structural optimization problems.\nWritten in Python and JAX, JAX-SSO is naturally within the machine learning\necosystem so it can be seamlessly integrated with neural networks to train\nmachine learning models with inclusion of physics. Moreover, JAX-SSO supports\nGPU acceleration to further boost finite element analysis. Several examples are\npresented to showcase the capabilities and efficiency of JAX-SSO: i) shape\noptimization of grid-shells and continuous shells; ii) size (thickness)\noptimization of continuous shells; iii) simultaneous shape and topology\noptimization of continuous shells; and iv) training of physics-informed neural\nnetworks for structural optimization. We believe that JAX-SSO can facilitate\nresearch related to differentiable physics and machine learning to further\naddress problems in structural and architectural design.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.20026v1"
    },
    {
        "title": "Matrix-Free Finite Volume Kernels on a Dataflow Architecture",
        "authors": [
            "Ryuichi Sai",
            "Francois P. Hamon",
            "John Mellor-Crummey",
            "Mauricio Araya-Polo"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Fast and accurate numerical simulations are crucial for designing large-scale\ngeological carbon storage projects ensuring safe long-term CO2 containment as a\nclimate change mitigation strategy. These simulations involve solving numerous\nlarge and complex linear systems arising from the implicit Finite Volume (FV)\ndiscretization of PDEs governing subsurface fluid flow. Compounded with highly\ndetailed geomodels, solving linear systems is computationally and memory\nexpensive, and accounts for the majority of the simulation time. Modern memory\nhierarchies are insufficient to meet the latency and bandwidth needs of\nlarge-scale numerical simulations. Therefore, exploring algorithms that can\nleverage alternative and balanced paradigms, such as dataflow and in-memory\ncomputing is crucial. This work introduces a matrix-free algorithm to solve\nFV-based linear systems using a dataflow architecture to significantly minimize\nmemory latency and bandwidth bottlenecks. Our implementation achieves two\norders of magnitude speedup compared to a GPGPU-based reference implementation,\nand up to 1.2 PFlops on a single dataflow device.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.03452v1"
    },
    {
        "title": "RAO-SS: A Prototype of Run-time Auto-tuning Facility for Sparse Direct\n  Solvers",
        "authors": [
            "Takahiro Katagiri",
            "Yoshinori Ishii",
            "Hiroki Honda"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In this paper, a run-time auto-tuning method for performance parameters\naccording to input matrices is proposed. RAO-SS (Run-time Auto-tuning Optimizer\nfor Sparse Solvers), which is a prototype of auto-tuning software using the\nproposed method, is also evaluated. The RAO-SS is implemented with the\nAutopilot, which is middle-ware to support run-time auto-tuning with fuzzy\nlogic function. The target numerical library is the SuperLU, which is a sparse\ndirect solver for linear equations. The result indicated that: (1) the speedup\nfactors of 1.2 for average and 3.6 for maximum to default executions were\nobtained; (2) the software overhead of the Autopilot can be ignored in RAO-SS.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.11880v1"
    },
    {
        "title": "TorchDA: A Python package for performing data assimilation with deep\n  learning forward and transformation functions",
        "authors": [
            "Sibo Cheng",
            "Jinyang Min",
            "Che Liu",
            "Rossella Arcucci"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Data assimilation techniques are often confronted with challenges handling\ncomplex high dimensional physical systems, because high precision simulation in\ncomplex high dimensional physical systems is computationally expensive and the\nexact observation functions that can be applied in these systems are difficult\nto obtain. It prompts growing interest in integrating deep learning models\nwithin data assimilation workflows, but current software packages for data\nassimilation cannot handle deep learning models inside. This study presents a\nnovel Python package seamlessly combining data assimilation with deep neural\nnetworks to serve as models for state transition and observation functions. The\npackage, named TorchDA, implements Kalman Filter, Ensemble Kalman Filter\n(EnKF), 3D Variational (3DVar), and 4D Variational (4DVar) algorithms, allowing\nflexible algorithm selection based on application requirements. Comprehensive\nexperiments conducted on the Lorenz 63 and a two-dimensional shallow water\nsystem demonstrate significantly enhanced performance over standalone model\npredictions without assimilation. The shallow water analysis validates data\nassimilation capabilities mapping between different physical quantity spaces in\neither full space or reduced order space. Overall, this innovative software\npackage enables flexible integration of deep learning representations within\ndata assimilation, conferring a versatile tool to tackle complex high\ndimensional dynamical systems across scientific domains.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.00244v1"
    },
    {
        "title": "A method of using RSVD in residual calculation of LowBit GEMM",
        "authors": [
            "Hongyaoxing Gu"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The advancements of hardware technology in recent years has brought many\npossibilities for low-precision applications. However, the use of low precision\ncan introduce significant computational errors, posing a considerable challenge\nto maintaining the computational accuracy.\n  We propose low-rank residuals quantized matrix multiplication(LRQMM) method\nwhich introduces low-rank approximation in residual compensation for dense low\nprecision quantization matrix multiplication. It can bring several times\naccuracy improvement with only BLAS-2 level extra time overhead. Moreover,\nLRQMM is a completely data-free quantization method that does not require\nadditional data for pre-training. And it only works with low precision GEMM\noperator, which is easy to couple with other methods.\n  Through experimentation, LRQMM can reduce the error of direct quantized\nmatrix multiplication by 1~2 orders of magnitude, when dealing with larger\nmatrix sizes, the computational speed is only reduced by approximately 20\\%. In\ndeep learning networks, LRQMM-4bit achieves 61.8% ImageNet Top-1 accuracy in\nResnet-50, while the Direct Quant accuracy is only 8.3%.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.18772v1"
    },
    {
        "title": "Development of a Python-Based Software for Calculating the Jones\n  Polynomial: Insights into the Behavior of Polymers and Biopolymers",
        "authors": [
            "Caleb Musfeldt"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This thesis details a Python-based software designed to calculate the Jones\npolynomial, a vital mathematical tool from Knot Theory used for characterizing\nthe topological and geometrical complexity of curves in \\( \\mathbb{R}^3 \\),\nwhich is essential in understanding physical systems of filaments, including\nthe behavior of polymers and biopolymers. The Jones polynomial serves as a\ntopological invariant capable of distinguishing between different knot\nstructures. This capability is fundamental to characterizing the architecture\nof molecular chains, such as proteins and DNA. Traditional computational\nmethods for deriving the Jones polynomial have been limited by closure-schemes\nand high execution costs, which can be impractical for complex structures like\nthose that appear in real life. This software implements methods that\nsignificantly reduce calculation times, allowing for more efficient and\npractical applications in the study of biological polymers. It utilizes a\ndivide-and-conquer approach combined with parallel computing and applies\nrecursive Reidemeister moves to optimize the computation, transitioning from an\nexponential to a near-linear runtime for specific configurations. This thesis\nprovides an overview of the software's functions, detailed performance\nevaluations using protein structures as test cases, and a discussion of the\nimplications for future research and potential algorithmic improvements.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.22652v1"
    },
    {
        "title": "Jaya R Package -- A Parameter-Free Solution for Advanced Single and\n  Multi-Objective Optimization",
        "authors": [
            "Neeraj Dhanraj Bokde"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The Jaya R package offers a robust and versatile implementation of the\nparameter-free Jaya optimization algorithm, suitable for solving both\nsingle-objective and multi-objective optimization problems. By integrating\nadvanced features such as constraint handling, adaptive population management,\nPareto front tracking for multi-objective trade-offs, and parallel processing\nfor computational efficiency, the package caters to a wide range of\noptimization challenges. Its intuitive design and flexibility allow users to\nsolve complex, real-world problems across various domains. To demonstrate its\npractical utility, a case study on energy modeling explores the optimization of\nrenewable energy shares, showcasing the package's ability to minimize carbon\nemissions and costs while enhancing system reliability. The Jaya R package is\nan invaluable tool for researchers and practitioners seeking efficient and\nadaptive optimization solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.16509v1"
    },
    {
        "title": "AD-HOC: A C++ Expression Template package for high-order derivatives\n  backpropagation",
        "authors": [
            "Juan Lucas Rey"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This document presents a new C++ Automatic Differentiation (AD) tool, AD-HOC\n(Automatic Differentiation for High-Order Calculations). This tool aims to have\nthe following features: -Calculation of user specified derivatives of arbitrary\norder -To be able to run with similar speeds as handwritten code -All\nderivatives calculations are computed in a single backpropagation tree pass -No\nsource code generation is used, relying heavily on the C++ compiler to\nstatically build the computation tree before runtime -A simple interface -The\nability to be used \\textit{in conjunction} with other established,\ngeneral-purpose dynamic AD tools -Header-only library, with no external\ndependencies -Open source, with a business-friendly license\n",
        "pdf_link": "http://arxiv.org/pdf/2412.05300v2"
    },
    {
        "title": "Rapid Experimentation with Python Considering Optional and Hierarchical\n  Inputs",
        "authors": [
            "Neil Ranly",
            "Torrey Wagner"
        ],
        "category": "cs.MS",
        "published_year": "2025",
        "summary": "  Space-filling experimental design techniques are commonly used in many\ncomputer modeling and simulation studies to explore the effects of inputs on\noutputs. This research presents raxpy, a Python package that leverages\nexpressive annotation of Python functions and classes to simplify space-filling\nexperimentation. It incorporates code introspection to derive a Python\nfunction's input space and novel algorithms to automate the design of\nspace-filling experiments for spaces with optional and hierarchical input\ndimensions. In this paper, we review the criteria for design evaluation given\nthese types of dimensions and compare the proposed algorithms with numerical\nexperiments. The results demonstrate the ability of the proposed algorithms to\ncreate improved space-filling experiment designs. The package includes support\nfor parallelism and distributed execution. raxpy is available as free and\nopen-source software under a MIT license.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.03398v1"
    },
    {
        "title": "Algorithm xxx: Modified Bessel functions of imaginary order and positive\n  argument",
        "authors": [
            "Amparo Gil",
            "Javier Segura",
            "Nico M. Temme"
        ],
        "category": "cs.MS",
        "published_year": "2004",
        "summary": "  Fortran 77 programs for the computation of modified Bessel functions of\npurely imaginary order are presented. The codes compute the functions\n$K_{ia}(x)$, $L_{ia}(x)$ and their derivatives for real $a$ and positive $x$;\nthese functions are independent solutions of the differential equation $x^2 w''\n+x w' +(a^2 -x^2)w=0$. The code also computes exponentially scaled functions.\nThe range of computation is $(x,a)\\in (0,1500]\\times [-1500,1500]$ when scaled\nfunctions are considered and it is larger than $(0,500]\\times [-400,400]$ for\nstandard IEEE double precision arithmetic. The relative accuracy is better than\n$10^{-13}$ in the range $(0,200]\\times [-200,200]$ and close to $10^{-12}$ in\n$(0,1500]\\times [-1500,1500]$.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0401008v1"
    },
    {
        "title": "Schwerdtfeger-Fillmore-Springer-Cnops Construction Implemented in GiNaC",
        "authors": [
            "Vladimir V. Kisil"
        ],
        "category": "cs.MS",
        "published_year": "2005",
        "summary": "  This paper presents an implementation of the\nSchwerdtfeger-Fillmore-Springer-Cnops construction (SFSCc) along with\nillustrations of its usage. SFSCc linearises the linear-fraction action of the\nMoebius group in R^n. This has clear advantages in several theoretical and\napplied fields including engineering. Our implementation is based on the\nClifford algebra capacities of the GiNaC computer algebra system\n(http://www.ginac.de/), which were described in cs.MS/0410044.\n  The core of this realisation of SFSCc is done for an arbitrary dimension of\nR^n with a metric given by an arbitrary bilinear form. We also present a\nsubclass for two dimensional cycles (i.e. circles, parabolas and hyperbolas),\nwhich add some 2D specific routines including a visualisation to PostScript\nfiles through the MetaPost (http://www.tug.org/metapost.html) or Asymptote\n(http://asymptote.sourceforge.net/) packages.\n  This software is the backbone of many results published in math.CV/0512416\nand we use its applications their for demonstration. The library can be ported\n(with various level of required changes) to other CAS with Clifford algebras\ncapabilities similar to GiNaC.\n  There is an ISO image of a Live Debian DVD attached to this paper as an\nauxiliary file, a copy is stored on Google Drive as well.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0512073v12"
    },
    {
        "title": "Classifying extrema using intervals",
        "authors": [
            "Marek W. Gutowski"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  We present a straightforward and verified method of deciding whether the\nn-dimensional point x (n>=1), such that \\nabla f(x)=0, is the local minimizer,\nmaximizer or just a saddle point of a real-valued function f.\n  The method scales linearly with dimensionality of the problem and never\nproduces false results.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0609082v1"
    },
    {
        "title": "Classdesc and Graphcode: support for scientific programming in C++",
        "authors": [
            "Russell K. Standish",
            "Duraid Madina"
        ],
        "category": "cs.MS",
        "published_year": "2006",
        "summary": "  Object-oriented programming languages such as Java and Objective C have\nbecome popular for implementing agent-based and other object-based simulations\nsince objects in those languages can {\\em reflect} (i.e. make runtime queries\nof an object's structure). This allows, for example, a fairly trivial {\\em\nserialisation} routine (conversion of an object into a binary representation\nthat can be stored or passed over a network) to be written. However C++ does\nnot offer this ability, as type information is thrown away at compile time. Yet\nC++ is often a preferred development environment, whether for performance\nreasons or for its expressive features such as operator overloading.\n  In scientific coding, changes to a model's codes takes place constantly, as\nthe model is refined, and different phenomena are studied. Yet traditionally,\nfacilities such as checkpointing, routines for initialising model parameters\nand analysis of model output depend on the underlying model remaining static,\notherwise each time a model is modified, a whole slew of supporting routines\nneeds to be changed to reflect the new data structures. Reflection offers the\nadvantage of the simulation framework adapting to the underlying model without\nprogrammer intervention, reducing the effort of modifying the model.\n  In this paper, we present the {\\em Classdesc} system which brings many of the\nbenefits of object reflection to C++, {\\em ClassdescMP} which dramatically\nsimplifies coding of MPI based parallel programs and {\\em\n  Graphcode} a general purpose data parallel programming environment.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0610120v2"
    },
    {
        "title": "LIBOPT - An environment for testing solvers on heterogeneous collections\n  of problems - Version 1.0",
        "authors": [
            "Jean Charles Gilbert",
            "Xavier Jonsson"
        ],
        "category": "cs.MS",
        "published_year": "2007",
        "summary": "  The Libopt environment is both a methodology and a set of tools that can be\nused for testing, comparing, and profiling solvers on problems belonging to\nvarious collections. These collections can be heterogeneous in the sense that\ntheir problems can have common features that differ from one collection to the\nother. Libopt brings a unified view on this composite world by offering, for\nexample, the possibility to run any solver on any problem compatible with it,\nusing the same Unix/Linux command. The environment also provides tools for\ncomparing the results obtained by solvers on a specified set of problems. Most\nof the scripts going with the Libopt environment have been written in Perl.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0703025v1"
    },
    {
        "title": "WinBioinfTools: Bioinformatics Tools for Windows High Performance\n  Computing Server 2008",
        "authors": [
            "Mohamed Abouelhoda",
            "Hisham Mohamed"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  Open source bioinformatics tools running under MS Windows are rare to find,\nand those running under Windows HPC cluster are almost non-existing. This is\ndespite the fact that the Windows is the most popular operating system used\namong life scientists. Therefore, we introduce in this initiative\nWinBioinfTools, a toolkit containing a number of bioinformatics tools running\nunder Windows High Performance Computing Server 2008. It is an open source code\npackage, where users and developers can share and add to. We currently start\nwith three programs from the area of sequence analysis: 1) CoCoNUT for pairwise\ngenome comparison, 2) parallel BLAST for biological database search, and 3)\nparallel global pairwise sequence alignment. In this report, we focus on\ntechnical aspects concerning how some components of these tools were ported\nfrom Linux/Unix environment to run under Windows. We also show the advantages\nof using the Windows HPC Cluster 2008. We demonstrate by experiments the\nperformance gain achieved when using a computer cluster against a single\nmachine. Furthermore, we show the results of comparing the performance of\nWinBioinfTools on the Windows and Linux Cluster.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.0586v1"
    },
    {
        "title": "PetRBF--A parallel O(N) algorithm for radial basis function\n  interpolation",
        "authors": [
            "Rio Yokota",
            "L. A. Barba",
            "Matthew G. Knepley"
        ],
        "category": "cs.MS",
        "published_year": "2009",
        "summary": "  We have developed a parallel algorithm for radial basis function (RBF)\ninterpolation that exhibits O(N) complexity,requires O(N) storage, and scales\nexcellently up to a thousand processes. The algorithm uses a GMRES iterative\nsolver with a restricted additive Schwarz method (RASM) as a preconditioner and\na fast matrix-vector algorithm. Previous fast RBF methods, --,achieving at most\nO(NlogN) complexity,--, were developed using multiquadric and polyharmonic\nbasis functions. In contrast, the present method uses Gaussians with a small\nvariance (a common choice in particle methods for fluid simulation, our main\ntarget application). The fast decay of the Gaussian basis function allows rapid\nconvergence of the iterative solver even when the subdomains in the RASM are\nvery small. The present method was implemented in parallel using the PETSc\nlibrary (developer version). Numerical experiments demonstrate its capability\nin problems of RBF interpolation with more than 50 million data points, timing\nat 106 seconds (19 iterations for an error tolerance of 10^-15 on 1024\nprocessors of a Blue Gene/L (700 MHz PowerPC processors). The parallel code is\nfreely available in the open-source model.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.5413v1"
    },
    {
        "title": "JBotSim, a Tool for Fast Prototyping of Distributed Algorithms in\n  Dynamic Networks",
        "authors": [
            "Arnaud Casteigts",
            "Rémi Laplace"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  JBotSim is a java library that offers basic primitives for prototyping,\nrunning, and visualizing distributed algorithms in dynamic networks. With\nJBotSim, one can implement an idea in minutes and interact with it ({\\it e.g.\n}, add, move, or delete nodes) while it is running. JBotSim is well suited to\nprepare live demonstrations of your algorithms to colleagues or students; it\ncan also be used to evaluate performance at the algorithmic level (number of\nmessages, number of rounds, etc.). Unlike most tools, JBotSim is not an\nintegrated environment. It is a lightweight library to be used in your program.\nIn this paper, we present an overview of its distinctive features and\narchitecture.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.1435v9"
    },
    {
        "title": "Having Fun with Lambert W(x) Function",
        "authors": [
            "Darko Veberic"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  This short note presents the Lambert W(x) function and its possible\napplication in the framework of physics related to the Pierre Auger\nObservatory. The actual numerical implementation in C++ consists of Halley's\nand Fritsch's iteration with branch-point expansion, asymptotic series and\nrational fits as initial approximations.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1628v2"
    },
    {
        "title": "MP users guide",
        "authors": [
            "Richard P. Brent"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  MP is a package of ANSI Standard Fortran (ANS X3.9-1966) subroutines for\nperforming multiple-precision floating-point arithmetic and evaluating\nelementary and special functions. The subroutines are machine independent and\nthe precision is arbitrary, subject to storage limitations. The User's Guide\ndescribes the routines and their calling sequences, example and test programs,\nuse of the Augment precompiler, and gives installation instructions for the\npackage.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3173v2"
    },
    {
        "title": "Nonsingular Efficient Modeling of Rotations in 3-space using three\n  components",
        "authors": [
            "Norman J. Goldstein"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  This article introduces yet another representation of rotations in 3-space.\nThe rotations form a 3-dimensional projective space, which fact has not been\nexploited in Computer Science. We use the four affine patches of this\nprojective space to parametrize the rotations. This affine patch representation\nis more compact than quaternions (which require 4 components for calculations),\nencompasses the entire rotation group without singularities (unlike the Euler\nangles and rotation vector approaches), and requires only ratios of linear or\nquadratic polynomials for basic computations (unlike the Euler angles and\nrotation vector approaches which require transcendental functions).\n  As an example, we derive the differential equation for the integration of\nangular velocity using this affine patch representation of rotations. We remark\nthat the complexity of this equation is the same as the corresponding\nquaternion equation, but has advantages over the quaternion approach e.g.\nrenormalization to unit length is not required, and state space has no dead\ndirections.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4661v2"
    },
    {
        "title": "An Elimination Method for Solving Bivariate Polynomial Systems:\n  Eliminating the Usual Drawbacks",
        "authors": [
            "Eric Berberich",
            "Pavel Emeliyanenko",
            "Michael Sagraloff"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  We present an exact and complete algorithm to isolate the real solutions of a\nzero-dimensional bivariate polynomial system. The proposed algorithm\nconstitutes an elimination method which improves upon existing approaches in a\nnumber of points. First, the amount of purely symbolic operations is\nsignificantly reduced, that is, only resultant computation and square-free\nfactorization is still needed. Second, our algorithm neither assumes generic\nposition of the input system nor demands for any change of the coordinate\nsystem. The latter is due to a novel inclusion predicate to certify that a\ncertain region is isolating for a solution. Our implementation exploits\ngraphics hardware to expedite the resultant computation. Furthermore, we\nintegrate a number of filtering techniques to improve the overall performance.\nEfficiency of the proposed method is proven by a comparison of our\nimplementation with two state-of-the-art implementations, that is, LPG and\nMaple's isolate. For a series of challenging benchmark instances, experiments\nshow that our implementation outperforms both contestants.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.1386v1"
    },
    {
        "title": "A novel parallel algorithm for Gaussian Elimination of sparse\n  unsymmetric matrices",
        "authors": [
            "Riccardo Murri"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  We describe a new algorithm for Gaussian Elimination suitable for general\n(unsymmetric and possibly singular) sparse matrices, of any entry type, which\nhas a natural parallel and distributed-memory formulation but degrades\ngracefully to sequential execution.\n  We present a sample MPI implementation of a program computing the rank of a\nsparse integer matrix using the proposed algorithm. Some preliminary\nperformance measurements are presented and discussed, and the performance of\nthe algorithm is compared to corresponding state-of-the-art algorithms for\nfloating-point and integer matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.4136v3"
    },
    {
        "title": "The MathScheme Library: Some Preliminary Experiments",
        "authors": [
            "Jacques Carette",
            "William M. Farmer",
            "Filip Jeremic",
            "Vincent Maccio",
            "Russell O'Connor",
            "Quang M. Tran"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  We present some of the experiments we have performed to best test our design\nfor a library for MathScheme, the mechanized mathematics software system we are\nbuilding. We wish for our library design to use and reflect, as much as\npossible, the mathematical structure present in the objects which populate the\nlibrary.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.1862v1"
    },
    {
        "title": "Odeint - Solving ordinary differential equations in C++",
        "authors": [
            "Karsten Ahnert",
            "Mario Mulansky"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  Many physical, biological or chemical systems are modeled by ordinary\ndifferential equations (ODEs) and finding their solution is an every-day-task\nfor many scientists. Here, we introduce a new C++ library dedicated to find\nnumerical solutions of initial value problems of ODEs: odeint (www.odeint.com).\nodeint is implemented in a highly generic way and provides extensive\ninteroperability at top performance. For example, due to it's modular design it\ncan be easily parallized with OpenMP and even runs on CUDA GPUs. Despite that,\nit provides a convenient interface that allows for a simple and easy usage.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.3397v1"
    },
    {
        "title": "LINPRO: linear inverse problem library for data contaminated by\n  statistical noise",
        "authors": [
            "Piotr Magierski",
            "Gabriel Wlazlowski"
        ],
        "category": "cs.MS",
        "published_year": "2011",
        "summary": "  The library LINPRO which provides solution to the linear inverse problem for\ndata contaminated by a statistical noise is presented. The library makes use of\ntwo methods: Maximum Entropy Method and Singular Value Decomposition. As an\nexample it has been applied to perform an analytic continuation of the\nimaginary time propagator obtained within the Quantum Monte Carlo method.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.5441v2"
    },
    {
        "title": "mlpy: Machine Learning Python",
        "authors": [
            "Davide Albanese",
            "Roberto Visintainer",
            "Stefano Merler",
            "Samantha Riccadonna",
            "Giuseppe Jurman",
            "Cesare Furlanello"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  mlpy is a Python Open Source Machine Learning library built on top of\nNumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of\nstate-of-the-art machine learning methods for supervised and unsupervised\nproblems and it is aimed at finding a reasonable compromise among modularity,\nmaintainability, reproducibility, usability and efficiency. mlpy is\nmultiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at\nthe website http://mlpy.fbk.eu.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.6548v2"
    },
    {
        "title": "NLSEmagic: Nonlinear Schrödinger Equation Multidimensional\n  Matlab-based GPU-accelerated Integrators using Compact High-order Schemes",
        "authors": [
            "R. M. Caplan"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  We present a simple to use, yet powerful code package called NLSEmagic to\nnumerically integrate the nonlinear Schr\\\"odinger equation in one, two, and\nthree dimensions. NLSEmagic is a high-order finite-difference code package\nwhich utilizes graphic processing unit (GPU) parallel architectures. The codes\nrunning on the GPU are many times faster than their serial counterparts, and\nare much cheaper to run than on standard parallel clusters. The codes are\ndeveloped with usability and portability in mind, and therefore are written to\ninterface with MATLAB utilizing custom GPU-enabled C codes with the\nMEX-compiler interface. The packages are freely distributed, including user\nmanuals and set-up files.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.1263v2"
    },
    {
        "title": "Set Reduction In Nonlinear Equations",
        "authors": [
            "Erhan Turan",
            "Ali Ecder"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In this paper, an idea to solve nonlinear equations is presented. During the\nsolution of any problem with Newton's Method, it might happen that some of the\nunknowns satisfy the convergence criteria where the others fail. The\nconvergence happens only when all variables reach to the convergence limit. A\nmethod to reduce the dimension of the overall system by excluding some of the\nunknowns that satisfy an intermediate tolerance is introduced. In this\napproach, a smaller system is solved in less amount of time and already\nestablished local solutions are preserved and kept as constants while the other\nvariables that belong to the \"set\" will be relaxed. To realize the idea, an\nalgorithm is given that utilizes applications of pointers to reduce and\nevaluate the sets. Matrix-free Newton-Krylov Techniques are used on a test\nproblem and it is shown that proposed idea improves the overall convergence.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.3059v1"
    },
    {
        "title": "FEAST Eigenvalue Solver v3.0 User Guide",
        "authors": [
            "Eric Polizzi",
            "James Kestyn"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  The FEAST eigensolver package is a free high-performance numerical library\nfor solving the Hermitian and non-Hermitian eigenvalue problems, and obtaining\nall the eigenvalues and (right/left) eigenvectors within a given search\ninterval or arbitrary contour in the complex plane. Its originality lies with a\nnew transformative numerical approach to the traditional eigenvalue algorithm\ndesign - the FEAST algorithm. The FEAST eigensolver combines simplicity and\nefficiency and it offers many important capabilities for achieving high\nperformance, robustness, accuracy, and scalability on parallel architectures.\nFEAST is both a comprehensive library package, and an easy to use software. It\nincludes flexible reverse communication interfaces and ready to use predefined\ninterfaces for dense, banded and sparse systems. The current version v3.0 of\nthe FEAST package can address both Hermitian and non-Hermitian eigenvalue\nproblems (real symmetric, real non-symmetric, complex Hermitian, complex\nsymmetric, or complex general systems) on both shared-memory and distributed\nmemory architectures (i.e contains both FEAST-SMP and FEAST-MPI packages). This\nUser's guide provides instructions for installation setup, a detailed\ndescription of the FEAST interfaces and a large number of examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.4031v3"
    },
    {
        "title": "Theory Presentation Combinators",
        "authors": [
            "Jacques Carette",
            "Russell O'Connor"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  We motivate and give semantics to theory presentation combinators as the\nfoundational building blocks for a scalable library of theories. The key\nobservation is that the category of contexts and fibered categories are the\nideal theoretical tools for this purpose.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.0053v2"
    },
    {
        "title": "Reliable Generation of High-Performance Matrix Algebra",
        "authors": [
            "Geoffrey Belter",
            "Elizabeth Jessup",
            "Thomas Nelson",
            "Boyana Norris",
            "Jeremy G. Siek"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Scientific programmers often turn to vendor-tuned Basic Linear Algebra\nSubprograms (BLAS) to obtain portable high performance. However, many numerical\nalgorithms require several BLAS calls in sequence, and those successive calls\nresult in suboptimal performance. The entire sequence needs to be optimized in\nconcert. Instead of vendor-tuned BLAS, a programmer could start with source\ncode in Fortran or C (e.g., based on the Netlib BLAS) and use a\nstate-of-the-art optimizing compiler. However, our experiments show that\noptimizing compilers often attain only one-quarter the performance of\nhand-optimized code. In this paper we present a domain-specific compiler for\nmatrix algebra, the Build to Order BLAS (BTO), that reliably achieves high\nperformance using a scalable search algorithm for choosing the best combination\nof loop fusion, array contraction, and multithreading for data parallelism. The\nBTO compiler generates code that is between 16% slower and 39% faster than\nhand-optimized code.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1098v1"
    },
    {
        "title": "A Domain-Specific Compiler for Linear Algebra Operations",
        "authors": [
            "Diego Fabregat-Traver",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  We present a prototypical linear algebra compiler that automatically exploits\ndomain-specific knowledge to generate high-performance algorithms. The input to\nthe compiler is a target equation together with knowledge of both the structure\nof the problem and the properties of the operands. The output is a variety of\nhigh-performance algorithms, and the corresponding source code, to solve the\ntarget equation. Our approach consists in the decomposition of the input\nequation into a sequence of library-supported kernels. Since in general such a\ndecomposition is not unique, our compiler returns not one but a number of\nalgorithms. The potential of the compiler is shown by means of its application\nto a challenging equation arising within the genome-wide association study. As\na result, the compiler produces multiple \"best\" algorithms that outperform the\nbest existing libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.5975v1"
    },
    {
        "title": "Bayes Blocks: An Implementation of the Variational Bayesian Building\n  Blocks Framework",
        "authors": [
            "Markus Harva",
            "Tapani Raiko",
            "Antti Honkela",
            "Harri Valpola",
            "Juha Karhunen"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  A software library for constructing and learning probabilistic models is\npresented. The library offers a set of building blocks from which a large\nvariety of static and dynamic models can be built. These include hierarchical\nmodels for variances of other variables and many nonlinear models. The\nunderlying variational Bayesian machinery, providing for fast and robust\nestimation but being mathematically rather involved, is almost completely\nhidden from the user thus making it very easy to use the library. The building\nblocks include Gaussian, rectified Gaussian and mixture-of-Gaussians variables\nand computational nodes which can be combined rather freely.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.1380v1"
    },
    {
        "title": "A Generic Library for Stencil Computations",
        "authors": [
            "Mauro Bianco",
            "Ugo Varetto"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In this era of diverse and heterogeneous computer architectures, the\nprogrammability issues, such as productivity and portable efficiency, are\ncrucial to software development and algorithm design. One way to approach the\nproblem is to step away from traditional sequential programming languages and\nmove toward domain specific programming environments to balance between\nexpressivity and efficiency. In order to demonstrate this principle, we\ndeveloped a domain specific C++ generic library for stencil computations, like\nPDE solvers. The library features high level constructs to specify computation\nand allows the development of parallel stencil computations with very limited\neffort. The high abstraction constructs (like do_all and do_reduce) make the\nprogram shorter and cleaner with increased contextual information for better\nperformance exploitation. The results show good performance from Windows\nmulticores, to HPC clusters and machines with accelerators, like GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.1746v1"
    },
    {
        "title": "Hamilton Operators, Discrete Symmetries, Brute Force and SymbolicC++",
        "authors": [
            "Willi-Hans Steeb",
            "Yorick Hardy"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  To find the discrete symmetries of a Hamilton operator $\\hat H$ is of central\nimportance in quantum theory. Here we describe and implement a brute force\nmethod to determine the discrete symmetries given by permutation matrices for\nHamilton operators acting in a finite-dimensional Hilbert space. Spin and Fermi\nsystems are considered as examples. A computer algebra implementation in\nSymbolicC++ is provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.4721v1"
    },
    {
        "title": "Orthogononalization on a general purpose graphics processing unit with\n  double double and quad double arithmetic",
        "authors": [
            "Jan Verschelde",
            "Genady Yoffe"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Our problem is to accurately solve linear systems on a general purpose\ngraphics processing unit with double double and quad double arithmetic. The\nlinear systems originate from the application of Newton's method on polynomial\nsystems. Newton's method is applied as a corrector in a path following method,\nso the linear systems are solved in sequence and not simultaneously. One\nsolution path may require the solution of thousands of linear systems. In\nprevious work we reported good speedups with our implementation to evaluate and\ndifferentiate polynomial systems on the NVIDIA Tesla C2050. Although the cost\nof evaluation and differentiation often dominates the cost of linear system\nsolving in Newton's method, because of the limited bandwidth of the\ncommunication between CPU and GPU, we cannot afford to send the linear system\nto the CPU for solving during path tracking.\n  Because of large degrees, the Jacobian matrix may contain extreme values,\nrequiring extended precision, leading to a significant overhead. This overhead\nof multiprecision arithmetic is our main motivation to develop a massively\nparallel algorithm. To allow overdetermined linear systems we solve linear\nsystems in the least squares sense, computing the QR decomposition of the\nmatrix by the modified Gram-Schmidt algorithm. We describe our implementation\nof the modified Gram-Schmidt orthogonalization method for the NVIDIA Tesla\nC2050, using double double and quad double arithmetic. Our experimental results\nshow that the achieved speedups are sufficiently high to compensate for the\noverhead of one extra level of precision.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.0800v2"
    },
    {
        "title": "MLPACK: A Scalable C++ Machine Learning Library",
        "authors": [
            "Ryan R. Curtin",
            "James R. Cline",
            "N. P. Slagle",
            "William B. March",
            "Parikshit Ram",
            "Nishant A. Mehta",
            "Alexander G. Gray"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning\nlibrary released in late 2011 offering both a simple, consistent API accessible\nto novice users and high performance and flexibility to expert users by\nleveraging modern features of C++. MLPACK provides cutting-edge algorithms\nwhose benchmarks exhibit far better performance than other leading machine\nlearning libraries. MLPACK version 1.0.3, licensed under the LGPL, is available\nat http://www.mlpack.org.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.6293v1"
    },
    {
        "title": "Solving Sequences of Generalized Least-Squares Problems on\n  Multi-threaded Architectures",
        "authors": [
            "Diego Fabregat-Traver",
            "Yurii Aulchenko",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Generalized linear mixed-effects models in the context of genome-wide\nassociation studies (GWAS) represent a formidable computational challenge: the\nsolution of millions of correlated generalized least-squares problems, and the\nprocessing of terabytes of data. We present high performance in-core and\nout-of-core shared-memory algorithms for GWAS: By taking advantage of\ndomain-specific knowledge, exploiting multi-core parallelism, and handling data\nefficiently, our algorithms attain unequalled performance. When compared to\nGenABEL, one of the most widely used libraries for GWAS, on a 12-core processor\nwe obtain 50-fold speedups. As a consequence, our routines enable genome\nstudies of unprecedented size.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.7325v1"
    },
    {
        "title": "Demonstrating the Usefulness of CAELinux for Computer Aided Engineering\n  using an Example of the Three Dimensional Reconstruction of a Pig Liver",
        "authors": [
            "Kirana Kumara P."
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  CAELinux is a Linux distribution which is bundled with free software packages\nrelated to Computer Aided Engineering (CAE). The free software packages include\nsoftware that can build a three dimensional solid model, programs that can mesh\na geometry, software for carrying out Finite Element Analysis (FEA), programs\nthat can carry out image processing etc. Present work has two goals: 1) To give\na brief description of CAELinux 2) To demonstrate that CAELinux could be useful\nfor Computer Aided Engineering, using an example of the three dimensional\nreconstruction of a pig liver from a stack of CT-scan images. One can note that\ninstead of using CAELinux, using commercial software for reconstructing the\nliver would cost a lot of money. One can also note that CAELinux is a free and\nopen source operating system and all software packages that are included in the\noperating system are also free. Hence one can conclude that CAELinux could be a\nvery useful tool in application areas like surgical simulation which require\nthree dimensional reconstructions of biological organs. Also, one can see that\nCAELinux could be a very useful tool for Computer Aided Engineering, in\ngeneral.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.8418v1"
    },
    {
        "title": "GPU-accelerated generation of correctly-rounded elementary functions",
        "authors": [
            "Pierre Fortin",
            "Mourad Gouicem",
            "Stef Graillat"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  The IEEE 754-2008 standard recommends the correct rounding of some elementary\nfunctions. This requires to solve the Table Maker's Dilemma which implies a\nhuge amount of CPU computation time. We consider in this paper accelerating\nsuch computations, namely Lefe'vre algorithm on Graphics Processing Units\n(GPUs) which are massively parallel architectures with a partial SIMD execution\n(Single Instruction Multiple Data). We first propose an analysis of the\nLef\\`evre hard-to-round argument search using the concept of continued\nfractions. We then propose a new parallel search algorithm much more efficient\non GPU thanks to its more regular control flow. We also present an efficient\nhybrid CPU-GPU deployment of the generation of the polynomial approximations\nrequired in Lef\\`evre algorithm. In the end, we manage to obtain overall\nspeedups up to 53.4x on one GPU over a sequential CPU execution, and up to 7.1x\nover a multi-core CPU, which enable a much faster solving of the Table Maker's\nDilemma for the double precision format.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.3056v2"
    },
    {
        "title": "Unified Form Language: A domain-specific language for weak formulations\n  of partial differential equations",
        "authors": [
            "Martin S. Alnaes",
            "Anders Logg",
            "Kristian B. Oelgaard",
            "Marie E. Rognes",
            "Garth N. Wells"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  We present the Unified Form Language (UFL), which is a domain-specific\nlanguage for representing weak formulations of partial differential equations\nwith a view to numerical approximation. Features of UFL include support for\nvariational forms and functionals, automatic differentiation of forms and\nexpressions, arbitrary function space hierarchies for multi-field problems,\ngeneral differential operators and flexible tensor algebra. With these\nfeatures, UFL has been used to effortlessly express finite element methods for\ncomplex systems of partial differential equations in near-mathematical\nnotation, resulting in compact, intuitive and readable programs. We present in\nthis work the language and its construction. An implementation of UFL is freely\navailable as an open-source software library. The library generates abstract\nsyntax tree representations of variational problems, which are used by other\nsoftware libraries to generate concrete low-level implementations. Some\napplication examples are presented and libraries that support UFL are\nhighlighted.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.4047v2"
    },
    {
        "title": "Application-tailored Linear Algebra Algorithms: A search-based Approach",
        "authors": [
            "Diego Fabregat-Traver",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In this paper, we tackle the problem of automatically generating algorithms\nfor linear algebra operations by taking advantage of problem-specific\nknowledge. In most situations, users possess much more information about the\nproblem at hand than what current libraries and computing environments accept;\nevidence shows that if properly exploited, such information leads to\nuncommon/unexpected speedups. We introduce a knowledge-aware linear algebra\ncompiler that allows users to input matrix equations together with properties\nabout the operands and the problem itself; for instance, they can specify that\nthe equation is part of a sequence, and how successive instances are related to\none another. The compiler exploits all this information to guide the generation\nof algorithms, to limit the size of the search space, and to avoid redundant\ncomputations. We applied the compiler to equations arising as part of\nsensitivity and genome studies; the algorithms produced exhibit, respectively,\n100- and 1000-fold speedups.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.5904v1"
    },
    {
        "title": "Programming CUDA and OpenCL: A Case Study Using Modern C++ Libraries",
        "authors": [
            "Denis Demidov",
            "Karsten Ahnert",
            "Karl Rupp",
            "Peter Gottschling"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  We present a comparison of several modern C++ libraries providing high-level\ninterfaces for programming multi- and many-core architectures on top of CUDA or\nOpenCL. The comparison focuses on the solution of ordinary differential\nequations and is based on odeint, a framework for the solution of systems of\nordinary differential equations. Odeint is designed in a very flexible way and\nmay be easily adapted for effective use of libraries such as Thrust, MTL4,\nVexCL, or ViennaCL, using CUDA or OpenCL technologies. We found that CUDA and\nOpenCL work equally well for problems of large sizes, while OpenCL has higher\noverhead for smaller problems. Furthermore, we show that modern high-level\nlibraries allow to effectively use the computational resources of many-core\nGPUs or multi-core CPUs without much knowledge of the underlying technologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6326v2"
    },
    {
        "title": "Parameter identification in large kinetic networks with BioPARKIN",
        "authors": [
            "Thomas Dierkes",
            "Susanna Röblitz",
            "Moritz Wade",
            "Peter Deuflhard"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Modelling, parameter identification, and simulation play an important role in\nsystems biology. Usually, the goal is to determine parameter values that\nminimise the difference between experimental measurement values and model\npredictions in a least-squares sense. Large-scale biological networks, however,\noften suffer from missing data for parameter identification. Thus, the\nleast-squares problems are rank-deficient and solutions are not unique. Many\ncommon optimisation methods ignore this detail because they do not take into\naccount the structure of the underlying inverse problem. These algorithms\nsimply return a \"solution\" without additional information on identifiability or\nuniqueness. This can yield misleading results, especially if parameters are\nco-regulated and data are noisy.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4928v2"
    },
    {
        "title": "ZKCM: a C++ library for multiprecision matrix computation with\n  applications in quantum information",
        "authors": [
            "Akira SaiToh"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  ZKCM is a C++ library developed for the purpose of multiprecision matrix\ncomputation, on the basis of the GNU MP and MPFR libraries. It provides an\neasy-to-use syntax and convenient functions for matrix manipulations including\nthose often used in numerical simulations in quantum physics. Its extension\nlibrary, ZKCM_QC, is developed for simulating quantum computing using the\ntime-dependent matrix-product-state simulation method. This paper gives an\nintroduction about the libraries with practical sample programs.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.6034v2"
    },
    {
        "title": "C Language Extensions for Hybrid CPU/GPU Programming with StarPU",
        "authors": [
            "Ludovic Courtès"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Modern platforms used for high-performance computing (HPC) include machines\nwith both general-purpose CPUs, and \"accelerators\", often in the form of\ngraphical processing units (GPUs). StarPU is a C library to exploit such\nplatforms. It provides users with ways to define \"tasks\" to be executed on CPUs\nor GPUs, along with the dependencies among them, and by automatically\nscheduling them over all the available processing units. In doing so, it also\nrelieves programmers from the need to know the underlying architecture details:\nit adapts to the available CPUs and GPUs, and automatically transfers data\nbetween main memory and GPUs as needed. While StarPU's approach is successful\nat addressing run-time scheduling issues, being a C library makes for a poor\nand error-prone programming interface. This paper presents an effort started in\n2011 to promote some of the concepts exported by the library as C language\nconstructs, by means of an extension of the GCC compiler suite. Our main\ncontribution is the design and implementation of language extensions that map\nto StarPU's task programming paradigm. We argue that the proposed extensions\nmake it easier to get started with StarPU,eliminate errors that can occur when\nusing the C library, and help diagnose possible mistakes. We conclude on future\nwork.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.0878v2"
    },
    {
        "title": "The Graph Grammar Library - a generic framework for chemical graph\n  rewrite systems",
        "authors": [
            "Martin Mann",
            "Heinz Ekker",
            "Christoph Flamm"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Graph rewrite systems are powerful tools to model and study complex problems\nin various fields of research. Their successful application to chemical\nreaction modelling on a molecular level was shown but no appropriate and simple\nsystem is available at the moment.\n  The presented Graph Grammar Library (GGL) implements a generic Double Push\nOut approach for general graph rewrite systems. The framework focuses on a high\nlevel of modularity as well as high performance, using state-of-the-art\nalgorithms and data structures, and comes with extensive documentation. The\nlarge GGL chemistry module enables extensive and detailed studies of chemical\nsystems. It well meets the requirements and abilities envisioned by Yadav et\nal. (2004) for such chemical rewrite systems. Here, molecules are represented\nas undirected labeled graphs while chemical reactions are described by\naccording graph grammar rules. Beside the graph transformation, the GGL offers\nadvanced cheminformatics algorithms for instance to estimate energies\nofmolecules or aromaticity perception. These features are illustrated using a\nset of reactions from polyketide chemistry a huge class of natural compounds of\nmedical relevance.\n  The graph grammar based simulation of chemical reactions offered by the GGL\nis a powerful tool for extensive cheminformatics studies on a molecular level.\nThe GGL already provides rewrite rules for all enzymes listed in the KEGG\nLIGAND database is freely available at\nhttp://www.tbi.univie.ac.at/software/GGL/.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.1356v1"
    },
    {
        "title": "A GEMM interface and implementation on NVIDIA GPUs for multiple small\n  matrices",
        "authors": [
            "Chetan Jhurani",
            "Paul Mullowney"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We present an interface and an implementation of the General Matrix Multiply\n(GEMM) routine for multiple small matrices processed simultaneously on NVIDIA\ngraphics processing units (GPUs). We focus on matrix sizes under 16. The\nimplementation can be easily extended to larger sizes. For single precision\nmatrices, our implementation is 30% to 600% faster than the batched cuBLAS\nimplementation distributed in the CUDA Toolkit 5.0 on NVIDIA Tesla K20c. For\nexample, we obtain 104 GFlop/s and 216 GFlop/s when multiplying 100,000\nindependent matrix pairs of size 10 and 16, respectively. Similar improvement\nin performance is obtained for other sizes, in single and double precision for\nreal and complex types, and when the number of matrices is smaller. Apart from\nour implementation, our different function interface also plays an important\nrole in the improved performance. Applications of this software include Finite\nElement computation on GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7053v1"
    },
    {
        "title": "Batched Kronecker product for 2-D matrices and 3-D arrays on NVIDIA GPUs",
        "authors": [
            "Chetan Jhurani"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We describe an interface and an implementation for performing Kronecker\nproduct actions on NVIDIA GPUs for multiple small 2-D matrices and 3-D arrays\nprocessed in parallel as a batch. This method is suited to cases where the\nKronecker product component matrices are identical but the operands in a\nmatrix-free application vary in the batch. Any batched GEMM (General Matrix\nMultiply) implementation, for example ours [1] or the one in cuBLAS, can also\nbe used for performing batched Kronecker products on GPUs. However, the\nspecialized implementation presented here is faster and uses less memory.\nPartly this is because a simple GEMM based approach would require extra copies\nto and from main memory. We focus on matrix sizes less than or equal to 16,\nsince these are the typical polynomial degrees in Finite Elements, but the\nimplementation can be easily extended for other sizes. We obtain 143 and 285\nGFlop/s for single precision real when processing matrices of size 10 and 16,\nrespectively on NVIDIA Tesla K20c using CUDA 5.0. The corresponding speeds for\n3-D array Kronecker products are 126 and 268 GFlop/s, respectively. Double\nprecision is easily supported using the C++ template mechanism.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7054v1"
    },
    {
        "title": "Manopt, a Matlab toolbox for optimization on manifolds",
        "authors": [
            "Nicolas Boumal",
            "Bamdev Mishra",
            "P. -A. Absil",
            "Rodolphe Sepulchre"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Optimization on manifolds is a rapidly developing branch of nonlinear\noptimization. Its focus is on problems where the smooth geometry of the search\nspace can be leveraged to design efficient numerical algorithms. In particular,\noptimization on manifolds is well-suited to deal with rank and orthogonality\nconstraints. Such structured constraints appear pervasively in machine learning\napplications, including low-rank matrix completion, sensor network\nlocalization, camera network registration, independent component analysis,\nmetric learning, dimensionality reduction and so on. The Manopt toolbox,\navailable at www.manopt.org, is a user-friendly, documented piece of software\ndedicated to simplify experimenting with state of the art Riemannian\noptimization algorithms. We aim particularly at reaching practitioners outside\nour field.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.5200v1"
    },
    {
        "title": "Algorithm 950: Ncpol2sdpa---Sparse Semidefinite Programming Relaxations\n  for Polynomial Optimization Problems of Noncommuting Variables",
        "authors": [
            "Peter Wittek"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  A hierarchy of semidefinite programming (SDP) relaxations approximates the\nglobal optimum of polynomial optimization problems of noncommuting variables.\nGenerating the relaxation, however, is a computationally demanding task, and\nonly problems of commuting variables have efficient generators. We develop an\nimplementation for problems of noncommuting problems that creates the\nrelaxation to be solved by SDPA -- a high-performance solver that runs in a\ndistributed environment. We further exploit the inherent sparsity of\noptimization problems in quantum physics to reduce the complexity of the\nresulting relaxations. Constrained problems with a relaxation of order two may\ncontain up to a hundred variables. The implementation is available in Python.\nThe tool helps solve problems such as finding the ground state energy or\ntesting quantum correlations.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.6029v3"
    },
    {
        "title": "Higher-order Reverse Automatic Differentiation with emphasis on the\n  third-order",
        "authors": [
            "Robert M. Gower",
            "Artur L. Gower"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  It is commonly assumed that calculating third order information is too\nexpensive for most applications. But we show that the directional derivative of\nthe Hessian ($D^3f(x)\\cdot d$) can be calculated at a cost proportional to that\nof a state-of-the-art method for calculating the Hessian matrix. We do this by\nfirst presenting a simple procedure for designing high order reverse methods\nand applying it to deduce several methods including a reverse method that\ncalculates $D^3f(x)\\cdot d$. We have implemented this method taking into\naccount symmetry and sparsity, and successfully calculated this derivative for\nfunctions with a million variables. These results indicate that the use of\nthird order information in a general nonlinear solver, such as Halley-Chebyshev\nmethods, could be a practical alternative to Newton's method.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5479v1"
    },
    {
        "title": "Modernizing PHCpack through phcpy",
        "authors": [
            "Jan Verschelde"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  PHCpack is a large software package for solving systems of polynomial\nequations. The executable phc is menu driven and file oriented. This paper\ndescribes the development of phcpy, a Python interface to PHCpack. Instead of\nnavigating through menus, users of phcpy solve systems in the Python shell or\nvia scripts. Persistent objects replace intermediate files.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.0056v2"
    },
    {
        "title": "Large-Scale Paralleled Sparse Principal Component Analysis",
        "authors": [
            "W. Liu",
            "H. Zhang",
            "D. Tao",
            "Y. Wang",
            "K. Lu"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  Principal component analysis (PCA) is a statistical technique commonly used\nin multivariate data analysis. However, PCA can be difficult to interpret and\nexplain since the principal components (PCs) are linear combinations of the\noriginal variables. Sparse PCA (SPCA) aims to balance statistical fidelity and\ninterpretability by approximating sparse PCs whose projections capture the\nmaximal variance of original data. In this paper we present an efficient and\nparalleled method of SPCA using graphics processing units (GPUs), which can\nprocess large blocks of data in parallel. Specifically, we construct parallel\nimplementations of the four optimization formulations of the generalized power\nmethod of SPCA (GP-SPCA), one of the most efficient and effective SPCA\napproaches, on a GPU. The parallel GPU implementation of GP-SPCA (using CUBLAS)\nis up to eleven times faster than the corresponding CPU implementation (using\nCBLAS), and up to 107 times faster than a MatLab implementation. Extensive\ncomparative experiments in several real-world datasets confirm that SPCA offers\na practical advantage.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.6182v1"
    },
    {
        "title": "A Study on the Influence of Caching: Sequences of Dense Linear Algebra\n  Kernels",
        "authors": [
            "Elmar Peise",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  It is universally known that caching is critical to attain high- performance\nimplementations: In many situations, data locality (in space and time) plays a\nbigger role than optimizing the (number of) arithmetic floating point\noperations. In this paper, we show evidence that at least for linear algebra\nalgorithms, caching is also a crucial factor for accurate performance modeling\nand performance prediction.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.5897v1"
    },
    {
        "title": "Semi-Analytical Computation of Acoustic Scattering by Spheroids and\n  Disks",
        "authors": [
            "Ross Adelman",
            "Nail A. Gumerov",
            "Ramani Duraiswami"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Analytical solutions to acoustic scattering problems involving nonspherical\nshapes, such as spheroids and disks, have long been known and have many\napplications. However, these solutions require special functions that are not\neasily computable. For this reason, their asymptotic forms are typically used\nsince they are more readily available. We explore these solutions and provide\ncomputational software for calculating their nonasymptotic forms, which are\naccurate over a wide range of frequencies and distances. This software, which\nruns in MATLAB, computes the solutions to acoustic scattering problems\ninvolving spheroids and disks by semi-analytical means, and is freely available\nfrom our webpage.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.0854v1"
    },
    {
        "title": "A Report of a Significant Error On a Frequently Used Pseudo Random\n  Number Generator",
        "authors": [
            "Ayse Ferhan Yesil",
            "M. Cemal Yalabik"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Emergence of stochastic simulations as an extensively used computational tool\nfor scientific purposes intensified the need for more accurate ways of\ngenerating sufficiently long sequences of uncorrelated random numbers. Even\nthough several different methods have been proposed for this end, deterministic\nalgorithms known as pseudo-random number generators (PRNGs) emerged to be the\nmost widely used tool as a replicable, portable and easy to use method to\ngenerate such random number sequences. Here, we introduce a simple Poisson\nprocess whose simulation gives systematic errors when the very commonly used\nrandom number generator of the GNU C Library (Glibc) is utilised. The PRNG of\nGlibc is an additive lagged Fibonacci generator, the family of such PRNGs are\naccepted as relatively safe among other PRNGs. The systematic errors indicate\ncomplex correlation relations among random numbers which requires a further\nexplanation.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.1900v1"
    },
    {
        "title": "Introduction to the R package TDA",
        "authors": [
            "Brittany Terese Fasy",
            "Jisu Kim",
            "Fabrizio Lecci",
            "Clément Maria"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We present a short tutorial and introduction to using the R package TDA,\nwhich provides some tools for Topological Data Analysis. In particular, it\nincludes implementations of functions that, given some data, provide\ntopological information about the underlying space, such as the distance\nfunction, the distance to a measure, the kNN density estimator, the kernel\ndensity estimator, and the kernel distance. The salient topological features of\nthe sublevel sets (or superlevel sets) of these functions can be quantified\nwith persistent homology. We provide an R interface for the efficient\nalgorithms of the C++ libraries GUDHI, Dionysus and PHAT, including a function\nfor the persistent homology of the Rips filtration, and one for the persistent\nhomology of sublevel sets (or superlevel sets) of arbitrary functions evaluated\nover a grid of points. The significance of the features in the resulting\npersistence diagrams can be analyzed with functions that implement recently\ndeveloped statistical methods. The R package TDA also includes the\nimplementation of an algorithm for density clustering, which allows us to\nidentify the spatial organization of the probability mass associated to a\ndensity function and visualize it by means of a dendrogram, the cluster tree.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.1830v2"
    },
    {
        "title": "An Infra-Structure for Performance Estimation and Experimental\n  Comparison of Predictive Models in R",
        "authors": [
            "Luis Torgo"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  This document describes an infra-structure provided by the R package\nperformanceEstimation that allows to estimate the predictive performance of\ndifferent approaches (workflows) to predictive tasks. The infra-structure is\ngeneric in the sense that it can be used to estimate the values of any\nperformance metrics, for any workflow on different predictive tasks, namely,\nclassification, regression and time series tasks. The package also includes\nseveral standard workflows that allow users to easily set up their experiments\nlimiting the amount of work and information they need to provide. The overall\ngoal of the infra-structure provided by our package is to facilitate the task\nof estimating the predictive performance of different modeling approaches to\npredictive tasks in the R environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.0436v4"
    },
    {
        "title": "Enhancing SfePy with Isogeometric Analysis",
        "authors": [
            "Robert Cimrman"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  In the paper a recent enhancement to the open source package SfePy (Simple\nFinite Elements in Python, http://sfepy.org) is introduced, namely the addition\nof another numerical discretization scheme, the isogeometric analysis, to the\noriginal implementation based on the nowadays standard and well-established\nnumerical solution technique, the finite element method. The isogeometric\nremoves the need of the solution domain approximation by a piece-wise polygonal\ndomain covered by the finite element mesh, and allows approximation of unknown\nfields with a higher smoothness then the finite element method, which can be\nadvantageous in many applications. Basic numerical examples illustrating the\nimplementation and use of the isogeometric analysis in SfePy are shown.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.6407v1"
    },
    {
        "title": "T3PS: Tool for Parallel Processing in Parameter Scans",
        "authors": [
            "Vinzenz Maurer"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  T3PS is a program that can be used to quickly design and perform parameter\nscans while easily taking advantage of the multi-core architecture of current\nprocessors. It takes an easy to read and write parameter scan definition file\nformat as input. Based on the parameter ranges and other options contained\ntherein, it distributes the calculation of the parameter space over multiple\nprocesses and possibly computers. The derived data is saved in a plain text\nfile format readable by most plotting software. The supported scanning\nstrategies include: grid scan, random scan, Markov Chain Monte Carlo, numerical\noptimization. Several example parameter scans are shown and compared with\nresults in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.01073v1"
    },
    {
        "title": "CSR5: An Efficient Storage Format for Cross-Platform Sparse\n  Matrix-Vector Multiplication",
        "authors": [
            "Weifeng Liu",
            "Brian Vinter"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Sparse matrix-vector multiplication (SpMV) is a fundamental building block\nfor numerous applications. In this paper, we propose CSR5 (Compressed Sparse\nRow 5), a new storage format, which offers high-throughput SpMV on various\nplatforms including CPUs, GPUs and Xeon Phi. First, the CSR5 format is\ninsensitive to the sparsity structure of the input matrix. Thus the single\nformat can support an SpMV algorithm that is efficient both for regular\nmatrices and for irregular matrices. Furthermore, we show that the overhead of\nthe format conversion from the CSR to the CSR5 can be as low as the cost of a\nfew SpMV operations. We compare the CSR5-based SpMV algorithm with 11\nstate-of-the-art formats and algorithms on four mainstream processors using 14\nregular and 10 irregular matrices as a benchmark suite. For the 14 regular\nmatrices in the suite, we achieve comparable or better performance over the\nprevious work. For the 10 irregular matrices, the CSR5 obtains average\nperformance improvement of 17.6\\%, 28.5\\%, 173.0\\% and 293.3\\% (up to 213.3\\%,\n153.6\\%, 405.1\\% and 943.3\\%) over the best existing work on dual-socket Intel\nCPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively. For\nreal-world applications such as a solver with only tens of iterations, the CSR5\nformat can be more practical because of its low-overhead for format conversion.\nThe source code of this work is downloadable at\nhttps://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05032v2"
    },
    {
        "title": "A Framework for General Sparse Matrix-Matrix Multiplication on GPUs and\n  Heterogeneous Processors",
        "authors": [
            "Weifeng Liu",
            "Brian Vinter"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  General sparse matrix-matrix multiplication (SpGEMM) is a fundamental\nbuilding block for numerous applications such as algebraic multigrid method\n(AMG), breadth first search and shortest path problem. Compared to other sparse\nBLAS routines, an efficient parallel SpGEMM implementation has to handle extra\nirregularity from three aspects: (1) the number of nonzero entries in the\nresulting sparse matrix is unknown in advance, (2) very expensive parallel\ninsert operations at random positions in the resulting sparse matrix dominate\nthe execution time, and (3) load balancing must account for sparse data in both\ninput matrices.\n  In this work we propose a framework for SpGEMM on GPUs and emerging CPU-GPU\nheterogeneous processors. This framework particularly focuses on the above\nthree problems. Memory pre-allocation for the resulting matrix is organized by\na hybrid method that saves a large amount of global memory space and\nefficiently utilizes the very limited on-chip scratchpad memory. Parallel\ninsert operations of the nonzero entries are implemented through the GPU merge\npath algorithm that is experimentally found to be the fastest GPU merge\napproach. Load balancing builds on the number of necessary arithmetic\noperations on the nonzero entries and is guaranteed in all stages.\n  Compared with the state-of-the-art CPU and GPU SpGEMM methods, our approach\ndelivers excellent absolute performance and relative speedups on various\nbenchmarks multiplying matrices with diverse sparsity structures. Furthermore,\non heterogeneous processors, our SpGEMM approach achieves higher throughput by\nusing re-allocatable shared virtual memory.\n  The source code of this work is available at\nhttps://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR\n",
        "pdf_link": "http://arxiv.org/pdf/1504.05022v2"
    },
    {
        "title": "Speculative Segmented Sum for Sparse Matrix-Vector Multiplication on\n  Heterogeneous Processors",
        "authors": [
            "Weifeng Liu",
            "Brian Vinter"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Sparse matrix-vector multiplication (SpMV) is a central building block for\nscientific software and graph applications. Recently, heterogeneous processors\ncomposed of different types of cores attracted much attention because of their\nflexible core configuration and high energy efficiency. In this paper, we\npropose a compressed sparse row (CSR) format based SpMV algorithm utilizing\nboth types of cores in a CPU-GPU heterogeneous processor. We first\nspeculatively execute segmented sum operations on the GPU part of a\nheterogeneous processor and generate a possibly incorrect results. Then the CPU\npart of the same chip is triggered to re-arrange the predicted partial sums for\na correct resulting vector. On three heterogeneous processors from Intel, AMD\nand nVidia, using 20 sparse matrices as a benchmark suite, the experimental\nresults show that our method obtains significant performance improvement over\nthe best existing CSR-based SpMV algorithms. The source code of this work is\ndownloadable at https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06474v2"
    },
    {
        "title": "Fireflies: New software for interactively exploring dynamical systems\n  using GPU computing",
        "authors": [
            "Robert Merrison-Hort"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  In non-linear systems, where explicit analytic solutions usually can't be\nfound, visualisation is a powerful approach which can give insights into the\ndynamical behaviour of models; it is also crucial for teaching this area of\nmathematics. In this paper we present new software, Fireflies, which exploits\nthe power of graphical processing unit (GPU) computing to produce spectacular\ninteractive visualisations of arbitrary systems of ordinary differential\nequations. In contrast to typical phase portraits, Fireflies draws the current\nposition of trajectories (projected onto 2D or 3D space) as single points of\nlight, which move as the system is simulated. Due to the massively parallel\nnature of GPU hardware, Fireflies is able to simulate millions of trajectories\nin parallel (even on standard desktop computer hardware), producing \"swarms\" of\nparticles that move around the screen in real-time according to the equations\nof the system. Particles that move forwards in time reveal stable attractors\n(e.g. fixed points and limit cycles), while the option of integrating another\ngroup of trajectories backwards in time can reveal unstable objects\n(repellers). Fireflies allows the user to change the parameters of the system\nas it is running, in order to see the effect that they have on the dynamics and\nto observe bifurcations. We demonstrate the capabilities of the software with\nthree examples: a two-dimensional \"mean field\" model of neuronal activity, the\nclassical Lorenz system, and a 15-dimensional model of three interacting\nbiologically realistic neurons.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.00344v1"
    },
    {
        "title": "Tracking Many Solution Paths of a Polynomial Homotopy on a Graphics\n  Processing Unit",
        "authors": [
            "Jan Verschelde",
            "Xiangcheng Yu"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Polynomial systems occur in many areas of science and engineering. Unlike\ngeneral nonlinear systems, the algebraic structure enables to compute all\nsolutions of a polynomial system. We describe our massive parallel\npredictor-corrector algorithms to track many solution paths of a polynomial\nhomotopy. The data parallelism that provides the speedups stems from the\nevaluation and differentiation of the monomials in the same polynomial system\nat different data points, which are the points on the solution paths.\nPolynomial homotopies that have tens of thousands of solution paths can keep a\nsufficiently large amount of threads occupied. Our accelerated code combines\nthe reverse mode of algorithmic differentiation with double double and quad\ndouble precision to compute more accurate results faster.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.00383v1"
    },
    {
        "title": "SYM-ILDL: Incomplete $LDL^{T}$ Factorization of Symmetric Indefinite and\n  Skew-Symmetric Matrices",
        "authors": [
            "Chen Greif",
            "Shiwen He",
            "Paul Liu"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  SYM-ILDL is a numerical software package that computes incomplete $LDL^{T}$\n(or `ILDL') factorizations of symmetric indefinite and real skew-symmetric\nmatrices. The core of the algorithm is a Crout variant of incomplete LU (ILU),\noriginally introduced and implemented for symmetric matrices by [Li and Saad,\nCrout versions of ILU factorization with pivoting for sparse symmetric\nmatrices, Transactions on Numerical Analysis 20, pp. 75--85, 2005]. Our code is\neconomical in terms of storage and it deals with real skew-symmetric matrices\nas well, in addition to symmetric ones. The package is written in C++ and it is\ntemplated, open source, and includes a MATLAB interface. The code includes\nbuilt-in RCM and AMD reordering, two equilibration strategies, threshold\nBunch-Kaufman pivoting and rook pivoting, as well as a wrapper to MC64, a\npopular matching based equilibration and reordering algorithm. We also include\ntwo built-in iterative solvers: SQMR preconditioned with ILDL, or MINRES\npreconditioned with a symmetric positive definite preconditioner based on the\nILDL factorization.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.07589v3"
    },
    {
        "title": "Efficient FFT mapping on GPU for radar processing application: modeling\n  and implementation",
        "authors": [
            "Mohamed Amine Bergach",
            "Emilien Kofman",
            "Robert de Simone",
            "Serge Tissot",
            "Michel Syska"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  General-purpose multiprocessors (as, in our case, Intel IvyBridge and Intel\nHaswell) increasingly add GPU computing power to the former multicore\narchitectures. When used for embedded applications (for us, Synthetic aperture\nradar) with intensive signal processing requirements, they must constantly\ncompute convolution algorithms, such as the famous Fast Fourier Transform. Due\nto its \"fractal\" nature (the typical butterfly shape, with larger FFTs defined\nas combination of smaller ones with auxiliary data array transpose functions),\none can hope to compute analytically the size of the largest FFT that can be\nperformed locally on an elementary GPU compute block. Then, the full\napplication must be organized around this given building block size. Now, due\nto phenomena involved in the data transfers between various memory levels\nacross CPUs and GPUs, the optimality of such a scheme is only loosely\npredictable (as communications tend to overcome in time the complexity of\ncomputations). Therefore a mix of (theoretical) analytic approach and\n(practical) runtime validation is here needed. As we shall illustrate, this\noccurs at both stage, first at the level of deciding on a given elementary FFT\nblock size, then at the full application level.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.08067v1"
    },
    {
        "title": "MADNESS: A Multiresolution, Adaptive Numerical Environment for\n  Scientific Simulation",
        "authors": [
            "Robert J. Harrison",
            "Gregory Beylkin",
            "Florian A. Bischoff",
            "Justus A. Calvin",
            "George I. Fann",
            "Jacob Fosso-Tande",
            "Diego Galindo",
            "Jeff R. Hammond",
            "Rebecca Hartman-Baker",
            "Judith C. Hill",
            "Jun Jia",
            "Jakob S. Kottmann",
            "M-J. Yvonne Ou",
            "Laura E. Ratcliff",
            "Matthew G. Reuter",
            "Adam C. Richie-Halford",
            "Nichols A. Romero",
            "Hideo Sekino",
            "William A. Shelton",
            "Bryan E. Sundahl",
            "W. Scott Thornton",
            "Edward F. Valeev",
            "Álvaro Vázquez-Mayagoitia",
            "Nicholas Vence",
            "Yukina Yokoi"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  MADNESS (multiresolution adaptive numerical environment for scientific\nsimulation) is a high-level software environment for solving integral and\ndifferential equations in many dimensions that uses adaptive and fast harmonic\nanalysis methods with guaranteed precision based on multiresolution analysis\nand separated representations. Underpinning the numerical capabilities is a\npowerful petascale parallel programming environment that aims to increase both\nprogrammer productivity and code scalability. This paper describes the features\nand capabilities of MADNESS and briefly discusses some current applications in\nchemistry and several areas of physics.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.01888v1"
    },
    {
        "title": "Shared Memory Pipelined Parareal",
        "authors": [
            "Daniel Ruprecht"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  For the parallel-in-time integration method Parareal, pipelining can be used\nto hide some of the cost of the serial correction step and improve its\nefficiency. The paper introduces a basic OpenMP implementation of pipelined\nParareal and compares it to a standard MPI-based variant. Both versions yield\nalmost identical runtimes, but, depending on the compiler, the OpenMP variant\nconsumes about 7% less energy and has a significantly smaller memory footprint.\nHowever, its higher implementation complexity might make it difficult to use in\nlegacy codes and in combination with spatial parallelisation.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.06935v3"
    },
    {
        "title": "UBL: an R package for Utility-based Learning",
        "authors": [
            "Paula Branco",
            "Rita P. Ribeiro",
            "Luis Torgo"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  This document describes the R package UBL that allows the use of several\nmethods for handling utility-based learning problems. Classification and\nregression problems that assume non-uniform costs and/or benefits pose serious\nchallenges to predictive analytic tasks. In the context of meteorology,\nfinance, medicine, ecology, among many other, specific domain information\nconcerning the preference bias of the users must be taken into account to\nenhance the models predictive performance. To deal with this problem, a large\nnumber of techniques was proposed by the research community for both\nclassification and regression tasks. The main goal of UBL package is to\nfacilitate the utility-based predictive analytic task by providing a set of\nmethods to deal with this type of problems in the R environment. It is a\nversatile tool that provides mechanisms to handle both regression and\nclassification (binary and multiclass) tasks. Moreover, UBL package allows the\nuser to specify his domain preferences, but it also provides some automatic\nmethods that try to infer those preference bias from the domain, considering\nsome common known settings.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.08079v2"
    },
    {
        "title": "Computing hypergeometric functions rigorously",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present an efficient implementation of hypergeometric functions in\narbitrary-precision interval arithmetic. The functions ${}_0F_1$, ${}_1F_1$,\n${}_2F_1$ and ${}_2F_0$ (or the Kummer $U$-function) are supported for\nunrestricted complex parameters and argument, and by extension, we cover\nexponential and trigonometric integrals, error functions, Fresnel integrals,\nincomplete gamma and beta functions, Bessel functions, Airy functions, Legendre\nfunctions, Jacobi polynomials, complete elliptic integrals, and other special\nfunctions. The output can be used directly for interval computations or to\ngenerate provably correct floating-point approximations in any format.\nPerformance is competitive with earlier arbitrary-precision software, and\nsometimes orders of magnitude faster. We also partially cover the generalized\nhypergeometric function ${}_pF_q$ and computation of high-order parameter\nderivatives.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.06977v2"
    },
    {
        "title": "High-Performance Tensor Contraction without Transposition",
        "authors": [
            "Devin A. Matthews"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Tensor computations--in particular tensor contraction (TC)--are important\nkernels in many scientific computing applications. Due to the fundamental\nsimilarity of TC to matrix multiplication (MM) and to the availability of\noptimized implementations such as the BLAS, tensor operations have\ntraditionally been implemented in terms of BLAS operations, incurring both a\nperformance and a storage overhead. Instead, we implement TC using the flexible\nBLIS framework, which allows for transposition (reshaping) of the tensor to be\nfused with internal partitioning and packing operations, requiring no explicit\ntransposition operations or additional workspace. This implementation, TBLIS,\nachieves performance approaching that of MM, and in some cases considerably\nhigher than that of traditional TC. Our implementation supports multithreading\nusing an approach identical to that used for MM in BLIS, with similar\nperformance characteristics. The complexity of managing tensor-to-matrix\ntransformations is also handled automatically in our approach, greatly\nsimplifying its use in scientific applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.00291v4"
    },
    {
        "title": "PRIMME_SVDS: A High-Performance Preconditioned SVD Solver for Accurate\n  Large-Scale Computations",
        "authors": [
            "Lingfei Wu",
            "Eloy Romero",
            "Andreas Stathopoulos"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  The increasing number of applications requiring the solution of large scale\nsingular value problems have rekindled interest in iterative methods for the\nSVD. Some promising recent ad- vances in large scale iterative methods are\nstill plagued by slow convergence and accuracy limitations for computing\nsmallest singular triplets. Furthermore, their current implementations in\nMATLAB cannot address the required large problems. Recently, we presented a\npreconditioned, two-stage method to effectively and accurately compute a small\nnumber of extreme singular triplets. In this research, we present a\nhigh-performance software, PRIMME SVDS, that implements our hybrid method based\non the state-of-the-art eigensolver package PRIMME for both largest and\nsmallest singular values. PRIMME SVDS fills a gap in production level software\nfor computing the partial SVD, especially with preconditioning. The numerical\nexperiments demonstrate its superior performance compared to other\nstate-of-the-art software and its good parallel performance under strong and\nweak scaling.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.01404v2"
    },
    {
        "title": "Accelerating eigenvector and pseudospectra computation using blocked\n  multi-shift triangular solves",
        "authors": [
            "Tim Moon",
            "Jack Poulson"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Multi-shift triangular solves are basic linear algebra calculations with\napplications in eigenvector and pseudospectra computation. We propose blocked\nalgorithms that efficiently exploit Level 3 BLAS to perform multi-shift\ntriangular solves and safe multi-shift triangular solves. Numerical experiments\nindicate that computing triangular eigenvectors with a safe multi-shift\ntriangular solve achieves speedups by a factor of 60 relative to LAPACK. This\nalgorithm accelerates the calculation of general eigenvectors threefold. When\nusing multi-shift triangular solves to compute pseudospectra, we report\nninefold speedups relative to EigTool.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.01477v2"
    },
    {
        "title": "Julia Implementation of the Dynamic Distributed Dimensional Data Model",
        "authors": [
            "Alexander Chen",
            "Alan Edelman",
            "Jeremy Kepner",
            "Vijay Gadepally",
            "Dylan Hutchison"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Julia is a new language for writing data analysis programs that are easy to\nimplement and run at high performance. Similarly, the Dynamic Distributed\nDimensional Data Model (D4M) aims to clarify data analysis operations while\nretaining strong performance. D4M accomplishes these goals through a\ncomposable, unified data model on associative arrays. In this work, we present\nan implementation of D4M in Julia and describe how it enables and facilitates\ndata analysis. Several experiments showcase scalable performance in our new\nJulia version as compared to the original Matlab implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.04041v1"
    },
    {
        "title": "GTApprox: surrogate modeling for industrial design",
        "authors": [
            "Mikhail Belyaev",
            "Evgeny Burnaev",
            "Ermek Kapushev",
            "Maxim Panov",
            "Pavel Prikhodko",
            "Dmitry Vetrov",
            "Dmitry Yarotsky"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We describe GTApprox - a new tool for medium-scale surrogate modeling in\nindustrial design. Compared to existing software, GTApprox brings several\ninnovations: a few novel approximation algorithms, several advanced methods of\nautomated model selection, novel options in the form of hints. We demonstrate\nthe efficiency of GTApprox on a large collection of test problems. In addition,\nwe describe several applications of GTApprox to real engineering problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.01088v1"
    },
    {
        "title": "OpenSBLI: A framework for the automated derivation and parallel\n  execution of finite difference solvers on a range of computer architectures",
        "authors": [
            "Christian T. Jacobs",
            "Satya P. Jammy",
            "Neil D. Sandham"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Exascale computing will feature novel and potentially disruptive hardware\narchitectures. Exploiting these to their full potential is non-trivial.\nNumerical modelling frameworks involving finite difference methods are\ncurrently limited by the 'static' nature of the hand-coded discretisation\nschemes and repeatedly may have to be re-written to run efficiently on new\nhardware. In contrast, OpenSBLI uses code generation to derive the model's code\nfrom a high-level specification. Users focus on the equations to solve, whilst\nnot concerning themselves with the detailed implementation. Source-to-source\ntranslation is used to tailor the code and enable its execution on a variety of\nhardware.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.01277v2"
    },
    {
        "title": "A Java library to perform S-expansions of Lie algebras",
        "authors": [
            "C. Inostroza",
            "I. Kondrashuk",
            "N. Merino",
            "F. Nadal"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The contraction method is a procedure that allows to establish non-trivial\nrelations between Lie algebras and has had succesful applications in both\nmathematics and theoretical physics. This work deals with generalizations of\nthe contraction procedure with a main focus in the so called S-expansion method\nas it includes most of the other generalized contractions. Basically, the\nS-exansion combines a Lie algebra $\\mathcal{G}$ with a finite abelian semigroup\n$S$ in order to define new S-expanded algebras. After giving a description of\nthe main ingredients used in this paper, we present a Java library that\nautomatizes the S-expansion procedure. With this computational tool we are able\nto represent Lie algebras and semigroups, so we can perform S-expansions of Lie\nalgebras using arbitrary semigroups. We explain how the library methods has\nbeen constructed and how they work; then we give a set of example programs\naimed to solve different problems. They are presented so that any user can\neasily modify them to perform his own calculations, without being necessarily\nan expert in Java. Finally, some comments about further developements and\npossible new applications are made.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.04036v2"
    },
    {
        "title": "A GPU-based Multi-level Algorithm for Boundary Value Problems",
        "authors": [
            "J. T. Becerra-Sagredo",
            "F. Mandujano",
            "C. Malaga"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  A novel and scalable geometric multi-level algorithm is presented for the\nnumerical solution of elliptic partial differential equations, specially\ndesigned to run with high occupancy of streaming processors inside Graphics\nProcessing Units(GPUs). The algorithm consists of iterative, superposed\noperations on a single grid, and it is composed of two simple full-grid\nroutines: a restriction and a coarsened interpolation-relaxation. The\nrestriction is used to collect sources using recursive coarsened averages, and\nthe interpolation-relaxation simultaneously applies coarsened finite-difference\noperators and interpolations. The routines are scheduled in a saw-like refining\ncycle. Convergence to machine precision is achieved repeating the full cycle\nusing accumulated residuals and successively collecting the solution. Its total\nnumber of operations scale linearly with the number of nodes. It provides an\nattractive fast solver for Boundary Value Problems (BVPs), specially for\nsimulations running entirely in the GPU. Applications shown in this work\ninclude the deformation of two-dimensional grids, the computation of\nthree-dimensional streamlines for a singular trifoil-knot vortex and the\ncalculation of three-dimensional electric potentials in heterogeneous\ndielectric media.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.07206v1"
    },
    {
        "title": "A Domain-Specific Language and Editor for Parallel Particle Methods",
        "authors": [
            "Sven Karol",
            "Tobias Nett",
            "Jeronimo Castrillon",
            "Ivo F. Sbalzarini"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Domain-specific languages (DSLs) are of increasing importance in scientific\nhigh-performance computing to reduce development costs, raise the level of\nabstraction and, thus, ease scientific programming. However, designing and\nimplementing DSLs is not an easy task, as it requires knowledge of the\napplication domain and experience in language engineering and compilers.\nConsequently, many DSLs follow a weak approach using macros or text generators,\nwhich lack many of the features that make a DSL a comfortable for programmers.\nSome of these features---e.g., syntax highlighting, type inference, error\nreporting, and code completion---are easily provided by language workbenches,\nwhich combine language engineering techniques and tools in a common ecosystem.\nIn this paper, we present the Parallel Particle-Mesh Environment (PPME), a DSL\nand development environment for numerical simulations based on particle methods\nand hybrid particle-mesh methods. PPME uses the meta programming system (MPS),\na projectional language workbench. PPME is the successor of the Parallel\nParticle-Mesh Language (PPML), a Fortran-based DSL that used conventional\nimplementation strategies. We analyze and compare both languages and\ndemonstrate how the programmer's experience can be improved using static\nanalyses and projectional editing. Furthermore, we present an explicit domain\nmodel for particle abstractions and the first formal type system for particle\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.00032v2"
    },
    {
        "title": "HPTT: A High-Performance Tensor Transposition C++ Library",
        "authors": [
            "Paul Springer",
            "Tong Su",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Recently we presented TTC, a domain-specific compiler for tensor\ntranspositions. Despite the fact that the performance of the generated code is\nnearly optimal, due to its offline nature, TTC cannot be utilized in all the\napplication codes in which the tensor sizes and the necessary tensor\npermutations are determined at runtime. To overcome this limitation, we\nintroduce the open-source C++ library High-Performance Tensor Transposition\n(HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking,\nmulti-threading, and explicit vectorization; furthermore it decomposes any\ntransposition into multiple loops around a so called micro-kernel. This modular\ndesign---inspired by BLIS---makes HPTT easy to port to different architectures,\nby only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose).\nHPTT also offers an optional autotuning framework---guided by a performance\nmodel---that explores a vast search space of implementations at runtime\n(similar to FFTW). Across a wide range of different tensor transpositions and\narchitectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM\nPower7), HPTT attains a bandwidth comparable to that of SAXPY, and yields\nremarkable speedups over Eigen's tensor transposition implementation. Most\nimportantly, the integration of HPTT into the Cyclops Tensor Framework (CTF)\nimproves the overall performance of tensor contractions by up to 3.1x.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.04374v2"
    },
    {
        "title": "Particle-based and Meshless Methods with Aboria",
        "authors": [
            "Martin Robinson",
            "Maria Bruna"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Aboria is a powerful and flexible C++ library for the implementation of\nparticle-based numerical methods. The particles in such methods can represent\nactual particles (e.g. Molecular Dynamics) or abstract particles used to\ndiscretise a continuous function over a domain (e.g. Radial Basis Functions).\nAboria provides a particle container, compatible with the Standard Template\nLibrary, spatial search data structures, and a Domain Specific Language to\nspecify non-linear operators on the particle set. This paper gives an overview\nof Aboria's design, an example of use, and a performance benchmark.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.08907v2"
    },
    {
        "title": "CLBlast: A Tuned OpenCL BLAS Library",
        "authors": [
            "Cedric Nugteren"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  This work introduces CLBlast, an open-source BLAS library providing optimized\nOpenCL routines to accelerate dense linear algebra for a wide variety of\ndevices. It is targeted at machine learning and HPC applications and thus\nprovides a fast matrix-multiplication routine (GEMM) to accelerate the core of\nmany applications (e.g. deep learning, iterative solvers, astrophysics,\ncomputational fluid dynamics, quantum chemistry). CLBlast has five main\nadvantages over other OpenCL BLAS libraries: 1) it is optimized for and tested\non a large variety of OpenCL devices including less commonly used devices such\nas embedded and low-power GPUs, 2) it can be explicitly tuned for specific\nproblem-sizes on specific hardware platforms, 3) it can perform operations in\nhalf-precision floating-point FP16 saving bandwidth, time and energy, 4) it has\nan optional CUDA back-end, 5) and it can combine multiple operations in a\nsingle batched routine, accelerating smaller problems significantly. This paper\ndescribes the library and demonstrates the advantages of CLBlast experimentally\nfor different use-cases on a wide variety of OpenCL hardware.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.05249v2"
    },
    {
        "title": "Designing and building the mlpack open-source machine learning library",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  mlpack is an open-source C++ machine learning library with an emphasis on\nspeed and flexibility. Since its original inception in 2007, it has grown to be\na large project implementing a wide variety of machine learning algorithms,\nfrom standard techniques such as decision trees and logistic regression to\nmodern techniques such as deep neural networks as well as other\nrecently-published cutting-edge techniques not found in any other library.\nmlpack is quite fast, with benchmarks showing mlpack outperforming other\nlibraries' implementations of the same methods. mlpack has an active community,\nwith contributors from around the world---including some from PUST. This short\npaper describes the goals and design of mlpack, discusses how the open-source\ncommunity functions, and shows an example usage of mlpack for a simple data\nscience problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.05279v2"
    },
    {
        "title": "Energy efficiency of finite difference algorithms on multicore CPUs,\n  GPUs, and Intel Xeon Phi processors",
        "authors": [
            "Satya P. Jammy",
            "Christian T. Jacobs",
            "David J. Lusher",
            "Neil D. Sandham"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  In addition to hardware wall-time restrictions commonly seen in\nhigh-performance computing systems, it is likely that future systems will also\nbe constrained by energy budgets. In the present work, finite difference\nalgorithms of varying computational and memory intensity are evaluated with\nrespect to both energy efficiency and runtime on an Intel Ivy Bridge CPU node,\nan Intel Xeon Phi Knights Landing processor, and an NVIDIA Tesla K40c GPU. The\nconventional way of storing the discretised derivatives to global arrays for\nsolution advancement is found to be inefficient in terms of energy consumption\nand runtime. In contrast, a class of algorithms in which the discretised\nderivatives are evaluated on-the-fly or stored as thread-/process-local\nvariables (yielding high compute intensity) is optimal both with respect to\nenergy consumption and runtime. On all three hardware architectures considered,\na speed-up of ~2 and an energy saving of ~2 are observed for the high compute\nintensive algorithms compared to the memory intensive algorithm. The energy\nconsumption is found to be proportional to runtime, irrespective of the power\nconsumed and the GPU has an energy saving of ~5 compared to the same algorithm\non a CPU node.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.09713v1"
    },
    {
        "title": "Performance Optimization and Parallelization of a Parabolic Equation\n  Solver in Computational Ocean Acoustics on Modern Many-core Computer",
        "authors": [
            "Min Xu",
            "Yongxian Wang",
            "Anthony Theodore Chronopoulos",
            "Hao Yue"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  As one of open-source codes widely used in computational ocean acoustics,\nFOR3D can provide a very good estimate for underwater acoustic propagation. In\nthis paper, we propose a performance optimization and parallelization to speed\nup the running of FOR3D. We utilized a variety of methods to enhance the entire\nperformance, such as using a multi-threaded programming model to exploit the\npotential capability of the many-core node of high-performance computing (HPC)\nsystem, tuning compile options, using efficient tuned mathematical library and\nutilizing vectorization optimization instruction. In addition, we extended the\napplication from single-frequency calculation to multi-frequency calculation\nsuccessfully by using OpenMP+MPI hybrid programming techniques on the\nmainstream HPC platform. A detailed performance evaluation was performed and\nthe results showed that the proposed parallelization obtained good accelerated\neffect of 25.77X when testing a typical three-dimensional medium-sized case on\nTianhe-2 supercomputer. It also showed that the tuned parallel version has a\nweak-scalability. The speed of calculation of underwater sound field can be\ngreatly improved by the strategy mentioned in this paper. The method used in\nthis paper is not only applicable to other similar computing models in\ncomputational ocean acoustics but also a guideline of performance enhancement\nfor scientific and engineering application running on modern\nmany-core-computing platform.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.00005v2"
    },
    {
        "title": "Fast matrix-free evaluation of discontinuous Galerkin finite element\n  operators",
        "authors": [
            "Martin Kronbichler",
            "Katharina Kormann"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We present an algorithmic framework for matrix-free evaluation of\ndiscontinuous Galerkin finite element operators based on sum factorization on\nquadrilateral and hexahedral meshes. We identify a set of kernels for fast\nquadrature on cells and faces targeting a wide class of weak forms originating\nfrom linear and nonlinear partial differential equations. Different algorithms\nand data structures for the implementation of operator evaluation are compared\nin an in-depth performance analysis. The sum factorization kernels are\noptimized by vectorization over several cells and faces and an even-odd\ndecomposition of the one-dimensional compute kernels. In isolation our\nimplementation then reaches up to 60\\% of arithmetic peak on Intel Haswell and\nBroadwell processors and up to 50\\% of arithmetic peak on Intel Knights\nLanding. The full operator evaluation reaches only about half that throughput\ndue to memory bandwidth limitations from loading the input and output vectors,\nMPI ghost exchange, as well as handling variable coefficients and the geometry.\nOur performance analysis shows that the results are often within 10\\% of the\navailable memory bandwidth for the proposed implementation, with the exception\nof the Cartesian mesh case where the cost of gather operations and MPI\ncommunication are more substantial.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.03590v1"
    },
    {
        "title": "Domain-Specific Acceleration and Auto-Parallelization of Legacy\n  Scientific Code in FORTRAN 77 using Source-to-Source Compilation",
        "authors": [
            "Wim Vanderbauwhede",
            "Gavin Davidson"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Massively parallel accelerators such as GPGPUs, manycores and FPGAs represent\na powerful and affordable tool for scientists who look to speed up simulations\nof complex systems. However, porting code to such devices requires a detailed\nunderstanding of heterogeneous programming tools and effective strategies for\nparallelization. In this paper we present a source to source compilation\napproach with whole-program analysis to automatically transform single-threaded\nFORTRAN 77 legacy code into OpenCL-accelerated programs with parallelized\nkernels.\n  The main contributions of our work are: (1) whole-source refactoring to allow\nany subroutine in the code to be offloaded to an accelerator. (2) Minimization\nof the data transfer between the host and the accelerator by eliminating\nredundant transfers. (3) Pragmatic auto-parallelization of the code to be\noffloaded to the accelerator by identification of parallelizable maps and\nreductions.\n  We have validated the code transformation performance of the compiler on the\nNIST FORTRAN 78 test suite and several real-world codes: the Large Eddy\nSimulator for Urban Flows, a high-resolution turbulent flow model; the shallow\nwater component of the ocean model Gmodel; the Linear Baroclinic Model, an\natmospheric climate model and Flexpart-WRF, a particle dispersion simulator.\n  The automatic parallelization component has been tested on as 2-D Shallow\nWater model (2DSW) and on the Large Eddy Simulator for Urban Flows (UFLES) and\nproduces a complete OpenCL-enabled code base. The fully OpenCL-accelerated\nversions of the 2DSW and the UFLES are resp. 9x and 20x faster on GPU than the\noriginal code on CPU, in both cases this is the same performance as manually\nported code.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.04471v1"
    },
    {
        "title": "Hydra: a C++11 framework for data analysis in massively parallel\n  platforms",
        "authors": [
            "A. A. Alves Jr",
            "M. D. Sokoloff"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Hydra is a header-only, templated and C++11-compliant framework designed to\nperform the typical bottleneck calculations found in common HEP data analyses\non massively parallel platforms. The framework is implemented on top of the\nC++11 Standard Library and a variadic version of the Thrust library and is\ndesigned to run on Linux systems, using OpenMP, CUDA and TBB enabled devices.\nThis contribution summarizes the main features of Hydra. A basic description of\nthe overall design, functionality and user interface is provided, along with\nsome code examples and measurements of performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.05683v2"
    },
    {
        "title": "A generic and fast C++ optimization framework",
        "authors": [
            "Ryan R. Curtin",
            "Shikhar Bhardwaj",
            "Marcus Edel",
            "Yannis Mentekidis"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The development of the mlpack C++ machine learning library\n(http://www.mlpack.org/) has required the design and implementation of a\nflexible, robust optimization system that is able to solve the types of\narbitrary optimization problems that may arise all throughout machine learning\nproblems. In this paper, we present the generic optimization framework that we\nhave designed for mlpack. A key priority in the design was ease of\nimplementation of both new optimizers and new objective functions to be\noptimized; therefore, implementation of a new optimizer requires only one\nmethod and implementation of a new objective function requires at most four\nfunctions. This leads to simple and intuitive code, which, for fast prototyping\nand experimentation, is of paramount importance. When compared to optimization\nframeworks of other libraries, we find that mlpack's supports more types of\nobjective functions, is able to make optimizations that other frameworks do\nnot, and seamlessly supports user-defined objective functions and optimizers.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.06581v1"
    },
    {
        "title": "PhasePack User Guide",
        "authors": [
            "Rohan Chandra",
            "Ziyuan Zhong",
            "Justin Hontz",
            "Val McCulloch",
            "Christoph Studer",
            "Tom Goldstein"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  \"Phase retrieval\" refers to the recovery of signals from the magnitudes (and\nnot the phases) of linear measurements. While there has been a recent explosion\nin development of phase retrieval methods, the lack of a common interface has\nmade it difficult to compare new methods against the current state-of-the-art.\nPhasePack is a software library that creates a common interface for a wide\nrange of phase retrieval schemes. PhasePack also provides a test bed for phase\nretrieval methods using both synthetic data and publicly available empirical\ndatasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09777v3"
    },
    {
        "title": "Efficiently and easily integrating differential equations with JiTCODE,\n  JiTCDDE, and JiTCSDE",
        "authors": [
            "Gerrit Ansmann"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We present a family of Python modules for the numerical integration of\nordinary, delay, or stochastic differential equations. The key features are\nthat the user enters the derivative symbolically and it is\njust-in-time-compiled, allowing the user to efficiently integrate differential\nequations from a higher-level interpreted language. The presented modules are\nparticularly suited for large systems of differential equations such as used to\ndescribe dynamics on complex networks. Through the selected method of input,\nthe presented modules also allow to almost completely automatize the process of\nestimating regular as well as transversal Lyapunov exponents for ordinary and\ndelay differential equations. We conceptually discuss the modules' design,\nanalyze their performance, and demonstrate their capabilities by application to\ntimely problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09886v2"
    },
    {
        "title": "In a Nutshell -- The Sequential Parameter Optimization Toolbox",
        "authors": [
            "Thomas Bartz-Beielstein",
            "Martin Zaefferer",
            "Frederik Rehbach"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The performance of optimization algorithms relies crucially on their\nparameterizations. Finding good parameter settings is called algorithm tuning.\nThe sequential parameter optimization (SPOT) package for R is a toolbox for\ntuning and understanding simulation and optimization algorithms. Model-based\ninvestigations are common approaches in simulation and optimization. Sequential\nparameter optimization has been developed, because there is a strong need for\nsound statistical analysis of simulation and optimization algorithms. SPOT\nincludes methods for tuning based on classical regression and analysis of\nvariance techniques; tree-based models such as CART and random forest; Gaussian\nprocess models (Kriging), and combinations of different meta-modeling\napproaches. Using a simple simulated annealing algorithm, we will demonstrate\nhow optimization algorithms can be tuned using SPOT. The underling concepts of\nthe SPOT approach are explained. This includes key techniques such as\nexploratory fitness landscape analysis and sensititvity analysis. Many examples\nillustrate how SPOT can be used for understanding the performance of algorithms\nand gaining insight into algorithm's behavior. Furthermore, we demonstrate how\nSPOT can be used as an optimizer and how a sophisticated ensemble approach is\nable to combine several meta models via stacking. This article exemplifies how\nSPOT can be used for automatic and interactive tuning.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04076v2"
    },
    {
        "title": "MPI+X: task-based parallelization and dynamic load balance of finite\n  element assembly",
        "authors": [
            "Marta Garcia-Gasulla",
            "Guillaume Houzeaux",
            "Roger Ferrer",
            "Antoni Artigues",
            "Victor López",
            "Jesús Labarta",
            "Mariano Vázquez"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The main computing tasks of a finite element code(FE) for solving partial\ndifferential equations (PDE's) are the algebraic system assembly and the\niterative solver. This work focuses on the first task, in the context of a\nhybrid MPI+X paradigm. Although we will describe algorithms in the FE context,\na similar strategy can be straightforwardly applied to other discretization\nmethods, like the finite volume method. The matrix assembly consists of a loop\nover the elements of the MPI partition to compute element matrices and\nright-hand sides and their assemblies in the local system to each MPI\npartition. In a MPI+X hybrid parallelism context, X has consisted traditionally\nof loop parallelism using OpenMP. Several strategies have been proposed in the\nliterature to implement this loop parallelism, like coloring or substructuring\ntechniques to circumvent the race condition that appears when assembling the\nelement system into the local system. The main drawback of the first technique\nis the decrease of the IPC due to bad spatial locality. The second technique\navoids this issue but requires extensive changes in the implementation, which\ncan be cumbersome when several element loops should be treated. We propose an\nalternative, based on the task parallelism of the element loop using some\nextensions to the OpenMP programming model. The taskification of the assembly\nsolves both aforementioned problems. In addition, dynamic load balance will be\napplied using the DLB library, especially efficient in the presence of hybrid\nmeshes, where the relative costs of the different elements is impossible to\nestimate a priori. This paper presents the proposed methodology, its\nimplementation and its validation through the solution of large computational\nmechanics problems up to 16k cores.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.03949v1"
    },
    {
        "title": "CUDACLAW: A high-performance programmable GPU framework for the solution\n  of hyperbolic PDEs",
        "authors": [
            "H. Gorune Ohannessian",
            "George Turkiyyah",
            "Aron Ahmadia",
            "David Ketcheson"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We present cudaclaw, a CUDA-based high performance data-parallel framework\nfor the solution of multidimensional hyperbolic partial differential equation\n(PDE) systems, equations describing wave motion. cudaclaw allows computational\nscientists to solve such systems on GPUs without being burdened by the need to\nwrite CUDA code, worry about thread and block details, data layout, and data\nmovement between the different levels of the memory hierarchy. The user defines\nthe set of PDEs to be solved via a CUDA- independent serial Riemann solver and\nthe framework takes care of orchestrating the computations and data transfers\nto maximize arithmetic throughput. cudaclaw treats the different spatial\ndimensions separately to allow suitable block sizes and dimensions to be used\nin the different directions, and includes a number of optimizations to minimize\naccess to global memory.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.08846v1"
    },
    {
        "title": "COREclust: a new package for a robust and scalable analysis of complex\n  data",
        "authors": [
            "Camille Champion",
            "Anne-Claire Brunet",
            "Jean-Michel Loubes",
            "Laurent Risser"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this paper, we present a new R package COREclust dedicated to the\ndetection of representative variables in high dimensional spaces with a\npotentially limited number of observations. Variable sets detection is based on\nan original graph clustering strategy denoted CORE-clustering algorithm that\ndetects CORE-clusters, i.e. variable sets having a user defined size range and\nin which each variable is very similar to at least another variable.\nRepresentative variables are then robustely estimate as the CORE-cluster\ncenters. This strategy is entirely coded in C++ and wrapped by R using the Rcpp\npackage. A particular effort has been dedicated to keep its algorithmic cost\nreasonable so that it can be used on large datasets. After motivating our work,\nwe will explain the CORE-clustering algorithm as well as a greedy extension of\nthis algorithm. We will then present how to use it and results obtained on\nsynthetic and real data.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10211v1"
    },
    {
        "title": "ensmallen: a flexible C++ library for efficient function optimization",
        "authors": [
            "Shikhar Bhardwaj",
            "Ryan R. Curtin",
            "Marcus Edel",
            "Yannis Mentekidis",
            "Conrad Sanderson"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We present ensmallen, a fast and flexible C++ library for mathematical\noptimization of arbitrary user-supplied functions, which can be applied to many\nmachine learning problems. Several types of optimizations are supported,\nincluding differentiable, separable, constrained, and categorical objective\nfunctions. The library provides many pre-built optimizers (including numerous\nvariants of SGD and Quasi-Newton optimizers) as well as a flexible framework\nfor implementing new optimizers and objective functions. Implementation of a\nnew optimizer requires only one method and a new objective function requires\ntypically one or two C++ functions. This can aid in the quick implementation\nand prototyping of new machine learning algorithms. Due to the use of C++\ntemplate metaprogramming, ensmallen is able to support compiler optimizations\nthat provide fast runtimes. Empirical comparisons show that ensmallen is able\nto outperform other optimization frameworks (like Julia and SciPy), sometimes\nby large margins. The library is distributed under the BSD license and is ready\nfor use in production environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.09361v2"
    },
    {
        "title": "Efficient and scalable data structures and algorithms for goal-oriented\n  adaptivity of space-time FEM codes",
        "authors": [
            "Uwe Köcher",
            "Marius Paul Bruchhäuser",
            "Markus Bause"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The cost- and memory-efficient numerical simulation of coupled volume-based\nmulti-physics problems like flow, transport, wave propagation and others\nremains a challenging task with finite element method (FEM) approaches.\nGoal-oriented space and time adaptive methods derived from the dual weighted\nresidual (DWR) method appear to be a shiny key technology to generate optimal\nspace-time meshes to minimise costs. Current implementations for challenging\nproblems of numerical screening tools including the DWR technology broadly\nsuffer in their extensibility to other problems, in high memory consumption or\nin missing system solver technologies. This work contributes to the efficient\nembedding of DWR space-time adaptive methods into numerical screening tools for\nchallenging problems of physically relevance with a new approach of flexible\ndata structures and algorithms on them, a modularised and complete\nimplementation as well as illustrative examples to show the performance and\nefficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.08558v1"
    },
    {
        "title": "GPU-accelerating ImageJ Macro image processing workflows using CLIJ",
        "authors": [
            "Daniela Vorkel",
            "Robert Haase"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This chapter introduces GPU-accelerated image processing in ImageJ/FIJI. The\nreader is expected to have some pre-existing knowledge of ImageJ Macro\nprogramming. Core concepts such as variables, for-loops, and functions are\nessential. The chapter provides basic guidelines for improved performance in\ntypical image processing workflows. We present in a step-by-step tutorial how\nto translate a pre-existing ImageJ macro into a GPU-accelerated macro.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.11799v1"
    },
    {
        "title": "Performance Portability Study of Linear Algebra Kernels in OpenCL",
        "authors": [
            "Karl Rupp",
            "Philippe Tillet",
            "Florian Rudolf",
            "Josef Weinbub",
            "Tibor Grasser",
            "Ansgar Jüngel"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The performance portability of OpenCL kernel implementations for common\nmemory bandwidth limited linear algebra operations across different hardware\ngenerations of the same vendor as well as across vendors is studied. Certain\ncombinations of kernel implementations and work sizes are found to exhibit good\nperformance across compute kernels, hardware generations, and, to a lesser\ndegree, vendors. As a consequence, it is demonstrated that the optimization of\na single kernel is often sufficient to obtain good performance for a large\nclass of more complicated operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.0669v1"
    },
    {
        "title": "A toolbox of Equation-Free functions in Matlab\\Octave for efficient\n  system level simulation",
        "authors": [
            "John Maclean",
            "J. E. Bunder",
            "A. J. Roberts"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The `equation-free toolbox' empowers the computer-assisted analysis of\ncomplex, multiscale systems. Its aim is to enable you to immediately use\nmicroscopic simulators to perform macro-scale system level tasks and analysis,\nbecause micro-scale simulations are often the best available description of a\nsystem. The methodology bypasses the derivation of macroscopic evolution\nequations by computing the micro-scale simulator only over short bursts in time\non small patches in space, with bursts and patches well-separated in time and\nspace respectively. We introduce the suite of coded equation-free functions in\nan accessible way, link to more detailed descriptions, discuss their\nmathematical support, and introduce a novel and efficient algorithm for\nProjective Integration. Some facets of toolbox development of equation-free\nfunctions are then detailed. Download the toolbox functions\n(https://github.com/uoa1184615/EquationFreeGit) and use to empower efficient\nand accurate simulation in a wide range of your science and engineering\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.01895v2"
    },
    {
        "title": "hyper.deal: An efficient, matrix-free finite-element library for\n  high-dimensional partial differential equations",
        "authors": [
            "Peter Munch",
            "Katharina Kormann",
            "Martin Kronbichler"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This work presents the efficient, matrix-free finite-element library\nhyper.deal for solving partial differential equations in two to six dimensions\nwith high-order discontinuous Galerkin methods. It builds upon the\nlow-dimensional finite-element library deal.II to create complex\nlow-dimensional meshes and to operate on them individually. These meshes are\ncombined via a tensor product on the fly and the library provides new\nspecial-purpose highly optimized matrix-free functions exploiting domain\ndecomposition as well as shared memory via MPI-3.0 features. Both node-level\nperformance analyses and strong/weak-scaling studies on up to 147,456 CPU cores\nconfirm the efficiency of the implementation. Results of the library hyper.deal\nare reported for high-dimensional advection problems and for the solution of\nthe Vlasov--Poisson equation in up to 6D phase space.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08110v1"
    },
    {
        "title": "Supporting 64-bit global indices in Epetra and other Trilinos packages\n  -- Techniques used and lessons learned",
        "authors": [
            "Chetan Jhurani",
            "Travis M. Austin",
            "Michael A. Heroux",
            "James M. Willenbring"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  The Trilinos Project is an effort to facilitate the design, development,\nintegration and ongoing support of mathematical software libraries within an\nobject-oriented framework. It is intended for large-scale, complex multiphysics\nengineering and scientific applications. Epetra is one of its basic packages.\nIt provides serial and parallel linear algebra capabilities. Before Trilinos\nversion 11.0, released in 2012, Epetra used the C++ int data-type for storing\nglobal and local indices for degrees of freedom (DOFs). Since int is typically\n32-bit, this limited the largest problem size to be smaller than approximately\ntwo billion DOFs. This was true even if a distributed memory machine could\nhandle larger problems. We have added optional support for C++ long long\ndata-type, which is at least 64-bit wide, for global indices. To save memory,\nmaintain the speed of memory-bound operations, and reduce further changes to\nthe code, the local indices are still 32-bit. We document the changes required\nto achieve this feature and how the new functionality can be used. We also\nreport on the lessons learned in modifying a mature and popular package from\nvarious perspectives -- design goals, backward compatibility, engineering\ndecisions, C++ language features, effects on existing users and other packages,\nand build integration.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.6638v1"
    },
    {
        "title": "An Optimized and Scalable Eigensolver for Sequences of Eigenvalue\n  Problems",
        "authors": [
            "Mario Berljafa",
            "Daniel Wortmann",
            "Edoardo Di Napoli"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  In many scientific applications the solution of non-linear differential\nequations are obtained through the set-up and solution of a number of\nsuccessive eigenproblems. These eigenproblems can be regarded as a sequence\nwhenever the solution of one problem fosters the initialization of the next. In\naddition, in some eigenproblem sequences there is a connection between the\nsolutions of adjacent eigenproblems. Whenever it is possible to unravel the\nexistence of such a connection, the eigenproblem sequence is said to be\ncorrelated. When facing with a sequence of correlated eigenproblems the current\nstrategy amounts to solving each eigenproblem in isolation. We propose a\nalternative approach which exploits such correlation through the use of an\neigensolver based on subspace iteration and accelerated with Chebyshev\npolynomials (ChFSI). The resulting eigensolver is optimized by minimizing the\nnumber of matrix-vector multiplications and parallelized using the Elemental\nlibrary framework. Numerical results show that ChFSI achieves excellent\nscalability and is competitive with current dense linear algebra parallel\neigensolvers.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4161v2"
    },
    {
        "title": "Unstructured Overlapping Mesh Distribution in Parallel",
        "authors": [
            "Matthew G. Knepley",
            "Michael Lange",
            "Gerard J. Gorman"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We present a simple mathematical framework and API for parallel mesh and data\ndistribution, load balancing, and overlap generation. It relies on viewing the\nmesh as a Hasse diagram, abstracting away information such as cell shape,\ndimension, and coordinates. The high level of abstraction makes our interface\nboth concise and powerful, as the same algorithm applies to any representable\nmesh, such as hybrid meshes, meshes embedded in higher dimension, and\noverlapped meshes in parallel. We present evidence, both theoretical and\nexperimental, that the algorithms are scalable and efficient. A working\nimplementation can be found in the latest release of the PETSc libraries.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.06194v1"
    },
    {
        "title": "Enhancing speed and scalability of the ParFlow simulation code",
        "authors": [
            "Carsten Burstedde",
            "Jose A. Fonseca",
            "Stefan Kollet"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Regional hydrology studies are often supported by high resolution simulations\nof subsurface flow that require expensive and extensive computations. Efficient\nusage of the latest high performance parallel computing systems becomes a\nnecessity. The simulation software ParFlow has been demonstrated to meet this\nrequirement and shown to have excellent solver scalability for up to 16,384\nprocesses. In the present work we show that the code requires further\nenhancements in order to fully take advantage of current petascale machines. We\nidentify ParFlow's way of parallelization of the computational mesh as a\ncentral bottleneck. We propose to reorganize this subsystem using fast mesh\npartition algorithms provided by the parallel adaptive mesh refinement library\np4est. We realize this in a minimally invasive manner by modifying selected\nparts of the code to reinterpret the existing mesh data structures. We evaluate\nthe scaling performance of the modified version of ParFlow, demonstrating good\nweak and strong scaling up to 458k cores of the Juqueen supercomputer, and test\nan example application at large scale.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.06898v2"
    },
    {
        "title": "HPC optimal parallel communication algorithm for the simulation of\n  fractional-order systems",
        "authors": [
            "Cosmin Bonchis",
            "Eva Kaslik",
            "Florin Rosu"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  A parallel numerical simulation algorithm is presented for fractional-order\nsystems involving Caputo-type derivatives, based on the Adams-Bashforth-Moulton\n(ABM) predictor-corrector scheme. The parallel algorithm is implemented using\nseveral different approaches: a pure MPI version, a combination of MPI with\nOpenMP optimization and a memory saving speedup approach. All tests run on a\nBlueGene/P cluster, and comparative improvement results for the running time\nare provided. As an applied experiment, the solutions of a fractional-order\nversion of a system describing a forced series LCR circuit are numerically\ncomputed, depicting cascades of period-doubling bifurcations which lead to the\nonset of chaotic behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.01133v1"
    },
    {
        "title": "Auto-Differentiating Linear Algebra",
        "authors": [
            "Matthias Seeger",
            "Asmus Hetzel",
            "Zhenwen Dai",
            "Eric Meissner",
            "Neil D. Lawrence"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Development systems for deep learning (DL), such as Theano, Torch,\nTensorFlow, or MXNet, are easy-to-use tools for creating complex neural network\nmodels. Since gradient computations are automatically baked in, and execution\nis mapped to high performance hardware, these models can be trained end-to-end\non large amounts of data. However, it is currently not easy to implement many\nbasic machine learning primitives in these systems (such as Gaussian processes,\nleast squares estimation, principal components analysis, Kalman smoothing),\nmainly because they lack efficient support of linear algebra primitives as\ndifferentiable operators. We detail how a number of matrix decompositions\n(Cholesky, LQ, symmetric eigen) can be implemented as differentiable operators.\nWe have implemented these primitives in MXNet, running on CPU and GPU in single\nand double precision. We sketch use cases of these new operators, learning\nGaussian process and Bayesian linear regression models, where we demonstrate\nvery substantial reductions in implementation complexity and running time\ncompared to previous codes. Our MXNet extension allows end-to-end learning of\nhybrid models, which combine deep neural networks (DNNs) with Bayesian\nconcepts, with applications in advanced Gaussian process models, scalable\nBayesian optimization, and Bayesian active learning.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.08717v5"
    },
    {
        "title": "GooFit 2.0",
        "authors": [
            "Henry Schreiner",
            "Christoph Hasse",
            "Bradley Hittle",
            "Himadri Pandey",
            "Michael Sokoloff",
            "Karen Tomko"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The GooFit package provides physicists a simple, familiar syntax for\nmanipulating probability density functions and performing fits, and is highly\noptimized for data analysis on NVIDIA GPUs and multithreaded CPU backends.\nGooFit was updated to version 2.0, bringing a host of new features. A\ncompletely revamped and redesigned build system makes GooFit easier to install,\ndevelop with, and run on virtually any system. Unit testing, continuous\nintegration, and advanced logging options are improving the stability and\nreliability of the system. Developing new PDFs now uses standard CUDA\nterminology and provides a lower barrier for new users. The system now has\nbuilt-in support for multiple graphics cards or nodes using MPI, and is being\ntested on a wide range of different systems. GooFit also has significant\nimprovements in performance on some GPU architectures due to optimized memory\naccess. Support for time-dependent four-body amplitude analyses has also been\nadded.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.08826v1"
    },
    {
        "title": "SGDLibrary: A MATLAB library for stochastic gradient descent algorithms",
        "authors": [
            "Hiroyuki Kasai"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We consider the problem of finding the minimizer of a function $f:\n\\mathbb{R}^d \\rightarrow \\mathbb{R}$ of the finite-sum form $\\min f(w) =\n1/n\\sum_{i}^n f_i(w)$. This problem has been studied intensively in recent\nyears in the field of machine learning (ML). One promising approach for\nlarge-scale data is to use a stochastic optimization algorithm to solve the\nproblem. SGDLibrary is a readable, flexible and extensible pure-MATLAB library\nof a collection of stochastic optimization algorithms. The purpose of the\nlibrary is to provide researchers and implementers a comprehensive evaluation\nenvironment for the use of these algorithms on various ML problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.10951v2"
    },
    {
        "title": "Exploiting nested task-parallelism in the $\\mathcal{H}-LU$ factorization",
        "authors": [
            "Rocío Carratalá-Sáez",
            "Sven Christophersen",
            "José I. Aliaga",
            "Vicenç Beltran",
            "Steffen Börm",
            "Enrique S. Quintana-Ortí"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We address the parallelization of the LU factorization of hierarchical\nmatrices ($\\mathcal{H}$-matrices) arising from boundary element methods. Our\napproach exploits task-parallelism via the OmpSs programming model and runtime,\nwhich discovers the data-flow parallelism intrinsic to the operation at\nexecution time, via the analysis of data dependencies based on the memory\naddresses of the tasks' operands. This is especially challenging for\n$\\mathcal{H}$-matrices, as the structures containing the data vary in dimension\nduring the execution. We tackle this issue by decoupling the data structure\nfrom that used to detect dependencies. Furthermore, we leverage the support for\nweak operands and early release of dependencies, recently introduced in\nOmpSs-2, to accelerate the execution of parallel codes with nested\ntask-parallelism and fine-grain tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.00874v1"
    },
    {
        "title": "Raising the Performance of the Tinker-HP Molecular Modeling Package\n  [Article v1.0]",
        "authors": [
            "Luc-Henri Jolly",
            "Alejandro Duran",
            "Louis Lagardère",
            "Jay W. Ponder",
            "Pengyu Ren",
            "Jean-Philip Piquemal"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  This living paper reviews the present High Performance Computing (HPC)\ncapabilities of the Tinker-HP molecular modeling package. We focus here on the\nreference, double precision, massively parallel molecular dynamics engine\npresent in Tinker-HP and dedicated to perform large scale simulations. We show\nhow it can be adapted to recent Intel Central Processing Unit (CPU) petascale\narchitectures. First, we discuss the new set of Intel Advanced Vector\nExtensions 512 (Intel AVX-512) instructions present in recent Intel processors\n(e.g., the Intel Xeon Scalable and Intel Xeon Phi 2nd generation processors)\nallowing for larger vectorization enhancements. These instructions constitute\nthe central source of potential computational gains when using the latest\nprocessors, justifying important vectorization efforts for developers. We then\nbriefly review the organization of the Tinker-HP code and identify the\ncomputational hotspots which require Intel AVX-512 optimization and we propose\na general and optimal strategy to vectorize those particular parts of the code.\nWe intended to present our optimization strategy in a pedagogical way so it\ncould benefit to other researchers and students interested in gaining\nperformances in their own software. Finally we present the performance\nenhancements obtained compared to the unoptimized code both sequentially and at\nthe scaling limit in parallel for classical non-polarizable (CHARMM) and\npolarizable force fields (AMOEBA). This paper never ceases to be updated as we\naccumulate new data on the associated Github repository between new versions of\nthis living paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.01211v4"
    },
    {
        "title": "Nektar++: enhancing the capability and application of high-fidelity\n  spectral/$hp$ element methods",
        "authors": [
            "David Moxey",
            "Chris D. Cantwell",
            "Yan Bao",
            "Andrea Cassinelli",
            "Giacomo Castiglioni",
            "Sehun Chun",
            "Emilia Juda",
            "Ehsan Kazemi",
            "Kilian Lackhove",
            "Julian Marcon",
            "Gianmarco Mengaldo",
            "Douglas Serson",
            "Michael Turner",
            "Hui Xu",
            "Joaquim Peiró",
            "Robert M. Kirby",
            "Spencer J. Sherwin"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Nektar++ is an open-source framework that provides a flexible,\nhigh-performance and scalable platform for the development of solvers for\npartial differential equations using the high-order spectral/$hp$ element\nmethod. In particular, Nektar++ aims to overcome the complex implementation\nchallenges that are often associated with high-order methods, thereby allowing\nthem to be more readily used in a wide range of application areas. In this\npaper, we present the algorithmic, implementation and application developments\nassociated with our Nektar++ version 5.0 release. We describe some of the key\nsoftware and performance developments, including our strategies on parallel\nI/O, on in situ processing, the use of collective operations for exploiting\ncurrent and emerging hardware, and interfaces to enable multi-solver coupling.\nFurthermore, we provide details on a newly developed Python interface that\nenables a more rapid introduction for new users unfamiliar with spectral/$hp$\nelement methods, C++ and/or Nektar++. This release also incorporates a number\nof numerical method developments - in particular: the method of moving frames,\nwhich provides an additional approach for the simulation of equations on\nembedded curvilinear manifolds and domains; a means of handling spatially\nvariable polynomial order; and a novel technique for quasi-3D simulations to\npermit spatially-varying perturbations to the geometry in the homogeneous\ndirection. Finally, we demonstrate the new application-level features provided\nin this release, namely: a facility for generating high-order curvilinear\nmeshes called NekMesh; a novel new AcousticSolver for aeroacoustic problems;\nour development of a 'thick' strip model for the modelling of fluid-structure\ninteraction problems in the context of vortex-induced vibrations. We conclude\nby commenting some directions for future code development and expansion.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.03489v2"
    },
    {
        "title": "Computing Theta Functions with Julia",
        "authors": [
            "Daniele Agostini",
            "Lynn Chua"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present a new package Theta.jl for computing with the Riemann theta\nfunction. It is implemented in Julia and offers accurate numerical evaluation\nof theta functions with characteristics and their derivatives of arbitrary\norder. Our package is optimized for multiple evaluations of theta functions for\nthe same Riemann matrix, in small dimensions. As an application, we report on\nexperimental approaches to the Schottky problem in genus five.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.06507v2"
    },
    {
        "title": "SPSMAT: GNU Octave software package for spectral and pseudospectral\n  methods",
        "authors": [
            "Sobhan Latifi",
            "Mehdi Delkhosh"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  SPSMAT (Spectral/Pseudospectral matrix method) is an add-on for Octave, that\nhelps you solve nonfractional-/fractional ordinary/partial\ndifferential/integral equations. In this version, as the first version, the\nwell-defined spectral or pseudospectral algorithms are considered to solve\ndifferential and integral equations. The motivation is that there are few\nsoftware packages available that make such methods easy to use for\npractitioners in the field of scientific computing. Additionally, one of the\nmost practical platforms in computation, MATLAB, is currently not supporting\nbeneficial and free numerical method for the solution of differential\nequations--to the best author's knowledge. To remedy this situation, this paper\nprovides a description of its relevant uploaded open source software package\nand is a broad guidance to describe how to work with this toolbox.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.09964v1"
    },
    {
        "title": "Parallel Performance of Algebraic Multigrid Domain Decomposition\n  (AMG-DD)",
        "authors": [
            "Wayne B. Mitchell",
            "Robert Strzodka",
            "Robert D. Falgout"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Algebraic multigrid (AMG) is a widely used scalable solver and preconditioner\nfor large-scale linear systems resulting from the discretization of a wide\nclass of elliptic PDEs. While AMG has optimal computational complexity, the\ncost of communication has become a significant bottleneck that limits its\nscalability as processor counts continue to grow on modern machines. This paper\nexamines the design, implementation, and parallel performance of a novel\nalgorithm, Algebraic Multigrid Domain Decomposition (AMG-DD), designed\nspecifically to limit communication. The goal of AMG-DD is to provide a\nlow-communication alternative to standard AMG V-cycles by trading some\nadditional computational overhead for a significant reduction in communication\ncost. Numerical results show that AMG-DD achieves superior accuracy per\ncommunication cost compared to AMG, and speedup over AMG is demonstrated on a\nlarge GPU cluster.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.10575v2"
    },
    {
        "title": "A High-Performance Implementation of a Robust Preconditioner for\n  Heterogeneous Problems",
        "authors": [
            "Linus Seelinger",
            "Anne Reinarz",
            "Robert Scheichl"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present an efficient implementation of the highly robust and scalable\nGenEO preconditioner in the high-performance PDE framework DUNE. The GenEO\ncoarse space is constructed by combining low energy solutions of a local\ngeneralised eigenproblem using a partition of unity. In this paper we\ndemonstrate both weak and strong scaling for the GenEO solver on over 15,000\ncores by solving an industrially motivated problem with over 200 million\ndegrees of freedom. Further, we show that for highly complex parameter\ndistributions arising in certain real-world applications, established methods\nbecome intractable while GenEO remains fully effective. The purpose of this\npaper is two-fold: to demonstrate the robustness and high parallel efficiency\nof the solver and to document the technical details that are crucial to the\nefficiency of the code.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.10944v2"
    },
    {
        "title": "HDGlab: An open-source implementation of the hybridisable discontinuous\n  Galerkin method in MATLAB",
        "authors": [
            "Matteo Giacomini",
            "Ruben Sevilla",
            "Antonio Huerta"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper presents HDGlab, an open source MATLAB implementation of the\nhybridisable discontinuous Galerkin (HDG) method. The main goal is to provide a\ndetailed description of both the HDG method for elliptic problems and its\nimplementation available in HDGlab. Ultimately, this is expected to make this\nrelatively new advanced discretisation method more accessible to the\ncomputational engineering community. HDGlab presents some features not\navailable in other implementations of the HDG method that can be found in the\nfree domain. First, it implements high-order polynomial shape functions up to\ndegree nine, with both equally-spaced and Fekete nodal distributions. Second,\nit supports curved isoparametric simplicial elements in two and three\ndimensions. Third, it supports non-uniform degree polynomial approximations and\nit provides a flexible structure to devise degree adaptivity strategies.\nFinally, an interface with the open-source high-order mesh generator Gmsh is\nprovided to facilitate its application to practical engineering problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.08805v1"
    },
    {
        "title": "Portable high-order finite element kernels I: Streaming Operations",
        "authors": [
            "Noel Chalmers",
            "Tim Warburton"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper is devoted to the development of highly efficient kernels\nperforming vector operations relevant in linear system solvers. In particular,\nwe focus on the low arithmetic intensity operations (i.e., streaming\noperations) performed within the conjugate gradient iterative method, using the\nparameters specified in the CEED benchmark problems for high-order hexahedral\nfinite elements. We propose a suite of new Benchmark Streaming tests to focus\non the distinct streaming operations which must be performed. We implemented\nthese new tests using the OCCA abstraction framework to demonstrate portability\nof these streaming operations on different GPU architectures, and propose a\nsimple performance model for such kernels which can accurately capture data\nmovement rates as well as kernel launch costs.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.10917v1"
    },
    {
        "title": "AMReX: Block-Structured Adaptive Mesh Refinement for Multiphysics\n  Applications",
        "authors": [
            "Weiqun Zhang",
            "Andrew Myers",
            "Kevin Gott",
            "Ann Almgren",
            "John Bell"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Block-structured adaptive mesh refinement (AMR) provides the basis for the\ntemporal and spatial discretization strategy for a number of ECP applications\nin the areas of accelerator design, additive manufacturing, astrophysics,\ncombustion, cosmology, multiphase flow, and wind plant modelling. AMReX is a\nsoftware framework that provides a unified infrastructure with the\nfunctionality needed for these and other AMR applications to be able to\neffectively and efficiently utilize machines from laptops to exascale\narchitectures. AMR reduces the computational cost and memory footprint compared\nto a uniform mesh while preserving accurate descriptions of different physical\nprocesses in complex multi-physics algorithms. AMReX supports algorithms that\nsolve systems of partial differential equations (PDEs) in simple or complex\ngeometries, and those that use particles and/or particle-mesh operations to\nrepresent component physical processes. In this paper, we will discuss the core\nelements of the AMReX framework such as data containers and iterators as well\nas several specialized operations to meet the needs of the application\nprojects. In addition we will highlight the strategy that the AMReX team is\npursuing to achieve highly performant code across a range of accelerator-based\narchitectures for a variety of different applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.12009v1"
    },
    {
        "title": "Flexible Performant GEMM Kernels on GPUs",
        "authors": [
            "Thomas Faingnaert",
            "Tim Besard",
            "Bjorn De Sutter"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  General Matrix Multiplication or GEMM kernels take centre place in high\nperformance computing and machine learning. Recent NVIDIA GPUs include GEMM\naccelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by\nthe two-language problem: it requires either low-level programming which\nimplies low programmer productivity or using libraries that only offer a\nlimited set of components. Because rephrasing algorithms in terms of\nestablished components often introduces overhead, the libraries' lack of\nflexibility limits the freedom to explore new algorithms. Researchers using\nGEMMs can hence not enjoy programming productivity, high performance, and\nresearch flexibility at once.\n  In this paper we solve this problem. We present three sets of abstractions\nand interfaces to program GEMMs within the scientific Julia programming\nlanguage. The interfaces and abstractions are co-designed for researchers'\nneeds and Julia's features to achieve sufficient separation of concerns and\nflexibility to easily extend basic GEMMs in many different ways without paying\na performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS\nand CUTLASS, we demonstrate that our performance is in the same ballpark of the\nlibraries, and in some cases even exceeds it, without having to write a single\nline of code in CUDA C++ or assembly, and without facing flexibility\nlimitations.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.12263v4"
    },
    {
        "title": "Compact 200 line MATLAB code for inverse design in photonics by topology\n  optimization: tutorial",
        "authors": [
            "Rasmus E. Christiansen",
            "Ole Sigmund"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We provide a compact 200 line MATLAB code demonstrating how topology\noptimization (TopOpt) as an inverse design tool may be used in photonics,\ntargeting the design of two-dimensional dielectric metalenses and a metallic\nreflector as examples. The physics model is solved using the finite element\nmethod, and the code utilizes MATLAB's fmincon algorithm to solve the\noptimization problem. In addition to presenting the code itself, we briefly\ndiscuss a number of extensions and provide the code required to implement some\nof these. Finally, we demonstrate the superiority of using a gradient-based\nmethod compared to a genetic-algorithm-based method (using MATLAB's ga\nalgorithm) for solving inverse design problems in photonics. The MATLAB\nsoftware is freely available in the paper and may be downloaded from\nhttps://www.topopt.mek.dtu.dk.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.14276v5"
    },
    {
        "title": "Accelerating Sparse Matrix-Matrix Multiplication with GPU Tensor Cores",
        "authors": [
            "Orestis Zachariadis",
            "Nitin Satpute",
            "Juan Gómez-Luna",
            "Joaquín Olivares"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Sparse general matrix-matrix multiplication (spGEMM) is an essential\ncomponent in many scientific and data analytics applications. However, the\nsparsity pattern of the input matrices and the interaction of their patterns\nmake spGEMM challenging. Modern GPUs include Tensor Core Units (TCUs), which\nspecialize in dense matrix multiplication. Our aim is to re-purpose TCUs for\nsparse matrices. The key idea of our spGEMM algorithm, tSparse, is to multiply\nsparse rectangular blocks using the mixed precision mode of TCUs. tSparse\npartitions the input matrices into tiles and operates only on tiles which\ncontain one or more elements. It creates a task list of the tiles, and performs\nmatrix multiplication of these tiles using TCUs. To the best of our knowledge,\nthis is the first time that TCUs are used in the context of spGEMM. We show\nthat spGEMM, with our tiling approach, benefits from TCUs. Our approach\nsignificantly improves the performance of spGEMM in comparison to cuSPARSE,\nCUSP, RMerge2, Nsparse, AC-SpGEMM and spECK.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.14600v1"
    },
    {
        "title": "emgr - The Empirical Gramian Framework",
        "authors": [
            "Christian Himpe"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  System Gramian matrices are a well-known encoding for properties of\ninput-output systems such as controllability, observability or minimality.\nThese so-called system Gramians were developed in linear system theory for\napplications such as model order reduction of control systems. Empirical\nGramian are an extension to the system Gramians for parametric and nonlinear\nsystems as well as a data-driven method of computation. The empirical Gramian\nframework - emgr - implements the empirical Gramians in a uniform and\nconfigurable manner, with applications such as Gramian-based (nonlinear) model\nreduction, decentralized control, sensitivity analysis, parameter\nidentification and combined state and parameter reduction.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.00675v2"
    },
    {
        "title": "GPU-Based Parallel Integration of Large Numbers of Independent ODE\n  Systems",
        "authors": [
            "Kyle E Niemeyer",
            "Chih-Jen Sung"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  The task of integrating a large number of independent ODE systems arises in\nvarious scientific and engineering areas. For nonstiff systems, common explicit\nintegration algorithms can be used on GPUs, where individual GPU threads\nconcurrently integrate independent ODEs with different initial conditions or\nparameters. One example is the fifth-order adaptive Runge-Kutta-Cash-Karp\n(RKCK) algorithm. In the case of stiff ODEs, standard explicit algorithms\nrequire impractically small time-step sizes for stability reasons, and implicit\nalgorithms are therefore commonly used instead to allow larger time steps and\nreduce the computational expense. However, typical high-order implicit\nalgorithms based on backwards differentiation formulae (e.g., VODE, LSODE)\ninvolve complex logical flow that causes severe thread divergence when\nimplemented on GPUs, limiting the performance. Therefore, alternate algorithms\nare needed. A GPU-based Runge-Kutta-Chebyshev (RKC) algorithm can handle\nmoderate levels of stiffness and performs significantly faster than not only an\nequivalent CPU version but also a CPU-based implicit algorithm (VODE) based on\nresults shown in the literature. In this chapter, we present the mathematical\nbackground, implementation details, and source code for the RKCK and RKC\nalgorithms for use integrating large numbers of independent systems of ODEs on\nGPUs. In addition, brief performance comparisons are shown for each algorithm,\ndemonstrating the potential benefit of moving to GPU-based ODE integrators.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.02274v1"
    },
    {
        "title": "Arb: Efficient Arbitrary-Precision Midpoint-Radius Interval Arithmetic",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Arb is a C library for arbitrary-precision interval arithmetic using the\nmidpoint-radius representation, also known as ball arithmetic. It supports real\nand complex numbers, polynomials, power series, matrices, and evaluation of\nmany special functions. The core number types are designed for versatility and\nspeed in a range of scenarios, allowing performance that is competitive with\nnon-interval arbitrary-precision types such as MPFR and MPC floating-point\nnumbers. We discuss the low-level number representation, strategies for\nprecision and error bounds, and the implementation of efficient polynomial\narithmetic with interval coefficients.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.02831v1"
    },
    {
        "title": "Bidiagonalization with Parallel Tiled Algorithms",
        "authors": [
            "Mathieu Faverge",
            "Julien Langou",
            "Yves Robert",
            "Jack Dongarra"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We consider algorithms for going from a \"full\" matrix to a condensed \"band\nbidiagonal\" form using orthogonal transformations. We use the framework of\n\"algorithms by tiles\". Within this framework, we study: (i) the tiled\nbidiagonalization algorithm BiDiag, which is a tiled version of the standard\nscalar bidiagonalization algorithm; and (ii) the R-bidiagonalization algorithm\nR-BiDiag, which is a tiled version of the algorithm which consists in first\nperforming the QR factorization of the initial matrix, then performing the\nband-bidiagonalization of the R-factor. For both bidiagonalization algorithms\nBiDiag and R-BiDiag, we use four main types of reduction trees, namely FlatTS,\nFlatTT, Greedy, and a newly introduced auto-adaptive tree, Auto. We provide a\nstudy of critical path lengths for these tiled algorithms, which shows that (i)\nR-BiDiag has a shorter critical path length than BiDiag for tall and skinny\nmatrices, and (ii) Greedy based schemes are much better than earlier proposed\nvariants with unbounded resources. We provide experiments on a single multicore\nnode, and on a few multicore nodes of a parallel distributed shared-memory\nsystem, to show the superiority of the new algorithms on a variety of matrix\nsizes, matrix shapes and core counts.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.06892v1"
    },
    {
        "title": "SimTensor: A synthetic tensor data generator",
        "authors": [
            "Hadi Fanaee-T",
            "Joao Gama"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  SimTensor is a multi-platform, open-source software for generating artificial\ntensor data (either with CP/PARAFAC or Tucker structure) for reproducible\nresearch on tensor factorization algorithms. SimTensor is a stand-alone\napplication based on MATALB. It provides a wide range of facilities for\ngenerating tensor data with various configurations. It comes with a\nuser-friendly graphical user interface, which enables the user to generate\ntensors with complicated settings in an easy way. It also has this facility to\nexport generated data to universal formats such as CSV and HDF5, which can be\nimported via a wide range of programming languages (C, C++, Java, R, Fortran,\nMATLAB, Perl, Python, and many more). The most innovative part of SimTensor is\nthis that can generate temporal tensors with periodic waves, seasonal effects\nand streaming structure. it can apply constraints such as non-negativity and\ndifferent kinds of sparsity to the data. SimTensor also provides this facility\nto simulate different kinds of change-points and inject various types of\nanomalies. The source code and binary versions of SimTensor is available for\ndownload in http://www.simtensor.org.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.03772v1"
    },
    {
        "title": "An efficient hybrid tridiagonal divide-and-conquer algorithm on\n  distributed memory architectures",
        "authors": [
            "Shengguo Li",
            "Francois-Henry Rouet",
            "Jie Liu",
            "Chun Huang",
            "Xingyu Gao",
            "Xuebin Chi"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  In this paper, an efficient divide-and-conquer (DC) algorithm is proposed for\nthe symmetric tridiagonal matrices based on ScaLAPACK and the hierarchically\nsemiseparable (HSS) matrices. HSS is an important type of rank-structured\nmatrices.Most time of the DC algorithm is cost by computing the eigenvectors\nvia the matrix-matrix multiplications (MMM). In our parallel hybrid DC (PHDC)\nalgorithm, MMM is accelerated by using the HSS matrix techniques when the\nintermediate matrix is large. All the HSS algorithms are done via the package\nSTRUMPACK. PHDC has been tested by using many different matrices. Compared with\nthe DC implementation in MKL, PHDC can be faster for some matrices with few\ndeflations when using hundreds of processes. However, the gains decrease as the\nnumber of processes increases. The comparisons of PHDC with ELPA (the\nEigenvalue soLvers for Petascale Applications library) are similar. PHDC is\nusually slower than MKL and ELPA when using 300 or more processes on Tianhe-2\nsupercomputer.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.07526v1"
    },
    {
        "title": "Far-HO: A Bilevel Programming Package for Hyperparameter Optimization\n  and Meta-Learning",
        "authors": [
            "Luca Franceschi",
            "Riccardo Grazzi",
            "Massimiliano Pontil",
            "Saverio Salzo",
            "Paolo Frasconi"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In (Franceschi et al., 2018) we proposed a unified mathematical framework,\ngrounded on bilevel programming, that encompasses gradient-based hyperparameter\noptimization and meta-learning. We formulated an approximate version of the\nproblem where the inner objective is solved iteratively, and gave sufficient\nconditions ensuring convergence to the exact problem. In this work we show how\nto optimize learning rates, automatically weight the loss of single examples\nand learn hyper-representations with Far-HO, a software package based on the\npopular deep learning framework TensorFlow that allows to seamlessly tackle\nboth HO and ML problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.04941v1"
    },
    {
        "title": "A scalable H-matrix approach for the solution of boundary integral\n  equations on multi-GPU clusters",
        "authors": [
            "Helmut Harbrecht",
            "Peter Zaspel"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this work, we consider the solution of boundary integral equations by\nmeans of a scalable hierarchical matrix approach on clusters equipped with\ngraphics hardware, i.e. graphics processing units (GPUs). To this end, we\nextend our existing single-GPU hierarchical matrix library hmglib such that it\nis able to scale on many GPUs and such that it can be coupled to arbitrary\napplication codes. Using a model GPU implementation of a boundary element\nmethod (BEM) solver, we are able to achieve more than 67 percent relative\nparallel speed-up going from 128 to 1024 GPUs for a model geometry test case\nwith 1.5 million unknowns and a real-world geometry test case with almost 1.2\nmillion unknowns. On 1024 GPUs of the cluster Titan, it takes less than 6\nminutes to solve the 1.5 million unknowns problem, with 5.7 minutes for the\nsetup phase and 20 seconds for the iterative solver. To the best of the\nauthors' knowledge, we here discuss the first fully GPU-based\ndistributed-memory parallel hierarchical matrix Open Source library using the\ntraditional H-matrix format and adaptive cross approximation with an\napplication to BEM problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.11558v1"
    },
    {
        "title": "Software System Design based on Patterns for Newton-Type Methods",
        "authors": [
            "Ricardo Serrato Barrera",
            "Gustavo Rodríguez Gómez",
            "Julio César Pérez Sansalvador",
            "Saul E. Pomares Hernández",
            "Leticia Flores Pulido",
            "Antonio Muñoz"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  A wide range of engineering applications uses optimisation techniques as part\nof their solution process. The researcher uses specialized software that\nimplements well-known optimisation techniques to solve his problem. However,\nwhen it comes to develop original optimisation techniques that fit a particular\nproblem the researcher has no option but to implement his own new method from\nscratch. This leads to large development times and error prone code that, in\ngeneral, will not be reused for any other application. In this work, we present\na novel methodology that simplifies, fasten and improves the development\nprocess of scientific software. This methodology guide us on the identification\nof design patterns. The application of this methodology generates reusable,\nflexible and high quality scientific software. Furthermore, the produced\nsoftware becomes a documented tool to transfer the knowledge on the development\nprocess of scientific software. We apply this methodology for the design of an\noptimisation framework implementing Newton's type methods which can be used as\na fast prototyping tool of new optimisation techniques based on Newton's type\nmethods. The abstraction, reusability and flexibility of the developed\nframework is measured by means of Martin's metric. The results indicate that\nthe developed software is highly reusable.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04642v1"
    },
    {
        "title": "ExaHyPE: An Engine for Parallel Dynamically Adaptive Simulations of Wave\n  Problems",
        "authors": [
            "Anne Reinarz",
            "Dominic E. Charrier",
            "Michael Bader",
            "Luke Bovard",
            "Michael Dumbser",
            "Kenneth Duru",
            "Francesco Fambri",
            "Alice-Agnes Gabriel",
            "Jean-Matthieu Gallard",
            "Sven Köppel",
            "Lukas Krenz",
            "Leonhard Rannabauer",
            "Luciano Rezzolla",
            "Philipp Samfass",
            "Maurizio Tavelli",
            "Tobias Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  ExaHyPE (\"An Exascale Hyperbolic PDE Engine\") is a software engine for\nsolving systems of first-order hyperbolic partial differential equations\n(PDEs). Hyperbolic PDEs are typically derived from the conservation laws of\nphysics and are useful in a wide range of application areas. Applications\npowered by ExaHyPE can be run on a student's laptop, but are also able to\nexploit thousands of processor cores on state-of-the-art supercomputers. The\nengine is able to dynamically increase the accuracy of the simulation using\nadaptive mesh refinement where required. Due to the robustness and shock\ncapturing abilities of ExaHyPE's numerical methods, users of the engine can\nsimulate linear and non-linear hyperbolic PDEs with very high accuracy. Users\ncan tailor the engine to their particular PDE by specifying evolved quantities,\nfluxes, and source terms. A complete simulation code for a new hyperbolic PDE\ncan often be realised within a few hours - a task that, traditionally, can take\nweeks, months, often years for researchers starting from scratch. In this\npaper, we showcase ExaHyPE's workflow and capabilities through real-world\nscenarios from our two main application areas: seismology and astrophysics.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.07987v3"
    },
    {
        "title": "PFASST-ER: Combining the Parallel Full Approximation Scheme in Space and\n  Time with parallelization across the method",
        "authors": [
            "Ruth Schöbel",
            "Robert Speck"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  To extend prevailing scaling limits when solving time-dependent partial\ndifferential equations, the parallel full approximation scheme in space and\ntime (PFASST) has been shown to be a promising parallel-in-time integrator.\nSimilar to a space-time multigrid, PFASST is able to compute multiple\ntime-steps simultaneously and is therefore in particular suitable for\nlarge-scale applications on high performance computing systems. In this work we\ncouple PFASST with a parallel spectral deferred correction (SDC) method,\nforming an unprecedented doubly time-parallel integrator. While PFASST provides\nglobal, large-scale \"parallelization across the step\", the inner parallel SDC\nmethod allows to integrate each individual time-step \"parallel across the\nmethod\" using a diagonalized local Quasi-Newton solver. This new method, which\nwe call \"PFASST with Enhanced concuRrency\" (PFASST-ER), therefore exposes even\nmore temporal parallelism. For two challenging nonlinear reaction-diffusion\nproblems, we show that PFASST-ER works more efficiently than the classical\nvariants of PFASST and can be used to run parallel-in-time beyond the number of\ntime-steps.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.00702v1"
    },
    {
        "title": "differint: A Python Package for Numerical Fractional Calculus",
        "authors": [
            "Matthew Adams"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Fractional calculus has become widely studied and applied to physical\nproblems in recent years. As a result, many methods for the numerical\ncomputation of fractional derivatives and integrals have been defined. However,\nthese algorithms are often programmed in an ad hoc manner, requiring\nresearchers to implement and debug their own code. This work introduces the\n\\textit{differint} software package, which offers a single repository for\nmultiple numerical algorithms for the computation of fractional derivatives and\nintegrals. This package is coded in the open-source Python programming\nlanguage. The Gr\\\"unwald-Letnikov, improved Gr\\\"unwald-Letnikov, and\nRiemann-Liouville algorithms from the fractional calculus are included in this\npackage. The algorithms presented are computed from their descriptions found in\n[2]. This work concludes with suggestions for the application of the\n\\textit{differint} software package.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05303v1"
    },
    {
        "title": "PCPATCH: software for the topological construction of multigrid\n  relaxation methods",
        "authors": [
            "Patrick E. Farrell",
            "Matthew G. Knepley",
            "Lawrence Mitchell",
            "Florian Wechsung"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Effective relaxation methods are necessary for good multigrid convergence.\nFor many equations, standard Jacobi and Gau{\\ss}-Seidel are inadequate, and\nmore sophisticated space decompositions are required; examples include problems\nwith semidefinite terms or saddle point structure. In this paper we present a\nunifying software abstraction, PCPATCH, for the topological construction of\nspace decompositions for multigrid relaxation methods. Space decompositions are\nspecified by collecting topological entities in a mesh (such as all vertices or\nfaces) and applying a construction rule (such as taking all degrees of freedom\nin the cells around each entity). The software is implemented in PETSc and\nfacilitates the elegant expression of a wide range of schemes merely by varying\nsolver options at runtime. In turn, this allows for the very rapid development\nof fast solvers for difficult problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.08516v4"
    },
    {
        "title": "Medusa: A C++ Library for solving PDEs using Strong Form Mesh-Free\n  methods",
        "authors": [
            "Jure Slak",
            "Gregor Kosec"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Medusa, a novel library for implementation of strong form mesh-free methods,\nis described. We identify and present common parts and patterns among many such\nmethods reported in the literature, such as node positioning, stencil selection\nand stencil weight computation. Many different algorithms exist for each part\nand the possible combinations offer a plethora of possibilities for\nimprovements of solution procedures that are far from fully understood. As a\nconsequence there are still many unanswered questions in mesh-free community\nresulting in vivid ongoing research in the field. Medusa implements the core\nmesh-free elements as independent blocks, which offers users great flexibility\nin experimenting with the method they are developing, as well as easily\ncomparing it with other existing methods. The paper describes the chosen\nabstractions and their usage, illustrates aspects of the philosophy and design,\noffers some executions time benchmarks and demonstrates the application of the\nlibrary on cases from linear elasticity and fluid flow in irregular 2D and 3D\ndomains.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.13282v1"
    },
    {
        "title": "A Hybrid MPI-CUDA Approach for Nonequispaced Discrete Fourier\n  Transformation",
        "authors": [
            "Sheng-Chun Yang",
            "Yong-Lei Wang"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Nonequispaced discrete Fourier transformation (NDFT) is widely applied in all\naspects of computational science and engineering. The computational efficiency\nand accuracy of NDFT has always been a critical issue in hindering its\ncomprehensive applications both in intensive and in extensive aspects of\nscientific computing. In our previous work (2018, S.-C. Yang et al., Appl.\nComput. Harmon. Anal. 44, 273), a CUNFFT method was proposed and it shown\noutstanding performance in handling NDFT at intermediate scale based on CUDA\n(Compute Unified Device Architecture) technology. In the current work, we\nfurther improved the computational efficiency of the CUNTTF method using an\nefficient MPI-CUDA hybrid parallelization (HP) scheme of NFFT to achieve a\ncutting-edge treatment of NDFT at super extended scale. Within this HP-NFFT\nmethod, the spatial domain of NDFT is decomposed into several parts according\nto the accumulative feature of NDFT and the detailed number of CPU and GPU\nnodes. These decomposed NDFT subcells are independently calculated on different\nCPU nodes using a MPI process-level parallelization mode, and on different GPU\nnodes using a CUDA threadlevel parallelization mode and CUNFFT algorithm. A\nmassive benchmarking of the HP-NFFT method indicates that this method exhibit a\ndramatic improvement in computational efficiency for handling NDFT at super\nextended scale without loss of computational precision. Furthermore, the\nHP-NFFT method is validated via the calculation of Madelung constant of\nfluorite crystal structure, and thereafter verified that this method is robust\nfor the calculation of electrostatic interactions between charged ions in\nmolecular dynamics simulation systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.01583v1"
    },
    {
        "title": "MonteCarloMeasurements.jl: Nonlinear Propagation of Arbitrary\n  Multivariate Distributions by means of Method Overloading",
        "authors": [
            "Fredrik Bagge Carlson"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This manuscript outlines a software package that facilitates working with\nprobability distributions by means of Monte-Carlo methods, in a way that allows\nfor propagation of multivariate probability distributions through arbitrary\nfunctions. We provide a \\emph{type} that represents probability distributions\nby an internal vector of unweighted samples, \\texttt{Particles}, which is a\nsubtype of a \\texttt{Real} number and behaves just like a regular real number\nin calculations by means of method overloading. This makes the software easy to\nwork with and presents minimal friction for the user. We highlight how this\ndesign facilitates optimal usage of SIMD instructions and showcase the package\nfor uncertainty propagation through an off-the-shelf ODE solver, as well as for\nrobust probabilistic optimization with automatic differentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.07625v1"
    },
    {
        "title": "SLEEF: A Portable Vectorized Library of C Standard Mathematical\n  Functions",
        "authors": [
            "Naoki Shibata",
            "Francesco Petrogalli"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper, we present techniques used to implement our portable\nvectorized library of C standard mathematical functions written entirely in C\nlanguage. In order to make the library portable while maintaining good\nperformance, intrinsic functions of vector extensions are abstracted by inline\nfunctions or preprocessor macros. We implemented the functions so that they can\nuse sub-features of vector extensions such as fused multiply-add, mask\nregisters and extraction of mantissa. In order to make computation with SIMD\ninstructions efficient, the library only uses a small number of conditional\nbranches, and all the computation paths are vectorized. We devised a variation\nof the Payne-Hanek argument reduction for trigonometric functions and a\nfloating point remainder, both of which are suitable for vector computation. We\ncompare the performance of our library to Intel SVML.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.09258v1"
    },
    {
        "title": "lbmpy: Automatic code generation for efficient parallel lattice\n  Boltzmann methods",
        "authors": [
            "Martin Bauer",
            "Harald Köstler",
            "Ulrich Rüde"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Lattice Boltzmann methods are a popular mesoscopic alternative to macroscopic\ncomputational fluid dynamics solvers. Many variants have been developed that\nvary in complexity, accuracy, and computational cost. Extensions are available\nto simulate multi-phase, multi-component, turbulent, or non-Newtonian flows. In\nthis work we present lbmpy, a code generation package that supports a wide\nvariety of different methods and provides a generic development environment for\nnew schemes as well. A high-level domain-specific language allows the user to\nformulate, extend and test various lattice Boltzmann schemes. The method\nspecification is represented in a symbolic intermediate representation.\nTransformations that operate on this intermediate representation optimize and\nparallelize the method, yielding highly efficient lattice Boltzmann compute\nkernels not only for single- and two-relaxation-time schemes but also for\nmulti-relaxation-time, cumulant, and entropically stabilized methods. An\nintegration into the HPC framework waLBerla makes massively parallel,\ndistributed simulations possible, which is demonstrated through scaling\nexperiments on the SuperMUC-NG supercomputing system\n",
        "pdf_link": "http://arxiv.org/pdf/2001.11806v2"
    },
    {
        "title": "AutoHOOT: Automatic High-Order Optimization for Tensors",
        "authors": [
            "Linjian Ma",
            "Jiayu Ye",
            "Edgar Solomonik"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  High-order optimization methods, including Newton's method and its variants\nas well as alternating minimization methods, dominate the optimization\nalgorithms for tensor decompositions and tensor networks. These tensor methods\nare used for data analysis and simulation of quantum systems. In this work, we\nintroduce AutoHOOT, the first automatic differentiation (AD) framework\ntargeting at high-order optimization for tensor computations. AutoHOOT takes\ninput tensor computation expressions and generates optimized derivative\nexpressions. In particular, AutoHOOT contains a new explicit Jacobian / Hessian\nexpression generation kernel whose outputs maintain the input tensors'\ngranularity and are easy to optimize. The expressions are then optimized by\nboth the traditional compiler optimization techniques and specific tensor\nalgebra transformations. Experimental results show that AutoHOOT achieves\ncompetitive CPU and GPU performance for both tensor decomposition and tensor\nnetwork applications compared to existing AD software and other tensor\ncomputation libraries with manually written kernels. The tensor methods\ngenerated by AutoHOOT are also well-parallelizable, and we demonstrate good\nscalability on a distributed memory supercomputer.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.04540v2"
    },
    {
        "title": "Batched computation of the singular value decompositions of order two by\n  the AVX-512 vectorization",
        "authors": [
            "Vedran Novaković"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper a vectorized algorithm for simultaneously computing up to eight\nsingular value decompositions (SVDs, each of the form $A=U\\Sigma V^{\\ast}$) of\nreal or complex matrices of order two is proposed. The algorithm extends to a\nbatch of matrices of an arbitrary length $n$, that arises, for example, in the\nannihilation part of the parallel Kogbetliantz algorithm for the SVD of a\nsquare matrix of order $2n$. The SVD algorithm for a single matrix of order two\nis derived first. It scales, in most instances error-free, the input matrix $A$\nsuch that its singular values $\\Sigma_{ii}$ cannot overflow whenever its\nelements are finite, and then computes the URV factorization of the scaled\nmatrix, followed by the SVD of a non-negative upper-triangular middle factor. A\nvector-friendly data layout for the batch is then introduced, where the\nsame-indexed elements of each of the input and the output matrices form\nvectors, and the algorithm's steps over such vectors are described. The\nvectorized approach is then shown to be about three times faster than\nprocessing each matrix in isolation, while slightly improving accuracy over the\nstraightforward method for the $2\\times 2$ SVD.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.07403v1"
    },
    {
        "title": "Lambert W Function for Applications in Physics",
        "authors": [
            "Darko Veberic"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  The Lambert W(x) function and its possible applications in physics are\npresented. The actual numerical implementation in C++ consists of Halley's and\nFritsch's iterations with initial approximations based on branch-point\nexpansion, asymptotic series, rational fits, and continued-logarithm recursion.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.0735v2"
    },
    {
        "title": "Performance Modeling for Dense Linear Algebra",
        "authors": [
            "Elmar Peise",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  It is well known that the behavior of dense linear algebra algorithms is\ngreatly influenced by factors like target architecture, underlying libraries\nand even problem size; because of this, the accurate prediction of their\nperformance is a real challenge. In this article, we are not interested in\ncreating accurate models for a given algorithm, but in correctly ranking a set\nof equivalent algorithms according to their performance. Aware of the\nhierarchical structure of dense linear algebra routines, we approach the\nproblem by developing a framework for the automatic generation of statistical\nperformance models for BLAS and LAPACK libraries. This allows us to obtain\npredictions through evaluating and combining such models. We demonstrate that\nour approach is successful in both single- and multi-core environments, not\nonly in the ranking of algorithms but also in tuning their parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.2364v2"
    },
    {
        "title": "mplrs: A scalable parallel vertex/facet enumeration code",
        "authors": [
            "David Avis",
            "Charles Jordan"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  We describe a new parallel implementation, mplrs, of the vertex enumeration\ncode lrs that uses the MPI parallel environment and can be run on a network of\ncomputers. The implementation makes use of a C wrapper that essentially uses\nthe existing lrs code with only minor modifications. mplrs was derived from the\nearlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses\nthe Boost library and runs on a shared memory machine. In developing mplrs we\ndiscovered a method of balancing the parallel tree search, called budgeting,\nthat greatly improves parallelization beyond the bottleneck encountered\npreviously at around 32 cores.\n  This method can be readily adapted for use in other reverse search\nenumeration codes. We also report some preliminary computational results\ncomparing parallel and sequential codes for vertex/facet enumeration problems\nfor convex polyhedra. The problems chosen span the range from simple to highly\ndegenerate polytopes. For most problems tested, the results clearly show the\nadvantage of using the parallel implementation mplrs of the reverse search\nbased code lrs, even when as few as 8 cores are available. For some problems\nalmost linear speedup was observed up to 1200 cores, the largest number of\ncores tested.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.06487v4"
    },
    {
        "title": "Chebyshev Filter Diagonalization on Modern Manycore Processors and\n  GPGPUs",
        "authors": [
            "Moritz Kreutzer",
            "Georg Hager",
            "Dominik Ernst",
            "Holger Fehske",
            "Alan R. Bishop",
            "Gerhard Wellein"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Chebyshev filter diagonalization is well established in quantum chemistry and\nquantum physics to compute bulks of eigenvalues of large sparse matrices.\nChoosing a block vector implementation, we investigate optimization\nopportunities on the new class of high-performance compute devices featuring\nboth high-bandwidth and low-bandwidth memory. We focus on the transparent\naccess to the full address space supported by both architectures under\nconsideration: Intel Xeon Phi \"Knights Landing\" and Nvidia \"Pascal.\"\n  We propose two optimizations: (1) Subspace blocking is applied for improved\nperformance and data access efficiency. We also show that it allows\ntransparently handling problems much larger than the high-bandwidth memory\nwithout significant performance penalties. (2) Pipelining of communication and\ncomputation phases of successive subspaces is implemented to hide communication\ncosts without extra memory traffic.\n  As an application scenario we use filter diagonalization studies on\ntopological insulator materials. Performance numbers on up to 512 nodes of the\nOakForest-PACS and Piz Daint supercomputers are presented, achieving beyond 100\nTflop/s for computing 100 inner eigenvalues of sparse matrices of dimension one\nbillion.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.02156v1"
    },
    {
        "title": "Scaling Structured Multigrid to 500K+ Cores through Coarse-Grid\n  Redistribution",
        "authors": [
            "Andrew Reisner",
            "Luke N. Olson",
            "J. David Moulton"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  The efficient solution of sparse, linear systems resulting from the\ndiscretization of partial differential equations is crucial to the performance\nof many physics-based simulations. The algorithmic optimality of multilevel\napproaches for common discretizations makes them a good candidate for an\nefficient parallel solver. Yet, modern architectures for high-performance\ncomputing systems continue to challenge the parallel scalability of multilevel\nsolvers. While algebraic multigrid methods are robust for solving a variety of\nproblems, the increasing importance of data locality and cost of data movement\nin modern architectures motivates the need to carefully exploit structure in\nthe problem.\n  Robust logically structured variational multigrid methods, such as Black Box\nMultigrid (BoxMG), maintain structure throughout the multigrid hierarchy. This\navoids indirection and increased coarse-grid communication costs typical in\nparallel algebraic multigrid. Nevertheless, the parallel scalability of\nstructured multigrid is challenged by coarse-grid problems where the overhead\nin communication dominates computation. In this paper, an algorithm is\nintroduced for redistributing coarse-grid problems through incremental\nagglomeration. Guided by a predictive performance model, this algorithm\nprovides robust redistribution decisions for structured multilevel solvers.\n  A two-dimensional diffusion problem is used to demonstrate the significant\ngain in performance of this algorithm over the previous approach that used\nagglomeration to one processor. In addition, the parallel scalability of this\napproach is demonstrated on two large-scale computing systems, with solves on\nup to 500K+ cores.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.02481v1"
    },
    {
        "title": "Glyph: Symbolic Regression Tools",
        "authors": [
            "Markus Quade",
            "Julien Gout",
            "Markus Abel"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We present Glyph - a Python package for genetic programming based symbolic\nregression. Glyph is designed for usage let by numerical simulations let by\nreal world experiments. For experimentalists, glyph-remote provides a\nseparation of tasks: a ZeroMQ interface splits the genetic programming\noptimization task from the evaluation of an experimental (or numerical) run.\nGlyph can be accessed at http://github.com/ambrosys/glyph . Domain experts are\nbe able to employ symbolic regression in their experiments with ease, even if\nthey are not expert programmers. The reuse potential is kept high by a generic\ninterface design. Glyph is available on PyPI and Github.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.06226v2"
    },
    {
        "title": "A Benchmark of Selected Algorithmic Differentiation Tools on Some\n  Problems in Computer Vision and Machine Learning",
        "authors": [
            "Filip Šrajer",
            "Zuzana Kukelova",
            "Andrew Fitzgibbon"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Algorithmic differentiation (AD) allows exact computation of derivatives\ngiven only an implementation of an objective function. Although many AD tools\nare available, a proper and efficient implementation of AD methods is not\nstraightforward. The existing tools are often too different to allow for a\ngeneral test suite. In this paper, we compare fifteen ways of computing\nderivatives including eleven automatic differentiation tools implementing\nvarious methods and written in various languages (C++, F#, MATLAB, Julia and\nPython), two symbolic differentiation tools, finite differences, and\nhand-derived computation.\n  We look at three objective functions from computer vision and machine\nlearning. These objectives are for the most part simple, in the sense that no\niterative loops are involved, and conditional statements are encapsulated in\nfunctions such as {\\tt abs} or {\\tt logsumexp}. However, it is important for\nthe success of algorithmic differentiation that such `simple' objective\nfunctions are handled efficiently, as so many problems in computer vision and\nmachine learning are of this form.\n  Of course, our results depend on programmer skill, and familiarity with the\ntools. However, we contend that this paper presents an important datapoint: a\nskilled programmer devoting roughly a week to each tool produced the timings we\npresent. We have made our implementations available as open source to allow the\ncommunity to replicate and update these benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.10129v1"
    },
    {
        "title": "Big Math and the One-Brain Barrier A Position Paper and Architecture\n  Proposal",
        "authors": [
            "Jacques Carette",
            "William M. Farmer",
            "Michael Kohlhase",
            "Florian Rabe"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Over the last decades, a class of important mathematical results have\nrequired an ever increasing amount of human effort to carry out. For some, the\nhelp of computers is now indispensable. We analyze the implications of this\ntrend towards \"big mathematics\", its relation to human cognition, and how\nmachine support for big math can be organized. The central contribution of this\nposition paper is an information model for \"doing mathematics\", which posits\nthat humans very efficiently integrate four aspects: inference, computation,\ntabulation, and narration around a well-organized core of mathematical\nknowledge. The challenge for mathematical software systems is that these four\naspects need to be integrated as well. We briefly survey the state of the art.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.10405v2"
    },
    {
        "title": "Open Traffic Models -- A framework for hybrid simulation of\n  transportation networks",
        "authors": [
            "Gabriel Gomes"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  This paper introduces a new approach to hybrid traffic modeling, along with\nits implementation in software. The software allows modelers to assign traffic\nmodels to individual links in a network. Each model implements a series of\nmethods, refered to as the modeling interface. These methods are used by the\nprogram to exchange information between adjacent models. Traffic controllers\nare implemented in a similar manner. The paper outlines the important\ncomponents of the method: the network description, the description of demands,\nand the modeling and control interfaces. We include tests demonstrating the\npropagation of congestion between pairs of macroscpoic, mesoscopic, and\nmicroscopic models. Open Traffic Models is an open source implementation of\nthese concepts, and is available at https://github.com/ggomes/otm-sim.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.04009v1"
    },
    {
        "title": "Abstractions and automated algorithms for mixed domain finite element\n  methods",
        "authors": [
            "Cécile Daversin-Catty",
            "Chris N. Richardson",
            "Ada J. Ellingsrud",
            "Marie E. Rognes"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Mixed dimensional partial differential equations (PDEs) are equations\ncoupling unknown fields defined over domains of differing topological\ndimension. Such equations naturally arise in a wide range of scientific fields\nincluding geology, physiology, biology and fracture mechanics. Mixed\ndimensional PDEs are also commonly encountered when imposing non-standard\nconditions over a subspace of lower dimension e.g. through a Lagrange\nmultiplier. In this paper, we present general abstractions and algorithms for\nfinite element discretizations of mixed domain and mixed dimensional PDEs of\nco-dimension up to one (i.e. nD-mD with |n-m| <= 1). We introduce high level\nmathematical software abstractions together with lower level algorithms for\nexpressing and efficiently solving such coupled systems. The concepts\nintroduced here have also been implemented in the context of the FEniCS finite\nelement software. We illustrate the new features through a range of examples,\nincluding a constrained Poisson problem, a set of Stokes-type flow models and a\nmodel for ionic electrodiffusion.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.01166v1"
    },
    {
        "title": "Exa-Dune -- Flexible PDE Solvers, Numerical Methods and Applications",
        "authors": [
            "Peter Bastian",
            "Mirco Altenbernd",
            "Nils-Arne Dreier",
            "Christian Engwer",
            "Jorrit Fahlke",
            "René Fritze",
            "Markus Geveler",
            "Dominik Göddeke",
            "Oleg Iliev",
            "Olaf Ippisch",
            "Jan Mohring",
            "Steffen Müthing",
            "Mario Ohlberger",
            "Dirk Ribbrock",
            "Nikolay Shegunov",
            "Stefan Turek"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  In the Exa-Dune project we have developed, implemented and optimised\nnumerical algorithms and software for the scalable solution of partial\ndifferential equations (PDEs) on future exascale systems exhibiting a\nheterogeneous massively parallel architecture. In order to cope with the\nincreased probability of hardware failures, one aim of the project was to add\nflexible, application-oriented resilience capabilities into the framework.\nContinuous improvement of the underlying hardware-oriented numerical methods\nhave included GPU-based sparse approximate inverses, matrix-free\nsum-factorisation for high-order discontinuous Galerkin discretisations as well\nas partially matrix-free preconditioners. On top of that, additional\nscalability is facilitated by exploiting massive coarse grained parallelism\noffered by multiscale and uncertainty quantification methods where we have\nfocused on the adaptive choice of the coarse/fine scale and the overlap region\nas well as the combination of local reduced basis multiscale methods and the\nmultilevel Monte-Carlo algorithm. Finally, some of the concepts are applied in\na land-surface model including subsurface flow and surface runoff.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.01492v2"
    },
    {
        "title": "MFEM: a modular finite element methods library",
        "authors": [
            "Robert Anderson",
            "Julian Andrej",
            "Andrew Barker",
            "Jamie Bramwell",
            "Jean-Sylvain Camier",
            "Jakub Cerveny",
            "Veselin Dobrev",
            "Yohann Dudouit",
            "Aaron Fisher",
            "Tzanio Kolev",
            "Will Pazner",
            "Mark Stowell",
            "Vladimir Tomov",
            "Johann Dahm",
            "David Medina",
            "Stefano Zampini"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  MFEM is an open-source, lightweight, flexible and scalable C++ library for\nmodular finite element methods that features arbitrary high-order finite\nelement meshes and spaces, support for a wide variety of discretization\napproaches and emphasis on usability, portability, and high-performance\ncomputing efficiency. MFEM's goal is to provide application scientists with\naccess to cutting-edge algorithms for high-order finite element meshing,\ndiscretizations and linear solvers, while enabling researchers to quickly and\neasily develop and test new algorithms in very general, fully unstructured,\nhigh-order, parallel and GPU-accelerated settings. In this paper we describe\nthe underlying algorithms and finite element abstractions provided by MFEM,\ndiscuss the software implementation, and illustrate various applications of the\nlibrary.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.09220v2"
    },
    {
        "title": "Hierarchical Jacobi Iteration for Structured Matrices on GPUs using\n  Shared Memory",
        "authors": [
            "Mohammad Shafaet Islam",
            "Qiqi Wang"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  High fidelity scientific simulations modeling physical phenomena typically\nrequire solving large linear systems of equations which result from\ndiscretization of a partial differential equation (PDE) by some numerical\nmethod. This step often takes a vast amount of computational time to complete,\nand therefore presents a bottleneck in simulation work. Solving these linear\nsystems efficiently requires the use of massively parallel hardware with high\ncomputational throughput, as well as the development of algorithms which\nrespect the memory hierarchy of these hardware architectures to achieve high\nmemory bandwidth.\n  In this paper, we present an algorithm to accelerate Jacobi iteration for\nsolving structured problems on graphics processing units (GPUs) using a\nhierarchical approach in which multiple iterations are performed within on-chip\nshared memory every cycle. A domain decomposition style procedure is adopted in\nwhich the problem domain is partitioned into subdomains whose data is copied to\nthe shared memory of each GPU block. Jacobi iterations are performed internally\nwithin each block's shared memory, avoiding the need to perform expensive\nglobal memory accesses every step. We test our algorithm on the linear systems\narising from discretization of Poisson's equation in 1D and 2D, and observe\nspeedup in convergence using our shared memory approach compared to a\ntraditional Jacobi implementation which only uses global memory on the GPU. We\nobserve a x8 speedup in convergence in the 1D problem and a nearly x6 speedup\nin the 2D case from the use of shared memory compared to a conventional GPU\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.16465v1"
    },
    {
        "title": "A 55-line code for large-scale parallel topology optimization in 2D and\n  3D",
        "authors": [
            "Abhinav Gupta",
            "Rajib Chowdhury",
            "Anupam Chakrabarti",
            "Timon Rabczuk"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper presents a 55-line code written in python for 2D and 3D topology\noptimization (TO) based on the open-source finite element computing software\n(FEniCS), equipped with various finite element tools and solvers. PETSc is used\nas the linear algebra back-end, which results in significantly less\ncomputational time than standard python libraries. The code is designed based\non the popular solid isotropic material with penalization (SIMP) methodology.\nExtensions to multiple load cases, different boundary conditions, and\nincorporation of passive elements are also presented. Thus, this implementation\nis the most compact implementation of SIMP based topology optimization for 3D\nas well as 2D problems.\n  Utilizing the concept of Euclidean distance matrix to vectorize the\ncomputation of the weight matrix for the filter, we have achieved a substantial\nreduction in the computational time and have also made it possible for the code\nto work with complex ground structure configurations. We have also presented\nthe code's extension to large-scale topology optimization problems with support\nfor parallel computations on complex structural configuration, which could help\nstudents and researchers explore novel insights into the TO problem with dense\nmeshes. Appendix-A contains the complete code, and the website:\n\\url{https://github.com/iitrabhi/topo-fenics} also contains the complete code.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.08208v1"
    },
    {
        "title": "Quasi-Monte Carlo Software",
        "authors": [
            "Sou-Cheng T. Choi",
            "Fred J. Hickernell",
            "R. Jagadeeswaran",
            "Michael J. McCourt",
            "Aleksei G. Sorokin"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Practitioners wishing to experience the efficiency gains from using low\ndiscrepancy sequences need correct, robust, well-written software. This\narticle, based on our MCQMC 2020 tutorial, describes some of the better\nquasi-Monte Carlo (QMC) software available. We highlight the key software\ncomponents required by QMC to approximate multivariate integrals or\nexpectations of functions of vector random variables. We have combined these\ncomponents in QMCPy, a Python open-source library, which we hope will draw the\nsupport of the QMC community. Here we introduce QMCPy.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.07833v3"
    },
    {
        "title": "Using Jupyter for reproducible scientific workflows",
        "authors": [
            "Marijan Beg",
            "Juliette Taka",
            "Thomas Kluyver",
            "Alexander Konovalov",
            "Min Ragan-Kelley",
            "Nicolas M. Thiéry",
            "Hans Fangohr"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Literate computing has emerged as an important tool for computational studies\nand open science, with growing folklore of best practices. In this work, we\nreport two case studies - one in computational magnetism and another in\ncomputational mathematics - where domain-specific software was exposed to the\nJupyter environment. This enables high-level control of simulations and\ncomputation, interactive exploration of computational results, batch processing\non HPC resources, and reproducible workflow documentation in Jupyter notebooks.\nIn the first study, Ubermag drives existing computational micromagnetics\nsoftware through a domain-specific language embedded in Python. In the second\nstudy, a dedicated Jupyter kernel interfaces with the GAP system for\ncomputational discrete algebra and its dedicated programming language. In light\nof these case studies, we discuss the benefits of this approach, including\nprogress toward more reproducible and reusable research results and outputs,\nnotably through the use of infrastructure such as JupyterHub and Binder.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.09562v1"
    },
    {
        "title": "An Empirical Analysis of the R Package Ecosystem",
        "authors": [
            "Ethan Bommarito",
            "Michael J Bommarito II"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  In this research, we present a comprehensive, longitudinal empirical summary\nof the R package ecosystem, including not just CRAN, but also Bioconductor and\nGitHub. We analyze more than 25,000 packages, 150,000 releases, and 15 million\nfiles across two decades, providing comprehensive counts and trends for common\nmetrics across packages, releases, authors, licenses, and other important\nmetadata. We find that the historical growth of the ecosystem has been robust\nunder all measures, with a compound annual growth rate of 29% for active\npackages, 28% for new releases, and 26% for active maintainers. As with many\nsimilar social systems, we find a number of highly right-skewed distributions\nwith practical implications, including the distribution of releases per\npackage, packages and releases per author or maintainer, package and maintainer\ndependency in-degree, and size per package and release. For example, the top\nfive packages are imported by nearly 25% of all packages, and the top ten\nmaintainers support packages that are imported by over half of all packages. We\nalso highlight the dynamic nature of the ecosystem, recording both dramatic\nacceleration and notable deceleration in the growth of R. From a licensing\nperspective, we find a notable majority of packages are distributed under\ncopyleft licensing or omit licensing information entirely. The data, methods,\nand calculations herein provide an anchor for public discourse and industry\ndecisions related to R and CRAN, serving as a foundation for future research on\nthe R software ecosystem and \"data science\" more broadly.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.09904v1"
    },
    {
        "title": "ModelingToolkit: A Composable Graph Transformation System For\n  Equation-Based Modeling",
        "authors": [
            "Yingbo Ma",
            "Shashi Gowda",
            "Ranjan Anantharaman",
            "Chris Laughman",
            "Viral Shah",
            "Chris Rackauckas"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Getting good performance out of numerical equation solvers requires that the\nuser has provided stable and efficient functions representing their model.\nHowever, users should not be trusted to write good code. In this manuscript we\ndescribe ModelingToolkit (MTK), a symbolic equation-based modeling system which\nallows for composable transformations to generate stable, efficient, and\nparallelized model implementations. MTK blurs the lines of traditional symbolic\ncomputing by acting directly on a user's numerical code. We show the ability to\napply graph algorithms for automatically parallelizing and performing index\nreduction on code written for differential-algebraic equation (DAE) solvers,\n\"fixing\" the performance and stability of the model without requiring any\nchanges to on the user's part. We demonstrate how composable model\ntransformations can be combined with automated data-driven surrogate generation\ntechniques, allowing machine learning methods to generate accelerated\napproximate models within an acausal modeling framework. These reduced models\nare shown to outperform the Dymola Modelica compiler on an HVAC model by 590x\nat 3\\% error. Together, this demonstrates MTK as a system for bringing the\nlatest research in graph transformations directly to modeling applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.05244v3"
    },
    {
        "title": "XAMG: A library for solving linear systems with multiple right-hand side\n  vectors",
        "authors": [
            "Boris Krasnopolsky",
            "Alexey Medvedev"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper presents the XAMG library for solving large sparse systems of\nlinear algebraic equations with multiple right-hand side vectors. The library\nspecializes but is not limited to the solution of linear systems obtained from\nthe discretization of elliptic differential equations. A corresponding set of\nnumerical methods includes Krylov subspace, algebraic multigrid, Jacobi,\nGauss-Seidel, and Chebyshev iterative methods. The parallelization is\nimplemented with MPI+POSIX shared memory hybrid programming model, which\nintroduces a three-level hierarchical decomposition using the corresponding\nper-level synchronization and communication primitives. The code contains a\nnumber of optimizations, including the multilevel data segmentation,\ncompression of indices, mixed-precision floating-point calculations, vector\nstatus flags, and others. The XAMG library uses the program code of the\nwell-known hypre library to construct the multigrid matrix hierarchy. The\nXAMG's own implementation for the solve phase of the iterative methods provides\nup to a twofold speedup compared to hypre for the tests performed.\nAdditionally, XAMG provides extended functionality to solve systems with\nmultiple right-hand side vectors.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.07329v1"
    },
    {
        "title": "Hessian Chain Bracketing",
        "authors": [
            "Uwe Naumann",
            "Shubhaditya Burela"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Second derivatives of mathematical models for real-world phenomena are\nfundamental ingredients of a wide range of numerical simulation methods\nincluding parameter sensitivity analysis, uncertainty quantification, nonlinear\noptimization and model calibration. The evaluation of such Hessians often\ndominates the overall computational effort. The combinatorial {\\sc Hessian\nAccumulation} problem aiming to minimize the number of floating-point\noperations required for the computation of a Hessian turns out to be\nNP-complete. We propose a dynamic programming formulation for the solution of\n{\\sc Hessian Accumulation} over a sub-search space. This approach yields\nimprovements by factors of ten and higher over the state of the art based on\nsecond-order tangent and adjoint algorithmic differentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.09480v2"
    },
    {
        "title": "SailFFish: A Lightweight, Parallelised Fast Poisson Solver Library",
        "authors": [
            "Joseph Saverin"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  A solver for the Poisson equation for 1D, 2D and 3D regular grids is\npresented. The solver applies the convolution theorem in order to efficiently\nsolve the Poisson equation in spectral space over a rectangular computational\ndomain. Conversion to and from the spectral space is achieved through the use\nof discrete Fourier transforms, allowing for the application of highly\noptimised O(NlogN) algorithms. The data structure is configured to be modular\nsuch that the underlying interface for operations to, from and within the\nspectral space may be interchanged. For computationally demanding tasks, the\nlibrary is optimised by making use of parallel processing architectures. A\nrange of boundary conditions can be applied to the domain including periodic,\nDirichlet, Neumann and fully unbounded. In the case of Neumann and Dirichlet\nboundary conditions, arbitrary inhomogeneous boundary conditions may be\nspecified. The desired solution may be found either on regular (cell-boundary)\nor staggered (cell-centre) grid configurations. For problems with periodic,\nDirichlet or Neumann boundary conditions either a pseudo-spectral or a\nsecond-order finite difference operator may be applied. For unbounded boundary\nconditions a range of Green's functions are available. In addition to this, a\nrange of differential operators may be applied in the spectral space in order\nto treat different forms of the Poisson equation or to extract highly accurate\ngradients of the input fields. The underlying framework of the solver is first\ndetailed, followed by a range of validations for each of the available boundary\ncondition types. Finally, the performance of the library is investigated. The\ncode is free and publicly available under a GNU v3.0 license.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.01145v1"
    },
    {
        "title": "Matrix representation of a solution of a combinatorial problem of the\n  group theory",
        "authors": [
            "Krasimir Yordzhev",
            "Lilyana Totina"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  An equivalence relation in the symmetric group, where is a positive integer\nhas been considered. An algorithm for calculation of the number of the\nequivalence classes by this relation for arbitrary integer has been described.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.3179v1"
    },
    {
        "title": "Interaction entre mathématique et informatique Libre/Open Source par\n  le logiciel mathématique",
        "authors": [
            "K. I. A. Derouiche"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  This article focuses on the application of model development and opening the\nsource code available and implemented by the Free Software and Open Source\nFLOSS to the instructional and teaching has both mathematics and computer by\nthe read-write(R/W) of mathematical software, including the most famous cases\nare numerical and symbolic computation. The article analysis the development of\nthe mathematical model of Free/Open Source(math FLOSS) software has proven its\nimportance in the area of research in mathematics and computer science .\nHowever, although their actual use, is very readable in higher education\ncourses. We discuss the feasibility of this model to the characteristics of the\ndomain, actors, interaction they have and the communities they form during the\ndevelopment of the software. Finally, we propose a mathematical example of\nFree/Open Source(Math FlOSS) software as analysis device .\n",
        "pdf_link": "http://arxiv.org/pdf/1401.0827v1"
    },
    {
        "title": "An efficient way to assemble finite element matrices in vector languages",
        "authors": [
            "François Cuvelier",
            "Caroline Japhet",
            "Gilles Scarella"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Efficient Matlab codes in 2D and 3D have been proposed recently to assemble\nfinite element matrices. In this paper we present simple, compact and efficient\nvectorized algorithms, which are variants of these codes, in arbitrary\ndimension, without the use of any lower level language. They can be easily\nimplemented in many vector languages (e.g. Matlab, Octave, Python, Scilab, R,\nJulia, C++ with STL,...). The principle of these techniques is general, we\npresent it for the assembly of several finite element matrices in arbitrary\ndimension, in the P1 finite element case. We also provide an extension of the\nalgorithms to the case of a system of PDE's. Then we give an extension to\npiecewise polynomials of higher order. We compare numerically the performance\nof these algorithms in Matlab, Octave and Python, with that in FreeFEM++ and in\na compiled language such as C. Examples show that, unlike what is commonly\nbelieved, the performance is not radically worse than that of C : in the\nbest/worst cases, selected vector languages are respectively 2.3/3.5 and\n2.9/4.1 times slower than C in the scalar and vector cases. We also present\nnumerical results which illustrate the computational costs of these algorithms\ncompared to standard algorithms and to other recent ones.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3301v2"
    },
    {
        "title": "MRRR-based Eigensolvers for Multi-core Processors and Supercomputers",
        "authors": [
            "Matthias Petschow"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The real symmetric tridiagonal eigenproblem is of outstanding importance in\nnumerical computations; it arises frequently as part of eigensolvers for\nstandard and generalized dense Hermitian eigenproblems that are based on a\nreduction to tridiagonal form. For its solution, the algorithm of Multiple\nRelatively Robust Representations (MRRR or MR3 in short) - introduced in the\nlate 1990s - is among the fastest methods. To compute k eigenpairs of a real\nn-by-n tridiagonal T, MRRR only requires O(kn) arithmetic operations; in\ncontrast, all the other practical methods require O(k^2 n) or O(n^3) operations\nin the worst case. This thesis centers around the performance and accuracy of\nMRRR.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4950v1"
    },
    {
        "title": "STABLAB Documentation for KdV : Numerical proof of stability of roll\n  waves in the small-amplitude limit for inclined thin film flow",
        "authors": [
            "Blake Barker"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We document the MATLAB code used in the following study: Numerical proof of\nstability of roll waves in the small-amplitude limit for inclined thin film\nflow.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5353v1"
    },
    {
        "title": "COFFEE: an Optimizing Compiler for Finite Element Local Assembly",
        "authors": [
            "Fabio Luporini",
            "Ana Lucia Varbanescu",
            "Florian Rathgeber",
            "Gheorghe-Teodor Bercea",
            "J. Ramanujam",
            "David A. Ham",
            "Paul H. J. Kelly"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The numerical solution of partial differential equations using the finite\nelement method is one of the key applications of high performance computing.\nLocal assembly is its characteristic operation. This entails the execution of a\nproblem-specific kernel to numerically evaluate an integral for each element in\nthe discretized problem domain. Since the domain size can be huge, executing\nefficient kernels is fundamental. Their op- timization is, however, a\nchallenging issue. Even though affine loop nests are generally present, the\nshort trip counts and the complexity of mathematical expressions make it hard\nto determine a single or unique sequence of successful transformations.\nTherefore, we present the design and systematic evaluation of COF- FEE, a\ndomain-specific compiler for local assembly kernels. COFFEE manipulates\nabstract syntax trees generated from a high-level domain-specific language for\nPDEs by introducing domain-aware composable optimizations aimed at improving\ninstruction-level parallelism, especially SIMD vectorization, and register\nlocality. It then generates C code including vector intrinsics. Experiments\nusing a range of finite-element forms of increasing complexity show that\nsignificant performance improvement is achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.0904v2"
    },
    {
        "title": "Elements of Design for Containers and Solutions in the LinBox Library",
        "authors": [
            "Brice Boyer",
            "Jean-Guillaume Dumas",
            "Pascal Giorgi",
            "Clément Pernet",
            "B. David Saunders"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We describe in this paper new design techniques used in the \\cpp exact linear\nalgebra library \\linbox, intended to make the library safer and easier to use,\nwhile keeping it generic and efficient. First, we review the new simplified\nstructure for containers, based on our \\emph{founding scope allocation} model.\nWe explain design choices and their impact on coding: unification of our matrix\nclasses, clearer model for matrices and submatrices, \\etc Then we present a\nvariation of the \\emph{strategy} design pattern that is comprised of a\ncontroller--plugin system: the controller (solution) chooses among plug-ins\n(algorithms) that always call back the controllers for subtasks. We give\nexamples using the solution \\mul. Finally we present a benchmark architecture\nthat serves two purposes: Providing the user with easier ways to produce\ngraphs; Creating a framework for automatically tuning the library and\nsupporting regression testing.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.3262v1"
    },
    {
        "title": "Pipelined Iterative Solvers with Kernel Fusion for Graphics Processing\n  Units",
        "authors": [
            "Karl Rupp",
            "Josef Weinbub",
            "Ansgar Jüngel",
            "Tibor Grasser"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  We revisit the implementation of iterative solvers on discrete graphics\nprocessing units and demonstrate the benefit of implementations using extensive\nkernel fusion for pipelined formulations over conventional implementations of\nclassical formulations. The proposed implementations with both CUDA and OpenCL\nare freely available in ViennaCL and are shown to be competitive with or even\nsuperior to other solver packages for graphics processing units. Highest\nperformance gains are obtained for small to medium-sized systems, while our\nimplementations are on par with vendor-tuned implementations for very large\nsystems. Our results are especially beneficial for transient problems, where\nmany small to medium-sized systems instead of a single big system need to be\nsolved.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.4054v3"
    },
    {
        "title": "GammaCHI: a package for the inversion and computation of the gamma and\n  chi-square cumulative distribution functions (central and noncentral)",
        "authors": [
            "A. Gil",
            "J. Segura",
            "N. M. Temme"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  A Fortran 90 module (GammaCHI) for computing and inverting the gamma and\nchi-square cumulative distribution functions (central and noncentral) is\npresented. The main novelty of this package are the reliable and accurate\ninversion routines for the noncentral cumulative distribution functions.\nAdditionally, the package also provides routines for computing the gamma\nfunction, the error function and other functions related to the gamma function.\nThe module includes the routines cdfgamC, invcdfgamC, cdfgamNC, invcdfgamNC,\nerrorfunction, inverfc, gamma, loggam, gamstar and quotgamm for the computation\nof the central gamma distribution function (and its complementary function),\nthe inversion of the central gamma distribution function, the computation of\nthe noncentral gamma distribution function (and its complementary function),\nthe inversion of the noncentral gamma distribution function, the computation of\nthe error function and its complementary function, the inversion of the\ncomplementary error function, the computation of: the gamma function, the\nlogarithm of the gamma function, the regulated gamma function and the ratio of\ntwo gamma functions, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.01578v1"
    },
    {
        "title": "Firedrake: automating the finite element method by composing\n  abstractions",
        "authors": [
            "Florian Rathgeber",
            "David A. Ham",
            "Lawrence Mitchell",
            "Michael Lange",
            "Fabio Luporini",
            "Andrew T. T. McRae",
            "Gheorghe-Teodor Bercea",
            "Graham R. Markall",
            "Paul H. J. Kelly"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Firedrake is a new tool for automating the numerical solution of partial\ndifferential equations. Firedrake adopts the domain-specific language for the\nfinite element method of the FEniCS project, but with a pure Python\nruntime-only implementation centred on the composition of several existing and\nnew abstractions for particular aspects of scientific computing. The result is\na more complete separation of concerns which eases the incorporation of\nseparate contributions from computer scientists, numerical analysts and\napplication specialists. These contributions may add functionality, or improve\nperformance.\n  Firedrake benefits from automatically applying new optimisations. This\nincludes factorising mixed function spaces, transforming and vectorising inner\nloops, and intrinsically supporting block matrix operations. Importantly,\nFiredrake presents a simple public API for escaping the UFL abstraction. This\nallows users to implement common operations that fall outside pure variational\nformulations, such as flux-limiters.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.01809v3"
    },
    {
        "title": "FASTA: A Generalized Implementation of Forward-Backward Splitting",
        "authors": [
            "Tom Goldstein",
            "Christoph Studer",
            "Richard Baraniuk"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  This is a user manual for the software package FASTA.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.04979v3"
    },
    {
        "title": "TTC: A high-performance Compiler for Tensor Transpositions",
        "authors": [
            "Paul Springer",
            "Jeff R. Hammond",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  We present TTC, an open-source parallel compiler for multidimensional tensor\ntranspositions. In order to generate high-performance C++ code, TTC explores a\nnumber of optimizations, including software prefetching, blocking,\nloop-reordering, and explicit vectorization. To evaluate the performance of\nmultidimensional transpositions across a range of possible use-cases, we also\nrelease a benchmark covering arbitrary transpositions of up to six dimensions.\nPerformance results show that the routines generated by TTC achieve close to\npeak memory bandwidth on both the Intel Haswell and the AMD Steamroller\narchitectures, and yield significant performance gains over modern compilers.\nBy implementing a set of pruning heuristics, TTC allows users to limit the\nnumber of potential solutions; this option is especially useful when dealing\nwith high-dimensional tensors, as the search space might become prohibitively\nlarge. Experiments indicate that when only 100 potential solutions are\nconsidered, the resulting performance is about 99% of that achieved with\nexhaustive search.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.02297v1"
    },
    {
        "title": "Pymanopt: A Python Toolbox for Optimization on Manifolds using Automatic\n  Differentiation",
        "authors": [
            "James Townsend",
            "Niklas Koep",
            "Sebastian Weichwald"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Optimization on manifolds is a class of methods for optimization of an\nobjective function, subject to constraints which are smooth, in the sense that\nthe set of points which satisfy the constraints admits the structure of a\ndifferentiable manifold. While many optimization problems are of the described\nform, technicalities of differential geometry and the laborious calculation of\nderivatives pose a significant barrier for experimenting with these methods.\n  We introduce Pymanopt (available at https://pymanopt.github.io), a toolbox\nfor optimization on manifolds, implemented in Python, that---similarly to the\nManopt Matlab toolbox---implements several manifold geometries and optimization\nalgorithms. Moreover, we lower the barriers to users further by using automated\ndifferentiation for calculating derivative information, saving users time and\nsaving them from potential calculation and implementation errors.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.03236v4"
    },
    {
        "title": "A mixed precision semi-Lagrangian algorithm and its performance on\n  accelerators",
        "authors": [
            "Lukas Einkemmer"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  In this paper we propose a mixed precision algorithm in the context of the\nsemi-Lagrangian discontinuous Galerkin method. The performance of this approach\nis evaluated on a traditional dual socket workstation as well as on a Xeon Phi\nand an NVIDIA K80. We find that the mixed precision algorithm can be\nimplemented efficiently on these architectures. This implies that, in addition\nto the considerable reduction in memory, a substantial increase in performance\ncan be observed as well. Moreover, we discuss the relative performance of our\nimplementations.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.07008v1"
    },
    {
        "title": "Computing Real Roots of Real Polynomials ... and now For Real!",
        "authors": [
            "Alexander Kobel",
            "Fabrice Rouillier",
            "Michael Sagraloff"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  Very recent work introduces an asymptotically fast subdivision algorithm,\ndenoted ANewDsc, for isolating the real roots of a univariate real polynomial.\nThe method combines Descartes' Rule of Signs to test intervals for the\nexistence of roots, Newton iteration to speed up convergence against clusters\nof roots, and approximate computation to decrease the required precision. It\nachieves record bounds on the worst-case complexity for the considered problem,\nmatching the complexity of Pan's method for computing all complex roots and\nimproving upon the complexity of other subdivision methods by several\nmagnitudes.\n  In the article at hand, we report on an implementation of ANewDsc on top of\nthe RS root isolator. RS is a highly efficient realization of the classical\nDescartes method and currently serves as the default real root solver in Maple.\nWe describe crucial design changes within ANewDsc and RS that led to a\nhigh-performance implementation without harming the theoretical complexity of\nthe underlying algorithm.\n  With an excerpt of our extensive collection of benchmarks, available online\nat http://anewdsc.mpi-inf.mpg.de/, we illustrate that the theoretical gain in\nperformance of ANewDsc over other subdivision methods also transfers into\npractice. These experiments also show that our new implementation outperforms\nboth RS and mature competitors by magnitudes for notoriously hard instances\nwith clustered roots. For all other instances, we avoid almost any overhead by\nintegrating additional optimizations and heuristics.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.00410v1"
    },
    {
        "title": "High level implementation of geometric multigrid solvers for finite\n  element problems: applications in atmospheric modelling",
        "authors": [
            "Lawrence Mitchell",
            "Eike Hermann Müller"
        ],
        "category": "cs.MS",
        "published_year": "2016",
        "summary": "  The implementation of efficient multigrid preconditioners for elliptic\npartial differential equations (PDEs) is a challenge due to the complexity of\nthe resulting algorithms and corresponding computer code. For sophisticated\nfinite element discretisations on unstructured grids an efficient\nimplementation can be very time consuming and requires the programmer to have\nin-depth knowledge of the mathematical theory, parallel computing and\noptimisation techniques on manycore CPUs. In this paper we show how the\ndevelopment of bespoke multigrid preconditioners can be simplified\nsignificantly by using a framework which allows the expression of the each\ncomponent of the algorithm at the correct abstraction level. Our approach (1)\nallows the expression of the finite element problem in a language which is\nclose to the mathematical formulation of the problem, (2) guarantees the\nautomatic generation and efficient execution of parallel optimised low-level\ncomputer code and (3) is flexible enough to support different abstraction\nlevels and give the programmer control over details of the preconditioner. We\nuse the composable abstractions of the Firedrake/PyOP2 package to demonstrate\nthe efficiency of this approach for the solution of strongly anisotropic PDEs\nin atmospheric modelling. The weak formulation of the PDE is expressed in\nUnified Form Language (UFL) and the lower PyOP2 abstraction layer allows the\nmanual design of computational kernels for a bespoke geometric multigrid\npreconditioner. We compare the performance of this preconditioner to a\nsingle-level method and hypre's BoomerAMG algorithm. The Firedrake/PyOP2 code\nis inherently parallel and we present a detailed performance analysis for a\nsingle node (24 cores) on the ARCHER supercomputer. Our implementation utilises\na significant fraction of the available memory bandwidth and shows very good\nweak scaling on up to 6,144 compute cores.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.00492v2"
    },
    {
        "title": "Automatic Differentiation using Constraint Handling Rules in Prolog",
        "authors": [
            "Samer Abdallah"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Automatic differentiation is a technique which allows a programmer to define\na numerical computation via compositions of a broad range of numeric and\ncomputational primitives and have the underlying system support the computation\nof partial derivatives of the result with respect to any of its inputs, without\nmaking any finite difference approximations, and without manipulating large\nsymbolic expressions representing the computation. This note describes a novel\napproach to reverse mode automatic differentiation using constraint logic\nprogrammming, specifically, the constraint handling rules (CHR) library of SWI\nProlog, resulting in a very small (50 lines of code) implementation. When\napplied to a differentiation-based implementation of the inside-outside\nalgorithm for parameter learning in probabilistic grammars, the CHR based\nimplementations outperformed two well-known frameworks for optimising\ndifferentiable functions, Theano and TensorFlow, by a large margin.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.00231v1"
    },
    {
        "title": "Solver composition across the PDE/linear algebra barrier",
        "authors": [
            "Robert C. Kirby",
            "Lawrence Mitchell"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The efficient solution of discretisations of coupled systems of partial\ndifferential equations (PDEs) is at the core of much of numerical simulation.\nSignificant effort has been expended on scalable algorithms to precondition\nKrylov iterations for the linear systems that arise. With few exceptions, the\nreported numerical implementation of such solution strategies is specific to a\nparticular model setup, and intimately ties the solver strategy to the\ndiscretisation and PDE, especially when the preconditioner requires auxiliary\noperators. In this paper, we present recent improvements in the Firedrake\nfinite element library that allow for straightforward development of the\nbuilding blocks of extensible, composable preconditioners that decouple the\nsolver from the model formulation. Our implementation extends the algebraic\ncomposability of linear solvers offered by the PETSc library by augmenting\noperators, and hence preconditioners, with the ability to provide any necessary\nauxiliary operators. Rather than specifying up front the full solver\nconfiguration, tied to the model, solvers can be developed independently of\nmodel formulation and configured at runtime. We illustrate with examples from\nincompressible fluids and temperature-driven convection.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.01346v3"
    },
    {
        "title": "Parareal Algorithm Implementation and Simulation in Julia",
        "authors": [
            "Tyler M. Masthay",
            "Saverio Perugini"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We present a full implementation of the parareal algorithm---an integration\ntechnique to solve differential equations in parallel---in the Julia\nprogramming language for a fully general, first-order, initial-value problem.\nWe provide a brief overview of Julia---a concurrent programming language for\nscientific computing. Our implementation of the parareal algorithm accepts both\ncoarse and fine integrators as functional arguments. We use Euler's method and\nanother Runge-Kutta integration technique as the integrators in our\nexperiments. We also present a simulation of the algorithm for purposes of\npedagogy and as a tool for investigating the performance of the algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.08569v2"
    },
    {
        "title": "GuiTeNet: A graphical user interface for tensor networks",
        "authors": [
            "Lisa Sahlmann",
            "Christian B. Mendl"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We introduce a graphical user interface for constructing arbitrary tensor\nnetworks and specifying common operations like contractions or splitting,\ndenoted GuiTeNet. Tensors are represented as nodes with attached legs,\ncorresponding to the ordered dimensions of the tensor. GuiTeNet visualizes the\ncurrent network, and instantly generates Python/NumPy source code for the\nhitherto sequence of user actions. Support for additional programming languages\nis planned for the future. We discuss the elementary operations on tensor\nnetworks used by GuiTeNet, together with high-level optimization strategies.\nThe software runs directly in web browsers and is available online at\nhttp://guitenet.org.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.00532v1"
    },
    {
        "title": "Accelerating wave-propagation algorithms with adaptive mesh refinement\n  using the Graphics Processing Unit (GPU)",
        "authors": [
            "Xinsheng Qin",
            "Randall J. LeVeque",
            "Michael R. Motley"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Clawpack is a library for solving nonlinear hyperbolic partial differential\nequations using high-resolution finite volume methods based on Riemann solvers\nand limiters. It supports Adaptive Mesh Refinement (AMR), which is essential in\nsolving multi-scale problems. Recently, we added capabilities to accelerate the\ncode by using the Graphics Process Unit (GPU). Routines that manage CPU and GPU\nAMR data and facilitate the execution of GPU kernels are added. Customized and\nCPU thread-safe memory managers are designed to manage GPU and CPU memory\npools, which is essential in eliminating the overhead of memory allocation and\nde-allocation. A global reduction is conducted every time step for dynamically\nadjusting the time step based on Courant number restrictions. Some small GPU\nkernels are merged into bigger kernels, which greatly reduces kernel launching\noverhead. A speed-up between $2$ and $3$ for the total running time is observed\nin an acoustics benchmark problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.02638v1"
    },
    {
        "title": "Bringing Together Dynamic Geometry Software and the Graphics Processing\n  Unit",
        "authors": [
            "Aaron Montag",
            "Jürgen Richter-Gebert"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We equip dynamic geometry software (DGS) with a user-friendly method that\nenables massively parallel calculations on the graphics processing unit (GPU).\nThis interplay of DGS and GPU opens up various applications in education and\nmathematical research. The GPU-aided discovery of mathematical properties,\ninteractive visualizations of algebraic surfaces (raycasting), the mathematical\ndeformation of images and footage in real-time, and computationally demanding\nnumerical simulations of PDEs are examples from the long and versatile list of\nnew domains that our approach makes accessible within a DGS. We ease the\ndevelopment of complex (mathematical) visualizations and provide a\nrapid-prototyping scheme for general-purpose computations (GPGPU).\n  The possibility to program both CPU and GPU with the use of only one\nhigh-level (scripting) programming language is a crucial aspect of our concept.\nWe embed shader programming seamlessly within a high-level (scripting)\nprogramming environment. The aforementioned requires the symbolic process of\nthe transcompilation of a high-level programming language into shader\nprogramming language for GPU and, in this article, we address the challenge of\nthe automatic translation of a high-level programming language to a shader\nlanguage of the GPU. To maintain platform independence and the possibility to\nuse our technology on modern devices, we focus on a realization through WebGL.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.04579v1"
    },
    {
        "title": "Code generation for generally mapped finite elements",
        "authors": [
            "Robert C. Kirby",
            "Lawrence Mitchell"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Many classical finite elements such as the Argyris and Bell elements have\nlong been absent from high-level PDE software. Building on recent theoretical\nwork, we describe how to implement very general finite element transformations\nin FInAT and hence into the Firedrake finite element system. Numerical results\nevaluate the new elements, comparing them to existing methods for classical\nproblems. For a second order model problem, we find that new elements give\nsmooth solutions at a mild increase in cost over standard Lagrange elements.\nFor fourth-order problems, however, the newly-enabled methods significantly\noutperform interior penalty formulations. We also give some advanced use cases,\nsolving the nonlinear Cahn-Hilliard equation and some biharmonic eigenvalue\nproblems (including Chladni plates) using $C^1$ discretizations.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.05513v2"
    },
    {
        "title": "Gravitational octree code performance evaluation on Volta GPU",
        "authors": [
            "Yohei Miki"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  In this study, the gravitational octree code originally optimized for the\nFermi, Kepler, and Maxwell GPU architectures is adapted to the Volta\narchitecture. The Volta architecture introduces independent thread scheduling\nrequiring either the insertion of the explicit synchronizations at appropriate\nlocations or the enforcement of the same implicit synchronizations as do the\nPascal or earlier architectures by specifying \\texttt{-gencode\narch=compute\\_60,code=sm\\_70}. The performance measurements on Tesla V100, the\ncurrent flagship GPU by NVIDIA, revealed that the $N$-body simulations of the\nAndromeda galaxy model with $2^{23} = 8388608$ particles took $3.8 \\times\n10^{-2}$~s or $3.3 \\times 10^{-2}$~s per step for each case. Tesla V100\nachieves a 1.4 to 2.2-fold acceleration in comparison with Tesla P100, the\nflagship GPU in the previous generation. The observed speed-up of 2.2 is\ngreater than 1.5, which is the ratio of the theoretical peak performance of the\ntwo GPUs. The independence of the units for integer operations from those for\nfloating-point number operations enables the overlapped execution of integer\nand floating-point number operations. It hides the execution time of the\ninteger operations leading to the speed-up rate above the theoretical peak\nperformance ratio. Tesla V100 can execute $N$-body simulation with up to $25\n\\times 2^{20} = 26214400$ particles, and it took $2.0 \\times 10^{-1}$~s per\nstep. It corresponds to $3.5$~TFlop/s, which is 22\\% of the single-precision\ntheoretical peak performance.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.02761v1"
    },
    {
        "title": "Zeffiro user interface for electromagnetic brain imaging: a GPU\n  accelerated FEM tool for forward and inverse computations in Matlab",
        "authors": [
            "Qin He",
            "Atena Rezaei",
            "Sampsa Pursiainen"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  This article introduces the Zeffiro interface (ZI) version 2.2 for brain\nimaging. ZI aims to provide a simple, accessible and multimodal open source\nplatform for finite element method (FEM) based and graphics processing unit\n(GPU) accelerated forward and inverse computations in the Matlab environment.\nIt allows one to (1) generate a given multi-compartment head model, (2) to\nevaluate a lead field matrix as well as (3) to invert and analyze a given set\nof measurements. GPU acceleration is applied in each of the processing stages\n(1)-(3). In its current configuration, ZI includes forward solvers for\nelectro-/magnetoencephalography (EEG) and linearized electrical impedance\ntomography (EIT) as well as a set of inverse solvers based on the hierarchical\nBayesian model (HBM). We report the results of EEG and EIT inversion tests\nperformed with real and synthetic data, respectively, and demonstrate\nnumerically how the inversion parameters affect the EEG inversion outcome in\nHBM. The GPU acceleration was found to be essential in the generation of the FE\nmesh and the LF matrix in order to achieve a reasonable computing time. The\ncode package can be extended in the future based on the directions given in\nthis article.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07717v4"
    },
    {
        "title": "Applying the swept rule for solving explicit partial differential\n  equations on heterogeneous computing systems",
        "authors": [
            "Daniel J. Magee",
            "Anthony S. Walker",
            "Kyle E. Niemeyer"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  Applications that exploit the architectural details of high-performance\ncomputing (HPC) systems have become increasingly invaluable in academia and\nindustry over the past two decades. The most important hardware development of\nthe last decade in HPC has been the General Purpose Graphics Processing Unit\n(GPGPU), a class of massively parallel devices that now contributes the\nmajority of computational power in the top 500 supercomputers. As these systems\ngrow, small costs such as latency---due to the fixed cost of memory accesses\nand communication---accumulate in a large simulation and become a significant\nbarrier to performance. The swept time-space decomposition rule is a\ncommunication-avoiding technique for time-stepping stencil update formulas that\nattempts to reduce latency costs. This work extends the swept rule by targeting\nheterogeneous, CPU/GPU architectures representing current and future HPC\nsystems. We compare our approach to a naive decomposition scheme with two test\nequations using an MPI+CUDA pattern on 40 processes over two nodes containing\none GPU. The swept rule produces a factor of 1.9 to 23 speedup for the heat\nequation and a factor of 1.1 to 2.0 speedup for the Euler equations, using the\nsame processors and work distribution, and with the best possible\nconfigurations. These results show the potential effectiveness of the swept\nrule for different equations and numerical schemes on massively parallel\ncomputing systems that incur substantial latency costs.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08282v2"
    },
    {
        "title": "Faster arbitrary-precision dot product and matrix multiplication",
        "authors": [
            "Fredrik Johansson"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present algorithms for real and complex dot product and matrix\nmultiplication in arbitrary-precision floating-point and ball arithmetic. A\nlow-overhead dot product is implemented on the level of GMP limb arrays; it is\nabout twice as fast as previous code in MPFR and Arb at precision up to several\nhundred bits. Up to 128 bits, it is 3-4 times as fast, costing 20-30 cycles per\nterm for floating-point evaluation and 40-50 cycles per term for balls. We\nhandle large matrix multiplications even more efficiently via blocks of scaled\ninteger matrices. The new methods are implemented in Arb and significantly\nspeed up polynomial operations and linear algebra.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.04289v2"
    },
    {
        "title": "Solving Polynomial Systems with phcpy",
        "authors": [
            "Jasmine Otto",
            "Angus Forbes",
            "Jan Verschelde"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The solutions of a system of polynomials in several variables are often\nneeded, e.g.: in the design of mechanical systems, and in phase-space analyses\nof nonlinear biological dynamics. Reliable, accurate, and comprehensive\nnumerical solutions are available through PHCpack, a FOSS package for solving\npolynomial systems with homotopy continuation. This paper explores new\ndevelopments in phcpy, a scripting interface for PHCpack, over the past five\nyears. For instance, phcpy is now available online through a JupyterHub server\nfeaturing Python2, Python3, and SageMath kernels. As small systems are solved\nin real-time by phcpy, they are suitable for interactive exploration through\nthe notebook interface. Meanwhile, phcpy supports GPU parallelization,\nimproving the speed and quality of solutions to much larger polynomial systems.\nFrom various model design and analysis problems in STEM, certain classes of\npolynomial system frequently arise, to which phcpy is well-suited.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.00096v1"
    },
    {
        "title": "GPU-based Parallel Computation Support for Stan",
        "authors": [
            "Rok Češnovar",
            "Steve Bronder",
            "Davor Sluga",
            "Jure Demšar",
            "Tadej Ciglarič",
            "Sean Talts",
            "Erik Štrumbelj"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  This paper details an extensible OpenCL framework that allows Stan to utilize\nheterogeneous compute devices. It includes GPU-optimized routines for the\nCholesky decomposition, its derivative, other matrix algebra primitives and\nsome commonly used likelihoods, with more additions planned for the near\nfuture. Stan users can now benefit from large speedups offered by GPUs with\nlittle effort and without changes to their existing Stan code. We demonstrate\nthe practical utility of our work with two examples - logistic regression and\nGaussian Process regression.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.01063v2"
    },
    {
        "title": "A generic finite element framework on parallel tree-based adaptive\n  meshes",
        "authors": [
            "Santiago Badia",
            "Alberto F. Martín",
            "Eric Neiva",
            "Francesc Verdugo"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  In this work we formally derive and prove the correctness of the algorithms\nand data structures in a parallel, distributed-memory, generic finite element\nframework that supports h-adaptivity on computational domains represented as\nforest-of-trees. The framework is grounded on a rich representation of the\nadaptive mesh suitable for generic finite elements that is built on top of a\nlow-level, light-weight forest-of-trees data structure handled by a\nspecialized, highly parallel adaptive meshing engine, for which we have\nidentified the requirements it must fulfill to be coupled into our framework.\nAtop this two-layered mesh representation, we build the rest of data structures\nrequired for the numerical integration and assembly of the discrete system of\nlinear equations. We consider algorithms that are suitable for both\nsubassembled and fully-assembled distributed data layouts of linear system\nmatrices. The proposed framework has been implemented within the FEMPAR\nscientific software library, using p4est as a practical forest-of-octrees\ndemonstrator. A strong scaling study of this implementation when applied to\nPoisson and Maxwell problems reveals remarkable scalability up to 32.2K CPU\ncores and 482.2M degrees of freedom. Besides, a comparative performance study\nof FEMPAR and the state-of-the-art deal.ii finite element software shows at\nleast comparative performance, and at most factor 2-3 improvements in the\nh-adaptive approximation of a Poisson problem with first- and second-order\nLagrangian finite elements, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.03709v2"
    },
    {
        "title": "Out-of-core singular value decomposition",
        "authors": [
            "Vadim Demchik",
            "Miroslav Bačák",
            "Stefan Bordag"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Singular value decomposition (SVD) is a standard matrix factorization\ntechnique that produces optimal low-rank approximations of matrices. It has\ndiverse applications, including machine learning, data science and signal\nprocessing. However, many common problems involve very large matrices that\ncannot fit in the main memory of commodity computers, making it impractical to\nuse standard SVD algorithms that assume fast random access or large amounts of\nspace for intermediate calculations. To address this issue, we have implemented\nan out-of-core (external memory) randomized SVD solution that is fully scalable\nand efficiently parallelizable. This solution factors both dense and sparse\nmatrices of arbitrarily large size within arbitrarily small memory limits,\nefficiently using out-of-core storage as needed. It uses an innovative\ntechnique for partitioning matrices that lends itself to out-of-core and\nparallel processing, as well as memory and I/O use planning, automatic load\nbalancing, performance tuning, and makes possible a number of other practical\nenhancements to the current state-of-the-art. Furthermore, by using persistent\nexternal storage (generally HDDs or SSDs), users can resume interrupted\noperations without having to recalculate previously performed steps, solving a\nmajor practical problem in factoring very large matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.06470v1"
    },
    {
        "title": "GPU Fast Convolution via the Overlap-and-Save Method in Shared Memory",
        "authors": [
            "Karel Adámek",
            "Sofia Dimoudi",
            "Mike Giles",
            "Wesley Armour"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  We present an implementation of the overlap-and-save method, a method for the\nconvolution of very long signals with short response functions, which is\ntailored to GPUs. We have implemented several FFT algorithms (using the CUDA\nprogramming language) which exploit GPU shared memory, allowing for GPU\naccelerated convolution. We compare our implementation with an implementation\nof the overlap-and-save algorithm utilizing the NVIDIA FFT library (cuFFT). We\ndemonstrate that by using a shared memory based FFT we can achieved significant\nspeed-ups for certain problem sizes and lower the memory requirements of the\noverlap-and-save method on GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.01972v2"
    },
    {
        "title": "New robust ScaLAPACK routine for computing the QR factorization with\n  column pivoting",
        "authors": [
            "Zvonimir Bujanović",
            "Zlatko Drmač"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  In this note we describe two modifications of the ScaLAPACK subroutines\nPxGEQPF for computing the QR factorization with the Businger-Golub column\npivoting. First, we resolve a subtle numerical instability in the same way as\nwe have done it for the LAPACK subroutines xGEQPF, xGEQP3 in 2006. [LAPACK\nWorking Note 176 (2006); ACM Trans. Math. Softw. 2008]. The problem originates\nin the first release of LINPACK in the 1970's: due to severe cancellations in\nthe down-dating of partial column norms, the pivoting procedure may be in the\ndark completely about the true norms of the pivot column candidates. This may\ncause miss-pivoting, and as a result loss of the important rank revealing\nstructure of the computed triangular factor, with severe consequences on other\nsolvers that rely on the rank revealing pivoting. The instability is so subtle\nthat, e.g., inserting a WRITE statement or changing the process topology can\ndrastically change the result. Secondly, we also correct a programming error in\nthe complex subroutines PCGEQPF, PZGEQPF, which also causes wrong pivoting\nbecause of erroneous use of PSCNRM2, PDZNRM2 for the explicit norm computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.05623v1"
    },
    {
        "title": "Some remarks on the performance of Matlab, Python and Octave in\n  simulating dynamical systems",
        "authors": [
            "P. F. S. Guedes",
            "E. G. Nepomuceno"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Matlab has been considered as a leader computational platform for many\nengineering fields. Well documented and reliable, Matlab presents as a great\nadvantage its ability to increase the user productivity. However, Python and\nOctave are among some of the languages that have challenged Matlab. Octave and\nPython are well known examples of high-level scripting languages, with a great\nadvantage of being open source software. The novelty of this paper is devoted\nto offer a comparison among these tree languages in the simulation of dynamical\nsystems. We have applied the lower bound error to estimate the error of\nsimulation. The comparison was performed with the chaotic systems Duffing-Ueda\noscillator and the Chua's circuit, both identified with polynomial NARMAX.\nOctave presents the best reliable outcome. Nevertheless, Matlab needs the\nlowest time to undertake the same activity. Python has presented the worse\nresult for the stop simulation criterion.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.06117v1"
    },
    {
        "title": "NEP: a module for the parallel solution of nonlinear eigenvalue problems\n  in SLEPc",
        "authors": [
            "Carmen Campos",
            "Jose E. Roman"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  SLEPc is a parallel library for the solution of various types of large-scale\neigenvalue problems. In the last years we have been developing a module within\nSLEPc, called NEP, that is intended for solving nonlinear eigenvalue problems.\nThese problems can be defined by means of a matrix-valued function that depends\nnonlinearly on a single scalar parameter. We do not consider the particular\ncase of polynomial eigenvalue problems (which are implemented in a different\nmodule in SLEPc) and focus here on rational eigenvalue problems and other\ngeneral nonlinear eigenproblems involving square roots or any other nonlinear\nfunction. The paper discusses how the NEP module has been designed to fit the\nneeds of applications and provides a description of the available solvers,\nincluding some implementation details such as parallelization. Several test\nproblems coming from real applications are used to evaluate the performance and\nreliability of the solvers.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.11712v3"
    },
    {
        "title": "Matrix Equations, Sparse Solvers: M-M.E.S.S.-2.0.1 -- Philosophy,\n  Features and Application for (Parametric) Model",
        "authors": [
            "Peter Benner",
            "Martin Köhler",
            "Jens Saak"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Matrix equations are omnipresent in (numerical) linear algebra and systems\ntheory. Especially in model order reduction (MOR) they play a key role in many\nbalancing based reduction methods for linear dynamical systems. When these\nsystems arise from spatial discretizations of evolutionary partial differential\nequations, their coefficient matrices are typically large and sparse. Moreover,\nthe numbers of inputs and outputs of these systems are typically far smaller\nthan the number of spatial degrees of freedom. Then, in many situations the\nsolutions of the corresponding large-scale matrix equations are observed to\nhave low (numerical) rank. This feature is exploited by M-M.E.S.S. to find\nsuccessively larger low-rank factorizations approximating the solutions. This\ncontribution describes the basic philosophy behind the implementation and the\nfeatures of the package, as well as its application in the model order\nreduction of large-scale linear time-invariant (LTI) systems and parametric LTI\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.02088v2"
    },
    {
        "title": "Flexible numerical optimization with ensmallen",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel",
            "Rahul Ganesh Prabhu",
            "Suryoday Basak",
            "Zhihao Lou",
            "Conrad Sanderson"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This report provides an introduction to the ensmallen numerical optimization\nlibrary, as well as a deep dive into the technical details of how it works. The\nlibrary provides a fast and flexible C++ framework for mathematical\noptimization of arbitrary user-supplied functions. A large set of pre-built\noptimizers is provided, including many variants of Stochastic Gradient Descent\nand Quasi-Newton optimizers. Several types of objective functions are\nsupported, including differentiable, separable, constrained, and categorical\nobjective functions. Implementation of a new optimizer requires only one\nmethod, while a new objective function requires typically only one or two C++\nmethods. Through internal use of C++ template metaprogramming, ensmallen\nprovides support for arbitrary user-supplied callbacks and automatic inference\nof unsupplied methods without any runtime overhead. Empirical comparisons show\nthat ensmallen outperforms other optimization frameworks (such as Julia and\nSciPy), sometimes by large margins. The library is available at\nhttps://ensmallen.org and is distributed under the permissive BSD license.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.04103v4"
    },
    {
        "title": "Parallel Robust Computation of Generalized Eigenvectors of Matrix\n  Pencils",
        "authors": [
            "Carl Christian Kjelgaard Mikkelsen",
            "Mirko Myllykoski"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper we consider the problem of computing generalized eigenvectors\nof a matrix pencil in real Schur form. In exact arithmetic, this problem can be\nsolved using substitution. In practice, substitution is vulnerable to\nfloating-point overflow. The robust solvers xTGEVC in LAPACK prevent overflow\nby dynamically scaling the eigenvectors. These subroutines are sequential\nscalar codes which compute the eigenvectors one by one. In this paper we\ndiscuss how to derive robust blocked algorithms. The new StarNEig library\ncontains a robust task-parallel solver Zazamoukh which runs on top of StarPU.\nOur numerical experiments show that Zazamoukh achieves a super-linear speedup\ncompared with DTGEVC for sufficiently large matrices.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.04776v1"
    },
    {
        "title": "Pressio: Enabling projection-based model reduction for large-scale\n  nonlinear dynamical systems",
        "authors": [
            "Francesco Rizzi",
            "Patrick J. Blonigan",
            "Eric J. Parish",
            "Kevin T. Carlberg"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This work introduces Pressio, an open-source project aimed at enabling\nleading-edge projection-based reduced order models (ROMs) for large-scale\nnonlinear dynamical systems in science and engineering. Pressio provides\nmodel-reduction methods that can reduce both the number of spatial and temporal\ndegrees of freedom for any dynamical system expressible as a system of\nparameterized ordinary differential equations (ODEs). We leverage this simple,\nexpressive mathematical framework as a pivotal design choice to enable a\nminimal application programming interface (API) that is natural to dynamical\nsystems. The core component of Pressio is a C++11 header-only library that\nleverages generic programming to support applications with arbitrary data types\nand arbitrarily complex programming models. This is complemented with Python\nbindings to expose these C++ functionalities to Python users with negligible\noverhead and no user-required binding code. We discuss the distinguishing\ncharacteristics of Pressio relative to existing model-reduction libraries,\noutline its key design features, describe how the user interacts with it, and\npresent two test cases -- including one with over 20 million degrees of freedom\n-- that highlight the performance results of Pressio and illustrate the breath\nof problems that can be addressed with it.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07798v3"
    },
    {
        "title": "Scalable parallel algorithm for solving non-stationary systems of linear\n  inequalities",
        "authors": [
            "Leonid B. Sokolinsky",
            "Irina M. Sokolinskaya"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper, a scalable iterative projection-type algorithm for solving\nnon-stationary systems of linear inequalities is considered. A non-stationary\nsystem is understood as a large-scale system of inequalities in which\ncoefficients and constant terms can change during the calculation process. The\nproposed parallel algorithm uses the concept of pseudo-projection which\ngeneralizes the notion of orthogonal projection. The parallel pseudo-projection\nalgorithm is implemented using the parallel BSF-skeleton. An analytical\nestimation of the algorithm scalability boundary is obtained on the base of the\nBSF cost metric. The large-scale computational experiments were performed on a\ncluster computing system. The obtained results confirm the efficiency of the\nproposed approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.09956v2"
    },
    {
        "title": "FlexRiLoG -- A SageMath Package for Motions of Graphs",
        "authors": [
            "Georg Grasegger",
            "Jan Legerský"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In this paper we present the SageMath package FlexRiLoG (short for flexible\nand rigid labelings of graphs). Based on recent results the software generates\nmotions of graphs using special edge colorings. The package computes and\nillustrates the colorings and the motions. We present the structure and usage\nof the package.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.12029v1"
    },
    {
        "title": "Making RooFit Ready for Run 3",
        "authors": [
            "Stephan Hageboeck",
            "Lorenzo Moneta"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used\nin most searches and measurements at the Large Hadron Collider. The data to be\ncollected in Run 3 will enable measurements with higher precision and models\nwith larger complexity, but also require faster data processing. In this work,\nfirst results on modernising RooFit's collections, restructuring data flow and\nvectorising likelihood fits in RooFit will be discussed. These improvements\nwill enable the LHC experiments to process larger datasets without having to\ncompromise with respect to model complexity, as fitting times would increase\nsignificantly with the large datasets to be expected in Run 3.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.12861v1"
    },
    {
        "title": "A Faster, More Intuitive RooFit",
        "authors": [
            "Stephan Hageboeck"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used\nin most searches and measurements at the Large Hadron Collider as well as at\n$B$ factories. Larger datasets to be collected at e.g. the High-Luminosity LHC\nwill enable measurements with higher precision, but will require faster data\nprocessing to keep fitting times stable. In this work, a simplification of\nRooFit's interfaces and a redesign of its internal dataflow is presented.\nInterfaces are being extended to look and feel more STL-like to be more\naccessible both from C++ and Python to improve interoperability and ease of\nuse, while maintaining compatibility with old code. The redesign of the\ndataflow improves cache locality and data loading, and can be used to process\nbatches of data with vectorised SIMD computations. This reduces the time for\ncomputing unbinned likelihoods by a factor four to 16. This will allow to fit\nlarger datasets of the future in the same time or faster than today's fits.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.12875v3"
    },
    {
        "title": "Interpolation of Dense and Sparse Rational Functions and other\n  Improvements in $\\texttt{FireFly}$",
        "authors": [
            "Jonas Klappert",
            "Sven Yannick Klein",
            "Fabian Lange"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We present the main improvements and new features in version $\\texttt{2.0}$\nof the open-source $\\texttt{C++}$ library $\\texttt{FireFly}$ for the\ninterpolation of rational functions. This includes algorithmic improvements,\ne.g. a hybrid algorithm for dense and sparse rational functions and an\nalgorithm to identify and remove univariate factors. The new version is applied\nto a Feynman-integral reduction to showcase the runtime improvements achieved.\nMoreover, $\\texttt{FireFly}$ now supports parallelization with $\\texttt{MPI}$\nand offers new tools like a parser for expressions or an executable for the\ninsertion of replacement tables.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.01463v2"
    },
    {
        "title": "Automatic Differentiation in ROOT",
        "authors": [
            "Vassil Vassilev",
            "Aleksandr Efremov",
            "Oksana Shadura"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  In mathematics and computer algebra, automatic differentiation (AD) is a set\nof techniques to evaluate the derivative of a function specified by a computer\nprogram. AD exploits the fact that every computer program, no matter how\ncomplicated, executes a sequence of elementary arithmetic operations (addition,\nsubtraction, multiplication, division, etc.), elementary functions (exp, log,\nsin, cos, etc.) and control flow statements. AD takes source code of a function\nas input and produces source code of the derived function. By applying the\nchain rule repeatedly to these operations, derivatives of arbitrary order can\nbe computed automatically, accurately to working precision, and using at most a\nsmall constant factor more arithmetic operations than the original program.\n  This paper presents AD techniques available in ROOT, supported by Cling, to\nproduce derivatives of arbitrary C/C++ functions through implementing source\ncode transformation and employing the chain rule of differential calculus in\nboth forward mode and reverse mode. We explain its current integration for\ngradient computation in TFormula. We demonstrate the correctness and\nperformance improvements in ROOT's fitting algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.04435v1"
    },
    {
        "title": "Fully Parallel Mesh I/O using PETSc DMPlex with an Application to\n  Waveform Modeling",
        "authors": [
            "Vaclav Hapla",
            "Matthew G. Knepley",
            "Michael Afanasiev",
            "Christian Boehm",
            "Martin van Driel",
            "Lion Krischer",
            "Andreas Fichtner"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Large-scale PDE simulations using high-order finite-element methods on\nunstructured meshes are an indispensable tool in science and engineering. The\nwidely used open-source PETSc library offers an efficient representation of\ngeneric unstructured meshes within its DMPlex module. This paper details our\nrecent implementation of parallel mesh reading and topological interpolation\n(computation of edges and faces from a cell-vertex mesh) into DMPlex. We apply\nthese developments to seismic wave propagation scenarios on Mars as an example\napplication. The principal motivation is to overcome single-node memory limits\nand reach mesh sizes which were impossible before. Moreover, we demonstrate\nthat scalability of I/O and topological interpolation goes beyond 12'000 cores,\nand memory-imposed limits on mesh size vanish.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.08729v2"
    },
    {
        "title": "Efficient parallel 3D computation of the compressible Euler equations\n  with an invariant-domain preserving second-order finite-element scheme",
        "authors": [
            "Matthias Maier",
            "Martin Kronbichler"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We discuss the efficient implementation of a high-performance second-order\ncollocation-type finite-element scheme for solving the compressible Euler\nequations of gas dynamics on unstructured meshes. The solver is based on the\nconvex limiting technique introduced by Guermond et al. (SIAM J. Sci. Comput.\n40, A3211-A3239, 2018). As such it is invariant-domain preserving, i.e., the\nsolver maintains important physical invariants and is guaranteed to be stable\nwithout the use of ad-hoc tuning parameters. This stability comes at the\nexpense of a significantly more involved algorithmic structure that renders\nconventional high-performance discretizations challenging. We develop an\nalgorithmic design that allows SIMD vectorization of the compute kernel,\nidentify the main ingredients for a good node-level performance, and report\nexcellent weak and strong scaling of a hybrid thread/MPI parallelization.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.00094v2"
    },
    {
        "title": "Algorithm 1019: A Task-based Multi-shift QR/QZ Algorithm with Aggressive\n  Early Deflation",
        "authors": [
            "Mirko Myllykoski"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The QR algorithm is one of the three phases in the process of computing the\neigenvalues and the eigenvectors of a dense nonsymmetric matrix. This paper\ndescribes a task-based QR algorithm for reducing an upper Hessenberg matrix to\nreal Schur form. The task-based algorithm also supports generalized eigenvalue\nproblems (QZ algorithm) but this paper concentrates on the standard case. The\ntask-based algorithm adopts previous algorithmic improvements, such as\ntightly-coupled multi-shifts and Aggressive Early Deflation (AED), and also\nincorporates several new ideas that significantly improve the performance. This\nincludes, but is not limited to, the elimination of several synchronization\npoints, the dynamic merging of previously separate computational steps, the\nshortening and the prioritization of the critical path, and experimental GPU\nsupport. The task-based implementation is demonstrated to be multiple times\nfaster than multi-threaded LAPACK and ScaLAPACK in both single-node and\nmulti-node configurations on two different machines based on Intel and AMD\nCPUs. The implementation is built on top of the StarPU runtime system and is\npart of the open-source StarNEig library.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.03576v3"
    },
    {
        "title": "A Survey of Numerical Methods Utilizing Mixed Precision Arithmetic",
        "authors": [
            "Ahmad Abdelfattah",
            "Hartwig Anzt",
            "Erik G. Boman",
            "Erin Carson",
            "Terry Cojean",
            "Jack Dongarra",
            "Mark Gates",
            "Thomas Grützmacher",
            "Nicholas J. Higham",
            "Sherry Li",
            "Neil Lindquist",
            "Yang Liu",
            "Jennifer Loe",
            "Piotr Luszczek",
            "Pratik Nayak",
            "Sri Pranesh",
            "Siva Rajamanickam",
            "Tobias Ribizel",
            "Barry Smith",
            "Kasia Swirydowicz",
            "Stephen Thomas",
            "Stanimire Tomov",
            "Yaohung M. Tsai",
            "Ichitaro Yamazaki",
            "Urike Meier Yang"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Within the past years, hardware vendors have started designing low precision\nspecial function units in response to the demand of the Machine Learning\ncommunity and their demand for high compute power in low precision formats.\nAlso the server-line products are increasingly featuring low-precision special\nfunction units, such as the NVIDIA tensor cores in ORNL's Summit supercomputer\nproviding more than an order of magnitude higher performance than what is\navailable in IEEE double precision. At the same time, the gap between the\ncompute power on the one hand and the memory bandwidth on the other hand keeps\nincreasing, making data access and communication prohibitively expensive\ncompared to arithmetic operations. To start the multiprecision focus effort, we\nsurvey the numerical linear algebra community and summarize all existing\nmultiprecision knowledge, expertise, and software capabilities in this\nlandscape analysis report. We also include current efforts and preliminary\nresults that may not yet be considered \"mature technology,\" but have the\npotential to grow into production quality within the multiprecision focus\neffort. As we expect the reader to be familiar with the basics of numerical\nlinear algebra, we refrain from providing a detailed background on the\nalgorithms themselves but focus on how mixed- and multiprecision technology can\nhelp improving the performance of these methods and present highlights of\napplication significantly outperforming the traditional fixed precision\nmethods.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.06674v1"
    },
    {
        "title": "Accelerating Geometric Multigrid Preconditioning with Half-Precision\n  Arithmetic on GPUs",
        "authors": [
            "Kyaw L. Oo",
            "Andreas Vogel"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs,\nhigh-performance computing applications can benefit from lower precision at\nappropriate spots to speed up the overall execution time. In this paper, we\ninvestigate a mixed-precision geometric multigrid method to solve large sparse\nsystems of equations stemming from discretization of elliptic PDEs. While the\nfinal solution is always computed with high-precision accuracy, an iterative\nrefinement approach with multigrid preconditioning in lower precision and\nresiduum scaling is employed. We compare the FP64 baseline for Poisson's\nequation to purely FP16 multigrid preconditioning and to the employment of\nFP16-FP32-FP64 combinations within a mesh hierarchy. While the iteration count\nis almost not affected by using lower accuracy, the solver runtime is\nconsiderably decreased due to the reduced memory transfer and a speedup of up\nto 2.5x is gained for the overall solver. We investigate the performance of\nselected kernels with the hierarchical Roofline model.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.07539v1"
    },
    {
        "title": "multivar_horner: a python package for computing Horner factorisations of\n  multivariate polynomials",
        "authors": [
            "Jannik Michelfeit"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Many applications in the sciences require numerically stable and\ncomputationally efficient evaluation of multivariate polynomials. Finding\nbeneficial representations of polynomials, such as Horner factorisations, is\ntherefore crucial. multivar_horner, the python package presented here, is the\nfirst open source software for computing multivariate Horner factorisations.\nThis work briefly outlines the functionality of the package and puts it into\nreference to previous work in the field. Benchmarks additionally prove the\nadvantages of the implementation and Horner factorisations in general.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.13152v2"
    },
    {
        "title": "The ITensor Software Library for Tensor Network Calculations",
        "authors": [
            "Matthew Fishman",
            "Steven R. White",
            "E. Miles Stoudenmire"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  ITensor is a system for programming tensor network calculations with an\ninterface modeled on tensor diagram notation, which allows users to focus on\nthe connectivity of a tensor network without manually bookkeeping tensor\nindices. The ITensor interface rules out common programming errors and enables\nrapid prototyping of tensor network algorithms. After discussing the philosophy\nbehind the ITensor approach, we show examples of each part of the interface\nincluding Index objects, the ITensor product operator, tensor factorizations,\ntensor storage types, algorithms for matrix product state (MPS) and matrix\nproduct operator (MPO) tensor networks, quantum number conserving block-sparse\ntensors, and the NDTensors library. We also review publications that have used\nITensor for quantum many-body physics and for other areas where tensor networks\nare increasingly applied. To conclude we discuss promising features and\noptimizations to be added in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.14822v2"
    },
    {
        "title": "Scipp: Scientific data handling with labeled multi-dimensional arrays\n  for C++ and Python",
        "authors": [
            "Simon Heybrock",
            "Owen Arnold",
            "Igor Gudich",
            "Daniel Nixon",
            "Neil Vaytet"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Scipp is heavily inspired by the Python library xarray. It enriches raw\nNumPy-like multi-dimensional arrays of data by adding named dimensions and\nassociated coordinates. Multiple arrays are combined into datasets. On top of\nthis, scipp introduces (i) implicit handling of physical units, (ii) implicit\npropagation of uncertainties, (iii) support for histograms, i.e., bin-edge\ncoordinate axes, which exceed the data's dimension extent by one, and (iv)\nsupport for event data. In conjunction these features enable a more natural and\nmore concise user experience. The combination of named dimensions, coordinates,\nand units helps to drastically reduce the risk for programming errors. The core\nof scipp is written in C++ to open opportunities for performance improvements\nthat a Python-based solution would not allow for. On top of the C++ core,\nscipp's Python components provide functionality for plotting and content\nrepresentations, e.g., for use in Jupyter Notebooks. While none of scipp's\nconcepts in isolation is novel per-se, we are not aware of any project\ncombining all of these aspects in a single coherent software package.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.00257v1"
    },
    {
        "title": "Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations\n  and visualizations via ParaMonte::Python library",
        "authors": [
            "Amir Shahmoradi",
            "Fatemeh Bagheri",
            "Joshua Alexander Osborne"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial\nand MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for\nsampling mathematical objective functions, in particular, the posterior\ndistributions of parameters in Bayesian modeling and analysis in data science,\nMachine Learning, and scientific inference in general. In addition to providing\naccess to fast high-performance serial/parallel Monte Carlo and MCMC sampling\nroutines, the ParaMonte::Python library provides extensive post-processing and\nvisualization tools that aim to automate and streamline the process of model\ncalibration and uncertainty quantification in Bayesian data analysis.\nFurthermore, the automatically-enabled restart functionality of\nParaMonte::Python samplers ensure seamless fully-deterministic into-the-future\nrestart of Monte Carlo simulations, should any interruptions happen. The\nParaMonte::Python library is MIT-licensed and is permanently maintained on\nGitHub at\nhttps://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.00724v1"
    },
    {
        "title": "Concurrent Alternating Least Squares for multiple simultaneous Canonical\n  Polyadic Decompositions",
        "authors": [
            "Christos Psarras",
            "Lars Karlsson",
            "Rasmus Bro",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Tensor decompositions, such as CANDECOMP/PARAFAC (CP), are widely used in a\nvariety of applications, such as chemometrics, signal processing, and machine\nlearning. A broadly used method for computing such decompositions relies on the\nAlternating Least Squares (ALS) algorithm. When the number of components is\nsmall, regardless of its implementation, ALS exhibits low arithmetic intensity,\nwhich severely hinders its performance and makes GPU offloading ineffective. We\nobserve that, in practice, experts often have to compute multiple\ndecompositions of the same tensor, each with a small number of components\n(typically fewer than 20), to ultimately find the best ones to use for the\napplication at hand. In this paper, we illustrate how multiple decompositions\nof the same tensor can be fused together at the algorithmic level to increase\nthe arithmetic intensity. Therefore, it becomes possible to make efficient use\nof GPUs for further speedups; at the same time the technique is compatible with\nmany enhancements typically used in ALS, such as line search, extrapolation,\nand non-negativity constraints. We introduce the Concurrent ALS algorithm and\nlibrary, which offers an interface to Matlab, and a mechanism to effectively\ndeal with the issue that decompositions complete at different times.\nExperimental results on artificial and real datasets demonstrate a shorter time\nto completion due to increased arithmetic intensity.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.04678v2"
    },
    {
        "title": "Generalized eigen, singular value, and partial least squares\n  decompositions: The GSVD package",
        "authors": [
            "Derek Beaton"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The generalized singular value decomposition (GSVD, a.k.a. \"SVD triplet\",\n\"duality diagram\" approach) provides a unified strategy and basis to perform\nnearly all of the most common multivariate analyses (e.g., principal\ncomponents, correspondence analysis, multidimensional scaling, canonical\ncorrelation, partial least squares). Though the GSVD is ubiquitous, powerful,\nand flexible, it has very few implementations. Here I introduce the GSVD\npackage for R. The general goal of GSVD is to provide a small set of accessible\nfunctions to perform the GSVD and two other related decompositions (generalized\neigenvalue decomposition, generalized partial least squares-singular value\ndecomposition). Furthermore, GSVD helps provide a more unified conceptual\napproach and nomenclature to many techniques. I first introduce the concept of\nthe GSVD, followed by a formal definition of the generalized decompositions.\nNext I provide some key decisions made during development, and then a number of\nexamples of how to use GSVD to implement various statistical techniques. These\nexamples also illustrate one of the goals of GSVD: how others can (or should)\nbuild analysis packages that depend on GSVD. Finally, I discuss the possible\nfuture of GSVD.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.14734v3"
    },
    {
        "title": "tvopt: A Python Framework for Time-Varying Optimization",
        "authors": [
            "Nicola Bastianello"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper introduces tvopt, a Python framework for prototyping and\nbenchmarking time-varying (or online) optimization algorithms. The paper first\ndescribes the theoretical approach that informed the development of tvopt. Then\nit discusses the different components of the framework and their use for\nmodeling and solving time-varying optimization problems. In particular, tvopt\nprovides functionalities for defining both centralized and distributed online\nproblems, and a collection of built-in algorithms to solve them, for example\ngradient-based methods, ADMM and other splitting methods. Moreover, the\nframework implements prediction strategies to improve the accuracy of the\nonline solvers. The paper then proposes some numerical results on a benchmark\nproblem and discusses their implementation using tvopt. The code for tvopt is\navailable at https://github.com/nicola-bastianello/tvopt.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.07119v2"
    },
    {
        "title": "calculus: High Dimensional Numerical and Symbolic Calculus in R",
        "authors": [
            "Emanuele Guidotti"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  The R package calculus implements C++ optimized functions for numerical and\nsymbolic calculus, such as the Einstein summing convention, fast computation of\nthe Levi-Civita symbol and generalized Kronecker delta, Taylor series\nexpansion, multivariate Hermite polynomials, high-order derivatives, ordinary\ndifferential equations, differential operators and numerical integration in\narbitrary orthogonal coordinate systems. The library applies numerical methods\nwhen working with R functions or symbolic programming when working with\ncharacters or expressions. The package handles multivariate numerical calculus\nin arbitrary dimensions and coordinates and implements the symbolic counterpart\nof the numerical methods whenever possible, without depending on external\ncomputer algebra systems. Except for Rcpp, the package has no strict\ndependencies in order to provide a stable self-contained toolbox that invites\nre-use.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00086v1"
    },
    {
        "title": "FDApy: a Python package for functional data",
        "authors": [
            "Steven Golovkine"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We introduce FDApy, an open-source Python package for the analysis of\nfunctional data. The package provides tools for the representation of\n(multivariate) functional data defined on different dimensional domains and for\nfunctional data that is irregularly sampled. Additionally, dimension reduction\ntechniques are implemented for multivariate and/or multidimensional functional\ndata that are regularly or irregularly sampled. A toolbox for generating\nfunctional datasets is also provided. The documentation includes installation\nand usage instructions, examples on simulated and real datasets and a complete\ndescription of the API. FDApy is released under the MIT license. The code and\ndocumentation are available at https://github.com/StevenGolovkine/FDApy.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.11003v2"
    },
    {
        "title": "AuTO: A Framework for Automatic differentiation in Topology Optimization",
        "authors": [
            "Aaditya Chandrasekhar",
            "Saketh Sridhara",
            "Krishnan Suresh"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  A critical step in topology optimization (TO) is finding sensitivities.\nManual derivation and implementation of the sensitivities can be quite\nlaborious and error-prone, especially for non-trivial objectives, constraints\nand material models. An alternate approach is to utilize automatic\ndifferentiation (AD). While AD has been around for decades, and has also been\napplied in TO, wider adoption has largely been absent.\n  In this educational paper, we aim to reintroduce AD for TO, and make it\neasily accessible through illustrative codes. In particular, we employ JAX, a\nhigh-performance Python library for automatically computing sensitivities from\na user defined TO problem. The resulting framework, referred to here as AuTO,\nis illustrated through several examples in compliance minimization, compliant\nmechanism design and microstructural design.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.01965v1"
    },
    {
        "title": "mlf-core: a framework for deterministic machine learning",
        "authors": [
            "Lukas Heumos",
            "Philipp Ehmele",
            "Luis Kuhn Cuellar",
            "Kevin Menden",
            "Edmund Miller",
            "Steffen Lemke",
            "Gisela Gabernet",
            "Sven Nahnsen"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Machine learning has shown extensive growth in recent years and is now\nroutinely applied to sensitive areas. To allow appropriate verification of\npredictive models before deployment, models must be deterministic. However,\nmajor machine learning libraries default to the usage of non-deterministic\nalgorithms based on atomic operations. Solely fixing all random seeds is not\nsufficient for deterministic machine learning. To overcome this shortcoming,\nvarious machine learning libraries released deterministic counterparts to the\nnon-deterministic algorithms. We evaluated the effect of these algorithms on\ndeterminism and runtime. Based on these results, we formulated a set of\nrequirements for deterministic machine learning and developed a new software\nsolution, the mlf-core ecosystem, which aids machine learning projects to meet\nand keep these requirements. We applied mlf-core to develop deterministic\nmodels in various biomedical fields including a single cell autoencoder with\nTensorFlow, a PyTorch-based U-Net model for liver-tumor segmentation in CT\nscans, and a liver cancer classifier based on gene expression profiles with\nXGBoost.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.07651v2"
    },
    {
        "title": "Boosting Memory Access Locality of the Spectral Element Method with\n  Hilbert Space-Filling Curves",
        "authors": [
            "Roger R. F. Araújo",
            "Lutz Gross",
            "Samuel Xavier-de-Souza"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We propose an algorithm based on Hilbert space-filling curves to reorder mesh\nelements in memory for use with the Spectral Element Method, aiming to attain\nfewer cache misses, better locality of data reference and faster execution. We\npresent a technique to numerically simulate acoustic wave propagation in 2D\ndomains using the Spectral Element Method, and discuss computational\nperformance aspects of this procedure. We reorder mesh-related data via Hilbert\ncurves to achieve sizable reductions in execution time under several mesh\nconfigurations in shared-memory systems. Our experiments show that the Hilbert\ncurve approach works well with meshes of several granularities and also with\nsmall and large variations in element sizes, achieving reductions between 9%\nand 25% in execution time when compared to three other ordering schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.08416v1"
    },
    {
        "title": "pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models",
        "authors": [
            "Anirudhan Badrinath",
            "Frederic Wang",
            "Zachary Pardos"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Bayesian Knowledge Tracing, a model used for cognitive mastery estimation,\nhas been a hallmark of adaptive learning research and an integral component of\ndeployed intelligent tutoring systems (ITS). In this paper, we provide a brief\nhistory of knowledge tracing model research and introduce pyBKT, an accessible\nand computationally efficient library of model extensions from the literature.\nThe library provides data generation, fitting, prediction, and cross-validation\nroutines, as well as a simple to use data helper interface to ingest typical\ntutor log dataset formats. We evaluate the runtime with various dataset sizes\nand compare to past implementations. Additionally, we conduct sanity checks of\nthe model using experiments with simulated data to evaluate the accuracy of its\nEM parameter learning and use real-world data to validate its predictions,\ncomparing pyBKT's supported model variants with results from the papers in\nwhich they were originally introduced. The library is open source and open\nlicense for the purpose of making knowledge tracing more accessible to\ncommunities of research and practice and to facilitate progress in the field\nthrough easier replication of past approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.00385v2"
    },
    {
        "title": "TensorFlow RiemOpt: a library for optimization on Riemannian manifolds",
        "authors": [
            "Oleg Smirnov"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The adoption of neural networks and deep learning in non-Euclidean domains\nhas been hindered until recently by the lack of scalable and efficient learning\nframeworks. Existing toolboxes in this space were mainly motivated by research\nand education use cases, whereas practical aspects, such as deploying and\nmaintaining machine learning models, were often overlooked.\n  We attempt to bridge this gap by proposing TensorFlow RiemOpt, a Python\nlibrary for optimization on Riemannian manifolds in TensorFlow. The library is\ndesigned with the aim for a seamless integration with the TensorFlow ecosystem,\ntargeting not only research, but also streamlining production machine learning\npipelines.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.13921v2"
    },
    {
        "title": "Fast Evaluation of Finite Element Weak Forms Using Python Tensor\n  Contraction Packages",
        "authors": [
            "Robert Cimrman"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  In finite element calculations, the integral forms are usually evaluated\nusing nested loops over elements, and over quadrature points. Many such forms\n(e.g. linear or multi-linear) can be expressed in a compact way, without the\nexplicit loops, using a single tensor contraction expression by employing the\nEinstein summation convention. To automate this process and leverage existing\nhigh performance codes, we first introduce a notation allowing trivial\ndifferentiation of multi-linear finite element forms. Based on that we propose\nand describe a new transpiler from Einstein summation based expressions,\naugmented to allow defining multi-linear finite element weak forms, to regular\ntensor contraction expressions. The resulting expressions are compatible with a\nnumber of Python scientific computing packages, that implement, optimize and in\nsome cases parallelize the general tensor contractions. We assess the\nperformance of those packages, as well as the influence of operand memory\nlayouts and tensor contraction paths optimizations on the elapsed time and\nmemory requirements of the finite element form evaluations. We also compare the\nefficiency of the transpiled weak form implementations to the C-based functions\navailable in the finite element package SfePy.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.04121v1"
    },
    {
        "title": "Algorithmic Causal Effect Identification with causaleffect",
        "authors": [
            "Martí Pedemonte",
            "Jordi Vitrià",
            "Álvaro Parafita"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Our evolution as a species made a huge step forward when we understood the\nrelationships between causes and effects. These associations may be trivial for\nsome events, but they are not in complex scenarios. To rigorously prove that\nsome occurrences are caused by others, causal theory and causal inference were\nformalized, introducing the $do$-operator and its associated rules. The main\ngoal of this report is to review and implement in Python some algorithms to\ncompute conditional and non-conditional causal queries from observational data.\nTo this end, we first present some basic background knowledge on probability\nand graph theory, before introducing important results on causal theory, used\nin the construction of the algorithms. We then thoroughly study the\nidentification algorithms presented by Shpitser and Pearl in 2006, explaining\nour implementation in Python alongside. The main identification algorithm can\nbe seen as a repeated application of the rules of $do$-calculus, and it\neventually either returns an expression for the causal query from experimental\nprobabilities or fails to identify the causal effect, in which case the effect\nis non-identifiable. We introduce our newly developed Python library and give\nsome usage examples.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.04632v1"
    },
    {
        "title": "Accelerated Multiple Precision Direct Method and Mixed Precision\n  Iterative Refinement on Python Programming Environment",
        "authors": [
            "Tomonori Kouya"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Current Python programming environment does not have any reliable and\nefficient multiple precision floating-point (MPF) arithmetic except ``mpmath\"\nand ``gmpy2\" packages based on GNU MP(GMP) and MPFR libraries. Although it is\nwell known that multi-component-type MPF library can be utilized for middle\nlength precision arithmetic under 200 bits, they are not widely used on Python\nenvironment. In this paper, we describe our accelerated MPF direct method with\nAVX2 techniques and its application to mixed precision iterative refinement\ncombined with mpmath, and demonstrate their efficiency on x86\\_64 computational\nenvironments.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.12550v1"
    },
    {
        "title": "High Performance Uncertainty Quantification with Parallelized Multilevel\n  Markov Chain Monte Carlo",
        "authors": [
            "Linus Seelinger",
            "Anne Reinarz",
            "Leonhard Rannabauer",
            "Michael Bader",
            "Peter Bastian",
            "Robert Scheichl"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Numerical models of complex real-world phenomena often necessitate High\nPerformance Computing (HPC). Uncertainties increase problem dimensionality\nfurther and pose even greater challenges.\n  We present a parallelization strategy for multilevel Markov chain Monte\nCarlo, a state-of-the-art, algorithmically scalable Uncertainty Quantification\n(UQ) algorithm for Bayesian inverse problems, and a new software framework\nallowing for large-scale parallelism across forward model evaluations and the\nUQ algorithms themselves. The main scalability challenge presents itself in the\nform of strong data dependencies introduced by the MLMCMC method, prohibiting\ntrivial parallelization.\n  Our software is released as part of the modular and open-source MIT UQ\nLibrary (MUQ), and can easily be coupled with arbitrary user codes. We\ndemonstrate it using the DUNE and the ExaHyPE Engine. The latter provides a\nrealistic, large-scale tsunami model in which identify the source of a tsunami\nfrom buoy-elevation data.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.14552v1"
    },
    {
        "title": "Improving MATLAB's isprime performance without arbitrary-precision\n  arithmetic",
        "authors": [
            "Travis Near"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  MATLAB is a numerical computing platform used by scientists, engineers,\nmathematicians, and students which contains many mathematical functions,\nincluding isprime. MATLAB's isprime function determines which elements of an\ninput array are prime. This research details modular arithmetic techniques, the\nMiller-Rabin primality test, vectorized operations, and division-minimizing\nstrategies which harness the power of MATLAB's capabilities to improve\nisprime's performance. The results are typically 5 to 10 times faster for small\nintegers and many hundreds of times faster for large integers and long arrays.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.04791v1"
    },
    {
        "title": "Adaptive numerical simulations with Trixi.jl: A case study of Julia for\n  scientific computing",
        "authors": [
            "Hendrik Ranocha",
            "Michael Schlottke-Lakemper",
            "Andrew R. Winters",
            "Erik Faulhaber",
            "Jesse Chan",
            "Gregor J. Gassner"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We present Trixi.jl, a Julia package for adaptive high-order numerical\nsimulations of hyperbolic partial differential equations. Utilizing Julia's\nstrengths, Trixi.jl is extensible, easy to use, and fast. We describe the main\ndesign choices that enable these features and compare Trixi.jl with a mature\nopen source Fortran code that uses the same numerical methods. We conclude with\nan assessment of Julia for simulation-focused scientific computing, an area\nthat is still dominated by traditional high-performance computing languages\nsuch as C, C++, and Fortran.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.06476v2"
    },
    {
        "title": "PyParSVD: A streaming, distributed and randomized\n  singular-value-decomposition library",
        "authors": [
            "Romit Maulik",
            "Gianmarco Mengaldo"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We introduce PyParSVD\\footnote{https://github.com/Romit-Maulik/PyParSVD}, a\nPython library that implements a streaming, distributed and randomized\nalgorithm for the singular value decomposition. To demonstrate its\neffectiveness, we extract coherent structures from scientific data. Futhermore,\nwe show weak scaling assessments on up to 256 nodes of the Theta machine at\nArgonne Leadership Computing Facility, demonstrating potential for large-scale\ndata analyses of practical data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.08845v1"
    },
    {
        "title": "The ensmallen library for flexible numerical optimization",
        "authors": [
            "Ryan R. Curtin",
            "Marcus Edel",
            "Rahul Ganesh Prabhu",
            "Suryoday Basak",
            "Zhihao Lou",
            "Conrad Sanderson"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We overview the ensmallen numerical optimization library, which provides a\nflexible C++ framework for mathematical optimization of user-supplied objective\nfunctions. Many types of objective functions are supported, including general,\ndifferentiable, separable, constrained, and categorical. A diverse set of\npre-built optimizers is provided, including Quasi-Newton optimizers and many\nvariants of Stochastic Gradient Descent. The underlying framework facilitates\nthe implementation of new optimizers. Optimization of an objective function\ntypically requires supplying only one or two C++ functions. Custom behavior can\nbe easily specified via callback functions. Empirical comparisons show that\nensmallen outperforms other frameworks while providing more functionality. The\nlibrary is available at https://ensmallen.org and is distributed under the\npermissive BSD license.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12981v2"
    },
    {
        "title": "OGRe: An Object-Oriented General Relativity Package for Mathematica",
        "authors": [
            "Barak Shoshany"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We present OGRe, a modern Mathematica package for tensor calculus, designed\nto be both powerful and user-friendly. The package can be used in a variety of\ncontexts where tensor calculations are needed, in both mathematics and physics,\nbut it is especially suitable for general relativity. By implementing an\nobject-oriented design paradigm, OGRe allows calculating arbitrarily\ncomplicated tensor formulas easily, and automatically transforms between index\nconfigurations and coordinate systems behind the scenes as needed, eliminating\nuser errors by making it impossible for the user to combine tensors in\ninconsistent ways. Other features include displaying tensors in various forms,\nautomatic calculation of curvature tensors and geodesic equations, easy\nimporting and exporting of tensors between sessions, optimized algorithms and\nparallelization for improved performance, and more.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.04193v1"
    },
    {
        "title": "AbstractDifferentiation.jl: Backend-Agnostic Differentiable Programming\n  in Julia",
        "authors": [
            "Frank Schäfer",
            "Mohamed Tarek",
            "Lyndon White",
            "Chris Rackauckas"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  No single Automatic Differentiation (AD) system is the optimal choice for all\nproblems. This means informed selection of an AD system and combinations can be\na problem-specific variable that can greatly impact performance. In the Julia\nprogramming language, the major AD systems target the same input and thus in\ntheory can compose. Hitherto, switching between AD packages in the Julia\nLanguage required end-users to familiarize themselves with the user-facing API\nof the respective packages. Furthermore, implementing a new, usable AD package\nrequired AD package developers to write boilerplate code to define convenience\nAPI functions for end-users. As a response to these issues, we present\nAbstractDifferentiation.jl for the automatized generation of an extensive,\nunified, user-facing API for any AD package. By splitting the complexity\nbetween AD users and AD developers, AD package developers only need to\nimplement one or two primitive definitions to support various utilities for AD\nusers like Jacobians, Hessians and lazy product operators from native\nprimitives such as pullbacks or pushforwards, thus removing tedious -- but so\nfar inevitable -- boilerplate code, and enabling the easy switching and\ncomposing between AD implementations for end-users.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.12449v2"
    },
    {
        "title": "LazySets.jl: Scalable Symbolic-Numeric Set Computations",
        "authors": [
            "Marcelo Forets",
            "Christian Schilling"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  LazySets.jl is a Julia library that provides ways to symbolically represent\nsets of points as geometric shapes, with a special focus on convex sets and\npolyhedral approximations. LazySets provides methods to apply common set\noperations, convert between different set representations, and efficiently\ncompute with sets in high dimensions using specialized algorithms based on the\nset types. LazySets is the core library of JuliaReach, a cutting-edge software\naddressing the fundamental problem of reachability analysis: computing the set\nof states that are reachable by a dynamical system from all initial states and\nfor all admissible inputs and parameters. While the library was originally\ndesigned for reachability and formal verification, its scope goes beyond such\ntopics. LazySets is an easy-to-use, general-purpose and scalable library for\ncomputations that mix symbolics and numerics. In this article we showcase the\nbasic functionality, highlighting some of the key design choices.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.01711v2"
    },
    {
        "title": "Least Squares on GPUs in Multiple Double Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper describes the application of the code generated by the CAMPARY\nsoftware to accelerate the solving of linear systems in the least squares sense\non Graphics Processing Units (GPUs), in double double, quad double, and octo\ndouble precision. The goal is to use accelerators to offset the cost overhead\ncaused by multiple double precision arithmetic. For the blocked Householder QR\nand the back substitution, of interest are those dimensions at which teraflop\nperformance is attained. The other interesting question is the cost overhead\nfactor that appears each time the precision is doubled.\n  Experimental results are reported on five different NVIDIA GPUs, with a\nparticular focus on the P100 and the V100, both capable of teraflop\nperformance. Thanks to the high Compute to Global Memory Access (CGMA) ratios\nof multiple double arithmetic, teraflop performance is already attained running\nthe double double QR on 1,024-by-1,024 matrices, both on the P100 and the V100.\nFor the back substitution, the dimension of the upper triangular system must be\nas high as 17,920 to reach one teraflops on the V100, in quad double precision,\nand then taking only the times spent by the kernels into account. The lower\nperformance of the back substitution in small dimensions does not prevent\nteraflop performance of the solver at dimension 1,024, as the time for the QR\ndecomposition dominates.\n  In doubling the precision from double double to quad double and from quad\ndouble to octo double, the observed cost overhead factors are lower than the\nfactors predicted by the arithmetical operation counts. This observation\ncorrelates with the increased performance for increased precision, which can\nagain be explained by the high CGMA ratios.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.08375v2"
    },
    {
        "title": "Escaping the abstraction: a foreign function interface for the Unified\n  Form Language [UFL]",
        "authors": [
            "Nacime Bouziani",
            "David A. Ham"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  High level domain specific languages for the finite element method underpin\nhigh productivity programming environments for simulations based on partial\ndifferential equations (PDE) while employing automatic code generation to\nachieve high performance. However, a limitation of this approach is that it\ndoes not support operators that are not directly expressible in the vector\ncalculus. This is critical in applications where PDEs are not enough to\naccurately describe the physical problem of interest. The use of deep learning\ntechniques have become increasingly popular in filling this knowledge gap, for\nexample to include features not represented in the differential equations, or\nclosures for unresolved spatiotemporal scales. We introduce an interface within\nthe Firedrake finite element system that enables a seamless interface with deep\nlearning models. This new feature composes with the automatic differentiation\ncapabilities of Firedrake, enabling the automated solution of inverse problems.\nOur implementation interfaces with PyTorch and can be extended to other machine\nlearning libraries. The resulting framework supports complex models coupling\nPDEs and deep learning whilst maintaining separation of concerns between\napplication scientists and software experts.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.00945v1"
    },
    {
        "title": "Source-to-Source Automatic Differentiation of OpenMP Parallel Loops",
        "authors": [
            "Jan Hückelheim",
            "Laurent Hascoët"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  This paper presents our work toward correct and efficient automatic\ndifferentiation of OpenMP parallel worksharing loops in forward and reverse\nmode. Automatic differentiation is a method to obtain gradients of numerical\nprograms, which are crucial in optimization, uncertainty quantification, and\nmachine learning. The computational cost to compute gradients is a common\nbottleneck in practice. For applications that are parallelized for multicore\nCPUs or GPUs using OpenMP, one also wishes to compute the gradients in\nparallel. We propose a framework to reason about the correctness of the\ngenerated derivative code, from which we justify our OpenMP extension to the\ndifferentiation model. We implement this model in the automatic differentiation\ntool Tapenade and present test cases that are differentiated following our\nextended differentiation procedure. Performance of the generated derivative\nprograms in forward and reverse mode is better than sequential, although our\nreverse mode often scales worse than the input programs.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.01861v1"
    },
    {
        "title": "A set of R packages to estimate population counts from mobile phone data",
        "authors": [
            "Bogdan Oancea",
            "David Salgado",
            "Luis Sanguiao Sande",
            "Sandra Barragan"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  In this paper, we describe the software implementation of the methodological\nframework designed to incorporate mobile phone data into the current production\nchain of official statistics during the ESSnet Big Data II project. We present\nan overview of the architecture of the software stack, its components, the\ninterfaces between them, and show how they can be used. Our software\nimplementation consists in four R packages: destim for estimation of the\nspatial distribution of the mobile devices, deduplication for classification of\nthe devices as being in 1:1 or 2:1 correspondence with its owner, aggregation\nfor estimation of the number of individuals detected by the network starting\nfrom the geolocation probabilities and the duplicity probabilities and\ninference which combines the number of individuals provided by the previous\npackage with other information like the population counts from an official\nregister and the mobile operator penetration rates to provide an estimation of\nthe target population counts.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.05269v1"
    },
    {
        "title": "On the very accurate evaluation of the Voigt/complex error function with\n  small imaginary argument",
        "authors": [
            "Yihong Wang"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  A rapidly convergent series, based on Taylor expansion of the imaginary part\nof the complex error function, is presented for highly accurate approximation\nof the Voigt/complex error function with small imaginary argument (Y less than\n0.1). Error analysis and run-time tests in double-precision computing platform\nreveals that in the real and imaginary parts the proposed algorithm provides\naverage accuracy exceeding 10^-15 and 10^-16, respectively, and the calculation\nspeed is as fast as that of reported in recent publications. An optimized\nMATLAB code providing rapid computation with high accuracy is presented.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.02078v1"
    },
    {
        "title": "ProbNum: Probabilistic Numerics in Python",
        "authors": [
            "Jonathan Wenger",
            "Nicholas Krämer",
            "Marvin Pförtner",
            "Jonathan Schmidt",
            "Nathanael Bosch",
            "Nina Effenberger",
            "Johannes Zenn",
            "Alexandra Gessner",
            "Toni Karvonen",
            "François-Xavier Briol",
            "Maren Mahsereci",
            "Philipp Hennig"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Probabilistic numerical methods (PNMs) solve numerical problems via\nprobabilistic inference. They have been developed for linear algebra,\noptimization, integration and differential equation simulation. PNMs naturally\nincorporate prior information about a problem and quantify uncertainty due to\nfinite computational resources as well as stochastic input. In this paper, we\npresent ProbNum: a Python library providing state-of-the-art probabilistic\nnumerical solvers. ProbNum enables custom composition of PNMs for specific\nproblem classes via a modular design as well as wrappers for off-the-shelf use.\nTutorials, documentation, developer guides and benchmarks are available online\nat www.probnum.org.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.02100v1"
    },
    {
        "title": "Accelerating jackknife resampling for the Canonical Polyadic\n  Decomposition",
        "authors": [
            "Christos Psarras",
            "Lars Karlsson",
            "Rasmus Bro",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The Canonical Polyadic (CP) tensor decomposition is frequently used as a\nmodel in applications in a variety of different fields. Using jackknife\nresampling to estimate parameter uncertainties is often desirable but results\nin an increase of the already high computational cost. Upon observation that\nthe resampled tensors, though different, are nearly identical, we show that it\nis possible to extend the recently proposed Concurrent ALS (CALS) technique to\na jackknife resampling scenario. This extension gives access to the\ncomputational efficiency advantage of CALS for the price of a modest increase\n(typically a few percent) in the number of floating point operations. Numerical\nexperiments on both synthetic and real-world datasets demonstrate that the new\nworkflow based on a CALS extension can be several times faster than a\nstraightforward workflow where the jackknife submodels are processed\nindividually.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.03985v1"
    },
    {
        "title": "Efficient implementation of modern entropy stable and kinetic energy\n  preserving discontinuous Galerkin methods for conservation laws",
        "authors": [
            "Hendrik Ranocha",
            "Michael Schlottke-Lakemper",
            "Jesse Chan",
            "Andrés M. Rueda-Ramírez",
            "Andrew R. Winters",
            "Florian Hindenlang",
            "Gregor J. Gassner"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Many modern discontinuous Galerkin (DG) methods for conservation laws make\nuse of summation by parts operators and flux differencing to achieve kinetic\nenergy preservation or entropy stability. While these techniques increase the\nrobustness of DG methods significantly, they are also computationally more\ndemanding than standard weak form nodal DG methods. We present several\nimplementation techniques to improve the efficiency of flux differencing DG\nmethods that use tensor product quadrilateral or hexahedral elements, in 2D or\n3D respectively. Focus is mostly given to CPUs and DG methods for the\ncompressible Euler equations, although these techniques are generally also\nuseful for other physical systems including the compressible Navier-Stokes and\nmagnetohydrodynamics equations. We present results using two open source codes,\nTrixi.jl written in Julia and FLUXO written in Fortran, to demonstrate that our\nproposed implementation techniques are applicable to different code bases and\nprogramming languages.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.10517v2"
    },
    {
        "title": "PyTracer: Automatically profiling numerical instabilities in Python",
        "authors": [
            "Yohan Chatelain",
            "Nigel Yong",
            "Gregory Kiar",
            "Tristan Glatard"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Numerical stability is a crucial requirement of reliable scientific\ncomputing. However, despite the pervasiveness of Python in data science,\nanalyzing large Python programs remains challenging due to the lack of scalable\nnumerical analysis tools available for this language. To fill this gap, we\ndeveloped PyTracer, a profiler to quantify numerical instability in Python\napplications. PyTracer transparently instruments Python code to produce\nnumerical traces and visualize them interactively in a Plotly dashboard. We\ndesigned PyTracer to be agnostic to numerical noise model, allowing for tool\nevaluation through Monte-Carlo Arithmetic, random rounding, random data\nperturbation, or structured noise for a particular application. We illustrate\nPyTracer's capabilities by testing the numerical stability of key functions in\nboth SciPy and Scikit-learn, two dominant Python libraries for mathematical\nmodeling. Through these evaluations, we demonstrate PyTracer as a scalable,\nautomatic, and generic framework for numerical profiling in Python.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.11508v2"
    },
    {
        "title": "An open tool based on lifex for myofibers generation in cardiac\n  computational models",
        "authors": [
            "Pasquale C. Africa",
            "Roberto Piersanti",
            "Marco Fedele",
            "Luca Dede'",
            "Alfio Quarteroni"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Modeling the whole cardiac function involves the solution of several complex\nmulti-physics and multi-scale models that are highly computationally demanding,\nwhich call for simpler yet accurate, high-performance computational tools.\nDespite the efforts made by several research groups, no software for\nwhole-heart fully-coupled cardiac simulations in the scientific community has\nreached full maturity yet. In this work we present the first publicly released\npackage of lifex, a high-performance Finite Element solver for multi-physics\nand multi-scale problems developed in the framework of the iHEART project. The\ngoal of lifex is twofold. On the one side, it aims at making in silico\nexperiments easily reproducible and accessible to a wide community of users,\nincluding those with a background in medicine or bio-engineering. On the other\nhand, as an academic research library lifex can be exploited by scientific\ncomputing experts to explore new mathematical models and numerical methods\nwithin a robust development framework. lifex has been developed with a modular\nstructure and will be released bundled in different modules. The tool presented\nhere proposes an innovative generator for myocardial fibers based on\nLaplace-Dirichlet Rule-Based Methods, which are the essential building blocks\nfor modeling the electrophysiological, mechanical and electromechanical cardiac\nfunction, from single-chamber to whole-heart simulations. This report comes\nwith an extensive technical and mathematical documentation to welcome new users\nto the core structure of a prototypical lifex application and to provide them\nwith a possible approach to include the generated cardiac fibers into more\nsophisticated computational pipelines.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.03303v4"
    },
    {
        "title": "PyHHMM: A Python Library for Heterogeneous Hidden Markov Models",
        "authors": [
            "Fernando Moreno-Pino",
            "Emese Sükei",
            "Pablo M. Olmos",
            "Antonio Artés-Rodríguez"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  We introduce PyHHMM, an object-oriented open-source Python implementation of\nHeterogeneous-Hidden Markov Models (HHMMs). In addition to HMM's basic core\nfunctionalities, such as different initialization algorithms and classical\nobservations models, i.e., continuous and multinoulli, PyHHMM distinctively\nemphasizes features not supported in similar available frameworks: a\nheterogeneous observation model, missing data inference, different model order\nselection criterias, and semi-supervised training. These characteristics result\nin a feature-rich implementation for researchers working with sequential data.\nPyHHMM relies on the numpy, scipy, scikit-learn, and seaborn Python packages,\nand is distributed under the Apache-2.0 License. PyHHMM's source code is\npublicly available on Github (https://github.com/fmorenopino/HeterogeneousHMM)\nto facilitate adoptions and future contributions. A detailed documentation\n(https://pyhhmm.readthedocs.io/en/latest), which covers examples of use and\nmodels' theoretical explanation, is available. The package can be installed\nthrough the Python Package Index (PyPI), via 'pip install pyhhmm'.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.06968v1"
    },
    {
        "title": "Efficient solution of 3D elasticity problems with smoothed aggregation\n  algebraic multigrid and block arithmetics",
        "authors": [
            "Denis Demidov"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Efficient solution of 3D elasticity problems is an important part of many\nindustrial and scientific applications. Smoothed aggregation algebraic\nmultigrid using rigid body modes for the tentative prolongation operator\nconstruction is an efficient and robust choice for the solution of linear\nsystems arising from the discretization of elasticity equations. The system\nmatrices on every level of the multigrid hierarchy have block structure, so\nusing block representation and block arithmetics should significantly improve\nthe solver efficiency. However, the tentative prolongation operator\nconstruction may only be done using scalar representation. The paper proposes a\ncouple of practical approaches for enabling the use of block arithmetics with\nsmoothed aggregation algebraic multigrid based on the open-source AMGCL\nlibrary. It is shown on the example of two real-world model problems that the\nsuggested improvements may speed up the solution by 50% and reduce the memory\nrequirements for the preconditioner by 30%. The implementation is\nstraightforward and only requires a minimal amount of code.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09056v1"
    },
    {
        "title": "Benchmarking the Linear Algebra Awareness of TensorFlow and PyTorch",
        "authors": [
            "Aravind Sankaran",
            "Navid Akbari Alashti",
            "Christos Psarras",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Linear algebra operations, which are ubiquitous in machine learning, form\nmajor performance bottlenecks. The High-Performance Computing community invests\nsignificant effort in the development of architecture-specific optimized\nkernels, such as those provided by the BLAS and LAPACK libraries, to speed up\nlinear algebra operations. However, end users are progressively less likely to\ngo through the error prone and time-consuming process of directly using said\nkernels; instead, frameworks such as TensorFlow (TF) and PyTorch (PyT), which\nfacilitate the development of machine learning applications, are becoming more\nand more popular. Although such frameworks link to BLAS and LAPACK, it is not\nclear whether or not they make use of linear algebra knowledge to speed up\ncomputations. For this reason, in this paper we develop benchmarks to\ninvestigate the linear algebra optimization capabilities of TF and PyT. Our\nanalyses reveal that a number of linear algebra optimizations are still\nmissing; for instance, reducing the number of scalar operations by applying the\ndistributive law, and automatically identifying the optimal parenthesization of\na matrix chain. In this work, we focus on linear algebra computations in TF and\nPyT; we both expose opportunities for performance enhancement to the benefit of\nthe developers of the frameworks and provide end users with guidelines on how\nto achieve performance gains.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.09888v1"
    },
    {
        "title": "The Sparse Grids Matlab kit -- a Matlab implementation of sparse grids\n  for high-dimensional function approximation and uncertainty quantification",
        "authors": [
            "Chiara Piazzola",
            "Lorenzo Tamellini"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  The Sparse Grids Matlab Kit provides a Matlab implementation of sparse grids,\nand can be used for approximating high-dimensional functions and, in\nparticular, for surrogate-model-based uncertainty quantification. It is\nlightweight, high-level and easy to use, good for quick prototyping and\nteaching; however, it is equipped with some features that allow its use also in\nrealistic applications. The goal of this paper is to provide an overview of the\ndata structure and of the mathematical aspects forming the basis of the\nsoftware, as well as comparing the current release of our package to similar\navailable software.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.09314v3"
    },
    {
        "title": "Automated Generation of High-Performance Computational Fluid Dynamics\n  Codes",
        "authors": [
            "Sandra Macià",
            "Pedro J. Martıínez-Ferrer",
            "Eduard Ayguadé",
            "Vicenç Beltran"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Domain-Specific Languages (DSLs) improve programmers productivity by\ndecoupling problem descriptions from algorithmic implementations. However, DSLs\nfor High-Performance Computing (HPC) have two additional critical requirements:\nperformance and scalability. This paper presents the automated process of\ngenerating, from abstract mathematical specifications of Computational Fluid\nDynamics (CFD) problems, optimised parallel codes that perform and scale as\nmanually optimised ones. We consciously combine within Saiph, a DSL for solving\nCFD problems, low-level optimisations and parallelisation strategies, enabling\nhigh-performance single-core executions which effectively scale to multi-core\nand distributed environments. Our results demonstrate how high-level DSLs can\noffer competitive performance by transparently leveraging state-of-the-art HPC\ntechniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.12120v2"
    },
    {
        "title": "parGeMSLR: A Parallel Multilevel Schur Complement Low-Rank\n  Preconditioning and Solution Package for General Sparse Matrices",
        "authors": [
            "Tianshi Xu",
            "Vassilis Kalantzis",
            "Ruipeng Li",
            "Yuanzhe Xi",
            "Geoffrey Dillon",
            "Yousef Saad"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  This paper discusses parGeMSLR, a C++/MPI software library for the solution\nof sparse systems of linear algebraic equations via preconditioned Krylov\nsubspace methods in distributed-memory computing environments. The\npreconditioner implemented in parGeMSLR is based on algebraic domain\ndecomposition and partitions the symmetrized adjacency graph recursively into\nseveral non-overlapping partitions via a p-way vertex separator, where p is an\ninteger multiple of the total number of MPI processes. From a numerical\nperspective, parGeMSLR builds a Schur complement approximate inverse\npreconditioner as the sum between the matrix inverse of the interface coupling\nmatrix and a low-rank correction term. To reduce the cost associated with the\ncomputation of the approximate inverse matrices, parGeMSLR exploits a\nmultilevel partitioning of the algebraic domain. The parGeMSLR library is\nimplemented on top of the Message Passing Interface and can solve both real and\ncomplex linear systems. Furthermore, parGeMSLR can take advantage of hybrid\ncomputing environments with in-node access to one or more Graphics Processing\nUnits. Finally, the parallel efficiency (weak and strong scaling) of parGeMSLR\nis demonstrated on a few model problems arising from discretizations of 3D\nPartial Differential Equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.03224v1"
    },
    {
        "title": "Enhancing data locality of the conjugate gradient method for high-order\n  matrix-free finite-element implementations",
        "authors": [
            "Martin Kronbichler",
            "Dmytro Sashko",
            "Peter Munch"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  This work investigates a variant of the conjugate gradient (CG) method and\nembeds it into the context of high-order finite-element schemes with fast\nmatrix-free operator evaluation and cheap preconditioners like the matrix\ndiagonal. Relying on a data-dependency analysis and appropriate enumeration of\ndegrees of freedom, we interleave the vector updates and inner products in a CG\niteration with the matrix-vector product with only minor organizational\noverhead. As a result, around 90% of the vector entries of the three active\nvectors of the CG method are transferred from slow RAM memory exactly once per\niteration, with all additional access hitting fast cache memory. Node-level\nperformance analyses and scaling studies on up to 147k cores show that the CG\nmethod with the proposed performance optimizations is around two times faster\nthan a standard CG solver as well as optimized pipelined CG and s-step CG\nmethods for large sizes that exceed processor caches, and provides similar\nperformance near the strong scaling limit.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08909v1"
    },
    {
        "title": "Accelerating High-Order Mesh Optimization Using Finite Element Partial\n  Assembly on GPUs",
        "authors": [
            "Jean-Sylvain Camier",
            "Veselin Dobrev",
            "Patrick Knupp",
            "Tzanio Kolev",
            "Ketan Mittal",
            "Robert Rieben",
            "Vladimir Tomov"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  In this paper we present a new GPU-oriented mesh optimization method based on\nhigh-order finite elements. Our approach relies on node movement with fixed\ntopology, through the Target-Matrix Optimization Paradigm (TMOP) and uses a\nglobal nonlinear solve over the whole computational mesh, i.e., all mesh nodes\nare moved together. A key property of the method is that the mesh optimization\nprocess is recast in terms of finite element operations, which allows us to\nutilize recent advances in the field of GPU-accelerated high-order finite\nelement algorithms. For example, we reduce data motion by using tensor\nfactorization and matrix-free methods, which have superior performance\ncharacteristics compared to traditional full finite element matrix assembly and\noffer advantages for GPU-based HPC hardware. We describe the major mathematical\ncomponents of the method along with their efficient GPU-oriented\nimplementation. In addition, we propose an easily reproducible mesh\noptimization test that can serve as a performance benchmark for the mesh\noptimization community.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.12721v2"
    },
    {
        "title": "ARKODE: a flexible IVP solver infrastructure for one-step methods",
        "authors": [
            "Daniel R. Reynolds",
            "David J. Gardner",
            "Carol S. Woodward",
            "Rujeko Chinomona"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  We describe the ARKODE library of one-step time integration methods for\nordinary differential equation (ODE) initial-value problems (IVPs). In addition\nto providing standard explicit and diagonally implicit Runge--Kutta methods,\nARKODE also supports one-step methods designed to treat additive splittings of\nthe IVP, including implicit-explicit (ImEx) additive Runge--Kutta methods and\nmultirate infinitesimal (MRI) methods. We present the role of ARKODE within the\nSUNDIALS suite of time integration and nonlinear solver libraries, the core\nARKODE infrastructure for utilities common to large classes of one-step\nmethods, as well as its use of ``time stepper'' modules enabling easy\nincorporation of novel algorithms into the library. Numerical results show\nexample problems of increasing complexity, highlighting the algorithmic\nflexibility afforded through this infrastructure, and include a larger\nmultiphysics application leveraging multiple algorithmic features from ARKODE\nand SUNDIALS.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.14077v2"
    },
    {
        "title": "Large-Scale Direct Numerical Simulations of Turbulence Using GPUs and\n  Modern Fortran",
        "authors": [
            "Martin Karp",
            "Daniele Massaro",
            "Niclas Jansson",
            "Alistair Hart",
            "Jacob Wahlgren",
            "Philipp Schlatter",
            "Stefano Markidis"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  We present our approach to making direct numerical simulations of turbulence\nwith applications in sustainable shipping. We use modern Fortran and the\nspectral element method to leverage and scale on supercomputers powered by the\nNvidia A100 and the recent AMD Instinct MI250X GPUs, while still providing\nsupport for user software developed in Fortran. We demonstrate the efficiency\nof our approach by performing the world's first direct numerical simulation of\nthe flow around a Flettner rotor at Re=30'000 and its interaction with a\nturbulent boundary layer. We present one of the first performance comparisons\nbetween the AMD Instinct MI250X and Nvidia A100 GPUs for scalable computational\nfluid dynamics. Our results show that one MI250X offers performance on par with\ntwo A100 GPUs and has a similar power efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.07098v1"
    },
    {
        "title": "lifex: a flexible, high performance library for the numerical solution\n  of complex finite element problems",
        "authors": [
            "Pasquale Claudio Africa"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Numerical simulations are ubiquitous in mathematics and computational\nscience. Several industrial and clinical applications entail modeling complex\nmultiphysics systems that evolve over a variety of spatial and temporal scales.\n  This study introduces the design and capabilities of lifex, an open source\nC++ library for high performance finite element simulations of multiphysics,\nmultiscale, and multidomain problems. lifex meets the emerging need for\nversatile, efficient computational tools that are easily accessed by users and\ndevelopers. We showcase its flexibility and effectiveness on a number of\nillustrative examples and advanced applications of use and demonstrate its\nparallel performance up to thousands of cores.\n",
        "pdf_link": "http://arxiv.org/pdf/2207.14668v3"
    },
    {
        "title": "NFFT.jl: Generic and Fast Julia Implementation of the Nonequidistant\n  Fast Fourier Transform",
        "authors": [
            "Tobias Knopp",
            "Marija Boberg",
            "Mirco Grosser"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  The non-equidistant fast Fourier transform (NFFT) is an extension of the\nfamous fast Fourier transform (FFT), which can be applied to non-equidistantly\nsampled data in time/space or frequency domain. It is an approximative\nalgorithm that allows to control the approximation error in such a way that\nmachine precision is reached while keeping the algorithmic complexity in the\nsame order as a regular FFT. The NFFT plays a major role in many signal\nprocessing applications and has been intensively studied from a theoretical and\ncomputational perspective. The fastest CPU implementations of the NFFT are\nimplemented in the low-level programming languages C and C++ and require a\ncompromise between code generalizability, code readability, and code\nefficiency. The programming language Julia promises new opportunities in\noptimizing these three conflicting goals. In this work we show that Julia\nindeed allows to develop an NFFT implementation, which is completely generic,\ndimension-agnostic and requires about 2-3 times less code than other famous\nlibraries while still being one of the fastest NFFT implementations developed\nto date.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.00049v2"
    },
    {
        "title": "SOniCS: Develop intuition on biomechanical systems through interactive\n  error controlled simulations",
        "authors": [
            "Arnaud Mazier",
            "Sidaty El Hadramy",
            "Jean-Nicolas Brunet",
            "Jack S. Hale",
            "Stéphane Cotin",
            "Stéphane P. A. Bordas"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  This new approach allows the user to experiment with model choices easily and\nquickly without requiring in-depth expertise, as constitutive models can be\nmodified by one line of code only. This ease in building new models makes\nSOniCS ideal to develop surrogate, reduced order models and to train machine\nlearning algorithms for uncertainty quantification or to enable\npatient-specific simulations. SOniCS is thus not only a tool that facilitates\nthe development of surgical training simulations but also, and perhaps more\nimportantly, paves the way to increase the intuition of users or otherwise\nnon-intuitive behaviors of (bio)mechanical systems. The plugin uses new\ndevelopments of the FEniCSx project enabling automatic generation with FFCx of\nfinite element tensors such as the local residual vector and Jacobian matrix.\nWe validate our approach with numerical simulations such as manufactured\nsolutions, cantilever beams, and benchmarks provided by FEBio. We reach machine\nprecision accuracy and demonstrate the use of the plugin for a real-time haptic\nsimulation involving a surgical tool controlled by the user in contact with a\nhyperelastic liver. We include complete examples showing the use of our plugin\nfor simulations involving Saint Venant-Kirchhoff, Neo-Hookean, Mooney-Rivlin,\nand Holzapfel Ogden anisotropic models as supplementary material.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.11676v1"
    },
    {
        "title": "Performance optimization and analysis of the unstructured Discontinuous\n  Galerkin solver on multi-core and many-core architectures",
        "authors": [
            "Zhe Dai",
            "Liang D",
            "Yueqin Wang",
            "Fang Wang",
            "Li Ming",
            "Jian Zhang"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  The discontinuous Galerkin (DG) algorithm is a representative high order\nmethod in Computational Fluid Dynamics (CFD) area which possesses considerable\nmathematical advantages such as high resolution, low dissipation, and\ndispersion. However, DG is rather computationally intensive to demonstrate\npractical engineering problems. This paper discusses the implementation of our\nin-house practical DG application in three different programming models, as\nwell as some optimization techniques, including grid renumbering and mixed\nprecision to maximize the performance improvements in a single node system. The\nexperiment on CPU and GPU shows that our CUDA, OpenACC, and OpenMP-based code\nobtains a maximum speedup of 42.9x, 35.3x, and 8.1x compared with serial\nexecution by the original application, respectively. Besides, we systematically\ncompare the programming models in two aspects: performance and productivity.\nOur empirical conclusions facilitate the programmers to select the right\nplatform with a suitable programming model according to their target\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.01877v1"
    },
    {
        "title": "End-to-end GPU acceleration of low-order-refined preconditioning for\n  high-order finite element discretizations",
        "authors": [
            "Will Pazner",
            "Tzanio Kolev",
            "Jean-Sylvain Camier"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  In this paper, we present algorithms and implementations for the end-to-end\nGPU acceleration of matrix-free low-order-refined preconditioning of high-order\nfinite element problems. The methods described here allow for the construction\nof effective preconditioners for high-order problems with optimal memory usage\nand computational complexity. The preconditioners are based on the construction\nof a spectrally equivalent low-order discretization on a refined mesh, which is\nthen amenable to, for example, algebraic multigrid preconditioning. The\nconstants of equivalence are independent of mesh size and polynomial degree.\nFor vector finite element problems in $H({\\rm curl})$ and $H({\\rm div})$ (e.g.\nfor electromagnetic or radiation diffusion problems) a specially constructed\ninterpolation-histopolation basis is used to ensure fast convergence. Detailed\nperformance studies are carried out to analyze the efficiency of the GPU\nalgorithms. The kernel throughput of each of the main algorithmic components is\nmeasured, and the strong and weak parallel scalability of the methods is\ndemonstrated. The different relative weighting and significance of the\nalgorithmic components on GPUs and CPUs is discussed. Results on problems\ninvolving adaptively refined nonconforming meshes are shown, and the use of the\npreconditioners on a large-scale magnetic diffusion problem using all spaces of\nthe finite element de Rham complex is illustrated.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.12253v1"
    },
    {
        "title": "A framework for structural shape optimization based on automatic\n  differentiation, the adjoint method and accelerated linear algebra",
        "authors": [
            "Gaoyuan Wu"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Shape optimization is of great significance in structural engineering, as an\nefficient geometry leads to better performance of structures. However, the\napplication of gradient-based shape optimization for structural and\narchitectural design is limited, which is partly due to the difficulty and the\ncomplexity in gradient evaluation. In this work, an efficient framework based\non automatic differentiation (AD), the adjoint method and accelerated linear\nalgebra (XLA) is proposed to promote the implementation of gradient-based shape\noptimization. The framework is realized by the implementation of the\nhigh-performance computing (HPC) library JAX. We leverage AD for gradient\nevaluation in the sensitivity analysis stage. Compared to numerical\ndifferentiation, AD is more accurate; compared to analytical and symbolic\ndifferentiation, AD is more efficient and easier to apply. In addition, the\nadjoint method is used to reduce the complexity of computation of the\nsensitivity. The XLA feature is exploited by an efficient programming\narchitecture that we proposed, which can boost gradient evaluation. The\nproposed framework also supports hardware acceleration such as GPUs. The\nframework is applied to the form finding of arches and different free-form\ngridshells: gridshell inspired by Mannheim Multihalle, four-point supported\ngridshell, and canopy-like structures. Two geometric descriptive methods are\nused: non-parametric and parametric description via B\\'ezier surface.\nNon-constrained and constrained shape optimization problems are considered,\nwhere the former is solved by gradient descent and the latter is solved by\nsequential quadratic programming (SQP). Through these examples, the proposed\nframework is shown to be able to provide structural engineers with a more\nefficient tool for shape optimization, enabling better design for the built\nenvironment.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.15409v1"
    },
    {
        "title": "Trimpack: Unstructured Triangular Mesh Generation Library",
        "authors": [
            "Juan M. Tizón",
            "Nicolás Becerra",
            "Daniel Bercebal",
            "Claus P. Grabowsky"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Trimpack is a library of routines written in Fortran that allow to create\nunstructured triangular meshes in any domain and with an user-defined size\ndistribution. The user must write a program that uses the elements of the\nlibrary as if it were a mathematical tool. First, the domain must be defined,\nusing point-defined boundaries, which the user provides. The library internally\nuses splines to mesh the boundaries with the node distribution function\nprovided by the user. Several meshing methods are available, from simple\nDalaunay mesh creation from a point cloud, an incremental Steiner-type\nalgorithm that also generates Dalaunay meshes to an efficient advancing-front\ntype algorithm. This report carries out a bibliographic review of the state of\nthe art in mesh generation corresponding to the period in which Trimpack was\nwritten for the first time, which is a very fruitful period in the development\nof this type of algorithms. Next, MeshGen is described in detail, which is a\nprogram written in C ++ that exploits the possibilities of the Trimpack library\nfor the generation of unstructured triangular meshes and that has a powerful\ngraphical interface. Finally, it also explains in detail the content of the\nTrimpack library that is available under GNU Public license for anyone who\nwants to use or improve it.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.02795v1"
    },
    {
        "title": "An Incremental Singular Value Decomposition Approach for Large-Scale\n  Spatially Parallel & Distributed but Temporally Serial Data -- Applied to\n  Technical Flows",
        "authors": [
            "Niklas Kühl",
            "Hendrik Fischer",
            "Michael Hinze",
            "Thomas Rung"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The paper presents a strategy to construct an incremental Singular Value\nDecomposition (SVD) for time-evolving, spatially 3D discrete data sets. A low\nmemory access procedure for reducing and deploying the snapshot data is\npresented. Considered examples refer to Computational Fluid Dynamic (CFD)\nresults extracted from unsteady flow simulations, which are computed spatially\nparallel using domain decomposition strategies. The framework addresses state\nof the art PDE-solvers dedicated to practical applications. Although the\napproach is applied to technical flows, it is applicable in similar\napplications under the umbrella of Computational Science and Engineering (CSE).\nTo this end, we introduce a bunch matrix that allows the aggregation of\nmultiple time steps and SVD updates, and significantly increases the\ncomputational efficiency. The incremental SVD strategy is initially verified\nand validated by simulating the 2D laminar single-phase flow around a circular\ncylinder. Subsequent studies analyze the proposed strategy for a 2D submerged\nhydrofoil located in turbulent two-phase flows. Attention is directed to the\naccuracy of the SVD-based reconstruction based on local and global flow\nquantities, their physical realizability, the independence of the domain\npartitioning, and related implementation aspects. Moreover, the influence of\nlower and (adaptive) upper construction rank thresholds on both the effort and\nthe accuracy are assessed. The incremental SVD process is applied to analyze\nand compress the predicted flow field around a Kriso container ship in harmonic\nhead waves at Fn = 0.26 and ReL = 1.4E+07. With a numerical overhead of O(10%),\nthe snapshot matrix of size O(R10E+08 x 10E+04) computed on approximately 3000\nprocessors can be incrementally compressed by O(95%). The storage reduction is\naccompanied by errors in integral force and local wave elevation quantities of\nO(1E-02%).\n",
        "pdf_link": "http://arxiv.org/pdf/2302.09149v1"
    },
    {
        "title": "Robust Parameter Estimation for Rational Ordinary Differential Equations",
        "authors": [
            "Oren Bassik",
            "Yosef Berman",
            "Soo Go",
            "Hoon Hong",
            "Ilia Ilmer",
            "Alexey Ovchinnikov",
            "Chris Rackauckas",
            "Pedro Soto",
            "Chee Yap"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present a new approach for estimating parameters in rational ODE models\nfrom given (measured) time series data.\n  In typical existing approaches, an initial guess for the parameter values is\nmade from a given search interval. Then, in a loop, the corresponding outputs\nare computed by solving the ODE numerically, followed by computing the error\nfrom the given time series data. If the error is small, the loop terminates and\nthe parameter values are returned. Otherwise, heuristics/theories are used to\npossibly improve the guess and continue the loop.\n  These approaches tend to be non-robust in the sense that their accuracy\ndepend on the search interval and the true parameter values; furthermore, they\ncannot handle the case where the parameters are locally identifiable.\n  In this paper, we propose a new approach, which does not suffer from the\nabove non-robustness. In particular, it does not require making good initial\nguesses for the parameter values or specifying search intervals. Instead, it\nuses differential algebra, interpolation of the data using rational functions,\nand multivariate polynomial system solving. We also compare the performance of\nthe resulting software with several other estimation software packages.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.02159v3"
    },
    {
        "title": "Acceleration of a production Solar MHD code with Fortran standard\n  parallelism: From OpenACC to `do concurrent'",
        "authors": [
            "Ronald M. Caplan",
            "Miko M. Stulajter",
            "Jon A. Linker"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  There is growing interest in using standard language constructs for\naccelerated computing, avoiding the need for (often vendor-specific) external\nAPIs. These constructs hold the potential to be more portable and much more\n`future-proof'. For Fortran codes, the current focus is on the {\\tt do\nconcurrent} (DC) loop. While there have been some successful examples of\nGPU-acceleration using DC for benchmark and/or small codes, its widespread\nadoption will require demonstrations of its use in full-size applications.\nHere, we look at the current capabilities and performance of using DC in a\nproduction application called Magnetohydrodynamic Algorithm outside a Sphere\n(MAS). MAS is a state-of-the-art model for studying coronal and heliospheric\ndynamics, is over 70,000 lines long, and has previously been ported to GPUs\nusing MPI+OpenACC. We attempt to eliminate as many of its OpenACC directives as\npossible in favor of DC. We show that using the NVIDIA {\\tt nvfortran}\ncompiler's Fortran 202X preview implementation, unified managed memory, and\nmodified MPI launch methods, we can achieve GPU acceleration across multiple\nGPUs without using a single OpenACC directive. However, doing so results in a\nslowdown between 1.25x and 3x. We discuss what future improvements are needed\nto avoid this loss, and show how we can still retain close\n",
        "pdf_link": "http://arxiv.org/pdf/2303.03398v2"
    },
    {
        "title": "waywiser: Ergonomic Methods for Assessing Spatial Models",
        "authors": [
            "Michael J Mahoney"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Assessing predictive models can be challenging. Modelers must navigate a wide\narray of evaluation methodologies implemented with incompatible interfaces\nacross multiple packages which may give different or even contradictory\nresults, while ensuring that their chosen approach properly estimates the\nperformance of their model when generalizing to new observations. Assessing\nmodels fit to spatial data can be particularly difficult, given that model\nerrors may exhibit spatial autocorrelation, model predictions are often\naggregated to multiple spatial scales by end users, and models are often tasked\nwith generalizing into spatial regions outside the boundaries of their initial\ntraining data.\n  The waywiser package for the R language attempts to make assessing spatial\nmodels easier by providing an ergonomic toolkit for model evaluation tasks,\nwith functions for multiple assessment methodologies sharing a unified\ninterface. Functions from waywiser share standardized argument names and\ndefault values, making the user-facing interface simple and easy to learn.\nThese functions are additionally designed to be easy to integrate into a wide\nvariety of modeling workflows, accepting standard classes as inputs and\nreturning size- and type-stable outputs, ensuring that their results are of\nconsistent and predictable data types and dimensions. Additional features make\nit particularly easy to use waywiser along packages and workflows in the\ntidymodels ecosystem.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.11312v1"
    },
    {
        "title": "Monotonicity of Multi-Term Floating-Point Adders",
        "authors": [
            "Mantas Mikaitis"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  In the literature on algorithms for performing the multi-term addition\n$s_n=\\sum_{i=1}^n x_i$ using floating-point arithmetic it is often shown that a\nhardware unit that has single normalization and rounding improves precision,\narea, latency, and power consumption, compared with the use of standard add or\nfused multiply-add units. However, non-monotonicity can appear when computing\nsums with a subclass of multi-term addition units, which currently is not\nexplored in the literature. We demonstrate that common techniques for\nperforming multi-term addition with $n\\geq 4$, without normalization of\nintermediate quantities, can result in non-monotonicity -- increasing one of\nthe addends $x_i$ decreases the sum $s_n$. Summation is required in dot product\nand matrix multiplication operations, operations that have increasingly started\nappearing in the hardware of supercomputers, thus knowing where monotonicity is\npreserved can be of interest to the users of these machines. Our results\nsuggest that non-monotonicity of summation, in some of the commercial hardware\ndevices that implement a specific class of multi-term adders, is a feature that\nmay have appeared unintentionally as a consequence of design choices that\nreduce circuit area and other metrics. To demonstrate our findings, we use\nformal proofs as well as a numerical simulation of non-monotonic multi-term\nadders in MATLAB.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01407v2"
    },
    {
        "title": "TransPimLib: A Library for Efficient Transcendental Functions on\n  Processing-in-Memory Systems",
        "authors": [
            "Maurus Item",
            "Juan Gómez-Luna",
            "Yuxin Guo",
            "Geraldo F. Oliveira",
            "Mohammad Sadrosadati",
            "Onur Mutlu"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Processing-in-memory (PIM) promises to alleviate the data movement bottleneck\nin modern computing systems. However, current real-world PIM systems have the\ninherent disadvantage that their hardware is more constrained than in\nconventional processors (CPU, GPU), due to the difficulty and cost of building\nprocessing elements near or inside the memory. As a result, general-purpose PIM\narchitectures support fairly limited instruction sets and struggle to execute\ncomplex operations such as transcendental functions and other hard-to-calculate\noperations (e.g., square root). These operations are particularly important for\nsome modern workloads, e.g., activation functions in machine learning\napplications.\n  In order to provide support for transcendental (and other hard-to-calculate)\nfunctions in general-purpose PIM systems, we present \\emph{TransPimLib}, a\nlibrary that provides CORDIC-based and LUT-based methods for trigonometric\nfunctions, hyperbolic functions, exponentiation, logarithm, square root, etc.\nWe develop an implementation of TransPimLib for the UPMEM PIM architecture and\nperform a thorough evaluation of TransPimLib's methods in terms of performance\nand accuracy, using microbenchmarks and three full workloads (Blackscholes,\nSigmoid, Softmax). We open-source all our code and datasets\nat~\\url{https://github.com/CMU-SAFARI/transpimlib}.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.01951v5"
    },
    {
        "title": "Consistent Point Data Assimilation in Firedrake and Icepack",
        "authors": [
            "Reuben W. Nixon-Hill",
            "Daniel Shapero",
            "Colin J. Cotter",
            "David A. Ham"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  When estimating quantities and fields that are difficult to measure directly,\nsuch as the fluidity of ice, from point data sources, such as satellite\naltimetry, it is important to solve a numerical inverse problem that is\nformulated with Bayesian consistency. Otherwise, the resultant probability\ndensity function for the difficult to measure quantity or field will not be\nappropriately clustered around the truth. In particular, the inverse problem\nshould be formulated by evaluating the numerical solution at the true point\nlocations for direct comparison with the point data source. If the data are\nfirst fitted to a gridded or meshed field on the computational grid or mesh,\nand the inverse problem formulated by comparing the numerical solution to the\nfitted field, the benefits of additional point data values below the grid\ndensity will be lost. We demonstrate, with examples in the fields of\ngroundwater hydrology and glaciology, that a consistent formulation can\nincrease the accuracy of results and aid discourse between modellers and\nobservationalists.\n  To do this, we bring point data into the finite element method ecosystem as\ndiscontinuous fields on meshes of disconnected vertices. Point evaluation can\nthen be formulated as a finite element interpolation operation\n(dual-evaluation). This new abstraction is well-suited to automation, including\nautomatic differentiation. We demonstrate this through implementation in\nFiredrake, which generates highly optimised code for solving Partial\nDifferential Equations (PDEs) with the finite element method. Our solution\nintegrates with dolfin-adjoint/pyadjoint, allowing PDE-constrained optimisation\nproblems, such as data assimilation, to be solved through forward and adjoint\nmode automatic differentiation.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.06058v5"
    },
    {
        "title": "Groebner.jl: A package for Gröbner bases computations in Julia",
        "authors": [
            "Alexander Demin",
            "Shashi Gowda"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present Groebner.jl, a Julia package for computing Groebner bases with the\nF4 algorithm. Groebner.jl is an efficient, portable, and open-source software.\nGroebner.jl works over integers modulo a prime and over the rationals, supports\nbasic multi-threading, and specializes in computation in the degree reverse\nlexicographical monomial ordering. The implementation incorporates various\nsymbolic computation techniques and leverages the Julia type system and\ntooling, which allows Groebner.jl to compete with the existing state of the\nart, in many instances outperform it, and exceed them in extensibility.\nGroebner.jl is freely available at https://github.com/sumiya11/Groebner.jl.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.06935v3"
    },
    {
        "title": "OpenLB User Guide: Associated with Release 1.6 of the Code",
        "authors": [
            "Adrian Kummerländer",
            "Samuel J. Avis",
            "Halim Kusumaatmaja",
            "Fedor Bukreev",
            "Michael Crocoll",
            "Davide Dapelo",
            "Simon Großmann",
            "Nicolas Hafen",
            "Shota Ito",
            "Julius Jeßberger",
            "Eliane Kummer",
            "Jan E. Marquardt",
            "Johanna Mödl",
            "Tim Pertzel",
            "František Prinz",
            "Florian Raichle",
            "Martin Sadric",
            "Maximilian Schecher",
            "Dennis Teutscher",
            "Stephan Simonis",
            "Mathias J. Krause"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  OpenLB is an object-oriented implementation of LBM. It is the first\nimplementation of a generic platform for LBM programming, which is shared with\nthe open source community (GPLv2). Since the first release in 2007, the code\nhas been continuously improved and extended which is documented by thirteen\nreleases as well as the corresponding release notes which are available on the\nOpenLB website (https://www.openlb.net). The OpenLB code is written in C++ and\nis used by application programmers as well as developers, with the ability to\nimplement custom models OpenLB supports complex data structures that allow\nsimulations in complex geometries and parallel execution using MPI, OpenMP and\nCUDA on high-performance computers. The source code uses the concepts of\ninterfaces and templates, so that efficient, direct and intuitive\nimplementations of the LBM become possible. The efficiency and scalability has\nbeen checked and proved by code reviews. This user manual and a source code\ndocumentation by DoxyGen are available on the OpenLB project website.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.11752v2"
    },
    {
        "title": "Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for\n  Tetrad Causal Search",
        "authors": [
            "Joseph D. Ramsey",
            "Bryan Andrews"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We give novel Python and R interfaces for the (Java) Tetrad project for\ncausal modeling, search, and estimation. The Tetrad project is a mainstay in\nthe literature, having been under consistent development for over 30 years.\nSome of its algorithms are now classics, like PC and FCI; others are recent\ndevelopments. It is increasingly the case, however, that researchers need to\naccess the underlying Java code from Python or R. Existing methods for doing\nthis are inadequate. We provide new, up-to-date methods using the JPype\nPython-Java interface and the Reticulate Python-R interface, directly solving\nthese issues. With the addition of some simple tools and the provision of\nworking examples for both Python and R, using JPype and Reticulate to interface\nPython and R with Tetrad is straightforward and intuitive.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.07346v1"
    },
    {
        "title": "An algorithm to approximate the real trilogarithm for a real argument",
        "authors": [
            "Alexander Voigt"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present an algorithm to approximate the real trilogarithm for a real\nargument with IEEE 754-1985 double precision accuracy. The approximation is\nstructured such that it can make use of instruction-level parallelism when\nexecuted on appropriate CPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.11619v2"
    },
    {
        "title": "Bringing PDEs to JAX with forward and reverse modes automatic\n  differentiation",
        "authors": [
            "Ivan Yashchuk"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Partial differential equations (PDEs) are used to describe a variety of\nphysical phenomena. Often these equations do not have analytical solutions and\nnumerical approximations are used instead. One of the common methods to solve\nPDEs is the finite element method. Computing derivative information of the\nsolution with respect to the input parameters is important in many tasks in\nscientific computing. We extend JAX automatic differentiation library with an\ninterface to Firedrake finite element library. High-level symbolic\nrepresentation of PDEs allows bypassing differentiating through low-level\npossibly many iterations of the underlying nonlinear solvers. Differentiating\nthrough Firedrake solvers is done using tangent-linear and adjoint equations.\nThis enables the efficient composition of finite element solvers with arbitrary\ndifferentiable programs. The code is available at\ngithub.com/IvanYashchuk/jax-firedrake.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.07137v1"
    },
    {
        "title": "A Number Representation Systems Library Supporting New Representations\n  Based on Morris Tapered Floating-point with Hidden Exponent Bit",
        "authors": [
            "Stefan-Dan Ciocirlan",
            "Dumitrel Loghin"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The introduction of posit reopened the debate about the utility of IEEE754 in\nspecific domains. In this context, we propose a high-level language (Scala)\nlibrary that aims to reduce the effort of designing and testing new number\nrepresentation systems (NRSs). The library's efficiency is tested with three\nnew NRSs derived from Morris Tapered Floating-Point by adding a hidden exponent\nbit. We call these NRSs MorrisHEB, MorrisBiasHEB, and MorrisUnaryHEB,\nrespectively. We show that they offer a better dynamic range, better decimal\naccuracy for unary operations, more exact results for addition (37.61% in the\ncase of MorrisUnaryHEB), and better average decimal accuracy for inexact\nresults on binary operations than posit and IEEE754. Going through existing\nbenchmarks in the literature, and favorable/unfavorable examples for\nIEEE754/posit, we show that these new NRSs produce similar (less than one\ndecimal accuracy difference) or even better results than IEEE754 and posit.\nGiven the entire spectrum of results, there are arguments for MorrisBiasHEB to\nbe used as a replacement for IEEE754 in general computations. MorrisUnaryHEB\nhas a more populated ``golden zone'' (+13.6%) and a better dynamic range (149X)\nthan posit, making it a candidate for machine learning computations.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.09797v1"
    },
    {
        "title": "Tackling the Matrix Multiplication Micro-kernel Generation with Exo",
        "authors": [
            "Adrián Castelló",
            "Julian Bellavita",
            "Grace Dinh",
            "Yuka Ikarashi",
            "Héctor Martínez"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The optimization of the matrix multiplication (or GEMM) has been a need\nduring the last decades. This operation is considered the flagship of current\nlinear algebra libraries such as BLIS, OpenBLAS, or Intel OneAPI because of its\nwidespread use in a large variety of scientific applications. The GEMM is\nusually implemented following the GotoBLAS philosophy, which tiles the GEMM\noperands and uses a series of nested loops for performance improvement. These\napproaches extract the maximum computational power of the architectures through\nsmall pieces of hardware-oriented, high-performance code called micro-kernel.\nHowever, this approach forces developers to generate, with a non-negligible\neffort, a dedicated micro-kernel for each new hardware.\n  In this work, we present a step-by-step procedure for generating\nmicro-kernels with the Exo compiler that performs close to (or even better\nthan) manually developed microkernels written with intrinsic functions or\nassembly language. Our solution also improves the portability of the generated\ncode, since a hardware target is fully specified by a concise library-based\ndescription of its instructions.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.17408v2"
    },
    {
        "title": "Fast multiplication by two's complement addition of numbers represented\n  as a set of polynomial radix 2 indexes, stored as an integer list for\n  massively parallel computation",
        "authors": [
            "Mark Stocks"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We demonstrate a multiplication method based on numbers represented as set of\npolynomial radix 2 indices stored as an integer list. The 'polynomial integer\nindex multiplication' method is a set of algorithms implemented in python code.\nWe demonstrate the method to be faster than both the Number Theoretic Transform\n(NTT) and Karatsuba for multiplication within a certain bit range. Also\nimplemented in python code for comparison purposes with the polynomial radix 2\ninteger method. We demonstrate that it is possible to express any integer or\nreal number as a list of integer indices, representing a finite series in base\ntwo. The finite series of integer index representation of a number can then be\nstored and distributed across multiple CPUs / GPUs. We show that operations of\naddition and multiplication can be applied as two's complement additions\noperating on the index integer representations and can be fully distributed\nacross a given CPU / GPU architecture. We demonstrate fully distributed\narithmetic operations such that the 'polynomial integer index multiplication'\nmethod overcomes the current limitation of parallel multiplication methods. Ie,\nthe need to share common core memory and common disk for the calculation of\nresults and intermediate results.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.09922v3"
    },
    {
        "title": "Ricci-Notation Tensor Framework for Model-based Approaches to Imaging",
        "authors": [
            "Dileepan Joseph"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  Model-based approaches to imaging, like specialized image enhancements in\nastronomy, facilitate explanations of relationships between observed inputs and\ncomputed outputs. These models may be expressed with extended matrix-vector\n(EMV) algebra, especially when they involve only scalars, vectors, and\nmatrices, and with n-mode or index notations, when they involve\nmultidimensional arrays, also called numeric tensors or, simply, tensors. While\nthis paper features an example, inspired by exoplanet imaging, that employs\ntensors to reveal (inverse) 2D fast Fourier transforms in an image enhancement\nmodel, the work is actually about the tensor algebra and software, or tensor\nframeworks, available for model-based imaging. The paper proposes a\nRicci-notation tensor (RT) framework, comprising a dual-variant index notation,\nwith Einstein summation convention, and codesigned object-oriented software,\ncalled the RTToolbox for MATLAB. Extensions to Ricci notation offer novel\nrepresentations for entrywise, pagewise, and broadcasting operations popular in\nEMV frameworks for imaging. Complementing the EMV algebra computable with\nMATLAB, the RTToolbox demonstrates programmatic and computational efficiency\nvia careful design of numeric tensor and dual-variant index classes. Compared\nto its closest competitor, also a numeric tensor framework that uses index\nnotation, the RT framework enables superior ways to model imaging problems and,\nthereby, to develop solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/2312.04018v3"
    },
    {
        "title": "Sphractal: Estimating the Fractal Dimension of Surfaces Computed from\n  Precise Atomic Coordinates via Box-Counting Algorithm",
        "authors": [
            "Jonathan Yik Chang Ting",
            "Andrew Thomas Agars Wood",
            "Amanda Susan Barnard"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The fractal dimension of a surface allows its degree of roughness to be\ncharacterized quantitatively. However, limited effort is attempted to calculate\nthe fractal dimension of surfaces computed from precisely known atomic\ncoordinates from computational biomolecular and nanomaterial studies. This work\nproposes methods to estimate the fractal dimension of the surface of any 3D\nobject composed of spheres, by representing the surface as either a voxelized\npoint cloud or a mathematically exact surface, and computing its box-counting\ndimension. Sphractal is published as a Python package that provides these\nfunctionalities, and its utility is demonstrated on a set of simulated\npalladium nanoparticle data.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.11737v2"
    },
    {
        "title": "Mixed-Order Meshes through rp-adaptivity for Surface Fitting to Implicit\n  Geometries",
        "authors": [
            "Ketan Mittal",
            "Veselin A. Dobrev",
            "Patrick Knupp",
            "Tzanio Kolev",
            "Franck Ledoux",
            "Claire Roche",
            "Vladimir Z. Tomov"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Computational analysis with the finite element method requires geometrically\naccurate meshes. It is well known that high-order meshes can accurately capture\ncurved surfaces with fewer degrees of freedom in comparison to low-order\nmeshes. Existing techniques for high-order mesh generation typically output\nmeshes with same polynomial order for all elements. However, high order\nelements away from curvilinear boundaries or interfaces increase the\ncomputational cost of the simulation without increasing geometric accuracy. In\nprior work, we have presented one such approach for generating body-fitted\nuniform-order meshes that takes a given mesh and morphs it to align with the\nsurface of interest prescribed as the zero isocontour of a level-set function.\nWe extend this method to generate mixed-order meshes such that curved surfaces\nof the domain are discretized with high-order elements, while low-order\nelements are used elsewhere. Numerical experiments demonstrate the robustness\nof the approach and show that it can be used to generate mixed-order meshes\nthat are much more efficient than high uniform-order meshes. The proposed\napproach is purely algebraic, and extends to different types of elements\n(quadrilaterals/triangles/tetrahedron/hexahedra) in two- and three-dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16369v1"
    },
    {
        "title": "Rigorous Error Analysis for Logarithmic Number Systems",
        "authors": [
            "Thanh Son Nguyen",
            "Alexey Solovyev",
            "Ganesh Gopalakrishnan"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Logarithmic Number Systems (LNS) hold considerable promise in helping reduce\nthe number of bits needed to represent a high dynamic range of real-numbers\nwith finite precision, and also efficiently support multiplication and\ndivision. However, under LNS, addition and subtraction turn into non-linear\nfunctions that must be approximated - typically using precomputed table-based\nfunctions. Additionally, multiple layers of error correction are typically\nneeded to improve result accuracy. Unfortunately, previous efforts have not\ncharacterized the resulting error bound. We provide the first rigorous analysis\nof LNS, covering detailed techniques such as co-transformation that are crucial\nto implementing subtraction with reasonable accuracy. We provide theorems\ncapturing the error due to table interpolations, the finite precision of\npre-computed values in the tables, and the error introduced by fix-point\nmultiplications involved in LNS implementations. We empirically validate our\nanalysis using a Python implementation, showing that our analytical bounds are\ntight, and that our testing campaign generates inputs diverse-enough to almost\nmatch (but not exceed) the analytical bounds. We close with discussions on how\nto adapt our analysis to LNS systems with different bases and also discuss many\npragmatic ramifications of our work in the broader arena of scientific\ncomputing and machine learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.17184v1"
    },
    {
        "title": "MATLAB Simulator of Level-Index Arithmetic",
        "authors": [
            "Mantas Mikaitis"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Level-index arithmetic appeared in the 1980s. One of its principal purposes\nis to abolish the issues caused by underflows and overflows in floating point.\nHowever, level-index arithmetic does not expand the set of numbers but spaces\nout the numbers of large magnitude even more than floating-point\nrepresentations to move the infinities further away from zero: gaps between\nnumbers on both ends of the range become very large. We revisit level index by\npresenting a custom precision simulator in MATLAB. This toolbox is useful for\nexploring performance of level-index arithmetic in research projects, such as\nusing 8-bit and 16-bit representations in machine learning algorithms where\nnarrow bit-width is desired but overflow/underflow of floating-point\nrepresentations causes difficulties.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.02301v2"
    },
    {
        "title": "FEniCSx Preconditioning Tools (FEniCSx-pctools)",
        "authors": [
            "Martin Řehoř",
            "Jack S. Hale"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  FEniCSx Preconditioning Tools (FEniCSx-pctools) is a software package for\neasing the specification of PETSc-based block preconditioning strategies in the\nDOLFINx finite element solver of the FEniCS Project. It attaches all of the\nnecessary metadata to the block-structured linear systems in order that\nblock-structured preconditioners can be applied straightforwardly via PETSc's\noptions-based configuration system. Fast prototyping is facilitated thanks to\nthe implementation in Python, and all intensive operations are executed in\nC/C++. FEniCSx-pctools is available under the LGPLv3 or later license.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.02523v1"
    },
    {
        "title": "BlackJAX: Composable Bayesian inference in JAX",
        "authors": [
            "Alberto Cabezas",
            "Adrien Corenflos",
            "Junpeng Lao",
            "Rémi Louf",
            "Antoine Carnec",
            "Kaustubh Chaudhari",
            "Reuben Cohn-Gordon",
            "Jeremie Coullon",
            "Wei Deng",
            "Sam Duffield",
            "Gerardo Durán-Martín",
            "Marcin Elantkowski",
            "Dan Foreman-Mackey",
            "Michele Gregori",
            "Carlos Iguaran",
            "Ravin Kumar",
            "Martin Lysy",
            "Kevin Murphy",
            "Juan Camilo Orduz",
            "Karm Patel",
            "Xi Wang",
            "Rob Zinkov"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  BlackJAX is a library implementing sampling and variational inference\nalgorithms commonly used in Bayesian computation. It is designed for ease of\nuse, speed, and modularity by taking a functional approach to the algorithms'\nimplementation. BlackJAX is written in Python, using JAX to compile and run\nNumpPy-like samplers and variational methods on CPUs, GPUs, and TPUs. The\nlibrary integrates well with probabilistic programming languages by working\ndirectly with the (un-normalized) target log density function. BlackJAX is\nintended as a collection of low-level, composable implementations of basic\nstatistical 'atoms' that can be combined to perform well-defined Bayesian\ninference, but also provides high-level routines for ease of use. It is\ndesigned for users who need cutting-edge methods, researchers who want to\ncreate complex sampling methods, and people who want to learn how these work.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.10797v2"
    },
    {
        "title": "High-performance finite elements with MFEM",
        "authors": [
            "Julian Andrej",
            "Nabil Atallah",
            "Jan-Phillip Bäcker",
            "John Camier",
            "Dylan Copeland",
            "Veselin Dobrev",
            "Yohann Dudouit",
            "Tobias Duswald",
            "Brendan Keith",
            "Dohyun Kim",
            "Tzanio Kolev",
            "Boyan Lazarov",
            "Ketan Mittal",
            "Will Pazner",
            "Socratis Petrides",
            "Syun'ichi Shiraiwa",
            "Mark Stowell",
            "Vladimir Tomov"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The MFEM (Modular Finite Element Methods) library is a high-performance C++\nlibrary for finite element discretizations. MFEM supports numerous types of\nfinite element methods and is the discretization engine powering many\ncomputational physics and engineering applications across a number of domains.\nThis paper describes some of the recent research and development in MFEM,\nfocusing on performance portability across leadership-class supercomputing\nfacilities, including exascale supercomputers, as well as new capabilities and\nfunctionality, enabling a wider range of applications. Much of this work was\nundertaken as part of the Department of Energy's Exascale Computing Project\n(ECP) in collaboration with the Center for Efficient Exascale Discretizations\n(CEED).\n",
        "pdf_link": "http://arxiv.org/pdf/2402.15940v1"
    },
    {
        "title": "GenML: A Python Library to Generate the Mittag-Leffler Correlated Noise",
        "authors": [
            "Xiang Qu",
            "Hui Zhao",
            "Wenjie Cai",
            "Gongyi Wang",
            "Zihan Huang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Mittag-Leffler correlated noise (M-L noise) plays a crucial role in the\ndynamics of complex systems, yet the scientific community has lacked tools for\nits direct generation. Addressing this gap, our work introduces GenML, a Python\nlibrary specifically designed for generating M-L noise. We detail the\narchitecture and functionalities of GenML and its underlying algorithmic\napproach, which enables the precise simulation of M-L noise. The effectiveness\nof GenML is validated through quantitative analyses of autocorrelation\nfunctions and diffusion behaviors, showcasing its capability to accurately\nreplicate theoretical noise properties. Our contribution with GenML enables the\neffective application of M-L noise data in numerical simulation and data-driven\nmethods for describing complex systems, moving beyond mere theoretical\nmodeling.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.04273v2"
    },
    {
        "title": "Symbolic and User-friendly Geometric Algebra Routines (SUGAR) for\n  Computations in Matlab",
        "authors": [
            "Manel Velasco",
            "Isiah Zaplana",
            "Arnau Dória-Cerezo",
            "Pau Martí"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Geometric algebra (GA) is a mathematical tool for geometric computing,\nproviding a framework that allows a unified and compact approach to geometric\nrelations which in other mathematical systems are typically described using\ndifferent more complicated elements. This fact has led to an increasing\nadoption of GA in applied mathematics and engineering problems. However, the\nscarcity of symbolic implementations of GA and its inherent complexity,\nrequiring a specific mathematical background, make it challenging and less\nintuitive for engineers to work with. This prevents wider adoption among more\napplied professionals. To address this challenge, this paper introduces SUGAR\n(Symbolic and User-friendly Geometric Algebra Routines), an open-source toolbox\ndesigned for Matlab and licensed under the MIT License. SUGAR facilitates the\ntranslation of GA concepts into Matlab and provides a collection of\nuser-friendly functions tailored for GA computations, including support for\nsymbolic operations. It supports both numeric and symbolic computations in\nhigh-dimensional GAs. Specifically tailored for applied mathematics and\nengineering applications, SUGAR has been meticulously engineered to represent\ngeometric elements and transformations within two and three-dimensional\nprojective and conformal geometric algebras, aligning with established\ncomputational methodologies in the literature. Furthermore, SUGAR efficiently\nhandles functions of multivectors, such as exponential, logarithmic,\nsinusoidal, and cosine functions, enhancing its applicability across various\nengineering domains, including robotics, control systems, and power\nelectronics. Finally, this work includes four distinct validation examples,\ndemonstrating SUGAR's capabilities across the above-mentioned fields and its\npractical utility in addressing real-world applied mathematics and engineering\nproblems.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.16634v1"
    },
    {
        "title": "Algorithm xxx: Faster Randomized SVD with Dynamic Shifts",
        "authors": [
            "Xu Feng",
            "Wenjian Yu",
            "Yuyang Xie",
            "Jie Tang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Aiming to provide a faster and convenient truncated SVD algorithm for large\nsparse matrices from real applications (i.e. for computing a few of largest\nsingular values and the corresponding singular vectors), a dynamically shifted\npower iteration technique is applied to improve the accuracy of the randomized\nSVD method. This results in a dynamic shifts based randomized SVD (dashSVD)\nalgorithm, which also collaborates with the skills for handling sparse\nmatrices. An accuracy-control mechanism is included in the dashSVD algorithm to\napproximately monitor the per vector error bound of computed singular vectors\nwith negligible overhead. Experiments on real-world data validate that the\ndashSVD algorithm largely improves the accuracy of randomized SVD algorithm or\nattains same accuracy with fewer passes over the matrix, and provides an\nefficient accuracy-control mechanism to the randomized SVD computation, while\ndemonstrating the advantages on runtime and parallel efficiency. A bound of the\napproximation error of the randomized SVD with the shifted power iteration is\nalso proved.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.09276v1"
    },
    {
        "title": "Differentiating Through Linear Solvers",
        "authors": [
            "Paul Hovland",
            "Jan Hückelheim"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Computer programs containing calls to linear solvers are a known challenge\nfor automatic differentiation. Previous publications advise against\ndifferentiating through the low-level solver implementation, and instead\nadvocate for high-level approaches that express the derivative in terms of a\nmodified linear system that can be solved with a separate solver call. Despite\nthis ubiquitous advice, we are not aware of prior work comparing the accuracy\nof both approaches. With this article we thus empirically study a simple\nquestion: What happens if we ignore common wisdom, and differentiate through\nlinear solvers?\n",
        "pdf_link": "http://arxiv.org/pdf/2404.17039v2"
    },
    {
        "title": "Xabclib:A Fully Auto-tuned Sparse Iterative Solver",
        "authors": [
            "Takahiro Katagiri",
            "Takao Sakurai",
            "Mitsuyoshi Igai",
            "Shoji Itoh",
            "Satoshi Ohshima",
            "Hisayasu Kuroda",
            "Ken Naono",
            "Kengo Nakajima"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In this paper, we propose a general application programming interface named\nOpenATLib for auto-tuning (AT). OpenATLib is designed to establish the\nreusability of AT functions. By using OpenATLib, we develop a fully auto-tuned\nsparse iterative solver named Xabclib. Xabclib has several novel run-time AT\nfunctions. First, the following new implementations of sparse matrix-vector\nmultiplication (SpMV) for thread processing are implemented:(1) non-zero\nelements; (2) omission of zero-elements computation for vector reduction; (3)\nbranchless segmented scan (BSS). According to the performance evaluation and\nthe comparison with conventional implementations, the following results are\nobtained: (1) 14x speedup for non-zero elements and zero-elements computation\nomission for symmetric SpMV; (2) 4.62x speedup by using BSS. We also develop a\n\"numerical computation policy\" that can optimize memory space and computational\naccuracy. Using the policy, we obtain the following: (1) an averaged 1/45\nmemory space reduction; (2) avoidance of the \"fault convergence\" situation,\nwhich is a problem of conventional solvers.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.01599v1"
    },
    {
        "title": "Enabling mixed-precision with the help of tools: A Nekbone case study",
        "authors": [
            "Yanxiang Chen",
            "Pablo de Oliveira Castro",
            "Paolo Bientinesi",
            "Roman Iakymchuk"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Mixed-precision computing has the potential to significantly reduce the cost\nof exascale computations, but determining when and how to implement it in\nprograms can be challenging. In this article, we consider Nekbone, a\nmini-application for the CFD solver Nek5000, as a case study, and propose a\nmethodology for enabling mixed-precision with the help of computer arithmetic\ntools and roofline model. We evaluate the derived mixed-precision program by\ncombining metrics in three dimensions: accuracy, time-to-solution, and\nenergy-to-solution. Notably, the introduction of mixed-precision in Nekbone,\nreducing time-to-solution by 40.7% and energy-to-solution by 47% on 128 MPI\nranks.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.11065v1"
    },
    {
        "title": "An 808 Line Phasor-Based Dehomogenisation Matlab Code For Multi-Scale\n  Topology Optimisation",
        "authors": [
            "Rebekka Varum Woldseth",
            "Ole Sigmund",
            "Peter Dørffler Ladegaard Jensen"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This work presents an 808-line Matlab educational code for combined\nmulti-scale topology optimisation and phasor-based dehomogenisation titled\ndeHomTop808. The multi-scale formulation utilises homogenisation of optimal\nmicrostructures to facilitate efficient coarse-scale optimisation.\nDehomogenisation allows for a high-resolution single-scale reconstruction of\nthe optimised multi-scale structure, achieving minor losses in structural\nperformance, at a fraction of the computational cost, compared to its\nlarge-scale topology optimisation counterpart. The presented code utilises\nstiffness optimal Rank-2 microstructures to minimise the compliance of a\nsingle-load case problem, subject to a volume fraction constraint. By\nexploiting the inherent efficiency benefits of the phasor-based\ndehomogenisation procedure, on-the-fly dehomogenisation to a single-scale\nstructure is obtained. The presented code includes procedures for structural\nverification of the final dehomogenised structure by comparison to the\nmulti-scale solution. The code is introduced in terms of the underlying theory\nand its major components, including examples and potential extensions, and can\nbe downloaded from https://github.com/peterdorffler/deHomTop808.git.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.14321v2"
    },
    {
        "title": "A square root algorithm faster than Newton's method for multiprecision\n  numbers, using floating-point arithmetic",
        "authors": [
            "Fabio Romano"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In this paper, an optimized version of classical Bombelli's algorithm for\ncomputing integer square roots is presented. In particular, floating-point\narithmetic is used to compute the initial guess of each digit of the root,\nfollowing similar ideas to those used in \"The Art of Computer Programming\" Vol.\n2, p. 4.3.1 for division. A program with an implementation of the algorithm in\nJava is also presented, and its running time is compared with that of the\nalgorithm provided by the Java standard library, which uses the Newton's\nmethod. From tests, the algorithm presented here turns out to be much faster.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.07751v1"
    },
    {
        "title": "Automating Variational Differentiation",
        "authors": [
            "Kangbo Li",
            "Anil Damle"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Many problems in Physics and Chemistry are formulated as the minimization of\na functional. Therefore, methods for solving these problems typically require\ndifferentiating maps whose input and/or output are functions -- commonly\nreferred to as variational differentiation. Such maps are not addressed at the\nmathematical level by the chain rule, which underlies modern symbolic and\nalgorithmic differentiation (AD) systems. Although there are algorithmic\nsolutions such as tracing and reverse accumulation, they do not provide human\nreadability and introduce strict programming constraints that bottleneck\nperformance, especially in high-performance computing (HPC) environments. In\nthis manuscript, we propose a new computer theoretic model of differentiation\nby combining the pullback of the $\\mathbf{B}$ and $\\mathbf{C}$ combinators from\nthe combinatory logic. Unlike frameworks based on the chain rule, this model\ndifferentiates a minimal complete basis for the space of computable functions.\nConsequently, the model is capable of analytic backpropagation and variational\ndifferentiation while supporting complex numbers. To demonstrate the generality\nof this approach we build a system named CombDiff, which can differentiate\nnontrivial variational problems such as Hartree-Fock (HF) theory and multilayer\nperceptrons.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.16154v1"
    },
    {
        "title": "Acceleration of Tensor-Product Operations with Tensor Cores",
        "authors": [
            "Cu Cui"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  In this paper, we explore the acceleration of tensor product operations in\nfinite element methods, leveraging the computational power of the NVIDIA A100\nGPU Tensor Cores. We provide an accessible overview of the necessary\nmathematical background and discuss our implementation strategies. Our study\nfocuses on two common programming approaches for NVIDIA Tensor Cores: the C++\nWarp Matrix Functions in nvcuda::wmma and the inline Parallel Thread Execution\n(PTX) instructions mma.sync.aligned. A significant focus is placed on the\nadoption of the versatile inline PTX instructions combined with a conflict-free\nshared memory access pattern, a key to unlocking superior performance. When\nbenchmarked against traditional CUDA Cores, our approach yields a remarkable\n2.3-fold increase in double precision performance, achieving 8 TFLOPS/s-45% of\nthe theoretical maximum. Furthermore, in half-precision computations, numerical\nexperiments demonstrate a fourfold enhancement in solving the Poisson equation\nusing the flexible GMRES (FGMRES) method, preconditioned by a multigrid method\nin 3D. This is achieved while maintaining the same discretization error as\nobserved in double precision computations. These results highlight the\nconsiderable benefits of using Tensor Cores for finite element operators with\ntensor products, achieving an optimal balance between computational speed and\nprecision.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.09621v1"
    },
    {
        "title": "Implementing a Restricted Function Space Class in Firedrake",
        "authors": [
            "Emma Rothwell"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  The implementation process of a $\\texttt{RestrictedFunctionSpace}$ class in\nFiredrake, a Python library which numerically solves partial differential\nequations through the use of the finite element method, is documented. This\nincludes an introduction to the current $\\texttt{FunctionSpace}$ class in\nFiredrake, and the key features that it has. With the current\n$\\texttt{FunctionSpace}$ class, the limitations of the capabilities of the\nsolvers in Firedrake when imposing Dirichlet boundary conditions are explored,\nas well as what the $\\texttt{RestrictedFunctionSpace}$ class does differently\nto remove these issues. These will be considered in both a mathematical way,\nand in the code as an abstraction of the mathematical ideas presented. Finally,\nthe benefits to the user of the $\\texttt{RestrictedFunctionSpace}$ class are\nconsidered, and demonstrated through tests and comparisons. This leads to the\nconclusion that in particular, the eigensolver in Firedrake is improved through\nthe use of the $\\texttt{RestrictedFunctionSpace}$, through the removal of\neigenvalues associated with the Dirichlet boundary conditions for a system.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.05217v1"
    },
    {
        "title": "cpp11armadillo: An R Package to Use the Armadillo C++ Library",
        "authors": [
            "Mauricio Vargas Sepúlveda",
            "Jonathan Schneider Malamud"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This article introduces 'cpp11armadillo', a new R package that integrates the\npowerful Armadillo C++ library for linear algebra into the R programming\nenvironment. Targeted primarily at social scientists and other non-programmers,\nthis article explains the computational benefits of moving code to C++ in terms\nof speed and syntax. We provide a comprehensive overview of Armadillo's\ncapabilities, highlighting its user-friendly syntax akin to MATLAB and its\nefficiency for computationally intensive tasks. The 'cpp11armadillo' package\nsimplifies a part of the process of using C++ within R by offering additional\nease of integration for those who require high-performance linear algebra\noperations in their R workflows. This work aims to bridge the gap between\ncomputational efficiency and accessibility, making advanced linear algebra\noperations more approachable for R users without extensive programming\nbackgrounds.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.11074v3"
    },
    {
        "title": "PySLSQP: A transparent Python package for the SLSQP optimization\n  algorithm modernized with utilities for visualization and post-processing",
        "authors": [
            "Anugrah Jo Joshy",
            "John T. Hwang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  PySLSQP is a seamless interface for using the SLSQP algorithm from Python. It\nwraps the original SLSQP Fortran code sourced from the SciPy repository and\nprovides a host of new features to improve the research utility of the original\nalgorithm. Some of the additional features offered by PySLSQP include\nauto-generation of unavailable derivatives using finite differences,\nindependent scaling of the problem variables and functions, access to internal\noptimization data, live-visualization, saving optimization data from each\niteration, warm/hot restarting of optimization, and various other utilities for\npost-processing.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.13420v1"
    },
    {
        "title": "Welding R and C++: A Tale of Two Programming Languages",
        "authors": [
            "Mauricio Vargas Sepulveda"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This article compares `cpp11armadillo` and `cpp11eigen`, new R packages that\nintegrate the powerful Armadillo and Eigen C++ libraries for linear algebra\ninto the R programming environment. This article provides a detailed comparison\nbetween Armadillo and Eigen speed and syntax. The goal of these packages is to\nsimplify a part of the process of solving bottlenecks by using C++ within R,\nthese offer additional ease of integration for users who require\nhigh-performance linear algebra operations in their R workflows. This document\naims to discuss the tradeoff between computational efficiency and\naccessibility.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.00568v2"
    },
    {
        "title": "LibMOON: A Gradient-based MultiObjective OptimizatioN Library in PyTorch",
        "authors": [
            "Xiaoyuan Zhang",
            "Liang Zhao",
            "Yingying Yu",
            "Xi Lin",
            "Yifan Chen",
            "Han Zhao",
            "Qingfu Zhang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Multiobjective optimization problems (MOPs) are prevalent in machine\nlearning, with applications in multi-task learning, learning under fairness or\nrobustness constraints, etc. Instead of reducing multiple objective functions\ninto a scalar objective, MOPs aim to optimize for the so-called Pareto\noptimality or Pareto set learning, which involves optimizing more than one\nobjective function simultaneously, over models with thousands / millions of\nparameters. Existing benchmark libraries for MOPs mainly focus on evolutionary\nalgorithms, most of which are zeroth-order / meta-heuristic methods that do not\neffectively utilize higher-order information from objectives and cannot scale\nto large-scale models with thousands / millions of parameters. In light of the\nabove gap, this paper introduces LibMOON, the first multiobjective optimization\nlibrary that supports state-of-the-art gradient-based methods, provides a fair\nbenchmark, and is open-sourced for the community.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.02969v3"
    },
    {
        "title": "A tutorial on automatic differentiation with complex numbers",
        "authors": [
            "Nicholas Krämer"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Automatic differentiation is everywhere, but there exists only minimal\ndocumentation of how it works in complex arithmetic beyond stating \"derivatives\nin $\\mathbb{C}^d$\" $\\cong$ \"derivatives in $\\mathbb{R}^{2d}$\" and, at best,\nshallow references to Wirtinger calculus. Unfortunately, the equivalence\n$\\mathbb{C}^d \\cong \\mathbb{R}^{2d}$ becomes insufficient as soon as we need to\nderive custom gradient rules, e.g., to avoid differentiating \"through\"\nexpensive linear algebra functions or differential equation simulators. To\ncombat such a lack of documentation, this article surveys forward- and\nreverse-mode automatic differentiation with complex numbers, covering topics\nsuch as Wirtinger derivatives, a modified chain rule, and different gradient\nconventions while explicitly avoiding holomorphicity and the Cauchy--Riemann\nequations (which would be far too restrictive). To be precise, we will derive,\nexplain, and implement a complex version of Jacobian-vector and vector-Jacobian\nproducts almost entirely with linear algebra without relying on complex\nanalysis or differential geometry. This tutorial is a call to action, for users\nand developers alike, to take complex values seriously when implementing custom\ngradient propagation rules -- the manuscript explains how.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.06752v3"
    },
    {
        "title": "Computing Arrangements of Hypersurfaces",
        "authors": [
            "Paul Breiding",
            "Bernd Sturmfels",
            "Kexin Wang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  We present a Julia package HypersurfaceRegions.jl for computing all connected\ncomponents in the complement of an arrangement of real algebraic hypersurfaces\nin $\\mathbb{R}^n$.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.09622v1"
    },
    {
        "title": "Some new techniques to use in serial sparse Cholesky factorization\n  algorithms",
        "authors": [
            "M. Ozan Karsavuran",
            "Esmond G. Ng",
            "Barry W. Peyton",
            "Jonathan L. Peyton"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  We present a new variant of serial right-looking supernodal sparse Cholesky\nfactorization (RL). Our comparison of RL with the multifrontal method confirms\nthat RL is simpler, slightly faster, and requires slightly less storage. The\nkey to the rest of the work in this paper is recent work on reordering columns\nwithin supernodes so that the dense off-diagonal blocks in the factor matrix\njoining pairs of supernodes are fewer and larger. We present a second new\nvariant of serial right-looking supernodal sparse Cholesky factorization (RLB),\nwhere this one is specifically designed to exploit fewer and larger\noff-diagonal blocks in the factor matrix obtained by reordering within\nsupernodes. A key distinction found in RLB is that it uses no floating-point\nworking storage and performs no assembly operations. Our key finding is that\nRLB is unequivocally faster than its competitors. Indeed, RLB is consistently,\nbut modestly, faster than its competitors whenever Intel's MKL sequential BLAS\nare used. More importantly, RLB is substantially faster than its competitors\nwhenever Intel's MKL multithreaded BLAS are used. Finally, RLB using the\nmultithreaded BLAS achieves impressive speedups over RLB using the sequential\nBLAS.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.13090v1"
    },
    {
        "title": "SequentialSamplingModels.jl: Simulating and Evaluating Cognitive Models\n  of Response Times in Julia",
        "authors": [
            "Kianté Fernandez",
            "Dominique Makowski",
            "Christopher Fisher"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Sequential sampling models (SSMs) are a widely used framework describing\ndecision-making as a stochastic, dynamic process of evidence accumulation. SSMs\npopularity across cognitive science has driven the development of various\nsoftware packages that lower the barrier for simulating, estimating, and\ncomparing existing SSMs. Here, we present a software tool,\nSequentialSamplingModels.jl (SSM.jl), designed to make SSM simulations more\naccessible to Julia users, and to integrate with the Julia ecosystem. We\ndemonstrate the basic use of SSM.jl for simulation, plotting, and Bayesian\ninference.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.06631v1"
    },
    {
        "title": "Evaluating the Design Features of an Intelligent Tutoring System for\n  Advanced Mathematics Learning",
        "authors": [
            "Ying Fang",
            "Bo He",
            "Zhi Liu",
            "Sannyuya Liu",
            "Zhonghua Yan",
            "Jianwen Sun"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Xiaomai is an intelligent tutoring system (ITS) designed to help Chinese\ncollege students in learning advanced mathematics and preparing for the\ngraduate school math entrance exam. This study investigates two distinctive\nfeatures within Xiaomai: the incorporation of free-response questions with\nautomatic feedback and the metacognitive element of reflecting on self-made\nerrors.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.17265v1"
    },
    {
        "title": "The myth of equidistribution for high-dimensional simulation",
        "authors": [
            "Richard P. Brent"
        ],
        "category": "cs.MS",
        "published_year": "2010",
        "summary": "  A pseudo-random number generator (RNG) might be used to generate w-bit random\nsamples in d dimensions if the number of state bits is at least dw. Some RNGs\nperform better than others and the concept of equidistribution has been\nintroduced in the literature in order to rank different RNGs. We define what it\nmeans for a RNG to be (d,w)-equidistributed, and then argue that\n(d,w)-equidistribution is not necessarily a desirable property.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.1320v1"
    },
    {
        "title": "Parallel random variates generator for GPUs based on normal numbers",
        "authors": [
            "Gleb Beliakov",
            "Michael Johnstone",
            "Doug Creighton",
            "Tim Wilkin"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  Pseudorandom number generators are required for many computational tasks,\nsuch as stochastic modelling and simulation. This paper investigates the serial\nCPU and parallel GPU implementation of a Linear Congruential Generator based on\nthe binary representation of the normal number $\\alpha_{2,3}$. We adapted two\nmethods of modular reduction which allowed us to perform most operations in\n64-bit integer arithmetic, improving on the original implementation based on\n106-bit double-double operations. We found that our implementation is faster\nthan existing methods in literature, and our generation rate is close to the\nlimiting rate imposed by the efficiency of writing to a GPU's global memory.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.1187v2"
    },
    {
        "title": "Computing Petaflops over Terabytes of Data: The Case of Genome-Wide\n  Association Studies",
        "authors": [
            "Diego Fabregat-Traver",
            "Paolo Bientinesi"
        ],
        "category": "cs.MS",
        "published_year": "2012",
        "summary": "  In many scientific and engineering applications, one has to solve not one but\na sequence of instances of the same problem. Often times, the problems in the\nsequence are linked in a way that allows intermediate results to be reused. A\ncharacteristic example for this class of applications is given by the\nGenome-Wide Association Studies (GWAS), a widely spread tool in computational\nbiology. GWAS entails the solution of up to trillions ($10^{12}$) of correlated\ngeneralized least-squares problems, posing a daunting challenge: the\nperformance of petaflops ($10^{15}$ floating-point operations) over terabytes\nof data.\n  In this paper, we design an algorithm for performing GWAS on multi-core\narchitectures. This is accomplished in three steps. First, we show how to\nexploit the relation among successive problems, thus reducing the overall\ncomputational complexity. Then, through an analysis of the required data\ntransfers, we identify how to eliminate any overhead due to input/output\noperations. Finally, we study how to decompose computation into tasks to be\ndistributed among the available cores, to attain high performance and\nscalability. With our algorithm, a GWAS that currently requires the use of a\nsupercomputer may now be performed in matter of hours on a single multi-core\nnode.\n  The discussion centers around the methodology to develop the algorithm rather\nthan the specific application. We believe the paper contributes valuable\nguidelines of general applicability for computational scientists on how to\ndevelop and optimize numerical algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.7683v1"
    },
    {
        "title": "MathGR: a tensor and GR computation package to keep it simple",
        "authors": [
            "Yi Wang"
        ],
        "category": "cs.MS",
        "published_year": "2013",
        "summary": "  We introduce the MathGR package, written in Mathematica. The package can\nmanipulate tensor and GR calculations with either abstract or explicit indices,\nsimplify tensors with permutational symmetries, decompose tensors from abstract\nindices to partially or completely explicit indices and convert partial\nderivatives into total derivatives. Frequently used GR tensors and a model of\nFRW universe with ADM type perturbations are predefined. The package is built\naround the philosophy to \"keep it simple\", and makes use of latest tensor\ntechnologies of Mathematica.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.1295v3"
    },
    {
        "title": "Transpose-free Fast Fourier Transform for Turbulence Simulation",
        "authors": [
            "A. G. Chatterjee",
            "M. K. Verma",
            "M. Chaudhuri"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  Pseudo-spectral method is one of the most accurate techniques for simulating\nturbulent flows. Fast Fourier transform (FFT) is an integral part of this\nmethod. In this paper, we present a new procedure to compute FFT in which we\nsave operations during interprocess communications by avoiding transpose of the\narray. As a result, our transpose-free FFT is 15\\% to 20\\% faster than FFTW.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.5597v1"
    },
    {
        "title": "Cluster-level tuning of a shallow water equation solver on the Intel MIC\n  architecture",
        "authors": [
            "Andrey Vladimirov",
            "Cliff Addison"
        ],
        "category": "cs.MS",
        "published_year": "2014",
        "summary": "  The paper demonstrates the optimization of the execution environment of a\nhybrid OpenMP+MPI computational fluid dynamics code (shallow water equation\nsolver) on a cluster enabled with Intel Xeon Phi coprocessors. The discussion\nincludes: (1) Controlling the number and affinity of OpenMP threads to optimize\naccess to memory bandwidth; (2) Tuning the inter-operation of OpenMP and MPI to\npartition the problem for better data locality; (3) Ordering the MPI ranks in a\nway that directs some of the traffic into faster communication channels; (4)\nUsing efficient peer-to-peer communication between Xeon Phi coprocessors based\non the InfiniBand fabric.\n  With tuning, the application has 90% percent efficiency of parallel scaling\nup to 8 Intel Xeon Phi coprocessors in 2 compute nodes. For larger problems,\nscalability is even better, because of the greater computation to communication\nratio. However, problems of that size do not fit in the memory of one\ncoprocessor. The performance of the solver on one Intel Xeon Phi coprocessor\n7120P exceeds the performance on a dual-socket Intel Xeon E5-2697 v2 CPU by a\nfactor of 1.6x. In a 2-node cluster with 4 coprocessors per compute node, the\nMIC architecture yields 5.8x more performance than the CPUs. Only one line of\nlegacy Fortran code had to be changed in order to achieve the reported\nperformance on the MIC architecture (not counting changes to the command-line\ninterface). The methodology discussed in this paper is directly applicable to\nother bandwidth-bound stencil algorithms utilizing a hybrid OpenMP+MPI\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.1727v1"
    },
    {
        "title": "Computing Tropical Prevarieties in Parallel",
        "authors": [
            "Anders Jensen",
            "Jeff Sommars",
            "Jan Verschelde"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  The computation of the tropical prevariety is the first step in the\napplication of polyhedral methods to compute positive dimensional solution sets\nof polynomial systems. In particular, pretropisms are candidate leading\nexponents for the power series developments of the solutions. The computation\nof the power series may start as soon as one pretropism is available, so our\nparallel computation of the tropical prevariety has an application in a\npipelined solver.\n  We present a parallel implementation of dynamic enumeration. Our first\ndistributed memory implementation with forked processes achieved good speedups,\nbut quite often resulted in large variations in the execution times of the\nprocesses. The shared memory multithreaded version applies work stealing to\nreduce the variability of the run time. Our implementation applies the thread\nsafe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU\nMultiprecision Arithmetic Library (GMP), aided by the fast memory allocations\nof TCMalloc.\n  Our parallel implementation is capable of computing the tropical prevariety\nof the cyclic 16-roots problem. We also report on computational experiments on\nthe $n$-body and $n$-vortex problems; our computational results compare\nfavorably with Gfan.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00720v2"
    },
    {
        "title": "Preconditioned Spectral Clustering for Stochastic Block Partition\n  Streaming Graph Challenge",
        "authors": [
            "David Zhuzhunashvili",
            "Andrew Knyazev"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) is\ndemonstrated to efficiently solve eigenvalue problems for graph Laplacians that\nappear in spectral clustering. For static graph partitioning, 10-20 iterations\nof LOBPCG without preconditioning result in ~10x error reduction, enough to\nachieve 100% correctness for all Challenge datasets with known truth\npartitions, e.g., for graphs with 5K/.1M (50K/1M) Vertices/Edges in 2 (7)\nseconds, compared to over 5,000 (30,000) seconds needed by the baseline Python\ncode. Our Python code 100% correctly determines 98 (160) clusters from the\nChallenge static graphs with 0.5M (2M) vertices in 270 (1,700) seconds using\n10GB (50GB) of memory. Our single-precision MATLAB code calculates the same\nclusters at half time and memory. For streaming graph partitioning, LOBPCG is\ninitiated with approximate eigenvectors of the graph Laplacian already computed\nfor the previous graph, in many cases reducing 2-3 times the number of required\nLOBPCG iterations, compared to the static case. Our spectral clustering is\ngeneric, i.e. assuming nothing specific of the block model or streaming, used\nto generate the graphs for the Challenge, in contrast to the base code.\nNevertheless, in 10-stage streaming comparison with the base code for the 5K\ngraph, the quality of our clusters is similar or better starting at stage 4 (7)\nfor emerging edging (snowballing) streaming, while the computations are over\n100-1000 faster.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.07481v1"
    },
    {
        "title": "Acceleration of tensor-product operations for high-order finite element\n  methods",
        "authors": [
            "Kasia Świrydowicz",
            "Noel Chalmers",
            "Ali Karakus",
            "Timothy Warburton"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  This paper is devoted to GPU kernel optimization and performance analysis of\nthree tensor-product operators arising in finite element methods. We provide a\nmathematical background to these operations and implementation details.\nAchieving close-to-the-peak performance for these operators requires extensive\noptimization because of the operators' properties: low arithmetic intensity,\ntiered structure, and the need to store intermediate results inside the kernel.\nWe give a guided overview of optimization strategies and we present a\nperformance model that allows us to compare the efficacy of these optimizations\nagainst an empirically calibrated roofline.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.00903v2"
    },
    {
        "title": "A Blackbox Polynomial System Solver on Parallel Shared Memory Computers",
        "authors": [
            "Jan Verschelde"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  A numerical irreducible decomposition for a polynomial system provides\nrepresentations for the irreducible factors of all positive dimensional\nsolution sets of the system, separated from its isolated solutions. Homotopy\ncontinuation methods are applied to compute a numerical irreducible\ndecomposition. Load balancing and pipelining are techniques in a parallel\nimplementation on a computer with multicore processors. The application of the\nparallel algorithms is illustrated on solving the cyclic $n$-roots problems, in\nparticular for $n = 8, 9$, and~12.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.03807v2"
    },
    {
        "title": "FDTD: solving 1+1D delay PDE in parallel",
        "authors": [
            "Yao-Lung L. Fang"
        ],
        "category": "cs.MS",
        "published_year": "2017",
        "summary": "  We present a proof of concept for solving a 1+1D complex-valued, delay\npartial differential equation (PDE) that emerges in the study of waveguide\nquantum electrodynamics (QED) by adapting the finite-difference time-domain\n(FDTD) method. The delay term is spatially non-local, rendering conventional\napproaches such as the method of lines inapplicable. We show that by properly\ndesigning the grid and by supplying the (partial) exact solution as the\nboundary condition, the delay PDE can be numerically solved. In addition, we\ndemonstrate that while the delay imposes strong data dependency, multi-thread\nparallelization can nevertheless be applied to such a problem. Our code\nprovides a numerically exact solution to the time-dependent multi-photon\nscattering problem in waveguide QED.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.05943v2"
    },
    {
        "title": "Solving Polynomial Systems in the Cloud with Polynomial Homotopy\n  Continuation",
        "authors": [
            "Nathan Bliss",
            "Jeff Sommars",
            "Jan Verschelde",
            "Xiangcheng Yu"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Polynomial systems occur in many fields of science and engineering.\nPolynomial homotopy continuation methods apply symbolic-numeric algorithms to\nsolve polynomial systems. We describe the design and implementation of our web\ninterface and reflect on the application of polynomial homotopy continuation\nmethods to solve polynomial systems in the cloud. Via the graph isomorphism\nproblem we organize and classify the polynomial systems we solved. The\nclassification with the canonical form of a graph identifies newly submitted\nsystems with systems that have already been solved.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.02618v1"
    },
    {
        "title": "Extendible and Efficient Python Framework for Solving Evolution\n  Equations with Stabilized Discontinuous Galerkin Method",
        "authors": [
            "Andreas Dedner",
            "Robert Klöfkorn"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper discusses a Python interface for the recently published\nDUNE-FEM-DG module which provides highly efficient implementations of the\nDiscontinuous Galerkin (DG) method for solving a wide range of non linear\npartial differential equations (PDE). Although the C++ interfaces of\nDUNE-FEM-DG are highly flexible and customizable, a solid knowledge of C++ is\nnecessary to make use of this powerful tool. With this work easier user\ninterfaces based on Python and the Unified Form Language are provided to open\nDUNE-FEM-DG for a broader audience. The Python interfaces are demonstrated for\nboth parabolic and first order hyperbolic PDEs.\n",
        "pdf_link": "http://arxiv.org/pdf/2009.13416v2"
    },
    {
        "title": "ParaMonte: A high-performance serial/parallel Monte Carlo simulation\n  library for C, C++, Fortran",
        "authors": [
            "Amir Shahmoradi",
            "Fatemeh Bagheri"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  ParaMonte (standing for Parallel Monte Carlo) is a serial and\nMPI/Coarray-parallelized library of Monte Carlo routines for sampling\nmathematical objective functions of arbitrary-dimensions, in particular, the\nposterior distributions of Bayesian models in data science, Machine Learning,\nand scientific inference. The ParaMonte library has been developed with the\ndesign goal of unifying the **automation**, **accessibility**,\n**high-performance**, **scalability**, and **reproducibility** of Monte Carlo\nsimulations. The current implementation of the library includes **ParaDRAM**, a\n**Para**llel **D**elyaed-**R**ejection **A**daptive **M**etropolis Markov Chain\nMonte Carlo sampler, accessible from a wide range of programming languages\nincluding C, C++, Fortran, with a unified Application Programming Interface and\nsimulation environment across all supported programming languages. The\nParaMonte library is MIT-licensed and is permanently located and maintained at\n[https://github.com/cdslaborg/paramonte](https://github.com/cdslaborg/paramonte).\n",
        "pdf_link": "http://arxiv.org/pdf/2009.14229v1"
    },
    {
        "title": "Efficient Differentiable Programming in a Functional Array-Processing\n  Language",
        "authors": [
            "Amir Shaikhha",
            "Andrew Fitzgibbon",
            "Dimitrios Vytiniotis",
            "Simon Peyton Jones",
            "Christoph Koch"
        ],
        "category": "cs.MS",
        "published_year": "2018",
        "summary": "  We present a system for the automatic differentiation of a higher-order\nfunctional array-processing language. The core functional language underlying\nthis system simultaneously supports both source-to-source automatic\ndifferentiation and global optimizations such as loop transformations. Thanks\nto this feature, we demonstrate how for some real-world machine learning and\ncomputer vision benchmarks, the system outperforms the state-of-the-art\nautomatic differentiation tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.02136v1"
    },
    {
        "title": "The JuliaConnectoR: a functionally oriented interface for integrating\n  Julia in R",
        "authors": [
            "Stefan Lenz",
            "Maren Hackenberg",
            "Harald Binder"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Like many groups considering the new programming language Julia, we faced the\nchallenge of accessing the algorithms that we develop in Julia from R.\nTherefore, we developed the R package JuliaConnectoR, available from the CRAN\nrepository and GitHub (https://github.com/stefan-m-lenz/JuliaConnectoR), in\nparticular for making advanced deep learning tools available. For\nmaintainability and stability, we decided to base communication between R and\nJulia on TCP, using an optimized binary format for exchanging data. Our package\nalso specifically contains features that allow for a convenient interactive use\nin R. This makes it easy to develop R extensions with Julia or to simply call\nfunctionality from Julia packages in R. Interacting with Julia objects and\ncalling Julia functions becomes user-friendly, as Julia functions and variables\nare made directly available as objects in the R workspace. We illustrate the\nfurther features of our package with code examples, and also discuss advantages\nover the two alternative packages JuliaCall and XRJulia. Finally, we\ndemonstrate the usage of the package with a more extensive example for\nemploying neural ordinary differential equations, a recent deep learning\ntechnique that has received much attention. This example also provides more\ngeneral guidance for integrating deep learning techniques from Julia into R.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06334v2"
    },
    {
        "title": "Accelerating Polynomial Homotopy Continuation on a Graphics Processing\n  Unit with Double Double and Quad Double Arithmetic",
        "authors": [
            "Jan Verschelde",
            "Xiangcheng Yu"
        ],
        "category": "cs.MS",
        "published_year": "2015",
        "summary": "  Numerical continuation methods track a solution path defined by a homotopy.\nThe systems we consider are defined by polynomials in several variables with\ncomplex coefficients. For larger dimensions and degrees, the numerical\nconditioning worsens and hardware double precision becomes often insufficient\nto reach the end of the solution path. With double double and quad double\narithmetic, we can solve larger problems that we could not solve with hardware\ndouble arithmetic, but at a higher computational cost. This cost overhead can\nbe compensated by acceleration on a Graphics Processing Unit (GPU). We describe\nour implementation and report on computational results on benchmark polynomial\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.06625v3"
    },
    {
        "title": "Algorithms and data structures for matrix-free finite element operators\n  with MPI-parallel sparse multi-vectors",
        "authors": [
            "Denis Davydov",
            "Martin Kronbichler"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  Traditional solution approaches for problems in quantum mechanics scale as\n$\\mathcal O(M^3)$, where $M$ is the number of electrons. Various methods have\nbeen proposed to address this issue and obtain linear scaling $\\mathcal O(M)$.\nOne promising formulation is the direct minimization of energy. Such methods\ntake advantage of physical localization of the solution, namely that the\nsolution can be sought in terms of non-orthogonal orbitals with local support.\nIn this work a numerically efficient implementation of sparse parallel vectors\nwithin the open-source finite element library deal.II is proposed. The main\nalgorithmic ingredient is the matrix-free evaluation of the Hamiltonian\noperator by cell-wise quadrature. Based on an a-priori chosen support for each\nvector we develop algorithms and data structures to perform (i) matrix-free\nsparse matrix multivector products (SpMM), (ii) the projection of an operator\nonto a sparse sub-space (inner products), and (iii) post-multiplication of a\nsparse multivector with a square matrix. The node-level performance is analyzed\nusing a roofline model. Our matrix-free implementation of finite element\noperators with sparse multivectors achieves the performance of 157 GFlop/s on\nIntel Cascade Lake architecture. Strong and weak scaling results are reported\nfor a typical benchmark problem using quadratic and quartic finite element\nbases.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.01005v1"
    },
    {
        "title": "Optimizing Block-Sparse Matrix Multiplications on CUDA with TVM",
        "authors": [
            "Zijing Gu"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  We implemented and optimized matrix multiplications between dense and\nblock-sparse matrices on CUDA. We leveraged TVM, a deep learning compiler, to\nexplore the schedule space of the operation and generate efficient CUDA code.\nWith the automatic parameter tuning in TVM, our cross-thread reduction based\nimplementation achieved competitive or better performance compared with other\nstate-of-the-art frameworks.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.13055v1"
    },
    {
        "title": "Instead of Rewriting Foreign Code for Machine Learning, Automatically\n  Synthesize Fast Gradients",
        "authors": [
            "William S. Moses",
            "Valentin Churavy"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Applying differentiable programming techniques and machine learning\nalgorithms to foreign programs requires developers to either rewrite their code\nin a machine learning framework, or otherwise provide derivatives of the\nforeign code. This paper presents Enzyme, a high-performance automatic\ndifferentiation (AD) compiler plugin for the LLVM compiler framework capable of\nsynthesizing gradients of statically analyzable programs expressed in the LLVM\nintermediate representation (IR). Enzyme synthesizes gradients for programs\nwritten in any language whose compiler targets LLVM IR including C, C++,\nFortran, Julia, Rust, Swift, MLIR, etc., thereby providing native AD\ncapabilities in these languages. Unlike traditional source-to-source and\noperator-overloading tools, Enzyme performs AD on optimized IR. On a\nmachine-learning focused benchmark suite including Microsoft's ADBench, AD on\noptimized IR achieves a geometric mean speedup of 4.5x over AD on IR before\noptimization allowing Enzyme to achieve state-of-the-art performance. Packaging\nEnzyme for PyTorch and TensorFlow provides convenient access to gradients of\nforeign code with state-of-the art performance, enabling foreign code to be\ndirectly incorporated into existing machine learning workflows.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.01709v1"
    },
    {
        "title": "Parallelizing multiple precision Taylor series method for integrating\n  the Lorenz system",
        "authors": [
            "I. Hristov",
            "R. Hristova",
            "S. Dimova",
            "P. Armyanov",
            "N. Shegunov",
            "I. Puzynin",
            "T. Puzynina",
            "Z. Sharipov",
            "Z. Tukhliev"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  A hybrid MPI+OpenMP strategy for parallelizing multiple precision Taylor\nseries method is proposed, realized and tested. To parallelize the algorithm we\ncombine MPI and OpenMP parallel technologies together with GMP library (GNU\nmiltiple precision libary) and the tiny MPIGMP library. The details of the\nparallelization are explained on the paradigmatic model of the Lorenz system.\nWe succeed to obtain a correct reference solution in the rather long time\ninterval - [0,7000]. The solution is verified by comparing the results for\n2700-th order Taylor series method and precision of ~ 3374 decimal digits, and\nthose with 2800-th order and precision of ~ 3510 decimal digits. With 192 CPU\ncores in Nestum cluster, Sofia, Bulgaria, the 2800-th order computation was ~\n145 hours with speedup ~ 105.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.14993v3"
    },
    {
        "title": "ReLie: a Reduce program for Lie group analysis of differential equations",
        "authors": [
            "Francesco Oliveri"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Lie symmetry analysis provides a general theoretical framework for\ninvestigating ordinary and partial differential equations. The theory is\ncompletely algorithmic even if it usually involves lengthy computations. For\nthis reason, many computer algebra packages have been developed along the years\nto automate the computation. In this paper, we describe the program ReLie,\nwritten in the Computer Algebra System Reduce, which since 2008 is an open\nsource program (http://www.reduce-algebra.com) and is available for all\nplatforms. \\relie is able to perform almost automatically the needed\ncomputations for Lie symmetry analysis of differential equations. Its source\ncode is freely available at the url http://mat521.unime.it/oliveri. The use of\nthe program is illustrated by means of some simple examples; nevertheless, it\nis to be underlined that it provides effective also for more complex\ncomputations where one has to deal with very large expressions.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.11534v1"
    },
    {
        "title": "Web-based Structural Identifiability Analyzer",
        "authors": [
            "Ilia Ilmer",
            "Alexey Ovchinnikov",
            "Gleb Pogudin"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  Parameter identifiability describes whether, for a given differential model,\none can determine parameter values from model equations. Knowing global or\nlocal identifiability properties allows construction of better practical\nexperiments to identify parameters from experimental data. In this work, we\npresent a web-based software tool that allows to answer specific\nidentifiability queries. Concretely, our toolbox can determine identifiability\nof individual parameters of the model and also provide all functions of\nparameters that are identifiable (also called identifiable combinations) from\nsingle or multiple experiments. The program is freely available at\nhttps://maple.cloud/app/6509768948056064.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.15066v1"
    },
    {
        "title": "Olsson.wl : a Mathematica package for the computation of linear\n  transformations of multivariable hypergeometric functions",
        "authors": [
            "B. Ananthanarayan",
            "Souvik Bera",
            "S. Friot",
            "Tanay Pathak"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  We present the Olsson.wl Mathematica package which aims to find linear\ntransformations for some classes of multivariable hypergeometric functions. It\nis based on a well-known method developed by P. O. M. Olsson in J. Math. Phys.\n5, 420 (1964) in order to derive the analytic continuations of the Appell $F_1$\ndouble hypergeometric series from the linear transformations of the Gauss\n$_2F_1$ hypergeometric function. We provide a brief description of Olsson's\nmethod and demonstrate the commands of the package, along with examples. We\nalso provide a companion package, called ROC2.wl and dedicated to the\nderivation of the regions of convergence of double hypergeometric series. This\npackage can be used independently of Olsson.wl.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.01189v1"
    },
    {
        "title": "Performance Portable Solid Mechanics via Matrix-Free $p$-Multigrid",
        "authors": [
            "Jed Brown",
            "Valeria Barra",
            "Natalie Beams",
            "Leila Ghaffari",
            "Matthew Knepley",
            "William Moses",
            "Rezgar Shakeri",
            "Karen Stengel",
            "Jeremy L. Thompson",
            "Junchao Zhang"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Finite element analysis of solid mechanics is a foundational tool of modern\nengineering, with low-order finite element methods and assembled sparse\nmatrices representing the industry standard for implicit analysis. We use\nperformance models and numerical experiments to demonstrate that high-order\nmethods greatly reduce the costs to reach engineering tolerances while enabling\neffective use of GPUs; these data structures also offer up to 2x benefit for\nlinear elements. We demonstrate the reliability, efficiency, and scalability of\nmatrix-free $p$-multigrid methods with algebraic multigrid coarse solvers\nthrough large deformation hyperelastic simulations of multiscale structures. We\ninvestigate accuracy, cost, and execution time on multi-node CPU and GPU\nsystems for moderate to large models (millions to billions of degrees of\nfreedom) using AMD MI250X (OLCF Crusher), NVIDIA A100 (NERSC Perlmutter), and\nV100 (LLNL Lassen and OLCF Summit), resulting in order of magnitude efficiency\nimprovements over a broad range of model properties and scales. We discuss\nefficient matrix-free representation of Jacobians and demonstrate how automatic\ndifferentiation enables rapid development of nonlinear material models without\nimpacting debuggability and workflows targeting GPUs. The methods are broadly\napplicable and amenable to common workflows, presented here via open source\nlibraries that encapsulate all GPU-specific aspects and are accessible to both\nnew and legacy code, allowing application code to be GPU-oblivious without\ncompromising end-to-end performance on GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.01722v3"
    },
    {
        "title": "Advanced Automatic Code Generation for Multiple Relaxation-Time Lattice\n  Boltzmann Methods",
        "authors": [
            "Frederik Hennig",
            "Markus Holzer",
            "Ulrich Rüde"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  The scientific code generation package lbmpy supports the automated design\nand the efficient implementation of lattice Boltzmann methods (LBMs) through\nmetaprogramming. It is based on a new, concise calculus for describing multiple\nrelaxation-time LBMs, including techniques that enable the numerically\nadvantageous subtraction of the constant background component from the\npopulations. These techniques are generalized to a wide range of collision\nspaces and equilibrium distributions. The article contains an overview of\nlbmpy's front-end and its code generation pipeline, which implements the new\nLBM calculus by means of symbolic formula manipulation tools and\nobject-oriented programming. The generated codes have only a minimal number of\narithmetic operations. Their automatic derivation rests on two novel Chimera\ntransforms that have been specifically developed for efficiently computing raw\nand central moments. Information contained in the symbolic representation of\nthe methods is further exploited in a customized sequence of algebraic\nsimplifications, further reducing computational cost. When combined, these\nalgebraic transformations lead to concise and compact numerical kernels.\nSpecifically, with these optimizations, the advanced central moment- and\ncumulant-based methods can be realized with only little additional cost as when\ncompared with the simple BGK method. The effectiveness and flexibility of the\nnew lbmpy code generation system is demonstrated in simulating Taylor-Green\nvortex decay and the automatic derivation of an LBM algorithm to solve the\nshallow water equations.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.02435v1"
    },
    {
        "title": "TorchOpt: An Efficient Library for Differentiable Optimization",
        "authors": [
            "Jie Ren",
            "Xidong Feng",
            "Bo Liu",
            "Xuehai Pan",
            "Yao Fu",
            "Luo Mai",
            "Yaodong Yang"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  Recent years have witnessed the booming of various differentiable\noptimization algorithms. These algorithms exhibit different execution patterns,\nand their execution needs massive computational resources that go beyond a\nsingle CPU and GPU. Existing differentiable optimization libraries, however,\ncannot support efficient algorithm development and multi-CPU/GPU execution,\nmaking the development of differentiable optimization algorithms often\ncumbersome and expensive. This paper introduces TorchOpt, a PyTorch-based\nefficient library for differentiable optimization. TorchOpt provides a unified\nand expressive differentiable optimization programming abstraction. This\nabstraction allows users to efficiently declare and analyze various\ndifferentiable optimization programs with explicit gradients, implicit\ngradients, and zero-order gradients. TorchOpt further provides a\nhigh-performance distributed execution runtime. This runtime can fully\nparallelize computation-intensive differentiation operations (e.g. tensor tree\nflattening) on CPUs / GPUs and automatically distribute computation to\ndistributed devices. Experimental results show that TorchOpt achieves\n$5.2\\times$ training time speedup on an 8-GPU server. TorchOpt is available at:\nhttps://github.com/metaopt/torchopt/.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.06934v1"
    },
    {
        "title": "Learned multiphysics inversion with differentiable programming and\n  machine learning",
        "authors": [
            "Mathias Louboutin",
            "Ziyi Yin",
            "Rafael Orozco",
            "Thomas J. Grady II",
            "Ali Siahkoohi",
            "Gabrio Rizzuti",
            "Philipp A. Witte",
            "Olav Møyner",
            "Gerard J. Gorman",
            "Felix J. Herrmann"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  We present the Seismic Laboratory for Imaging and Modeling/Monitoring (SLIM)\nopen-source software framework for computational geophysics and, more\ngenerally, inverse problems involving the wave-equation (e.g., seismic and\nmedical ultrasound), regularization with learned priors, and learned neural\nsurrogates for multiphase flow simulations. By integrating multiple layers of\nabstraction, our software is designed to be both readable and scalable. This\nallows researchers to easily formulate their problems in an abstract fashion\nwhile exploiting the latest developments in high-performance computing. We\nillustrate and demonstrate our design principles and their benefits by means of\nbuilding a scalable prototype for permeability inversion from time-lapse\ncrosswell seismic data, which aside from coupling of wave physics and\nmultiphase flow, involves machine learning.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.05592v1"
    },
    {
        "title": "Extrapolating Solution Paths of Polynomial Homotopies towards\n  Singularities with PHCpack and phcpy",
        "authors": [
            "Jan Verschelde",
            "Kylash Viswanathan"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  PHCpack is a software package for polynomial homotopy continuation, which\nprovides a robust path tracker [Telen, Van Barel, Verschelde, SISC 2020]. This\ntracker computes the radius of convergence of Newton's method, estimates the\ndistance to the nearest path, and then applies Pad\\'{e} approximants to predict\nthe next point on the path. A priori step size control is less sensitive to\nfinely tuned tolerances than a posteriori step size control, and is therefore\nrobust. The Python interface phcpy is extended with a new step-by-step tracker\nand is applied to experiment with extrapolation methods to accurately locate\nthe singular points at the end of solution paths.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.14844v2"
    },
    {
        "title": "MPPI-Generic: A CUDA Library for Stochastic Optimization",
        "authors": [
            "Bogdan Vlahov",
            "Jason Gibson",
            "Manan Gandhi",
            "Evangelos A. Theodorou"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This paper introduces a new C++/CUDA library for GPU-accelerated stochastic\noptimization called MPPI-Generic. It provides implementations of Model\nPredictive Path Integral control, Tube-Model Predictive Path Integral Control,\nand Robust Model Predictive Path Integral Control, and allows for these\nalgorithms to be used across many pre-existing dynamics models and cost\nfunctions. Furthermore, researchers can create their own dynamics models or\ncost functions following our API definitions without needing to change the\nactual Model Predictive Path Integral Control code. Finally, we compare\ncomputational performance to other popular implementations of Model Predictive\nPath Integral Control over a variety of GPUs to show the real-time capabilities\nour library can allow for. Library code can be found at:\nhttps://acdslab.github.io/mppi-generic-website/ .\n",
        "pdf_link": "http://arxiv.org/pdf/2409.07563v1"
    },
    {
        "title": "modOpt: A modular development environment and library for optimization\n  algorithms",
        "authors": [
            "Anugrah Jo Joshy",
            "John T. Hwang"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  Recent advances in computing hardware and modeling software have given rise\nto new applications for numerical optimization. These new applications\noccasionally uncover bottlenecks in existing optimization algorithms and\nnecessitate further specialization of the algorithms. However, such\nspecialization requires expert knowledge of the underlying mathematical theory\nand the software implementation of existing algorithms. To address this\nchallenge, we present modOpt, an open-source software framework that\nfacilitates the construction of optimization algorithms from modules. The\nmodular environment provided by modOpt enables developers to tailor an existing\nalgorithm for a new application by only altering the relevant modules. modOpt\nis designed as a platform to support students and beginner developers in\nquickly learning and developing their own algorithms. With that aim, the\nentirety of the framework is written in Python, and it is well-documented,\nwell-tested, and hosted open-source on GitHub. Several additional features are\nembedded into the framework to assist both beginner and advanced developers. In\naddition to providing stock modules, the framework also includes fully\ntransparent implementations of pedagogical optimization algorithms in Python.\nTo facilitate testing and benchmarking of new algorithms, the framework\nfeatures built-in visualization and recording capabilities, interfaces to\nmodeling frameworks such as OpenMDAO and CSDL, interfaces to general-purpose\noptimization algorithms such as SNOPT and SLSQP, an interface to the CUTEst\ntest problem set, etc. In this paper, we present the underlying software\narchitecture of modOpt, review its various features, discuss several\neducational and performance-oriented algorithms within modOpt, and present\nnumerical studies illustrating its unique benefits.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.12942v1"
    },
    {
        "title": "The Python LevelSet Toolbox (LevelSetPy)",
        "authors": [
            "Lekan Molu"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  This paper describes open-source scientific contributions in python\nsurrounding the numerical solutions to hyperbolic Hamilton-Jacobi (HJ) partial\ndifferential equations viz., their implicit representation on co-dimension one\nsurfaces; dynamics evolution with levelsets; spatial derivatives; total\nvariation diminishing Runge-Kutta integration schemes; and their applications\nto the theory of reachable sets. They are increasingly finding applications in\nmultiple research domains such as reinforcement learning, robotics, control\nengineering and automation. We describe the library components, illustrate\nusage with an example, and provide comparisons with existing implementations.\nThis GPU-accelerated package allows for easy portability to many modern\nlibraries for the numerical analyses of the HJ equations. We also provide a CPU\nimplementation in python that is significantly faster than existing\nalternatives.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.03501v1"
    },
    {
        "title": "Computing rank-revealing factorizations of matrices stored out-of-core",
        "authors": [
            "Nathan Heavner",
            "Per-Gunnar Martinsson",
            "Gregorio Quintana-Ortí"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  This paper describes efficient algorithms for computing rank-revealing\nfactorizations of matrices that are too large to fit in RAM, and must instead\nbe stored on slow external memory devices such as solid-state or spinning disk\nhard drives (out-of-core or out-of-memory). Traditional algorithms for\ncomputing rank revealing factorizations, such as the column pivoted QR\nfactorization, or techniques for computing a full singular value decomposition\nof a matrix, are very communication intensive. They are naturally expressed as\na sequence of matrix-vector operations, which become prohibitively expensive\nwhen data is not available in main memory. Randomization allows these methods\nto be reformulated so that large contiguous blocks of the matrix can be\nprocessed in bulk. The paper describes two distinct methods. The first is a\nblocked version of column pivoted Householder QR, organized as a \"left-looking\"\nmethod to minimize the number of write operations (which are more expensive\nthan read operations on a spinning disk drive). The second method results in a\nso called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where\n$U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an\nalgorithm-by-blocks, in which floating point operations overlap read and write\noperations. The second method incorporates power iterations, and is\nexceptionally good at revealing the numerical rank; it can often be used as a\nsubstitute for a full singular value decomposition. Numerical experiments\ndemonstrate that the new algorithms are almost as fast when processing data\nstored on a hard drive as traditional algorithms are for data stored in main\nmemory. To be precise, the computational time for fully factorizing an $n\\times\nn$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only\nmarginally larger when the matrix is stored out of core.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.06960v2"
    },
    {
        "title": "MORLAB -- The Model Order Reduction LABoratory",
        "authors": [
            "Peter Benner",
            "Steffen W. R. Werner"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  For an easy use of model order reduction techniques in applications, software\nsolutions are needed. In this paper, we describe the MORLAB, Model Order\nReduction LABoratory, toolbox as an efficient implementation of model reduction\ntechniques for dense, medium-scale linear time-invariant systems. Giving an\nintroduction to the underlying programming principles of the toolbox, we show\nthe basic idea of spectral splitting and present an overview about implemented\nmodel reduction techniques. Two numerical examples are used to illustrate\ndifferent use cases of the MORLAB toolbox.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.12682v1"
    },
    {
        "title": "Parallel Software to Offset the Cost of Higher Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  Hardware double precision is often insufficient to solve large scientific\nproblems accurately. Computing in higher precision defined by software causes\nsignificant computational overhead. The application of parallel algorithms\ncompensates for this overhead. Newton's method to develop power series\nexpansions of algebraic space curves is the use case for this application.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.06607v1"
    },
    {
        "title": "RationalizeRoots: Software Package for the Rationalization of Square\n  Roots",
        "authors": [
            "Marco Besier",
            "Pascal Wasser",
            "Stefan Weinzierl"
        ],
        "category": "cs.MS",
        "published_year": "2019",
        "summary": "  The computation of Feynman integrals often involves square roots. One way to\nobtain a solution in terms of multiple polylogarithms is to rationalize these\nsquare roots by a suitable variable change. We present a program that can be\nused to find such transformations. After an introduction to the theoretical\nbackground, we explain in detail how to use the program in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.13251v2"
    },
    {
        "title": "Parametric model order reduction using pyMOR",
        "authors": [
            "Petar Mlinarić",
            "Stephan Rave",
            "Jens Saak"
        ],
        "category": "cs.MS",
        "published_year": "2020",
        "summary": "  pyMOR is a free software library for model order reduction that includes both\nreduced basis and system-theoretic methods. All methods are implemented in\nterms of abstract vector and operator interfaces, which allows direct\nintegration of pyMOR's algorithms with a wide array of external PDE solvers. In\nthis contribution, we give a brief overview of the available methods and\nexperimentally compare them for the parametric instationary thermal-block\nbenchmark defined in arXiv:2003.00846.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.05825v2"
    },
    {
        "title": "Accelerated Polynomial Evaluation and Differentiation at Power Series in\n  Multiple Double Precision",
        "authors": [
            "Jan Verschelde"
        ],
        "category": "cs.MS",
        "published_year": "2021",
        "summary": "  The problem is to evaluate a polynomial in several variables and its gradient\nat a power series truncated to some finite degree with multiple double\nprecision arithmetic. To compensate for the cost overhead of multiple double\nprecision and power series arithmetic, data parallel algorithms for general\npurpose graphics processing units are presented. The reverse mode of\nalgorithmic differentiation is organized into a massively parallel computation\nof many convolutions and additions of truncated power series. Experimental\nresults demonstrate that teraflop performance is obtained in deca double\nprecision with power series truncated at degree 152. The algorithms scale well\nfor increasing precision and increasing degrees.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.10881v3"
    },
    {
        "title": "Exasim: Generating Discontinuous Galerkin Codes for Numerical Solutions\n  of Partial Differential Equations on Graphics Processors",
        "authors": [
            "Jordi Vila-Pérez",
            "R. Loek Van Heyningen",
            "Ngoc-Cuong Nguyen",
            "Jaume Peraire"
        ],
        "category": "cs.MS",
        "published_year": "2022",
        "summary": "  This paper presents an overview of the functionalities and applications of\nExasim, an open-source code for generating high-order discontinuous Galerkin\ncodes to numerically solve parametrized partial differential equations (PDEs).\nThe software combines high-level and low-level languages to construct\nparametrized PDE models via Julia, Python or Matlab scripts and produce\nhigh-performance C++ codes for solving the PDE models on CPU and Nvidia GPU\nprocessors with distributed memory. Exasim provides matrix-free discontinuous\nGalerkin discretization schemes together with scalable reduced basis\npreconditioners and Newton-GMRES solvers, making it suitable for accurate and\nefficient approximation of wide-ranging classes of PDEs.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.07824v1"
    },
    {
        "title": "$\\texttt{ChisholmD.wl}$- Automated rational approximant for bi-variate\n  series",
        "authors": [
            "Souvik Bera",
            "Tanay Pathak"
        ],
        "category": "cs.MS",
        "published_year": "2023",
        "summary": "  The Chisholm rational approximant is a natural generalization to two\nvariables of the well-known single variable Pad\\'e approximant, and has the\nadvantage of reducing to the latter when one of the variables is set equals to\n0. We present, to our knowledge, the first automated Mathematica package to\nevaluate diagonal Chisholm approximants of two variable series. For the moment,\nthe package can only be used to evaluate diagonal approximants i.e. the maximum\npowers of both the variables, in both the numerator and the denominator, is\nequal to some integer $M$. We further modify the original method so as to allow\nus to evaluate the approximants around some general point $(x,y)$ not\nnecessarily $(0,0)$. Using the approximants around general point $(x,y)$,\nallows us to get a better estimate of the result when the point of evaluation\nis far from $(0,0)$. Several examples of the elementary functions have been\nstudied which shows that the approximants can be useful for analytic\ncontinuation and convergence acceleration purposes. We continue our study using\nvarious examples of two variable hypergeometric series,\n$\\mathrm{Li}_{2,2}(x,y)$ etc that arise in particle physics and in the study of\ncritical phenomena in condensed matter physics. The demonstration of the\npackage is discussed in detail and the Mathematica package is provided as an\nancillary file.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.07687v1"
    },
    {
        "title": "An Open-Source Framework for Efficient Numerically-Tailored Computations",
        "authors": [
            "Louis Ledoux",
            "Marc Casas"
        ],
        "category": "cs.MS",
        "published_year": "2024",
        "summary": "  We present a versatile open-source framework designed to facilitate\nefficient, numerically-tailored Matrix-Matrix Multiplications (MMMs). The\nframework offers two primary contributions: first, a fine-tuned, automated\npipeline for arithmetic datapath generation, enabling highly customizable\nsystolic MMM kernels; second, seamless integration of the generated kernels\ninto user code, irrespective of the programming language employed, without\nnecessitating modifications.\n  The framework demonstrates a systematic enhancement in accuracy per energy\ncost across diverse High Performance Computing (HPC) workloads displaying a\nvariety of numerical requirements, such as Artificial Intelligence (AI)\ninference and Sea Surface Height (SSH) computation. For AI inference, we\nconsider a set of state-of-the-art neural network models, namely ResNet18,\nResNet34, ResNet50, DenseNet121, DenseNet161, DenseNet169, and VGG11, in\nconjunction with two datasets, two computer formats, and 27 distinct\nintermediate arithmetic datapaths. Our approach consistently reduces energy\nconsumption across all cases, with a notable example being the reduction by\nfactors of $3.3\\times$ for IEEE754-32 and $1.4\\times$ for Bfloat16 during\nImageNet inference with ResNet50. This is accomplished while maintaining\naccuracies of $82.3\\%$ and $86\\%$, comparable to those achieved with\nconventional Floating-Point Units (FPUs). In the context of SSH computation,\nour method achieves fully-reproducible results using double-precision words,\nsurpassing the accuracy of conventional double- and quad-precision arithmetic\nin FPUs. Our approach enhances SSH computation accuracy by a minimum of\n$5\\times$ and $27\\times$ compared to IEEE754-64 and IEEE754-128, respectively,\nresulting in $5.6\\times$ and $15.1\\times$ improvements in accuracy per power\ncost.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.02579v1"
    }
]