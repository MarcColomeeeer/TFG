[
    {
        "title": "Numeration systems on a regular language",
        "authors": [
            "Pierre B. A. Lecomte",
            "Michel Rigo"
        ],
        "category": "cs.OH",
        "published_year": "1999",
        "summary": "  Generalizations of linear numeration systems in which the set of natural\nnumbers is recognizable by finite automata are obtained by describing an\narbitrary infinite regular language following the lexicographic ordering. For\nthese systems of numeration, we show that ultimately periodic sets are\nrecognizable. We also study the translation and the multiplication by constants\nas well as the order dependence of the recognizability.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9903005v1"
    },
    {
        "title": "The Sources of Certainty in Computation and Formal Systems",
        "authors": [
            "Michael J. O'Donnell"
        ],
        "category": "cs.OH",
        "published_year": "1999",
        "summary": "  In his Discourse on the Method of Rightly Conducting the Reason, and Seeking\nTruth in the Sciences, Rene Descartes sought ``clear and certain knowledge of\nall that is useful in life.'' Almost three centuries later, in ``The\nfoundations of mathematics,'' David Hilbert tried to ``recast mathematical\ndefinitions and inferences in such a way that they are unshakable.'' Hilbert's\nprogram relied explicitly on formal systems (equivalently, computational\nsystems) to provide certainty in mathematics. The concepts of computation and\nformal system were not defined in his time, but Descartes' method may be\nunderstood as seeking certainty in essentially the same way.\n  In this article, I explain formal systems as concrete artifacts, and\ninvestigate the way in which they provide a high level of certainty---arguably\nthe highest level achievable by rational discourse. The rich understanding of\nformal systems achieved by mathematical logic and computer science in this\ncentury illuminates the nature of programs, such as Descartes' and Hilbert's,\nthat seek certainty through rigorous analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/9911010v1"
    },
    {
        "title": "Efficient generation of rotating workforce schedules",
        "authors": [
            "Nysret Musliu",
            "Johannes Gaertner",
            "Wolfgang Slany"
        ],
        "category": "cs.OH",
        "published_year": "2000",
        "summary": "  Generating high-quality schedules for a rotating workforce is a critical task\nin all settings where a certain staffing level must be guaranteed beyond the\ncapacity of single employees, such as for instance in industrial plants,\nhospitals, or airline companies. Results from ergonomics \\cite{BEST91} indicate\nthat rotating workforce schedules have a profound impact on the health and\nsocial life of employees as well as on their performance at work. Moreover,\nrotating workforce schedules must satisfy legal requirements and should also\nmeet the objectives of the employing organization. We describe our solution to\nthis problem. A basic design decision was to aim at quickly obtaining\nhigh-quality schedules for realistically sized problems while maintaining human\ncontrol. The interaction between the decision maker and the algorithm therefore\nconsists in four steps: (1) choosing a set of lengths of work blocks (a work\nblock is a sequence of consecutive days of work shifts), (2) choosing a\nparticular sequence of work and days-off blocks among those that have optimal\nweekend characteristics, (3) enumerating possible shift sequences for the\nchosen work blocks subject to shift change constraints and bounds on sequences\nof shifts, and (4) assignment of shift sequences to work blocks while\nfulfilling the staffing requirements. The combination of constraint\nsatisfaction and problem-oriented intelligent backtracking algorithms in each\nof the four steps allows to find good solutions for real-world problems in\nacceptable time. Computational results from real-world problems and from\nbenchmark examples found in the literature confirm the viability of our\napproach. The algorithms are now part of a commercial shift scheduling software\npackage.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0002018v2"
    },
    {
        "title": "On the theory of system administration",
        "authors": [
            "Mark Burgess"
        ],
        "category": "cs.OH",
        "published_year": "2000",
        "summary": "  This paper describes necessary elements for constructing theoretical models\nof network and system administration. Armed with a theoretical model it becomes\npossible to determine best practices and optimal strategies in a way which\nobjectively relates policies and assumptions to results obtained. It is\nconcluded that a mixture of automation and human, or other intelligent\nincursion is required to fully implement system policy with current technology.\nSome aspects of the author's immunity model for automated system administration\nare explained, as an example. A theoretical framework makes the prediction that\nthe optimal balance between resource availability and garbage collection\nstrategies is encompassed by the immunity model.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0003075v1"
    },
    {
        "title": "The Competitiveness of On-Line vis-a-vis Conventional Retailing: A\n  Preliminary Study",
        "authors": [
            "Ivan Png"
        ],
        "category": "cs.OH",
        "published_year": "2000",
        "summary": "  Previous research has directly studied whether on-line retailing is more\ncompetitive than conventional retail markets. The evidence from books and music\nCDs is mixed. Here, I use an indirect approach to compare the competitiveness\nof on-line with conventional markets. Focusing on the retail market for books,\nI identify a peculiarity in the pricing of bestsellers relative to other\ntitles. Supposing that competitive barriers are lower in on-line retailing, I\nanalyze how the lower barriers would affect the relative pricing of\nbestsellers. The empirical data indicates that on-line retailing is more\ncompetitive than conventional retailing.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0007034v1"
    },
    {
        "title": "A Virtual Java Simulation Lab for Computer Science Students",
        "authors": [
            "Javier Diaz",
            "Claudia Queiruga",
            "Villar Claudia",
            "Laura Fava"
        ],
        "category": "cs.OH",
        "published_year": "2000",
        "summary": "  The VJ-Lab is a project oriented to improve the students learning process of\nComputer Science degree at the National University of La Plata. The VJ-Lab is a\nWeb application with Java based simulations. Java can be used to provide\nsimulation environments with simple pictorial interfaces that can help students\nto understand the subject. There are many fields in which it is difficult to\ngive students a feel for the subject that they are learning. Computer based\nsimulations offer a fun and effective way to enable students to learn by doing.\nBoth, practicing skills and applying knowledge are both allowed in simulated\nworlds. We will focus on the VJ-Lab project overview, the work in progress and\nsome Java based simulations running. They imitate the behavior of data network\nprotocol and data structure algorithms. These applets are produced by the\nstudents of the 'Software Development Laboratory' course.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0012016v1"
    },
    {
        "title": "A polynomial axles-detection algorithm for a four-contacts treadle",
        "authors": [
            "Giancarlo Crocetti"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  This submission was removed because it contained proprietary information that\nwas distributed without permission.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0108012v1"
    },
    {
        "title": "How to Commission, Operate and Maintain a Large Future Accelerator\n  Complex from Far Remote",
        "authors": [
            "P. Czarapata",
            "D. Hartill",
            "S. Myers",
            "S. Peggs",
            "N. Phinney",
            "M. Serio",
            "N. Toge",
            "F. Willeke",
            "C. Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  A study on future large accelerators [1] has considered a facility, which is\ndesigned, built and operated by a worldwide collaboration of equal partner\ninstitutions, and which is remote from most of these institutions. The full\nrange of operation was considered including commi-ssioning, machine\ndevelopment, maintenance, trouble shooting and repair. Experience from existing\naccele-rators confirms that most of these activities are already performed\n'remotely'. The large high-energy physics ex-periments and astronomy projects,\nalready involve inter-national collaborations of distant institutions. Based on\nthis experience, the prospects for a machine operated remotely from far sites\nare encouraging. Experts from each laboratory would remain at their home\ninstitution but continue to participate in the operation of the machine after\nconstruction. Experts are required to be on site only during initial\ncommissioning and for par-ticularly difficult problems. Repairs require an\non-site non-expert maintenance crew. Most of the interventions can be made\nwithout an expert and many of the rest resolved with remote assistance. There\nappears to be no technical obstacle to controlling an accelerator from a\ndistance. The major challenge is to solve the complex management and\ncommunication problems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0110029v3"
    },
    {
        "title": "Overview of the Experimental Physics and Industrial Control System\n  (EPICS) Channel Archiver",
        "authors": [
            "K. U. Kasemir",
            "L. R. Dalesio"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  The Channel Archiver has been operational for more than two years at Los\nAlamos National Laboratory and other sites. This paper introduces the available\ncomponents (data sampling engine, viewers, scripting interface, HTTP/CGI\nintegration and data management), presents updated performance measurements and\nreviews operational experience with the Channel Archiver.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0110066v1"
    },
    {
        "title": "Integrating LabVIEW into a Distributed Computing Environment",
        "authors": [
            "K. U. Kasemir",
            "M. Pieck",
            "L. R. Dalesio"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  Being easy to learn and well suited for a self-contained desktop laboratory\nsetup, many casual programmers prefer to use the National Instruments LabVIEW\nenvironment to develop their logic. An ActiveX interface is presented that\nallows integration into a plant-wide distributed environment based on the\nExperimental Physics and Industrial Control System (EPICS). This paper\ndiscusses the design decisions and provides performance information, especially\nconsidering requirements for the Spallation Neutron Source (SNS) diagnostics\nsystem.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0111001v1"
    },
    {
        "title": "L-Fuzzy Valued Inclusion Measure, L-Fuzzy Similarity and L-Fuzzy\n  Distance",
        "authors": [
            "Ath. Kehagias",
            "M. Konstantinidou"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  The starting point of this paper is the introduction of a new measure of\ninclusion of fuzzy set A in fuzzy set B. Previously used inclusion measures\ntake values in the interval [0,1]; the inclusion measure proposed here takes\nvalues in a Boolean lattice. In other words, inclusion is viewed as an L-fuzzy\nvalued relation between fuzzy sets. This relation is re exive, antisymmetric\nand transitive, i.e. it is a fuzzy order relation; in addition it possesess a\nnumber of properties which various authors have postulated as axiomatically\nappropriate for an inclusion measure. We also define an L-fuzzy valued measure\nof similarity between fuzzy sets and and an L-fuzzy valued distance function\nbetween fuzzy sets; these possess properties analogous to the ones of\nreal-valued similarity and distance functions.\n  Keywords: Fuzzy Relations, inclusion measure, subsethood, L-fuzzy sets,\nsimilarity, distance, transitivity.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0111002v1"
    },
    {
        "title": "First Experiences Integrating PC Distributed I/O Into Argonne's ATLAS\n  Control System",
        "authors": [
            "F. H. Munson",
            "D. E. R. Quock",
            "S. L. Dean",
            "K. J. Eder"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  First Experiences Integrating PC Distributed I/O Into Argonne's ATLAS Control\nSystem The roots of ATLAS (Argonne Tandem-Linac Accelerator System) date back\nto the early 1960s. Located at the Argonne National Laboratory, the accelerator\nhas been designated a National User Facility, which focuses primarily on\nheavy-ion nuclear physics. Like the accelerator it services, the control system\nhas been in a constant state of evolution. The present real-time portion of the\ncontrol system is based on the commercial product Vsystem [1]. While Vsystem\nhas always been capable of distributed I/O processing, the latest offering of\nthis product provides for the use of relatively inexpensive PC hardware and\nsoftware. This paper reviews the status of the ATLAS control system, and\ndescribes first experiences with PC distributed I/O.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0111017v1"
    },
    {
        "title": "Gemini MCAO Control System",
        "authors": [
            "C. Boyer",
            "J. Sebag",
            "B. Ellerbroek"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  The Gemini Observatory is planning to implement a Multi Conjugate Adaptive\nOptics (MCAO) System as a facility instrument for the Gemini-South telescope.\nThe system will include 5 Laser Guide Stars, 3 Natural Guide Stars, and 3\nDeformable mirrors optically conjugated at different altitudes to achieve\nnear-uniform atmospheric compensation over a 1 arc minute square field of view.\nThe control of such a system will be split into 3 main functions: the control\nof the opto-mechanical assemblies of the whole system (including the Laser, the\nBeam Transfer Optics and the Adaptive Optics bench), the control of the\nAdaptive Optics System itself at a rate of 800FPS and the control of the safety\nsystem. The control of the Adaptive Optics System is the most critical in terms\nof real time performances. The control system will be an EPICS based system. In\nthis paper, we will describe the requirements for the whole MCAO control\nsystem, preliminary designs for the control of the opto-mechanical devices and\narchitecture options for the control of the Adaptive Optics system and the\nsafety system.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0111020v1"
    },
    {
        "title": "SNS Standard Power Supply Interface",
        "authors": [
            "S. Peng",
            "R. Lambiase",
            "B. Oerter",
            "J. Smith"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  The SNS has developed a standard power supply interface for the approximately\n350 magnet power supplies in the SNS accumulator ring, Linac and transport\nlines. Power supply manufacturers are providing supplies compatible with the\nstandard interface. The SNS standard consists of a VME based power supply\ncontroller module (PSC) and a power supply interface unit (PSI) that mounts on\nthe power supply. Communication between the two is via a pair of multimode\nfibers. This PSI/PSC system supports one 16-bit analog reference, four 16-bit\nanalog readbacks, fifteen digital commands and sixteen digital status bits in a\nsingle fiber-isolated module. The system can send commands to the supplies and\nread data from them synchronized to an external signal at up to a 10KHz rate.\nThe PSC time stamps and stores this data in a circular buffer so historical\ndata leading up to a fault event can be analyzed. The PSC contains a serial\nport so that local testing of hardware can be accomplished with a laptop. This\npaper concentrates on the software being provided to control the power supply.\nIt includes the EPICS driver; software to test hardware and power supplies via\nthe serial port and VME interface.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0111044v1"
    },
    {
        "title": "Overview of the NSTX Control System",
        "authors": [
            "P. Sichta",
            "J. Dong",
            "G. Oliaro",
            "P. Roney"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  The National Spherical Torus Experiment (NSTX) is an innovative magnetic\nfusion device that was constructed by the Princeton Plasma Physics Laboratory\n(PPPL) in collaboration with the Oak Ridge National Laboratory, Columbia\nUniversity, and the University of Washington at Seattle. Since achieving first\nplasma in 1999, the device has been used for fusion research through an\ninternational collaboration of over twenty institutions. The NSTX is operated\nthrough a collection of control systems that encompass a wide range of\ntechnology, from hardwired relay controls to real-time control systems with\ngiga-FLOPS of capability. This paper presents a broad introduction to the\ncontrol systems used on NSTX, with an emphasis on the computing controls, data\nacquisition, and synchronization systems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0111055v2"
    },
    {
        "title": "The Lattice of Fuzzy Intervals and Sufficient Conditions for its\n  Distributivity",
        "authors": [
            "Ath. Kehagias"
        ],
        "category": "cs.OH",
        "published_year": "2002",
        "summary": "  Given a reference lattice, we define fuzzy intervals to be the fuzzy sets\nsuch that their p-cuts are crisp closed intervals. We show that: given a\ncomplete reference lattice, the collection of its fuzzy intervals is a complete\nlattice. Furthermore we show that: if the reference lattice is completely\ndistributive then the lattice of its fuzzy intervals is distributive.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0206025v1"
    },
    {
        "title": "Evolutionary Circuit Design: Information Theory Perspective on Signal\n  Propagation",
        "authors": [
            "Denis V. Popel",
            "Nawar Al-Hakeem"
        ],
        "category": "cs.OH",
        "published_year": "2002",
        "summary": "  This paper presents case-study results on the application of information\ntheoretic approach to gate-level evolutionary circuit design. We introduce\ninformation measures to provide better estimates of synthesis criteria of\ndigital circuits. For example, the analysis of signal propagation during\nevolving gate-level synthesis can be improved by using information theoretic\nmeasures that will make it possible to find the most effective geometry and\ntherefore predict the cost of the final design solution. The problem is\nconsidered from the information engine point of view. That is, the process of\nevolutionary gate-level circuit design is presented via such measures as\nentropy, logical work and information vitality. Some examples of geometry\ndriven synthesis are provided to prove the above idea.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0207007v1"
    },
    {
        "title": "Information Measures in Detecting and Recognizing Symmetries",
        "authors": [
            "Denis V. Popel"
        ],
        "category": "cs.OH",
        "published_year": "2002",
        "summary": "  This paper presents a method to detect and recognize symmetries in Boolean\nfunctions. The idea is to use information theoretic measures of Boolean\nfunctions to detect sub-space of possible symmetric variables. Coupled with the\nnew techniques of efficient estimations of information measures on Binary\nDecision Diagrams (BDDs) we obtain promised results in symmetries detection for\nlarge-scale functions.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0207019v1"
    },
    {
        "title": "Towards Efficient Calculation of Information Measures for Reordering of\n  Binary Decision Diagrams",
        "authors": [
            "Denis V. Popel"
        ],
        "category": "cs.OH",
        "published_year": "2002",
        "summary": "  This paper introduces new technique for efficient calculation of different\nShannon information measures which operates Binary Decision Diagrams (BDDs). We\noffer an algorithm of BDD reordering which demonstrates the improvement of the\nobtaining outcomes over the existing reordering approaches. The technique and\nthe reordering algorithm have been implemented, and the results on circuits'\nbenchmarks are analyzed. We point out that the results are quite promising, the\nalgorithm is very fast, and it is easy to implement. Finally, we show that our\napproach to BDD reordering can yield to reduction in the power dissipation for\nthe circuits derived from BDDs.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0207020v1"
    },
    {
        "title": "A universal alphabet and rewrite system",
        "authors": [
            "Peter Rowlands",
            "Bernard Diaz"
        ],
        "category": "cs.OH",
        "published_year": "2002",
        "summary": "  We present two ways in which an infinite universal alphabet may be generated\nusing a novel rewrite system that conserves zero (a special character of the\nalphabet and the symbol for that character) at every step. The recursive method\ndelivers the entire alphabet in one step when invoked with the zero character\nas the initial subset alphabet. The iterative method with the same start\ndelivers characters that act as ciphers for properties that the developing\nsubset alphabet contains. These properties emerge in an arbitrary sequence and\nthere are an infinite number of ways they may be selected. The subset alphabets\nin addition to having mathematical interpretation as algebra can also be\nconstrained to emerge in a minimal way which then has application as a\nfoundational physical system. Each subset alphabet may itself be the basis of a\nrewrite system where rules that operate on symbols (representing characters) or\ncollections of symbols manipulate the specific properties in a dynamic way.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0209026v1"
    },
    {
        "title": "On probabilistic analog automata",
        "authors": [
            "A. Ben-Hur",
            "A. Roitershtein",
            "H. Siegelmann"
        ],
        "category": "cs.OH",
        "published_year": "2003",
        "summary": "  We consider probabilistic automata on a general state space and study their\ncomputational power. The model is based on the concept of language recognition\nby probabilistic automata due to Rabin and models of analog computation in a\nnoisy environment suggested by Maass and Orponen, and Maass and Sontag. Our\nmain result is a generalization of Rabin's reduction theorem that implies that\nunder very mild conditions, the computational power of the automaton is limited\nto regular languages.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0304042v2"
    },
    {
        "title": "Modeling of aerodynamic Space-to-Surface flight with optimal trajectory\n  for targeting",
        "authors": [
            "Serge Gornev"
        ],
        "category": "cs.OH",
        "published_year": "2003",
        "summary": "  Modeling has been created for a Space-to-Surface system defined for an\noptimal trajectory for targeting in terminal phase. The modeling includes\nmodels for simulation atmosphere, speed of sound, aerodynamic flight and\nnavigation by an infrared system. The modeling simulation includes statistical\nanalysis of the modeling results.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0305043v1"
    },
    {
        "title": "CASTOR status and evolution",
        "authors": [
            "Jean-Philippe Baud",
            "Ben Couturier",
            "Charles Curran",
            "Jean-Damien Durand",
            "Emil Knezo",
            "Stefano Occhetti",
            "Olof Barring"
        ],
        "category": "cs.OH",
        "published_year": "2003",
        "summary": "  In January 1999, CERN began to develop CASTOR (\"CERN Advanced STORage\nmanager\"). This Hierarchical Storage Manager targetted at HEP applications has\nbeen in full production at CERN since May 2001. It now contains more than two\nPetabyte of data in roughly 9 million files. In 2002, 350 Terabytes of data\nwere stored for COMPASS at 45 MB/s and a Data Challenge was run for ALICE in\npreparation for the LHC startup in 2007 and sustained a data transfer to tape\nof 300 MB/s for one week (180 TB). The major functionality improvements were\nthe support for files larger than 2 GB (in collaboration with IN2P3) and the\ndevelopment of Grid interfaces to CASTOR: GridFTP and SRM (\"Storage Resource\nManager\"). An ongoing effort is taking place to copy the existing data from\nobsolete media like 9940 A to better cost effective offerings. CASTOR has also\nbeen deployed at several HEP sites with little effort. In 2003, we plan to\ncontinue working on Grid interfaces and to improve performance not only for\nCentral Data Recording but also for Data Analysis applications where thousands\nof processes possibly access the same hot data. This could imply the selection\nof another filesystem or the use of replication (hardware or software).\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0305047v1"
    },
    {
        "title": "SCRAM: Software configuration and management for the LHC Computing Grid\n  project",
        "authors": [
            "J. P. Wellisch",
            "C. Williams",
            "S. Ashby"
        ],
        "category": "cs.OH",
        "published_year": "2003",
        "summary": "  Recently SCRAM (Software Configuration And Management) has been adopted by\nthe applications area of the LHC computing grid project as baseline\nconfiguration management and build support infrastructure tool.\n  SCRAM is a software engineering tool, that supports the configuration\nmanagement and management processes for software development. It resolves the\nissues of configuration definition, assembly break-down, build, project\norganization, run-time environment, installation, distribution, deployment, and\nsource code distribution. It was designed with a focus on supporting a\ndistributed, multi-project development work-model.\n  We will describe the underlying technology, and the solutions SCRAM offers to\nthe above software engineering processes, while taking a users view of the\nsystem under configuration management.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0306014v1"
    },
    {
        "title": "Monitoring Systems and Services",
        "authors": [
            "Alwin Brokmann"
        ],
        "category": "cs.OH",
        "published_year": "2003",
        "summary": "  The DESY Computer Center is the home of O(1000) computers supplying a wide\nrange of different services Monitoring such a large installation is a\nchallenge. After a long time running a SNMP based commercial Network Management\nSystem, the evaluation of a new System was started. There are a lot of\ndifferent commercial and freeware products on the market, but none of them\nfully satisfied all our requirements. After re-valuating our original\nrequirements we selected NAGIOS as our monitoring and alarming tool. After a\nsuccessful test we are in production since autumn 2002 and are extending the\nservice to fully support a distributed monitoring and alarming.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0306024v1"
    },
    {
        "title": "Multi-valued Connectives for Fuzzy Sets",
        "authors": [
            "Ath. Kehagias",
            "K. Serafimidis"
        ],
        "category": "cs.OH",
        "published_year": "2003",
        "summary": "  We present a procedure for the construction of multi-valued t-norms and\nt-conorms. Our procedure makes use of a pair of single-valued t-norms and the\nrespective dual t-conorms and produces interval-valued t-norms and t-conorms.\nIn this manner we combine desirable characteristics of different t-norms and\nt-conorms; if we use the t-norm min and t-conorm max, then the resulting\nstructure is a superlattice, i.e. the multivalued analog of a lattice.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0306033v1"
    },
    {
        "title": "Verification of Process Rewrite Systems in normal form",
        "authors": [
            "Laura Bozzelli"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  We consider the problem of model--checking for Process Rewrite Systems (PRSs)\nin normal form. In a PRS in normal form every rewrite rule either only deals\nwith procedure calls and procedure termination, possibly with value return,\n(this kind of rules allows to capture Pushdown Processes), or only deals with\ndynamic activation of processes and synchronization (this kind of rules allows\nto capture Petri Nets). The model-checking problem for PRSs and action-based\nlinear temporal logic (ALTL) is undecidable. However, decidability of\nmodel--checking for PRSs and some interesting fragment of ALTL remains an open\nquestion. In this paper we state decidability results concerning generalized\nacceptance properties about infinite derivations (infinite term rewritings) in\nPRSs in normal form. As a consequence, we obtain decidability of the\nmodel-checking (restricted to infinite runs) for PRSs in normal form and a\nmeaningful fragment of ALTL.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0401013v1"
    },
    {
        "title": "New Visualization of Surfaces in Parallel Coordinates - Eliminating\n  Ambiguity and Some \"Over-Plotting\"",
        "authors": [
            "Zur Izhakian"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  $\\cal{A}$ point $P \\in \\Real^n$ is represented in Parallel Coordinates by a\npolygonal line $\\bar{P}$ (see \\cite{Insel99a} for a recent survey). Earlier\n\\cite{inselberg85plane}, a surface $\\sigma$ was represented as the {\\em\nenvelope} of the polygonal lines representing it's points. This is ambiguous in\nthe sense that {\\em different} surfaces can provide the {\\em same} envelopes.\nHere the ambiguity is eliminated by considering the surface $\\sigma$ as the\nenvelope of it's {\\em tangent planes} and in turn, representing each of these\nplanes by $n$-1 points \\cite{Insel99a}. This, with some future extension, can\nyield a new and unambiguous representation, $\\bar{\\sigma}$, of the surface\nconsisting of $n$-1 planar regions whose properties correspond lead to the {\\em\nrecognition} of the surfaces' properties i.e. developable, ruled etc.\n\\cite{hung92smooth}) and {\\em classification} criteria.\n  It is further shown that the image (i.e. representation) of an algebraic\nsurface of degree 2 in $\\Real^n$ is a region whose boundary is also an\nalgebraic curve of degree 2. This includes some {\\em non-convex} surfaces which\nwith the previous ambiguous representation could not be treated. An efficient\nconstruction algorithm for the representation of the quadratic surfaces (given\neither by {\\em explicit} or {\\em implicit} equation) is provided. The results\nobtained are suitable for applications, to be presented in a future paper, and\nin particular for the approximation of complex surfaces based on their {\\em\nplanar} images. An additional benefit is the elimination of the\n``over-plotting'' problem i.e. the ``bunching'' of polygonal lines which often\nobscure part of the parallel-coordinate display.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0403004v1"
    },
    {
        "title": "Algebraic Curves in Parallel Coordinates - Avoiding the \"Over-Plotting\"\n  Problem",
        "authors": [
            "Zur Izhakian"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  ${\\cal U}$ntil now the representation (i.e. plotting) of curve in Parallel\nCoordinates is constructed from the point $\\leftrightarrow$ line duality. The\nresult is a ``line-curve'' which is seen as the envelope of it's tangents.\nUsually this gives an unclear image and is at the heart of the\n``over-plotting'' problem; a barrier in the effective use of Parallel\nCoordinates. This problem is overcome by a transformation which provides\ndirectly the ``point-curve'' representation of a curve. Earlier this was\napplied to conics and their generalizations. Here the representation, also\ncalled dual, is extended to all planar algebraic curves. Specifically, it is\nshown that the dual of an algebraic curve of degree $n$ is an algebraic of\ndegree at most $n(n - 1)$ in the absence of singular points. The result that\nconics map into conics follows as an easy special case. An algorithm, based on\nalgebraic geometry using resultants and homogeneous polynomials, is obtained\nwhich constructs the dual image of the curve. This approach has potential\ngeneralizations to multi-dimensional algebraic surfaces and their\napproximation. The ``trade-off'' price then for obtaining {\\em planar}\nrepresentation of multidimensional algebraic curves and hyper-surfaces is the\nhigher degree of the image's boundary which is also an algebraic curve in\n$\\|$-coords.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0403005v1"
    },
    {
        "title": "What we should teach, but don't: Proposal for a cross pollinated HCI-SE\n  curriculum",
        "authors": [
            "Pardha S. Pyla",
            "Manuel A. Perez-Quinones",
            "James D. Arthur",
            "H. Rex Hartson"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  Software engineering (SE) and usability engineering (UE), as disciplines,\nhave reached substantial levels of maturity. Each of these two disciplines is\nnow well represented with respect to most computer science (CS) curricula. But,\nthe two disciplines are practiced almost independently - missing oppurtunities\nto collaborate, coordinate and communicate about the overall design - and\nthereby contributing to system failures. Today, a confluence of several\ningredients contribute to these failures: the increasing importance of the user\ninterface (UI) component in the overall system, the independent maturation of\nthe human computer interaction area, and the lack of a cohesive process model\nto integrate the UI experts' UE development efforts with that of SE. This in\nturn, we believe, is a result of a void in computing curricula: a lack of\neducation and training regarding the importance of communication, collaboration\nand coordination between the SE and UE processes. In this paper we describe the\ncurrent approach to teaching SE and UE and its shortcomings. We identify and\nanalyze the barriers and issues involved in developing systems having\nsubstantial interactive components. We then propose four major themes of\nlearning for a comprehensive computing curriculum integrating SE, UE, and\nsystem architectures in a project environment.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0403026v1"
    },
    {
        "title": "Model checking for Process Rewrite Systems and a class of action--based\n  regular properties",
        "authors": [
            "Laura Bozzelli"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  We consider the model checking problem for Process Rewrite Systems (PRSs), an\ninfinite-state formalism (non Turing-powerful) which subsumes many common\nmodels such as Pushdown Processes and Petri Nets. PRSs can be adopted as formal\nmodels for programs with dynamic creation and synchronization of concurrent\nprocesses, and with recursive procedures. The model-checking problem for PRSs\nand action-based linear temporal logic (ALTL) is undecidable. However,\ndecidability for some interesting fragment of ALTL remains an open question. In\nthis paper we state decidability results concerning generalized acceptance\nproperties about infinite derivations (infinite term rewriting) in PRSs. As a\nconsequence, we obtain decidability of the model-checking (restricted to\ninfinite runs) for PRSs and a meaningful fragment of ALTL.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0405003v1"
    },
    {
        "title": "Effects of wireless computing technology",
        "authors": [
            "A. A. Eremin"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  Wireless technology can provide many benefits to computing including faster\nresponse to queries, reduced time spent on paperwork, increased online time for\nusers, just-in-time and real time control, tighter communications between\nclients and hosts. Wireless Computing is governed by two general forces:\nTechnology, which provides a set of basic building blocks and User\nApplications, which determine a set of operations that must be carried out\nefficiently on demand. This paper summarizes technological changes that are\nunderway and describes their impact on wireless computing development and\nimplementation. It also describes the applications that influence the\ndevelopment and implementation of wireless computing and shows what current\nsystems offer.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0406018v1"
    },
    {
        "title": "Scheduling with Fuzzy Methods",
        "authors": [
            "Wolfgang Anthony Eiden"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  Nowadays, manufacturing industries -- driven by fierce competition and rising\ncustomer requirements -- are forced to produce a broader range of individual\nproducts of rising quality at the same (or preferably lower) cost. Meeting\nthese demands implies an even more complex production process and thus also an\nappropriately increasing request to its scheduling. Aggravatingly, vagueness of\nscheduling parameters -- such as times and conditions -- are often inherent in\nthe production process. In addition, the search for an optimal schedule\nnormally leads to very difficult problems (NP-hard problems in the complexity\ntheoretical sense), which cannot be solved effciently. With the intent to\nminimize these problems, the introduced heuristic method combines standard\nscheduling methods with fuzzy methods to get a nearly optimal schedule within\nan appropriate time considering vagueness adequately.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0407030v1"
    },
    {
        "title": "Business Processes: The Theoretical Impact of Process Thinking on\n  Information Systems Development",
        "authors": [
            "Mark Dumay"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  This paper investigates two aspects of process thinking that affect the\nsuccess rate of IT projects. These two aspects are the changes in the structure\nof organizations and the epistemology of Information Systems Development.\nFirstly, the conception of business processes within the management of\norganizations increases the structural complexity of Information Systems,\nbecause existing systems have to be integrated into a coherent cross-functional\narchitecture. Secondly, process thinking leads to a particular view of\norganizations that ultimately has a negative effect on the support of\nInformation Systems. As an illustration of process thinking, the Business\nProcess Reengineering movement adheres to a technocratic management perspective\nof organizations. Particularly this conception of organization views people as\nmechanisms to realize certain organizational goals. As a result of this view\nstakeholders are confronted with the implemented systems, rather than consulted\nabout the scope and functionality of those systems. Therefore, both aspects of\nprocess thinking have a negative impact on the success of IT projects. The\nproblem of structural complexity is an area that is addressed by Enterprise\nApplication Integration, and mainly requires technical solutions. However, the\nproblems associated with the conception of organization require a different,\nmarkedly non-technical, perspective. Several directions are discussed to\novercome some limitations of process thinking, but these directions are merely\nsmall pointers. If truly effective and useful Information Systems are to be\nacquired, IT practitioners and scientists require a completely different\nmindset.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0409037v1"
    },
    {
        "title": "Demo or Practice: Critical Analysis of the Language/Action Perspective",
        "authors": [
            "Mark Dumay"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  Despite offering several promising concepts, the Language/Action Perspective\n(LAP) is still not in the mainstream of Information Systems Development (ISD).\nSince at present there is only a limited understanding of LAP theory and\npractice, it remains unclear whether the lack of LAP's impact is due to\nshortcomings in LAP theory itself. One classic problem within ISD is the\ndichotomy between social perspectives and technical perspectives. LAP claims it\noffers a solution to this problem. This paper investigates this claim as a\nmeans to review LAP theory. To provide a structure to a critical analysis of\nDEMO - an example methodology that belongs to the LAP research community - this\npaper utilizes a paradigmatic framework. This framework is augmented by the\nopinion of several DEMO practitioners by means of an expert discussion. With\nuse of a comparative evaluation of LAP theory and DEMO theory, the implication\nof DEMO's reflection upon LAP is determined. The paper concludes by outlining\nan agenda for further research if LAP is to improve its footprint in the field.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0410006v1"
    },
    {
        "title": "Toward a Human-Centered Uml for Risk Analysis",
        "authors": [
            "Jeremie Guiochet",
            "Gilles Motet",
            "Claude Baron",
            "Guy Boy"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  Safety is now a major concern in many complex systems such as medical robots.\nA way to control the complexity of such systems is to manage risk. The first\nand important step of this activity is risk analysis. During risk analysis, two\nmain studies concerning human factors must be integrated: task analysis and\nhuman error analysis. This multidisciplinary analysis often leads to a work\nsharing between several stakeholders who use their own languages and\ntechniques. This often produces consistency errors and understanding\ndifficulties between them. Hence, this paper proposes to treat the risk\nanalysis on the common expression language UML (Unified Modeling Language) and\nto handle human factors concepts for task analysis and human error analysis\nbased on the features of this language. The approach is applied to the\ndevelopment of a medical robot for teleechography.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0412010v1"
    },
    {
        "title": "Successful E-Business Systems - Paypal",
        "authors": [
            "Archil Avaliani"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  PayPal is an account-based system that allows anyone with an email address to\nsend and receive online payment s. This service is easy to use for customers.\nMembers can instantaneously send money to anyone. Recipients are informed by\nemail that they have received a payment. PayPal is also available to people in\n38 countries. This paper starts with introduction to the company and its\nservices. The information about the history and the current company situation\nare covered. Later some interesting and different technical issues are\ndiscussed. The Paper ends with analysis of the company and several future\nrecommendations.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0412011v1"
    },
    {
        "title": "High efficiency and low absorption Fresnel compound zone plates for hard\n  X-ray focusing",
        "authors": [
            "A. Kuyumchyan",
            "A. Isoyan",
            "E. Shulakov",
            "V. Aristov",
            "M. Kondratenkov",
            "A. Snigirev",
            "I. Snigireva",
            "A. Souvorov",
            "K. Tamasaku",
            "M. Yabashi",
            "T. Ishikawa",
            "K. Trouni"
        ],
        "category": "cs.OH",
        "published_year": "2005",
        "summary": "  Circular and linear zone plates have been fabricated on the surface of\nsilicon crystals for the energy of 8 keV by electron beam lithography and deep\nion plasma etching methods. Various variants of compound zone plates with\nfirst, second, third diffraction orders have been made. The zone relief height\nis about 10 mkm, the outermost zone width of the zone plate is 0.4 mkm. The\nexperimental testing of the zone plates has been conducted on SPring-8 and ESRF\nsynchrotron radiation sources. A focused spot size and diffraction efficiency\nmeasured by knife-edge scanning are accordingly 0.5 mkm and 39% for the first\norder circular zone plate.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0503005v2"
    },
    {
        "title": "A Fast Combined Decimal Adder/Subtractor",
        "authors": [
            "Hooman Nikmehr",
            "Braden Phillips",
            "Cheng-Chew Lim"
        ],
        "category": "cs.OH",
        "published_year": "2005",
        "summary": "  This paper has been withdrawn.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0503017v2"
    },
    {
        "title": "Improved direct sum theorem in classical communication complexity",
        "authors": [
            "Rahul Jain"
        ],
        "category": "cs.OH",
        "published_year": "2005",
        "summary": "  Withdrawn due to critical error.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0504087v3"
    },
    {
        "title": "Asynchronous pseudo-systems",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2005",
        "summary": "  The paper introduces the concept of asynchronous pseudo-system. Its purpose\nis to correct/generalize/continue the study of the asynchronous systems (the\nmodels of the asynchronous circuits) that has been started in [1], [2].\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0505040v1"
    },
    {
        "title": "f2mma: FORTRAN to Mathematica translator",
        "authors": [
            "A. S. Siver"
        ],
        "category": "cs.OH",
        "published_year": "2005",
        "summary": "  f2mma program can be used to translate programs written in some subset of the\nFORTRAN language into {\\sl Mathematica} system's programming language. This\nsubset have been enough to translate GAPP (Global Analysis of Particle\nProperties) programm into {\\sl Mathematica} language automatically. Observables\ntable calculated with GAPP({\\sl Mathematica}) is presented.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0507054v4"
    },
    {
        "title": "Mapping DEVS Models onto UML Models",
        "authors": [
            "Dmitry Zinoviev"
        ],
        "category": "cs.OH",
        "published_year": "2005",
        "summary": "  Discrete event simulation specification (DEVS) is a formalism designed to\ndescribe both discrete state and continuous state systems. It is a powerful\nabstract mathematical notation. However, until recently it lacked proper\ngraphical representation, which made computer simulation of DEVS models a\nchallenging issue. Unified modeling language (UML) is a multipurpose graphical\nmodeling language, a de-facto industrial modeling standard. There exist several\ncommercial and open-source UML editors and code generators. Most of them can\nsave UML models in XML-based XMI files ready for further automated processing.\nIn this paper, we propose a mapping of DEVS models onto UML state and component\ndiagrams. This mapping may lead to an eventual unification of the two modeling\nformalisms, combining the abstractness of DEVS and expressive power and\n``computer friendliness'' of the UML.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0508128v1"
    },
    {
        "title": "Fat Tailed Distributions in Catastrophe Prediction",
        "authors": [
            "Louis Mello"
        ],
        "category": "cs.OH",
        "published_year": "2005",
        "summary": "  This paper discusses the use of fat-tailed distributions in catastrophe\nprediction as opposed to the more common use of the Normal Distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0512022v1"
    },
    {
        "title": "The Fibonacci Sequence Mod m",
        "authors": [
            "Louis Mello"
        ],
        "category": "cs.OH",
        "published_year": "2005",
        "summary": "  This paper proposes a computational method for obtaining the length of the\ncycle that arises from the Fibonacci series taken mod m (some number) and mod p\n(some prime number).\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0512103v1"
    },
    {
        "title": "Efficient Teamwork",
        "authors": [
            "Endre Cska"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  Our goal is to solve both problems of adverse selection and moral hazard for\nmulti-agent projects. In our model, each selected agent can work according to\nhis private \"capability tree\". This means a process involving hidden actions,\nhidden chance events and hidden costs in a dynamic manner, and providing\ncontractible consequences which are affecting each other's working process and\nthe outcome of the project. We will construct a mechanism that induces truthful\nrevelation of the agents' capability trees and chance events and to follow the\ninstructions about their hidden decisions. This enables the planner to select\nthe optimal subset of agents and obtain the efficient joint execution. We will\nconstruct another mechanism that is collusion-resistant but implements an only\napproximately efficient outcome. The latter mechanism is widely applicable, and\nthe major application details will be elaborated.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0602009v103"
    },
    {
        "title": "Quasi-Linear Soft Tissue Models Revisited",
        "authors": [
            "J. S. Espinoza Ortiz",
            "Gilson A. Giraldi",
            "E. A. de Souza Neto",
            "Raul A. Feijo"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  Incompressibility, nonlinear deformation under stress and viscoelasticity are\nthe fingerprint of soft tissue mechanical behavior. In order to model soft\ntissues appropriately, we must pursue to complete these requirements. In this\nwork we revisited different soft tissue quasi-linear model possibilities in\ntrying to achieve for this commitment.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0602017v1"
    },
    {
        "title": "Natural Economics",
        "authors": [
            "Louis Mello"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  A few considerations on the nature of Economics and its relationship to human\ncommunities through the prism of Self-Organizing-Systems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0602066v1"
    },
    {
        "title": "A unifying framework for seed sensitivity and its application to subset\n  seeds (Extended abstract)",
        "authors": [
            "Gregory Kucherov",
            "Laurent Noe",
            "Mikhail Roytberg"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  We propose a general approach to compute the seed sensitivity, that can be\napplied to different definitions of seeds. It treats separately three\ncomponents of the seed sensitivity problem - a set of target alignments, an\nassociated probability distribution, and a seed model - that are specified by\ndistinct finite automata. The approach is then applied to a new concept of\nsubset seeds for which we propose an efficient automaton construction.\nExperimental results confirm that sensitive subset seeds can be efficiently\ndesigned using our approach, and can then be used in similarity search\nproducing better results than ordinary spaced seeds.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603105v1"
    },
    {
        "title": "Estimating seed sensitivity on homogeneous alignments",
        "authors": [
            "Gregory Kucherov",
            "Laurent Noe",
            "Yann Ponty"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  We address the problem of estimating the sensitivity of seed-based similarity\nsearch algorithms. In contrast to approaches based on Markov models [18, 6, 3,\n4, 10], we study the estimation based on homogeneous alignments. We describe an\nalgorithm for counting and random generation of those alignments and an\nalgorithm for exact computation of the sensitivity for a broad class of seed\nstrategies. We provide experimental results demonstrating a bias introduced by\nignoring the homogeneousness condition.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603106v1"
    },
    {
        "title": "Mathematical Modeling of Aerodynamic Space -to - Surface Flight with\n  Trajectory for Avoid Intercepting Process",
        "authors": [
            "Serge Gornev"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  Modeling has been created for a Space-to-Surface system defined for an\noptimal trajectory for targeting in terminal phase with avoids an intercepting\nprocess. The modeling includes models for simulation atmosphere, speed of\nsound, aerodynamic flight and navigation by an infrared system. The modeling\nand simulation includes statistical analysis of the modeling results.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0603113v1"
    },
    {
        "title": "Computational Modeling in Applied Problems: collected papers on\n  econometrics, operations research, game theory and simulation",
        "authors": [
            "Florentin Smarandache",
            "Sukanto Bhattacharya",
            "Mohammad Khoshnevisan",
            "Housila P. Singh",
            "Rajesh Singh",
            "F. Kaymram",
            "S. Malakar",
            "Jose L. Salmeron"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  Computational models pervade all branches of the exact sciences and have in\nrecent times also started to prove to be of immense utility in some of the\ntraditionally 'soft' sciences like ecology, sociology and politics. This volume\nis a collection of a few cutting-edge research papers on the application of\nvariety of computational models and tools in the analysis, interpretation and\nsolution of vexing real-world problems and issues in economics, management,\necology and global politics by some prolific researchers in the field.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605018v1"
    },
    {
        "title": "An Electronic Payment System to Ensure Cost Effectiveness with Easy\n  Security Incorporation for the Developing Countries",
        "authors": [
            "Asif Ahmed Anik",
            "Al-Mukaddim Khan Pathan"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  With the rapid growth of Information and Communication Technology, Electronic\ncommerce is now acting as a new means of carrying out business transactions\nthrough electronic means such as Internet environment. To avoid the\ncomplexities associated with the digital cash and electronic cash, consumers\nand vendors are looking for credit card payments on the Internet as one\npossible time-tested alternative. This gave rise of the on-line payment\nprocessing using a third-party verification; which is not suitable for the\ndeveloping countries in most of the cases because of the excessive costs\nassociated with it for maintenance and establishment of an online third-party\nprocessor. As a remedy of this problem, in this paper, we have proposed a\nframework for easy security incorporation in credit card based electronic\npayment system without the use of an on-line third- party processor; which\ntends to be low cost and effective for the developing countries.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0605063v1"
    },
    {
        "title": "Authorised Translations of Electronic Documents",
        "authors": [
            "Jan Piechalski",
            "Andreas U. Schmidt"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  A concept is proposed to extend authorised translations of documents to\nelectronically signed, digital documents. Central element of the solution is an\nelectronic seal, embodied as an XML data structure, which attests to the\ncorrectness of the translation and the authorisation of the translator. The\nseal contains a digital signature binding together original and translated\ndocument, thus enabling forensic inspection and therefore legal security in the\nappropriation of the translation. Organisational aspects of possible\nimplementation variants of electronic authorised translations are discussed and\na realisation as a stand-alone web-service is presented.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0606046v1"
    },
    {
        "title": "Models simulation and interoperability using MDA and HLA",
        "authors": [
            "Hind El Haouzi"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  In the manufacturing context, there have been numerous efforts to use\nmodeling and simulation tools and techniques to improve manufacturing\nefficiency over the last four decades. While an increasing number of\nmanufacturing system decisions are being made based on the use of models, their\nuse is still sporadic in many manufacturing environments. Our paper advocates\nfor an approach combining MDA (model driven architecture) and HLA (High Level\nArchitecture), the IEEE standard for modeling and simulation, in order to\novercome the deficiencies of current simulation methods at the level of\ninteroperability and reuse.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0606111v1"
    },
    {
        "title": "Levels of Product Differentiation in the Global Mobile Phones Market",
        "authors": [
            "Stanimir Andonov"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  The sixth product level called compliant product is a connecting element\nbetween the physical product characteristics and the strategy of the producer\ncompany. The article discusses the differentiation among the product offers of\ncompanies working in the global markets, as well as the strategies which they\nuse and could use in that respect.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0607144v1"
    },
    {
        "title": "Exploring Computer Science Concepts with a Ready-made Computer Game\n  Framework",
        "authors": [
            "Joseph Distasio",
            "Thomas P. Way"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  Leveraging the prevailing interest in computer games among college students,\nboth for entertainment and as a possible career path, is a major reason for the\nincreasing prevalence of computer game design courses in computer science\ncurricula. Because implementing a computer game requires strong programming\nskills, game design courses are most often restricted to more advanced computer\nscience students. This paper reports on a ready-made game design and\nexperimentation framework, implemented in Java, that makes game programming\nmore widely accessible. This framework, called Labyrinth, enables students at\nall programming skill levels to participate in computer game design. We\ndescribe the architecture of the framework, and discuss programming projects\nsuitable for a wide variety of computer science courses, from capstone to\nnon-major.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0609070v2"
    },
    {
        "title": "Domain Wall Displacement Detection Technology Research Report",
        "authors": [
            "Ran Ren"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  This article introduce a new data storage method called DWDD(Domain Wall\nDisplacement Detection) and tell you why it succeed.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0610005v1"
    },
    {
        "title": "Developing strategies to produce better scientific papers: a Recipe for\n  non-native users of English",
        "authors": [
            "Osvaldo N. Oliveira Jr.",
            "Valtencir Zucolotto",
            "Sandra M. Aluisio"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  In this paper we introduce the AMADEUS strategy, which has been used to\nproduce scientific writing tools for non-native users of English for 15 years,\nand emphasize a learn-by-doing approach through which students and novice\nwriters can improve their scientific writing. More specifically, we provide a\n9-step recipe for the students to compile writing material according to a\nprocedure that has proven efficient in scientific writing courses.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0611013v1"
    },
    {
        "title": "Relatively inertial delays",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  The paper studies the relatively inertial delays that represent one of the\nmost important concepts in the modeling of the asynchronous circuits.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0611021v1"
    },
    {
        "title": "Safety Evaluation of Critical Applications Distributed on TDMA-Based\n  Networks",
        "authors": [
            "Franoise Simonot-Lion",
            "Franois Simonot",
            "Ye-Qiong Song"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  Critical embedded systems have to provide a high level of dependability. In\nautomotive domain, for example, TDMA protocols are largely recommended because\nof their deterministic behavior. Nevertheless, under the transient\nenvironmental perturbations, the loss of communication cycles may occur with a\ncertain probability and, consequently, the system may fail. This paper analyzes\nthe impact of the transient perturbations (especially due to Electromagnetic\nInterferences) on the dependability of systems distributed on TDMA-based\nnetworks. The dependability of such system is modeled as that of\n\"consecutive-k-out-of-n:F\" systems and we provide a efficient way for its\nevaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0611078v1"
    },
    {
        "title": "Analysing viewpoints in design through the argumentation process",
        "authors": [
            "Graldine Martin",
            "Franoise Dtienne",
            "Elisabeth Lavigne"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  We present an empirical study aimed at analysing the use of viewpoints in an\nindustrial Concurrent Engineering context. Our focus is on the viewpoints\nexpressed in the argumentative process taking place in evaluation meetings. Our\nresults show that arguments enabling a viewpoint or proposal to be defended are\noften characterized by the use of constraints. Firstly, we show that, even if\nsome constraints are apparently identically used by the different specialists\ninvolved in meetings, various meanings and weightings are associated with these\nconstraints by these different specialists. Secondly, we show that the implicit\nor explicit nature of constraints depends on several interlocutive factors.\nThirdly, we show that an argument often covers not only one constraint but a\nnetwork of constraints. The type of combination reflects viewpoints which have\nspecific status in the meeting. Then, we will propose a first model of the\ndynamics of viewpoints confrontation/integration.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0612020v1"
    },
    {
        "title": "Verification Across Intellectual Property Boundaries",
        "authors": [
            "Sagar Chaki",
            "Christian Schallhart",
            "Helmut Veith"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In many industries, the importance of software components provided by\nthird-party suppliers is steadily increasing. As the suppliers seek to secure\ntheir intellectual property (IP) rights, the customer usually has no direct\naccess to the suppliers' source code, and is able to enforce the use of\nverification tools only by legal requirements. In turn, the supplier has no\nmeans to convince the customer about successful verification without revealing\nthe source code. This paper presents an approach to resolve the conflict\nbetween the IP interests of the supplier and the quality interests of the\ncustomer. We introduce a protocol in which a dedicated server (called the\n\"amanat\") is controlled by both parties: the customer controls the verification\ntask performed by the amanat, while the supplier controls the communication\nchannels of the amanat to ensure that the amanat does not leak information\nabout the source code. We argue that the protocol is both practically useful\nand mathematically sound. As the protocol is based on well-known (and\nrelatively lightweight) cryptographic primitives, it allows a straightforward\nimplementation on top of existing verification tool chains. To substantiate our\nsecurity claims, we establish the correctness of the protocol by cryptographic\nreduction proofs.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0701187v2"
    },
    {
        "title": "A Dynamic I/O Model for TRACON Traffic Management",
        "authors": [
            "Maxime Gariel",
            "John-Paul Clarke",
            "Eric Feron"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This work investigates the TRACON flow management around a major airport.\nAircraft flows are analyzed through a study of TRACON trajectories records.\nRerouting and queuing processes are highlighted and airport characteristics are\nshown as function of the number of planes in the TRACON. Then, a simple\ninput-output TRACON queuing and landing model is proposed. This model is\ncalibrated and validated using available TRACON data. It reproduces the same\nphenomenon as the real system. This model is used to show the impact of\nlimiting the number of aircrafts in the TRACON. A limited number of aircraft\ndoes not increase delays but reduces the controller's workload and increases\nsafety.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0702019v1"
    },
    {
        "title": "Authentication via wireless networks",
        "authors": [
            "Darko Fuduric",
            "Marko Horvat",
            "Mario Zagar"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Personal authentication is an important process we encounter almost every\nday; when we are logging on a computer, entering a company where we work, or a\nrestricted area, when we are using our plastic credit cards to pay for a\nservice or to complete some other financial transaction, etc. In each of these\nprocesses of personal authentication some kind of magnetic or optical token is\nrequired. But by using novel technologies like mobile computing and wireless\nnetworking, it is possible to avoid carrying multitude of ID cards or\nremembering a number of PIN codes. Article shows how to efficiently\nauthenticate users via Personal Area Networks (PAN) like Bluetooth or IrDA\nusing commonplace AES (Rijndel) or MD5 encryption. This method can be\nimplemented on many types of mobile devices like Pocket PC PDA with Windows CE\n(Windows Mobile 2003) real-time operating system, or any other customized OS,\nso we will explain all components and key features of such basic system.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0702094v1"
    },
    {
        "title": "A Sum-Product Model as a Physical Basis for Shadow Fading",
        "authors": [
            "Jari Salo"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Shadow fading (slow fading) effects play a central role in mobile\ncommunication system design and analysis. Experimental evidence indicates that\nshadow fading exhibits log-normal power distribution almost universally, and\nyet it is still not well understood what causes this. In this paper, we propose\na versatile sum-product signal model as a physical basis for shadow fading.\nSimulation results imply that the proposed model results in log-normally\ndistributed local mean power regardless of the distributions of the\ninteractions in the radio channel, and hence it is capable of explaining the\nlog-normality in a wide variety of propagation scenarios. The sum-product model\nalso includes as its special cases the conventional product model as well as\nthe recently proposed sum model, and improves upon these by: a) being\napplicable in both global and local distance scales; b) being more plausible\nfrom physical point of view; c) providing better goodness-of-fit to log-normal\ndistribution than either of these models.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0702098v1"
    },
    {
        "title": "Comparing Architectures of Mobile Applications",
        "authors": [
            "Kresimir Fertalj",
            "Marko Horvat"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This article describes various advantages and disadvantages of SMS, WAP, J2ME\nand Windows CE technologies in designing mobile applications. In defining the\narchitecture of any software application it is important to get the best\ntrade-off between platform's possibilities and design requirements. Achieving\noptimum software design is even more important with mobile applications where\nall computer resources are limited. Therefore, it is important to have a\ncomparative analysis of all relevant contemporary approaches in designing\nmobile applications. As always, the choice between these technologies is\ndetermined by application requirements and system capabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0703041v1"
    },
    {
        "title": "Automatic Annotation of XHTML Pages with Audio Components",
        "authors": [
            "Paul Fodor"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this paper we present Deiush, a multimodal system for browsing hypertext\nWeb documents. The Deiush system is based on our novel approach to\nautomatically annotate hypertext Web documents (i.e. XHTML pages) with\nbrowsable audio components. It combines two key technologies: (1) middleware\nautomatic separation of Web documents through structural and semantic analysis\nwhich is annotated with audio components, transforming them into XHTML+VoiceXML\nformat to represent multimodal dialog; and (2) Opera Browser, an already\nstandardized browser which we adopt as an interface of the XHTML+VoiceXML\noutput of annotating. This paper describes the annotation technology of Deiush\nand presents an initial system evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0703071v3"
    },
    {
        "title": "Domain Directed Dialogs for Decision Processes",
        "authors": [
            "Paul Fodor"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The search for a standardized optimum way to communicate using natural\nlanguage dialog has involved a lot of research. However, due to the diversity\nof communication domains, we think that this is extremely difficult to achieve\nand different dialogue management techniques should be applied for different\nsituations. Our work presents the basis of a communication mechanism that\nsupports decision processes, is based on decision trees, and minimizes the\nnumber of steps (turn-takes) in the dialogue. The initial dialog workflow is\nautomatically generated and the user's interaction with the system can also\nchange the decision tree and create new dialog paths with optimized cost. The\ndecision tree represents the chronological ordering of the actions (via the\nparent-child relationship) and uses an object frame to represent the\ninformation state (capturing the notion of context). This paper presents our\nframework, the formalism for interaction and dialogue, and an evaluation of the\nsystem compared to relevant dialog planning frameworks (i.e. finite state\ndiagrams, frame-based, information state and planning-based dialogue systems).\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0703072v3"
    },
    {
        "title": "Asynchronous Event-Driven Particle Algorithms",
        "authors": [
            "Aleksandar Donev"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  We present, in a unifying way, the main components of three asynchronous\nevent-driven algorithms for simulating physical systems of interacting\nparticles. The first example, hard-particle molecular dynamics, is well-known.\nWe also present a recently-developed diffusion kinetic Monte Carlo algorithm,\nas well as a novel stochastic molecular-dynamics algorithm that builds on the\nDirect Simulation Monte Carlo. We explain how to effectively combine\nasynchronous event-driven with classical time-driven or with synchronous\nevent-driven handling. Finally, we discuss some promises and challenges for\nevent-driven simulation of realistic physical systems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0703096v2"
    },
    {
        "title": "Performance Analysis of the IEEE 802.11e Enhanced Distributed\n  Coordination Function using Cycle Time Approach",
        "authors": [
            "Inanc Inan",
            "Feyza Keceli",
            "Ender Ayanoglu"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The recently ratified IEEE 802.11e standard defines the Enhanced Distributed\nChannel Access (EDCA) function for Quality-of-Service (QoS) provisioning in the\nWireless Local Area Networks (WLANs). The EDCA uses Carrier Sense Multiple\nAccess with Collision Avoidance (CSMA/CA) and slotted Binary Exponential\nBackoff (BEB) mechanism. We present a simple mathematical analysis framework\nfor the EDCA function. Our analysis considers the fact that the distributed\nrandom access systems exhibit cyclic behavior where each station successfully\ntransmits a packet in a cycle. Our analysis shows that an AC-specific cycle\ntime exists for the EDCA function. Validating the theoretical results via\nsimulations, we show that the proposed analysis accurately captures EDCA\nsaturation performance in terms of average throughput, medium access delay, and\npacket loss ratio. The cycle time analysis is a simple and insightful\nsubstitute for previously proposed more complex EDCA models.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.1838v1"
    },
    {
        "title": "Fairness Provision in the IEEE 802.11e Infrastructure Basic Service Set",
        "authors": [
            "Feyza Keceli",
            "Inanc Inan",
            "Ender Ayanoglu"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Most of the deployed IEEE 802.11e Wireless Local Area Networks (WLANs) use\ninfrastructure Basic Service Set (BSS) in which an Access Point (AP) serves as\na gateway between wired and wireless domains. We present the unfairness problem\nbetween the uplink and the downlink flows of any Access Category (AC) in the\n802.11e Enhanced Distributed Channel Access (EDCA) when the default settings of\nthe EDCA parameters are used. We propose a simple analytical model to calculate\nthe EDCA parameter settings that achieve weighted fair resource allocation for\nall uplink and downlink flows. We also propose a simple model-assisted\nmeasurement-based dynamic EDCA parameter adaptation algorithm. Moreover, our\ndynamic solution addresses the differences in the transport layer and the\nMedium Access Control (MAC) layer interactions of User Datagram Protocol (UDP)\nand Transmission Control Protocol (TCP). We show that proposed Contention\nWindow (CW) and Transmit Opportunity (TXOP) limit adaptation at the AP provides\nfair UDP and TCP access between uplink and downlink flows of the same AC while\npreserving prioritization among ACs.\n",
        "pdf_link": "http://arxiv.org/pdf/0704.1842v2"
    },
    {
        "title": "The Use of ITIL for Process Optimisation in the IT Service Centre of\n  Harz University, exemplified in the Release Management Process",
        "authors": [
            "Hans-Juergen Scheruhn",
            "Christian Reinboth",
            "Thomas Habel"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper details the use of the IT Infrastructure Library Framework (ITIL)\nfor optimising process workflows in the IT Service Centre of Harz University in\nWernigerode, Germany, exemplified by the Release Management Process. It is\ndescribed, how, during the course of a special ITIL project, the As-Is-Status\nof the various original processes was documented as part of the process life\ncycle and then transformed in the To-Be-Status, according to the ITIL Best\nPractice Framework. It is also shown, how the ITIL framework fits into the\nfour-layered-process model, that could be derived from interviews with the\nuniversities IT support staff, and how the various modified processes\ninterconnect with each other to form a value chain. The paper highlights the\nfinal results of the project and gives an outlook on the future use of ITIL as\na business modelling tool in the IT Service Centre of Harz University. It is\ncurrently being considered, whether the process model developed during the\nproject could be used as a reference model for other university IT centres.\n",
        "pdf_link": "http://arxiv.org/pdf/0705.2351v1"
    },
    {
        "title": "Remote laboratories: new technology and standard based architecture",
        "authors": [
            "Hcene Benmohamed",
            "Arnaud Leleve",
            "Patrick Prvot"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  E-Laboratories are important components of e- learning environments,\nespecially in scientific and technical disciplines. First widespread E-Labs\nconsisted in proposing simulations of real systems (virtual labs), as building\nremote labs (remote control of real systems) was difficult by lack of\nindustrial standards and common protocols. Nowadays, robotics and automation\ntechnologies make easier the interfacing of systems with computers. In this\nframe, many researchers (such as those mentioned in [1]) focus on how to set up\nsuch a remote control. But, only a few of them deal with the educational point\nof view of the problem. This paper outlines our current research and reflection\nabout remote laboratory modelling.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.2974v1"
    },
    {
        "title": "Hypocomputation",
        "authors": [
            "David Love"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Hypercomputational formal theories will, clearly, be both structurally and\nfoundationally different from the formal theories underpinning computational\ntheories. However, many of the maps that might guide us into this strange realm\nhave been lost. So little work has been done recently in the area of\nmetamathematics, and so many of the previous results have been folded into\nother theories, that we are in danger of loosing an appreciation of the broader\nstructure of formal theories. As an aid to those looking to develop\nhypercomputational theories, we will briefly survey the known landmarks both\ninside and outside the borders of computational theory. We will not focus in\nthis paper on why the structure of formal theory looks the way it does. Instead\nwe will focus on what this structure looks like, moving from hypocomputational,\nthrough traditional computational theories, and then beyond to\nhypercomputational theories.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.3479v1"
    },
    {
        "title": "2-State 3-Symbol Universal Turing Machines Do Not Exist",
        "authors": [
            "Craig Alan Feinstein"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this brief note, we give a simple information-theoretic proof that 2-state\n3-symbol universal Turing machines cannot possibly exist, unless one loosens\nthe definition of \"universal\".\n",
        "pdf_link": "http://arxiv.org/pdf/0706.4440v5"
    },
    {
        "title": "Modeling Context, Collaboration, and Civilization in End-User\n  Informatics",
        "authors": [
            "George A. Maney"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  End-user informatics applications are Internet data web management automation\nsolutions. These are mass modeling and mass management collaborative communal\nconsensus solutions. They are made and maintained by managerial, professional,\ntechnical and specialist end-users. In end-user informatics the end-users are\nalways right. So it becomes necessary for information technology professionals\nto understand information and informatics from the end-user perspective.\nEnd-user informatics starts with the observation that practical prose is a mass\nconsensus communal modeling technology. This high technology is the mechanistic\nmodeling medium we all use every day in all of our practical pursuits.\nPractical information flows are the lifeblood of modern capitalist communities.\nBut what exactly is practical information? It's ultimately physical\ninformation, but the physics is highly emergent rather than elementary. So\npractical reality is just physical reality in deep disguise. Practical prose is\nthe medium that we all use to model the everyday and elite mechanics of\npractical reality. So this is the medium that end-user informatics must\nautomate and animate.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.3178v1"
    },
    {
        "title": "The Accidental Detection Index as a Fault Ordering Heuristic for\n  Full-Scan Circuits",
        "authors": [
            "Irith Pomeranz",
            "Sudhakar M. Reddy"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  We investigate a new fault ordering heuristic for test generation in\nfull-scan circuits. The heuristic is referred to as the accidental detection\nindex. It associates a value ADI (f) with every circuit fault f. The heuristic\nestimates the number of faults that will be detected by a test generated for f.\nFault ordering is done such that a fault with a higher accidental detection\nindex appears earlier in the ordered fault set and targeted earlier during test\ngeneration. This order is effective for generating compact test sets, and for\nobtaining a test set with a steep fault coverage curve. Such a test set has\nseveral applications. We present experimental results to demonstrate the\neffectiveness of the heuristic.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4637v1"
    },
    {
        "title": "Modeling and Propagation of Noisy Waveforms in Static Timing Analysis",
        "authors": [
            "Shahin Nazarian",
            "Massoud Pedram",
            "Emre Tuncer",
            "Tao Lin",
            "Amir H. Ajami"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  A technique based on the sensitivity of the output to input waveform is\npresented for accurate propagation of delay information through a gate for the\npurpose of static timing analysis (STA) in the presence of noise. Conventional\nSTA tools represent a waveform by its arrival time and slope. However, this is\nnot an accurate way of modeling the waveform for the purpose of noise analysis.\nThe key contribution of our work is the development of a method that allows\nefficient propagation of equivalent waveforms throughout the circuit.\nExperimental results demonstrate higher accuracy of the proposed\nsensitivity-based gate delay propagation technique, SGDP, compared to the best\nof existing approaches. SGDP is compatible with the current level of gate\ncharacterization in conventional ASIC cell libraries, and as a result, it can\nbe easily incorporated into commercial STA tools to improve their accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4642v1"
    },
    {
        "title": "RIP: An Efficient Hybrid Repeater Insertion Scheme for Low Power",
        "authors": [
            "Xun Liu",
            "Yuantao Peng",
            "Marios C. Papaefthymiou"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents a novel repeater insertion algorithm for interconnect\npower minimization. The novelty of our approach is in the judicious integration\nof an analytical solver and a dynamic programming based method. Specifically,\nthe analytical solver chooses a concise repeater library and a small set of\nrepeater location candidates such that the dynamic programming algorithm can be\nperformed fast with little degradation of the solution quality. In comparison\nwith previously reported repeater insertion schemes, within comparable\nruntimes, our approach achieves up to 37% higher power savings. Moreover, for\nthe same design quality, our scheme attains a speedup of two orders of\nmagnitude.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4690v1"
    },
    {
        "title": "HEBS: Histogram Equalization for Backlight Scaling",
        "authors": [
            "Ali Iranli",
            "Hanif Fatemi",
            "Massoud Pedram"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this paper, a method is proposed for finding a pixel transformation\nfunction that maximizes backlight dimming while maintaining a pre-specified\nimage distortion level for a liquid crystal display. This is achieved by\nfinding a pixel transformation function, which maps the original image\nhistogram to a new histogram with lower dynamic range. Next the contrast of the\ntransformed image is enhanced so as to compensate for brightness loss that\nwould arise from backlight dimming. The proposed approach relies on an accurate\ndefinition of the image distortion which takes into account both the pixel\nvalue differences and a model of the human visual system and is amenable to\nhighly efficient hardware realization. Experimental results show that the\nhistogram equalization for backlight scaling method results in about 45% power\nsaving with an effective distortion rate of 5% and 65% power saving for a 20%\ndistortion rate. This is significantly higher power savings compared to\npreviously reported backlight dimming approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4710v1"
    },
    {
        "title": "Noise Figure Evaluation Using Low Cost BIST",
        "authors": [
            "Marcelo Negreiros",
            "Luigi Carro",
            "Altamiro A. Susin"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  A technique for evaluating noise figure suitable for BIST implementation is\ndescribed. It is based on a low cost single-bit digitizer, which allows the\nsimultaneous evaluation of noise figure in several test points of the analog\ncircuit. The method is also able to benefit from SoC resources, like memory and\nprocessing power. Theoretical background and experimental results are presented\nin order to demonstrate the feasibility of the approach.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4718v1"
    },
    {
        "title": "Efficient Feasibility Analysis for Real-Time Systems with EDF Scheduling",
        "authors": [
            "Karsten Albers",
            "Frank Slomka"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents new fast exact feasibility tests for uniprocessor\nreal-time systems using preemptive EDF scheduling. Task sets which are accepted\nby previously described sufficient tests will be evaluated in nearly the same\ntime as with the old tests by the new algorithms. Many task sets are not\naccepted by the earlier tests despite them beeing feasible. These task sets\nwill be evaluated by the new algorithms a lot faster than with known exact\nfeasibility tests. Therefore it is possible to use them for many applications\nfor which only sufficient test are suitable. Additionally this paper shows that\nthe best previous known sufficient test, the best known feasibility bound and\nthe best known approximation algorithm can be derived from these new tests. In\nresult this leads to an integrated schedulability theory for EDF.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4737v1"
    },
    {
        "title": "Q-DPM: An Efficient Model-Free Dynamic Power Management Technique",
        "authors": [
            "Min Li",
            "Xiaobo Wu",
            "Richard Yao",
            "Xiaolang Yan"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  When applying Dynamic Power Management (DPM) technique to pervasively\ndeployed embedded systems, the technique needs to be very efficient so that it\nis feasible to implement the technique on low end processor and tight-budget\nmemory. Furthermore, it should have the capability to track time varying\nbehavior rapidly because the time varying is an inherent characteristic of real\nworld system. Existing methods, which are usually model-based, may not satisfy\nthe aforementioned requirements. In this paper, we propose a model-free DPM\ntechnique based on Q-Learning. Q-DPM is much more efficient because it removes\nthe overhead of parameter estimator and mode-switch controller. Furthermore,\nits policy optimization is performed via consecutive online trialing, which\nalso leads to very rapid response to time varying behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4739v1"
    },
    {
        "title": "A New Approach to Component Testing",
        "authors": [
            "Horst Brinkmeyer"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Carefully tested electric/electronic components are a requirement for\neffective hardware-in-the-loop tests and vehicle tests in automotive industry.\nA new method for definition and execution of component tests is described. The\nmost important advantage of this method is independance from the test stand. It\ntherefore offers the oppportunity to build up knowledge over a long period of\ntime and the ability to share this knowledge with different partners.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4740v1"
    },
    {
        "title": "Embedded Automotive System Development Process",
        "authors": [
            "Joachim Langenwalter"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Model based design enables the automatic generation of final-build software\nfrom models for high-volume automotive embedded systems. This paper presents a\nframework of processes, methods and tools for the design of automotive embedded\nsystems. A steer-by-wire system serves as an example.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4745v1"
    },
    {
        "title": "An Iterative Algorithm for Battery-Aware Task Scheduling on Portable\n  Computing Platforms",
        "authors": [
            "Jawad Khan",
            "Ranga Vemuri"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this work we consider battery powered portable systems which either have\nField Programmable Gate Arrays (FPGA) or voltage and frequency scalable\nprocessors as their main processing element. An application is modeled in the\nform of a precedence task graph at a coarse level of granularity. We assume\nthat for each task in the task graph several unique design-points are available\nwhich correspond to different hardware implementations for FPGAs and different\nvoltage-frequency combinations for processors. It is assumed that performance\nand total power consumption estimates for each design-point are available for\nany given portable platfrom, including the peripheral components such as memory\nand display power usage. We present an iterative heuristic algorithm which\nfinds a sequence of tasks along with an appropriate design-point for each task,\nsuch that a deadline is met and the amount of battery energy used is as small\nas possible. A detailed illustrative example along with a case study of a\nreal-world application of a robotic arm controller which demonstrates the\nusefulness of our algorithm is also presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4752v1"
    },
    {
        "title": "Exploiting Dynamic Workload Variation in Low Energy Preemptive Task\n  Scheduling",
        "authors": [
            "Lap-Fai Leung",
            "Chi-Ying Tsui",
            "Xiaobo Sharon Hu"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  A novel energy reduction strategy to maximally exploit the dynamic workload\nvariation is proposed for the offline voltage scheduling of preemptive systems.\nThe idea is to construct a fully-preemptive schedule that leads to minimum\nenergy consumption when the tasks take on approximately the average execution\ncycles yet still guarantees no deadline violation during the worst-case\nscenario. End-time for each sub-instance of the tasks obtained from the\nschedule is used for the on-line dynamic voltage scaling (DVS) of the tasks.\nFor the tasks that normally require a small number of cycles but occasionally a\nlarge number of cycles to complete, such a schedule provides more opportunities\nfor slack utilization and hence results in larger energy saving. The concept is\nrealized by formulating the problem as a Non-Linear Programming (NLP)\noptimization problem. Experimental results show that, by using the proposed\nscheme, the total energy consumption at runtime is reduced by as high as 60%\nfor randomly generated task sets when comparing with the static scheduling\napproach only using worst case workload.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4758v1"
    },
    {
        "title": "Rapid Generation of Thermal-Safe Test Schedules",
        "authors": [
            "Paul Rosinger",
            "Bashir Al-Hashimi",
            "Krishnendu Chakrabarty"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Overheating has been acknowledged as a major issue in testing complex SOCs.\nSeveral power constrained system-level DFT solutions (power constrained test\nscheduling) have recently been proposed to tackle this problem. However, as it\nwill be shown in this paper, imposing a chip-level maximum power constraint\ndoesn't necessarily avoid local overheating due to the non-uniform distribution\nof power across the chip. This paper proposes a new approach for dealing with\noverheating during test, by embedding thermal awareness into test scheduling.\nThe proposed approach facilitates rapid generation of thermal-safer test\nschedules without requiring time-consuming thermal simulations. This is\nachieved by employing a low-complexity test session thermal model used to guide\nthe test schedule generation algorithm. This approach reduces the chances of a\ndesign re-spin due to potential overheating during test.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4797v1"
    },
    {
        "title": "System Synthesis for Networks of Programmable Blocks",
        "authors": [
            "Ryan Mannion",
            "Harry Hsieh",
            "Susan Cotterell",
            "Frank Vahid"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The advent of sensor networks presents untapped opportunities for synthesis.\nWe examine the problem of synthesis of behavioral specifications into networks\nof programmable sensor blocks. The particular behavioral specification we\nconsider is an intuitive user-created network diagram of sensor blocks, each\nblock having a pre-defined combinational or sequential behavior. We synthesize\nthis specification to a new network that utilizes a minimum number of\nprogrammable blocks in place of the pre-defined blocks, thus reducing network\nsize and hence network cost and power. We focus on the main task of this\nsynthesis problem, namely partitioning pre-defined blocks onto a minimum number\nof programmable blocks, introducing the efficient but effective PareDown\ndecomposition algorithm for the task. We describe the synthesis and simulation\ntools we developed. We provide results showing excellent network size\nreductions through such synthesis, and significant speedups of our algorithm\nover exhaustive search while obtaining near-optimal results for 15 real network\ndesigns as well as nearly 10,000 randomly generated designs.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4798v1"
    },
    {
        "title": "Access Pattern-Based Code Compression for Memory-Constrained Embedded\n  Systems",
        "authors": [
            "O. Ozturk",
            "H. Saputra",
            "M. Kandemir",
            "I. Kolcu"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  As compared to a large spectrum of performance optimizations, relatively\nlittle effort has been dedicated to optimize other aspects of embedded\napplications such as memory space requirements, power, real-time\npredictability, and reliability. In particular, many modern embedded systems\noperate under tight memory space constraints. One way of satisfying these\nconstraints is to compress executable code and data as much as possible. While\nresearch on code compression have studied efficient hardware and software based\ncode strategies, many of these techniques do not take application behavior into\naccount, that is, the same compression/decompression strategy is used\nirrespective of the application being optimized. This paper presents a code\ncompression strategy based on control flow graph (CFG) representation of the\nembedded program. The idea is to start with a memory image wherein all basic\nblocks are compressed, and decompress only the blocks that are predicted to be\nneeded in the near future. When the current access to a basic block is over,\nour approach also decides the point at which the block could be compressed. We\npropose several compression and decompression strategies that try to reduce\nmemory requirements without excessively increasing the original instruction\ncycle counts.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4799v1"
    },
    {
        "title": "Mutation Sampling Technique for the Generation of Structural Test Data",
        "authors": [
            "M. Scholive",
            "V. Beroulle",
            "C. Robach",
            "M. L. Flottes",
            "B. Rouzeyre"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Our goal is to produce validation data that can be used as an efficient (pre)\ntest set for structural stuck-at faults. In this paper, we detail an original\ntest-oriented mutation sampling technique used for generating such data and we\npresent a first evaluation on these validation data with regard to a structural\ntest.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4802v1"
    },
    {
        "title": "System Level Analysis of the Bluetooth Standard",
        "authors": [
            "Massimo Conti",
            "Daniele Moretti"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The SystemC modules of the Link Manager Layer and Baseband Layer have been\ndesigned in this work at behavioral level to analyze the performances of the\nBluetooth standard. In particular the probability of the creation of a piconet\nin presence of noise in the channel and the power reduction using the sniff and\nhold mode have been investigated.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4811v1"
    },
    {
        "title": "LC Oscillator Driver for Safety Critical Applications",
        "authors": [
            "Pavel Horsky"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  A CMOS harmonic signal LC oscillator driver for automotive applications\nworking in a harsh environment with high safety critical requirements is\ndescribed. The driver can be used with a wide range of external components\nparameters (LC resonance network of a sensor). Quality factor of the external\nLC network can vary two decades. Amplitude regulation of the driver is\ndigitally controlled and the DAC is constructed as exponential with\npiece-wise-linear (PWL) approximation. Low current consumption for high quality\nresonance networks is achieved. Realized oscillator is robust, used in safety\ncritical application and has low EMC emissions.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4831v1"
    },
    {
        "title": "A CMOS-Based Tactile Sensor for Continuous Blood Pressure Monitoring",
        "authors": [
            "K. -U. Kirstein",
            "J. Sedivy",
            "T. Salo",
            "C. Hagleitner",
            "T. Vancura",
            "A. Hierlemann"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  A monolithic integrated tactile sensor array is presented, which is used to\nperform non-invasive blood pressure monitoring of a patient. The advantage of\nthis device compared to a hand cuff based approach is the capability of\nrecording continuous blood pressure data. The capacitive, membrane-based sensor\ndevice is fabricated in an industrial CMOS-technology combined with post-CMOS\nmicromachining. The capacitance change is detected by a S?-modulator. The\nmodulator is operated at a sampling rate of 128kS/s and achieves a resolution\nof 12bit with an external decimation filter and an OSR of 128.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4835v1"
    },
    {
        "title": "A Tool and Methodology for AC-Stability Analysis of Continuous-Time\n  Closed-Loop Systems",
        "authors": [
            "Momchil Milev",
            "Rod Burt"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Presented are a methodology and a DFII-based tool for AC-stability analysis\nof a wide variety of closed-loop continuous-time (operational amplifiers and\nother linear circuits). The methodology used allows for easy identification and\ndiagnostics of ac-stability problems including not only main-loop effects but\nalso local-instability loops in current mirrors, bias circuits and emitter or\nsource followers without breaking the loop. The results of the analysis are\neasy to interpret. Estimated phase margin is readily available. Instability\nnodes and loops along with their respective oscillation frequencies are\nimmediately identified and mapped to the existing circuit nodes thus offering\nsignificant advantages compared to traditional \"black-box\" methods of stability\nanalysis (Transient Overshoot, Bode and Phase margin plots etc.). The tool for\nAC-Stability analysis is written in SKILL? and is fully integrated in DFII?\nenvironment. Its \"push-button\" graphical user interface (GUI) is easy to use\nand understand. The tool can be invoked directly from Composer? schematic and\ndoes not require active Analog Artist? session. The tool is not dependent on\nthe use of a specific fabrication technology or Process Design Kit\ncustomization. It requires OCEAN?, Spectre? and Waveform calculator\ncapabilities to run.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4836v1"
    },
    {
        "title": "An Assembler Driven Verification Methodology (ADVM)",
        "authors": [
            "John S. Macbeth",
            "Dietmar Heinz",
            "Ken Gray"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents an overview of an assembler driven verification\nmethodology (ADVM) that was created and implemented for a chip card project at\nInfineon Technologies AG. The primary advantage of this methodology is that it\nenables rapid porting of directed tests to new targets and derivatives, with\nonly a minimum amount of code refactoring. As a consequence, considerable\nverification development time and effort was saved.\n",
        "pdf_link": "http://arxiv.org/pdf/0710.4852v1"
    },
    {
        "title": "Conception individuelle et collective. Approche de l'ergonomie cognitive\n  [Individual and Collective Design. The Cognitive-Ergonomics Approach]",
        "authors": [
            "Willemien Visser"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This text presents the cognitive-ergonomics approach to design, in both its\nindividual and collective form. It focuses on collective design with respect to\nindividual design. The theoretical framework adopted is that of information\nprocessing, specified for design problems. The cognitive characteristics of\ndesign problems are presented: the effects of their ill-defined character and\nof the different types of representation implemented in solving these problems,\namongst others the more or less \"satisficing\" character of the different\npossible solutions. The text first describes the cognitive activities\nimplemented in both individual and collective design: different types of\ncontrol activities and of the executive activities of solution development and\nevaluation. Specific collective-design characteristics are then presented:\nco-design and distributed-design activities, temporo-operative and cognitive\nsynchronisation, and different types of argumentation, of co-designers'\nintervention modes in the design process, of solution-proposals evaluation. The\npaper concludes by a confrontation between the two types of design, individual\nand collective.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.1290v1"
    },
    {
        "title": "Microsystem Product Development",
        "authors": [
            "M. -A. Polosky",
            "E. -J. Garcia"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Over the last decade the successful design and fabrication of complex MEMS\n(MicroElectroMechanical Systems), optical circuits and ASICs have been\ndemonstrated. Packaging and integration processes have lagged behind MEMS\nresearch but are rapidly maturing. As packaging processes evolve, a new\nchallenge presents itself, microsystem product development. Product development\nentails the maturation of the design and all the processes needed to\nsuccessfully produce a product. Elements such as tooling design, fixtures,\ngages, testers, inspection, work instructions, process planning, etc., are\noften overlooked as MEMS engineers concentrate on design, fabrication and\npackaging processes. Thorough, up-front planning of product development efforts\nis crucial to the success of any project.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3274v1"
    },
    {
        "title": "Parasitic Effects Reduction for Wafer-Level Packaging of RF-Mems",
        "authors": [
            "J. Iannacci",
            "Jason Tian",
            "S. Sinaga",
            "R. Gaddi",
            "A. Gnudi",
            "M. Bartek"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In RF-MEMS packaging, next to the protection of movable structures,\noptimization of package electrical performance plays a very important role. In\nthis work, a wafer-level packaging process has been investigated and optimized\nin order to minimize electrical parasitic effects. The RF-MEMS package concept\nused is based on a wafer-level bonding of a capping silicon substrate to an\nRF-MEMS wafer. The capping silicon substrate resistivity, substrate thickness\nand the geometry of through-substrate electrical interconnect vias have been\noptimized using finite-element electromagnetic simulations (Ansoft HFSS). Test\nstructures for electrical characterization have been designed and after their\nfabrication, measurement results will be compared with simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3275v1"
    },
    {
        "title": "Surface Conditioning Effect on Vacuum Microelectronics Components\n  Fabricated by Deep Reactive Ion Etching",
        "authors": [
            "A. Phommahaxay",
            "G. Lissorgues",
            "L. Rousseau",
            "T. Bourouina",
            "P. Nicole"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Advances in material processing such as silicon micromachining are opening\nthe way to vacuum microelectronics. Two-dimensional vacuum components can be\nfabricated using the microsystems processes. We developed such devices using a\nsingle metal layer and silicon micromachining by DRIE. The latter technological\nstep has significant impact on the characteristics of the vacuum components.\nThis paper presents a brief summary of electron emission possibilities and the\ndesign leading to the fabrication of a lateral field emission diode. First\nmeasurement results and the aging of the devices are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3276v1"
    },
    {
        "title": "3-D Self-Assembled Soi Mems: An Example of Multiphysics Simulation",
        "authors": [
            "C. Mendez",
            "C. Louis",
            "S. Paquay",
            "P. De Vincenzo",
            "I. Klapka",
            "V. Rochus",
            "F. Iker",
            "Nicolas Andr",
            "J. -P. Raskin"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  MEMS devices are typical systems where multiphysics simulations are\nunavoidable. In this work, we present possible applications of 3-D\nself-assembled SOI (Silicon-on-Insulator) MEMS such as, for instance, thermal\nactuators and flow sensors. The numerical simulations of these microsystems are\npresented. Structural and thermal parts have to be strongly coupled for\ncorrectly describing the fabrication process and for simulating the behavior of\nthese 3-D SOI MEMS.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3277v1"
    },
    {
        "title": "Influence of the Feedback Filter on the Response of the Pulsed Digital\n  Oscillator",
        "authors": [
            "M. Dominguez",
            "Joan Pons",
            "J. Ricart",
            "J. Juillard",
            "E. Colinet"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper introduces a new feedback topology for the Pulsed Digital\nOscillator (PDO) and compares it to the classical topology. The `classic' or\nsingle feedback topology, introduced in previous works, shows a strong behavior\ndependence on the damping losses in the MEMS resonator. A new double feedback\ntopology is introduced here in order to help solving this problem. Comparative\ndiscrete-time simulations and preliminary experimental measurements have been\ncarried out for both topologies, showing how the new double feedback topology\nmay increase PDO performance for some frequency ranges.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3279v1"
    },
    {
        "title": "Concave Microlens Array Mold Fabrication in Photoresist Using UV\n  Proximity Printing",
        "authors": [
            "Tsung-Hung Lin",
            "Hsiharng Yang",
            "Ching-Kong Chao"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents a simple and effective method to fabricate a\npolydimethyl-siloxane (PDMS) microlens array with a high fill factor, which\nutilizes the UV proximity printing and photoresist replication methods. The\nconcave microlens array mold was made using a printing gap in lithography\nprocess, which utilizes optical diffraction of UV light to deflect away from\nthe aperture edges and produces a certain exposure in the photoresist material\noutside the aperture edges. This method can precisely control the geometric\nprofile of concave microlens array. The experimental results showed that the\nconcave micro-lens array in photoresist could be formed automatically when the\nprinting gap ranged from 240 micron to 720 micron. High fill factor microlens\narray can be produced, when the control pitch distance between the adjacent\napertures of the concave microlens array was decreased to the aperture size.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3284v1"
    },
    {
        "title": "The annealing induced extraordinary properties of SI based ZNO film\n  grown by RF sputtering",
        "authors": [
            "Jing Li",
            "L. Dedeng",
            "Suntao Wu"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Pb(Zr0.52Ti0.48)O3 (PZT) thin films were in situ deposited by pulsed laser\ndeposition (PLD) on Pt/Ti/SiO2/Si substrates using a template layer derived by\nsol-gel method. A 0.1-$\\mu$m-thick PZT layer with (111) or (100)-preferred\norientation was first deposited onto Pt/Ti/SiO2/Si substrates using the sol-gel\nmethod, and than a PZT layer with thickness of 1$\\mu$m was in situ deposited by\nPLD on the above-mentioned PZT layer. The crystalline phases and the preferred\norientations of the PZT films were investigated by X-ray diffraction analysis.\nSurface and cross-sectional morphologies were observed by scanning electron\nmicroscopy and transmission electron microscopy. The electrical properties of\nthe films were evaluated by measuring their P-E hysteresis loops and dielectric\nconstants. The preferred orientation of the films can be controlled using the\ntemplate layer derived by the sol-gel method. The deposition temperature\nrequired to obtain the perovskite phase in this process is approximately 460\ndegrees C, and is significantly lower than that in the case of direct film\ndeposition by PLD on the Pt/Ti/SiO2/Si substrates.\n  Keywords: lead zirconate titanate (PZT), thin film, sol-gel method, laser\nablation, electrical properties\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3286v1"
    },
    {
        "title": "Parametric Yield Analysis of Mems via Statistical Methods",
        "authors": [
            "S. -P. Vudathu",
            "K. -K. Duganapalli",
            "Rainer Laur",
            "D. Kubalinska",
            "A. Bunse-Gerstner"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper considers a developing theory on the effects of inevitable process\nvariations during the fabrication of MEMS and other microsystems. The effects\non the performance and design yield of the microsystems devices are analyzed\nand presented. A novel methodology in the design cycle of MEMS and other\nmicrosystems is briefly introduced. This paper describes the initial steps of\nthis methodology that is aimed at counteracting the parametric variations in\nthe product cycle of microsystems. It is based on a concept of worst-case\nanalysis that has proven successful in the parent IC technology. Issues ranging\nfrom the level of abstraction of the microsystem models to the availability of\nsuch models are addressed\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3287v1"
    },
    {
        "title": "Electrostatically-Driven Resonator on Soi with Improved Temperature\n  Stability",
        "authors": [
            "A. Giridhar",
            "F. Verjus",
            "F. Marty",
            "A. Bosseboeuf",
            "T. Bourouina"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper deals with a single-crystal-silicon (SCS) MEMS resonator with\nimproved temperature stability. While simulations have shown that the\ntemperature coefficient of resonant frequency can be down to 1 ppm/degrees C,\npreliminary measurements on non-optimised structures gave evidence of a\ntemperature coefficient of 29 ppm/degrees C. Design, optimisation, experimental\nresults with post process simulation and prospective work are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3288v1"
    },
    {
        "title": "Electromechanical Reliability Testing of Three-Axial Silicon Force\n  Sensors",
        "authors": [
            "S. Spinner",
            "J. Bartholomeyczik",
            "B. Becker",
            "M. Doelle",
            "O. Paul",
            "I. Polian",
            "R. Roth",
            "K. Seitz",
            "P. Ruther"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper reports on the systematic electromechanical characterization of a\nnew three-axial force sensor used in dimensional metrology of micro components.\nThe siliconbased sensor system consists of piezoresistive mechanicalstress\ntransducers integrated in thin membrane hinges supporting a suspended flexible\ncross structure. The mechanical behavior of the fragile micromechanical\nstructure isanalyzed for both static and dynamic load cases. This work\ndemonstrates that the silicon microstructure withstands static forces of 1.16N\napplied orthogonally to the front-side of the structure. A statistical Weibull\nanalysis of the measured data shows that these values are significantly reduced\nif the normal force is applied to the back of the sensor. Improvements of the\nsensor system design for future development cycles are derived from the\nmeasurement results.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3289v1"
    },
    {
        "title": "An Active Chaotic Micromixer Integrating Thermal Actuation Associating\n  PDMS and Silicon Microtechnology",
        "authors": [
            "O. Franais",
            "M. -C. Jullien",
            "L. Rousseau",
            "P. Poulichet",
            "S. Desportes",
            "A. Chouai",
            "J. -P. Lefevre",
            "J. Delaire"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Due to scaling laws, in microfluidic, flows are laminar. Consequently, mixing\nbetween two liquids is mainly obtained by natural diffusion which may take a\nlong time or equivalently requires centimetre length channels. To reduce time\nand length for mixing, it is possible to generate chaotic-like flows either by\nmodifying the channel geometry or by creating an external perturbation of the\nflow. In this paper, an active micromixer is presented consisting on thermal\nactuation with heating resistors. In order to disturb the liquid flow, an\noscillating transverse flow is generated by heating the liquid. Depending on\nthe value of boiling point, either bubble expansion or volumetric dilation\ncontrolled the transverse flow amplitude. A chaotic like mixing is then induced\nunder particular conditions depending on volume expansion, liquid velocity,\nfrequency of actuation... This solution presents the advantage to achieve\nmixing in a very short time (1s) and along a short channel distance (channel\nwidth). It can also be integrated in a more complex device due to actuator\nintegration with microfluidics.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3290v1"
    },
    {
        "title": "Resolution Limits for Resonant Mems Sensors Based on Discrete Relay\n  Feedback Techniques",
        "authors": [
            "J. Juillard",
            "E. Colinet",
            "M. Dominguez",
            "Joan Pons",
            "J. Ricart"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper is devoted to the analysis of resonant MEMS sensors based on\ndiscrete relay feedback techniques. One drawback of such techniques is that\nsome synchronization usually occurs between the discrete part and the\ncontinuous part of the system: this results in sensor responses that are very\nsimilar to the curves known as devil's staircases, i.e. the frequency does not\nvary smoothly with the sensor's input. The main contribution of this paper is a\ntheoretical calculation of the resolution of such systems. The resolutions of\ntwo existing resonant MEMS architectures are then calculated and these results\nare discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3291v1"
    },
    {
        "title": "A Silicon-Based Micro Gas Turbine Engine for Power Generation",
        "authors": [
            "X. -C. Shan",
            "Z. -F. Wang",
            "R. Maeda",
            "Y. F. Sun",
            "M. Wu",
            "J. S. Hua"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper reports on our research in developing a micro power generation\nsystem based on gas turbine engine and piezoelectric converter. The micro gas\nturbine engine consists of a micro combustor, a turbine and a centrifugal\ncompressor. Comprehensive simulation has been implemented to optimal the\ncomponent design. We have successfully demonstrated a silicon-based micro\ncombustor, which consists of seven layers of silicon structures. A\nhairpin-shaped design is applied to the fuel/air recirculation channel. The\nmicro combustor can sustain a stable combustion with an exit temperature as\nhigh as 1600 K. We have also successfully developed a micro turbine device,\nwhich is equipped with enhanced micro air-bearings and driven by compressed\nair. A rotation speed of 15,000 rpm has been demonstrated during lab test. In\nthis paper, we will introduce our research results major in the development of\nmicro combustor and micro turbine test device.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3292v1"
    },
    {
        "title": "Energy Conversion Using New Thermoelectric Generator",
        "authors": [
            "Guillaume Savelli",
            "Marc Plissonnier",
            "Jacqueline Bablet",
            "C. Salvi",
            "J. M. Fournier"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  During recent years, microelectronics helped to develop complex and varied\ntechnologies. It appears that many of these technologies can be applied\nsuccessfully to realize Seebeck micro generators: photolithography and\ndeposition methods allow to elaborate thin thermoelectric structures at the\nmicro-scale level. Our goal is to scavenge energy by developing a miniature\npower source for operating electronic components. First Bi and Sb micro-devices\non silicon glass substrate have been manufactured with an area of 1cm2\nincluding more than one hundred junctions. Each step of process fabrication has\nbeen optimized: photolithography, deposition process, anneals conditions and\nmetallic connections. Different device structures have been realized with\ndifferent micro-line dimensions. Each devices performance will be reviewed and\ndiscussed in function of their design structure.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3294v1"
    },
    {
        "title": "Above Ic Micro-Power Generators for RF-Mems",
        "authors": [
            "S. Oukassi",
            "R. Salot",
            "S. Bancel",
            "J. -P. Pereira-Ramos"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This work presents recent advances in the development and the integration of\nan electrochemical (chemicalelectrical energy conversion) micro power generator\nused as a high voltage energy source for RF-MEMS powering. Autonomous MEMS\nrequire similarly miniaturized power sources. Up to day, solid state thin film\nbatteries are realized with mechanical masks. This method doesn't allow\ndimensions below a few mm^2 active area, and besides the whole process flow is\ndone under controlled atmosphere so as to ensure materials chemical stability\n(mainly lithiated materials). Within this context, Microelectronics\nmicro-fabrication procedures (photolithography, Reactive Ion Etching...) are\nused to reach both miniaturisation (100x100 $\\mu$m^2 targeted unit cell active\narea) and Above IC technological compatibility. All process steps developed\nhere are realized in clean room environment.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3296v1"
    },
    {
        "title": "Packaging of RF Mems Switching Functions on Alumina Substrate",
        "authors": [
            "M. -K. El Khatib",
            "A. Pothier",
            "P. Blondy"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Recently the strong demands in wireless communication requires expanding\ndevelopment for the application of RF MEMS (Radio Frequency micro electro\nmechanical systems) sensing devices such as micro-switches, tunable capacitors\nbecause it offers lower power consumption, lower losses, higher linearity and\nhigher Q factors compared with conventional communications components. To\naccelerate commercialisation of RF MEMS products, development for packaging\ntechnologies is one of the most critical issues should be solved beforehand.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3297v1"
    },
    {
        "title": "Recent Developments in Mems-Based Micro Fuel Cells",
        "authors": [
            "T. Pichonat",
            "B. Gauthier-Manuel"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Micro fuel cells ($\\mu$-FC) represent promising power sources for portable\napplications. Today, one of the technological ways to make $\\mu$-FC is to have\nrecourse to standard microfabrication techniques used in the fabrication of\nmicro electromechanical systems (MEMS). This paper shows an overview on the\napplications of MEMS techniques on miniature FC by presenting several solutions\ndeveloped throughout the world. It also describes the latest developments of a\nnew porous silicon-based miniature fuel cell. Using a silane grafted on an\ninorganic porous media as the proton-exchange membrane instead of a common\nionomer such as Nafion, the fuel cell achieved a maximum power density of 58 mW\ncm-2 at room temperature with hydrogen as fuel.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3298v1"
    },
    {
        "title": "Influence of Micro-Cantilever Geometry and Gap on Pull-in Voltage",
        "authors": [
            "W. Faris",
            "H. Mohammed",
            "M. M. Abdalla",
            "C. -H. Ling"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this paper, we study the behaviour of a microcantilever beam under\nelectrostatic actuation using finite difference method. This problem has a lot\nof applications in MEMS based devices like accelerometers, switches and others.\nIn this paper, we formulated the problem of a cantilever beam with proof mass\nat its end and carried out the finite difference solution. we studied the\neffects of length, width, and the gap size on the pull-in voltage using data\nthat are available in the literature. Also, the stability limit is compared\nwith the single degree of freedom commonly used in the earlier literature as an\napproximation to calculate the pull-in voltage.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3299v1"
    },
    {
        "title": "Design and Development of Novel Electroplating Spring Frame Mems\n  Structure Specimens for the Microtensile Testing of Thin Film Materials",
        "authors": [
            "Ming-Tzer Lin",
            "Chi-Jia Tong",
            "Chung-Hsun Chiang"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Microelectromechanical systems (MEMS) technologies are developing rapidly\nwith increasing study of the design, fabrication and commercialization of\nmicroscale systems and devices. Accurate mechanical properties are important\nfor successful design and development of MEMS. We have demonstrated here a\nnovel electroplating spring frame MEMS Structure Specimen integrates pin-pin\nalign holes, misalignment compensate spring structure frame, load sensor beam\nand freestanding thin film. The specimen can be fit into a specially designed\nmicrotensile apparatus which is capable of carrying out a series of tests on\nsub-micro scale freestanding thin films.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3300v1"
    },
    {
        "title": "Characterisation of the Etching Quality in Micro-Electro-Mechanical\n  Systems by Thermal Transient Methodology",
        "authors": [
            "P. Szabo",
            "B. Nemeth",
            "M. Rencz",
            "B. Courtois"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Our paper presents a non-destructive thermal transient measurement method\nthat is able to reveal differences even in the micron size range of MEMS\nstructures. Devices of the same design can have differences in their\nsacrificial layers as consequence of the differences in their manufacturing\nprocesses e.g. different etching times. We have made simulations examining how\nthe etching quality reflects in the thermal behaviour of devices. These\nsimulations predicted change in the thermal behaviour of MEMS structures having\ndifferences in their sacrificial layers. The theory was tested with\nmeasurements of similar MEMS devices prepared with different etching times. In\nthe measurements we used the T3Ster thermal transient tester equipment. The\nresults show that deviations in the devices, as consequence of the different\netching times, result in different temperature elevations and manifest also as\nshift in time in the relevant temperature transient curves.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3301v1"
    },
    {
        "title": "The Effects of Additives on the Physical Properties of Electroformed\n  Nickel and on the Stretch of Photoelectroformed Nickel Components",
        "authors": [
            "D. Allen",
            "N. Duclos",
            "I. Garbutt",
            "M. Saumer",
            "Ch. Dhum",
            "M. Schmitt",
            "J. E. Hoffmann"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The process of nickel electroforming is becoming increasingly important in\nthe manufacture of MST products, as it has the potential to replicate complex\ngeometries with extremely high fidelity. Electroforming of nickel uses\nmulti-component electrolyte formulations in order to maximise desirable product\nproperties. In addition to nickel sulphamate (the major electrolyte component),\nformulation additives can also comprise nickel chloride (to increase nickel\nanode dissolution), sulphamic acid (to control pH), boric acid (to act as a pH\nbuffer), hardening/levelling agents (to increase deposit hardness and lustre)\nand wetting agents (to aid surface wetting and thus prevent gas bubbles and\nvoid formation). This paper investigates the effects of some of these variables\non internal stress and stretch as a function of applied current density.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3302v1"
    },
    {
        "title": "A Novel Contact Resistance Model of Anisotropic Conductive Film for FPD\n  Packaging",
        "authors": [
            "Gou-Jen Wang",
            "Yi-Chin Lin",
            "Gwo-Sen Lin"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this research, a novel contact resistance model for the flat panel display\n(FPD) packaging based on the within layer parallel and between layers series\nresistance concepts was proposed. The FJ2530 anisotropic conductive films (ACF)\nby Sony Inc. containing the currently smallest 3micron conductive particles was\nused to conduct the experiments to verify the accuracy of the proposed model.\nCalculated resistance of the chip-on-glass (COG) packaging by the proposed\nmodel is 0.163\\Omega. It is found that the gold bump with 0.162\\Omega\nresistance play the major role of the overall resistance. Although the\npredicted resistance by the proposed model is only one third of the\nexperimentally measured value, it has been three-fold improvement compared to\nthe existing models.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3304v1"
    },
    {
        "title": "Measurement Technique for Elastic and Mechanical Properties of\n  Polycrystalline Silicon-Germanium Films Using Surface Acoustic Waves and\n  Projection Masks",
        "authors": [
            "A. Bennis",
            "C. Leinenbach",
            "C. Raudzis",
            "R. Mller-Fiedler",
            "S. Kronmller"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Using Rayleigh surface acoustic waves (SAW), the Young's modulus, the density\nand the thickness of polycrystalline Silicon-Germanium (SiGe) films deposited\non silicon and SiO2 were measured, in excellent agreement with theory. The\ndispersion curve of the propagating SAW is calculated with a Boundary Element\nMethod (BEM)-Model based on Green's functions. The propagating SAW is generated\nwith a nanosecond laser in a narrowband scheme projecting stripes from a mask\non the surface of the sample. For this purpose a glass mask and a liquid\ncrystal display (LCD) mask are used. The slope of the SAW is then measured\nusing a probe beam setup. From the wavelength of the mask and the frequency of\nthe measured SAW, the dispersion curve is determined point by point. Fitting\nthe BEM-Model to the measured nonlinear dispersion curve provides several\nphysical parameters simultaneously. In the present work this is demonstrated\nfor the Young's modulus, the density and the thickness of SiGe films. The\nresults from the narrowband scheme measurement are in excellent agreement with\nseparated measurements of the thickness (profilometer), the density (balance)\nand the Young's modulus (nanoindenter).\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3305v1"
    },
    {
        "title": "Effect of Surface Finish of Substrate on Mechanical Reliability of\n  in-48SN Solder Joints in Moems Package",
        "authors": [
            "Ja-Myeong Koo",
            "Seung-Boo Jung"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Interfacial reactions and shear properties of the In-48Sn (in wt.%) ball grid\narray (BGA) solder joints after bonding were investigated with four different\nsurface finishes of the substrate over an underlying Cu pad: electroplated\nNi/Au (hereafter E-NG), electroless Ni/immersion Au (hereafter ENIG), immersion\nAg (hereafter I-Ag) and organic solderability preservative (hereafter OSP).\nDuring bonding, continuous AuIn2, Ni3(Sn,In)4 and Cu6(Sn,In)5 intermetallic\ncompound (IMC) layers were formed at the solder/E-NG, solder/ENIG and\nsolder/OSP interface, respectively. The interfacial reactions between the\nsolder and I-Ag substrate during bonding resulted in the formation of\nCu6(Sn,In)5 and Cu(Sn,In)2 IMCs with a minor Ag element. The In-48Sn/I-Ag\nsolder joint showed the best shear properties among the four solder joints\nafter bonding, whereas the solder/ENIG solder joint exhibited the weakest\nmechanical integrity.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3306v1"
    },
    {
        "title": "Non Linear Techniques for Increasing Harvesting Energy from\n  Piezoelectric and Electromagnetic Micro-Power-Generators",
        "authors": [
            "Yasser Ammar",
            "S. Basrour"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Non-linear techniques are used to optimize the harvested energy from\npiezoelectric and electromagnetic generators. This paper introduces an\nanalytical study for the voltage amplification obtained from these techniques.\nThe analytical study is experimentally validated using a macro model of\npiezoelectric generator. Moreover, the integration influences on these\ntechniques is studied. Through all the obtained results, a suitable structure\nfor autonomous microsystems is proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3308v1"
    },
    {
        "title": "Optimization of Piezoelectric Electrical Generators Powered by Random\n  Vibrations",
        "authors": [
            "E. Lefeuvre",
            "A. Badel",
            "C. Richard",
            "L. Petit",
            "D. Guyomar"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper compares the performances of a vibrationpowered electrical\ngenerators using PZT piezoelectric ceramic associated to two different power\nconditioning circuits. A new approach of the piezoelectric power conversion\nbased on a nonlinear voltage processing is presented and implemented with a\nparticular power conditioning circuit topology. Theoretical predictions and\nexperimental results show that the nonlinear processing technique may increase\nthe power harvested by a factor up to 4 compared to the Standard optimization\ntechnique. Properties of this new technique are analyzed in particular in the\ncase of broadband, random vibrations, and compared to those of the Standard\ninterface.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3309v1"
    },
    {
        "title": "Power Processing Circuits for Mems Inertial Energy Scavengers",
        "authors": [
            "P. -D. Mitcheson",
            "T. -C. Green",
            "E. -M. Yeatman"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Inertial energy scavengers are self-contained devices which generate power\nfrom ambient motion, by electrically damping the internal motion of a suspended\nproof mass. There are significant challenges in converting the power generated\nfrom such devices to useable form, particularly in micro-engineered variants.\nThis paper presents approaches to this power conversion requirement, with\nemphasis on the cases of electromagnetic and electrostatic transduction.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3311v1"
    },
    {
        "title": "Motion-Based Generators for Industrial Applications",
        "authors": [
            "T. Sterken",
            "P. Fiorini",
            "R. Puers"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Scaling down of electronic systems has generated a large interest in the\nresearch on miniature energy sources. In this paper a closer look is given to\nthe use of vibration based scavengers in industrial environments, where waste\nenergy is abundantly available as engine related vibrations or large amplitude\nmotions. The modeling of mechanical generators resulted in the design and\nrealization of two prototypes, based on electromagnetic and electrostatic\nconversion of energy. Although the prototypes are not yet optimized against\nsize and efficiency, a power of 0.3 mW has been generated in a 5 Hz motion with\na 0.5 meter amplitude.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3312v1"
    },
    {
        "title": "Design and Fabrication of a Micro Electrostatic Vibration-to-Electricity\n  Energy Converter",
        "authors": [
            "Yi Chiu",
            "Chiung-Ting Kuo",
            "Yu-Shan Chu"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents a micro electrostatic vibration-toelectricity energy\nconverter. For the 3.3 V supply voltage and 1cm2 chip area constraints, optimal\ndesign parameters were found from theoretical calculation and Simulink\nsimulation. In the current design, the output power is 200 $\\mu$W/cm2 for the\noptimal load of 8 M\\Omega. The device was fabricated in a silicon-on-insulator\n(SOI) wafer. Mechanical and electrical measurements were conducted. Residual\nparticles caused shortage of the variable capacitor and the output power could\nnot be measured. Device design and fabrication processes are being refined.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3313v1"
    },
    {
        "title": "Macro and Micro Scale Electromagnetic Kinetic Energy Harvesting\n  Generators",
        "authors": [
            "S. -P. Beeby",
            "M. -J. Tudor",
            "R. -N. Torah",
            "E. Koukharenko",
            "S. Roberts",
            "T. O'Donnell",
            "S. Roy"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper is concerned with generators that harvest electrical energy from\nthe kinetic energy present in the sensor nodes environment. These generators\nhave the potential to replace or augment battery power which has a limited\nlifetime and requires periodic replacement which limits the placement and\napplication of the sensor node.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3314v1"
    },
    {
        "title": "Impact of Thermal Behavior on Offset in a High-Q Gyroscope",
        "authors": [
            "Fei Duan",
            "J. Jiao",
            "Y. Wang"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this paper, CFD approach is used to simulate the thermal behavior in a\nsensitive high-Q gyroscope. The electromagnetically driving wires, in which AC\ncurrent flows, are treated as Joule heat sources in the model. We found that\nthe differences of temperature, pressure and velocity along the driving\ndirection and transversely across the proof masses increased as the gap height\nbetween the proof mass and top glass became smaller. Local pressure gradient is\nexpected to possibly enhance the impact of any imperfect led by MEMS processes\nor designs on the offset of our tuning fork type gyroscope, which has been\nexperimentally verified. A device with 200um gap gives a two-third offset down\ncompared with that of its counterpart with 50um gap.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3315v1"
    },
    {
        "title": "Scaling Effects for Electromagnetic Vibrational Power Generators",
        "authors": [
            "T. O'Donnell",
            "C. Saha",
            "S. -P. Beeby",
            "M. -J. Tudor"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper investigates how the power generated by electromagnetic based\nvibrational power generators scales with the dimension of the generator. The\neffects of scaling on the magnetic fields, the coil parameters and the\nelectromagnetic damping are presented. An analysis is presented for both\nwire-wound coil technology and micro-fabricated coils.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3316v1"
    },
    {
        "title": "A Generic Surface Micromachining Module for Mems Hermetic Packaging at\n  Temperatures Below 200 degrees C",
        "authors": [
            "R. Hellin-Rico",
            "J. -P. Celis",
            "K. Baert",
            "C. Van Hoof",
            "A. Witvrouw"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents the different processing steps of a new generic surface\nmicromachining module for MEMS hermetic packaging at temperatures around 180\ndegrees C based on nickel plating and photoresist sacrificial layers. The\nadvantages of thin film caps are the reduced thickness and area consumption and\nthe promise of being a low-cost batch process. Moreover, sealing happens by a\nreflow technique, giving the freedom of choosing the pressure and atmosphere\ninside the cavity. Sacrificial etch holes are situated above the device\nallowing shorter release times compared to the state-of-the-art. With the\nso-called over-plating process, small etch holes can be created in the membrane\nwithout the need of expensive lithography tools. The etch holes in the membrane\nhave been shown to be sufficiently small to block the sealing material to pass\nthrough, but still large enough to enable an efficient release.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3317v1"
    },
    {
        "title": "A Ku-Band Novel Micromachined Bandpass Filter with Two Transmission\n  Zeros",
        "authors": [
            "Zhang Yong",
            "Zhu Jian",
            "Yu Yuanwei",
            "Chen Chen",
            "Jia Shi Xing"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents a micromachined bandpass filter with miniature size that\nhas relatively outstanding performance. A silicon-based eight-order microstrip\nbandpass filter is fabricated and measured. A novel design method of the\ninterdigital filter that can create two transmission zeros is described. The\nlocation of the transmission zeros can be shifted arbitrarily in the stopband.\nBy adjusting the zero location properly, the filter provides much better skirt\nrejection and lower insertion loss than a conventional microstrip interdigital\nfilter. To reduce the chip size, through-silicon-substrate-via-hole is used.\nGood experimental results are obtained.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3318v1"
    },
    {
        "title": "The Design and Fabrication of Platform Device for Dna Amplification",
        "authors": [
            "Ch. -Heng Chien",
            "Hui-Min Yu"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Thermalcycler were extensively used machine for amplify DNA sample. One of\nthe major problems in the working time was that it spent most of time for\ncooling and heating. In order to improve the efficient, this study presented a\nnovel method for amplify DNA sample. For this concept, the DNA sample in the\nsilicon chamber which was pushed by a beam through three temperature regions\naround a center and then the DNA segments could be amplified rapidly after 30\ncycles. The polymerase chain reaction platform was composed of thin-film\nheaters, copper plates, DC powers, and temperature controllers. The\nphotolithography and bulk etching technologies were utilized to construct the\nthin-film heater and DNA reaction chambers. Finally, 1 pound gL 100bp DNA\nsegment of E. coli K12 was amplified successfully within 36 minutes on this PCR\nplatform.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3319v1"
    },
    {
        "title": "Design and Modeling of a Mems-Based Valveless Pump Driven by an\n  Electromagnetic Force",
        "authors": [
            "Hsien-Tsung Chang",
            "Chia-Yen Lee",
            "Chih-Yung Wen"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  A novel valveless micro impedance pump is proposed and analyzed in this\nstudy.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3320v1"
    },
    {
        "title": "Electrostatic Actuators Operating in Liquid Environment : Suppression of\n  Pull-in Instability and Dynamic Response",
        "authors": [
            "A. -S. Rollier",
            "M. Faucher",
            "B. Legrand",
            "D. Collard",
            "L. Buchaillot"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents results about fabrication and operation of electrostatic\nactuators in liquids with various permittivities. In the static mode, we\nprovide experimental and theoretical demonstration that the pull-in effect can\nbe shifted beyond one third of the initial gap and even be eliminated when\nelectrostatic actuators are operated in liquids. This should benefit to\napplications in microfluidics requiring either binary state actuation (e.g.\npumps, valves) or continuous displacements over the whole gap (e.g.\nmicrotweezers). In dynamic mode, actuators like micro-cantilevers present a\ngreat interest for Atomic Force Microscopy (AFM) in liquids. As this\napplication requires a good understanding of the cantilever resonance frequency\nand Q-factor, an analytical modeling in liquid environment has been\nestablished. The theoretically derived curves are validated by experimental\nresults using a nitride encapsulated cantilever with integrated electrostatic\nactuation. Electrode potential screening and undesirable electrochemistry in\ndielectric liquids are counteracted using AC-voltages. Both experimental and\ntheoretical results should prove useful in micro-cantilever design for AFM in\nliquids.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3321v1"
    },
    {
        "title": "Au-SN Flip-Chip Solder Bump for Microelectronic and Optoelectronic\n  Applications",
        "authors": [
            "Jeong-Won Yoon",
            "H. -S. Chun",
            "Ja-Myeong Koo",
            "Seung-Boo Jung"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  As an alternative to the time-consuming solder pre-forms and pastes currently\nused, a co-electroplating method of eutectic Au-Sn alloy was used in this\nstudy. Using a co-electroplating process, it was possible to plate the Au-Sn\nsolder directly onto a wafer at or near the eutectic composition from a single\nsolution. Two distinct phases, Au5Sn and AuSn, were deposited at a composition\nof 30at.%Sn. The Au-Sn flip-chip joints were formed at 300 and 400 degrees\nwithout using any flux. In the case where the samples were reflowed at 300\ndegrees, only an (Au,Ni)3Sn2 IMC layer formed at the interface between the\nAu-Sn solder and Ni UBM. On the other hand, two IMC layers, (Au,Ni)3Sn2 and\n(Au,Ni)3Sn, were found at the interfaces of the samples reflowed at 400\ndegrees. As the reflow time increased, the thickness of the (Au,Ni)3Sn2 and\n(Au,Ni)3Sn IMC layers formed at the interface increased and the eutectic\nlamellae in the bulk solder coarsened.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3323v1"
    },
    {
        "title": "Contactless Thermal Characterization Method of PCB-s Using an IR Sensor\n  Array",
        "authors": [
            "Gy. Bognar",
            "V. Szekely",
            "M. Rencz"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this paper the feasibility study of an IR sensor card is presented. The\nmethodology and the results of a quasi real-time thermal characterization tool\nand method for the temperature mapping of circuits and boards based on sensing\nthe infrared radiation is introduced. With the proposed method the IR\nradiation-distribution of boards from the close proximity of the sensor card is\nmonitored in quasi real-time. The proposed method is enabling in situ IR\nmeasurement among operating cards of a system e.g. in a rack.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3324v1"
    },
    {
        "title": "Miniaturized Fluorescence Excitation Platform with Optical Fiber for\n  Bio-Detection Chips",
        "authors": [
            "Hsiharng Yang",
            "Chung-Tze Lee"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents a new research study on the platform fabrication of\nfluorescence bio-detection chip with an optical fiber transmission. Anisotropic\nwet etching on (100) silicon wafers to fabrication V-groove for optical fiber\nalignment and micro-mirror were included. Combing with anodic bonding technique\nto adhere glass, silicon structure and optical fiber for a fluorescence\nexcitation platform was completed. In this study, the etching solution 40% KOH\nwas used to study the parameters effect. The results show that working\ntemperature is the main parameter to significantly effect the etch rate. The\nanisotropic etching resulted 54.7 degrees reflective mirrors and its\nreflectivity for optical beam were also examined. The surface roughness of the\nmicro-mirror is Ra 4.1 nm measured using AFM, it provides excellent optical\nreflection. The incident light and beam profiles were also examined for further\nstudy. This study can show this micro-platform adaptable for fluorescence\nbio-detection.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3325v1"
    },
    {
        "title": "Characterization of Flexible RF Microcoil Dedicated to Surface Mri",
        "authors": [
            "M. Woytasik",
            "J. -C. Ginefri",
            "J. -S. Raynaud",
            "M. Poirier-Quinot",
            "E. Dufour-Gergam",
            "J. -P. Grandchamp",
            "L. Darrasse",
            "P. Robert",
            "J. -P. Gilles",
            "E. Martincic",
            "O. Girard"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In Magnetic Resonance Imaging (MRI), to achieve sufficient Signal to Noise\nRatio (SNR), the electrical performance of the RF coil is critical. We\ndeveloped a device (microcoil) based on the original concept of monolithic\nresonator. This paper presents the used fabrication process based on\nmicromoulding. The dielectric substrates are flexible thin films of polymer,\nwhich allow the microcoil to be form fitted to none-plane surface. Electrical\ncharacterizations of the RF coils are first performed and results are compared\nto the attempted values. Proton MRI of a saline phantom using a flexible RF\ncoil of 15 mm in diameter is performed. When the coil is conformed to the\nphantom surface, a SNR gain up to 2 is achieved as compared to identical but\nplanar RF coil. Finally, the flexible coil is used in vivo to perform MRI with\nhigh spatial resolution on a mouse using a small animal dedicated scanner\noperating at in a 2.35 T.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3326v1"
    },
    {
        "title": "Integration of Micro-Electro-Mechanical Deformable Mirrors in Doped\n  Fiber Amplifiers",
        "authors": [
            "D. Bouyge",
            "D. Sabourdy",
            "A. Crunteanu",
            "P. Blondy",
            "V. Couderc",
            "J. Lhermite",
            "L. Grossard",
            "A. Barthlemy"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  We present a simple technique to produce active Q-switching in various types\nof fiber amplifiers by active integration of an electrostatic actuated\ndeformable metallic micro-mirror. The optical MEMS (MOEMS) device acts as one\nof the laser cavity reflectors and, at the same time, as switching/ modulator\nelement. We aim to obtain laser systems emitting short, high-power pulses and\nhaving variable repetition rate. The electro-mechanical behavior of membrane\n(bridge-type) was simulated by using electrostatic and modal 3D finite element\nanalysis (FEA). The results of the simulations fit well with the experimental\nmechanical, electrical and thermal measurements of the components. In order to\ndecrease the sensitiveness to fiber-mirror alignment we are developing novel\noptical devices based on stressed-metal cantilever-type geometry that allow\ndeflections up to 50 $\\mu$m with increased reflectivity discrimination during\nactuation.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3327v1"
    },
    {
        "title": "Micro-Ball Lens Array Fabrication in Photoresist Using Ptfe Hydrophobic\n  Effect",
        "authors": [
            "Ruey-Fang Shyu",
            "Hsiharng Yang",
            "Wen-Ren Tsai",
            "Jhy-Cherng Tsai"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper presents a simple method to fabricate micro-ball lens and its\narray. The key technology is to use the hydrophobic characteristics of\npolyterafluoroethylene (PTFE) substrate. High contact angle between melted\nphotoresist pattern and PTFE can generate micro-ball lens and its array. PTFE\nthin film was spun onto a silicon wafer and dried in oven. Photoresist AZ4620\nwas used to pattern micro-columns with different diameters 60, 70 and 80\n$\\mu$m. A thermal reflow process then was applied to melt these micro-column\npatterns resulted in micro-ball lens array. The achieved micro-ball lens array\nwith diameter 98 $\\mu$m was fabricated using 80 $\\mu$m in diameter patterns.\nThis method provides a simple fabrication process and low material cost.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3329v1"
    },
    {
        "title": "Reduced-Order Modelling of the Bending of an Array of Torsional\n  Micromirrors",
        "authors": [
            "A. Molfese",
            "A. Nannini",
            "F. Pieri"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Reduced-Order Modelling of the Bending of an Array of An array of\nmicromirrors for beam steering optical switching has been designed in a thick\npolysilicon technology. A novel semi-analytical method to calculate the static\ncharacteristics of the micromirrors by taking into account the flexural\ndeformation of the structure is presented. The results are compared with 3D\ncoupled-field FEM simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3330v1"
    },
    {
        "title": "Model of Electrostatic Actuated Deformable Mirror Using Strongly Coupled\n  Electro-Mechanical Finite Element",
        "authors": [
            "V. Rochus",
            "J. -C. Golinval",
            "C. Louis",
            "C. Mendez",
            "I. Klapka"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The aim of this paper is to deal with multi-physics simulation of\nmicro-electro-mechanical systems (MEMS) based on an advanced numerical\nmethodology. MEMS are very small devices in which electric as well as\nmechanical and fluid phenomena appear and interact. Because of their\nmicroscopic scale, strong coupling effects arise between the different physical\nfields, and some forces, which were negligible at macroscopic scale, have to be\ntaken into account. In order to accurately design such micro-electro-mechanical\nsystems, it is of primary importance to be able to handle the strong coupling\nbetween the electric and the mechanical fields. In this paper, the finite\nelement method (FEM) is used to model the strong coupled electro-mechanical\ninteractions and to perform static and transient analyses taking into account\nlarge mesh displacements. These analyses will be used to study the behaviour of\nelectrostatically actuated micro-mirrors.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3331v1"
    },
    {
        "title": "New Internal Stress Driven on-Chip Micromachines for Extracting\n  Mechanical Properties of Thin Films",
        "authors": [
            "D. Fabrgue",
            "Nicolas Andr",
            "T. Pardoen",
            "J. P. Raskin"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  A new concept of micromachines has been developed for measuring the\nmechanical properties of thin metallic films. The actuator is a beam undergoing\nlarge internal stresses built up during the deposition process. Al thin films\nare deposited partly on the actuator beam and on the substrate. By etching the\nstructure, the actuator contracts and pulls the Al film. Full stress strain\ncurves can be generated by designing a set of micromachines with various\nactuator lengths. In the present study, the displacements have been measured by\nscanning electronic microscopy. The stress is derived from simple continuum\nmechanics relationships. The tensile properties of Al films of various\nthicknesses have been tested. A marked increase of the strength with decreasing\nfilm thickness is observed.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3332v1"
    },
    {
        "title": "Process Issues for a Multi-Layer Microelectrofluidic Platform",
        "authors": [
            "S. -H. Ng",
            "Z. -F. Wang",
            "R. -T. Tjeung",
            "N. De Rooij"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  We report on the development of some process capabilities for a\npolymer-based, multi-layer microelectrofluidic platform, namely: the hot\nembossing process, metallization on polymer and polymer bonding. Hot embossing\nexperiments were conducted to look at the effects of load applied, embossing\ntemperature and embossing time on the fidelity of line arrays representing\nmicro channels. The results revealed that the embossing temperature is a more\nsensitive parameter than the others due to its large effect on the polymer\nmaterial's viscoelastic properties. Dynamic mechanical analysis (DMA) on\npolymethyl methacrylate (PMMA) revealed a steep glass transition over a 20 oC\nrange, with the material losing more than 95 % of its storage modulus. The data\nexplained the hot embossing results which showed large change in the embossed\nchannel dimensions when the temperature is within the glass transition range.\nIt was demonstrated that the micro-printing of silver epoxy is a possible\nlow-cost technique in the mass production of disposable lab chips. An\ninterconnecting network of electrical traces was fabricated in the form of a\nfour-layer PMMA-based device. A four PMMA layer device with interconnecting\nmicrofluidic channels was also fabricated and tested.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3333v1"
    },
    {
        "title": "Fabrication of Switches on Polymer-Based by Hot Embossing",
        "authors": [
            "Chao-Heng Chien",
            "Hui-Min Yu"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In MEMS technology, most of the devices are fabricated on glass or silicon\nsubstrate. However, this research presents a novel manufacture method that is\nderived from conventional hot embossing technology to fabricate the\nelectrostatic switches on polymer material. The procedures of fabrication\ninvolve the metal deposition, photolithography, electroplating, hot embossing\nand hot embed techniques. The fundamental concept of the hot embed technology\nis that the temperature should be increased above Tg of polymer, and the\npolymer becomes plastic and viscous and could be molded. According to the\nfundamental concept, the metal layer on the silicon/glass substrate could be\nembedded into polymer material during the hot embossing process. Afterward, the\nmetal layer is bonded together with the polymer after removing the substrate in\nthe de-embossing step. Finally, the electrostatic switch is fabricated on\npolymethylmethacrylate(PMMA) material to demonstrate the novel method.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3334v1"
    },
    {
        "title": "A New Model of Fringing Capacitance and its Application to the Control\n  of Parallel-Plate Electrostatic Micro Actuators",
        "authors": [
            "M. Hosseini",
            "G. Zhu",
            "Y. -A. Peter"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Fringing field has to be taken into account in the formulation of\nelectrostatic parallel-plate actuators when the gap separating the electrodes\nis comparable to the geometrical dimensions of the moving plate. Even in this\ncase, the existing formulations often result in complicated mathematical models\nfrom which it is difficult to determine the deflection of the moving plate for\ngiven voltages and therefore to predict the necessary applied voltages for\nactuation control. This work presents a new method for the modeling of fringing\nfield, in which the effect of fringing field is modeled as a serial capacitor.\nNumerical simulation demonstrates the suitability of this formulation. Based on\nthis model, a robust control scheme is constructed using the theory of\ninput-to-state stabilization (ISS) and back-stepping state feedback design. The\nstability and the performance of the system using this control scheme are\ndemonstrated through both stability analysis and numerical simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.3335v1"
    },
    {
        "title": "Fluoroscopy-based navigation system in spine surgery",
        "authors": [
            "Philippe Merloz",
            "Jocelyne Troccaz",
            "Herv Vouaillat",
            "Christian Vasile",
            "Jrme Tonetti",
            "Ahmad Eid",
            "Stphane Plaweski"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The variability in width, height, and spatial orientation of a spinal pedicle\nmakes pedicle screw insertion a delicate operation. The aim of the current\npaper is to describe a computer-assisted surgical navigation system based on\nfluoroscopic X-ray image calibration and three-dimensional optical localizers\nin order to reduce radiation exposure while increasing accuracy and reliability\nof the surgical procedure for pedicle screw insertion. Instrumentation using\ntranspedicular screw fixation was performed: in a first group, a conventional\nsurgical procedure was carried out with 26 patients (138 screws); in a second\ngroup, a navigated surgical procedure (virtual fluoroscopy) was performed with\n26 patients (140 screws). Evaluation of screw placement in every case was done\nby using plain X-rays and post-operative computer tomography scan. A 5 per cent\ncortex penetration (7 of 140 pedicle screws) occurred for the computer-assisted\ngroup. A 13 per cent penetration (18 of 138 pedicle screws) occurred for the\nnon computer-assisted group. The radiation running time for each vertebra level\n(two screws) reached 3.5 s on average in the computer-assisted group and 11.5 s\non average in the non computer-assisted group. The operative time for two\nscrews on the same vertebra level reaches 10 min on average in the non\ncomputer-assisted group and 11.9 min on average in the computer-assisted group.\nThe fluoroscopy-based (two-dimensional) navigation system for pedicle screw\ninsertion is a safe and reliable procedure for surgery in the lower thoracic\nand lumbar spine.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.4516v1"
    },
    {
        "title": "Robot-based tele-echography: clinical evaluation of the TER system in\n  abdominal aortic exploration",
        "authors": [
            "Thomas Martinelli",
            "Jean-Luc Bosson",
            "Luc Bressollette",
            "Franck Pelissier",
            "Eric Boidard",
            "Jocelyne Troccaz",
            "Philippe Cinquin"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  OBJECTIVE: The TER system is a robot-based tele-echography system allowing\nremote ultrasound examination. The specialist moves a mock-up of the ultrasound\nprobe at the master site, and the robot reproduces the movements of the real\nprobe, which sends back ultrasound images and force feedback. This tool could\nbe used to perform ultrasound examinations in small health care centers or from\nisolated sites. The objective of this study was to prove, under real\nconditions, the feasibility and reliability of the TER system in detecting\nabdominal aortic and iliac aneurysms. METHODS: Fifty-eight patients were\nincluded in 2 centers in Brest and Grenoble, France. The remote examination was\ncompared with the reference standard, the bedside examination, for aorta and\niliac artery diameter measurement, detection and description of aneurysms,\ndetection of atheromatosis, the duration of the examination, and acceptability.\nRESULTS: All aneurysms (8) were detected by both techniques as intramural\nthrombosis and extension to the iliac arteries. The interobserver correlation\ncoefficient was 0.982 (P < .0001) for aortic diameters. The rate of concordance\nbetween 2 operators in evaluating atheromatosis was 84% +/- 11% (95% confidence\ninterval). CONCLUSIONS: Our study on 58 patients suggests that the TER system\ncould be a reliable, acceptable, and effective robot-based system for\nperforming remote abdominal aortic ultrasound examinations. Research is\ncontinuing to improve the equipment for general abdominal use.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.4523v1"
    },
    {
        "title": "Development of miniaturized light endoscope-holder robot for\n  laparoscopic surgery",
        "authors": [
            "Jean-Alexandre Long",
            "Philippe Cinquin",
            "Jocelyne Troccaz",
            "Sandrine Voros",
            "Jean-Luc Descotes",
            "Peter Berkelman",
            "Christian Letoublon",
            "Jean-Jacques Rambeaud"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  PURPOSE: We have conducted experiments with an innovatively designed robot\nendoscope holder for laparoscopic surgery that is small and low cost. MATERIALS\nAND METHODS: A compact light endoscope robot (LER) that is placed on the\npatient's skin and can be used with the patient in the lateral or dorsal supine\nposition was tested on cadavers and laboratory pigs in order to allow\nsuccessive modifications. The current control system is based on voice\nrecognition. The range of vision is 360 degrees with an angle of 160 degrees .\nTwenty-three procedures were performed. RESULTS: The tests made it possible to\nadvance the prototype on a variety of aspects, including reliability,\nsteadiness, ergonomics, and dimensions. The ease of installation of the robot,\nwhich takes only 5 minutes, and the easy handling made it possible for 21 of\nthe 23 procedures to be performed without an assistant. CONCLUSION: The LER is\na camera holder guided by the surgeon's voice that can eliminate the need for\nan assistant during laparoscopic surgery. The ease of installation and\nmanufacture should make it an effective and inexpensive system for use on\npatients in the lateral and dorsal supine positions. Randomized clinical trials\nwill soon validate a new version of this robot prior to marketing.\n",
        "pdf_link": "http://arxiv.org/pdf/0711.4944v1"
    },
    {
        "title": "Prostate biopsies guided by three-dimensional real-time (4-D)\n  transrectal ultrasonography on a phantom: comparative study versus\n  two-dimensional transrectal ultrasound-guided biopsies",
        "authors": [
            "Jean-Alexandre Long",
            "Vincent Daanen",
            "Alexandre Moreau-Gaudry",
            "Jocelyne Troccaz",
            "Jean-Jacques Rambeaud",
            "Jean-Luc Descotes"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  OBJECTIVE: This study evaluated the accuracy in localisation and distribution\nof real-time three-dimensional (4-D) ultrasound-guided biopsies on a prostate\nphantom. METHODS: A prostate phantom was created. A three-dimensional real-time\nultrasound system with a 5.9MHz probe was used, making it possible to see\nseveral reconstructed orthogonal viewing planes in real time. Fourteen\noperators performed biopsies first under 2-D then 4-D transurethral ultrasound\n(TRUS) guidance (336 biopsies). The biopsy path was modelled using segmentation\nin a 3-D ultrasonographic volume. Special software was used to visualise the\nbiopsy paths in a reference prostate and assess the sampled area. A comparative\nstudy was performed to examine the accuracy of the entry points and target of\nthe needle. Distribution was assessed by measuring the volume sampled and a\nredundancy ratio of the sampled prostate. RESULTS: A significant increase in\naccuracy in hitting the target zone was identified using 4-D ultrasonography as\ncompared to 2-D. There was no increase in the sampled volume or improvement in\nthe biopsy distribution with 4-D ultrasonography as compared to 2-D.\nCONCLUSION: The 4-D TRUS guidance appears to show, on a synthetic model, an\nimprovement in location accuracy and in the ability to reproduce a protocol.\nThe biopsy distribution does not seem improved.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.0531v1"
    },
    {
        "title": "Knowledge Engineering Technique for Cluster Development",
        "authors": [
            "Pradorn Sureephong",
            "Nopasit Chakpitak",
            "Yacine Ouzrout",
            "Gilles Neubert",
            "Abdelaziz Bouras"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  After the concept of industry cluster was tangibly applied in many countries,\nSMEs trended to link to each other to maintain their competitiveness in the\nmarket. The major key success factors of the cluster are knowledge sharing and\ncollaboration between partners. This knowledge is collected in form of tacit\nand explicit knowledge from experts and institutions within the cluster. The\nobjective of this study is about enhancing the industry cluster with knowledge\nmanagement by using knowledge engineering which is one of the most important\nmethod for managing knowledge. This work analyzed three well known knowledge\nengineering methods, i.e. MOKA, SPEDE and CommonKADS, and compares the\ncapability to be implemented in the cluster context. Then, we selected one\nmethod and proposed the adapted methodology. At the end of this paper, we\nvalidated and demonstrated the proposed methodology with some primary result by\nusing case study of handicraft cluster in Thailand.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.1994v1"
    },
    {
        "title": "MRI/TRUS data fusion for brachytherapy",
        "authors": [
            "V. Daanen",
            "J. Gastaldo",
            "J. Y. Giraud",
            "P. Fourneret",
            "J. L. Descotes",
            "M. Bolla",
            "D. Collomb",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  BACKGROUND: Prostate brachytherapy consists in placing radioactive seeds for\ntumour destruction under transrectal ultrasound imaging (TRUS) control. It\nrequires prostate delineation from the images for dose planning. Because\nultrasound imaging is patient- and operator-dependent, we have proposed to fuse\nMRI data to TRUS data to make image processing more reliable. The technical\naccuracy of this approach has already been evaluated. METHODS: We present work\nin progress concerning the evaluation of the approach from the dosimetry\nviewpoint. The objective is to determine what impact this system may have on\nthe treatment of the patient. Dose planning is performed from initial TRUS\nprostate contours and evaluated on contours modified by data fusion. RESULTS:\nFor the eight patients included, we demonstrate that TRUS prostate volume is\nmost often underestimated and that dose is overestimated in a correlated way.\nHowever, dose constraints are still verified for those eight patients.\nCONCLUSIONS: This confirms our initial hypothesis.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.2099v1"
    },
    {
        "title": "Cell mapping description for digital control system with quantization\n  effect",
        "authors": [
            "Wang Liang",
            "Wang Bing-wen",
            "Guo Yi-Ping"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Quantization problem in digital control system have attracted more and more\nattention in these years. Normally, a quantized variable is regarded as a\nperturbed copy of the unquantized variable in the research of quantization\neffect, but this model has shown many obvious disadvantages in control system\nanalysis and design process. In this paper, we give a new model for\nquantization based 'cell mapping' concept. This cell model could clearly\ndescribe the global dynamics of quantized digital system. Then some important\ncharacteristics of control system like controllability are analyzed by this\nmodel. The finite precision control design method based on cell concept is also\npresented.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.2501v2"
    },
    {
        "title": "Cyberspace security: How to develop a security strategy",
        "authors": [
            "Bel G. Raggad",
            "Sahbi Sidhom"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Despite all visible dividers, the Internet is getting us closer and closer,\nbut with a great price. Our security is the price. The international community\nis fully aware of the urgent need to secure the cyberspace as you see the\nmultiplication of security standards and national schemes interpreting them\nbeyond borders: ISO 15408, ISO 17799, and ISO 27001. Even though some\ncountries, including the Security Big Six (SB6), are equipped with their\nsecurity books and may feel relatively safe; this remains a wrong sense of\nsecurity as long as they share their networks with entities of less security.\nThe standards impose security best practices and system specifications for the\ndevelopment of information security management systems. Partners beyond borders\nhave to be secure as this is only possible if all entities connected to the\npartnership remain secure. Unfortunately, there is no way to verify the\ncontinuous security of partners without periodic security auditing and\ncertification, and members who do not comply should be barred from the\npartnership. This concept also applies to the cyber space or the electronic\nsociety. In order to clean our society from cyber crimes and cyber terrorism we\nneed to impose strict security policies and enforce them in a cooperative\nmanner. The paper discusses a country's effort in the development of a national\nsecurity strategy given its security economic intelligence position, its\nsecurity readiness, and its adverse exposure.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.4215v1"
    },
    {
        "title": "Partitioning the Threads of a Mobile System",
        "authors": [
            "Jrme Feret"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, we show how thread partitioning helps in proving properties of\nmobile systems. Thread partitioning consists in gathering the threads of a\nmobile system into several classes. The partitioning criterion is left as a\nparameter of both the mobility model and the properties we are interested in.\nThen, we design a polynomial time abstract interpretation-based static analysis\nthat counts the number of threads inside each partition class.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.0188v1"
    },
    {
        "title": "Structural aspects of tilings",
        "authors": [
            "Alexis Ballier",
            "Bruno Durand",
            "Emmanuel Jeandel"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, we study the structure of the set of tilings produced by any\ngiven tile-set. For better understanding this structure, we address the set of\nfinite patterns that each tiling contains. This set of patterns can be analyzed\nin two different contexts: the first one is combinatorial and the other\ntopological. These two approaches have independent merits and, once combined,\nprovide somehow surprising results. The particular case where the set of\nproduced tilings is countable is deeply investigated while we prove that the\nuncountable case may have a completely different structure. We introduce a\npattern preorder and also make use of Cantor-Bendixson rank. Our first main\nresult is that a tile-set that produces only periodic tilings produces only a\nfinite number of them. Our second main result exhibits a tiling with exactly\none vector of periodicity in the countable case.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.2828v1"
    },
    {
        "title": "Fabrication of Miniaturized Variable-focus Lens Using Liquid Filling\n  Technique",
        "authors": [
            "Hsiharng Yang",
            "Chung-Yao Yang",
            "Mau-Shiun Yeh"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper describes a simple method for fabricating a variable-focus lens by\nusing PDMS (polydimethylsiloxane) and filling with liquid for the\nvariable-focus lens. The lens diameter of 2-mm was designed in this experiment\nand expected to reach the focal length in the range of 3 ~ 12 mm. The\ntheoretical value between the liquid volume and the lens contact angle at\ndifferent focal lengths were simulated and measured. The pumped-in volumes\nranged from 200 to 1400 $\\mu$l, the contact angles ranged from 14.25 degrees to\n49.02 degrees. Changing the deformation of PDMS film using different\nmicro-fluidic volume produces the variable focal length from 4 10 mm in this\nexperiment. The proposed method successfully fabricated a variable-focus lens.\nBonding PDMS only once using no expensive instrument such as oxygen plasma was\naccomplished. The final objective is to insert the variable focus lens into\nportable optical imagery products.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3037v1"
    },
    {
        "title": "A Novel X-Axis Tuning Fork Gyroscope with \"8 Vertical Springs-Proofmass\"\n  Structure on (111)-Silicon",
        "authors": [
            "Fei Duan",
            "Jiwei Jiao",
            "Yucai Wang",
            "Ying Zhang",
            "Binwei Mi",
            "Jinpeng Li",
            "Jian Zhu",
            "Yuelin Wang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A novel x-axis tuning fork MEMS gyroscope with \"8 vertical springs-proofmass\"\nstructure for Coriolis effect detection is presented. Compared with the common\nsingle-plane springs, the 8 vertical springs, symmetrically located at the top\nand bottom sides, more stably suspend the large thick proofmass featuring large\ncapacitance variation and low mechanical noise. A bulk-micromachining\ntechnology is applied to obtain the large proofmass and twins-like dual beams.\nDuring the fabrication process, the dimensions of the 8 vertical springs are\nprecisely confined by thermal oxide protected limit trenches (LTs) sidewalls\nand the extreme slowly etched (111)-planes; therefore a small mismatch of less\nthan 30 Hz is achieved before tuning. Initial test shows a sensitivity of\n0.15mV/(deg/s) and rate resolution around 0.1deg/s under atmosphere pressure.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3038v1"
    },
    {
        "title": "Fabrication of MEMS Resonators in Thin SOI",
        "authors": [
            "D. Grogg",
            "Nicoleta Diana Badila-Ciressan",
            "Adrian Mihai Ionescu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A simple and fast process for micro-electromechanical (MEM) resonators with\ndeep sub-micron transduction gaps in thin SOI is presented in this paper. Thin\nSOI wafers are important for advanced CMOS technology and thus are evaluated as\nresonator substrates for future co-integration with CMOS circuitry on a single\nchip. As the transduction capacitance scales with the resonator thickness, it\nis important to fabricate deep sub-micron trenches in order to achieve a good\ncapacitive coupling. Through the combination of conventional UV-lithography and\nfocused ion beam (FIB) milling the process needs only two lithography steps,\nenabling therefore a way for fast prototyping of MEM-resonators. Different FIB\nparameters and etching parameters are compared in this paper and their effect\non the process are reported.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3040v1"
    },
    {
        "title": "Usage of Porous Al2O3 Layers for RH Sensing",
        "authors": [
            "Veronika Timr-Horvth",
            "Lszl Juhsz",
            "Andrs Vass-Vrnai",
            "Gergely Perlaky"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  At the Department of Electron Devices a cheap, more or less CMOS process\ncompatible capacitive type RH sensor has been developed. Capacitive sensors are\nbased on dielectric property changes of thin films upon water vapour uptake\nwhich depends on the surrounding media's relative humidity content. Because of\nthe immense surface-to-volume ratio and the abundant void fraction, very high\nsensitivities can be obtained with porous ceramics. One of the ceramics to be\nused is porous Al2O3, obtained by electrochemical oxidation of aluminium under\nanodic bias. The average pore sizes are between 6...9 nm. In our paper we\nintend to demonstrate images representing the influence of the technological\nparameters on the porous structure and the device sensitivity.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3041v1"
    },
    {
        "title": "Modeling of large area hot embossing",
        "authors": [
            "M. Worgull",
            "K. K. Kabanemi",
            "J. -P. Marcotte",
            "J. -F. Htu",
            "M. Heckele"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Today, hot embossing and injection molding belong to the established plastic\nmolding processes in microengineering. Based on experimental findings, a\nvariety of microstructures have been replicated so far using the processes.\nHowever, with increasing requirements regarding the embossing surface and the\nsimultaneous decrease of the structure size down into the nanorange, increasing\nknow-how is needed to adapt hot embossing to industrial standards. To reach\nthis objective, a German-Canadian cooperation project has been launched to\nstudy hot embossing theoretically by a process simulation and experimentally.\nThe present publication shall report about the first results of the simulation\n- the modeling and simulation of large area replication based on an eight inch\nmicrostructured mold.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3042v1"
    },
    {
        "title": "Liquid Density Sensing Using Resonant Flexural Plate Wave Device with\n  Sol-Gel PZT Thin Films",
        "authors": [
            "Jyh-Cheng Yu",
            "Huang-Yao Lin"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents the design, fabrication and preliminary experimental\nresults of a flexure plate wave (FPW) resonator using sol-gel derived lead\nzirconate titanates (PZT) thin films. The resonator adopts a two-port structure\nwith reflecting grates on the composite membrane of PZT and SiNx. The design of\nthe reflecting grate is derived from a SAW resonator model using COM theory to\nproduce a sharp resonant peak. The comparison between the mass and the\nviscosity effects from the theoretical expression illustrates the applications\nand the constraints of the proposed device in liquid sensing. Multiple coatings\nof sol-gel derived PZT films are adopted because of the cost advantage and the\nhigh electromechanical coupling effect over other piezoelectric films. The\nfabrication issues of the proposed material structure are addressed.\nTheoretical estimations of the mass and the viscosity effects are compared with\nthe experimental results. The resonant frequency has a good linear correlation\nwith the density of low viscosity liquids, which demonstrate the feasibility of\nthe proposed device.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3043v1"
    },
    {
        "title": "Design, Fabrication and Characterization of a Piezoelectric\n  Microgenerator Including a Power Management Circuit",
        "authors": [
            "M. Marzencki",
            "Y. Ammar",
            "S. Basrour"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  We report in this paper the design, fabrication and experimental\ncharacterization of a piezoelectric MEMS microgenerator. This device scavenges\nthe energy of ambient mechanical vibrations characterized by frequencies in the\nrange of 1 kHz. This component is made with Aluminum Nitride thin film\ndeposited with a CMOS compatible process. Moreover we analyze two possible\nsolutions for the signal rectification: a discrete doubler-rectifier and a full\ncustom power management circuit. The ASIC developed for this application takes\nadvantage of diodes with very low threshold voltage and therefore allows the\nconversion of extremely low input voltages corresponding to very weak input\naccelerations. The volume of the proposed generator is inferior to 1mm3 and the\ngenerated powers are in the range of 1$\\mu$W. This system is intended to supply\npower to autonomous wireless sensor nodes.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3044v1"
    },
    {
        "title": "A complete study of electroactive polymers for energy scavenging:\n  modelling and experiments",
        "authors": [
            "C. Jean-Mistral",
            "S. Basrour",
            "J. J. Chaillout",
            "A. Bonvilain"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Recent progresses in ultra low power microelectronics propelled the\ndevelopment of several microsensors and particularly the self powered\nmicrosystems (SPMS). One of their limitations is their size and their autonomy\ndue to short lifetime of the batteries available on the market. To ensure their\necological energetic autonomy, a promising alternative is to scavenge the\nambient energy such as the mechanical one. Nowadays, few microgenerators\noperate at low frequency. They are often rigid structures that can perturb the\napplication or the environment; none of them are perfectly flexible. Thus, our\nobjective is to create a flexible, non-intrusive scavenger using electroactive\npolymers. The goal of this work is to design a generator which can provide\ntypically 100 ?W to supply a low consumption system. We report in this paper an\nanalytical model which predicts the energy produced by a simple electroactive\nmembrane, and some promising experimental results.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3046v1"
    },
    {
        "title": "Step-up converter for electromagnetic vibrational energy scavenger",
        "authors": [
            "C. Saha",
            "T. O'Donnell",
            "J. Godsell",
            "L. Carlioz",
            "N. Wang",
            "P. Mccloskey",
            "S. Beeby",
            "J. Tudor",
            "Russel Torah"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper introduces a voltage multiplier (VM) circuit which can step up a\nminimum voltage of 150 mV (peak). The operation and characteristics of this\nconverter circuit are described. The voltage multiplier circuit is also tested\nwith micro and macro scale electromagnetic vibrational generators and the\neffect of the VM on the optimum load conditions of the electromagnetic\ngenerator is presented. The measured results show that 85% efficiency can be\nachieved from this VM circuit at a power level of 18 ?W.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3047v1"
    },
    {
        "title": "Gas Damping Coefficient Research for MEMS Comb Linear Vibration\n  Gyroscope",
        "authors": [
            "G. Qiufen",
            "G. Yuansheng",
            "S. Feng",
            "L. Fuqiang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Silicon-MEMS gyroscope is an important part of MEMS (Micro Electrical\nMechanical System). There are some disturb ignored in traditional gyroscope\nthat must be evaluated newly because of its smaller size (reach the level of\nmicron). In these disturb, the air pressure largely influences the performance\nof MEMS gyroscope. Different air pressure causes different gas damping\ncoefficient for the MEMS comb linear vibration gyroscope and different gas\ndamping coefficient influences the quality factor of the gyroscope directive.\nThe quality factor influences the dynamic working bandwidth of the MEMS comb\nlinear vibration gyroscope, so it is influences the output characteristic of\nthe MEMS comb linear vibration gyroscope. The paper shows the relationship\nbetween the air pressure and the output amplified and phase of the detecting\naxis through analyzing the air pressure influence on the MEMS comb linear\nvibration gyroscope. It discusses the influence on the frequency distribute and\nquality factor of the MEMS comb linear vibration gyroscope for different air\npressure.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3048v1"
    },
    {
        "title": "Comparison of Two Low-Power Electronic Interfaces for Capacitive Mems\n  Sensors",
        "authors": [
            "G. Nagy",
            "Z. Szucs",
            "S. Hodossy",
            "M. Rencz",
            "A. Poppe"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The paper discusses the importance and the issues of interfacing capacitive\nsensors. Two architectures applicable for interfacing capacitive sensors are\npresented. The first solution was designed to interface a capacitive humidity\nsensor designed and built for a humidity-dependent monolithic capacitor\ndeveloped at Budapest University of Technology and Economics. The second case\npresents the possible read-out solutions for a SOI-MEMS accelerometer. Both of\nthe architectures were built and tested in a discrete implementation to qualify\nthe methods before the integrated realization. The paper presents a detailed\ncomparison of the two methods\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3049v1"
    },
    {
        "title": "High Efficiency 3-Phase Cmos Rectifier with Step Up and Regulated",
        "authors": [
            "J. -C. Crebier",
            "Y. Lembeye",
            "H. Raisigel",
            "O. Deleage",
            "J. Delamare",
            "O. Cugat"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents several design issues related to the monolithic\nintegration of a 3-phase AC to DC low voltage, low power rectifier for 3-phase\nmicro source electrical conditioning. Reduced input voltage operation (down to\n1V), high efficiency, and output voltage regulations are implemented, based on\ncommercially available CMOS technology. Global design and system issues are\ndetailed. The management of start-up sequences under self supplied conditions\nas well as output voltage regulations are specifically addressed. Simulation\nresults, practical implementation and validation are presented. They are based\non the association of three micro elements : a 3-phase micro-generator, a stand\nalone 3-phase AC to DC integrated rectifier, and an output voltage conditioner\nbased on a commercially available IC.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3050v1"
    },
    {
        "title": "Silicon on Nothing Mems Electromechanical Resonator",
        "authors": [
            "C. Durand",
            "F. Casset",
            "P. Ancey",
            "F. Judong",
            "A. Talbot",
            "R. Quenouillere",
            "D. Renaud",
            "S. Borel",
            "B. Florin",
            "L. Buchaillot"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The very significant growth of the wireless communication industry has\nspawned tremendous interest in the development of high performances radio\nfrequencies (RF) components. Micro Electro Mechanical Systems (MEMS) are good\ncandidates to allow reconfigurable RF functions such as filters, oscillators or\nantennas. This paper will focus on the MEMS electromechanical resonators which\nshow interesting performances to replace SAW filters or quartz reference\noscillators, allowing smaller integrated functions with lower power\nconsumption. The resonant frequency depends on the material properties, such as\nYoung's modulus and density, and on the movable mechanical structure dimensions\n(beam length defined by photolithography). Thus, it is possible to obtain multi\nfrequencies resonators on a wafer. The resonator performance (frequency,\nquality factor) strongly depends on the environment, like moisture or pressure,\nwhich imply the need for a vacuum package. This paper will present first\nresonator mechanisms and mechanical behaviors followed by state of the art\ndescriptions with applications and specifications overview. Then MEMS resonator\ndevelopments at STMicroelectronics including FEM analysis, technological\ndevelopments and characterization are detailed.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3051v1"
    },
    {
        "title": "Copper Planar Microcoils Applied to Magnetic Actuation",
        "authors": [
            "J. Moulin",
            "M. Woytasik",
            "E. Martincic",
            "E. Dufour-Gergam"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Recent advances in microtechnology allow realization of planar microcoils.\nThese components are integrated in MEMS as magnetic sensor or actuator. In the\nlatter case, it is necessary to maximize the effective magnetic field which is\nproportional to the current passing through the copper track and depends on the\ndistance to the generation microcoil. The aim of this work was to determine the\noptimal microcoil design configuration for magnetic field generation. The\nresults were applied to magnetic actuation, taking into account technological\nconstraints. In particular, we have considered different realistic\nconfigurations that involve a magnetically actuated device coupled to a\nmicrocoil. Calculations by a semi-analytical method using Matlab software were\nvalidated by experimental measurements. The copper planar microcoils are\nfabricated by U.V. micromoulding on different substrates: flexible polymer\n(Kapton) and silicate on silicon. They are constituted by a spiral-like\ncontinuous track. Their total surface is about 1 mm2.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3052v1"
    },
    {
        "title": "Ni-MH battery modelling for ambient intelligence applications",
        "authors": [
            "D. Szente-Varga",
            "D. Horvath",
            "M. Rencz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Mobile devices, like sensor networks and MEMS actuators use mobile power\nsupplies to ensure energy for their operation. These are mostly batteries. The\nlifetime of the devices depends on the power consumption and on the quality and\ncapacitance of the battery. Though the integrated circuits and their power\nconsumption improve continually, their clock frequency also increases with the\ntime, and the resultant power consumption seems not to vary, or slightly\nincrease. On the other hand, the properties of batteries are developing much\nslower, necessitating the optimization of their usage on system level.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3053v1"
    },
    {
        "title": "Analysis of polysilicon micro beams buckling with temperature-dependent\n  properties",
        "authors": [
            "M. Shamshirsaz",
            "M. Bahrami",
            "M. B. Asgari",
            "M. Tayefeh"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The suspended electrothermal polysilicon micro beams generate displacements\nand forces by thermal buckling effects. In the previous electro-thermal and\nthermo-elastic models of suspended polysilicon micro beams, the\nthermo-mechanical properties of polysilicon have been considered constant over\na wide rang of temperature (20- 900 degrees C). In reality, the\nthermo-mechanical properties of polysilicon depend on temperature and change\nsignificantly at high temperatures. This paper describes the development and\nvalidation of theoretical and Finite Element Model (FEM) including the\ntemperature dependencies of polysilicon properties such as thermal expansion\ncoefficient and Young's modulus. In the theoretical models, two parts of\nelastic deflection model and thermal elastic model of micro beams buckling have\nbeen established and simulated. Also, temperature dependent buckling of\npolysilicon micro beam under high temperature has been modeled by Finite\nElement Analysis (FEA). Analytical results and numerical results using FEA are\ncompared with experimental data available in literature. Their reasonable\nagreement validates analytical model and FEM. This validation indicates the\nimportance of including temperature dependencies of polysilicon\nthermo-mechanical properties such as Coefficient of Thermal Expansion (CTE) in\nthe previous models.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3054v1"
    },
    {
        "title": "Parameter Identification of Pressure Sensors by Static and Dynamic\n  Measurements",
        "authors": [
            "S. Michael",
            "S. Kurth",
            "J. Klattenhoff",
            "H. Geissler",
            "S. Hering"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Fast identification methods of pressure sensors are investigated. With regard\nto a complete accurate sensor parameter identification two different\nmeasurement methods are combined. The approach consists on one hand in\nperforming static measurements - an applied pressure results in a membrane\ndeformation measured interferometrically and the corresponding output voltage.\nOn the other hand optical measurements of the modal responses of the sensor\nmembranes are performed. This information is used in an inverse identification\nalgorithm to identify geometrical and material parameters based on a FE model.\nThe number of parameters to be identified is thereby generally limited only by\nthe number of measurable modal frequencies. A quantitative evaluation of the\nidentification results permits furthermore the classification of processing\nerrors like etching errors. Algorithms and identification results for membrane\nthickness, intrinsic stress and output voltage will be discussed in this\ncontribution on the basis of the parameter identification of relative pressure\nsensors.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3055v1"
    },
    {
        "title": "New Horizontal Frustum Optical Waveguide Fabrication Using UV Proximity\n  Printing",
        "authors": [
            "T. -H. Lin",
            "H. Yang",
            "Ruey Fang Shyu",
            "C. -K. Chao"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents a novel method to fabricate the horizontal frustum\nstructure as a planar optical waveguide by using the proximity printing\ntechnique. A horizontal frustum optical waveguide with a both lateral and\nvertical taper structure was produced. The orthogonal and inclined masks with\nthe diffraction effect were employed in lithography process. This method can\nprecisely control each horizontal frustum optical waveguide geometric profile\nin the fabrication process. The horizontal frustum optical waveguide and its\narray with the same inclined angle were generated. The beam propagation\nsimulation software (BPM_CAD) was used to modeling the optical performance. The\nsimulation results reveal that the mode profile matched into horizontal frustum\noptical waveguide and fiber from the laser diode. The optical loss of\nhorizontal hemi-frustum structure of optical waveguides was less than 0.2dB.\nThe horizontal hemifrustum waveguide will be used for fiber coupling on boards\nfor further optical communication systems.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3056v1"
    },
    {
        "title": "A Fully Parameterized Fem Model for Electromagnetic Optimization of an\n  RF Mems Wafer Level Package",
        "authors": [
            "J. Iannacci",
            "J. Tian",
            "R. Gaddi",
            "A. Gnudi",
            "M. Bartek"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this work, we present a fully parameterized capped transmission line model\nfor electromagnetic optimization of a wafer level package (WLP) for RF MEMS\napplications using the Ansoft HFSS-TM electromagnetic simulator. All the\ndegrees of freedom (DoF's) in the package fabrication can be modified within\nthe model in order to optimize for losses and mismatch (capacitive and\ninductive couplings) introduced by the cap affecting the MEMS RF behaviour.\nAnsoft HFSS-TM was also validated for the simulation of capped RF MEMS devices\nby comparison against experimental data. A test run of capped 50 transmission\nlines and shorts was fabricated and tested.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3057v1"
    },
    {
        "title": "Development of a Nanostructual Microwave Probe Based on GaAs",
        "authors": [
            "Y. Ju",
            "T. Kobayashi",
            "H. Soyama"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  With the development of nanotechnology, the measurement of electrical\nproperties in local area of materials and devices has become a great need.\nAlthough a lot kind of scanning probe microscope have been developed for\nsatisfying the requirement of nanotechnology, a microscope technique which can\ndetermine electrical properties in local area of materials and devices is not\nyet developed. Recently, microwave microscope has been an interest to many\nresearchers, due to its potential in the evaluation of electrical properties of\nmaterials and devices. The advance of microwave is that the response of\nmaterials is directly relative to the electromagnetic properties of materials.\nHowever, because of the problem of the structure of probes, nanometer-scale\nresolution has not been successful. To achieve the goal, a new structure\nmicrowave probe is required. In this paper, we report a nanostructural\nmicrowave probe. To restrain the attenuation of microwave in the probe, GaAs\nwas used as the substrate of the probe. To obtain the desired structure, wet\netching was used to fabricate the probe. Different with the dry etching, a\nside-etching will occur under the etching mask. Utilizing this property, a\nmicro tip can be fabricated by etching a wafer, of which a small mask was\nintroduced on the surface in advance.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3059v1"
    },
    {
        "title": "Characterisation of an Electrostatic Vibration Harvester",
        "authors": [
            "T. Sterken",
            "Geert Altena",
            "P. Fiorini",
            "R. Puers"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Harvesting energy from ambient vibration is proposed as an alternative to\nstorage based power supplies for autonomous systems. The system presented\nconverts the mechanical energy of a vibration into electrical energy by means\nof a variable capacitor, which is polarized by an electret. A lumped element\nmodel is used to study the generator and design a prototype. The device has\nbeen micromachined in silicon, based on a two-wafer process. The prototype was\nsuccessfully tested, both using an external polarization source and an\nelectret.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3060v1"
    },
    {
        "title": "Surface Generation Analysis in Micro End-Milling Considering the\n  Influences of Grain",
        "authors": [
            "J. Wang",
            "Y. Gong",
            "G. Abba",
            "Kui Chen",
            "J. Shi",
            "G. Cai"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Micro end-milling method is a universal micro manufacturing method, which can\nbe used to fabricating complex 3D structures and parts with many materials. But\ncompared with their micrometer order size, their surface roughness quality is\nnot satisfied. In this paper, the different metal phase grains influences are\nresearched, and the micro end-milling process is described while the material\nis anisotropic. In this paper, the physical characteristics of different\ngrains, especially friction coefficient and elastic module, are very critical\nto determine the chip formation process and surface generation. The chip is\noften discontinues because of the grain boundary effect. Through the micro\nend-milling experiment, the bottom surface results correlate very well with the\ntheory analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3061v1"
    },
    {
        "title": "An Integrated Circuit Compatible Compact Package for Thermal Gas\n  Flowmeters",
        "authors": [
            "P. Bruschi",
            "V. Nurra"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  An original packaging method suitable for integrated thermal mass flow\nsensors is presented. The method consists in the application of a plastic\ntransparent adapter to the chip surface. The adapter is sealed to the chip\nsurface by means of a thermal procedure. By this approach it is possible to\nselectively convey the fluid flow to reduced chip areas, avoiding contact with\nthe pads. Fabrication and testing of a very compact flow sensor is described.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3062v1"
    },
    {
        "title": "A High Power Density Electrostatic Vibration-to-Electric Energy\n  Converter Based On An In-Plane Overlap Plate (IPOP) Mechanism",
        "authors": [
            "A. M. Paracha",
            "Ph. Basset",
            "F. Marty",
            "A. Vaisman Chasin",
            "P. Poulichet",
            "T. Bourouina"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, design, fabrication and characterization issues of a bulk\nsilicon-based, vibration powered, electric energy generator are addressed. The\nconverter is based on an In-Plane Overlap Plate (IPOP) configuration [1].\nMeasurements have shown that with a theoretically lossless electronics and a\nstarting voltage of 5 V, power density of 58 $\\mu$W/cm3 is achievable at the\nresonance frequency of 290 Hz. It can be further improved by reducing the\nparasitic capacitance, which can be achieved by silicon etching, but a\nconsiderable mass is lost. In [2], it is shown that 19% of mass reduction\nimproves power density from 12.95 $\\mu$W/cm3 to 59 $\\mu$W/cm3. Hence an\nenhancement in fabrication process is proposed, which is termed as Backside\nDRIE. It helps in increasing power density without loosing an important\nquantity of mass. Simulations have shown that 2.5% of mass removal improves\npower density up to 76.71 $\\mu$W/cm3. Initial simulation results and problems\nof associated electronics are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3063v1"
    },
    {
        "title": "Formation of Embedded Microstructures by Thermal Activated Solvent\n  Bonding",
        "authors": [
            "S. H. Ng",
            "R. T. Tjeung",
            "Z. F. Wang",
            "A. C. W. Lu",
            "I. Rodriguez",
            "N. De Rooij"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  We present a thermal activated solvent bonding technique for the formation of\nembedded microstrucutres in polymer. It is based on the temperature dependent\nsolubility of polymer in a liquid that is not a solvent at room temperature.\nWith thermal activation, the liquid is transformed into a solvent of the\npolymer, creating a bonding capability through segmental or chain\ninterdiffusion at the bonding interface. The technique has advantages over the\nmore commonly used thermal bonding due to its much lower operation temperature\n(30 degrees C lower than the material's Tg), lower load, as well as shorter\ntime. Lap shear test indicated bonding shear strength of up to 2.9 MPa. Leak\ntest based on the bubble emission technique showed that the bonded microfluidic\ndevice can withstand at least 6 bars (87 psi) of internal pressure (gauge) in\nthe microchannel. This technique can be applied to other systems of polymer and\nsolvent.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3064v1"
    },
    {
        "title": "Design and Modeling of Micromechanical GaAs based Hot Plate for Gas\n  Sensors",
        "authors": [
            "J. Jakovenko",
            "M. Husak",
            "T. Lalinskytfh",
            "M. Drzik",
            "G. Vanko"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  For modern Gas sensors, high sensitivity and low power are expected. This\npaper discusses design, simulation and fabrication of new Micromachined Thermal\nConverters (MTCs) based on GaAs developed for Gas sensors. Metal oxide gas\nsensors generally work in high temperature mode that is required for chemical\nreactions to be performed between molecules of the specified gas and the\nsurface of sensing material. There is a low power consumption required to\nobtain the operation temperatures in the range of 200 to 500 oC. High thermal\nisolation of these devices solves consumption problem and can be made by\ndesigning of free standing micromechanical hot plates. Mechanical stability and\na fast thermal response are especially significant parameters that can not be\nneglected. These characteristics can be achieved with new concept of GaAs\nthermal converter.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3065v1"
    },
    {
        "title": "Set-up and characterization of a humidity sensor realized in\n  LTCC-technology",
        "authors": [
            "W. Smetana",
            "M. Unger"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A new type of integrated temperature and humidity sensor applying\nLTCC-technology has been developed and characterized. In this approach, sensing\nelements are implemented using heated metal resistors (Pt-elements), where one\nis exposed to the humid environment that causes the sensor element to cool down\nwith increased humidity, while the other one is sealed from the environment.\nSensor design is based on FEA (Finite Element Analyses) where the critical\ndesign parameters have been analyzed with regard to the performance\ncharacteristic of the device. The set-up of sensor element will be shown and\nthe functional capability will be demonstrated by experimental results.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3066v1"
    },
    {
        "title": "Micromachined Polycrystalline Sige-Based Thermopiles for Micropower\n  Generation on Human Body",
        "authors": [
            "Z. Wang",
            "V. Leonov",
            "P. Fiorini",
            "C. Van Hoof"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents a polycrystalline silicon germanium (poly-SiGe)\nthermopile specially designed for thermoelectric generators used on human body.\nBoth the design of the single thermocouple and the arrangement of the\nthermocouple array have been described. A rim structure has been introduced in\norder to increase the temperature difference across the thermocouple junctions.\nThe modeling of the thermocouple and the thermopile has been performed\nanalytically and numerically. An output power of about 1 $\\mu$W at an output\nvoltage of more than 1 V is expected from the current design of thermopiles in\na watch-size generator. The key material properties of the poly-SiGe have been\nmeasured. The thermopile has been fabricated and tested. Experimental results\nclearly demonstrate the advantage of the rim structure in increasing output\nvoltage. In presence of forced convection, the output voltage of a non-released\nthermopile can increase from about 53 mV/K/cm2 to about 130 mV/K/cm2 after the\nrim structure is formed. A larger output voltage from the thermopile is\nexpected upon process completion.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3067v1"
    },
    {
        "title": "Silicon microneedles array with biodegradable tips for transdermal drug\n  delivery",
        "authors": [
            "B. Chen",
            "J. Wei",
            "Francis Tay",
            "Y. T. Wong",
            "C. Iliescu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents the fabrication process, characterization results and\nbasic functionality of silicon microneedles array with biodegradable tips. In\norder to avoid the main problems related to silicon microneedles : broking of\nthe top part of the needles inside the skin, a simple solution can be\nfabrication of microneedles array with biodegradable tips. The silicon\nmicroneedles array was fabricated by using reactive ion etching while the\nbiodegradable tips were performed using and anodization process that generates\nselectively porous silicon only on the top part of the skin. The paper presents\nalso the results of in vitro release of calcein using microneedles array with\nbiodegradable tips\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3068v1"
    },
    {
        "title": "2-D Analysis of Enhancement of Analytes Adsorption Due to Flow Stirring\n  by Electrothermal Force in The Microcantilever Sensor",
        "authors": [
            "M. C. Wu",
            "J. S. Chang",
            "C. -K. Yang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Ac electrokinetic flows are commonly used for manipulating micron-scale\nparticles in a biosensor system. At the solid-liquid state there are two kinds\nof processes in the reaction between analytes and ligands: the mass transport\nprocess and the chemical reaction process. The mass transport process is\nrelated to convection and diffusion. Total or partial limit of mass transport\nwould retard the diffusion from the bulk fluid to the interface of reaction.\nThis effect decreases the possibility of adsorption of analyte and ligand\nbecause the chemical reaction is faster than the diffusion. In order to solve\nthis problem, we apply an ac electric field to induce a vortex field by the\nelectrothermal effect, which helps in increasing the rate of diffusion. By\nusing the finite element analysis software, COMSOL Multiphysics, we optimized\nseveral parameters of the microelectrode structures and the position of the\nreacting surface, i.e. the microcantilever, by a simplified 2-D model and a 3-D\nmodel. It is successful in accelerating the reacting rate of the molecule which\nis limited by mass transport. The factor of the efficiency is about 1.429 when\nthe operating voltage is 15 Vrms peak-to-peak. In addition, the surface\nconcentration of the complex on the microcantilever has been simulated.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3069v1"
    },
    {
        "title": "Development and Application of a Diaphragm Micro-Pump with Piezoelectric\n  Device",
        "authors": [
            "H. K. Ma",
            "B. R. Hou",
            "H. Y. Wu",
            "C. Y. Lin",
            "J. J. Gao",
            "M. C. Kou"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this study, a new type of thin, compact, and light weighed diaphragm\nmicro-pump has been successfully developed to actuate the liquid by the\nvibration of a diaphragm. The micro-diaphragm pump with two valves is\nfabricated in an aluminum case by using highly accurate CNC machine, and the\ncross-section dimension is 5mm x 8mm. Both valves and diaphragm are\nmanufactured from PDMS. The amplitude of vibration by a piezoelectric device\nproduces an oscillating flow which may change the chamber volume by changing\nthe curvature of a diaphragm. Several experimental set-ups for performance test\nin a single micro-diaphragm pump, isothermal flow open system, and a closed\nliquid cooling system is designed and implemented. The performance of one-side\nactuating micro-diaphragm pump is affected by the design of check valves,\ndiaphragm, piezoelectric device, chamber volume, input voltage and frequency.\nThe measured maximum flow rate of present design is 72 ml/min at zero total\npump head in the range of operation frequency 70-180 Hz.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3070v1"
    },
    {
        "title": "Simulation of valveless micropump and mode analysis",
        "authors": [
            "W. P. Lan",
            "J. S. Chang",
            "K. C. Wu",
            "Y. C. Shih"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this work, a 3-D simulation is performed to study for the solid-fluid\ncoupling effect driven by piezoelectric materials and utilizes asymmetric\nobstacles to control the flow direction. The result of simulation is also\nverified. For a micropump, it is crucial to find the optimal working frequency\nwhich produce maximum net flow rate. The PZT plate vibrates under the first\nmode, which is symmetric. Adjusting the working frequency, the maximum flow\nrate can be obtained. For the micrpump we studied, the optimal working\nfrequency is 3.2K Hz. At higher working frequency, say 20K Hz, the fluid-solid\nmembrane may come out a intermediate mode, which is different from the first\nmode and the second mode. It is observed that the center of the mode drifts.\nMeanwhile, the result shows that a phase shift lagging when the excitation\nforce exists in the vibration response. Finally, at even higher working\nfrequency, say 30K Hz, a second vibration mode is observed.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3071v1"
    },
    {
        "title": "Enhanced Sensing Characteristics in MEMS-based Formaldehyde Gas Sensor",
        "authors": [
            "Yu-Hsiang Wang",
            "C. -C. Hsiao",
            "Chia-Yen Lee",
            "R. -H. Ma",
            "Po-Cheng Chou"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This study has successfully demonstrated a novel self-heating formaldehyde\ngas sensor based on a thin film of NiO sensing layer. A new fabrication process\nhas been developed in which the Pt micro heater and electrodes are deposited\ndirectly on the substrate and the NiO thin film is deposited above on the micro\nheater to serve as sensing layer. Pt electrodes are formed below the sensing\nlayer to measure the electrical conductivity changes caused by formaldehyde\noxidation at the oxide surface. Furthermore, the upper sensing layer and\nNiO/Al2O3 co-sputtering significantly increases the sensitivity of the gas\nsensor, improves its detection limit capability. The microfabricated\nformaldehyde gas sensor presented in this study is suitable not only for\nindustrial process monitoring, but also for the detection of formaldehyde\nconcentrations in buildings in order to safeguard human health.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3072v1"
    },
    {
        "title": "Mems Q-Factor Enhancement Using Parametric Amplification: Theoretical\n  Study and Design of a Parametric Device",
        "authors": [
            "L. Grasser",
            "H. Mathias",
            "F. Parrain",
            "X. Le Roux",
            "J. -P. Gilles"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Parametric amplification is an interesting way of artificially increasing a\nMEMS Quality factor and could be helpful in many kinds of applications. This\npaper presents a theoretical study of this principle, based on Matlab/Simulink\nsimulations, and proposes design guidelines for parametric structures. A new\ndevice designed with this approach is presented together with the corresponding\nFEM simulation results.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3073v1"
    },
    {
        "title": "Biodegradable Polylactic Acid (PLA) Microstructures for Scaffold\n  Applications",
        "authors": [
            "G. -J. Wang",
            "K. -H. Ho",
            "C. -C. Hsueh"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this research, we present a simple and cost effective soft lithographic\nprocess to fabricate PLA scaffolds for tissue engineering. In which, the\nnegative photoresist JSR THB-120N was spun on a glass subtract followed by\nconventional UV lithographic processes to fabricate the master to cast the PDMS\nelastomeric mold. A thin poly(vinyl alcohol) (PVA) layer was used as a mode\nrelease such that the PLA scaffold can be easily peeled off. The PLA precursor\nsolution was then cast onto the PDMS mold to form the PLA microstructures.\nAfter evaporating the solvent, the PLA microstructures can be easily peeled off\nfrom the PDMS mold. Experimental results show that the desired microvessels\nscaffold can be successfully transferred to the biodegradable polymer PLA.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3074v1"
    },
    {
        "title": "Solving functional reliability issue for an optical electrostatic switch",
        "authors": [
            "H. Camon",
            "C. Ganibal",
            "N. Rapahoz",
            "M. Trzmiel",
            "C. Pisella",
            "C. Martinez",
            "K. Gilbert",
            "S. Valette"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, we report the advantage of using AC actuating signal for\ndriving MEMS actuators instead of DC voltages. The study is based upon micro\nmirror devices used in digital mode for optical switching operation. When the\npull-in effect is used, charge injection occurs when the micro mirror is\nmaintained in the deflected position. To avoid this effect, a geometrical\nsolution is to realize grounded landing electrodes which are electro-statically\nseparated from the control electrodes. Another solution is the use of AC signal\nwhich eliminates charge injection particularly if a bipolar signal is used.\nLong term experiments have demonstrated the reliability of such a signal\ncommand to avoid injection of electric charges.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3075v1"
    },
    {
        "title": "Identification of Test Structures for Reduced Order Modeling of the\n  Squeeze Film Damping in Mems",
        "authors": [
            "A. Soma",
            "G. De Pasquale"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this study the dynamic behaviour of perforated microplates oscillating\nunder the effect of squeeze film damping is analyzed. A numerical approach is\nadopted to predict the effects of damping and stiffness transferred from the\nsurrounding ambient air to oscillating structures ; the effect of hole's cross\nsection and plate's extension is observed. Results obtained by F.E.M. models\nare compared with experimental measurements performed by an optical\ninterferometric microscope.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3076v1"
    },
    {
        "title": "Out-of-Plane Cmos Compatible Magnetometers",
        "authors": [
            "M. El Ghorba",
            "N. Andr",
            "S. Sobieski",
            "J. -P. Raskin"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Three-dimensional MEMS magnetometers with use of residual stresses in thin\nmultilayers cantilevers are presented. Half-loop cantilevers based on\nLorentz-force deflection convert magnetic flux in changes, thanks to\npiezoresistive transducers mounted in Wheatstone bridge. Magnetic field in the\norder of 10 Gauss was measured with a sensitivity of 0.015 mV/Gauss. A Finite\nElement Model of the device has been developed with Ansys for static and\ndynamic simulations. Novel out-of-plane ferromagnetic nickel plate magnetometer\nis also presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3077v1"
    },
    {
        "title": "Tuneable Capacitor based on dual picks profile of the sacrificial layer",
        "authors": [
            "S. Soulimane",
            "F. Casset",
            "F. Chapuis",
            "P. -L. Charvet",
            "M. ad"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, we present a novel dual gap tuneable capacitor process based\non the profile of the sacrificial layer. This profile involves a tri-layer\nphoto-resist process with only one mask level. This realization is based on a\nspecial profile of the sacrificial layer designed by two picks. The mechanism\nof the sacrificial layer realisation is dependent on resist thickness, resist\nformulation (viscosity, type of polymer and/or solvent, additives...), design\nof the patterned layer (size or width) and the conditions under which this\nlayer is prepared: thermal treatment, etch back processes... In this\ncommunication we demonstrate influence of the later parameters and discuss how\na dual pick profile was achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3078v1"
    },
    {
        "title": "Reduced 30% scanning time 3D multiplexer integrated circuit applied to\n  large array format 20KHZ frequency inkjet print heads",
        "authors": [
            "J. -C. Liou",
            "F. -G. Tseng"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Enhancement of the number and array density of nozzles within an inkjet head\nchip is one of the keys to raise the printing speed and printing resolutions.\nHowever, traditional 2D architecture of driving circuits can not meet the\nrequirement for high scanning speed and low data accessing points when nozzle\nnumbers greater than 1000. This paper proposes a novel architecture of\nhigh-selection-speed three-dimensional data registration for inkjet\napplications. With the configuration of three-dimensional data registration,\nthe number of data accessing points as well as the scanning lines can be\ngreatly reduced for large array inkjet printheads with nozzles numbering more\nthan 1000. This IC (Integrated Circuit) architecture involves three-dimensional\nmultiplexing with the provision of a gating transistor for each ink firing\nresistor, where ink firing resistors are triggered only by the selection of\ntheir associated gating transistors. Three signals: selection (S), address (A),\nand power supply (P), are employed together to activate a nozzle for droplet\nejection. The smart printhead controller has been designed by a 0.35 um CMOS\nprocess with a total circuit area, 2500 x 500 microm2, which is 80% of the\ncirucuit area by 2D configuration for 1000 nozzles. Experiment results\ndemonstrate the functionality of the fabricated IC in operation, signal\ntransmission and a potential to control more than 1000 nozzles with only 31\ndata access points and reduced 30% scanning time.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3079v1"
    },
    {
        "title": "Analysis of Asymmetric Piezoelectric Composite Beam",
        "authors": [
            "J. -S. Chen",
            "S. -H. Chen",
            "K. -C. Wu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper deals with the vibration analysis of an asymmetric composite beam\ncomposed of glass a piezoelectric material. The Bernoulli's beam theory is\nadopted for mechanical deformations, and the electric potential field of the\npiezoelectric material is assumed such that the divergence-free requirement of\nthe electrical displacements is satisfied. The accuracy of the analytic model\nis assessed by comparing the resonance frequencies obtained by the analytic\nmodel with those obtained by the finite element method. The model developed can\nbe used as a tool for designing piezoelectric actuators such as micro-pumps.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3080v1"
    },
    {
        "title": "A High-Q Microwave MEMS Resonator",
        "authors": [
            "Z. Jian",
            "Y. Yuanwei",
            "Z. Yong",
            "Chen Chen",
            "J. Shixing"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A High-Q microwave (K band) MEMS resonator is presented, which empolys\nsubstrate integrated waveguide (SIW) and micromachined via-hole arrays by ICP\nprocess. Nonradiation dielectric waveguide (NRD) is formed by metal filled\nvia-hole arrays and grounded planes. The three dimensional (3D) high\nresistivity silicon substrate filled cavity resonator is fed by current probes\nusing CPW line. This monolithic resonator results in low cost, high performance\nand easy integration with planar cicuits. The measured quality factor is beyond\n180 and the resonance frequency is 21GHz.It shows a good agreement with the\nsimulation results. The chip size is only 4.7mm x 4.6mm x 0.5mm. Finally, as an\nexample of applications, a filter using two SIW resonators is designed.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3081v1"
    },
    {
        "title": "Lamination And Microstructuring Technology for a Bio-Cell Multiwell\n  array",
        "authors": [
            "E. Jung",
            "D. Manessis",
            "A. Neumann",
            "L. Bottcher",
            "T. Braun",
            "J. Bauer",
            "H. Reichl",
            "B. Iafelice",
            "F. Destro",
            "R. Gambari"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Microtechnology becomes a versatile tool for biological and biomedical\napplications. Microwells have been established long but remained\nnon-intelligent up to now. Merging new fabrication techniques and handling\nconcepts with microelectronics enables to realize intelligent microwells\nsuitable for future improved cancer treatment. The described technology depicts\nthe basis for the fabrication of a elecronically enhanced microwell. Thin\naluminium sheets are structured by laser micro machining and laminated\nsuccessively to obtain registration tolerances of the respective layers of\n5..10\\^A$\\mu$m. The microwells lasermachined into the laminate are with\n50..80\\^A$\\mu$m diameter, allowing to hold individual cells within the well.\nThe individual process steps are described and results on the microstructuring\nare given.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3082v1"
    },
    {
        "title": "Monotonic and fatigue testing of spring-bridged freestanding microbeams\n  application for MEMS",
        "authors": [
            "Ming-Tzer Lin",
            "K. -S. Shiu",
            "Chi-Jia Tong"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Microelectromechanical systems (MEMS) technologies are developing rapidly\nwith increasing study of the design, fabrication and commercialization of\nmicroscale systems and devices. Accurate knowledge on the mechanical behaviors\nof thin film materials used for MEMS is important for successful design and\ndevelopment of MEMS. Here a novel electroplating spring-bridge micro-tensile\nspecimen integrates pin-pin align holes, misalignment compensate spring, load\nsensor beam and freestanding thin film is demonstrated and fabricated. The\nspecimen is fit into a specially designed micro-mechanical apparatus to carry\nout a series of monotonic tensile testing on sub-micron freestanding thin\nfilms. Certain thin films applicable as structure or motion gears in MEMS were\ntested including sputtered gold, copper and tantalum nitride thin films. Metal\nspecimens were fabricated by sputtering; for tantalum nitride film samples,\nnitrogen gas was introduced into the chamber during sputtering tantalum films\non the silicon wafer. The sample fabrication method involves three steps of\nlithography and two steps of electroplating copper to hold a dog bone\nfreestanding thin film. Using standard wet etching or lift off techniques, a\nseries of microtensile specimens were patterned in metal thin films, holes, and\nseed layer for spring and frame structure on the underlying silicon oxide\ncoated silicon substrate. Two steps of electroplating processing to distinct\nspring and frame portion of the test chip. Finally, chemical etched away the\nsilicon oxide to separated electroplated specimen and silicon substrate.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3083v1"
    },
    {
        "title": "Profile Control of a Borosilicate-Glass Groove Formed by Deep Reactive\n  Ion Etching",
        "authors": [
            "T. Akashi",
            "Y. Yoshimura"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Deep reactive ion etching (DRIE) of borosilicate glass and profile control of\nan etched groove are reported. DRIE was carried out using an anodically bonded\nsilicon wafer as an etching mask. We controlled the groove profile, namely\nimproving its sidewall angle, by removing excessively thick polymer film\nproduced by carbonfluoride etching gases during DRIE. Two fabrication processes\nwere experimentally compared for effective removal of the film : DRIE with the\naddition of argon to the etching gases and a novel combined process in which\nDRIE and subsequent ultrasonic cleaning in DI water were alternately carried\nout. Both processes improved the sidewall angle, and it reached 85o independent\nof the mask-opening width. The results showed the processes can remove\nexcessive polymer film on sidewalls. Accordingly, the processes are an\neffective way to control the groove profile of borosilicate glass.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3085v1"
    },
    {
        "title": "Selection of High Strength Encapsulant for MEMS Devices Undergoing High\n  Pressure Packaging",
        "authors": [
            "A. A. Hamzah",
            "Y. Husaini",
            "Y. Husaini",
            "B. Y. Majlis",
            "I. Ahmad"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Deflection behavior of several encapsulant materials under uniform pressure\nwas studied to determine the best encapsulant for MEMS device. Encapsulation is\nneeded to protect movable parts of MEMS devices during high pressure transfer\nmolded packaging process. The selected encapsulant material has to have surface\ndeflection of less than 5 ?m under 100 atm vertical loading. Deflection was\nsimulated using CoventorWare ver.2005 software and verified with calculation\nresults obtained using shell bending theory. Screening design was used to\nconstruct a systematic approach for selecting the best encapsulant material and\nthickness under uniform pressure up to 100 atm. Materials considered for this\nstudy were polyimide, parylene C and carbon based epoxy resin. It was observed\nthat carbon based epoxy resin has deflection of less than 5 ?m for all\nthickness and pressure variations. Parylene C is acceptable and polyimide is\nunsuitable as high strength encapsulant. Carbon based epoxy resin is considered\nthe best encapsulation material for MEMS under high pressure packaging process\ndue to its high strength.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3086v1"
    },
    {
        "title": "A Two-Step Etching Method to Fabricate Nanopores in Silicon",
        "authors": [
            "G. -J. Wang",
            "W. -Z. Chen",
            "K. J. Chang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A cost effectively method to fabricate nanopores in silicon by only using the\nconventional wet-etching technique is developed in this research. The main\nconcept of the proposed method is a two-step etching process, including a\npremier double-sided wet etching and a succeeding track-etching. A special\nfixture is designed to hold the pre-etched silicon wafer inside it such that\nthe track-etching can be effectively carried out. An electrochemical system is\nemployed to detect and record the ion diffusion current once the pre-etched\ncavities are etched into a through nanopore. Experimental results indicate that\nthe proposed method can cost effectively fabricate nanopores in silicon.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3087v1"
    },
    {
        "title": "A Reconfigurable Impedance Matching Network Employing RF-MEMS Switches",
        "authors": [
            "M. Bedani",
            "F. Carozza",
            "R. Gaddi",
            "A. Gnudi",
            "B. Margesin",
            "F. Giacomozzi"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  We propose the design of a reconfigurable impedance matching network for the\nlower RF frequency band, based on a developed RF-MEMS technology. The circuit\nis composed of RF-MEMS ohmic relays, metal-insulator-metal (MIM) capacitors and\nsuspended spiral inductors, all integrated on a high resistivity Silicon\nsubstrate. The presented circuit is well-suited for all applications requiring\nadaptive impedance matching between two in principle unknown cascaded\nRF-circuits. The fabrication and testing of a monolithic integrated prototype\nin RF-MEMS technology from ITC-irst is currently underway.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3088v1"
    },
    {
        "title": "Towards a Methodology for Analysis of Interconnect Structures for\n  3D-Integration of Micro Systems",
        "authors": [
            "P. Schneider",
            "S. Reitz",
            "A. Wilde",
            "G. Elst",
            "P. Schwarz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Functional aspects as well as the influence of integration technology on the\nsystem behavior have to be considered in the 3D integration design process of\nmicro systems. Therefore, information from different physical domains has to be\nprovided to designers. Due to the variety of structures and effects of\ndifferent physical domains, efficient modeling approaches and simulation\nalgorithms have to be combined. The paper describes a modular approach which\ncovers detailed analysis with PDE solvers and model generation for system level\nsimulation.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3089v1"
    },
    {
        "title": "Modeling of a piezoelectric micro-scanner",
        "authors": [
            "A. Chaehoi",
            "M. Begbie",
            "D. Cornez",
            "K. Kirk"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Micro-scanners have been widely used in many optical applications. The\nmicro-scanner presented in this paper uses multimorph-type bending actuators to\ntilt a square plate mirror. This paper presents a complete analytical model of\nthe piezoelectric micro-scanner. This theoretical model based on strength of\nmaterial equations calculates the force generated by the multimorphs on the\nmirror, the profile of the structure and the angular deflection of the mirror.\nThe proposed model, used to optimize the design of the piezoelectric silicon\nmicro-scanner, is intended for further HDL integration, allowing in this way\nsystem level simulation and optimization.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3090v1"
    },
    {
        "title": "A novel method for fatigue testing of MEMS devices containing movable\n  elements",
        "authors": [
            "Z. Szucs",
            "M. Rencz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper we present an electronic circuit for position or capacitance\nestimation of MEMS electrostatic actuators based on a switched capacitor\ntechnique. The circuit uses a capacitive divider configuration composed by a\nfixed capacitor and the variable capacitance of the electrostatic actuator for\ngenerating a signal that is a function of the input voltage and capacitive\nratio. The proposed circuit can be used to actuate and to sense position of an\nelectrostatic MEMS actuator without extra sensing elements. This approach is\ncompatible with the requirements of most analog feedback systems and the\ncircuit topology of pulsed digital oscillators (PDO).\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3091v1"
    },
    {
        "title": "Noise and thermal stability of vibrating micro-gyrometers preamplifiers",
        "authors": [
            "R. Levy",
            "A. Dupret",
            "H. Mathias",
            "J. -P. Gilles",
            "F. Parrain",
            "B. Eisenbeis",
            "S. Megherbi"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The preamplifier is a critical component of gyrometer's electronics. Indeed\nthe resolution of the sensor is limited by its signal to noise ratio, and the\ngyrometer's thermal stability is limited by its gain drift. In this paper, five\ndifferent kinds of preamplifiers are presented and compared. Finally, the\ndesign of an integrated preamplifier is shown in order to increase the gain\nstability while reducing its noise and size.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3092v1"
    },
    {
        "title": "0-level Vacuum Packaging RT Process for MEMS Resonators",
        "authors": [
            "N. Abel",
            "D. Grogg",
            "C. Hibert",
            "F. Casset",
            "P. Ancey",
            "A. Ionescu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A new Room Temperature (RT) 0-level vacuum package is demonstrated in this\nwork, using amorphous silicon (aSi) as sacrificial layer and SiO2 as structural\nlayer. The process is compatible with most of MEMS resonators and Resonant\nSuspended-Gate MOSFET [1] fabrication processes. This paper presents a study on\nthe influence of releasing hole dimensions on the releasing time and hole\nclogging. It discusses mass production compatibility in terms of packaging\nstress during back-end plastic injection process. The packaging is done at room\ntemperature making it fully compatible with IC-processed wafers and avoiding\nany subsequent degradation of the active devices.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3093v1"
    },
    {
        "title": "From MEMS Devices to Smart Integrated Systems",
        "authors": [
            "O. Soeraasen",
            "J. E. Ramstad"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The smart integrated systems of tomorrow would demand a combination of\nmicromechanical components and traditional electronics. On-chip solutions will\nbe the ultimate goal. One way of making such systems is to implement the\nmechanical parts in an ordinary CMOS process. This procedure has been used to\ndesign an oscillator consisting of a resonating cantilever beam and a CMOS\nPierce feedback amplifier. The resonating frequency is changed if the beam is\nbent by external forces. The paper describes central features of this procedure\nand highlights the design considerations for the CMOS-MEMS oscillator. The\ncircuit is used as an example of a \"VLSI designer\" way of making future\nintegrated micromechanical and microelectronic systems on-chip. The possibility\nfor expansion to larger systems is reviewed.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3094v1"
    },
    {
        "title": "Interconnect Challenges in Highly Integrated MEMS/ASIC Subsystems",
        "authors": [
            "N. Marenco",
            "S. Warnat",
            "W. Reinert"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Micromechanical devices like accelerometers or rotation sensors form an\nincreasing segment beneath the devices supplying the consumer market. A hybrid\nintegration approach to build smart sensor clusters for the precise detection\nof movements in all spatial dimensions requires a large toolbox of interconnect\ntechnologies, each with its own constraints regarding the total process\nintegration. Specific challenges described in this paper are post-CMOS\nfeedthroughs, front-to-front die contact arrays, vacuum-compliant lateral\ninterconnect and fine-pitch solder balling to finally form a Chip-Scale\nSystem-in-Package (CSSiP).\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3095v1"
    },
    {
        "title": "Experimental Characterization of the static behaviour of\n  microcatntilevers electrostatically actuated",
        "authors": [
            "A. Ballestra",
            "E. Brusa",
            "M. G. Munteanu",
            "A. Soma"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper concerns the experimental validation of some mathematical models\npreviously developed by the authors, to predict the static behaviour of\nmicroelectrostatic actuators, basically free-clamped microbeams. This layout is\ncurrently used in RF-MEMS design operation or even in material testing at\nmicroscale. The analysis investigates preliminarily the static behaviour of a\nset of microcantilevers bending in-plane. This investigation is aimed to\ndistinguish the geometrical linear behaviour, exhibited under small\ndisplacement assumption, from the geometrical nonlinearity, caused by large\ndeflection. The applied electromechanical force, which nonlinearly depends on\ndisplacement, charge and voltage, is predicted by a coupled-field approach,\nbased on numerical methods and herewith experimentally validated, by means of a\nFogale Zoomsurf 3D. Model performance is evaluated on pull-in prediction and on\nthe curve displacement vs. voltage. In fact, FEM nonlinear solution performed\nby a coupled-field approach, available on commercial codes, and by a FEM\nnon-incremental approach are compared with linear solution, for different\nvalues of the design parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3097v1"
    },
    {
        "title": "Nanobiosensors based on individual olfactory receptors",
        "authors": [
            "E. Pajot-Augy"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In the SPOT-NOSED European project, nanoscale sensing elements bearing\nolfactory receptors and grafted onto functionalized gold substrates are used as\nodorant detectors to develop a new concept of nanobioelectronic nose, through\nsensitive impedancemetric measurement of single receptor conformational change\nupon ligand binding, with a better specificity and lower detection threshold\nthan traditional physical sensors.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3099v1"
    },
    {
        "title": "Bridge configurations in piezoresistive two-axis accelerometers",
        "authors": [
            "E. Halvorsen",
            "S. Husa"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In piezoresisitive two-axis accelerometers with two proof masses suspended by\ncantilever beams, there are generally many ways to configure the Wheatstone\nbridges. The configurations are different both with respect to functionality\nand performance. The main distinction is between bridges that contain resistors\nbelonging to both proof masses, and the one bridge that doesn't. We compare the\ndifferent bridge configurations by analytical calculations of bridge\nnon-linearity, robustness towards manufacturing variations and electronic\nnoise. We consider accelerometers where the ratio between the sensitivity to\nacceleration normal and parallel to the chip plane vary over a wide range. For\nnumerical examples we use representative values for p-type silicon. The\nperformance of the configuration with one bridge connected to each proof mass\nis superior to those that combine resistors belonging to different proof\nmasses.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3100v1"
    },
    {
        "title": "Online Sensor Testing through Superposition of Encoded Stimulus",
        "authors": [
            "N. Dumas",
            "Z. Xu",
            "K. Georgopopoulos",
            "J. Bunyan",
            "A. Richardson"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Online monitoring remains an important requirement for a range of\nmicrosystems. The solution based on the injection of an actuating test stimulus\ninto the bias structure of active devices holds great potential. This paper\npresents an improved solution that aims to remove the measurand-induced signal\nfrom the sensor output. It involves encoding the test stimulus and using a\ncovariance algorithm to reject the signal that does not contain the code. The\ntrade-off between the sine wave rejection ratio of the technique and the test\ntime response is studied and, in the case of a MEMS accelerometer, it is\ndemonstrated that the rejection is higher than 14dB for a test time of about\n0.7s. Furthermore, the accuracy of the test signal can be evaluated to\nguarantee the integrity of the online test output.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3101v1"
    },
    {
        "title": "Modeling of T-Shaped Microcantilever Resonators",
        "authors": [
            "M. Narducci",
            "E. Figueras",
            "I. Gracia",
            "L. Fonseca",
            "J. Santander",
            "C. Can"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The extensive research and development of micromechanical resonators is\ntrying to allow the use of these devices for highly sensitive applications.\nMicrocantilevers are some of the simplest MEMS structure and had been proved to\nbe a good platform due to its excellent mechanical properties. A cantilever\nworking in dynamic mode, adjust its resonance frequency depending on changes in\nboth the spring constant (k) and mass (m) of the resonator. The aim of this\nwork was to model a cantilever structure to determine the optimal dimensions in\nwhich the resonance frequency would be a function dominated by mass changes and\nnot stiffness changes. In order to validate the model a set of microcantilevers\nwere fabricated and characterized.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3102v1"
    },
    {
        "title": "Novel Bonding technologies for wafer-level transparent packaging of\n  MOEMS",
        "authors": [
            "H. Kirchberger",
            "P. Lindler",
            "M. Wimpliger"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Depending on the type of Micro-Electro-Mechanical System (MEMS), packaging\ncosts are contributing up to 80% of the total device cost. Each MEMS device\ncategory, its function and operational environment will individually dictate\nthe packaging requirement. Due to the lack of standardized testing procedures,\nthe reliability of those MEMS packages sometimes can only be proven by taking\ninto consideration its functionality over lifetime. Innovation with regards to\ncost reduction and standardization in the field of packaging is therefore of\nutmost importance to the speed of commercialisation of MEMS devices. Nowadays\nheavily driven by consumer applications the MEMS device market is forecasted to\nenjoy a compound annual growth rate (CAGR) above 13%, which is when compared to\nthe IC device market, an outstanding growth rate. Nevertheless this forecasted\nvalue can drift upwards or downwards depending on the rate of innovation in the\nfield of packaging. MEMS devices typically require a specific fabrication\nprocess where the device wafer is bonded to a second wafer which effectively\nencapsulates the MEMS structure. This method leaves the device free to move\nwithin a vacuum or an inert gas atmosphere.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3103v1"
    },
    {
        "title": "Design and Fabrication of the Suspended High-Q Spiral Inductors with\n  X-Beams",
        "authors": [
            "M. C. Hsieh",
            "D. K. Jair",
            "Y. K. Fang",
            "C. S. Lin"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, deep sub-micron CMOS process compatible high Q on chip spiral\ninductors with air gap structure were designed and fabricated. In the design\nthe electromagnetic were used for electrical-characteristics and maximum\nmechanical strength, respectively. The copper wires were capped with\nelectroless Ni plating to prevent the copper from oxidizing. A Si3N4/ SiO2\nX-beam was designed to increase the mechanical strength of the inductor in air\ngap. The enhancement of maximum mechanical strength of a spiral inductor with\nX-beams is more than 4500 times. Among these structures, the measured maximum\nquality factor (Q) of the suspending inductor and frequency at maximum Q are\nimproved from 5.2 and 1.6GHz of conventional spiral inductor to 7.3 and 2.1\nGHz, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3104v1"
    },
    {
        "title": "One MEMS Design Tool with Maximal Six Design Flows",
        "authors": [
            "H. Chang",
            "J. Xu",
            "J. Xie",
            "Ch. Zhang",
            "Z. Yan",
            "W. Yuan"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents one MEMS design tool with total six design flows, which\nmakes it possible that the MEMS designers are able to choose the most suitable\ndesign flow for their specific devices. The design tool is divided into three\nlevels and interconnected by six interfaces. The three levels are\nlumped-element model based system level, finite element analysis based device\nlevel and process level, which covers nearly all modeling and simulation\nfunctions for MEMS design. The six interfaces are proposed to automatically\ntransmit the design data between every two levels, thus the maximal six design\nflows could be realized. The interfaces take the netlist, solid model and\nlayout as the data inlet and outlet for the system, device and process level\nrespectively. The realization of these interfaces are presented and verified by\ndesign examples, which also proves that the enough flexibility in the design\nflow can really increase the design efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3105v1"
    },
    {
        "title": "Studies of Polymer Deformation and Recovery in Hot Embossing",
        "authors": [
            "X. C. Shan",
            "Y. C. Liu",
            "H. J. Lu",
            "Z. F. Wang",
            "Y. C. Lam"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In large area micro hot embossing, the process temperature plays a critical\nrole to both the local fidelity of microstructure formation and global\nuniformity. The significance of low temperature hot embossing is to improve\nglobal flatness of embossed devices. This paper reports on experimental studies\nof polymer deformation and relaxation in micro embossing when the process\ntemperatures are below or near its glass transition temperature (Tg). In this\ninvestigation, an indentation system and a micro embosser were used to\ninvestigate the relationship of microstructure formation versus process\ntemperature and load pressure. The depth of indentation was controlled and the\nload force at a certain indentation depth was measured. Experiments were\ncarried out using 1 mm thick PMMA films with the process temperature ranging\nfrom Tg-55 degrees C to Tg +20 degrees C. The embossed structures included a\nsingle micro cavity and groups of micro cavity arrays. It was found that at\ntemperature of Tg-55 degrees C, elastic deformation dominated the formation of\nmicrostructures and significant relaxation happened after embossing. From Tg-20\ndegrees C to Tg, plastic deformation dominated polymer deformation, and\npermanent cavities could be formed on PMMA substrates without obvious\nrelaxation. However, the formation of protrusive structures as micro pillars\nwas not complete since there was little polymer flow. With an increase in\nprocess temperature, microstructure could be formed under lower loading\npressure. Considering the fidelity of a single microstructure and global\nflatness of embossed substrates, micro hot embossing at a low process\ntemperature, but with good fidelity, should be preferred.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3106v1"
    },
    {
        "title": "Evaluation of the thermal and hydraulic performances of a very thin\n  sintered copper flat heat pipe for 3D microsystem packages",
        "authors": [
            "S. Tzanova",
            "L. Kamenova",
            "Y. Avenas",
            "Ch. Schaeffer"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The reported research work presents numerical studies validated by\nexperimental results of a flat micro heat pipe with sintered copper wick\nstructure. The objectives of this project are to produce and demonstrate the\nefficiency of the passive cooling technology (heat pipe) integrated in a very\nthin electronic substrate that is a part of a multifunctional 3-D electronic\npackage. The enhanced technology is dedicated to the thermal management of high\ndissipative microsystems having heat densities of more than 10W/cm2. Future\napplications are envisaged in the avionics sector. In this research 2D\nnumerical hydraulic model has been developed to investigate the performance of\na very thin flat micro heat pipe with sintered copper wick structure, using\nwater as a refrigerant. Finite difference method has been used to develop the\nmodel. The model has been used to determine the mass transfer and fluid flow in\norder to evaluate the limits of heat transport capacity as functions of the\ndimensions of the wick and the vapour space and for various copper spheres\nradii. The results are presented in terms of liquid and vapour pressures within\nthe heat pipe. The simulated results are validated by experiments and proved\nthat the method can be further used to predict thermal performance of the heat\npipe and to optimise its design.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3107v1"
    },
    {
        "title": "Architecture for Integrated Mems Resonators Quality Factor Measurement",
        "authors": [
            "H. Mathias",
            "F. Parrain",
            "J. -P. Gilles",
            "S. Megherbi",
            "M. Zhang",
            "Ph. Coste",
            "A. Dupret"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, an architecture designed for electrical measurement of the\nquality factor of MEMS resonators is proposed. An estimation of the measurement\nperformance is made using PSPICE simulations taking into account the\ncomponent's non-idealities. An error on the measured Q value of only several\npercent is achievable, at a small integration cost, for sufficiently high\nquality factor values (Q > 100).\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3767v1"
    },
    {
        "title": "Optimization of Cricket-inspired, Biomimetic Artificial Hair Sensors for\n  Flow Sensing",
        "authors": [
            "N. Izadi",
            "R. K. Jaganatharaja",
            "J. Floris",
            "G. Krijnen"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  High density arrays of artificial hair sensors, biomimicking the extremely\nsensitive mechanoreceptive filiform hairs found on cerci of crickets have been\nfabricated successfully. We assess the sensitivity of these artificial sensors\nand present a scheme for further optimization addressing the deteriorating\neffects of stress in the structures. We show that, by removing a portion of\nchromium electrodes close to the torsional beams, the upward lift at the edges\nof the membrane due to the stress, will decrease hence increase the\nsensitivity.\n",
        "pdf_link": "http://arxiv.org/pdf/0802.3768v1"
    },
    {
        "title": "Qtier-Rapor: Managing Spreadsheet Systems & Improving Corporate\n  Performance, Compliance and Governance",
        "authors": [
            "Keith Bishop"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Much of what EuSpRIG discusses is concerned with the integrity of individual\nspreadsheets. In businesses, interlocking spreadsheets are regularly used to\nfill functional gaps in core administrative systems. The growth and deployment\nof such integrated spreadsheet SYSTEMS raises the scale of issues to a whole\nnew level. The correct management of spreadsheet systems is necessary to ensure\nthat the business achieves its goals of improved performance and good corporate\ngovernance, within the constraints of legislative compliance - poor management\nwill deliver the opposite. This paper is an anatomy of the real-life issues of\nthe commercial use of spreadsheets in business, and demonstrates how\nQtier-Rapor has been used to instil best practice in the use of integrated\ncommercial spreadsheet systems.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.0011v1"
    },
    {
        "title": "From a set of parts to an indivisible whole. Part I: Operations in a\n  closed mode",
        "authors": [
            "Leonid Andreev"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper provides a description of a new method for information processing\nbased on holistic approach wherein analysis is a direct product of synthesis.\nThe core of the method is iterative averaging of all the elements of a system\naccording to all the parameters describing the elements. Contrary to common\nlogic, the iterative averaging of a system's elements does not result in\nhomogenization of the system; instead, it causes an obligatory subdivision of\nthe system into two alternative subgroups, leaving no outliers. Within each of\nthe formed subgroups, similarity coefficients between the elements reach the\nvalue of 1, whereas similarity coefficients between the elements of different\nsubgroups equal a certain constant value greater than 0 but lower than 1. When\nsubjected to iterative averaging, any system consisting of three or more\nelements of which at least two elements are not completely identical undergo\nsuch a process of bifurcation that occurs non-linearly. Successive iterative\naveraging of each of the forming subgroups eventually provides a hierarchical\nsystem that reflects relationships between the elements of an input system\nunder analysis. We propose a definition of a natural hierarchy that can exist\nonly in conditions of closeness of a system and can be discovered upon\nproviding such an effect onto a system which allows its elements interact with\neach other based on the principle of self-organization. Self-organization can\nbe achieved through an overall and total cross-averaging of a system's\nelements. We demonstrate the application potentials of the proposed technology\non a number of examples, including a system of scattered points, randomized\ndatasets, as well as meteorological and demographical datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.0034v2"
    },
    {
        "title": "Evaluation and exploitation of knowledge robustness in knowledge-based\n  systems",
        "authors": [
            "M. Barcikowski",
            "P. Pernelle",
            "A. Lefebvre",
            "M. Martinez",
            "J. Renaud"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Industrial knowledge is complex, difficult to formalize and very dynamic in\nreason of the continuous development of techniques and technologies. The\nverification of the validity of the knowledge base at the time of its\nelaboration is not sufficient. To be exploitable, this knowledge must then be\nable to be used under conditions (slightly) different from the conditions in\nwhich it was formalized. So, it becomes vital for the company to permanently\nevaluate the quality of the industrial knowledge implemented in the system.\nThis evaluation is founded on the concept of robustness of the knowledge\nformalized by conceptual graphs. The evaluation method is supported by a\ncomputerized tool.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.0529v1"
    },
    {
        "title": "Science mapping with asymmetrical paradigmatic proximity",
        "authors": [
            "Jean-Philippe Cointet",
            "David Chavalarias"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  We propose a series of methods to represent the evolution of a field of\nscience at different levels: namely micro, meso and macro levels. We use a\npreviously introduced asymmetric measure of paradigmatic proximity between\nterms that enables us to extract structure from a large publications database.\nWe apply our set of methods on a case study from the complex systems community\nthrough the mapping of more than 400 complex systems science concepts indexed\nfrom a database as large as several millions of journal papers. We will first\nsummarize the main properties of our asymmetric proximity measure. Then we show\nhow salient paradigmatic fields can be embedded into a 2-dimensional\nvisualization into which the terms are plotted according to their relative\nspecificity and generality index. This meso-level helps us producing\nmacroscopic maps of the field of science studied featuring the former\nparadigmatic fields.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.2315v1"
    },
    {
        "title": "The Role of Management Practices in Closing the Productivity Gap",
        "authors": [
            "Peer-Olaf Siebers",
            "Uwe Aickelin",
            "Giuliana Battisti",
            "Helen Celia",
            "Christopher Clegg",
            "Xiaolan Fu",
            "Raphael De Hoyos",
            "Alfonsiana Iona",
            "Alina Petrescu",
            "Peixoto Adriano"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  There is no doubt that management practices are linked to the productivity\nand performance of a company. However, research findings are mixed. This paper\nprovides a multi-disciplinary review of the current evidence of such a\nrelationship and offers suggestions for further exploration. We provide an\nextensive review of the literature in terms of research findings from studies\nthat have been trying to measure and understand the impact that individual\nmanagement practices and clusters of management practices have on productivity\nat different levels of analysis. We focus our review on Operations Management\n(om) and Human Resource Management (hrm) practices as well as joint\napplications of these practices. In conclusion, we can say that taken as a\nwhole, the research findings are equivocal. Some studies have found a positive\nrelationship between the adoption of management practices and productivity,\nsome negative and some no association whatsoever. We believe that the lack of\nuniversal consensus on the effect of the adoption of complementary management\npractices might be driven either by measurement issues or by the level of\nanalysis. Consequently, there is a need for further research. In particular,\nfor a multi-level approach from the lowest possible level of aggregation up to\nthe firm-level of analysis in order to assess the impact of management\npractices upon the productivity of firms.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.2995v2"
    },
    {
        "title": "Geographic Information Systems in Evaluation and Visualization of\n  Construction Schedule",
        "authors": [
            "V. K. Bansal",
            "Mahesh Pal"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Commercially available scheduling tools such as Primavera and Microsoft\nProject fail to provide information pertaining to the spatial aspects of\nconstruction project. A methodology using geographical information systems\n(GIS) is developed to represent spatial aspects of the construction progress\ngraphically by synchronizing it with construction schedule. The spatial aspects\nare depicted by 3D model developed in AutoCAD and construction schedule is\ngenerated using Microsoft Excel. Spatial and scheduling information are linked\ntogether into the GIS environment (ArcGIS). The GIS-based system developed in\nthis study may help in better understanding the schedule along with its spatial\naspects.\n",
        "pdf_link": "http://arxiv.org/pdf/0803.3515v1"
    },
    {
        "title": "Some properties of the regular asynchronous systems",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The asynchronous systems are the models of the asynchronous circuits from the\ndigital electrical engineering. An asynchronous system f is a multi-valued\nfunction that assigns to each admissible input u a set f(u) of possible states\nx in f(u). A special case of asynchronous system consists in the existence of a\nBoolean function \\Upsilon such that for any u and any x in f(u), a certain\nequation involving \\Upsilon is fulfilled. Then \\Upsilon is called the generator\nfunction of f (Moisil used the terminology of network function) and we say that\nf is generated by \\Upsilon. The systems that have a generator function are\ncalled regular.\n  Our purpose is to continue the study of the generation of the asynchronous\nsystems that was started in [2], [3].\n",
        "pdf_link": "http://arxiv.org/pdf/0804.2037v1"
    },
    {
        "title": "From a set of parts to an indivisible whole. Part II: Operations in an\n  open comparative mode",
        "authors": [
            "Leonid Andreev"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper describes a new method, HGV2C, for pattern analysis. The HGV2C\nmethod involves the construction of a computer ego (CE) based on an individual\nobject that can be either a part of the system under analysis or a newly\ncreated object based on a certain hypothesis. The CE provides a capability to\nanalyze data from a specific standpoint, e.g. from a viewpoint of a certain\nobject. The CE is constructed from two identical copies of a query object, and\nits functioning mechanism involves: a hypothesis-parameter (HP) and\ninfothyristor (IT). HP is a parameter that is introduced into an existing set\nof parameters. The HP value for one of the clones of a query object is set to\nequal 1, whereas for another clone it is greater than 1. The IT is based on the\npreviously described algorithm of iterative averaging and performs three\nfunctions: 1) computation of a similarity matrix for the group of three objects\nincluding two clones of a query object and a target object; 2) division of the\ngroup into two alternative subgroups; and 3) a successive increase of the HP\nweight in the totality of all the parameters. Initially, both clones of the\nquery object appear together in one of the subgroups as all of their parameter\nvalues, except the HP, are identical. At a certain point of the HP\nmultiplication, one of the clones moves to the group of the target object. A\nrespective number of the HP multiplications represents the dissimilarity (D)\nbetween the query and target objects. The product of D multiplied by the\ndifference in HP values of the clones is strictly constant and linearly\nincreases as the difference in HP values of the clones decreases. This new\napproach to knowledge representation is demonstrated on the example of\npopulation pyramids of 220 countries.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0455v1"
    },
    {
        "title": "Climate modification directed by control theory",
        "authors": [
            "Wang Liang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Climate modification measures to counteract global warming receive some more\nnew attentions in these years. Most current researches only discuss the impact\nof these measures to climate, but how to design such a climate regulator is\nstill unknown. This paper shows the control theory could give the systematic\ndirection for climate modification. But the control analyzing also reveals that\nclimate modifications should only be regarded as a last-ditch measure.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0541v2"
    },
    {
        "title": "Sub-$$ structured Lotus Surfaces Manufacturing",
        "authors": [
            "M. Worgull",
            "M. Heckele",
            "T. Mappes",
            "B. Matthis",
            "G. Tosello",
            "T. Metz",
            "J. Gavillet",
            "P. Koltay",
            "H. N. Hansen"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Sub-micro structured surfaces allow modifying the behavior of polymer films\nor components. Especially in micro fluidics a lotus-like characteristic is\nrequested for many applications. Structure details with a high aspect ratio are\nnecessary to decouple the bottom and the top of the functional layer. Unlike to\nstochastic methods, patterning with a LIGA-mold insert it is possible to\nstructure surfaces very uniformly or even with controlled variations (e.g. with\ngradients). In this paper we present the process chain to realize polymer\nsub-micro structures with minimum lateral feature size of 400 nm and up to 4\nmicrometers high.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0854v1"
    },
    {
        "title": "Linear and Non Linear Behaviour of Mechanical Resonators for Optimized\n  Inertial Electromagnetic Microgenerators",
        "authors": [
            "C. Serre",
            "A. Prez-Rodrigueza",
            "N. Fondevilla",
            "E. Martincic",
            "J. R. Morante",
            "J. Montserrat",
            "J. Esteve"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The need for wearable or abandoned microsystems, as well as the trend to a\nlower power consumption of electronic devices, make miniaturized renewable\nenergy generators a viable alternative to batteries. Among the different\nalternatives, an interesting option is the use of inertial microgenerators for\nenergy scavenging from vibrations present in the environment. These devices\nconstitute perpetual energy sources without the need for refilling, thus being\nwell suited for abandoned sensors, wireless systems or microsystems which must\nbe embedded within the structure, without outside physical connections.\nDifferent electromagnetic energy scavenging devices have been described in the\nliterature [1,2,3], based on the use of a velocity damped resonator, which is\nwell suited for harvesting of vibrational energy induced by the operation of\nmachines. These vibrations are characterized by a well defined frequency (in\nthe range between few Hz's and few kHz's) and low displacement amplitudes.\nAdjusting the resonant frequency of the system to that of the vibrations allows\namplification of these low amplitude displacements. Moreover, for these\napplications, the use of an electromagnetic device has the potential advantages\nof a good level of compatibility with Si Microsystem technology, as well as the\npossibility of relatively high electromechanical coupling with simple designs.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0855v1"
    },
    {
        "title": "Design And Fabrication of Condenser Microphone Using Wafer Transfer And\n  Micro-electroplating Technique",
        "authors": [
            "Zhen-Zhun Shu",
            "Ming-Li Ke",
            "Guan-Wei Chen",
            "Ray Hua Horng",
            "Chao-Chih Chang",
            "Jean-Yih Tsai",
            "Chung-Ching Lai",
            "Ji-Liang Chen"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A novel fabrication process, which uses wafer transfer and\nmicro-electroplating technique, has been proposed and tested. In this paper,\nthe effects of the diaphragm thickness and stress, the air-gap thickness, and\nthe area ratio of acoustic holes to backplate on the sensitivity of the\ncondenser microphone have been demonstrated since the performance of the\nmicrophone depends on these parameters. The microphone diaphragm has been\ndesigned with a diameter and thickness of 1.9 mm and 0.6 $\\mu$m, respectively,\nan air-gap thickness of 10 $\\mu$m, and a 24% area ratio of acoustic holes to\nbackplate. To obtain a lower initial stress, the material used for the\ndiaphragm is polyimide. The measured sensitivities of the microphone at the\nbias voltages of 24 V and 12 V are -45.3 and -50.2 dB/Pa (at 1 kHz),\nrespectively. The fabricated microphone shows a flat frequency response\nextending to 20 kHz.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0856v1"
    },
    {
        "title": "Porous Alumina Based Capacitive MEMS RH Sensor",
        "authors": [
            "L. Juhasz",
            "A. Vass-Varnai",
            "Veronika Timar-Horvath",
            "Marc Desmulliez",
            "Resh Dhariwal"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The aim of a joint research and development project at the BME and HWU is to\nproduce a cheap, reliable, low-power and CMOS-MEMS process compatible\ncapacitive type relative humidity (RH) sensor that can be incorporated into a\nstate-of-the-art, wireless sensor network. In this paper we discuss the\npreparation of our new capacitive structure based on post-CMOS MEMS processes\nand the methods which were used to characterize the thin film porous alumina\nsensing layer. The average sensitivity is approx. 15 pF/RH% which is more than\na magnitude higher than the values found in the literature. The sensor is\nequipped with integrated resistive heating, which can be used for maintenance\nto reduce drift, or for keeping the sensing layer at elevated temperature, as\nan alternative method for temperature-dependence cancellation.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0857v1"
    },
    {
        "title": "Integrated RF MEMS/CMOS Devices",
        "authors": [
            "R. R. Mansour",
            "S. Fouladi",
            "M. Bakeri-Kassem"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A maskless post-processing technique for CMOS chips is developed that enables\nthe fabrication of RF MEMS parallel-plate capacitors with a high quality factor\nand a very compact size. Simulations and measured results are presented for\nseveral MEMS/CMOS capacitors. A 2-pole coupled line tunable bandpass filter\nwith a center frequency of 9.5 GHz is designed, fabricated and tested. A tuning\nrange of 17% is achieved using integrated variable MEMS/CMOS capacitors with a\nquality factor exceeding 20. The tunable filter occupies a chip area of 1.2 x\n2.1 mm2.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0858v1"
    },
    {
        "title": "Design Methodology and Manufacture of a Microinductor",
        "authors": [
            "D. Flynn",
            "Marc Desmulliez"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Potential core materials to supersede ferrite in the 0.5-10 MHz frequency\nrange are investigated. The performance of electrodeposited nickel-iron,\ncobalt-iron-copper alloys and the commercial alloy Vitrovac 6025 have been\nassessed through their inclusion within a custom-made solenoid microinductor.\nAlthough the present inductor, at 500 KHz, achieves 77% power efficiency for\n24.7W/cm3 power density, an optimized process predicts a power efficiency of\n97% for 30.83W/cm3 power density. The principle issues regarding microinductor\ndesign and performance are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0859v1"
    },
    {
        "title": "Megasonic Enhanced Electrodeposition",
        "authors": [
            "Jens Georg Kaufmann",
            "Marc Desmulliez",
            "D. Price"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A novel way of filling high aspect ratio vertical interconnection (microvias)\nwith an aspect ratio of >2:1 is presented. High frequency acoustic streaming at\nmegasonic frequencies enables the decrease of the Nernst-diffusion layer down\nto the sub-micron range, allowing thereby conformal electrodeposition in deep\ngrooves. Higher throughput and better control over the deposition properties\nare possible for the manufacturing of interconnections and metal-based MEMS.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0860v1"
    },
    {
        "title": "UV Direct-Writing of Metals on Polyimide",
        "authors": [
            "Jack Hoyd-Gigg Ng",
            "Marc Desmulliez",
            "Aongus Mccarthy",
            "Himanshu Suyal",
            "Kevin Prior",
            "Duncan P. Hand"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Conductive micro-patterned copper tracks were fabricated by UV direct-writing\nof a nanoparticle silver seed layer followed by selective electroless copper\ndeposition. Silver ions were first incorporated into a hydrolyzed polyimide\nsurface layer by wet chemical treatment. A photoreactive polymer coating,\nmethoxy poly(ethylene glycol) (MPEG) was coated on top of the substrate prior\nto UV irradiation. Electrons released through the interaction between the MPEG\nmolecules and UV photons allowed the reduction of the silver ions across the\nMPEG/doped polyimide interface. The resultant silver seed layer has a cluster\nmorphology which is suitable for the initiation of electroless plating. Initial\nresults showed that the deposited copper tracks were in good agreement with the\ntrack width on the photomask and laser direct-writing can also fabricate\nsmaller line width metal tracks with good accuracy. The facile fabrication\npresented here can be carried out in air, at atmospheric pressure, and on\ncontoured surfaces.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0861v1"
    },
    {
        "title": "Micro Embossing of Ceramic Green Substrates for Micro Devices",
        "authors": [
            "X. -C. Shan",
            "S. H. Ling",
            "H. P. Maw",
            "C. W. Lu",
            "Y. C. Lam"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Multilayered ceramic substrates with embedded micro patterns are becoming\nincreasingly important, for example, in harsh environment electronics and\nmicrofluidic devices. Fabrication of these embedded micro patterns, such as\nmicro channels, cavities and vias, is a challenge. This study focuses on the\nprocess of patterning micro features on ceramic green substrates using micro\nembossing. A ceramic green tape that possessed near-zero shrinkage in the x-y\nplane was used, six layers of which were laminated as the embossing substrate.\nThe process parameters that impact on the pattern fidelity were investigated\nand optimized in this study. Micro features with line-width as small as several\nmicrometers were formed on the ceramic green substrates. The dynamic\nthermo-mechanical analysis indicated that extending the holding time at certain\ntemperature range would harden the green substrates with little effect on\nimproving the embossing fidelity. Ceramic substrates with embossed micro\npatterns were obtain d after co-firing. The embedded micro channels were also\nobtained by laminating the green tapes on the embossed substrates.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0862v1"
    },
    {
        "title": "Characterization and Modeling of an Electro-thermal MEMS Structure",
        "authors": [
            "P. G. Szabo",
            "Vladimir Szekely"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Thermal functional circuits are an interesting and perspectivic group of the\nMEMS elements. A practical realization is called Quadratic Transfer\nCharacteristic (QTC) element which driving principle is the Seebeck-effect. In\nthis paper we present the analyses of a QTC element from different\nperspectives. To check the real behavior of the device, we measured a few,\nsecondary properties of the structure which correspond to special behavior\nbecause these properties can not be easily derived from the main\ncharacteristics.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0863v1"
    },
    {
        "title": "Measurement of Large Forces and Deflections in Microstructures",
        "authors": [
            "Kai Axel Hals",
            "Einar Halvorsen",
            "Xuyuan Chen"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Properties of typical MEMS materials have been widely investigated.\nMechanical properties of MEMS structures depend not only on the bulk material\nproperties, but also structural factors. A measurement system has been made to\nmeasure force/deflection on microstructures to examine some of the structural\nproperties. This is a stylus setup integrated with a load cell and a linear\nactuator. First, the requirements for the measurement system were established.\nThen the system was built up and characterized. We have successfully made\nmeasurements on a typical micromechanical structure, a cantilever accelerometer\ndesign. The stylus placement accuracy, the spring constant along the proof\nmass, analysis of the force/deflection curve shape and destructive tests on the\ncantilever have been investigated in our experiment and will be presented in\nthis paper.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0864v1"
    },
    {
        "title": "Contactless Thermal Characterization of High Temperature Test Chamber",
        "authors": [
            "Z. Szucs",
            "G. Bognar",
            "Vladimir Szekely",
            "M. Rencz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper the methodology and the results of a contactless thermal\ncharacterization of a high temperature test chamber will be introduced. The\ntest chamber is used for fatigue testing of different MEMS devices where the\nhomogenous temperature distribution within the close proximity from the heating\nfilaments is very important. Our aim was to characterize the evolving\ntemperature distribution inside the test chamber. In order to achieve smaller\ntime constant a new contactless sensor card was developed. The contactless\nthermal characterization method introduced in this paper enables in situ heat\ndistribution measurement inside the test chamber during operation, with the\ndetection of potentially uneven heat distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0865v1"
    },
    {
        "title": "Processing and Characterization of Precision Microparts from\n  Nickel-based Materials",
        "authors": [
            "D. Allen",
            "H. J. Almond",
            "K. Bedner",
            "M. Cabezza",
            "B. Courtot",
            "A. Duval",
            "S. A. Impey",
            "M. Saumer"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The objective of this research was to study the influence of electroplating\nparameters on electrodeposit characteristics for the production of nickel (Ni)\nand nickel-iron (Ni-Fe) microparts by photoelectroforming. The research focused\non the most relevant parameter for industry, which is the current density,\nbecause it determines the process time and the consumed energy. The results of\nthe Ni and Ni-Fe characterisations can be divided into two aspects closely\nlinked with each other ; the morphology and the hardness.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0866v1"
    },
    {
        "title": "Manufacturing of A micro probe using supersonic aided electrolysis\n  process",
        "authors": [
            "R. F. Shyu",
            "Litsai Weng",
            "Chi-Ting Ho"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, a practical micromachining technology was applied for the\nfabrication of a micro probe using a complex nontraditional machining process.\nA series process was combined to machine tungsten carbide rods from original\ndimension. The original dimension of tungsten carbide rods was 3mm ; the rods\nwere ground to a fixed-dimension of 50 micrometers using precision grinding\nmachine in first step. And then, the rod could be machined to a\nmiddle-dimension of 20 micrometers by electrolysis. A final desired micro\ndimension can be achieved using supersonic aided electrolysis.\nHigh-aspect-ratio of micro tungsten carbide rod was easily obtained by this\nprocess. Surface roughness of the sample with supersonic aided agitation was\ncompared with that with no agitation in electrolysis. The machined surface of\nthe sample is very smooth due to ionized particles of anode could be removed by\nsupersonic aided agitation during electrolysis. Deep micro holes can also be\nachieved by the machined high-aspect-rati tungsten carbide rod using EDM\nprocess. A micro probe of a ball shape at the end was processed by proposed\nsupersonic aided electrolysis machining process.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0868v1"
    },
    {
        "title": "Large Area Roller Embossing of Multilayered Ceramic Green Composites",
        "authors": [
            "X. Shan",
            "Y. C. Soh",
            "C. W. P. Shi",
            "C. K. Tay",
            "C. W. Lu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, we will report our achievements in developing large area\npatterning of multilayered ceramic green composites using roller embossing. The\naim of our research is to pattern large area ceramic green composites using a\nmodified roller laminating apparatus, which is compatible with screen printing\nmachines, for integration of embossing and screen printing. The instrumentation\nof our roller embossing apparatus, as shown in Figure1, consists of roller 1\nand rollers 2. Roller 1 is heated up to the desired embossing temperature ;\nroller 2 is, however, kept at room temperature. The mould is a nickel template\nmanufactured by plating nickel-based micro patterns (height : 50 $\\mu$m) on a\nnickel film (thickness : 70 $\\mu$m) ; the substrate for the roller embossing is\na multilayered Heraeus Heralock HL 2000 ceramic green composite. Comparing with\nthe conventional simultaneous embossing, the advantages of roller embossing\ninclude : (1) low embossing force ; (2) easiness of demoulding ; (3) localized\narea in contact with heater ; and etc. We have demonstrated the capability of\nlarge area roller embossing with a panel size of 150mmx 150mm on the mentioned\nsubstrate. We have explored and confirmed the impact of parameters (feed speed,\ntemperature of roller and applied pressure) to the pattern quality of roller\nembossing. Furthermore, under the optimized process parameters, we\ncharacterized the variations of pattern dimension over the panel area, and\ncalculated a scaling factor in order to make the panel compatible with other\nprocesses. Figure 2 shows the embossed patterns on a 150mmx 150mm green ceramic\npanel.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0871v1"
    },
    {
        "title": "Study of mechanical response in embossing of ceramic green substrate by\n  micro-indentation",
        "authors": [
            "Y. C. Liu",
            "X. -C. Shan"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Micro-indentation test with a micro flat-end cone indenter was employed to\nsimulate micro embossing process and investigate the thermo-mechanical response\nof ceramic green substrates. The laminated low temperature co-fired ceramic\ngreen tapes were used as the testing material ; the correlations of indentation\ndepth versus applied force and applied stress at the temperatures of 25 degrees\nC and 75degrees C were studied. The results showed that permanent indentation\ncavities could be formed at temperatures ranging from 25 degrees C to 75\ndegrees C, and the depth of cavities created was applied force, temperature and\ndwell time dependent. Creep occurred and made a larger contribution to the\nplastic deformation at elevated temperatures and high peak loads. There was\ninstantaneous recovery during the unloading and retarded recovery in the first\nday after indentation. There was no significant pile-up due to material flow\nobserved under compression at the temperature up to 75 degrees C. The plastic\ndeformation was the main cause for formation of cavity on the ceramic green\nsubstrate under compression. The results can be used as a guideline for\nembossing ceramic green substrates.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0872v1"
    },
    {
        "title": "Top-Down Behavioral Modeling Methodology of a Piezoelectric\n  Microgenerator For Integrated Power Harvesting Systems",
        "authors": [
            "Hela Boussetta",
            "S. Basrour",
            "M. Marzencki"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this study, we developed a top/down methodology for behavioral and\nstructural modeling of multi-domain microsystems. Then, we validated this\nmethodology through a study case : a piezoelectric microgenerator. We also\nproved the effectiveness of VHDL-AMS language not only for modeling in\nbehavioral and structural levels but also in writing physical models that can\npredict the experimental results. Finally, we validated these models by\npresenting and discussing simulations results.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0873v1"
    },
    {
        "title": "Hybridization of Magnetism and Piezoelectricity for an Energy Scavenger\n  based on Temporal Variation of Temperature",
        "authors": [
            "L. Carlioz",
            "J. Delamare",
            "S. Basrour",
            "G. Poulin"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Autonomous microsystems are confronted today to a major challenge : the one\nof energy supply. Energy scavenging, i.e. collecting energy from the ambient\nenvironment has been developed to answer this problematic. Various sources have\nalready been successfully used (solar, vibration). This article presents\ntemporal variations of temperature as a new source of exploitable energy. A\nbrief review will take place at the beginning, exposing the different\napproaches used in the past. Then we will focus our attention on hybridization\nof magnetism and piezoelectricity. A new kind of thermal generator is proposed\nand a preliminary model is exposed. Conclusions will be drawn on the\nsuitability of this prototype and the improvements that are needed to increase\nits potential.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0874v1"
    },
    {
        "title": "Simulation of an Electrostatic Energy Harvester at Large Amplitude\n  Narrow and Wide Band Vibrations",
        "authors": [
            "Lars Geir Whist Tvedt",
            "Lars-Cyril Julin Blystad",
            "Einar Halvorsen"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  An electrostatic in-plane overlap varying energy harvester is modeled and\nsimulated using a circuit simulator. Both linear and nonlinear models are\ninvestigated. The nonlinear model includes mechanical stoppers at the\ndisplacement extremes. Large amplitude excitation signals, both narrow and wide\nband, are used to emulate environmental vibrations. Nonlinear behavior is\nsignificant at large displacement due to the impact on mechanical stoppers. For\na sinusoidal excitation the mechanical stoppers cause the output power to\nflatten and weakly decrease. For a wide band excitation, the output power first\nincreases linearly with the power spectral density of the input signal, then\ngrows slower than linearly.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0876v1"
    },
    {
        "title": "Optimization and AMS Modeling for Design of an Electrostatic Vibration\n  Energy Harvester's Conditioning Circuit with an Auto-Adaptive Process to the\n  External Vibration Changes",
        "authors": [
            "Dimitri Galayko",
            "Philippe Basset",
            "Ayyaz Mahmood Paracha"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Electrostatic transducers for vibration energy scavenging have been an object\nto numerous studies, but are still facing major issues relating to their\nconditioning circuit. One of the most popular ones uses a charge pump and a\nflyback circuit based on a Buck DC-DC converter (Fig. 1). A commutation between\nthe energy accumulation in the charge pump and the recharge of the buffer\ncapacitor Cres is assured by a switch which is the major bottleneck in the\nenergy harvester circuit. The commutation timing of the switch determines the\nefficiency of the energy harvesting. In previous papers [1] the switch\ncommutates periodically with some fixed duty ratio. However, this solution is\nnot appropriate when the environment parameters, e.g. the vibration frequency,\nchange. We found that the switching should be ordered by the internal state of\nthe circuit, an not by some fixed timing scenario. We presents how to find the\noptimal operation mode of the harvester. To validate the study, the system was\nmodeled using a mixed VHDL-AMS - ELDO model.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0877v1"
    },
    {
        "title": "Fabrication of Nanostructured PLGA Scaffolds Using Anodic Aluminum Oxide\n  Templates",
        "authors": [
            "Cheng-Chih Hsueh",
            "Gou-Jen Wang",
            "Shan-Hui Hsu",
            "Huey-Shan Hung"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  PLGA (poly(lactic-co-glycolic acid)) is one of the most used biodegradable\nand biocompatible materials. Nanostructured PLGA even has great application\npotentials in tissue engineering. In this research, a fabrication technique for\nnanostructured PLGA membrane was investigated and developed. In this novel\nfabrication approach, an anodic aluminum oxide (AAO) film was use as the\ntemplate ; the PLGA solution was then cast on it ; the vacuum air-extraction\nprocess was applied to transfer the nano porous pattern from the AAO membrane\nto the PLGA membrane and form nanostures on it. The cell culture experiments of\nthe bovine endothelial cells demonstrated that the nanostructured PLGA membrane\ncan double the cell growing rate. Compared to the conventional chemical-etching\nprocess, the physical fabrication method proposed in this research not only is\nsimpler but also does not alter the characteristics of the PLGA. The\nnanostructure of the PLGA membrane can be well controlled by the AAO temperate.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0879v1"
    },
    {
        "title": "High Performance Microreactor for Rapid Fluid Mixing and Redox Reaction\n  of Ascorbic Acid",
        "authors": [
            "Wei-Feng Fang",
            "J. T. Yang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A novel micro device with a mechanism of split and recombination (SNR) for\nrapid fluidic mixing and reaction, named a SNR micro-reactor, was designed,\nfabricated and systematically analyzed. This SNR micro-reactor possessing an\nin-plane dividing structure requires only simple fabrication. We investigated\nthis reactor and compared it numerically and experimentally with a\nslanted-groove micromixer (SGM). From the numerical results the mixing indices\nand mixing patterns demonstrated that the mixing ability of the SNR\nmicro-reactor was much superior to that of the SGM. From a mixing test with\nphenolphthalein and sodium hydroxide solutions, the mixing lengths of the SNR\nmicro-reactor were less than 4 mm for a Reynolds number over a wide range (Re =\n0.1 - 10). From a comparison of mixing lengths, the results revealed also that\nthe SNR micro-reactor surpassed the SGM in mixing performance by more than 200\n%. As a reaction length is a suitable test of the performance of a reactor, we\nintroduced a redox reaction between ascorbic acid and iodine solutions to\nassess the reaction capability of these micro devices ; the reaction lengths of\nthe SNR micro-reactor were much shorter than those of a SGM. The SNR\nmicro-reactor has consequently a remarkable efficiency for fluid mixing and\nreaction.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0880v1"
    },
    {
        "title": "Cell Trapping Utilizing Insulator-based Dielectrophoresis in The\n  Open-Top Microchannels",
        "authors": [
            "Chun-Ping Jen",
            "Yao-Hung Huang",
            "Teng-Wen Chen"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The ability to manipulate or separate a biological small particle, such as a\nliving cell and embryo, is fundamental needed to many biological and medical\napplications. The insulator-based dielectrophoresis (iDEP) trapping is composed\nof conductless tetragon structures in micro-chip. In this study, a lower\nconductive material of photoresist was adopted as a structure in open-top\nmicrochannel instead of a metallic wire to squeeze the electric field in a\nconducting solution, therefore, creating a high field gradient with a local\nmaximum. The microchip with the open-top microchannels was designed and\nfabricated herein. The insulator-based DEP trapping microchip with the open-top\nmicrochannels was designed and fabricated in this work. The cells trapped by\nDEP force could be further treated or cultured in the open-top microchannel ;\nhowever, those trapped in the microchip with enclosed microchannels could not\nbe proceeded easily.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0881v1"
    },
    {
        "title": "Design and Analysis of a Chaotic Micromixer with Vortices Modulation",
        "authors": [
            "K. Y. Tung",
            "J. T. Yang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A novel design for vortex modulation of a passive chaotic micromixer, named a\ncirculation-disturbance micromixer (CDM), has been achieved and analyzed\nexperimentally and numerically. The systematic numerical analyses - topological\nflow characteristics and particle tracking method - have been developed, that\nenable visualization of detailed mixing patterns. To display the cross section\nof mixing region of flows in our CDM, the biotin-streptavidin binding is\ndetected through the fluorescence resonance energy transfer (FRET) pair of\nfluorescent proteins - R-phycoerythrin (RPE) and cross-linked allophycocyanin\n(clAPC). We expect the diagnosis technique using FRET will be successfully\napplied to biochemical analysis in microfluidic system.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0882v1"
    },
    {
        "title": "Portable Valve-less Peristaltic Micro-pump Design and Fabrication",
        "authors": [
            "H. Yang",
            "T. -H. Tsai",
            "C. -C. Hu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper is to describe a design and fabrication method for a valve-less\nperistaltic micro-pump. The valve-less peristaltic micro-pump with three\nmembrane chambers in a serial is actuated by three piezoelectric (PZT)\nactuators. With the fluidic flow design, liquid in the flow channel is pumped\nto a constant flow speed ranged from 0.4 to 0.48 mm/s. In term of the maximum\nflow rate of the micro-pump is about 365 mircoliters/min, when the applied\nvoltage is 24V and frequency 50 Hz. Photolithography process was used to\nfabricate the micro-pump mold. PDMS molding and PDMS bonding method were used\nto fabricate the micro-channel and actuator chambers. A portable drive\ncontroller was designed to control three PZT actuators in a proper sequence to\ndrive the chamber membrane. Then, all parts were integrated into the portable\nvalve-less peristaltic micro-pump system.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0883v1"
    },
    {
        "title": "Microfluidic Device for Continuous Magnetophoretic Separation of Red\n  Blood Cells",
        "authors": [
            "Ciprian Iliescu",
            "Elena Barbarini",
            "Marioara Avram",
            "G. Xu",
            "Andrei Avram"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents a microfluidic device for magnetophoretic separation red\nblood cells from blood under contionous flow. The separation method consist of\ncontinous flow of a blood sample (diluted in PBS) through a microfluidic\nchannel which presents on the bottom \"dots\" of feromagnetic layer. By appling a\nmagnetic field perpendicular on the flowing direction, the feromagnetic \"dots\"\ngenerates a gradient of magnetic field which amplifies the magnetic force. As a\nresult, the red blood cells are captured on the bottom of the microfluidic\nchannel while the rest of the blood is collected at the outlet. Experimental\nresults show that an average of 95 % of red blood cells are trapped in the\ndevice\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0884v1"
    },
    {
        "title": "Fabrication of Embedded Microvalve on PMMA Microfluidic Devices through\n  Surface Functionalization",
        "authors": [
            "A. G. G. Toh",
            "Z. F. Wang",
            "S. H. Ng"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The integration of a PDMS membrane within orthogonally placed PMMA\nmicrofluidic channels enables the pneumatic actuation of valves within bonded\nPMMA-PDMS-PMMA multilayer devices. Here, surface functionalization of PMMA\nsubstrates via acid catalyzed hydrolysis and air plasma corona treatment were\ninvestigated as possible techniques to permanently bond PMMA microfluidic\nchannels to PDMS surfaces. FTIR and water contact angle analysis of\nfunctionalized PMMA substrates showed that air plasma corona treatment was most\neffective in inducing PMMA hydrophilicity. Subsequent fluidic tests showed that\nair plasma modified and bonded PMMA multilayer devices could withstand fluid\npressure at an operational flow rate of 9 mircoliters/min. The pneumatic\nactuation of the embedded PDMS membrane was observed through optical microscopy\nand an electrical resistance based technique. PDMS membrane actuation occurred\nat pneumatic pressures of as low as 10kPa and complete valving occurred at\n14kPa for 100 micrometers x 100 micrometers channel cross-sections.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0885v1"
    },
    {
        "title": "Hot Roller Embossing for the Creation of Microfluidic Devices",
        "authors": [
            "Sum Huan Ng",
            "Zhenfeng Wang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  We report on the hot roller embossing of polymer sheets for the creation of\nmicrofluidic structures. Measurements conducted on 100 $\\mu$m features showed\nthat the lateral dimensions could be replicated to within 2% tolerance, while\nover 85% of mould depth was embossed. Feature sizes down to 50 $\\mu$m and\nfeature depths up to 30 $\\mu$m had been achieved. At lower temperatures,\nasymmetric pile up of polymer material outside embossed regions was observed\nwith higher pile up occurring on the trailing side of the embossed regions.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0887v1"
    },
    {
        "title": "Geometrical Variation Analysis of an Electrothermally Driven Polysilicon\n  Microactuator",
        "authors": [
            "M. Shamshirsaz",
            "M. Maroufi",
            "M. B. Asgari"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The analytical models that predict thermal and mechanical responses of\nmicroactuator have been developed. These models are based on electro thermal\nand thermo mechanical analysis of the microbeam. Also, Finite Element Analysis\n(FEA) is used to evaluate microactuator tip deflection. Analytical and Finite\nElement results are compared with experimental results in literature and show\ngood agreement in low input voltages. A dimensional variation of beam lengths,\nbeam lengths ratios and gap are introduced in analytical and FEA models to\nexplore microactuator performance. An electrothermally driven polysilicon\nmicroactuator similar to Pan's actuator architecture has been studied in this\npaper. This microactuator generates deflection through asymmetric heating of\nthe hot and cold polysilicon arms with different lengths. For this\nmicroactuator architecture, an optimal beam length ratio equal to 0.46 has been\nobtained to achieve maximum tip deflection. . As it was expected, the results\nshow decreasing air gap increase microactuator tip deflection. It is also found\nthat for microactuators with longer hot arms, microactuator tip deflections are\nmore sensitive to beam length ratios and air gap.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0888v1"
    },
    {
        "title": "In-Plane Bistable Nanowire For Memory Devices",
        "authors": [
            "B. Charlot",
            "W. Sun",
            "K. Yamashita",
            "H. Fujita",
            "H. Toshiyoshi"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  We present a nanomechanical device design to be used in a non-volatile\nmechanical memory point. The structure is composed of a suspended slender\nnanowire (width : 100nm, thickness 430nm length : 8 to 30$\\mu$m) clamped at its\nboth ends. Electrodes are placed on each sides of the nanowire and are used to\nactuate the structure (writing, erasing) and to measure the position through a\ncapactive bridge (reading). The structure is patterned by electron beam\nlithography on a pre-stressed thermally grown silicon dioxide layer. When later\nreleased, the stressed material relaxes and the beam buckles in a position of\nlower energy. Such symmetric beams, called Euler beams, show two stable\ndeformed positions thus form a bistable structure. This paper will present the\nfabrication, simulation and mechanical and electrical actuation of an in plane\nbistable nanowire. Final paper will include a section on FEM simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0889v1"
    },
    {
        "title": "RF-MEMS Switched Varactors for Medium Power Applications",
        "authors": [
            "F. Maury",
            "A. Pothier",
            "A. Crunteanu",
            "F. Conseil",
            "P. Blondy"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In RF (Radio Frequency) domain, one of the limitations of using MEMS (Micro\nElectromechanical Systems) switching devices for medium power applications is\nRF power. Failure phenomena appear even for 500 mW. A design of MEMS switched\ncapacitors with an enhanced topology is presented in this paper to prevent it.\nThis kind of device and its promising performances will serve to fabricate a\nMEMS based phase shifter able to work under several watts.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0890v1"
    },
    {
        "title": "Low-Drift Flow Sensor with Zero-Offset Thermopile-Based Power Feedback",
        "authors": [
            "M. Dijkstra",
            "T. S. J. Lammerink",
            "Meint De Boer",
            "J. W. Berenschot",
            "Remco Wiegerink",
            "M. Elwenspoek"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A thermal flow sensor has been realised consisting of freely-suspended\nsilicon-rich silicon-nitride microchannels with an integrated Al/poly-Si++\nthermopile in combination with up- and downstream Al heater resistors. The\ninherently zero offset of the thermopile is exploited in a feedback loop\ncontrolling the dissipated power in the heater resistors, eliminating\ninevitable influences of resistance drift and mismatch of the thin-film metal\nresistors. The control system cancels the flow-induced temperature difference\nacross the thermopile by controlling a power difference between both heater\nresistors, thereby giving a measure for the flow rate. The flow sensor was\ncharacterised for power difference versus water flow rates up to 1.5 ul/min,\nbeing in good agreement with a thermal model of the sensor, and the correct\nlow-drift operation of the temperature-balancing control system has been\nverified.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0891v1"
    },
    {
        "title": "Single Chip Sensing of Multiple Gas Flows",
        "authors": [
            "P. Bruschi",
            "M. Dei",
            "M. Piotto"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The fabrication and experimental characterization of a thermal flow meter,\ncapable of detecting and measuring two independent gas flows with a single\nchip, is described. The device is based on a 4 x 4 mm2 silicon chip, where a\nseries of differential micro-anemometers have been integrated together with\nstandard electronic components by means of postprocessing techniques. The\ninnovative aspect of the sensor is the use of a plastic adapter, thermally\nbonded to the chip, to convey the gas flow only to the areas where the sensors\nare located. The use of this inexpensive packaging procedure to include\ndifferent sensing structures in distinct flow channels is demonstrated.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0892v1"
    },
    {
        "title": "Comparison Between Damping Coefficients of Measured Perforated\n  Micromechanical Test Structures and Compact Models",
        "authors": [
            "T. Veijola",
            "Giorgio De Pasquale",
            "Aurelio Som"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Measured damping coefficients of six different perforated micromechanical\ntest structures are compared with damping coefficients given by published\ncompact models. The motion of the perforated plates is almost translational,\nthe surface shape is rectangular, and the perforation is uniform validating the\nassumptions made for compact models. In the structures, the perforation ratio\nvaries from 24% - 59%. The study of the structure shows that the\ncompressibility and inertia do not contribute to the damping at the frequencies\nused (130kHz - 220kHz). The damping coefficients given by all four compact\nmodels underestimate the measured damping coefficient by approximately 20%. The\nreasons for this underestimation are discussed by studying the various flow\ncomponents in the models.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0893v1"
    },
    {
        "title": "A piecewise-linear reduced-order model of squeeze-film damping for\n  deformable structures including large displacement effects",
        "authors": [
            "A. Missoffe",
            "J. Juillard",
            "Denis Aubry"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents a reduced-order model for the Reynolds equation for\ndeformable structure and large displacements. It is based on the model\nestablished in [11] which is piece-wise linearized using two different methods.\nThe advantages and drawbacks of each method are pointed out. The pull-in time\nof a microswitch is determined and compared to experimental and other\nsimulation data.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0894v1"
    },
    {
        "title": "RF-MEMS beam components : FEM modelling and experimental identification\n  of pull-in in presence of residual stress",
        "authors": [
            "Alberto Ballestra",
            "Eugenio Brusa",
            "Giorgio De Pasquale",
            "Mircea Gh. Munteanu",
            "Aurelio Som"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper an experimental validation of numerical approaches aimed to\npredict the coupled behaviour of microbeams for out-of-plane bending tests is\nperformed. This work completes a previous investigation concerning in plane\nmicrobeams bending. Often out-of-plane microcantilevers and clamped-clamped\nmicrobeams suffer the presence of residual strain and stress, which affect the\nvalue of pull-in voltage. In case of microcantilever an accurate modelling\nincludes the effect of the initial curvature due to microfabrication. In double\nclamped microbeams a preloading applied by tensile stress is considered.\nGeometrical onlinearity caused by mechanical coupling between axial and\nflexural behaviour is detected and modelled. Experimental results demonstrate a\ngood agreement between FEM approaches proposed and tests. A fairly fast and\naccurate prediction of pull-in condition is performed, thus numerical models\ncan be used to identify residual stress in microbridges by reverse analysis\nfrom the measured value of pull-in voltage.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0895v1"
    },
    {
        "title": "Validation of compact models of microcantilever actuators for RF-MEMS\n  application",
        "authors": [
            "Eugenio Brusa",
            "Antonio Della-Gaspera",
            "Mircea Gh. Munteanu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Microcantilever specimens for in-plane and out-ofplane bending tests are here\nanalyzed. Experimental validation of 2D and 3D numerical models is performed.\nMain features of in-plane and out-of-plane layouts are then discussed.\nEffectiveness of plane models to predict pull-in in presence of geometric\nnonlinearity due to a large tip displacement and initial curvature of microbeam\nis investigated. The paper is aimed to discuss the capability of 2D models to\nbe used as compact tools to substitute some model order reduction techniques,\nwhich appear unsuitable in presence of both electromechanical and geometric\nnonlinearities.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0896v1"
    },
    {
        "title": "Numerical Investigation of Laser-Assisted Nanoimprinting on a Copper\n  Substrate from a Perspective of Heat Transfer Analysis",
        "authors": [
            "Chun-Ping Jen"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The technique of laser-assisted nanoimprinting lithography (LAN) has been\nproposed to utilize an excimer laser to irradiate through a quartz mold and\nmelts a thin polymer film on the substrate for micro- to nano-scaled\nfabrications. In the present study, the novel concept of that copper was\nadopted as the substrate instead of silicon, which is conventionally used, was\nproposed. The micro/nano structures on the copper substrate could be fabricated\nby chemical/electrochemical etching or electroforming ; following by the\npatterns have been transferred onto the substrate using LAN process.\nAlternatives of the substrate materials could lead versatile applications in\nmicro/nano-fabrication. To demonstrate the feasibility of this concept\nnumerically, this study introduced optical multiple reflection theory to\nperform both analytical and numerical modeling during the process and to\npredict the thermal response theoretically.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0897v1"
    },
    {
        "title": "Micro-electroforming metallic bipolar electrodes for mini-DMFC stacks",
        "authors": [
            "R. F. Shyu",
            "H. Yang",
            "J. -H. Lee"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper describes the development of metallic bipolar plate fabrication\nusing micro-electroforming process for mini-DMFC (direct methanol fuel cell)\nstacks. Ultraviolet (UV) lithography was used to define micro-fluidic channels\nusing a photomask and exposure process. Micro-fluidic channels mold with 300\nmicrometers thick and 500 micrometers wide were firstly fabricated in a\nnegative photoresist onto a stainless steel plate. Copper micro-electroforming\nwas used to replicate the micro-fluidic channels mold. Following by sputtering\nsilver (Ag) with 1.2 micrometers thick, the metallic bipolar plates were\ncompleted. The silver layer is used for corrosive resistance. The completed\nmini-DMFC stack is a 2x2 cm2 fuel cell stack including a 1.5x1.5 cm2 MEA\n(membrane electrode assembly). Several MEAs were assembly into mini-DMFC stacks\nusing the completed metallic bipolar plates. All test results showed the\nmetallic bipolar plates suitable for mini-DMFC stacks. The maximum output power\ndensity is 9.3mW/cm2 and current density is 100 mA/cm2 when using 8 vol. %\nmethanol as fuel and operated at temperature 30 degrees C. The output power\nresult is similar to other reports by using conventional graphite bipolar\nplates. However, conventional graphite bipolar plates have certain difficulty\nto be machined to such micro-fluidic channels. The proposed\nmicro-electroforming metallic bipolar plates are feasible to miniaturize DMFC\nstacks for further portable 3C applications.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0898v1"
    },
    {
        "title": "On the determination of Poisson's ratio of stressed monolayer and\n  bilayer submicron thick films",
        "authors": [
            "P. Martins",
            "C. Malhaire",
            "S. Brida",
            "D. Barbier"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper, the bulge test is used to determine the mechanical properties\nof very thin dielectric membranes. Commonly, this experimental method permits\nto determine the residual stress (s0) and biaxial Young's modulus (E/(1-u)).\nAssociating square and rectangular membranes with different length to width\nratios, the Poisson's ratio (u) can also be determined. LPCVD Si3N4 monolayer\nand Si3N4/SiO2 bilayer membranes, with thicknesses down to 100 nm, have been\ncharacterized giving results in agreement with literature for Si3N4, E = 212\n$\\pm$ 14 GPa, s0 = 420 $\\pm$ 8 and u = 0.29.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0899v1"
    },
    {
        "title": "New high fill-factor triangular micro-lens array fabrication method\n  using UV proximity printing",
        "authors": [
            "T. -H. Lin",
            "H. Yang",
            "C. -K. Chao"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A simple and effective method to fabricate a high fill-factor triangular\nmicrolens array using the proximity printing in lithography process is\nreported. The technology utilizes the UV proximity printing by controlling a\nprinting gap between the mask and substrate. The designed approximate triangle\nmicrolens array pattern can be fabricated the high fill-factor triangular\nmicrolens array in photoresist. It is due to the UV light diffraction to\ndeflect away from the aperture edges and produce a certain exposure in\nphotoresist material outside the aperture edges. This method can precisely\ncontrol the geometric profile of high fill factor triangular microlens array.\nThe experimental results showed that the triangular micro-lens array in\nphotoresist could be formed automatically when the printing gap ranged from 240\nmicrometers to 840 micrometers. The gapless triangular microlens array will be\nused to increases of luminance for backlight module of liquid crystal displays.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0900v1"
    },
    {
        "title": "Design Optimization for an Electro-Thermally Actuated Polymeric\n  Microgripper",
        "authors": [
            "R. Voicu",
            "R. Muller",
            "L. Eftime"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Thermal micro-actuators are a promising solution to the need for\nlarge-displacement, gentle handling force, low-power MEMS actuators. Potential\napplications of these devices are micro-relays, assembling and miniature\nmedical instrumentation. In this paper the development of thermal\nmicroactuators based on SU-8 polymer is described. The paper presents the\ndevelopment of a new microgripper which can realize a movement of the gripping\narms with possibility for positioning and manipulating of the gripped object.\nTwo models of polymeric microgripper electrothermo- mechanical actuated, using\nlow actuation voltages, designed for SU-8 polymer fabrication were presented.\nThe electro-thermal microgrippers were designed and optimized using finite\nelement simulations. Electro-thermo-mechanical simulations based on finite\nelement method were performed for each of the model in order to compare the\nresults. Preliminary experimental tests were carried out.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0901v1"
    },
    {
        "title": "Design And Fabrication of High Numerical Aperture And Low Aberration\n  Bi-Convex Micro Lens Array",
        "authors": [
            "Jhy-Cherng Tsai",
            "Ming-Fong Chen",
            "Hsiharng Yang"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Micro lens array is crucial in various kinds of optical and electronic\napplications. A micro lens array with high numerical aperture (NA) and low\naberration is in particular needed. This research is aimed to design and\nfabricate such a micro lens array with simple structure while keeps the same NA\nof a same-diameter hemisphere lens. A bi-convex semispherical micro lens array,\nwith corresponding NA 0.379, by PDMS is first designed and analyzed.\nExperiments are further conducted to fabricate the designed micro lens array by\nthe thermal reflow process. The formed profile is then sputtered with copper to\nserve as the mold. The front and the rear micro lens array are fabricated by\nplating PDMS to the mold and then assembled to form the designed micro lens\narray.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0903v1"
    },
    {
        "title": "Micromachined Inclinometer Based on Fluid Convection",
        "authors": [
            "N. Crespy",
            "J. Courteaud",
            "P. Combette",
            "P. Temple Boyer",
            "A. Giani",
            "A. Foucaran"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents a numerical simulation and experimental results of a\none-dimensional thermal inclinometer with the cavity filled of gas and liquid.\nThe sensor principle consists of one heating resistor placed between two\ndetectors. When the resistor is electrically powered, it creates a symmetrical\ntemperature profile inside a micromachined silicon cavity. By applying a tilt\nto the sensor, the profile shifts in the same direction of the sensible axis\ncorresponding to the horizontal one to one. The temperature profile and the\nsensitivity according to the CO2 gas and mineral oil SAE50 have been studied\nusing numerical resolution of fluid dynamics equations with the computational\nfluid dynamics (CFD) software package Fluent V6.2. We have shown that the\nsensitivity of liquid sensors is higher than the gas sensors one. By using\nmicromachined silicon technique, a thermal inclinometer with one pair of\ndetectors placed at 300 um from the heater has been made. Experimental\nmeasurements corroborate with the numerical simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0904v1"
    },
    {
        "title": "Model Based Sensor System for Temperature Measurement in R744 Air\n  Conditioning Systems",
        "authors": [
            "Sven Reitz",
            "Andreas Schroth",
            "Peter Schneider"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The goal is the development of a novel principle for the temperature\nacquisition of refrigerants in CO2 air conditioning systems. The new approach\nis based on measuring the temperature inside a pressure sensor, which is also\nneeded in the system. On the basis of simulative investigations of different\nmounting conditions functional relations between measured and medium\ntemperature will be derived.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0905v1"
    },
    {
        "title": "Integrated 3D Sound Intensity Sensor with Four-Wire Particle Velocity\n  Sensors",
        "authors": [
            "Doekle Yntema",
            "Joost Van Honschoten",
            "Remco Wiegerink"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A new symmetrical four-wire sensor configuration has resulted in a fully\nintegrated sound intensity sensor with significant lower noise floor and\nsmaller size than its predecessors. An integrated sound pressure sensor was\nfurther miniaturized by using a folded \"back chamber\" at both sides of the\nchip.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0906v1"
    },
    {
        "title": "High Aspect Pattern Formation by Integration of Micro Inkjetting and\n  Electroless Plating",
        "authors": [
            "P. W. Gian",
            "Xuechuan Shan",
            "Y. N. Liang",
            "B. K. Lok",
            "C. W. Lu",
            "B. L. Ooi"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper reports on formation of high aspect micro patterns on low\ntemperature co-fired ceramic (LTCC) substrates by integrating micro inkjetting\nwith electroless plating. Micro inkjetting was realized by using an inkjetting\nprinter that ejects ink droplets from a printhead. This printhead consists of a\nglass nozzle with a diameter of 50 micrometers and a piezoelectric transducer\nthat is coated on the nozzle. The silver colloidal solution was inkjetted on a\nsintered CT800 ceramic substrate, followed by curing at 200 degrees C for 60\nminutes. As a result, the silver trace with a thickness of 200 nm was obtained.\nThe substrate, with the ejected silver thin film as the seed layer, was then\nimmersed into a preinitiator solution to coat a layer of palladium for\nenhancing the deposition of nickel. Electroless nickel plating was successfully\nconducted at a rate of 0.39 micrometers /min, and the thickness of traces was\nplated up to 84 micrometers. This study demonstrates that the integration of\ninkjetting with plating is an effective method to form high aspect patterns at\nthe demand location.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0907v1"
    },
    {
        "title": "A Nanostructual Microwave Probe Used for Atomic Force Microscope",
        "authors": [
            "Y. Ju",
            "M. Hamada",
            "T. Kobayashi",
            "H. Soyama"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In order to develop a new structure microwave probe, the fabrication of AFM\nprobe on the GaAs wafer was studied. A waveguide was introduced by evaporating\nAu film on the top and bottom surfaces of the GaAs AFM probe. A tip having 8\nmicrometers high, and curvature radius about 50 nm was formed. The dimensions\nof the cantilever are 250x30x15 micrometers. The open structure of the\nwaveguide at the tip of the probe was introduced by using FIB fabrication. AFM\ntopography of a grating sample was measured by using the fabricated GaAs\nmicrowave probe. The fabricated probe was found having nanometer scale\nresolution, and microwave emission was detected successfully at the tip of the\nprobe by approaching Cr-V steel and Au wire samples.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0908v1"
    },
    {
        "title": "High Density out-of-Plane Microprobe Array",
        "authors": [
            "Huang C. H. Huang C. H.",
            "Chingfu Tsou",
            "Tenghsien Lai"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  MEMS technology has been developed rapidly in the last few years. More and\nmore special micro structures were discussed in several publications. However,\nall of the structures were produced by consist of the three fundamental\nstructures, which included bridge, cantilever and membrane structures. Even the\nmore complex structures were no exception. The cantilever with the property of\nsimple design and easy fabrication among three kinds of fundamental structure,\ntherefore, it was popular used in the design of MEMS device.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0911v1"
    },
    {
        "title": "Simulation of Coating -Visco-Elastic liquid in the Mico-Nip of Metering\n  Size Press",
        "authors": [
            "Haifa El-Sadi",
            "N. Esmail"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  For a set of operating conditions and coating color formulations, undesirable\nphenomena like color spitting and coating ribs may be triggered in the\nMicro-nip during the coating process. Therefore, our interest in this work\nfocus on another parameter affect on the undesirable phenomena as the vortices\nin the Micro-nip. The problem deals with the flow through the Micro-nip of\nmetering size press. The flow enters and exits at a tangential velocity of 20\nm/s between two rollers with diameter 80 cm and 60 -m apart. In the upper and\nbottom part of the domain the angular velocity is 314 rad /s. It has one\nsub-domain. Previous studies focus on the Micro-nip without considering the\ninertia and the viscoelasticity of the material. Roll coating is a technique\ncommonly used in the coating industry to meter a thin fluid film on a moving\nsubstrate. During the film formation, the fluid is subjected to very high shear\nand extensional rates over a very short period of time. The fluid domain\nchanges as a function of the hydrodynamic pressure within the nip as a result\nof the deformable cover usually used on one of the rolls. The free surface also\nadds more complexity to the flow due to the force equilibrium in the fluid gas\ninterface. Last of all, the rheological behavior of the coating fluid is\nusually non-Newtonian, so the metering flow hydrodynamics is finally very\ndifficult to describe. It is concluded that the normal forces of micro-nip\nincreases with increasing the inhibitors. Therefore, it affects on the\nsmoothness and creates defects. On the other hand, it can be concluded that the\ncreation of big vortex in the middle of micro-nip affects on the coating liquid\nbehavior.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0912v1"
    },
    {
        "title": "A Microcantilever-based Gas Flow Sensor for Flow Rate and Direction\n  Detection",
        "authors": [
            "Y. -H. Wang",
            "Tzu-Han Hsueh",
            "Rong-Hua Ma",
            "Chia-Yen Lee",
            "Lung-Ming Fu",
            "P. -Ch. Chou",
            "Chien-Hsiung Tsai"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The purpose of this paper is to apply characteristics of residual stress that\ncauses cantilever beams to bend for manufacturing a micro-structured gas flow\nsensor. This study uses a silicon wafer deposited silicon nitride layers,\nreassembled the gas flow sensor with four cantilever beams that perpendicular\nto each other and manufactured piezoresistive structure on each\nmicro-cantilever by MEMS technologies, respectively. When the cantilever beams\nare formed after etching the silicon wafer, it bends up a little due to the\nreleased residual stress induced in the previous fabrication process. As air\nflows through the sensor upstream and downstream beam deformation was made,\nthus the airflow direction can be determined through comparing the resistance\nvariation between different cantilever beams. The flow rate can also be\nmeasured by calculating the total resistance variations on the four\ncantilevers.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0913v1"
    },
    {
        "title": "Process nano scale mechanical properties measurement of thin metal films\n  using a novel paddle cantilever test structure",
        "authors": [
            "Chi-Jia Tong",
            "Ming-Tzer Lin"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A new technique was developed for studying the mechanical behavior of\nnano-scale thin metal films on substrate is presented. The test structure was\ndesigned on a novel \"paddle\" cantilever beam specimens with dimensions as few\nhundred nanometers to less than 10 nanometers. This beam is in triangle shape\nin order to provide uniform plane strain distribution. Standard clean room\nprocessing was used to prepare the paddle sample. The experiment can be\noperated by using the electrostatic deflection on the paddle uniform\ndistributed stress cantilever beam and then measure the deposited thin metal\nfilm materials on top of it. A capacitance technique was used to measurement on\nthe other side of the deflected plate to measure its deflection with respect to\nthe force. The measured strain was converted through the capacitance\nmeasurement for the deflection of the cantilever. System performance on the\nresidual stress measurement of thin films are calculated with three different\nforces on the \"paddle\" cantilever beam, including the force due to the film,\ncompliance force and electrostatic force.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0914v1"
    },
    {
        "title": "High Q-factor CMOS-MEMS inductor",
        "authors": [
            "Ching-Liang Dai",
            "Jin-Yu Hong",
            "Mao-Chen Liu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This study investigates a high Q-factor spiral inductor fabricated by the\nCMOS (complementary metal oxide semiconductor) process and a post-process. The\nspiral inductor is manufactured on silicon substrate using the 0.35 micrometers\nCMOS process. In order to reduce the substrate loss and enhance the Q-factor of\nthe inductor, silicon substrate under the inductor is removed using a\npost-process. The post-process uses RIE (reactive ion etching) to etch the\nsacrificial layer of silicon dioxide, and then TMAH (tetra methyl ammonium\nhydroxide) is employed to remove the underlying silicon substrate and obtain\nthe suspended spiral inductor. The advantage of the post process is compatible\nwith the CMOS process. The Agilent 8510C network analyzer and a Cascade probe\nstation are used to measure the performances of the spiral inductor.\nExperiments indicate that the spiral inductor has a Q-factor of 15 at 11 GHz,\nan inductance of 4 nH at 25.5 GHz and a self-resonance frequency of about 27\nGHz.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0915v1"
    },
    {
        "title": "Copper Electrodeposition for 3D Integration",
        "authors": [
            "Rozalia Beica",
            "Charles Sharbono",
            "Tom Ritzdorf"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Two dimensional (2D) integration has been the traditional approach for IC\nintegration. Due to increasing demands for providing electronic devices with\nsuperior performance and functionality in more efficient and compact packages,\nhas driven the semiconductor industry to develop more advanced packaging\ntechnologies. Three-dimensional (3D) approaches address both miniaturization\nand integration required for advanced and portable electronic products.\nVertical integration proved to be essential in achieving a greater integration\nflexibility of disparate technologies, reason for which a general trend of\ntransition from 2D to 3D integration is currently being observed in the\nindustry. 3D chip integration using through silicon via (TSV) copper is\nconsidered one of the most advanced technologies among all different types of\n3D packaging technologies. Copper electrodeposition is one of technologies that\nenable the formation of TSV structures. Because of its well-known application\nfor copper damascene, it was believed that its transfer to filling TSV vias\nwould be easily adopted. However, as any new technology at its beginning, there\nare several challenges that need to be addressed and resolved before becoming a\nfully mature technology. This paper will address the TSV fill processes using\ncopper electrodeposition, the advantages as well as difficulties associated\nwith this technology and approaches taken to overcome them. Electrochemical\ncharacterization of the organics behavior and their effect on via filling will\nbe presented. The effect of wafer design on process performance and throughput,\nincluding necessary process optimizations that are required for achieving\nvoid-free via filling while reducing the processing time, will be discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0916v1"
    },
    {
        "title": "Technologies for 3D Heterogeneous Integration",
        "authors": [
            "Jrgen Wolf",
            "P. Ramm",
            "Armin Klumpp",
            "H. Reichl"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  3D-Integration is a promising technology towards higher interconnect\ndensities and shorter wiring lengths between multiple chip stacks, thus\nachieving a very high performance level combined with low power consumption.\nThis technology also offers the possibility to build up systems with high\ncomplexity just by combining devices of different technologies. For ultra thin\nsilicon is the base of this integration technology, the fundamental processing\nsteps will be described, as well as appropriate handling concepts. Three main\nconcepts for 3D integration have been developed at IZM. The approach with the\ngreatest flexibility called Inter Chip Via - Solid Liquid Interdiffusion\n(ICV-SLID) is introduced. This is a chip-to-wafer stacking technology which\ncombines the advantages of the Inter Chip Via (ICV) process and the\nsolid-liquid-interdiffusion technique (SLID) of copper and tin. The fully\nmodular ICV-SLID concept allows the formation of multiple device stacks. A test\nchip was designed and the total process sequence of the ICV-SLID technology for\nthe realization of a three-layer chip-to-wafer stack was demonstrated. The\nproposed wafer-level 3D integration concept has the potential for low cost\nfabrication of multi-layer high-performance 3D-SoCs and is well suited as a\nreplacement for embedded technologies based on monolithic integration. To\naddress yield issues a wafer-level chip-scale handling is presented as well, to\nselect known-good dies and work on them with wafer-level process sequences\nbefore joining them to integrated stacks.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0917v1"
    },
    {
        "title": "Through Silicon Vias as Enablers for 3D Systems",
        "authors": [
            "E. Jung",
            "Andreas Ostmann",
            "Peter Ramm",
            "Jrgen Wolf",
            "Michael Toepper",
            "Maik Wiemer"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This special session on 3D TSV's will highlight some of the fabrication\nprocesses and used technologies to create vias from the frontside of an active\ncircuit to its backside and potential implementation solutions to form complex\nsystems leveraging these novel possibilities. General techniques for via\nformation are discussed as well as advanced integration solutions leveraging\nthe power of 3D TSV's.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0918v1"
    },
    {
        "title": "Fabrication of 3D Packaging TSV using DRIE",
        "authors": [
            "M. Puech",
            "Jean-Marc Thevenoud",
            "J. M. Gruffat",
            "N. Launay",
            "N. Arnal",
            "P. Godinat"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Emerging 3D chips stacking and MEMS/Sensors packaging technologies are using\nDRIE (Deep Reactive Ion Etching) to etch through-silicon via (TSV) for advanced\ninterconnections. The interconnection step can be done prior to or post CMOS\nmanufacturing, each requiring different etch process performances. A review of\nthe DRIE capability in terms of etching profile, etch rate, etch depth has been\ncarried out. Excellent tool flexibility allows a wide range of basic and\ncomplex profiles to be achieved. Unlike other techniques, DRIE has the\ncapability to etch feature sizes ranging from sub-micron to millimeter width.\nThe main specificity of the DRIE is that etch rate is sensitive to the total\nexposed area and the aspect ratio. For the TSV applications, where the total\nexposed area is lower than 10%, high etch rates are achievable. A study has\nalso been done to highlight the importance of via profile for the success of\nthe refilling step. In addition, due to the high flexibility of DRIE, we also\nexplore the capability of using this technique for wafer thinning and plasma\ndie separation.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0919v1"
    },
    {
        "title": "Study of First-Order Thermal Sigma-Delta Architecture for Convective\n  Accelerometers",
        "authors": [
            "Pascal Nouet",
            "Frdrick Mailly",
            "Laurent Latorre",
            "Pascal Nouet"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents the study of an original closed-loop conditioning\napproach for fully-integrated convective inertial sensors. The method is\napplied to an accelerometer manufactured on a standard CMOS technology using an\nauto-aligned bulk etching step. Using the thermal behavior of the sensor as a\nsumming function, a first order sigma-delta modulator is built. This\n\"electro-physical\" modulator realizes an analog-to-digital conversion of the\nsignal. Besides the feedback scheme should improve the sensor performance.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0920v1"
    },
    {
        "title": "High Density Through Silicon Via (TSV)",
        "authors": [
            "Magnus Rimskog",
            "Tomas Bauer"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The Through Silicon Via (TSV) process developed by Silex provides down to 30\nmicrometers pitch for through wafer connections in up to 600 micrometers thick\nsubstrates. Integrated with MEMS designs it enables significantly reduced die\nsize and true \"Wafer Level Packaging\" - features that are particularly\nimportant in consumer market applications. The TSV technology also enables\nintegration of advanced interconnect functions in optical MEMS, sensors and\nmicrofluidic devices. In addition the Via technology opens for very interesting\npossibilities considering integration with CMOS processing. With several\ncompanies using the process already today, qualified volume manufacturing in\nplace and a line-up of potential users, the process is becoming a standard in\nthe MEMS industry. We provide a introduction to the via formation process and\nalso present some on the novel solutions made available by the technology.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0922v1"
    },
    {
        "title": "Rejection of Power Supply Noise in Wheatstone Bridges : Application to\n  Piezoresistive MEMS",
        "authors": [
            "El Mehdi Boujamaa",
            "Yannick Soulie",
            "Frdrick Mailly",
            "Laurent Latorre",
            "Pascal Nouet"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper deals with the design of MEMS using piezoresistivity as\ntransduction principle. It is demonstrated that when the sensor topology\ndoesn't allow a perfect matching of strain gauges, the resolution is limited by\nthe ability of the conditioning circuit (typically a Wheatstone bridge) to\nreject power supply noise. As this ability is strongly reduced when an offset\nvoltage is present at the output of the bridge, the proposed architecture\nimplements a feedback loop to control MOS transistors inserted in the\nWheatstone bridge to compensate resistor mismatches. This feedback exhibits a\nvery good offset cancellation and therefore a better resolution is achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0925v1"
    },
    {
        "title": "Next Generation of TCAD Environments for MEMS Design",
        "authors": [
            "Udo Triltsch",
            "Stephanus Bttgenbach"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this paper we present the latest version of the TCAD environment BICEP'S\n(Braunschweigs Integrated CAD-Environment for Product Planning and Process\nSimulation). By using a central process database, which allows the exchange of\nall relevant process data it is able to overcome many of the mentioned\nobstacles. The database and process planning tool can be used by process\ndevelopers to document changes in process settings and the influence of such\nchanges on the process result. This information can then be used by the\ndesigners to set-up a simulation file for a detailed analysis of the impact of\nsuch parameter changes on the requested design. This will be shown by the\nexample of silicon etching using an atomistic etch simulator.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0926v1"
    },
    {
        "title": "Noise Analysis and Noise-based Optimization for Resonant MEMS Structures",
        "authors": [
            "Mrigank Sharma",
            "Akila Kannan",
            "Edmond Cretu"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents a detailed noise analysis and a noise-based optimization\nprocedure for resonant MEMS structures. A design for high sensitivity of MEMS\nstructures needs to take into account the noise shaping induced by damping\nphenomena at micro scale. The existing literature presents detailed models for\nthe damping at microscale, but usually neglects them in the noise analysis\nprocess, assuming instead a white spectrum approximation for the\nmechano-thermal noise. The present work extends the implications of the complex\ngas-solid interaction into the field of noise analysis for mechanical sensors,\nand provides a semi-automatic procedure for behavioral macromodel extraction\nand sensor optimization with respect to signal-to-noise ratio.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0927v1"
    },
    {
        "title": "Haptic sensing for MEMS with application for cantilever and Casimir\n  effect",
        "authors": [
            "M. Calis",
            "Marc Desmulliez"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents an implementation of the Cosserat theory into haptic\nsensing technologies for real-time simulation of microstructures. Cosserat\ntheory is chosen instead of the classical theory of elasticity for a better\nrepresentation of stress, especially in the nonlinear regime. The use of\nCosserat theory leads to a reduction of the complexity of the modelling and\nthus increases its capability for real time simulation which is indispensable\nfor haptic technologies. The incorporation of Cosserat theory into haptic\nsensing technology enables the designer to simulate in real-time the components\nin a virtual reality environment (VRE) which can enable virtual manufacturing\nand prototyping. The software tool created as a result of this methodology\ndemonstrates the feasibility of the proposed model. As test demonstrators, a\ncantilever microbeam and microbridge undergoing bending in VRE are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0929v1"
    },
    {
        "title": "On-Chip Hotplate for Temperature Control of Cmos Saw Resonators",
        "authors": [
            "Anis Nordin",
            "Ioana Voiculescu",
            "Mona Zaghloul"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Due to the sensitivity of the piezoelectric layer in surface acoustic wave\n(SAW) resonators to temperature, a method of achieving device stability as a\nfunction of temperature is required. This work presents the design, modeling\nand characterization of integrated dual-serpentine polysilicon resistors as a\nmethod for temperature control of CMOS SAW resonators. The design employs the\noven control temperature stabilization scheme where the device's temperature is\nelevated to higher than Tmax to maintain constant device temperature. The\nefficiency of the polysilicon resistor as a heating element was verified\nthrough a 1-D partial differential equation model, 3-D CoventorWare finite\nelement simulations and measurements using Compix thermal camera. To verify\nthat the on-chip hotplate is effective as a temperature control method, both DC\nand RF measurements of the heater together with the resonator were conducted.\nExperimental results have indicated that the TCF of the CMOS SAW resonator of\n-97.2 ppm/deg C has been reduced to -23.19 ppm/deg C when heated to 56 deg C.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0930v1"
    },
    {
        "title": "Modelling methodology of MEMS structures based on Cosserat theory",
        "authors": [
            "Mustafa Calis",
            "Omar Laghrouche",
            "Marc Desmulliez"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Modelling MEMS involves a variety of software tools that deal with the\nanalysis of complex geometrical structures and the assessment of various\ninteractions among different energy domains and components. Moreover, the MEMS\nmarket is growing very fast, but surprisingly, there is a paucity of modelling\nand simulation methodology for precise performance verification of MEMS\nproducts in the nonlinear regime. For that reason, an efficient and rapid\nmodelling approach is proposed that meets the linear and nonlinear dynamic\nbehaviour of MEMS systems.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0931v1"
    },
    {
        "title": "Low Voltage Totally Free Flexible RF MEMS Switch With Anti-Stiction\n  System",
        "authors": [
            "Salim Touati",
            "Nicolas Lorphelin",
            "Alexandre Kanciurzewski",
            "Renaud Robin",
            "A. -S. Rollier",
            "Olivier Millet",
            "Karim Segueni"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper concerns a new design of RF MEMS switch combined with an\ninnovative process which enable low actuation voltage (<5V) and avoid stiction.\nFirst, the structure described with principal design issues, the corresponding\nanti-stiction system is presented and FEM simulations are done. Then, a short\ndescription of the process flow based on two non polymer sacrificial layers.\nFinally, RF measurements are presented and preliminary experimental protocol\nand results of anti-stiction validation is detailed. Resulting RF performances\nare -30dB of isolation and -0.45dB of insertion loss at 10 GHz.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0932v1"
    },
    {
        "title": "High Quality Factor Silicon Cantilever Driven by PZT Actuator for\n  Resonant Based Mass Detection",
        "authors": [
            "Jian Lu",
            "T. Ikehara",
            "Yi Zhang",
            "Takashi Mihara",
            "Toshihiro Itoh",
            "Ryutaro Maeda"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A high quality factor (Q-factor) piezoelectric lead zirconat titanate (PZT)\nactuated single crystal silicon cantilever was proposed in this paper for\nresonant based ultra-sensitive mass detection. Energy dissipation from\nintrinsic mechanical loss of the PZT film was successfully compressed by\nseparating the PZT actuator from resonant structure. Excellent Q-factor, which\nis several times larger than conventional PZT cantilever, was achieved under\nboth atmospheric pressure and reduced pressures. For a 30 micrometer-wide 100\nmicrometer-long cantilever, Q-factor was measured as high as 1113 and 7279\nunder the pressure of 101.2 KPa and 35 Pa, respectively. Moreover, it was found\nthat high-mode vibration can be realized by the cantilever for the pursuit of\ngreat Q-factor, while support loss became significant because of the increased\nvibration amplitude at the actuation point. An optimized structure using\nnode-point actuation was suggested then to suppress corresponding energy\ndissipation.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0933v1"
    },
    {
        "title": "A New Four States High Deflection Low Actuation Voltage Electrostatic\n  Mems Switch for RF Applications",
        "authors": [
            "Renaud Robin",
            "Salim Touati",
            "Karim Segueni",
            "Olivier Millet",
            "Lionel Buchaillot"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents a new electrostatic MEMS (MicroElectroMechanical System)\nbased on a single high reliability totally free flexible membrane. Using four\nelectrodes, this structure enables four states which allowed large deflections\n(4$\\mu$m) with low actuation voltage (7,5V). This design presents also a good\ncontact force and improve the restoring force of the structure. As an example\nof application, a Single Pole Double Throw (SPDT) for 24GHz applications, based\non this design, has been simulated.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0934v1"
    },
    {
        "title": "Design and Fabrication of a Novel Micro Electromagnetic Actuator",
        "authors": [
            "C. -Y. Lee",
            "Zgen-Hui Chen",
            "Hsien-Tseng Chang",
            "Chiang-Ho Cheng",
            "Chih-Yung Wen"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The present study presents a new micro electromagnetic actuator utilizing a\nPDMS membrane with a magnet. The actuator is integrated with micro coils to\nelectromagnetically actuate the membrane and results in a large deflection. The\nmicro electromagnetic actuator proposed in this study is easily fabricated and\nis readily integrated with existing bio-medical chips due to its planar\nstructure.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0935v1"
    },
    {
        "title": "Flexible Micro Thermoelectric Generator based on Electroplated Bi2Te3",
        "authors": [
            "E. Schwyter",
            "W. Glatz",
            "L. Durrer",
            "Ch. Hierold"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  We present and discuss the fabrication process and the performance of a\nflexible micro thermoelectric generator with electroplated Bi2Te3 thermocouples\nin a SU-8 mold. Demonstrator devices generate 278uWcm-2 at dTmeas=40K across\nthe experimental set up. Based on model calculations, a temperature difference\nof dTG=21.4K across the generator is assumed. Due to the flexible design and\nthe chosen generator materials, the performance stays high even for curved\ncontact surfaces. The measurement results correlate well with the model based\ndesign optimization predictions.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0937v1"
    },
    {
        "title": "A Novel Piezoelectric Microtransformer for Autonmous Sensors\n  Applications",
        "authors": [
            "Patrick Sangouard",
            "G. Lissorgues",
            "T. Bourouina"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This work relates to a novel piezoelectric transformer to be used in an\nautonomous sensor unit, possibly in conjunction with a RF-MEMS retro-modulator.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0938v1"
    },
    {
        "title": "Optimization of efficiency and energy density of passive micro fuel\n  cells and galvanic hydrogen generators",
        "authors": [
            "Robert Hahn",
            "Stefan Wagner",
            "Steffen Krumbholz",
            "Herbert Reichl"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A PEM micro fuel cell system is described which is based on self-breathing\nPEM micro fuel cells in the power range between 1 mW and 1W. Hydrogen is\nsupplied with on-demand hydrogen production with help of a galvanic cell, that\nproduces hydrogen when Zn reacts with water. The system can be used as a\nbattery replacement for low power applications and has the potential to improve\nthe run time of autonomous systems. The efficiency has been investigated as\nfunction of fuel cell construction and tested for several load profiles.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0939v1"
    },
    {
        "title": "Design and Fabrication of Acoustic Wave Actuated Microgenerator for\n  Portable Electronic Devices",
        "authors": [
            "Tenghsien Lai",
            "Changhan Huang",
            "Chingfu Tsou"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The past few years have seen an increasing focus on energy harvesting issue,\nincluding power supply for portable electric devices. Utilize scavenging\nambient energy from the environment could eliminate the need for batteries and\nincrease portable device lifetimes indefinitely. In addition, through MEMS\ntechnology fabricated micro-generator could easy integrate with these small or\nportable devices. Several different ambient sources, including solar, vibration\nand temperature effect, have already exploited [1-3]. Each energy source should\nbe used in suitable environment, therefore to produce maximum efficiency. In\nthis paper, we present an acoustic wave actuated micro-generator for power\nsystem by using the energy of acoustic waves, such as the sound from human\nvoices or speakerphone, to actuate a MEMS-type electromagnetic transducer. This\nprovides a longer device lifetime and greater power system convenience.\nMoreover, it is convenient to integrate MEMS-based microgenerators with small\nor porta le devices\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0940v1"
    },
    {
        "title": "Package Hermeticity Testing with Thermal Transient Measurements",
        "authors": [
            "Andras Vass-Varnai",
            "M. Rencz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The rapid incursion of new technologies such as MEMS and smart sensor device\nmanufacturing requires new tailor-made packaging designs. In many applications\nthese devices are exposed to humid environments. Since the penetration of\nmoisture into the package may result in internal corrosion or shift of the\noperating parameters, the reliability testing of hermetically sealed packages\nhas become a crucial question in the semiconductor industry.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0941v1"
    },
    {
        "title": "Micro-tensile tests on micromachined metal on polymer specimens:\n  elasticity, plasticity and rupture",
        "authors": [
            "C. Seguineau",
            "M. Ignat",
            "C. Malhaire",
            "S. Brida",
            "X. Lafontan",
            "J. -M. Desmarres",
            "C. Josserond",
            "L. Debove"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This study is focused on the mechanical characterization of materials used in\nmicroelectronic and micro- electromechanical systems (MEMS) devices. In order\nto determine their mechanical parameters, a new deformation bench test with\nsuitable micromachined specimens have been developed. Uniaxial tensile tests\nwere performed on \"low cost\" specimens, consisting in electroplated thin copper\nfilms and structures, deposited on a polimide type substrate. Moreover, a\ncyclic mechanical actuation via piezoelectric actuators was tested on the same\ndeformation bench. These experiments validate the device for performing dynamic\ncharacterization of materials, and reliability studies of different\nmicrostructures.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0942v1"
    },
    {
        "title": "Open Ended Microwave Oven for Packaging",
        "authors": [
            "K. I. Sinclair",
            "T. Tilford",
            "M. Y. P. Desmulliez",
            "G. Goussetis",
            "C. Bailey",
            "K. Parrott",
            "A. J. Sangster"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  A novel open waveguide cavity resonator is presented for the combined\nvariable frequency microwave curing of bumps, underfills and encapsulants, as\nwell as the alignment of devices for fast flip-chip assembly, direct chip\nattach (DCA) or wafer-scale level packaging (WSLP). This technology achieves\nradio frequency (RF) curing of adhesives used in microelectronics,\noptoelectronics and medical devices with potential simultaneous micron-scale\nalignment accuracy and bonding of devices. In principle, the open oven cavity\ncan be fitted directly onto a flip-chip or wafer scale bonder and, as such,\nwill allow for the bonding of devices through localised heating thus reducing\nthe risk to thermally sensitive devices. Variable frequency microwave (VFM)\nheating and curing of an idealised polymer load is numerically simulated using\na multi-physics approach. Electro-magnetic fields within a novel open ended\nmicrowave oven developed for use in micro-electronics manufacturing\napplications are solved using a de icated Yee scheme finite-difference\ntime-domain (FDTD) solver. Temperature distribution, degree of cure and thermal\nstresses are analysed using an Unstructured Finite Volume method (UFVM)\nmulti-physics package. The polymer load was meshed for thermophysical analysis,\nwhilst the microwave cavity - encompassing the polymer load - was meshed for\nmicrowave irradiation. The two solution domains are linked using a\ncross-mapping routine. The principle of heating using the evanescent fringing\nfields within the open-end of the cavity is demonstrated. A closed loop\nfeedback routine is established allowing the temperature within a lossy sample\nto be controlled. A distribution of the temperature within the lossy sample is\nobtained by using a thermal imaging camera.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0943v1"
    },
    {
        "title": "Mechanical Fatigue on Gold MEMS Devices: Experimental Results",
        "authors": [
            "Giorgio De Pasquale",
            "Aurelio Som",
            "Alberto Ballestra"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The effect of mechanical fatigue on structural performances of gold devices\nis investigated. The pull-in voltage of special testing micro-systems is\nmonitored during the cyclical load application. The mechanical collapse is\nidentified as a dramatic loss of mechanical strength of the specimen. The\nfatigue limit is estimated through the stair-case method by means of the\npull-in voltage measurements. Measurements are performed by means of the\noptical interferometric technique.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0945v1"
    },
    {
        "title": "Testability of Reversible Iterative Logic Arrays",
        "authors": [
            "Avik Chakraborty"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Iterative Logic Arrays (ILAs) are ideal as VLSI sub-systems because of their\nregular structure and its close resemblance with FPGAs (Field Programmable Gate\nArrays). Reversible circuits are of interest in the design of very low power\ncircuits where energy loss implied by high frequency switching is not of much\nconsideration. Reversibility is essential for Quantum Computing. This paper\nexamines the testability of Reversible Iterative Logic Arrays (ILAs) composed\nof reversible k-CNOT gates. For certain ILAs it is possible to find a test set\nwhose size remains constant irrespective of the size of the ILA, while for\nothers it varies with array size. Former type of ILAs is known as\nConstant-Testable, i.e. C-Testable. It has been shown that Reversible Logic\nArrays are C-Testable and size of test set is equal to number of entries in\ncells truth table implying that the reversible ILAs are also Optimal-Testable,\ni.e. O-Testable. Uniform-Testability, i.e. U-Testability has been defined and\nReversible Heterogeneous ILAs have been characterized as U-Testable. The test\ngeneration problem has been shown to be related to certain properties of cycles\nin a set of graphs derived from cell truth table. By careful analysis of these\ncycles an efficient test generation technique that can be easily converted to\nan ATPG program has been presented for both 1-D and 2D ILAs. The same\nalgorithms can be easily extended for n-Dimensional Reversible ILAs.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.1293v2"
    },
    {
        "title": "Fast Monte Carlo Estimation of Timing Yield: Importance Sampling with\n  Stochastic Logical Effort (ISLE)",
        "authors": [
            "Alp Arslan Bayrakci",
            "Alper Demir",
            "Serdar Tasiran"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In the nano era in integrated circuit fabrication technologies, the\nperformance variability due to statistical process and circuit parameter\nvariations is becoming more and more significant. Considerable effort has been\nexpended in the EDA community during the past several years in trying to cope\nwith the so-called statistical timing problem. Most of this effort has been\naimed at generalizing the static timing analyzers to the statistical case. In\nthis paper, we take a pragmatic approach in pursuit of making the Monte Carlo\nmethod for timing yield estimation practically feasible. The Monte Carlo method\nis widely used as a golden reference in assessing the accuracy of other timing\nyield estimation techniques. However, it is generally believed that it can not\nbe used in practice for estimating timing yield as it requires too many costly\nfull circuit simulations for acceptable accuracy. In this paper, we present a\nnovel approach to constructing an improvedMonte Carlo estimator for timing\nyield which provides the same accuracy as the standard Monte Carlo estimator,\nbut at a cost of much fewer full circuit simulations. This improved estimator\nis based on a novel combination of a variance reduction technique, importance\nsampling, and a stochastic generalization of the logical effort formalism for\ncheap but approximate delay estimation. The results we present demonstrate that\nour improved yield estimator achieves the same accuracy as the standard Monte\nCarlo estimator at a cost reduction reaching several orders of magnitude.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.2627v2"
    },
    {
        "title": "Fusion d'images: application au contrle de la distribution des\n  biopsies prostatiques",
        "authors": [
            "Pierre Mozer",
            "Michael Baumann",
            "G. Chevreau",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper is about the application of a 3D ultrasound data fusion technique\nto the 3D reconstruction of prostate biopies in a reference volume. The method\nis introduced and its evaluation on a series of data coming from 15 patients is\ndescribed.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.2864v1"
    },
    {
        "title": "Fuzzy Feedback Scheduling of Resource-Constrained Embedded Control\n  Systems",
        "authors": [
            "Feng Xia",
            "Youxian Sun",
            "Yu-Chu Tian",
            "Moses Tade",
            "Jinxiang Dong"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The quality of control (QoC) of a resource-constrained embedded control\nsystem may be jeopardized in dynamic environments with variable workload. This\ngives rise to the increasing demand of co-design of control and scheduling. To\ndeal with uncertainties in resource availability, a fuzzy feedback scheduling\n(FFS) scheme is proposed in this paper. Within the framework of feedback\nscheduling, the sampling periods of control loops are dynamically adjusted\nusing the fuzzy control technique. The feedback scheduler provides QoC\nguarantees in dynamic environments through maintaining the CPU utilization at a\ndesired level. The framework and design methodology of the proposed FFS scheme\nare described in detail. A simplified mobile robot target tracking system is\ninvestigated as a case study to demonstrate the effectiveness of the proposed\nFFS scheme. The scheme is independent of task execution times, robust to\nmeasurement noises, and easy to implement, while incurring only a small\noverhead.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.3059v1"
    },
    {
        "title": "Neural Feedback Scheduling of Real-Time Control Tasks",
        "authors": [
            "Feng Xia",
            "Yu-Chu Tian",
            "Youxian Sun",
            "Jinxiang Dong"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Many embedded real-time control systems suffer from resource constraints and\ndynamic workload variations. Although optimal feedback scheduling schemes are\nin principle capable of maximizing the overall control performance of\nmultitasking control systems, most of them induce excessively large\ncomputational overheads associated with the mathematical optimization routines\ninvolved and hence are not directly applicable to practical systems. To\noptimize the overall control performance while minimizing the overhead of\nfeedback scheduling, this paper proposes an efficient feedback scheduling\nscheme based on feedforward neural networks. Using the optimal solutions\nobtained offline by mathematical optimization methods, a back-propagation (BP)\nneural network is designed to adapt online the sampling periods of concurrent\ncontrol tasks with respect to changes in computing resource availability.\nNumerical simulation results show that the proposed scheme can reduce the\ncomputational overhead significantly while delivering almost the same overall\ncontrol performance as compared to optimal feedback scheduling.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.3062v1"
    },
    {
        "title": "From a set of parts to an indivisible whole. Part III: Holistic space of\n  multi-object relations",
        "authors": [
            "Leonid Andreev"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The previously described methodology for hierarchical grouping of objects\nthrough iterative averaging has been used for simulation of cooperative\ninteractions between objects of a system with the purpose of investigation of\nthe conformational organization of the system. Interactions between objects\nwere analyzed within the space of an isotropic field of one of the objects\n(drifter). Such an isotropic field of an individual object can be viewed as a\nprototype of computer ego. It allows visualization of a holistic space of\nmulti-object relations (HSMOR) which has a complex structure depending on the\nnumber of objects, their mutual arrangement in space, and the type of metric\nused for assessment of (dis)similarities between the objects. In the course of\ncomputer simulation of cooperative interactions between the objects, only those\npoints of the space were registered which corresponded to transitions in\nhierarchical grouping. Such points appeared to aggregate into complex spatial\nstructures determining a unique internal organization of a respective HSMOR. We\ndescribe some of the peculiarities of such structures, referred to by us as\nattractor membranes, and discuss their properties. We also demonstrate the\npeculiarities of the changing of intergroup similarities which occurs when a\ndrifter infinitely moves away from the fixed objects.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.1355v1"
    },
    {
        "title": "Control-Scheduling Codesign: A Perspective on Integrating Control and\n  Computing",
        "authors": [
            "Feng Xia",
            "Youxian Sun"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Despite rapid evolution, embedded computing systems increasingly feature\nresource constraints and workload uncertainties. To achieve much better system\nperformance in unpredictable environments than traditional design approaches, a\nnovel methodology, control-scheduling codesign, is emerging in the context of\nintegrating feedback control and real-time computing. The aim of this work is\nto provide a better understanding of this emerging methodology and to spark new\ninterests and developments in both the control and computer science\ncommunities. The state of the art of control-scheduling codesign is captured.\nRelevant research efforts in the literature are discussed under two categories,\ni.e., control of computing systems and codesign for control systems. Critical\nopen research issues on integrating control and computing are also outlined.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.1385v1"
    },
    {
        "title": "Atlas-Based Prostate Segmentation Using an Hybrid Registration",
        "authors": [
            "Sbastien Martin",
            "Vincent Daanen",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Purpose: This paper presents the preliminary results of a semi-automatic\nmethod for prostate segmentation of Magnetic Resonance Images (MRI) which aims\nto be incorporated in a navigation system for prostate brachytherapy. Methods:\nThe method is based on the registration of an anatomical atlas computed from a\npopulation of 18 MRI exams onto a patient image. An hybrid registration\nframework which couples an intensity-based registration with a robust\npoint-matching algorithm is used for both atlas building and atlas\nregistration. Results: The method has been validated on the same dataset that\nthe one used to construct the atlas using the \"leave-one-out method\". Results\ngives a mean error of 3.39 mm and a standard deviation of 1.95 mm with respect\nto expert segmentations. Conclusions: We think that this segmentation tool may\nbe a very valuable help to the clinician for routine quantitative image\nexploitation.\n",
        "pdf_link": "http://arxiv.org/pdf/0806.3708v1"
    },
    {
        "title": "Collaborative Virtual Queue: Fair Management of Congested Departure\n  Operations and Benefit Analysis",
        "authors": [
            "Pierrick Burgain",
            "Eric Feron",
            "John-Paul Clarke"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Due to the stochastic nature of departure operations, working at full\ncapacity makes major US airports very sensitive to uncertainties. Consequently,\nairport ground operations face critically congested taxiways and long runway\nqueues. In this report, we show how improved management of departure operations\nfrom the ready-to-push-back time to the wheels-off time can potentially yield\nsignificant benefits to airlines and air traffic services. We develop a\nCollaborative Virtual Queue to enable better optimization capabilities during\ncongested situations while taking into account the laissez-faire competitive\nenvironment. Results are evaluated using a departure system model, validated\nusing current statistics and previous studies. First, the Collaborative Virtual\nQueue enables keeping aircraft away from runway queues, which increases\nwheels-off time predictability. Second, holding aircraft enables last-minute\nintra-airline flight switching. This creates new optimization capabilities for\nairlines i.e. it gives airlines the flexibility to prioritize their flight\nsequence in real-time. These capabilities are illustrated by the trade-off\nbetween minimizing the average passenger waiting time and minimizing the level\nof unfairness between aircraft of the same airline. For instance, airlines\ncould choose to decrease by up to 15% their average passenger waiting time by\nprioritizing heavy planes over small planes when the taxiway system is\ncongested.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.0661v1"
    },
    {
        "title": "Random XML sampling the Boltzmann way",
        "authors": [
            "Alexis Darrasse"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this article we present the prototype of a framework capable of producing,\nwith linear complexity, uniformly random XML documents with respect to a given\nRELAX NG grammar. The generation relies on powerful combinatorial methods\ntogether with numerical and symbolic resolution of polynomial systems.\n",
        "pdf_link": "http://arxiv.org/pdf/0807.0992v1"
    },
    {
        "title": "Fixed-Point Design of Generalized Comb Filters: A Statistical Approach",
        "authors": [
            "Massimiliano Laddomada"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper is concerned with the problem of designing computationally\nefficient Generalized Comb Filters (GCF). Basically, GCF filters are\nanti-aliasing filters that guarantee superior performance in terms of\nselectivity and quantization noise rejection compared to classical comb\nfilters, when used as decimation filters in multistage architectures. Upon\nemploying a partial polyphase (PP) architecture proposed in a companion paper,\nwe develop a sensitivity analysis in order to investigate the effects of the\ncoefficients' quantization on the frequency response of the designed filters.\nWe show that the sensitivity of the filter response to errors in the\ncoefficients is dependent on the particular split of the decimation factor\nbetween the two sub-filters constituting the PP architecture. The sensitivity\nanalysis is then used for developing a fixed-point implementation of a sample\nfilter from the class of GCF filters, used as reference filter throughout the\npaper. Finally, we present computer simulations in order to evaluate the\nperformance of the designed fixed-point filters.\n",
        "pdf_link": "http://arxiv.org/pdf/0808.2296v1"
    },
    {
        "title": "Enhanced Energy-Aware Feedback Scheduling of Embedded Control Systems",
        "authors": [
            "Feng Xia",
            "Longhua Ma",
            "Wenhong Zhao",
            "Youxian Sun",
            "Jinxiang Dong"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Dynamic voltage scaling (DVS) is one of the most effective techniques for\nreducing energy consumption in embedded and real-time systems. However,\ntraditional DVS algorithms have inherent limitations on their capability in\nenergy saving since they rarely take into account the actual application\nrequirements and often exploit fixed timing constraints of real-time tasks.\nTaking advantage of application adaptation, an enhanced energy-aware feedback\nscheduling (EEAFS) scheme is proposed, which integrates feedback scheduling\nwith DVS. To achieve further reduction in energy consumption over pure DVS\nwhile not jeopardizing the quality of control, the sampling period of each\ncontrol loop is adapted to its actual control performance, thus exploring\nflexible timing constraints on control tasks. Extensive simulation results are\ngiven to demonstrate the effectiveness of EEAFS under different scenarios.\nCompared with the optimal pure DVS scheme, EEAFS saves much more energy while\nyielding comparable control performance.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.4917v1"
    },
    {
        "title": "Integrated Design and Implementation of Embedded Control Systems with\n  Scilab",
        "authors": [
            "Longhua Ma",
            "Feng Xia",
            "Zhe Peng"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Embedded systems are playing an increasingly important role in control\nengineering. Despite their popularity, embedded systems are generally subject\nto resource constraints and it is therefore difficult to build complex control\nsystems on embedded platforms. Traditionally, the design and implementation of\ncontrol systems are often separated, which causes the development of embedded\ncontrol systems to be highly time-consuming and costly. To address these\nproblems, this paper presents a low-cost, reusable, reconfigurable platform\nthat enables integrated design and implementation of embedded control systems.\nTo minimize the cost, free and open source software packages such as Linux and\nScilab are used. Scilab is ported to the embedded ARM-Linux system. The drivers\nfor interfacing Scilab with several communication protocols including serial,\nEthernet, and Modbus are developed. Experiments are conducted to test the\ndeveloped embedded platform. The use of Scilab enables implementation of\ncomplex control algorithms on embedded platforms. With the developed platform,\nit is possible to perform all phases of the development cycle of embedded\ncontrol systems in a unified environment, thus facilitating the reduction of\ndevelopment time and cost.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.4920v1"
    },
    {
        "title": "Performance-Aware Power Management in Embedded Controllers with\n  Multiple-Voltage Processors",
        "authors": [
            "Feng Xia",
            "Liping Liu",
            "Longhua Ma",
            "Youxian Sun",
            "Jinxiang Dong"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The goal of this work is to minimize the energy dissipation of embedded\ncontrollers without jeopardizing the quality of control (QoC). Taking advantage\nof the dynamic voltage scaling (DVS) technology, this paper develops a\nperformance-aware power management scheme for embedded controllers with\nprocessors that allow multiple voltage levels. The periods of control tasks are\nadapted online with respect to the current QoC, thus facilitating additional\nenergy reduction over standard DVS. To avoid the waste of CPU resources as a\nresult of the discrete voltage levels, a resource reclaiming mechanism is\nemployed to maximize the CPU utilization and also to improve the QoC.\nSimulations are conducted to evaluate the performance of the proposed scheme.\nCompared with the optimal standard DVS scheme, the proposed scheme is shown to\nbe able to save remarkably more energy while maintaining comparable QoC.\n",
        "pdf_link": "http://arxiv.org/pdf/0809.4929v1"
    },
    {
        "title": "Design of a Fractional Order PID Controller Using Particle Swarm\n  Optimization Technique",
        "authors": [
            "Deepyaman Maiti",
            "Sagnik Biswas",
            "Amit Konar"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Particle Swarm Optimization technique offers optimal or suboptimal solution\nto multidimensional rough objective functions. In this paper, this optimization\ntechnique is used for designing fractional order PID controllers that give\nbetter performance than their integer order counterparts. Controller synthesis\nis based on required peak overshoot and rise time specifications. The\ncharacteristic equation is minimized to obtain an optimum set of controller\nparameters. Results show that this design method can effectively tune the\nparameters of the fractional order controller.\n",
        "pdf_link": "http://arxiv.org/pdf/0810.3776v1"
    },
    {
        "title": "Approximation of a Fractional Order System by an Integer Order Model\n  Using Particle Swarm Optimization Technique",
        "authors": [
            "Deepyaman Maiti",
            "Amit Konar"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  System identification is a necessity in control theory. Classical control\ntheory usually considers processes with integer order transfer functions. Real\nprocesses are usually of fractional order as opposed to the ideal integral\norder models. A simple and elegant scheme is presented for approximation of\nsuch a real world fractional order process by an ideal integral order model. A\npopulation of integral order process models is generated and updated by PSO\ntechnique, the fitness function being the sum of squared deviations from the\nset of observations obtained from the actual fractional order process. Results\nshow that the proposed scheme offers a high degree of accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0077v1"
    },
    {
        "title": "A Swarm Intelligence Based Scheme for Complete and Fault-tolerant\n  Identification of a Dynamical Fractional Order Process",
        "authors": [
            "Deepyaman Maiti",
            "Ayan Acharya",
            "Amit Konar"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  System identification refers to estimation of process parameters and is a\nnecessity in control theory. Physical systems usually have varying parameters.\nFor such processes, accurate identification is particularly important. Online\nidentification schemes are also needed for designing adaptive controllers. Real\nprocesses are usually of fractional order as opposed to the ideal integral\norder models. In this paper, we propose a simple and elegant scheme of\nestimating the parameters for such a fractional order process. A population of\nprocess models is generated and updated by particle swarm optimization (PSO)\ntechnique, the fitness function being the sum of squared deviations from the\nactual set of observations. Results show that the proposed scheme offers a high\ndegree of accuracy even when the observations are corrupted to a significant\ndegree. Additional schemes to improve the accuracy still further are also\nproposed and analyzed.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0078v1"
    },
    {
        "title": "The Application of Stochastic Optimization Algorithms to the Design of a\n  Fractional-order PID Controller",
        "authors": [
            "Mithun Chakraborty",
            "Deepyaman Maiti",
            "Amit Konar"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The Proportional-Integral-Derivative Controller is widely used in industries\nfor process control applications. Fractional-order PID controllers are known to\noutperform their integer-order counterparts. In this paper, we propose a new\ntechnique of fractional-order PID controller synthesis based on peak overshoot\nand rise-time specifications. Our approach is to construct an objective\nfunction, the optimization of which yields a possible solution to the design\nproblem. This objective function is optimized using two popular bio-inspired\nstochastic search algorithms, namely Particle Swarm Optimization and\nDifferential Evolution. With the help of a suitable example, the superiority of\nthe designed fractional-order PID controller to an integer-order PID controller\nis affirmed and a comparative study of the efficacy of the two above algorithms\nin solving the optimization problem is also presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0079v1"
    },
    {
        "title": "A Deterministic Model for Analyzing the Dynamics of Ant System Algorithm\n  and Performance Amelioration through a New Pheromone Deposition Approach",
        "authors": [
            "Ayan Acharya",
            "Deepyaman Maiti",
            "Amit Konar",
            "Ramadoss Janarthanan"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Ant Colony Optimization (ACO) is a metaheuristic for solving difficult\ndiscrete optimization problems. This paper presents a deterministic model based\non differential equation to analyze the dynamics of basic Ant System algorithm.\nTraditionally, the deposition of pheromone on different parts of the tour of a\nparticular ant is always kept unvarying. Thus the pheromone concentration\nremains uniform throughout the entire path of an ant. This article introduces\nan exponentially increasing pheromone deposition approach by artificial ants to\nimprove the performance of basic Ant System algorithm. The idea here is to\nintroduce an additional attracting force to guide the ants towards destination\nmore easily by constructing an artificial potential field identified by\nincreasing pheromone concentration towards the goal. Apart from carrying out\nanalysis of Ant System dynamics with both traditional and the newly proposed\ndeposition rules, the paper presents an exhaustive set of experiments performed\nto find out suitable parameter ranges for best performance of Ant System with\nthe proposed deposition approach. Simulations reveal that the proposed\ndeposition rule outperforms the traditional one by a large extent both in terms\nof solution quality and algorithm convergence. Thus, the contributions of the\narticle can be presented as follows: i) it introduces differential equation and\nexplores a novel method of analyzing the dynamics of ant system algorithms, ii)\nit initiates an exponentially increasing pheromone deposition approach by\nartificial ants to improve the performance of algorithm in terms of solution\nquality and convergence time, iii) exhaustive experimentation performed\nfacilitates the discovery of an algebraic relationship between the parameter\nset of the algorithm and feature of the problem environment.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0080v1"
    },
    {
        "title": "Tuning PID and FOPID Controllers using the Integral Time Absolute Error\n  Criterion",
        "authors": [
            "Deepyaman Maiti",
            "Ayan Acharya",
            "Mithun Chakraborty",
            "Amit Konar",
            "Ramadoss Janarthanan"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Particle swarm optimization (PSO) is extensively used for real parameter\noptimization in diverse fields of study. This paper describes an application of\nPSO to the problem of designing a fractional-order\nproportional-integral-derivative (FOPID) controller whose parameters comprise\nproportionality constant, integral constant, derivative constant, integral\norder (lambda) and derivative order (delta). The presence of five optimizable\nparameters makes the task of designing a FOPID controller more challenging than\nconventional PID controller design. Our design method focuses on minimizing the\nIntegral Time Absolute Error (ITAE) criterion. The digital realization of the\ndeigned system utilizes the Tustin operator-based continued fraction expansion\nscheme. We carry out a simulation that illustrates the effectiveness of the\nproposed approach especially for realizing fractional-order plants. This paper\nalso attempts to study the behavior of fractional PID controller vis-a-vis that\nof its integer order counterpart and demonstrates the superiority of the former\nto the latter.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0083v1"
    },
    {
        "title": "A Study of the Grunwald-Letnikov Definition for Minimizing the Effects\n  of Random Noise on Fractional Order Differential Equations",
        "authors": [
            "Mithun Chakraborty",
            "Deepyaman Maiti",
            "Amit Konar",
            "Ramadoss Janarthanan"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Of the many definitions for fractional order differintegral, the\nGrunwald-Letnikov definition is arguably the most important one. The necessity\nof this definition for the description and analysis of fractional order systems\ncannot be overstated. Unfortunately, the Fractional Order Differential Equation\n(FODE) describing such a systems, in its original form, highly sensitive to the\neffects of random noise components inevitable in a natural environment. Thus\ndirect application of the definition in a real-life problem can yield erroneous\nresults. In this article, we perform an in-depth mathematical analysis the\nGrunwald-Letnikov definition in depth and, as far as we know, we are the first\nto do so. Based on our analysis, we present a transformation scheme which will\nallow us to accurately analyze generalized fractional order systems in presence\nof significant quantities of random errors. Finally, by a simple experiment, we\ndemonstrate the high degree of robustness to noise offered by the said\ntransformation and thus validate our scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0133v1"
    },
    {
        "title": "Complete Identification of a Dynamic Fractional Order System Under\n  Non-ideal Conditions Using Fractional Differintegral Definitions",
        "authors": [
            "Deepyaman Maiti",
            "Ayan Acharya",
            "R. Janarthanan",
            "Amit Konar"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This contribution deals with identification of fractional-order dynamical\nsystems. System identification, which refers to estimation of process\nparameters, is a necessity in control theory. Real processes are usually of\nfractional order as opposed to the ideal integral order models. A simple and\nelegant scheme of estimating the parameters for such a fractional order process\nis proposed. This method employs fractional calculus theory to find equations\nrelating the parameters that are to be estimated, and then estimates the\nprocess parameters after solving the simultaneous equations. The data used for\nthe calculations are intentionally corrupted to simulate real-life conditions.\nResults show that the proposed scheme offers a very high degree of accuracy\neven for erroneous data.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0135v1"
    },
    {
        "title": "A Novel Approach for Complete Identification of Dynamic Fractional Order\n  Systems Using Stochastic Optimization Algorithms and Fractional Calculus",
        "authors": [
            "Deepyaman Maiti",
            "Mithun Chakraborty",
            "Amit Konar"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This contribution deals with identification of fractional-order dynamical\nsystems. System identification, which refers to estimation of process\nparameters, is a necessity in control theory. Real processes are usually of\nfractional order as opposed to the ideal integral order models. A simple and\nelegant scheme of estimating the parameters for such a fractional order process\nis proposed. This method employs fractional calculus theory to find equations\nrelating the parameters that are to be estimated, and then estimates the\nprocess parameters after solving the simultaneous equations. The said\nsimultaneous equations are generated and updated using particle swarm\noptimization (PSO) technique, the fitness function being the sum of squared\ndeviations from the actual set of observations. The data used for the\ncalculations are intentionally corrupted to simulate real-life conditions.\nResults show that the proposed scheme offers a very high degree of accuracy\neven for erroneous data.\n",
        "pdf_link": "http://arxiv.org/pdf/0811.0137v1"
    },
    {
        "title": "Adaptive Fault Masking With Incoherence Scoring",
        "authors": [
            "B. Baykant Alagoz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  An adaptive voting algorithm for digital media was introduced in this study.\nAvailability was improved by incoherence scoring in voting mechanism of\nMulti-Modular Redundancy. Regulation parameters give the algorithm flexibility\nof adjusting priorities in decision process. Proposed adaptive voting algorithm\nwas shown to be more aware of fault status of redundant modules\n",
        "pdf_link": "http://arxiv.org/pdf/0811.3816v3"
    },
    {
        "title": "The Impact of New Technologies in Public Financial Management and\n  Performance: Agenda for Public Financial Management Reformance in the Context\n  of Global Best Practices",
        "authors": [
            "Amos David"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Information and Communication Technologies (ICT) has practically penetrated\ninto all spheres of life. Therefore a closer look at the impact of ICT in\npublic financial management and performance is highly justified. Public finance\nis defined as a field of economics concerned with paying for collective or\ngovernmental activities, and with the administration and design of those\nactivities. Activities will be viewed as services or more precisely as public\nservices. We believe that there is need to consider performance from the\nperspective of effective performance and the perceived performance. In fact the\nreal or effective performance might not correspond to the perceived\nperformance. A service can be considered from the perspective of the\ndecision-maker, who in our case could be a government or a collectivity. ICT\ncan be employed in the three phases that concern the decision-maker: design,\nimplementation and evaluation. The beneficiaries of a service can employ ICT in\nany of the three phases - awareness, exploitation and assessment - for\nguarantying a high level of efficiency. Each phase in the environment of a\nservice will be presented as well as illustrations of how ICT can be employed\nin order to improve the end-result of each one of them. We believe that a high\nefficiency of each phase will produce a high global efficiency. It should be\nnoted however that the effectiveness of any system is highly dependent on the\nhuman engagement in the system. Therefore, the impact of ICT in public\nfinancial management will be felt only if the decision-makers and the end-users\nof the services engage themselves in the success of the system. Instead of\ngiving a catalog of services, the focus has been on the model (or methodology)\nto adopt in designing services for which ICT could enhance the implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/0812.1218v1"
    },
    {
        "title": "Developments in ROOT I/O and trees",
        "authors": [
            "R. Brun",
            "P. Canal",
            "M. Frank",
            "A. Kreshuk",
            "S. Linev",
            "P. Russo",
            "F. Rademakers"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  For the last several months the main focus of development in the ROOT I/O\npackage has been code consolidation and performance improvements. Access to\nremote files is affected both by bandwidth and latency. We introduced a\npre-fetch mechanism to minimize the number of transactions between client and\nserver and hence reducing the effect of latency. We will review the\nimplementation and how well it works in different conditions (gain of an order\nof magnitude for remote file access). We will also review new utilities,\nincluding a faster implementation of TTree cloning (gain of an order of\nmagnitude), a generic mechanism for object references, and a new entry list\nmechanism tuned both for small and large number of selections. In addition to\nreducing the coupling with the core module and becoming its owns library\n(libRIO) (as part of the general restructuration of the ROOT libraries), the\nI/O package has been enhanced in the area of XML and SQL support, thread\nsafety, schema evolution, TTreeFormula, and many other areas. We will also\ndiscuss various ways, ROOT will be able to benefit from multi-core architecture\nto improve I/O performances.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.0886v1"
    },
    {
        "title": "Fault Masking By Probabilistic Voting",
        "authors": [
            "B. Baykant Alagoz"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  In this study, we introduced a probabilistic voter, regarding symbol\nprobabilities in decision process besides majority consensus. Conventional\nmajority voter is independent of functionality of redundant modules. In our\nstudy, proposed probabilistic voter is designed corresponding to functionality\nof the redundant module. We tested probabilistic voter for 3 and 5 redundant\nmodules with random transient errors inserted the wires and it was seen from\nsimulation results that Multi-Modular Redundancy (M-MR) with Probabilistic\nVoting (PV) had been shown better availability performance than conventional\nmajority voter.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.1181v2"
    },
    {
        "title": "Information science and technology as applications of the physics of\n  signalling",
        "authors": [
            "A. P. Young"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Adopting the scientific method a theoretical model is proposed as foundation\nfor information science and technology, extending the existing theory of\nsignaling: a fact f becomes known in a physical system only following the\nsuccess of a test f, tests performed primarily by human sensors and applied to\n(physical) phenomena within which further tests may be performed. Tests are\nphenomena and classify phenomena. A phenomenon occupies both time and space,\nfacts and inferences having physical counterparts which are phenomena of\nspecified classes. Identifiers such as f are conventional, assigned by humans;\na fact (f', f'') reports the success of a test of generic class f', the outcome\nf'' of the reported application classifying the successful test in more detail.\nFacts then exist only within structures of a form dictated by constraints on\nthe structural design of tests. The model explains why responses of real time\nsystems are not uniquely predictable and why restrictions, on concurrency in\nperforming inferences within them, are needed. Improved methods, based on the\nmodel and applicable throughout the software life-cycle, are summarised in the\npaper. No report of similar work has been found in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.2723v3"
    },
    {
        "title": "Self-assembly of the discrete Sierpinski carpet and related fractals",
        "authors": [
            "Steven M. Kautz",
            "James I. Lathrop"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  It is well known that the discrete Sierpinski triangle can be defined as the\nnonzero residues modulo 2 of Pascal's triangle, and that from this definition\none can easily construct a tileset with which the discrete Sierpinski triangle\nself-assembles in Winfree's tile assembly model. In this paper we introduce an\ninfinite class of discrete self-similar fractals that are defined by the\nresidues modulo a prime p of the entries in a two-dimensional matrix obtained\nfrom a simple recursive equation. We prove that every fractal in this class\nself-assembles using a uniformly constructed tileset. As a special case we show\nthat the discrete Sierpinski carpet self-assembles using a set of 30 tiles.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.3189v1"
    },
    {
        "title": "An Alternative Cracking of The Genetic Code",
        "authors": [
            "O. Babatunde Okunoye"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  We Propose 22 unique Solutions to the Genetic Code. An Alternative Cracking,\nfrom the Perspective of a Mathematician.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.0056v1"
    },
    {
        "title": "Hierarchical Triple-Modular Redundancy (H-TMR) Network For Digital\n  Systems",
        "authors": [
            "B. Baykant Alagoz"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Hierarchical application of Triple-Modular Redundancy (TMR) increases fault\ntolerance of digital Integrated Circuit (IC). In this paper, a simple\nprobabilistic model was proposed for analysis of fault masking performance of\nhierarchical TMR networks. Performance improvements obtained by second order\nTMR network were theoretically compared with first order TMR network.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.0241v2"
    },
    {
        "title": "MicroSim: Modeling the Swedish Population",
        "authors": [
            "Lisa Brouwers",
            "Martin Camitz",
            "Baki Cakici",
            "Kalle Mkil",
            "Paul Saretok"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This article presents a unique, large-scale and spatially explicit\nmicrosimulation model that uses official anonymized register data collected\nfrom all individuals living in Sweden. Individuals are connected to households\nand workplaces and represent crucial links in the Swedish social contact\nnetwork. This enables significant policy experiments in the domain of epidemic\noutbreaks. Development of the model started in 2004 at the Swedish Institute\nfor Infectious Disease Control (SMI) in Solna, Sweden with the goal of creating\na tool for testing the effects of intervention policies. These interventions\ninclude mass vaccination, targeted vaccination, isolation and social\ndistancing. The model was initially designed for simulating smallpox outbreaks.\nIn 2006, it was modified to support simulations of pandemic influenza. All nine\nmillions members of the Swedish population are represented in the model. This\narticle is a technical description of the simulation model; the input data, the\nsimulation engine and the basic object types.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.0901v1"
    },
    {
        "title": "On Why and What of Randomness",
        "authors": [
            "Soubhik Chakraborty"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper has several objectives. First, it separates randomness from\nlawlessness and shows why even genuine randomness does not imply lawlessness.\nSecond, it separates the question -why should I call a phenomenon random? (and\nanswers it in part one) from the patent question -What is a random sequence?\n-for which the answer lies in Kolmogorov complexity (which is explained in part\ntwo). While answering the first question the note argues why there should be\nfour motivating factors for calling a phenomenon random: ontic, epistemic,\npseudo and telescopic, the first two depicting genuine randomness and the last\ntwo false. Third, ontic and epistemic randomness have been distinguished from\nontic and epistemic probability. Fourth, it encourages students to be applied\nstatisticians and advises against becoming armchair theorists but this is\ninterestingly achieved by a straight application of telescopic randomness.\nOverall, it tells (the teacher) not to jump to probability without explaining\nrandomness properly first and similarly advises the students to read (and\nunderstand) randomness minutely before taking on probability.\n",
        "pdf_link": "http://arxiv.org/pdf/0902.1232v1"
    },
    {
        "title": "Directing RF Terminals Using TELNET Applications",
        "authors": [
            "Georgiana Petruta Fintineanu"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The present study aims to emphasize the way in which the TELNET protocol for\ndirecting the mobile terminals is used and works. The paper is structured in\nthree parts: the first two parts are a theoretic presentation of the TELNET\nprotocol, respectively of the mobile terminals. The third part contains an\napplication of the way in which a mobile terminal can be programmed using the\nTELNET protocol.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.0960v1"
    },
    {
        "title": "Generating Hierarchically Modular Networks via Link Switching",
        "authors": [
            "Susan Khor"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper introduces a method to generate hierarchically modular networks\nwith prescribed node degree list by link switching. Unlike many existing\nnetwork generating models, our method does not use link probabilities to\nachieve modularity. Instead, it utilizes a user-specified topology to determine\nrelatedness between pairs of nodes in terms of edge distances and links are\nswitched to increase edge distances. To measure the modular-ness of a network\nas a whole, a new metric called Q2 is proposed. Comparisons are made between\nthe Q [15] and Q2 measures. We also comment on the effect of our modularization\nmethod on other network characteristics such as clustering, hierarchy, average\npath length, small-worldness, degree correlation and centrality. An application\nof this method is reported elsewhere [12]. Briefly, the generated networks are\nused as test problems to explore the effect of modularity and degree\ndistribution on evolutionary search algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.2598v3"
    },
    {
        "title": "Boolean Logic with Fault Tolerant Coding",
        "authors": [
            "B. Baykant Alagoz"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Error detectable and error correctable coding in Hamming space was researched\nto discover possible fault tolerant coding constellations, which can implement\nBoolean logic with fault tolerant property. Basic logic operators of the\nBoolean algebra were developed to apply fault tolerant coding in the logic\ncircuits. It was shown that application of three-bit fault tolerant codes have\nprovided the digital system skill of auto-recovery without need for designing\nadditional-fault tolerance mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4046v2"
    },
    {
        "title": "Analysis of some properties for a basic Petri net model",
        "authors": [
            "Alexandra Emilia Fortis"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The formalism of the models with Petri networks provides a sound theoretical\nbase, supported by powerful mathematical methods able to extract information\nnecessary for the formalism and simulation of the real system that provides\nfeatures of competition and synchronization. The paper presents a model based\non a Petri net, in order to extract information relative to the technological\nproducing process of a food additive.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4270v1"
    },
    {
        "title": "Pipeline Leak Detection Techniques",
        "authors": [
            "Timur Chis"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Leak detection systems range from simple, visual line walking and checking\nones to complex arrangements of hard-ware and software. No one method is\nuniversally applicable and operating requirements dictate which method is the\nmost cost effective. The aim of the paper is to review the basic techniques of\nleak detection that are currently in use. The advantages and disadvantages of\neach method are discussed and some indications of applicability are outlined.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4283v1"
    },
    {
        "title": "Computer Systems to Oil Pipeline Transporting",
        "authors": [
            "Timur Chis"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Computer systems in the pipeline oil transporting that the greatest amount of\ndata can be gathered, analyzed and acted upon in the shortest amount of time.\nMost operators now have some form of computer based monitoring system employing\neither commercially available or custom developed software to run the system.\nThis paper presented the SCADA systems to oil pipeline in concordance to the\nRomanian environmental reglementations.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4286v1"
    },
    {
        "title": "ShopList: Programming PDA applications for Windows Mobile using C#",
        "authors": [
            "Daniela Ilea",
            "Dan L. Lacrama"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper is focused on a C# and Sql Server Mobile 2005 application to keep\nevidence of a shop list. The purpose of the application is to offer to the user\nan easier way to manage his shopping options.\n",
        "pdf_link": "http://arxiv.org/pdf/0903.4302v1"
    },
    {
        "title": "5-axis High Speed Milling Optimisation",
        "authors": [
            "Christophe Tournier",
            "Sylvain Lavernhe",
            "Claire Lartigue"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Manufacturing of free form parts relies on the calculation of a tool path\nbased on a CAD model, on a machining strategy and on a given numerically\ncontrolled machine tool. In order to reach the best possible performances, it\nis necessary to take into account a maximum of constraints during tool path\ncalculation. For this purpose, we have developed a surface representation of\nthe tool paths to manage 5-axis High Speed Milling, which is the most\ncomplicated case. This model allows integrating early in the step of tool path\ncomputation the machine tool geometrical constraints (axis ranges, part holder\norientation), kinematical constraints (speed and acceleration on the axes,\nsingularities) as well as gouging issues between the tool and the part. The aim\nof the paper is to optimize the step of 5-axis HSM tool path calculation with a\nbi-parameter surface representation of the tool path. We propose an example of\nintegration of the digital process for tool path computation, ensuring the\nrequired quality and maximum productivity\n",
        "pdf_link": "http://arxiv.org/pdf/0904.1083v1"
    },
    {
        "title": "Usinage de poches en UGV - Aide au choix de stratgies",
        "authors": [
            "Kwamiwi Mawussi",
            "Sylvain Lavernhe",
            "Claire Lartigue"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The paper deals with associating the optimal machining strategy to a given\npocket geometry, within the context of High-Speed Machining (HSM) of\naeronautical pockets. First we define different classes of pocket features\naccording to geometrical criteria. Following, we propose a method allowing to\nassociate a set of capable tools to the features. Each capable tool defines a\nmachined zone with a specific geometry. The last part of the paper is thus\ndedicated to associate the optimal machining strategy to a given geometry\nwithin the context of HSM. Results highlight that analyses must be conducted in\na dynamical as well as a geometrical viewpoint. In particular, it becomes\nnecessary to integrate dynamical specifities associated to the behavior of the\ncouple machine/NC unit in the tool path calculation.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.1084v1"
    },
    {
        "title": "First Person Singular",
        "authors": [
            "Stevan Harnad"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Brian Rotman argues that (one) \"mind\" and (one) \"god\" are only conceivable,\nliterally, because of (alphabetic) literacy, which allowed us to designate each\nof these ghosts as an incorporeal, speaker-independent \"I\" (or, in the case of\ninfinity, a notional agent that goes on counting forever). I argue that to have\na mind is to have the capacity to feel. No one can be sure which organisms\nfeel, hence have minds, but it seems likely that one-celled organisms and\nplants do not, whereas animals do. So minds originated before humans and before\nlanguage --hence, a fortiori, before writing, whether alphabetic or\nideographic.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.1889v1"
    },
    {
        "title": "P vs NP Problem in the field anthropology",
        "authors": [
            "Michael A. Popov"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  An attempt of a new kind of complexity anthropology is considered.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3074v1"
    },
    {
        "title": "Internet: Romania vs. Europe",
        "authors": [
            "Papin Nicolae",
            "Tiberiu Marius Karnyanszky"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper presents various access ways to Internet for home users, both for\nthose who are low consumers (consumed time online or traffic monthly value), or\nlarge consumers (unlimited connection). The main purpose of the work consists\nin making a comparison between the situation of the Internet in Romania and\nother countries in Europe such as Hungary (more western than Romania, so a\nlittle more developed, still an Eastern country comparing to the more developed\ncountries in Western Europe and others well developed such as England, Italy,\nFrance, and to those in development such as Poland, and at the periphery of\nEurope such as Ukraine.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3552v1"
    },
    {
        "title": "Les technologies de l'information et de la communication au niveau\n  mondial et en Roumanie dans les dernieres annees",
        "authors": [
            "Diana Sophia Codat"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The level of development of the electronic communication market and of the\ninformation technology, the indicators regarding the penetration of Internet\nand the level of penetration of the connections in wide band, the integration\ndegree of the Tic application in the business area are crucial for the\ndevelopment of an informational society and for the creation of a society based\non knowledge. Though the levels are still reduced their positive evolution\nreflects the attenuation of the gaps by Romania, comparatively to other\ncountries.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3629v2"
    },
    {
        "title": "On the Ambiguity of Commercial Open Source",
        "authors": [
            "Ioan Despi",
            "Lucian Luca"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Open source and commercial applications used to be two separate worlds. The\nformer was the work of amateurs who had little interest in making a profit,\nwhile the latter was only profit oriented and was produced by big companies.\nNowadays open source is a threat and an opportunity to serious businesses of\nall kinds, generating good profits while delivering low costs products to\ncustomers. The competition between commercial and open source software has\nimpacted the industry and the society as a whole. But in the last years, the\nmarkets for commercial and open source software are converging rapidly and it\nis interesting to resume and discuss the implications of this new paradigm,\ntaking into account arguments pro and against it.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3631v1"
    },
    {
        "title": "Quantum theory can be collectively verified",
        "authors": [
            "Arindam Mitra"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  No theory of physics has been collectively scientifically verified in an\nexperiment so far. It is pointed out that probabilistic structure of quantum\ntheory can be collectively scientifically verified in an experiment. It is also\nargued that experimentalist point of view quantum theory is a complete theory.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3677v2"
    },
    {
        "title": "Output Width Signal Control In Asynchronous Digital Systems Using\n  External Clock Signal",
        "authors": [
            "Mihai Timis"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  In present paper, I propose a method for resolving the timing delays for\noutput signals from an asynchronous sequential system. It will be used an\nexample of an asynchronous sequential system that will set up an output signal\nwhen an input signal will be set up. The width of the output signal depends on\nthe input signal width, and in this case it is very short. There are many\nsynthesis methods, like using a RC group system, a monostable system in design\nof the asynchronous digital system or using an external clock signal, CK. In\nthis paper will be used an external clock signal, CK.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3711v1"
    },
    {
        "title": "Output Width Signal Control In Asynchronous Digital Systems Using\n  Monostable Circuits",
        "authors": [
            "Mihai Timis"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  In present paper, I propose a method for resolving the timing delays for\noutput signals from an asynchronous sequential system. It will be used an\nexample of an asynchronous sequential system that will set up an output signal\nwhen an input signal will be set up. The width of the output signal depends on\nthe input signal width, and in this case it is very short. There are many\nsynthesis methods, like using a RC group system, a monostable system in design\nof the asynchronous digital system or using an external clock signal, CK. In\nthis paper will be used a monostable circuit.\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3714v1"
    },
    {
        "title": "Mesh",
        "authors": [
            "Radu Vultur"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Whether you just want to take a peek of a remote computer status, or you want\nto install the latest version of a software on several workstations, you can do\nall of this from your computer. The networks are growing, the time spent\nadministering the workstations increases and the number of repetitive tasks is\ngoing sky high. But here comes MESH to take that load off your shoulders. And\nbecause of SMS commands you can take this \"command center\" wherever you will\ngo. Just connect a GSM phone to the computer (using a cable, IrDA or Bluetooth)\nand lock/restart/shutdown computers from your LAN with the push of a cell phone\nbutton. You can even create your own SMS commands. This is MESH - the network\nadministrator's Swiss knife\n",
        "pdf_link": "http://arxiv.org/pdf/0904.3715v1"
    },
    {
        "title": "Predictability of PV power grid performance on insular sites without\n  weather stations: use of artificial neural networks",
        "authors": [
            "Cyril Voyant",
            "Marc Muselli",
            "Christophe Paoli",
            "Marie Laure Nivet",
            "Philippe Poggi"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The official meteorological network is poor on the island of Corsica: only\nthree sites being about 50 km apart are equipped with pyranometers which enable\nmeasurements by hourly and daily step. These sites are Ajaccio (seaside),\nBastia (seaside) and Corte (average altitude of 486 meters). This lack of\nweather station makes difficult the predictability of PV power grid\nperformance. This work intends to study a methodology which can predict global\nsolar irradiation using data available from another location for daily and\nhourly horizon. In order to achieve this prediction, we have used Artificial\nNeural Network which is a popular artificial intelligence technique in the\nforecasting domain. A simulator has been obtained using data available for the\nstation of Ajaccio that is the only station for which we have a lot of data: 16\nyears from 1972 to 1987. Then we have tested the efficiency of this simulator\nin two places with different geographical features: Corte, a mountainous region\nand Bastia, a coastal region. On daily horizon, the relocation has implied\nfewer errors than a naive prediction method based on the persistence (RMSE=1468\nVs 1383Wh/m2 to Bastia and 1325 Vs 1213Wh/m2 to Corte). On hourly case, the\nresults were still satisfactory, and widely better than persistence (RMSE=138.8\nVs 109.3 Wh/m2 to Bastia and 135.1 Vs 114.7 Wh/m2 to Corte). The last\nexperiment was to evaluate the accuracy of our simulator on a PV power grid\nlocalized at 10 km from the station of Ajaccio. We got errors very suitable\n(nRMSE=27.9%, RMSE=99.0 W.h) compared to those obtained with the persistence\n(nRMSE=42.2%, RMSE=149.7 W.h).\n",
        "pdf_link": "http://arxiv.org/pdf/0905.3569v1"
    },
    {
        "title": "Multimedia Aplication for Solving a Sudoku Game",
        "authors": [
            "Alasu Paul Sabrin"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This article explains the way in which, with the help of Action Script 3 in\ncombination with Flash, a method of solving Sudoku game was implemented,\nthrough searching for the certain numbers and after that trying to guess for\nthe squares where there are two possible numbers.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4203v1"
    },
    {
        "title": "Mathematical Models in Danube Water Quality",
        "authors": [
            "Valerian Antohe",
            "Constantin Stanciu"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The mathematical shaping in the study of water quality has become a branch of\nenvironmental engineering. The comprehension and effective application of\nmathematical models in studying environmental phenomena keep up with the\nresults in the domain of mathematics and the development of specialized\nsoftware as well. Integrated software programs simulate and predict extreme\nevents, propose solutions, analyzing and processing data in due time. This\npaper presents a browsing through some mathematical categories of processing\nthe statistical data, examples and their analysis concerning the degree of\nwater pollution downstream the river Danube.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4322v1"
    },
    {
        "title": "Proposition d'une methode de qualification et de selection d'un logiciel\n  d'analyse et de suivi du referencement dans les moteurs de recherche",
        "authors": [
            "Sebastien Bruyere",
            "Vincent Pillet",
            "Luc Quoniam"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  In order to measure website visibility in search engines, there are softwares\nfor analytics and referencing follow-up. They permit to quantify website's\nefficacity of referencing and optimize its positionning in search engines. With\nregard to search engines' algorithms' evolution and centralization of Key\nPerformance Indicators for Marketing decision making, it becomes hard to find\nsolutions to effectively lead a lot of projects for referencing. That's why we\nhave built a methodology in order compare, evaluate and choose a software for\nanalytics and referencing follow-up in search engines.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4433v1"
    },
    {
        "title": "XML Technologies in Computer Assisted Learning and Testing Systems",
        "authors": [
            "Adrian Cojocariu",
            "Cristina Ofelia Stanciu"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The learning and assessment activities have undergone major changes due to\nthe development of modern technologies. The computer-assisted learning and\ntesting has proven a number of advantages in the development of modern\neducational system. The paper suggests a solution for the computer-assisted\ntesting, which uses XML technologies, a solution that could make the basis for\ndeveloping a learning computer-assisted system.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4604v1"
    },
    {
        "title": "Designing a Framework to Develop WEB Graphical Interfaces for ORACLE\n  Databases - Web Dialog",
        "authors": [
            "Georgiana-Petruta Fintineanu",
            "Florentina Anica Pintea"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The present article aims to describe a project consisting in designing a\nframework of applications used to create graphical interfaces with an Oracle\ndistributed database. The development of the project supposed the use of the\nlatest technologies: database Oracle server, Tomcat web server, JDBC (Java\nlibrary used for accessing a database), JSP and Tag Library (for the\ndevelopment of graphical interfaces).\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4608v1"
    },
    {
        "title": "The Effectiveness of Computer Assisted Classes for English as a Second\n  Language",
        "authors": [
            "Ioana Iacob"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The present study aims to evaluate the efficiency of the computer assisted\nEnglish classes and to emphasize the necessity of developing sound\nmethodological strategies adjusted to the new technology. It also present the\nbenefits of using the computer in the pre-school and elementary school classes,\nhighlighted by a report on the comparative observation of four groups of\nchildren studying English in a computer assisted environment.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4611v1"
    },
    {
        "title": "Informatics Issues Used in the Production Dashboard",
        "authors": [
            "Alin Isac",
            "Claudia Isac"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The aim of this paper is to present some computer aspects regarding the\nimplementation and the employing of a dashboard in relation to the production\nactivity. The paper begins with the theoretical presentation of the managerial\nperspective regarding the necessity of using the dashboard. The main functions\nof the dashboard in the production activity and the way it is employed are\npresented in the second part of the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4860v1"
    },
    {
        "title": "Flexible frontiers for text division into rows",
        "authors": [
            "Dan L. Lacrama",
            "Ioan Snep"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper presents an original solution for flexible hand-written text\ndivision into rows. Unlike the standard procedure, the proposed method avoids\nthe isolated characters extensions amputation and reduces the recognition error\nrate in the final stage.\n",
        "pdf_link": "http://arxiv.org/pdf/0905.4902v1"
    },
    {
        "title": "Specific Characteristics of Applying the Paired Comparison Method for\n  Parameterization of Consumer Wants",
        "authors": [
            "Vasiliy Saiko"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The article describes the main problems concerned with using expert\nassessment method in consumer preference researches. The author proved the\nexpediency of using a 3-point measurement scale. The author suggested an\nalgorithm for controlling the judgments' consistency that includes analyzing\nand correcting the input estimates in real-time mode.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.0851v1"
    },
    {
        "title": "Decision Support Systems Architectures",
        "authors": [
            "Cristina Ofelia Stanciu"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper presents the main components of the decision assisting systems.\nFurther on three types of architectures of these systems are described,\nanalyzed, and respectively compared, namely: the network architecture, the\ncentralized architecture and the hierarchical architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.0863v1"
    },
    {
        "title": "Adobe AIR, Bringing Rich Internet Applications to the Desktop",
        "authors": [
            "Valentin Vieriu",
            "Catalin Tuican"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Rich Internet Applications are the new trend in software development today.\nAdobe AIR offers the possibility to create cross-platform desktop applications\nusing popular Web technologies like HTML, JavaScript, Flash and Flex. This\narticle is focused on presenting the advantages that this new environment has\nto offer for the web development community and how quickly you can develop a\ndesktop application using Adobe AIR.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.0869v1"
    },
    {
        "title": "Upon the Modeling and the Optimization of the Debiting Process through\n  Computer Aided Non-Conventional Technologies",
        "authors": [
            "Tiberiu Marius Karnyanszky",
            "Mihai Titu"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The debiting process of the remarkable properties materials can be managed\nthrough unconventional technologies as the complex electrical erosion. We\npresent the modeling of the previous experimental results to obtain a\nmathematical dependence of the output parameters (processing time, surface\nquality) on the input parameters (voltage or current). All the experimental\ndata are memorized on a database and for each particular debiting process a new\ndependence is built. Because all the experiments applied in the Romanian\nlaboratories or practical applications of the nonconventional technological\nprocesses in the factories were based on the particular conditions of one\nactivity, this papers presents the technical implementation of a computer-aided\nsolution that keeps all previous experimental data, optimizes the processing\nconditions and eventual manage the driving gear. The flow-chart we present in\nthis paper offers a solution for practitioners to reduce the electrical\nconsumption while a technological processing of special materials is necessary.\nThe computer program and the database can be easily adapted to any\ntechnological processes (conventional or not).\n",
        "pdf_link": "http://arxiv.org/pdf/0906.0871v1"
    },
    {
        "title": "PayPal in Romania",
        "authors": [
            "Florentina Anica Pintea",
            "Georgiana Petruta Fintineanu",
            "Bogdan Ioan Selariu"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The present paper refers to the usefulness of online payment through PayPal\nand to the development of this payment manner in Romania. PayPal is an example\nof a payment intermediary service that facilitates worldwide e-commerce.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.0877v1"
    },
    {
        "title": "The morpho-topographic and cartographic analysis of the archaeological\n  site Cornesti \"Iarcuri\", Timis County, Romania, using computer sciences\n  methods (GIS and Remote Sensing techniques)",
        "authors": [
            "Dorel Micle",
            "Marcel Torok-Oance",
            "Liviu Maruia"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The archaeological site Cornesti \"Iarcuri\" is the largest earth fortification\nin Romania, made out of four concentric compounds, spreading over 1780\nhectares. It is known since 1700, but it had only a few small attempts of\nsystematic research, the fortress gained interest only after the publishing of\nsome satellite images by Google Earth. It is located in an area of high fields\nand it occupies three interfluves and contains two streams. Our paper contains\na geomorphologic, topographic and cartographic analysis of the site in order to\ndetermine the limits, the structure, the morphology, the construction technique\nand the functionality of such a fortification.Our research is based on\nsatellite image analysis, on archaeological topography, on soil, climate and\nvegetation analysis as a way to offer a complex image, through this\ninterdisciplinary study of landscape archaeology. Through our work we try not\nto date the site as this objective will be achieved only after completing the\nsystematic excavations which started in 2007, but only to analyze the\nco-relationship with the environment.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.1644v1"
    },
    {
        "title": "Towards Activity Context using Software Sensors",
        "authors": [
            "Kamran Taj Pathan",
            "Stephan Reiff-Marganiec"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Service-Oriented Computing delivers the promise of configuring and\nreconfiguring software systems to address user's needs in a dynamic way.\nContext-aware computing promises to capture the user's needs and hence the\nrequirements they have on systems. The marriage of both can deliver ad-hoc\nsoftware solutions relevant to the user in the most current fashion. However,\nhere it is a key to gather information on the users' activity (that is what\nthey are doing). Traditionally any context sensing was conducted with hardware\nsensors. However, software can also play the same role and in some situations\nwill be more useful to sense the activity of the user. Furthermore they can\nmake use of the fact that Service-oriented systems exchange information through\nstandard protocols. In this paper we discuss our proposed approach to sense the\nactivity of the user making use of software.\n",
        "pdf_link": "http://arxiv.org/pdf/0906.3925v1"
    },
    {
        "title": "Mathematical Modeling of Aerodynamic Space -to - Surface Flight with\n  Trajectory for Avoid Intercepting Process for Safety and Security Issues",
        "authors": [
            "Serge Gorneff"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The research project has been made for mathematical modeling of aerospace\nsystem Space-to-Surface for avoid intercepting process by flight objects\nSurface-to-Air. The research has been completed and created mathematical models\nwhich used for research and statistical analysis. In mathematical modeling has\nbeen including a few models: Model of atmosphere, Model of speed of sound,\nModel of flight head in space, Model of flight in atmosphere, Models of\nnavigation and guidance, Model and statistical analysis of approximation of\naerodynamic characteristics. Modeling has been created for a Space-to-Surface\nsystem defined for an optimal trajectory in terminal phase. The modeling\nincludes models for simulation atmosphere, aerodynamic flight and navigation by\nan infrared system. The modeling simulation includes statistical analysis of\nthe modeling results.\n",
        "pdf_link": "http://arxiv.org/pdf/0908.3271v1"
    },
    {
        "title": "How does certainty enter into the mind?",
        "authors": [
            "Ching-an Hsiao"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Any problem is concerned with the mind, but what do minds make a decision on?\nHere we show that there are three conditions for the mind to make a certain\nanswer. We found that some difficulties in physics and mathematics are in fact\nintroduced by infinity, which can not be rightly expressed by minds. Based on\nthis point, we suggest a general observation system, where we use region (a\ntype of infinity) to substitute for infinitesimal (another type of infinity)\nand thus get a consistent image with the mind. Furthermore, we declare that\nwithout world pictures we can never have ideas to any expressive events, which\nis the primary condition for a wave function like mind to collapse to a series\nof numbers. A following observation by expanding algorithm brings the final\ncollapse: classifying the numbers and coming up with a certain yes or no\nanswer.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.1709v2"
    },
    {
        "title": "On the Interesting World of Fractals and Their Applications to Music",
        "authors": [
            "Pabitra Pal Choudhury",
            "Sk. Sarif Hassan",
            "Sudhakar Sahoo",
            "Soubhik Chakraborty"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  In this paper we have defined one function that has been used to construct\ndifferent fractals having fractal dimensions between 1.58 and 2. Also, we tried\nto calculate the amount of increment of fractal dimension in accordance with\nthe base of the number systems. Further, interestingly enough, these very\nfractals could be a frame of lyrics for the musicians, as we know that the\nfractal dimension of music is around 1.65 and varies between a high of 1.68 and\na low of 1.60. Further, at the end we conjecture that the switching from one\nmusic fractal to another is nothing but enhancing a constant amount fractal\ndimension which might be equivalent to a kind of different sets of musical\nnotes in various orientations.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.2517v2"
    },
    {
        "title": "Dynamically Generated Interfaces in XML Based Architecture",
        "authors": [
            "Minit Gupta",
            "Laurent Romary"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Providing on-line services on the Internet will require the definition of\nflexible interfaces that are capable of adapting to the user's characteristics.\nThis is all the more important in the context of medical applications like home\nmonitoring, where no two patients have the same medical profile. Still, the\nproblem is not limited to the capacity of defining generic interfaces, as has\nbeen made possible by UIML, but also to define the underlying information\nstructures from which these may be generated. The DIATELIC project deals with\nthe tele-monitoring of patients under peritoneal dialysis. By means of XML\nabstractions, termed as \"medical components\", to represent the patient's\nprofile, the application configures the customizable properties of the\npatient's interface and generates a UIML document dynamically. The interface\nallows the patient to feed the data manually or use a device which allows\n\"automatic data acquisition\". The acquired medical data is transferred to an\nexpert system, which analyses the data and sends alerts to the medical staff.\nIn this paper we show how UIML can be seen as one component within a global XML\nbased architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.2721v1"
    },
    {
        "title": "Multiple antenna technologies",
        "authors": [
            "Manar Mohaisen",
            "YuPeng Wang",
            "KyungHi Chang"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Multiple antenna technologies have received high attention in the last few\ndecades for their capabilities to improve the overall system performance.\nMultiple-input multiple-output systems include a variety of techniques capable\nof not only increase the reliability of the communication but also impressively\nboost the channel capacity. In addition, smart antenna systems can increase the\nlink quality and lead to appreciable interference reduction.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.3342v1"
    },
    {
        "title": "An Empirical Comparative Study of Checklist based and Ad Hoc Code\n  Reading Techniques in a Distributed Groupware Environment",
        "authors": [
            "Olalekan S. Akinola",
            "Adenike O. Osofisan"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Software inspection is a necessary and important tool for software quality\nassurance. Since it was introduced by Fagan at IBM in 1976, arguments exist as\nto which method should be adopted to carry out the exercise, whether it should\nbe paper based or tool based, and what reading technique should be used on the\ninspection document. Extensive works have been done to determine the\neffectiveness of reviewers in paper based environment when using ad hoc and\nchecklist reading techniques. In this work, we take the software inspection\nresearch further by examining whether there is going to be any significant\ndifference in defect detection effectiveness of reviewers when they use either\nad hoc or checklist reading techniques in a distributed groupware environment.\nTwenty final year undergraduate students of computer science, divided into ad\nhoc and checklist reviewers groups of ten members each were employed to inspect\na medium sized java code synchronously on groupware deployed on the Internet.\nThe data obtained were subjected to tests of hypotheses using independent T\ntest and correlation coefficients. Results from the study indicate that there\nare no significant differences in the defect detection effectiveness, effort in\nterms of time taken in minutes and false positives reported by the reviewers\nusing either ad hoc or checklist based reading techniques in the distributed\ngroupware environment studied.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.4260v2"
    },
    {
        "title": "Through-Wall Tracking Using Variance-Based Radio Tomography Networks",
        "authors": [
            "Joey Wilson",
            "Neal Patwari"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper presents a new method for imaging, localizing, and tracking motion\nbehind walls in real-time. The method takes advantage of the motion-induced\nvariance of received signal strength measurements made in a wireless\npeer-to-peer network. Using a multipath channel model, we show that the signal\nstrength on a wireless link is largely dependent on the power contained in\nmultipath components that travel through space containing moving objects. A\nstatistical model relating variance to spatial locations of movement is\npresented and used as a framework for the estimation of a motion image. From\nthe motion image, the Kalman filter is applied to recursively track the\ncoordinates of a moving target. Experimental results for a 34-node through-wall\nimaging and tracking system over a 780 square foot area are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.5417v2"
    },
    {
        "title": "Prostate Biopsy Assistance System with Gland Deformation Estimation for\n  Enhanced Precision",
        "authors": [
            "Michael Baumann",
            "Pierre Mozer",
            "Vincent Daanen",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Computer-assisted prostate biopsies became a very active research area during\nthe last years. Prostate tracking makes it possi- ble to overcome several\ndrawbacks of the current standard transrectal ultrasound (TRUS) biopsy\nprocedure, namely the insufficient targeting accuracy which may lead to a\nbiopsy distribution of poor quality, the very approximate knowledge about the\nactual location of the sampled tissues which makes it difficult to implement\nfocal therapy strategies based on biopsy results, and finally the difficulty to\nprecisely reach non-ultrasound (US) targets stemming from different modalities,\nstatistical atlases or previous biopsy series. The prostate tracking systems\npresented so far are limited to rigid transformation tracking. However, the\ngland can get considerably deformed during the intervention because of US probe\npres- sure and patient movements. We propose to use 3D US combined with\nimage-based elastic registration to estimate these deformations. A fast elastic\nregistration algorithm that copes with the frequently occurring US shadows is\npresented. A patient cohort study was performed, which yielded a statistically\nsignificant in-vivo accuracy of 0.83+-0.54mm.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.5554v1"
    },
    {
        "title": "Co-Channel Interference Cancellation in OFDM Networks using Coordinated\n  Symbol Repetition and Soft Decision MLE CCI Canceler",
        "authors": [
            "Manar Mohaisen",
            "KyungHi Chang"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  In this paper, a new scheme of downlink co-channel interference (CCI)\ncancellation in OFDM cellular networks is introduced for users at the\ncell-edge. Coordinated symbol transmission between base stations (BS) is\noperated where the same symbol is transmitted from different BS on different\nsub-carriers. At the mobile station (MS) receiver, we introduce a soft decision\nmaximum likelihood CCI canceler and a modified maximum ratio combining (M-MRC)\nto obtain an estimate of the transmitted symbols. Weights used in the combining\nmethod are derived from the channels coefficients between the cooperated BS and\nthe MS. Simulations show that the proposed scheme works well under\nfrequency-selective channels and frequency non-selective channels. A gain of 9\ndB and 6 dB in SIR is obtained under multipath fading and flat-fading channels,\nrespectively.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.0733v1"
    },
    {
        "title": "A methodology for semi-automatic classification schema building",
        "authors": [
            "Erika De Francesco",
            "Salvatore Iiritano",
            "Antonino Spagnolo",
            "Marco Iannelli"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper describe a methodology for semi-automatic classification schema\ndefinition (a classification schema is a taxonomy of categories useful for\nautomatic document classification). The methodology is based on: (i) an\nextensional approach useful to create a typology starting from a document base,\nand (ii) an intensional approach to build the classification schema starting\nfrom the typology. The extensional approach uses clustering techniques to group\ntogether documents on the basis of a similarity measure, whereas the\nintensional approach uses different operations (aggregation, reduction,\ngeneralization specialization) to define classes. keywords: ontology,\nclassification schema, fundamentum divisionis, cluster analysis classification\ntask.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.0735v1"
    },
    {
        "title": "Some Thoughts on Hypercomputation",
        "authors": [
            "Apostolos Syropoulos"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Hypercomputation is a relatively new branch of computer science that emerged\nfrom the idea that the Church--Turing Thesis, which is supposed to describe\nwhat is computable and what is noncomputable, cannot possible be true. Because\nof its apparent validity, the Church--Turing Thesis has been used to\ninvestigate the possible limits of intelligence of any imaginable life form,\nand, consequently, the limits of information processing, since living beings\nare, among others, information processors. However, in the light of\nhypercomputation, which seems to be feasibly in our universe, one cannot impose\narbitrary limits to what intelligence can achieve unless there are specific\nphysical laws that prohibit the realization of something. In addition,\nhypercomputation allows us to ponder about aspects of communication between\nintelligent beings that have not been considered before\n",
        "pdf_link": "http://arxiv.org/pdf/0910.1494v1"
    },
    {
        "title": "Assessment of a percutaneous iliosacral screw insertion simulator",
        "authors": [
            "J. Tonetti",
            "L. Vadcard",
            "P. Girard",
            "M. Dubois",
            "P. Merloz",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  BACKGROUND: Navigational simulator use for specialized training purposes is\nrather uncommon in orthopaedic and trauma surgery. However, it reveals\nproviding a valuable tool to train orthopaedic surgeons and help them to plan\ncomplex surgical procedures. PURPOSE: This work's objective was to assess\neducational efficiency of a path simulator under fluoroscopic guidance applied\nto sacroiliac joint percutaneous screw fixation. MATERIALS AND METHODS: We\nevaluated 23 surgeons' accuracy inserting a guide-wire in a human cadaver\nexperiment, following a pre-established procedure. These medical trainees were\ndefined in three prospective respects: novice or skilled; with or without\ntheoretical knowledge; with or without surgical procedure familiarity. Analysed\ncriteria for each tested surgeon included the number of intraoperative X-rays\ntaken in order to achieve the surgical procedure as well as an iatrogenic index\nreflecting the surgeon's ability to detect any hazardous trajectory at the time\nof performing said procedure. RESULTS: An average number of 13 X-rays was\nrequired for wire implantation by the G1 group. G2 group, assisted by the\nsimulator use, required an average of 10 X-rays. A substantial difference was\nespecially observed within the novice sub-group (N), with an average of 12.75\nX-rays for the G1 category and an average of 8.5 X-rays for the G2 category. As\nfar as the iatrogenic index is concerned, we were unable to observe any\nsignificant difference between the groups.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.2154v1"
    },
    {
        "title": "Can we debug the Universe?",
        "authors": [
            "Apostolos Syropoulos"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Roughly, the Church-Turing thesis is a hypothesis that describes exactly what\ncan be computed by any real or feasible conceptual computing device. Generally\nspeaking, the computational metaphor is the idea that everything, including the\nuniverse itself, has a computational nature. However, if the Church-Turing\nthesis is not valid, then does it make sense to expect the construction of a\ncomputer program capable of simulating the whole Universe? In the lights of\nhypercomputation, the scientific discipline that is about computing beyond the\nChurch-Turing barrier, the most natural answer to this question is: No. This\nnote is a justification of this answer and its deeper meaning based on\narguments from physics, the philosophy of the mind, and, of course,\n(hyper)computability theory.\n",
        "pdf_link": "http://arxiv.org/pdf/0910.2859v2"
    },
    {
        "title": "Knowledge Extraction for Discriminating Male and Female in Logical\n  Reasoning from Student Model",
        "authors": [
            "A. E. E. Elalfi",
            "M. E. Elalami",
            "Y. M . Asem"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The learning process is a process of communication and interaction between\nthe teacher and his students on one side and between the students and each\nothers on the other side. Interaction of the teacher with his students has a\ngreat importance in the process of learning and education. The pattern and\nstyle of this interaction is determined by the educational situation, trends\nand concerns, and educational characteristics. Classroom interaction has an\nimportance and a big role in increasing the efficiency of the learning process\nand raising the achievement levels of students. Students need to learn skills\nand habits of study, especially at the university level. The effectiveness of\nlearning is affected by several factors that include the prevailing patterns of\ninteractive behavior in the classroom. These patterns are reflected in the\nactivities of teacher and learners during the learning process. The\neffectiveness of learning is also influenced by the cognitive and non cognitive\ncharacteristics of teacher that help him to succeed, the characteristics of\nlearners, teaching subject, and the teaching methods. This paper presents a\nmachine learning algorithm for extracting knowledge from student model. The\nproposed algorithm utilizes the inherent characteristic of genetic algorithm\nand neural network for extracting comprehensible rules from the student\ndatabase. The knowledge is used for discriminating male and female levels in\nlogical reasoning as a part of an expert system course.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0028v1"
    },
    {
        "title": "An Alternative To Common Content Management Techniques",
        "authors": [
            "Rares Vasilescu"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Content management systems use various strategies to store and manage\ninformation. One of the most usual methods encountered in commercial products\nis to make use of the file system to store the raw content information, while\nthe associated metadata is kept synchronized in a relational database\nmanagement system. This strategy has its advantages but we believe it also has\nsignificant limitations which should be addressed and eventually solved. In\nthis paper we propose an alternative method of storing and managing content\naiming at finding solutions for current limitations both in terms of functional\nand nonfunctional requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0151v1"
    },
    {
        "title": "Radio Transmission Performance of EPCglobal Gen-2 RFID System",
        "authors": [
            "Manar Mohaisen",
            "HeeSeok Yoon",
            "KyungHi Chang"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  In this paper, we analyze the performance of the encoding and the modulation\nprocesses in the downlink and uplink of the EPCglobal Gen2 system through the\nanalysis and simulation. Furthermore, the synchronization issues on time and\nfrequency domain and the preamble architecture are evaluated. Through the\nsimulation in the uplink, we find that the detection probability of FM0 and\nMiller coding approaches 1 at 13dB Eb/N0.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.0542v1"
    },
    {
        "title": "Rule-based Modelling and Tunable Resolution",
        "authors": [
            "Russ Harmer"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  We investigate the use of an extension of rule-based modelling for cellular\nsignalling to create a structured space of model variants. This enables the\nincremental development of rule sets that start from simple mechanisms and\nwhich, by a gradual increase in agent and rule resolution, evolve into more\ndetailed descriptions.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.2508v1"
    },
    {
        "title": "Le travail coopratif comme vecteur d'volution de nos systmes\n  d'information",
        "authors": [
            "Patrick Nourrissier",
            "Sahbi Sidhom"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This article focuses on presenting the cooperative tool DIMS, it is a\nplatform that can manage the participants's daily life, by providing\nflexibility and speed in the organization's tasks. The main interest lies in\nthe possibility of organizing information system in a logical network, across\nmultiple physical sites, incorporating a specific protocol to making possible\nthe inter-server communication. This protocol, based on the Jabber standard,\nthat meets the needs of working everyday matters, allowing the distribution of\nresearch and access to resources of the WAN. The technological objective\nconcerns the evolution of an information system architectures, where the\napplication may be a comprehensive set of tools and services on a distributed\nnetwork of remote sites. The challenge for users is the perception of a\ncollective role to each individual who cooperates in compliance with safety\nrules and unlimited access to technical information.\n",
        "pdf_link": "http://arxiv.org/pdf/0911.3301v1"
    },
    {
        "title": "Alternate methods of evaluation for web sites concordant to IAS/IFRS\n  Standards",
        "authors": [
            "I. Bostan",
            "D. Mates",
            "V. Grosu",
            "E. Iancu"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This work has as the principal theme, the study, analysis and implementation\nof the methodology for use the web sites in e-commerce. The authors try to deal\nwith particular methodological and applied aspects inherent in the analysis of\ndata from the interaction of man-Internet (Web-mining). The research\nmethodology of this work will be focused on a prevalent optic multidisciplinary\nresearch based on the pillars of data mining and Web mining. The explosion of\nInternet and electronic commerce has made the most of business to have its own\nwebsite. A company may engage internal costs for the development and operation\nof their website. The website can be designed for internal access (in which\ncase it can be used for presentation and data storage company policies with\nreferences of customers) or for external access (they are created and used for\npromotional and advertising products and services company). The objective of\nthis research, primarily concerns the definition of a repertoire of tools in\nanalyzing e-business through the development process for web-usage mining; 2nd\nobjective is oriented to management, recognizing and evaluating the web-sites\nin accountancy, as property intangible, which is a special case and very little\nstudied in economic literature financial specialty, the authors try to achieve\na national and international accounting treatment of the creation and\ndevelopment of web-sites.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3922v1"
    },
    {
        "title": "Web Based Cross Language Plagiarism Detection",
        "authors": [
            "Chow Kok Kent",
            "Naomie Salim"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  As the Internet help us cross language and cultural border by providing\ndifferent types of translation tools, cross language plagiarism, also known as\ntranslation plagiarism are bound to arise. Especially among the academic works,\nsuch issue will definitely affect the student's works including the quality of\ntheir assignments and paper works. In this paper, we propose a new approach in\ndetecting cross language plagiarism. Our web based cross language plagiarism\ndetection system is specially tuned to detect translation plagiarism by\nimplementing different techniques and tools to assist the detection process.\nGoogle Translate API is used as our translation tool and Google Search API,\nwhich is used in our information retrieval process. Our system is also\nintegrated with the fingerprint matching technique, which is a widely used\nplagiarism detection technique. In general, our proposed system is started by\ntranslating the input documents from Malay to English, followed by removal of\nstop words and stemming words, identification of similar documents in corpus,\ncomparison of similar pattern and finally summary of the result. Three\nleast-frequent 4-grams fingerprint matching is used to implement the core\ncomparison phase during the plagiarism detection process. In K-gram fingerprint\nmatching technique, although any value of K can be considered, yet K = 4 was\nstated as an ideal choice. This is because smaller values of K (i.e., K = 1, 2,\nor 3), do not provide good discrimination between sentences. On the other hand,\nthe larger the values of K (i.e., K = 5, 6, 7...etc), the better discrimination\nof words in one sentence from words in another.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3959v1"
    },
    {
        "title": "Speed Control of Multi Level Inverter Designed DC Series Motor with\n  Neuro-Fuzzy Controllers",
        "authors": [
            "G. MadhusudhanaRao",
            "B. V. SankerRam"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This paper describes the speed control of a DC series motor for an accurate\nand high-speed performance. A neural network based controlling operation with\nfuzzy modeling is suggested in this paper. The driver units of these machines\nare designed with a Multi-level inverter operation and are controlled by a\ncommon current control mechanism for an accurate and efficient driving\ntechnique for DC series motor. The neuro-fuzzy logic control technique is\nintroduced to eliminate uncertainties in the plant parameters of the DC Series\nmotors, and also considered as potential candidate for different applications\nto prove adequacy of the proposed control algorithm through simulations. The\nsimulation result with such an approach is made and observed efficient over\nother controlling technique.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3962v1"
    },
    {
        "title": "Analysis on the Study of QoS-Aware Web Services Discovery",
        "authors": [
            "T. Rajendran",
            "P. Balasubramanie"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Web service technology has gained more important role in developing\ndistributed applications and systems on the Internet. Rapid growth of published\nWeb services makes their discovery more and more difficult. There exist many\nweb services which exhibit similar functional characteristics. It is imperative\nto provide service consumers with facilities for selecting required web\nservices according to their non-functional characteristics or QoS. The\nQoS-based web service discovery mechanisms will play an essential role in SOA,\nas e-Business applications want to use services that most accurately meet their\nrequirements. However, representing and storing the values of QoS attributes\nare problematic, as the current UDDI was not designed to accommodate these\nemerging requirements. To solve the problems of storing QoS in UDDI and\naggregating QoS values using the tModel approach. The aim is to study these\napproaches and other existing QoS tModel representation for their efficiency\nand consistency in service discovery. This paper discusses a broad range of\nresearch issues such as web service discovery or web service selection based on\nQoS in the E-Business domain.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3965v1"
    },
    {
        "title": "Advanced Technology in Speech Disorder Therapy of Romanian Language",
        "authors": [
            "Mirela Danubianu",
            "Iolanda Tobolcea",
            "Stefan Gheorghe Pentiuc"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  One of the key challenges of the society development is related to public\nhealth and one of its specific targets includes better treatments of diseases.\nIt is true that there are affections which by their nature do not endanger the\nlife of a person, but they may have negative implications during his/her\nlifetime. Various language or speech disorders are part of this category.\nDiscovered and treated in time, they can be corrected, most often in childhood.\nBecause the Romanian language is a phonetic one that has its own special\nlinguistic particularities, there is a real need to develop advanced\ninformation systems, which can be used to assist and help specialists in\ndifferent speech disorders therapy. The aim of this paper is to present a few\nCBTS developed for the treatment of various language and speech disorders\nspecific to the Romanian language.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3969v1"
    },
    {
        "title": "The Effected Oxide Capacitor in CMOS Structure of Integrated Circuit\n  Level 5 Micrometer Technology",
        "authors": [
            "S. Rodthong",
            "B. Burapattanasiri"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  This article is present the effected oxide capacitor in CMOS structure of\nintegrated circuit level 5 micrometer technology. It has designed and basic\nstructure of MOS diode. It establish with aluminum metallization layer by\nsputtering method, oxide insulator layer mode from silicon dioxide, n+ and p+\nsemiconductor layer, it has high capacitance concentrate. From the MOS diode\nstructure silicon dioxide thickness 0.5 micrometer, it will get capacitance\nbetween aluminum metal layer and p+ semiconductor at 28.62 pF, the capacitance\nbetween aluminum metal layer and n+ semiconductor at 29.55 pF. In this article\nestablish second metal layer for measurement density values of first aluminum\nmetal layer with second aluminum metal layer, it has density values at 16 pF.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3971v1"
    },
    {
        "title": "Teaching Result Analysis Using Rough Sets and Data Mining",
        "authors": [
            "P. Ramasubramanian",
            "K. Iyakutti",
            "P. Thangavelu",
            "J. Joy Winston"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  The development of IT and WWW provides different teaching strategies, which\nare chosen by teachers. Students can acquire knowledge through different\nlearning models. The problem based learning is a popular teaching strategy for\nteachers. Based on the educational theory, students increase their learning\nmotivation, which can increase learning effectiveness. In this paper, we\npropose a concept map for each student and staff. This map finds the result of\nthe subjects and also recommends a sequence of remedial teaching. Here, rough\nset theory is used for dealing with uncertainty in the hidden pattern of data.\nFor each competence the lower and upper approximations are calculated based on\nthe brainstorm maps.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3975v1"
    },
    {
        "title": "Retail Market analysis in targeting sales based on Consumer Behaviour\n  using Fuzzy Clustering - A Rule Based Mode",
        "authors": [
            "D. Bhanu",
            "S. Pavai Madeshwari"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Product Bundling and offering products to customers is of critical importance\nin retail marketing. In general, product bundling and offering products to\ncustomers involves two main issues, namely identification of product taste\naccording to demography and product evaluation and selection to increase sales.\nThe former helps to identify, analyze and understand customer needs according\nto the demo-graphical characteristics and correspondingly transform them into a\nset of specifications and offerings for people. The latter, concerns with how\nto determine the best product strategy and offerings for the customer in\nhelping the retail market to improve their sales. Existing research has focused\nonly on identifying patterns for a particular dataset and for a particular\nsetting. This work aims to develop an explicit decision support for the\nretailers to improve their product segmentation for different settings based on\nthe people characteristics and thereby promoting sales by efficient knowledge\ndiscovery from the existing sales and product records. The work presents a\nframework, which models an association relation mapping between the customers\nand the clusters of products they purchase in an existing location and helps in\nfinding rules for a new location. The methodology is based on the integration\nof popular data mining approaches such as clustering and association rule\nmining. It focuses on the discovery of rules that vary according to the\neconomic and demographic characteristics and concentrates on marketing of\nproducts based on the population.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.3982v1"
    },
    {
        "title": "Pseudorandomness in Central Force Optimization",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Central Force Optimization is a deterministic metaheuristic for an\nevolutionary algorithm that searches a decision space by flying probes whose\ntrajectories are computed using a gravitational metaphor. CFO benefits\nsubstantially from the inclusion of a pseudorandom component (a numerical\nsequence that is precisely known by specification or calculation but otherwise\narbitrary). The essential requirement is that the sequence is uncorrelated with\nthe decision space topology, so that its effect is to pseudorandomly distribute\nprobes throughout the landscape. While this process may appear to be similar to\nthe randomness in an inherently stochastic algorithm, it is in fact\nfundamentally different because CFO remains deterministic at every step. Three\npseudorandom methods are discussed (initial probe distribution, repositioning\nfactor, and decision space adaptation). A sample problem is presented in detail\nand summary data included for a 23-function benchmark suite. CFO's performance\nis quite good compared to other highly developed, state-of-the-art algorithms.\nIncludes corrections 02-03-2010.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.0317v2"
    },
    {
        "title": "Design and Analysis of a Spurious Switching Suppression Technique\n  Equipped Low Power Multiplier with Hybrid Encoding Scheme",
        "authors": [
            "S. Saravanan",
            "M. Madheswaran"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Multiplication is an arithmetic operation that is mostly used in Digital\nSignal Processing (DSP) and communication applications. Efficient\nimplementation of the multipliers is required in many applications. The design\nand analysis of Spurious Switching Suppression Technique (SSST) equipped low\npower multiplier with hybrid encoding is presented in this paper. The proposed\nencoding technique reduces the number of switching activity and dynamic power\nconsumption by analyzing the bit patterns in the input data. In this proposed\nencoding scheme, the operation is executed depends upon the number of 1s and\nits position in the multiplier data. The architecture of the proposed\nmultiplier is designed using a low power full adder which consumes less power\nthan the other adder architectures. The switching activity of the proposed\nmultiplier has been reduced by 86 percent and 46percent compared with\nconventional and Booth multiplier respectively. It is observed from the device\nlevel simulation using TANNER 12.6 EDA that the power consumption of the\nproposed multiplier has been reduced by 87 percent and 26 percent compared with\nconventional and Booth multiplier.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.1976v1"
    },
    {
        "title": "An Efficient Inter Carrier Interference Cancellation Schemes for OFDM\n  Systems",
        "authors": [
            "B. Sathish Kumar",
            "K. R. Shankar Kumar",
            "R. Radhakrishnan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Orthogonal Frequency Division Multiplexing (OFDM) has recently been used\nwidely in wireless communication systems. OFDM is very effective in combating\nintersymbol interference and can achieve high data rate in frequency selective\nchannel. For OFDM communication systems, the frequency offsets in mobile radio\nchannels distort the orthogonality between subcarriers resulting in Inter\nCarrier Interference (ICI). ICI causes power leakage among subcarriers thus\ndegrading the system performance. A wellknown problem of OFDM is its\nsensitivity to frequency offset between the transmitted and received carrier\nfrequencies. There are two deleterious effects caused by frequency offset one\nis the reduction of signal amplitude in the output of the filters matched to\neach of the carriers and the second is introduction of ICI from the other\ncarriers. This research work investigates three effective methods for combating\nthe effects of ICI: ICI Self Cancellation (SC), Maximum Likelihood (ML)\nestimation, and Extended Kalman Filter (EKF) method. These three methods are\ncompared in terms of bit error rate performance and bandwidth efficiency.\nThrough simulations, it is shown that the three techniques are effective in\nmitigating the modulation schemes, the ML and EKF methods perform better than\nthe SC method.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.2250v1"
    },
    {
        "title": "High Precision HalfWave Rectifier Circuit In Dual Phase Output Mode",
        "authors": [
            "Theerayut Jamjaem",
            "Bancha Burapattanasiri"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper present high precision halfwave rectifier circuit in dual phase\noutput mode by 0.5 micrometer CMOS technology, plus or minus 1.5 V low voltage,\nit has received input signal and sent output current signal, respond in high\nfrequency. The main structure compound with CMOS inverter circuit, common\nsource circuit, and current mirror circuit. Simulation and confirmation quality\nof working by PSpice program, then it able to operating at maximum frequency\nabout 100 MHz, maximum input current range about 400 \\mu Ap p, high precision\noutput signal, low power dissipation, and uses a little transistor.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.2253v1"
    },
    {
        "title": "High Precision MultiWave Rectifier Circuit Operating in Low Voltage 1.5\n  Volt Current Mode",
        "authors": [
            "Bancha Burapattanasiri"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This article is present high precision multiwave rectifier circuit operating\nin low voltage plus or minus 1.5 Volt current modes by CMOS technology 0.5\n\\mum, receive input and give output in current mode, respond at high frequency\nperiod. The structure compound with high speed current comparator circuit,\ncurrent mirror circuit, and CMOS inverter circuit. PSpice program used for\nconfirmation the performance of testing. The PSpice program shows operating of\ncircuit is able to working at maximum input current 400 \\muAp p, maximum\nfrequency responding 200 MHz, high precision and low power losses, and\nnon-precision zero crossing output signal.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.2261v1"
    },
    {
        "title": "Sinusoidal Frequency Doublers Circuit With Low Voltage 1.5 Volt CMOS\n  Inverter",
        "authors": [
            "Bancha Burapattanasiri"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper is present sinusoidal frequency doublers circuit with low voltage\n1.5 volt CMOS inverter. Main structure of circuit has three parts that is CMOS\ninverter circuit, differential amplifier circuit, and square root circuit. This\ncircuit has designed to receive input voltage and give output voltage use few\nMOS transistor, easy to understand, non complex of circuit, high precision, low\nerror and low power. The Simulation of circuit has MOS transistor functional in\nactive and saturation period. PSpice programmed has used to confirmation of\ntesting and simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.2264v1"
    },
    {
        "title": "Mortality and Longevity Valuation - A Quantitative Approach",
        "authors": [
            "Louis Mello"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper examines several computer algorithms designed to assess mortality\nand longevity risk.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.3038v2"
    },
    {
        "title": "Heat Sink Performance Analysis through Numerical Technique",
        "authors": [
            "B. Sri Aravindh",
            "T. R. Gopalakrishnan Nair"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The increase in dissipated power per unit area of electronic components sets\nhigher demands on the performance of the heat sink. Also if we continue at our\ncurrent rate of miniaturisation, laptops and other electronic devices can get\nheated up tremendously. Hence we require a better heat dissipating system to\novercome the excess heat generating problem of using nanoelectronics, which is\nexpected to power the next generation of computers. To handle the excessive and\noften unpredictable heating up of high performance electronic components like\nmicroprocessors, we need to predict the temperature profile of the heat sink\nused. This also helps us to select the best heat sink for the operating power\nrange of any microprocessor. Understanding the temperature profile of a heat\nsink and a microprocessor helps us to handle its temperature efficiently for a\nrange of loads. In this work, a method to estimate the normal response of a\nheat sink to various loads of a microprocessor is explained.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.3751v3"
    },
    {
        "title": "A Study of VLSI Technology, Wafers and Impact on Nanotechnology",
        "authors": [
            "Kiran Gupta",
            "T. R. Gopalakrishnan Nair"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper presents a detailed study of the present VLSI technological\naspects, importance and their replacement or combination with the\nNanotechnology in the VLSI world of silicon semiconductors. Here authors bring\nout the nanotechnology in Silicon world which invariably means shrinking\ngeometry of CMOS devices to nano scale. This also refers to a new world of\nnanotechnology where chemists are working in manufacturing of carbon nanotubes\n, nano devices of varius materials of nano dimensions without even knowing how\nthis could change the whole world of Si and CMOS technology and the world we\nlive in.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.3771v1"
    },
    {
        "title": "Solar Still Coupled With Solar Collector and Storage Tank",
        "authors": [
            "A. M. Rajesh",
            "K. N. Bharath"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Acute shortage of good, clean drinking water is a major problem for most\ndeveloping countries of the world. In most cases, ponds, streams, wells and\nrivers are often polluted that they are unsafe for direct use as drinking water\n>.Often water sources are brackish and or contain harmful bacteria. Therefore\ncannot be used for drinking .In addition there are many coastal locations where\nsea water is abundant but potable water is not available. Solar distillation is\none of the important methods of utilizing solar energy for the supply of\npotable water to small communities where natural supply of fresh water is\ninadequate or of poor quality .In this direction an experimental performance\nanalysis was carried out on a single basin still compared with FPC coupled one.\nTest were carried out for different water samples namely borewell water, sea\nwater, river water for a water depth of 20 mm\n",
        "pdf_link": "http://arxiv.org/pdf/1002.0049v1"
    },
    {
        "title": "Modeling of 2D and 3D Assemblies Taking Into Account Form Errors of\n  Plane Surfaces",
        "authors": [
            "Serge Samper",
            "Pierre-Antoine Adragna",
            "Hugues Favreliere",
            "Maurice Pillet"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The tolerancing process links the virtual and the real worlds. From the\nformer, tolerances define a variational geometrical language (geometric\nparameters). From the latter, there are values limiting those parameters. The\nbeginning of a tolerancing process is in this duality. As high precision\nassemblies cannot be analyzed with the assumption that form errors are\nnegligible, we propose to apply this process to assemblies with form errors\nthrough a new way of allowing to parameterize forms and solve their assemblies.\nThe assembly process is calculated through a method of allowing to solve the 3D\nassemblies of pairs of surfaces having form errors using a static equilibrium.\nWe have built a geometrical model based on the modal shapes of the ideal\nsurface. We compute for the completely deterministic contact points between\nthis pair of shapes according to a given assembly process. The solution gives\nan accurate evaluation of the assembly performance. Then we compare the results\nwith or without taking into account the form errors. When we analyze a batch of\nassemblies, the problem is to compute for the nonconformity rate of a pilot\nproduction according to the functional requirements. We input probable errors\nof surfaces (position, orientation, and form) in our calculus and we evaluate\nthe quality of the results compared with the functional requirements. The pilot\nproduction then can or cannot be validated.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.0214v1"
    },
    {
        "title": "Caractrisation des dfauts d'une surface sphrique par\n  dcomposition modale",
        "authors": [
            "Hugues Favreliere",
            "Serge Samper",
            "Pierre-Antoine Adragna"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The [ISO 1101] standard specifies the form errors with geometrical tolerances\nusing the zone concept.To complete this concept, we present a generic method\nwhich adapts to any geometry and allows to describe any kind of errors. Thus,we\ncan dissociate the part errors according to reference categories: position,\norientation,form, waviness and roughnesses. Starting from a cloud of poinds\nrepresenting the error measurement, the \"modal\" method decompose, like Fourier\nseries,this error in a sum of sorted errors according to the ircomplexity\ndegree (a number of \"wavinesses\"). In addition, we propose to show, on a simple\nexample, that according to error complexity to be characterized, an\ninterpolation by the modal method allows to optimize the measuring strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.0251v1"
    },
    {
        "title": "A proposition of 3D inertial tolerancing to consider the statistical\n  combination of the location and orientation deviations",
        "authors": [
            "Pierre-Antoine Adragna",
            "Serge Samper",
            "Maurice Pillet"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Tolerancing of assembly mechanisms is a major interest in the product life\ncycle. One can distinguish several models with growing complexity, from\n1-dimensional (1D) to 3-dimensional (3D) (including form deviations), and two\nmain tolerancing assumptions, the worst case and the statistical hypothesis.\nThis paper presents an approach to 3D statistical tolerancing using a new\nacceptance criterion. Our approach is based on the 1D inertial acceptance\ncriterion that is extended to 3D and form acceptance. The modal\ncharacterisation is used to describe the form deviation of a geometry as the\ncombination of elementary deviations (location, orientation and form). The\nproposed 3D statistical tolerancing is applied on a simple mechanism with lever\narm. It is also compared to the traditional worst-case tolerancing using a\ntolerance zone.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.0253v1"
    },
    {
        "title": "Optimization of a Classical Stamping Progression by Modal Correction of\n  Anisotropy Ears",
        "authors": [
            "Y. Ledoux",
            "H. Favreliere",
            "Serge Samper"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This work is a development from the Inetforsmep European project. We proposed\nto realize a global optimization of a deep drawing industrial progression (made\nof several stages) for a cup manufacture. The objectives of the process were\nthe thickness decrease and the geometrical parameters (especially the height).\nThis paper improves on this previous work in the aim of mastering the contour\nerror. From the optimal configuration, we expect to cut down the amount of the\nneeded material and the number of forming operations. Our action is focused on\nthe appearance of unexpected undulations (ears) located on the rim of the cups\nduring forming due to a nonuniform crystallographic texture. Those undulations\ncan cause a significant amount of scraps, productivity loss, and cost during\nmanufacture. In this paper, this phenomenon causes the use of four forming\noperations for the cup manufacture. The aim is to cut down from four to two\nforming stages by defining an optimal blank (size and shape). The advantage is\nto reduce the cost of the tool manufacturing and to minimize the needed\nmaterial (by suppressing the part flange). The chosen approach consists in\ndefining a particular description of the ears' part by modal decomposition and\nthen simulating several blank shapes and sizes generated by discrete cosine\ntransformation (DCT). The use of a numerical simulation for the forming\noperation and the design of an experiment technique allow mathematical links\nbetween the ears' formation and the DCT coefficients. An optimization is then\npossible by using mathematical links. This original approach leads the ears'\namplitude to be reduced by a factor of 10, with only 15 numerical experiments.\nMoreover, we have limited the number of forming stages from 4 to 2 with a\nminimal material use.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.0262v1"
    },
    {
        "title": "Inertial tolerancing and capability indices in an assembly production",
        "authors": [
            "Pierre-Antoine Adragna",
            "Maurice Pillet",
            "Fabien Formosa",
            "Serge Samper"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Traditional tolerancing considers the conformity of a batch when the batch\nsatisfies the specifications. The characteristic is considered for itself and\nnot according to its incidence in the assembly. Inertial tolerancing proposes\nanother alternative of tolerancing in order to guarantee the final assembly\ncharacteristic. The inertia I2 = \\sqrt{\\delta^2 + \\sigma^2} is not toleranced\nby a tolerance interval but by a scalar representing the maximum inertia that\nthe characteristic should not exceed. We detail how to calculate the inertial\ntolerances according to two cases, one aims to guarantee an inertia of the\nassembly characteristic the other a tolerance interval on the assembly\ncharacteristic by a Cpk capability index, in the particular but common case of\nuniform tolerances or more general with non uniform tolerances. An example will\nbe detailed to show the results of the different tolerancing methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.0270v1"
    },
    {
        "title": "ICT in Universities of the Western Himalayan Region of India II: A\n  Comparative SWOT Analysis",
        "authors": [
            "Dhirendra Sharma",
            "Vikram Singh"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This study presents a comparative SWOT analysis to comprehend the pattern of\ndevelopment of ICT within six universities of western Himalayan region of\nIndia. With the objective of achieving quality and excellence in higher\neducation system in the region, this study provides a basis to decision makers\nto exploit opportunities and minimize the external threats. The SWOT analysis\nof different universities, placed under three categories, has been undertaken\nwithin the four-tier framework used earlier by the authors. Guided by the\ninitiatives of National Mission on Education through ICT (NMEICT) for SWOT\nanalysis, findings of this paper reveal, relative consistency of these three\ncategories of universities, with the earlier study. A few suggestions, as\nopportunities, with an emphasis on problem solving orientation in higher\neducation, have been made to strengthen the leadership of universities in the\nfield of ICT.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.1193v1"
    },
    {
        "title": "Modified EESM Based Link Adaptation Algorithm for Multimedia\n  Transmission in Multicarrier Systems",
        "authors": [
            "R. Sandanalakshmi",
            " Athilakshmi",
            "K. Manivannan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The previous link adaptation algorithms on ofdm based systems use equal\nmodulation order for all sub carrier index within a block. For multimedia\ntransmission using ofdm as the modulation technique, unequal constellation is\nused within one ofdm subcarrier block, a set of subcarriers for audio and\nanother set for video transmissions. A generic model has been shown for such a\ntransmission and link adaptation algorithm has been proposed using EESM\n(Effective Exponential SNR mapping) method as basic method. Mathematical model\nhas been derived for the channel based on bivariate Gaussian distribution in\nwhich the amplitude varies two dimensionally in the same envelope. From the\nMoment generating function of bivariate distribution, Probability of error has\nbeen theoretically derived. Results have been shown for BER performance of an\nofdm system using unequal constellation. BER performances have been shown for\ndifferent values of correlation parameter and fading figure.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.1198v1"
    },
    {
        "title": "Understanding Formulation of Social Capital in Online Social Network\n  Sites (SNS)",
        "authors": [
            "S. S. Phulari",
            "S. D. Khamitkar",
            "N. K. Deshmukh",
            "P. U. Bhalchandra",
            "S. N. Lokhande",
            "A. R. Shinde"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Online communities are the gatherings of like-minded people, brought together\nin cyberspace by shared interests. The shared interest has hidden social\ncapital aspects and can be of bridging or bonding type. Creating such\ncommunities is not a big challenge but sustaining member's participation is.\nThis study examines the formation and maintenance of social capital in social\nnetwork sites. In addition to assessing bonding and bridging social capital, we\nexplore a dimension of social capital that assesses one's ability to stay\nconnected with members of a previously inhabited community, which we call\nmaintained social capital. Such dimension is enacted here in terms of\nHypothesis.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.1201v1"
    },
    {
        "title": "Design of Current Controller for Two Quadrant DC Motor Drive by Using\n  Model Order Reduction Technique",
        "authors": [
            "K. Ramesh",
            "K. Ayyar",
            "A. Nirmalkumar",
            "G. Gurusamy"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper, design of current controller for a two quadrant DC motor drive\nwas proposed with the help of model order reduction technique. The calculation\nof current controller gain with some approximations in the conventional design\nprocess is replaced by proposed model order reduction method. The model order\nreduction technique proposed in this paper gives the better controller gain\nvalue for the DC motor drive. The proposed model order reduction method is a\nmixed method, where the numerator polynomial of reduced order model is obtained\nby using stability equation method and the denominator polynomial is obtained\nby using some approximation technique preceded in this paper. The designed\ncontrollers responses were simulated with the help of MATLAB to show the\nvalidity of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.1683v1"
    },
    {
        "title": "An Intelligent System For Effective Forest Fire Detection Using Spatial\n  Data",
        "authors": [
            "K. Angayarkkani",
            "N. Radhakrishnan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The explosive growth of spatial data and extensive utilization of spatial\ndatabases emphasize the necessity for the automated discovery of spatial\nknowledge. In modern times, spatial data mining has emerged as an area of\nvoluminous research. Forest fires are a chief environmental concern, causing\neconomical and ecological damage while endangering human lives across the\nworld. The fast or early detection of forest fires is a vital element for\ncontrolling such phenomenon. The application of remote sensing is at present a\nsignificant method for forest fires monitoring, particularly in vast and remote\nareas. Different methods have been presented by researchers for forest fire\ndetection. The motivation behind this research is to obtain beneficial\ninformation from images in the forest spatial data and use the same in the\ndetermination of regions at the risk of fires by utilizing Image Processing and\nArtificial Intelligence techniques. This paper presents an intelligent system\nto detect the presence of forest fires in the forest spatial data using\nArtificial Neural Networks. The digital images in the forest spatial data are\nconverted from RGB to XYZ color space and then segmented by employing\nanisotropic diffusion to identify the fire regions. Subsequently, Radial Basis\nFunction Neural Network is employed in the design of the intelligent system,\nwhich is trained with the color space values of the segmented fire regions.\nExtensive experimental assessments on publicly available spatial data\nillustrated the efficiency of the proposed system in effectively detecting\nforest fires.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.2199v1"
    },
    {
        "title": "IT in Power Sector A KPCL Implementation",
        "authors": [
            "T. P. Pushpavathi",
            "N. R. Shashi Kumar",
            "R. Selvarani"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper we investigate the extent of Information Technology penetration\nin Power sector, taking KPCL, Karnataka Power Corporation Ltd., a premier power\ngenerating, a state owned public sector organization as an example. Any\norganization to flourish, adoption of Information Technology is inevitable in\nthe days of fast changing technological advancements. It is not merely the\ninvestment on IT which helps but adoption of right IT solutions and the optimum\nuse of the same does matter and becomes most critical. A strong infrastructure\ncoupled with modern technical and management concepts has helped KPCL to meet\nthe challenges of the rising energy demands of Karnataka.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.2687v1"
    },
    {
        "title": "Comparative Results: Group Search Optimizer and Central Force\n  Optimization",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This note compares the performance of two multidimensional search and\noptimization algorithms: Group Search Optimizer and Central Force Optimization.\nGSO is a new state-of-the-art algorithm that has gained some notoriety,\nconsequently providing an excellent yardstick for measuring the performance of\nother algorithms. CFO is a novel deterministic metaheuristic that has performed\nwell against GSO in previous tests. The CFO implementation reported here\nincludes architectural improvements in errant probe retrieval and decision\nspace adaptation that result in even better performance. Detailed results are\nprovided for the twenty-three function benchmark suite used to evaluate GSO.\nCFO performs better than or essentially as well as GSO on twenty functions and\nnearly as well on one of the remaining three. Includes update 24 February 2010.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.2798v2"
    },
    {
        "title": "Effect of different substrates on Compact stacked square Microstrip\n  Antenna",
        "authors": [
            "Asok De",
            "N. S. Raghava",
            "Sagar Malhotra",
            "Pushkar Arora",
            "Rishik Bazaz"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Selection of the most suitable substrate for a Microstrip antenna is a matter\nof prime importance. This is because many limitations of the microstrip antenna\nsuch as high return loss, low gain and low efficiency can be overcome by\nselecting an appropriate substrate for fabrication of the antenna, without\nshifting the resonant frequency significantly. The substate properties such as\nits dielectric constant, loss tangent have a pronounced effect on the antenna\ncharacteristics. Some of the critical properties that are to be taken care of\nwhile selecting a dielectric are homogeneity, moisture absorption and adhesion\nof metal- foil cladding. In this paper a comprehensive study of the effect of\nvariation of substrate material on the antenna properties has been presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3337v1"
    },
    {
        "title": "Limited Memory Prediction for Linear Systems with Different types of\n  Observation",
        "authors": [
            "Ha-ryong Song",
            "Vladimir Shin"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper is concerned with distributed limited memory prediction for\ncontinuous-time linear stochastic systems with multiple sensors. A distributed\nfusion with the weighted sum structure is applied to the optimal local limited\nmemory predictors. The distributed prediction algorithm represents the optimal\nlinear fusion by weighting matrices under the minimum mean square criterion.\nThe algorithm has the parallel structure and allows parallel processing of\nobservations making it reliable since the rest faultless sensors can continue\nto the fusion estimation if some sensors occur faulty. The derivation of\nequations for error cross-covariances between the local predictors is the key\nof this paper. Example demonstrates effectiveness of the distributed limited\nmemory predictor.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3339v1"
    },
    {
        "title": "FPGA Based Sinusoidal Pulse Width Modulated Waveform Generation for\n  Solar (PV) Rural Home Power Inverter",
        "authors": [
            "S. N. Singh",
            "A. K. Singh"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  With the increasing concern about global environmental protection and energy\ndemand due to rapid growth of population in developing countries and the\ndiminishing trend of resources of conventional grid supply, the need to produce\nfreely available pollution free natural energy such as solar/wind energy has\nbeen drawing increasing interest in every corner of the world. In an effort to\nutilize these energies effectively through Power converter, a great deal of\nresearch is being carried out by different researchers / scientist and\nengineers at different places in the world to meet the increasing demand of\nload. The study presents methodology to integrate solar (PV) energy (which is\nfreely available in every corner of the world) with grid source and supplement\nthe existing grid power in rural houses during its cut off or restricted supply\nperiod. In order to get consistency in supply a DG is also added as a standby\nsource in the proposed integration of network. The software using novel Direct\nPWM modulation strategy and its soft control features extend the flexibility to\ncontrol converter (inverter) parameters like voltage, frequency, number of\nsamples of PWM pulses constituting sine-wave without changing any hardware\nconfiguration in the circuit. The system simulation of PWM Pulse generation has\nbeen done on a XILINX based FPGA Spartan 3E board using VHDL code. The test on\nsimulation of PWM generation program after synthesis and compilation were\nrecorded and verified on a prototype sample.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3340v1"
    },
    {
        "title": "Optimized reversible BCD adder using new reversible logic gates",
        "authors": [
            "H. R. Bhagyalakshmi",
            "M. K. Venkatesha"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Reversible logic has received great attention in the recent years due to\ntheir ability to reduce the power dissipation which is the main requirement in\nlow power digital design. It has wide applications advanced computing, low\npower CMOS design, Optical information processing, DNA computing, bio\ninformation, quantum computation and nanotechnology. This paper presents an\noptimized reversible BCD adder using a new reversible gate. A comparative\nresult is presented which shows that the proposed design is more optimized in\nterms of number of gates, number of garbage outputs and quantum cost than the\nexisting designs.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3994v1"
    },
    {
        "title": "Determining the quality evaluation procedures using the expert systems",
        "authors": [
            "N. Holban",
            "V. Ditoiu",
            "E. Iancu"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  At this time, quality is a strategic instrument of the entities' global\nmanagement, but it is also a determining element of their competitive spirit.\nThe importance given to quality is abundantly found in the preoccupations of\nthe European Union's Minister Board, by elaborating documents with a high\nimpact over the quality of products/ services in special, and organizations in\ngeneral. We live in an era, when the evolution of the social life puts the\naccent more and more on quality, resulted from various processes, at the level\nof various domains of the economical and social development.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3995v1"
    },
    {
        "title": "The Role of the XBRL Standard in Optimizing the Financial Reporting",
        "authors": [
            "V. Grosu",
            "E. Hlaciuc",
            "E. Iancu",
            "R. Petris",
            "M. Socoliuc"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  When the financial information is difficult to produce, interpret, compare\nand analyze, we are put in the situation to face inconvenient consequences with\nnegative repercussions, such as: the investor can give up the investment (with\nnegative consequences on the risk equity market), the banks may not give loans,\nan auditor may not consider the financial statements as being credible etc.\nThese facts allow the introduction of this paper's main objective, the\neXtensible Business Reporting Language (XBRL) which is an open standard,\nindependent and international for the treatments, opportunity, correctness,\nefficiency and minor costs of the financial and economical information. The\nXBRL will be analyzed in the second part of the paper, the history of this\nelectronic communication language will be described, as there will also be\ndescribed the promoting organizations, the base technology (the WEB and XML\narchitecture which will be the next stage of the internet programming), and the\nrole it has within the chain of reporting between the XBRL consortium and the\ninternational accounting organizations IASB-CI. This taxonomy serves clearly\nevery accounting and extra- accounting information made by the company. This\ninformation which is treated in present by resorting to various formats or\nstructures (most times incompatible between them and the owners) will be\nstandardized with the XBRL.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3997v1"
    },
    {
        "title": "Equal Power Distribution and Dynamic Subcarrier Assignment in OFDM Using\n  Minimum Channel Gain Flow with Robust Optimization Uncertain Demand",
        "authors": [
            "F. A. Hla Myo Tun",
            "S. B. Aye Thandar Phyo",
            "T. C. Zaw Min Naing"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper, the minimum channel gain flow with uncertainty in the demand\nvector is examined. The approach is based on a transformation of uncertainty in\nthe demand vector to uncertainty in the gain vector. OFDM systems are known to\novercome the impairment of the wireless channel by splitting the given system\nbandwidth into parallel sub-carriers, on which data-symbols can be transmitted\nsimultaneously. This enables the possibility of enhancing the system's\nperformance by deploying adaptive mechanisms, namely power distribution and\ndynamic sub-carrier assignments. The performances of maximizing the minimum\nthroughput have been analyzed by MATLAB codes.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.4045v1"
    },
    {
        "title": "Optimal Control Strategies in Delayed Sharing Information Structures",
        "authors": [
            "Ashutosh Nayyar",
            "Aditya Mahajan",
            "Demosthenis Teneketzis"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The $n$-step delayed sharing information structure is investigated. This\ninformation structure comprises of $K$ controllers that share their information\nwith a delay of $n$ time steps. This information structure is a link between\nthe classical information structure, where information is shared perfectly\nbetween the controllers, and a non-classical information structure, where there\nis no \"lateral\" sharing of information among the controllers. Structural\nresults for optimal control strategies for systems with such information\nstructures are presented. A sequential methodology for finding the optimal\nstrategies is also derived. The solution approach provides an insight for\nidentifying structural results and sequential decomposition for general\ndecentralized stochastic control problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.4172v1"
    },
    {
        "title": "Low-complexity Fusion Filtering for Continuous-Discrete Systems",
        "authors": [
            "Seokhyoung Lee",
            "Vladimir Shin"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper, low-complexity distributed fusion filtering algorithm for\nmixed continuous-discrete multisensory dynamic systems is proposed. To\nimplement the algorithm a new recursive equations for local cross-covariances\nare derived. To achieve an effective fusion filtering the covariance\nintersection (CI) algorithm is used. The CI algorithm is useful due to its\nlow-computational complexity for calculation of a big number of\ncross-covariances between local estimates and matrix weights. Theoretical and\nnumerical examples demonstrate the effectiveness of the covariance intersection\nalgorithm in distributed fusion filtering.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.4724v1"
    },
    {
        "title": "Nonlinear System Identification and Behavioral Modeling",
        "authors": [
            "Kazi Mohammed Saidul Huq",
            "Md. Taslim Arefin",
            "A. F. M. Sultanul Kabir"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper has been withdrawn by the author\n",
        "pdf_link": "http://arxiv.org/pdf/1002.4830v2"
    },
    {
        "title": "Processing of Communication Signal Using Operational Transconductance\n  Amplifier",
        "authors": [
            "A. Roy",
            "K. Ghosh",
            "S. Mondal",
            "B. N. Ray"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper proposes a signal processing methodology of communication system\nand realized that circuits using operational transconductance amplifier (OTA).\nTwo important classes of communication circuit, delta modulator and compander\nhave been designed using that procedure. In the first implementation coded\npulse modulation system is demonstrated which employ sampling, quantizing and\ncoding to convert analog waveforms to digital signals while the second gives\ndata compression and expansion in digital communication system. The proposed\ncompander circuit is realized with operational transconductance amplifier and\ndiode. Required power supply to operate the circuit is 3.5V. Performance of the\ncircuits realized with OTAs has been demonstrated through SPICE simulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.4837v1"
    },
    {
        "title": "Central Force Optimization Applied to the PBM Suite of Antenna\n  Benchmarks",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Central Force Optimization (CFO) is a new nature-inspired deterministic\nmulti-dimensional search and optimization metaheuristic based on the metaphor\nof gravitational kinematics. CFO is applied to the PBM antenna benchmark suite\nand the results compared to published performance data for other optimization\nalgorithms. CFO acquits itself quite well. CFO's gradient-like nature is\ndiscussed, and it is speculated that a \"generalized hyperspace derivative\"\nmight be defined for optimization problems as a new mathematical construct\nbased on the Unit Step function. What appears to be a sufficient but not\nnecessary condition for local trapping, oscillation in the probe average\ndistance curve, is discussed in the context of the theory of gravitational\n\"resonant returns\" that gives rise to strikingly similar oscillatory curves. It\nis suggested that the theory may be applicable to CFO as an aid to\nunderstanding trapping and to developing effective mitigation techniques,\npossibly based on a concept of \"energy\" in CFO space. It also is suggested that\nCFO may be re-formulated as a \"total energy\" model by analogizing conservation\nof energy for orbiting masses in physical space.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.0221v1"
    },
    {
        "title": "Flexible Lyapunov Functions and Applications to Fast Mechatronic Systems",
        "authors": [
            "M. Lazar"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The property that every control system should posses is stability, which\ntranslates into safety in real-life applications. A central tool in systems\ntheory for synthesizing control laws that achieve stability are control\nLyapunov functions (CLFs). Classically, a CLF enforces that the resulting\nclosed-loop state trajectory is contained within a cone with a fixed,\npredefined shape, and which is centered at and converges to a desired\nconverging point. However, such a requirement often proves to be\noverconservative, which is why most of the real-time controllers do not have a\nstability guarantee. Recently, a novel idea that improves the design of CLFs in\nterms of flexibility was proposed. The focus of this new approach is on the\ndesign of optimization problems that allow certain parameters that define a\ncone associated with a standard CLF to be decision variables. In this way\nnon-monotonicity of the CLF is explicitly linked with a decision variable that\ncan be optimized on-line. Conservativeness is significantly reduced compared to\nclassical CLFs, which makes \\emph{flexible CLFs} more suitable for\nstabilization of constrained discrete-time nonlinear systems and real-time\ncontrol. The purpose of this overview is to highlight the potential of flexible\nCLFs for real-time control of fast mechatronic systems, with sampling periods\nbelow one millisecond, which are widely employed in aerospace and automotive\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.0634v1"
    },
    {
        "title": "Parameter-Free Deterministic Global Search with Central Force\n  Optimization",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This note describes a parameter-free implementation of Central Force\nOptimization for deterministic multidimensional search and optimization. The\nuser supplies only one input: the objective function to be maximized, nothing\nmore. The CFO equations of motion are simplified by assigning specific values\nto CFO's basic parameters, and this particular algorithmic implementation also\nincludes hardwired internal parameters so that none is user-specified. The\nalgorithm's performance is tested against a widely used suite of twenty three\nbenchmark functions and compared to other state-of-the-art algorithms. CFO\nperforms very well indeed. Includes important update 20 March 2010 addressing\nthe issue of different probes coalescing into one.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1039v2"
    },
    {
        "title": "New clustering method to decrease probability of failure nodes and\n  increasing the lifetime in WSNs",
        "authors": [
            "Shahram Babaie",
            "Ahmad Khadem Zade",
            "Ali Hosseinalipour"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Clustering in wireless sensor networks is one of the crucial methods for\nincreasing of network lifetime. There are many algorithms for clustering. One\nof the important cluster based algorithm in wireless sensor networks is LEACH\nalgorithm. In this paper we proposed a new clustering method for increasing of\nnetwork lifetime. We distribute several sensors with a high-energy for managing\nthe cluster head and to decrease their responsibilities in network. The\nperformance of the proposed algorithm via computer simulation was evaluated and\ncompared with other clustering algorithms. The simulation results show the high\nperformance of the proposed clustering algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1472v1"
    },
    {
        "title": "Current Conveyor Based Multifunction Filter",
        "authors": [
            "Manish Kumar",
            "M. C. Srivastava",
            "Umesh Kumar"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The paper presents a current conveyor based multifunction filter. The\nproposed circuit can be realized as low pass, high pass, band pass and\nelliptical notch filter. The circuit employs two balanced output current\nconveyors, four resistors and two grounded capacitors, ideal for integration.\nIt has only one output terminal and the number of input terminals may be used.\nFurther, there is no requirement for component matching in the circuit. The\nparameter resonance frequency (\\omega_0) and bandwidth (\\omega_0 /Q) enjoy\northogonal tuning. The complementary metal oxide semiconductor (CMOS)\nrealization of the current conveyor is given for the simulation of the proposed\ncircuit. A HSPICE simulation of circuit is also studied for the verification of\ntheoretical results. The non-ideal analysis of CCII is also studied.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1491v1"
    },
    {
        "title": "Creating A Model HTTP Server Program Using java",
        "authors": [
            "Bala Dhandayuthapani Veerasamy"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  HTTP Server is a computer programs that serves webpage content to clients. A\nwebpage is a document or resource of information that is suitable for the World\nWide Web and can be accessed through a web browser and displayed on a computer\nscreen. This information is usually in HTML format, and may provide navigation\nto other webpage's via hypertext links. WebPages may be retrieved from a local\ncomputer or from a remote HTTP Server. WebPages are requested and served from\nHTTP Servers using Hypertext Transfer Protocol (HTTP). WebPages may consist of\nfiles of static or dynamic text stored within the HTTP Server's file system.\nClient-side scripting can make WebPages more responsive to user input once in\nthe client browser. This paper encompasses the creation of HTTP server program\nusing java language, which is basically supporting for HTML and JavaScript.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1497v1"
    },
    {
        "title": "QoS Based Dynamic Web Services Composition & Execution",
        "authors": [
            "Farhan Hassan Khan",
            "Saba Bashir",
            "M. Younus Javed",
            "Aihab Khan",
            "Malik Sikandar Hayat Khiyal"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The use of web services has dominated software industry. Existing\ntechnologies of web services are extended to give value added customized\nservices to customers through composition. Automated web service composition is\na very challenging task. This paper proposed the solution of existing problems\nand proposed a technique by combination of interface based and functionality\nbased rules. The proposed framework also solves the issues related to\nunavailability of updated information and inaccessibility of web services from\nrepository/databases due to any fault/failure. It provides updated information\nproblem by adding aging factor in repository/WSDB (Web Services Database) and\ninaccessibility is solved by replication of WSDB. We discussed data\ndistribution techniques and proposed our framework by using one of these\nstrategies by considering quality of service issues. Finally, our algorithm\neliminates the dynamic service composition and execution issues, supports web\nservice composition considering QoS (Quality of Service), efficient data\nretrieval and updation, fast service distribution and fault tolerance.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1502v1"
    },
    {
        "title": "Knowledge Management",
        "authors": [
            "Mohsen Gerami"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper discusses the important process of knowledge and its management,\nand differences between tacit and explicit knowledge and understanding the\nculture as a key issue for the successful implementation of knowledge\nmanagement, in addition to, this paper is concerned with the four-stage model\nfor the evolution of information technology (IT) support for knowledge\nmanagement in law firms.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1807v1"
    },
    {
        "title": "Wireless IP Telephony",
        "authors": [
            "Mohsen Gerami"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The convergence of traditional telecommunications and the Internet is\ncreating new network-based service delivery opportunities for\ntelecommunications companies carriers, service providers, and network equipment\nproviders. Voice over Wireless IP is one of the most exciting new developments\nemerging within the telephony market. It is set to revolutionize the delivery\nof mobile voice Services and provide exciting new opportunities for operators\nand service providers alike. This survey discusses principal of Wireless IP\nTelephony.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1809v1"
    },
    {
        "title": "Model Based Ceramic tile inspection using Discrete Wavelet Transform and\n  Euclidean Distance",
        "authors": [
            "Samir Elmougy",
            "Ibrahim El-Henawy",
            "Ahmed El-Azab"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Visual inspection of industrial products is used to determine the control\nquality for these products. This paper deals with the problem of visual\ninspection of ceramic tiles industry using Wavelet Transform. The third level\nthe coefficients of two dimensions Haar Discrete Wavelet Transform (HDWT) is\nused in this paper to process the images and feature extraction. The proposed\nalgorithm consists of two main phases. The first phase is to compute the\nwavelet transform for an image free of defects which known as reference image,\nand the image to be inspected which known as test image. The second phase is\nused to decide whether the tested image is defected or not using the Euclidean\ndistance similarity measure. The experimentation results of the proposed\nalgorithm give 97% for correct detection of ceramic defects.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1811v1"
    },
    {
        "title": "FP-tree and COFI Based Approach for Mining of Multiple Level Association\n  Rules in Large Databases",
        "authors": [
            "Virendra Kumar Shrivastava",
            "Parveen Kumar",
            "K. R. Pardasani"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In recent years, discovery of association rules among itemsets in a large\ndatabase has been described as an important database-mining problem. The\nproblem of discovering association rules has received considerable research\nattention and several algorithms for mining frequent itemsets have been\ndeveloped. Many algorithms have been proposed to discover rules at single\nconcept level. However, mining association rules at multiple concept levels may\nlead to the discovery of more specific and concrete knowledge from data. The\ndiscovery of multiple level association rules is very much useful in many\napplications. In most of the studies for multiple level association rule\nmining, the database is scanned repeatedly which affects the efficiency of\nmining process. In this research paper, a new method for discovering multilevel\nassociation rules is proposed. It is based on FP-tree structure and uses\ncooccurrence frequent item tree to find frequent items in multilevel concept\nhierarchy.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1821v1"
    },
    {
        "title": "Dual-hop transmissions with fixed-gain relays over Generalized-Gamma\n  fading channels",
        "authors": [
            "K. P. Peppas",
            "A. Mansour",
            "G. S. Tombras"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper, a study on the end-to-end performance of dual-hop wireless\ncommunication systems equipped with fixed-gain relays and operating over\nGeneralized-Gamma (GG) fading channels is presented. A novel closed form\nexpression for the moments of the end-to-end signal-to-noise ratio (SNR) is\nderived. The average bit error probability for coherent and non-coherent\nmodulation schemes as well as the end-to-end outage probability of the\nconsidered system are also studied. Extensive numerically evaluated and\ncomputer simulations results are presented that verify the accuracy of the\nproposed mathematical analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1910v1"
    },
    {
        "title": "Simulating Grover's Quantum Search in a Classical Computer",
        "authors": [
            "D. K. Ningtyas",
            "A. B. Mutiara"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The rapid progress of computer science has been accompanied by a\ncorresponding evolution of computation, from classical computation to quantum\ncomputation. As quantum computing is on its way to becoming an established\ndiscipline of computing science, much effort is being put into the development\nof new quantum algorithms. One of quantum algorithms is Grover algorithm, which\nis used for searching an element in an unstructured list of N elements with\nquadratic speed-up over classical algorithms. In this work, Quantum Computer\nLanguage (QCL) is used to make a Grover's quantum search simulation in a\nclassical computer\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1930v1"
    },
    {
        "title": "Automated selection of LEDs by luminance and chromaticity coordinate",
        "authors": [
            "Ulrich H. P. Fischer",
            "Jens-Uwe Just",
            "Christian Reinboth"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The increased use of LEDs for lighting purposes has led to the development of\nnumerous applications requiring a pre-selection of LEDs by their luminance and\n/ or their chromaticity coordinate. This paper demonstrates how a manual\npre-selection process can be realized using a relatively simple configuration.\nSince a manual selection service can only be commercially viable as long as\nonly small quantities of LEDs need to be sorted, an automated solution suggests\nitself. This paper introduces such a solution, which has been developed by\nHarzoptics in close cooperation with Rundfunk Gernrode. The paper also\ndiscusses current challenges in measurement technology as well as market\ntrends.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.2255v1"
    },
    {
        "title": "Scalable, Time-Responsive, Digital, Energy-Efficient Molecular Circuits\n  using DNA Strand Displacement",
        "authors": [
            "Ehsan Chiniforooshan",
            "David Doty",
            "Lila Kari",
            "Shinnosuke Seki"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  We propose a novel theoretical biomolecular design to implement any Boolean\ncircuit using the mechanism of DNA strand displacement. The design is scalable:\nall species of DNA strands can in principle be mixed and prepared in a single\ntest tube, rather than requiring separate purification of each species, which\nis a barrier to large-scale synthesis. The design is time-responsive: the\nconcentration of output species changes in response to the concentration of\ninput species, so that time-varying inputs may be continuously processed. The\ndesign is digital: Boolean values of wires in the circuit are represented as\nhigh or low concentrations of certain species, and we show how to construct a\nsingle-input, single-output signal restoration gate that amplifies the\ndifference between high and low, which can be distributed to each wire in the\ncircuit to overcome signal degradation. This means we can achieve a digital\nabstraction of the analog values of concentrations. Finally, the design is\nenergy-efficient: if input species are specified ideally (meaning absolutely 0\nconcentration of unwanted species), then output species converge to their ideal\nconcentrations at steady-state, and the system at steady-state is in (dynamic)\nequilibrium, meaning that no energy is consumed by irreversible reactions until\nthe input again changes.\n  Drawbacks of our design include the following. If input is provided\nnon-ideally (small positive concentration of unwanted species), then energy\nmust be continually expended to maintain correct output concentrations even at\nsteady-state. In addition, our fuel species - those species that are\npermanently consumed in irreversible reactions - are not \"generic\"; each gate\nin the circuit is powered by its own specific type of fuel species. Hence\ndifferent circuits must be powered by different types of fuel. Finally, we\nrequire input to be given according to the dual-rail convention, so that an\ninput of 0 is specified not only by the absence of a certain species, but by\nthe presence of another. That is, we do not construct a \"true NOT gate\" that\nsets its output to high concentration if and only if its input's concentration\nis low. It remains an open problem to design scalable, time-responsive,\ndigital, energy-efficient molecular circuits that additionally solve one of\nthese problems, or to prove that some subset of their resolutions are mutually\nincompatible.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.3275v2"
    },
    {
        "title": "Design of A Low Power Low Voltage CMOS Opamp",
        "authors": [
            "Ratul Kr. Baruah"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper a CMOS operational amplifier is presented which operates at 2V\npower supply and 1microA input bias current at 0.8 micron technology using non\nconventional mode of operation of MOS transistors and whose input is depended\non bias current. The unique behaviour of the MOS transistors in subthreshold\nregion not only allows a designer to work at low input bias current but also at\nlow voltage. While operating the device at weak inversion results low power\ndissipation but dynamic range is degraded. Optimum balance between power\ndissipation and dynamic range results when the MOS transistors are operated at\nmoderate inversion. Power is again minimised by the application of input\ndependant bias current using feedback loops in the input transistors of the\ndifferential pair with two current substractors. In comparison with the\nreported low power low voltage opamps at 0.8 micron technology, this opamp has\nvery low standby power consumption with a high driving capability and operates\nat low voltage. The opamp is fairly small (0.0084 mm 2) and slew rate is more\nthan other low power low voltage opamps reported at 0.8 um technology [1,2].\nVittoz at al [3] reported that slew rate can be improved by adaptive biasing\ntechnique and power dissipation can be reduced by operating the device in weak\ninversion. Though lower power dissipation is achieved the area required by the\ncircuit is very large and speed is too small. So, operating the device in\nmoderate inversion is a good solution. Also operating the device in\nsubthreshold region not only allows lower power dissipation but also a lower\nvoltage operation is achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.5439v1"
    },
    {
        "title": "Arithmetic Operations in Multi-Valued Logic",
        "authors": [
            "Vasundara Patel",
            "K. S. Gurumurthy"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper presents arithmetic operations like addition, subtraction and\nmultiplications in Modulo-4 arithmetic, and also addition, multiplication in\nGalois field, using multi-valued logic (MVL). Quaternary to binary and binary\nto quaternary converters are designed using down literal circuits. Negation in\nmodular arithmetic is designed with only one gate. Logic design of each\noperation is achieved by reducing the terms using Karnaugh diagrams, keeping\nminimum number of gates and depth of net in to consideration. Quaternary\nmultiplier circuit is proposed to achieve required optimization. Simulation\nresult of each operation is shown separately using Hspice.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.5442v1"
    },
    {
        "title": "Bit Error Rate Performance Analysis on Modulation Techniques of Wideband\n  Code Division Multiple Access",
        "authors": [
            "M. A. Masud",
            "M. Samsuzzaman",
            "M. A. Rahman"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In the beginning of 21st century there has been a dramatic shift in the\nmarket dynamics of telecommunication services. The transmission from base\nstation to mobile or downlink transmission using M-ary Quadrature Amplitude\nmodulation (QAM) and Quadrature phase shift keying (QPSK) modulation schemes\nare considered in Wideband-Code Division Multiple Access (W-CDMA) system. We\nhave done the performance analysis of these modulation techniques when the\nsystem is subjected to Additive White Gaussian Noise (AWGN) and multipath\nRayleigh fading are considered in the channel. The research has been performed\nby using MATLAB 7.6 for simulation and evaluation of Bit Error Rate (BER) and\nSignal-To-Noise Ratio (SNR) for W-CDMA system models. It is shows that the\nanalysis of Quadrature phases shift key and 16-ary Quadrature Amplitude\nmodulations which are being used in wideband code division multiple access\nsystem, Therefore, the system could go for more suitable modulation technique\nto suit the channel quality, thus we can deliver the optimum and efficient data\nrate to mobile terminal.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.5629v1"
    },
    {
        "title": "A Mobile Message Scheduling and Delivery System using m-Learning\n  framework",
        "authors": [
            "Moumita Majumder",
            "Sumit Dhar"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Wireless data communications in form of Short Message Service (SMS) and\nWireless Access Protocols (WAP) browsers have gained global popularity, yet,\nnot much has been done to extend the usage of these devices in electronic\nlearning (e-learning) and information sharing. This project explores the\nextension of e learning into wireless/ handheld (W/H) computing devices with\nthe help of a mobile learning (m-learning) framework. This framework provides\nthe requirements to develop m-learning application that can be used to share\nacademic and administrative information among people within the university\ncampus. A prototype application has been developed to demonstrate the important\nfunctionality of the proposed system in simulated environment. This system is\nsupposed to work both in bulk SMS and interactive SMS delivery mode. Here we\nhave combined both Short Message Service (SMS) and Wireless Access Protocols\n(WAP) browsers. SMS is used for Short and in time information delivery and WAP\nis used for detailed information delivery like course content, training\nmaterial, interactive evolution tests etc. The push model is used for sending\npersonalized multicasting messages to a group of mobile users with a common\nprofile thereby improving the effectiveness and usefulness of the cntent\ndelivered. Again pull mechanism can be applied for sending information as SMS\nwhen requested by end user in interactive SMS delivery mode. The main strength\nof the system is that, the actual SMS delivery application can be hosted on a\nmobile device, which can operate even when the device is on move.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.5631v1"
    },
    {
        "title": "Performance Analysis of Best suited Adaptive Equalization Algorithm for\n  Optical Communication",
        "authors": [
            "Tarek Hasan-Al-Mahmud",
            "M. Mahbubur Rahman",
            "Sumon Kumar Debnath"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Fiber optics is one of the highest bandwidth communication channel types in\nthe current communication industry. The paper is to analyze a typical optical\nchannel and perform channel equalization using an adaptive modified DFE with\nActivity Detection Guidance and Tap Decoupling algorithm. Evaluation can be\nmade on the employment of the DFE algorithm and with enhancements, like\nFractionally-Spaced equalization and Activity Detection Guidance, to improve\nits stability, steady-state error performance and convergence rate. The\nsuccessful implementation of the Adaptive FS-DFE with ADG and TD technique\noffers an excellent alternative to linear equalization, which is known to be of\nlittle benefit for optical channels because of exorbitant noise enhancement.\nThe FSE technique, when combined with the DFE, would offer improved\neffectiveness to amplitude distortion. As the impulse response of a typical\noptical link would have regions that are essentially zero, the employment of\nthe activity detection scheme with Tap Decoupling would further enhance the\nsteady-state error performance and convergence rate.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.5633v1"
    },
    {
        "title": "Web-Based Learning and Training for Virtual Metrology Lab",
        "authors": [
            "Fahad Al-Zahrani"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The use of World Web Wide for distance education has received increasing\nattention over the past decades. The real challenge of adapting this technology\nfor engineering education and training is to facilitate the laboratory\nexperiments via Internet. In the sciences, measurement plays an important role.\nThe accuracy of the measurement, as well as the units, help scientists to\nbetter understand phenomena occurring in nature. This paper introduces\nMetrology educators to the use and adoption of Java-applets in order to create\nvirtual, online Metrology laboratories for students. These techniques have been\nused to successfully form a laboratory course which augments the more\nconventional lectures in concepts of Metrology course at Faculty of\nEngineering, Albaha University, KSA. Improvements of the package are still\nundergoing to incorporate Web-based technologies (Internet home page, HTML,\nJava programming etc...). This Web-based education and training has been\nsuccessfully class-tested within an undergraduate preliminary year engineering\ncourse and students reported a positive experience with its use. The use of\nthese labs should be self-explanatory and their reliable operation has been\nthoroughly tested.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.5635v1"
    },
    {
        "title": "Variable Threshold MOSFET Approach (Through Dynamic Threshold MOSFET)\n  For Universal Logic Gates",
        "authors": [
            "K. Ragini",
            "M. Satyam",
            "B. C. Jinaga"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this article, we proposed a Variable threshold MOSFET(VTMOS)approach which\nis realized from Dynamic Threshold MOSFET(DTMOS), suitable for sub-threshold\ndigital circuit operation. Basically the principle of sub- threshold logics is\noperating MOSFET in sub-threshold region and using the leakage current in that\nregion for switching action, there by drastically decreasing power. To reduce\nthe power consumption of sub-threshold circuits further, a novel body biasing\ntechnique termed VTMOS is introduced .VTMOS approach is realized from DTMOS\napproach. Dynamic threshold MOS (DTMOS) circuits provide low leakage and high\ncurrent drive, compared to CMOS circuits, operated at lower voltages. The VTMOS\nis based on operating the MOS devices with an appropriate substrate bias which\nvaries with gate voltage, by connecting a positive bias voltage between gate\nand substrate for NMOS and negative bias voltage between gate and substrate for\nPMOS. With VTMOS, there is a considerable reduction in operating current and\npower dissipation, while the remaining characteristics are almost the same as\nthose of DTMOS. Results of our investigations show that VTMOS circuits improves\nthe power up to 50% when compared to CMOS and DTMOS circuits, in sub- threshold\nregion.. The performance analysis and comparison of VTMOS, DTMOS and CMOS is\nmade and test results of Power dissipation, Propagation delay and Power delay\nproduct are presented to justify the superiority of VTMOS logic over\nconventional sub-threshold logics using Hspice Tool. The dependency of these\nparameters on frequency of operation has also been investigated.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.6030v1"
    },
    {
        "title": "Effect of Weighting Scheme to QoS Properties in Web Service Discovery",
        "authors": [
            "Agushaka J. O.",
            "Lawal M. M.",
            " Bagiwa",
            "A. M.",
            "Abdullahi B. F"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Specifying QoS properties can limit the selection of some good web services\nthat the user will have considered; this is because the algorithm used strictly\nensures that there is a match between QoS properties of the consumer with that\nof the available services. This is to say that, a situation may arise that some\nservices might not have all that the user specifies but are rated high in those\nthey have. With some tradeoffs specified in form of weight, these services will\nbe made available to the user for consideration. This assertion is from the\nfact that, the user's requirements for the specified QoS properties are of\nvarying degree i.e. he will always prefer one ahead of the other. This can be\ncaptured in form of weight i.e. the one preferred most will have the highest\nweight. If a consumer specifies light weight for those QoS properties that a\nweb service is deficient in and high weight for those it has, this will\nminimize the difference between them. Hence the service can be returned.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.1673v1"
    },
    {
        "title": "An Improved Fixed Switching Frequency Direct Torque Control of Induction\n  Motor Drives Fed by Direct Matrix Converter",
        "authors": [
            "Nabil Taib",
            "Toufik Rekioua",
            "Bruno Francois"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  A few papers have been interested by the fixed switching frequency direct\ntorque control fed by direct matrix converters, where we can find just the use\nof direct torque controlled space vector modulated method. In this present\npaper, we present an improved method used for a fixed switching frequency\ndirect torque control (DTC) using a direct matrix converter (DMC). This method\nis characterized by a simple structure, a fixed switching frequency which\ncauses minimal torque ripple and a unity input power factor. Using this\nstrategy, we combine the direct matrix converters advantages with those of\ndirect torque control (DTC) schemes. The used technique for constant frequency\nis combined with the input current space vector to create the switching table\nof direct matrix converter (DMC). Simulation results clearly demonstrate a\nbetter dynamic and steady state performances of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.1745v1"
    },
    {
        "title": "Predictive Gain Estimation - A mathematical analysis",
        "authors": [
            "P. Chakrabarti"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In case of realization of successful business, gain analysis is essential. In\nthis paper we have cited some new techniques of gain expectation on the basis\nof neural property of perceptron. Support rule and Sequence mining based\nartificial intelligence oriented practices have also been done in this context.\nIn the view of above fuzzy and statistical based gain sensing is also pointed\nout.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.1983v1"
    },
    {
        "title": "Kinematic modelling of a 3-axis NC machine tool in linear and circular\n  interpolation",
        "authors": [
            "Xavier Pessoles",
            "Yann Landon",
            "Walter Rubio"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Machining time is a major performance criterion when it comes to high-speed\nmachining. CAM software can help in estimating that time for a given strategy.\nBut in practice, CAM-programmed feed rates are rarely achieved, especially\nwhere complex surface finishing is concerned. This means that machining time\nforecasts are often more than one step removed from reality. The reason behind\nthis is that CAM routines do not take either the dynamic performances of the\nmachines or their specific machining tolerances into account. The present\narticle seeks to improve simulation of high-speed NC machine dynamic behaviour\nand machining time prediction, offering two models. The first contributes\nthrough enhanced simulation of three-axis paths in linear and circular\ninterpolation, taking high-speed machine accelerations and jerks into account.\nThe second model allows transition passages between blocks to be integrated in\nthe simulation by adding in a polynomial transition path that caters for the\ntrue machining environment tolerances. Models are based on respect for path\nmonitoring. Experimental validation shows the contribution of polynomial\nmodelling of the transition passage due to the absence of a leap in\nacceleration. Simulation error on the machining time prediction remains below\n1%.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.2354v1"
    },
    {
        "title": "A Computational Algorithm for Metrical Classification of Verse",
        "authors": [
            "N. Rama",
            "Meenakshi Lakshmanan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The science of versification and analysis of verse in Sanskrit is governed by\nrules of metre or chandas. Such metre-wise classification of verses has\nnumerous uses for scholars and researchers alike, such as in the study of poets\nand their style of Sanskrit poetical works. This paper presents a comprehensive\ncomputational scheme and set of algorithms to identify the metre of verses\ngiven as Sanskrit (Unicode) or English E-text (Latin Unicode). The paper also\ndemonstrates the use of euphonic conjunction rules to correct verses in which\nthese conjunctions, which are compulsory in verse, have erroneously not been\nimplemented.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3262v3"
    },
    {
        "title": "Modelling of Human Glottis in VLSI for Low Power Architectures",
        "authors": [
            "Nikhil Raj",
            "R. K. Sharma"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The Glottal Source is an important component of voice as it can be considered\nas the excitation signal to the voice apparatus. Nowadays, new techniques of\nspeech processing such as speech recognition and speech synthesis use the\nglottal closure and opening instants. Current models of the glottal waves\nderive their shape from approximate information rather than from exactly\nmeasured data. General method concentrate on assessment of the glottis opening\nusing optical, acoustical methods, or on visualization of the larynx position\nusing ultrasound, computer tomography or magnetic resonance imaging techniques.\nIn this work, circuit model of Human Glottis using MOS is designed by\nexploiting fluid volume velocity to current, fluid pressure to voltage, and\nlinear and nonlinear mechanical impedances to linear and nonlinear electrical\nimpedances. The glottis modeled as current source includes linear, non-linear\nimpedances to represent laminar and turbulent flow respectively, in vocal\ntract. The MOS modelling and simulation results of glottal circuit has been\ncarried out on BSIM 3v3 model in TSMC 0.18 micrometer technology using ELDO\nsimulator.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3265v1"
    },
    {
        "title": "Adaptive Neuro-Fuzzy Extended Kalman Filtering for Robot Localization",
        "authors": [
            "Ramazan Havangi",
            "Mohammad Ali Nekoui",
            "Mohammad Teshnehlab"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Extended Kalman Filter (EKF) has been a popular approach to localization a\nmobile robot. However, the performance of the EKF and the quality of the\nestimation depends on the correct a priori knowledge of process and measurement\nnoise covariance matrices (Qk and Rk, respectively). Imprecise knowledge of\nthese statistics can cause significant degradation in performance. This paper\nproposed the development of an Adaptive Neuro- Fuzzy Extended Kalman Filtering\n(ANFEKF) for localization of robot. The Adaptive Neuro-Fuzzy attempts to\nestimate the elements of Qk and Rk matrices of the EKF algorithm, at each\nsampling instant when measurement update step is carried out. The ANFIS\nsupervises the performance of the EKF with the aim of reducing the mismatch\nbetween the theoretical and actual covariance of the innovation sequences. The\nfree parameters of ANFIS are trained using the steepest gradient descent (SD)\nto minimize the differences of the actual value of the covariance of the\nresidual with its theoretical value as much possible. The simulation results\nshow the effectiveness of the proposed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3267v1"
    },
    {
        "title": "A General Simulation Framework for Supply Chain Modeling: State of the\n  Art and Case Study",
        "authors": [
            "Antonio Cimino",
            "Francesco Longo",
            "Giovanni Mirabelli"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Nowadays there is a large availability of discrete event simulation software\nthat can be easily used in different domains: from industry to supply chain,\nfrom healthcare to business management, from training to complex systems\ndesign. Simulation engines of commercial discrete event simulation software use\nspecific rules and logics for simulation time and events management.\nDifficulties and limitations come up when commercial discrete event simulation\nsoftware are used for modeling complex real world-systems (i.e. supply chains,\nindustrial plants). The objective of this paper is twofold: first a state of\nthe art on commercial discrete event simulation software and an overview on\ndiscrete event simulation models development by using general purpose\nprogramming languages are presented; then a Supply Chain Order Performance\nSimulator (SCOPS, developed in C++) for investigating the inventory management\nproblem along the supply chain under different supply chain scenarios is\nproposed to readers.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3271v1"
    },
    {
        "title": "Propose a Fuzzy Queuing Maximal Benefit Location Problem",
        "authors": [
            "Reza Rabieyan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper presents a fuzzy queuing location model for congested system. In a\nqueuing system there are different criteria that are not constant such as\nservice rate, service rate demand, queue length, the occupancy probability of a\nservice center and Probability of joining the queue line. In this paper with\nfuzzifying all of these variables, will try to reach an accurate real problem.\nFinally we change the problem to a single objective function and as far as this\nmodel is in NP-Hard classification we will use genetic algorithm for solving it\nand ant colony for comparison is used for their results and run time.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.3534v1"
    },
    {
        "title": "An approximate analytical (structural) superposition in terms of two, or\n  more, \"alfa\"-circuits of the same topology: Pt.1 - description of the\n  superposition",
        "authors": [
            "Emanuel Gluskin"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  One-ports named \"f-circuits\", composed of similar conductors described by a\nmonotonic polynomial, or quasi-polynomial (i.e. with positive but not\nnecessarily integer, powers) characteristic i = f(v) are studied, focusing on\nthe algebraic map f --> F. Here F(.) is the input conductivity characteristic;\ni.e., iin = F(vin) is the input current. The \"power-law\" \"alfa-circuit\"\nintroduced in [1], for which f(v) ~ v^\"alfa\", is an important particular case.\nBy means of a generalization of a parallel connection, the f-circuits are\nconstructed from the alfa-circuits of the same topology, with different \"alfa\",\nso that the given topology is kept, and 'f' is an additive function of the\nconnection. We observe and consider an associated, generally approximated, but,\nin all of the cases studied, always high-precision, specific superposition.\nThis superposition is in terms of f --> F, and it means that F(.) of the\nconnection is close to the sum of the input currents of the independent\n\"alfa\"-circuits, all connected in parallel to the same source. In other words,\nF(.) is well approximated by a linear combination of the same degrees of the\nindependent variable as in f(.), i.e. the map of the characteristics f --> F is\nclose to a linear one. This unexpected result is useful for understanding\nnonlinear algebraic circuits, and is missed in the classical theory.\n  The cases of f(v) = D1v + D2v^2 and f(v) = D1v + D3v^3, are analyzed in\nexamples. Special topologies when the superposition must be ideal, are also\nconsidered. In the second part [2] of the work the \"circuit mechanism\" that is\nresponsible for the high precision of the superposition, in the most general\ncase, will be explained.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4128v2"
    },
    {
        "title": "Intelligent Technologies in Model Base Management System Design\n  Automation",
        "authors": [
            "Irina Semenova"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The article describes the prospects of model base management system design\nautomation for decision support systems and suggests the toolbox scheme for\ndesign automation based on intelligent technologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4275v1"
    },
    {
        "title": "An approximate analytical (structural) superposition in terms of two, or\n  more, \"alfa\"-circuits of the same topology: Pt. 2 - the \"internal circuit\n  mechanism\"",
        "authors": [
            "Emanuel Gluskin"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This is the second part, after [1], of the research devoted to analysis of\n1-ports composed of similar conductors (\"f-circuits\") described by the\ncharacteristic i = f(v) of a polynomial type. This analysis is performed by\nmeans of the power-law \"alfa\"-circuits\" introduced in [2], for which f(v) ~\nv^\"alfa\". The f-circuits are constructed from the \"alfa\"-circuits of the same\ntopology, with the proper \"alfa\", so that the given topology is kept, and 'f'\nis an additive function of the connection. Explaining the situation described\nin detail in [1], we note and analyze a simple \"circuit mechanism\" that causes\nthe difference between the input current of the f-circuit and the sum of the\ninput currents of the f-circuits before the composition to be relatively small.\nThe case of two degrees, f(v) = Dmv^m + Dnv^n, m unequal n, is treated in the\nmain proofs. Some simulations are presented, and some boundaries for the error\nof the superposition are found. The cases of f(.) being a polynomial of the\nthird or fourth degrees are finally briefly considered.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4428v2"
    },
    {
        "title": "Plagiarism Detection Using Graph-Based Representation",
        "authors": [
            "Ahmed Hamza Osman",
            "Naomie Salim",
            "Mohammed Salem Binwahlan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Plagiarism of material from the Internet is a widespread and growing problem.\nSeveral methods used to detect the plagiarism and similarity between the source\ndocument and suspected documents such as fingerprint based on character or\nn-gram. In this paper, we discussed a new method to detect the plagiarism based\non graph representation; however, Preprocessing for each document is required\nsuch as breaking down the document into its constituent sentences. Segmentation\nof each sentence into separated terms and stop word removal. We build the graph\nby grouping each sentence terms in one node, the resulted nodes are connected\nto each other based on order of sentence within the document, all nodes in\ngraph are also connected to top level node \"Topic Signature\". Topic signature\nnode is formed by extracting the concepts of each sentence terms and grouping\nthem in such node. The main advantage of the proposed method is the topic\nsignature which is main entry for the graph is used as quick guide to the\nrelevant nodes. which should be considered for the comparison between source\ndocuments and suspected one. We believe the proposed method can achieve a good\nperformance in terms of effectiveness and efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4449v1"
    },
    {
        "title": "Crosstalk Noise Modeling for RC and RLC interconnects in Deep Submicron\n  VLSI Circuits",
        "authors": [
            "P. V. Hunagund",
            "A. B. Kalpana"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The crosstalk noise model for noise constrained interconnects optimization is\npresented for RC interconnects. The proposed model has simple closed-form\nexpressions, which is capable of predicting the noise amplitude and the noise\npulse width of an RC interconnect as well as coupling locations (near-driver\nand near-receiver) on victim net. This paper also presents a crosstalk noise\nmodel for both identical and non identical coupled\nresistance-inductance-capacitance (RLC) interconnects, which is developed based\non a decoupling technique exhibiting an average error of 6.8% as compared to\nSPICE. The crosstalk noise model, together with a proposed concept of effective\nmutual inductance, is applied to evaluate the effectiveness of the shielding\ntechnique.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4458v1"
    },
    {
        "title": "Prediction of Retained Capacity and EODV of Li-ion Batteries in LEO\n  Spacecraft Batteries",
        "authors": [
            "S. Ramakrishnan",
            "S. Venugopalan",
            "A. Ebenezer Jeyakumar"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In resent years ANN is widely reported for modeling in different areas of\nscience including electro chemistry. This includes modeling of different\ntechnological batteries such as lead acid battery, Nickel cadmium batteries\netc. Lithium ion batteries are advance battery technology which satisfy most of\nthe space mission requirements. Low earth orbit (LEO)space craft batteries\nundergo large number of charge discharge cycles (about 25000 cycles)compared to\nother ground level or space applications. This study is indented to develop ANN\nmodel for about 25000 cycles, cycled under various temperature, Depth Of\nDischarge (DOD) settings with constant charge voltage limit to predict the\nretained capacity and End of Discharge Voltage (EODV). To extract firm\nconclusion and distinguish the capability of ANN method, the predicted values\nare compared with experimental result by statistical method and Bland Altman\nplot.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4480v1"
    },
    {
        "title": "Modelling and Design of a Microstrip Band-Pass Filter Using Space\n  Mapping Techniques",
        "authors": [
            "Saeed Tavakoli",
            "Mahdieh Zeinadini",
            "Shahram Mohanna"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Determination of design parameters based on electromagnetic simulations of\nmicrowave circuits is an iterative and often time-consuming procedure. Space\nmapping is a powerful technique to optimize such complex models by efficiently\nsubstituting accurate but expensive electromagnetic models, fine models, with\nfast and approximate models, coarse models. In this paper, we apply two space\nmapping, an explicit space mapping as well as an implicit and response residual\nspace mapping, techniques to a case study application, a microstrip band-pass\nfilter. First, we model the case study application and optimize its design\nparameters, using explicit space mapping modelling approach. Then, we use\nimplicit and response residual space mapping approach to optimize the filter's\ndesign parameters. Finally, the performance of each design methods is\nevaluated. It is shown that the use of above-mentioned techniques leads to\nachieving satisfactory design solutions with a minimum number of\ncomputationally expensive fine model evaluations.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4594v1"
    },
    {
        "title": "Clustering of Content Supporting Computer Mediated Courseware\n  Development",
        "authors": [
            "G. M. M. Bashir",
            "M. J. Hossain",
            "M. R. Karim"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Computer Mediated Courseware (CMC) has been developed so far for individual\ncourses considering single or multiple text books. A group of courseware can be\ndeveloped by using multiple text books and in this case, it is a requirement to\ncluster the contents of different books to form a generalized clustered\ncontent. No work has been found to develop courseware applying generalized\nclustered content. We have proposed a clustering of content supporting computer\nmediated courseware development based on data mining techniques to construct a\nhierarchical general structure of a group of courseware combining the\nindividual structure of a set of books. The clustering will help the courseware\ndeveloper to dynamically allocate contents to develop different courses using a\ngroup of books. The authors have applied this methodology for different level\nof courses on database. The methodology is generalized and can be applied to\nany other courses.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4595v1"
    },
    {
        "title": "Video shot boundary detection using motion activity descriptor",
        "authors": [
            "Abdelati Malek Amel",
            "Ben Abdelali Abdessalem",
            "Mtibaa Abdellatif"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper focus on the study of the motion activity descriptor for shot\nboundary detection in video sequences. We interest in the validation of this\ndescriptor in the aim of its real time implementation with reasonable high\nperformances in shot boundary detection. The motion activity information is\nextracted in uncompressed domain based on adaptive rood pattern search (ARPS)\nalgorithm. In this context, the motion activity descriptor was applied for\ndifferent video sequence.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4605v1"
    },
    {
        "title": "Evaluation of Burst Loss Rate of an Optical Burst Switching (OBS)\n  Network with Wavelength Conversion Capability",
        "authors": [
            "Md. Shamim Reza",
            "Md. Maruf Hossain",
            "Satya Prasad Majumder"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper presents a new analytical model for calculating burst loss rate\n(BLR) in a slotted optical burst switched network. The analytical result leads\nto a framework which provides guidelines for optical burst switched networks.\nWavelength converter is used for burst contention resolution. The effect of\nseveral design parameters such as burst arrival probability, wavelength\nconversion capability, number of slots per burst and number of wavelengths is\nincorporated on the above performance measure. We also extend the analytical\nresult of BLR for different types of service classes where each service class\nhas a reserved number of wavelengths in a network with fixed number of\nwavelengths. We also introduce an algorithm to calculate the resultant number\nof wavelength for each service classes depending on the various scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4612v1"
    },
    {
        "title": "Modelling and Implementation of ITWS: An ultimate solution to ITS",
        "authors": [
            "Nirmalendu Bikas Sinha",
            "Manish sonal",
            "Makar Chand Snai",
            "R. Bera",
            "M. Mitra"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Casualties due to traffic accidents are increasing day by day. Think of this\nmessage being displayed on your computer screen while you were driving \"there's\na possibility of collision with a car in the next few minutes if you go on\ndriving with this speed and direction\". Our research is intended towards\ndeveloping collision avoidance architecture for the latest Intelligent\nTransport System. The exchange of safety messages among vehicles and with\ninfrastructure devices poses major challenges. Specially, safety messages have\nto be adaptively distributed within a certain range of a basically unbounded\nsystem. These messages are to be well coordinated and processed via different\nalgorithms. The purpose of the paper is to discuss the ITWS (intelligent\ntransportation warning system), we have discussed the Assisted Global\nPositioning System(AGPS) system providing additional positioning information at\nvariable conditions. We have also discussed study the Data fusion and kalaman\nfilter in details. The performance of kalman filter and output are discussed.\nHardware realization of this model is achieved through software defined radio\n(SDR).\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0754v1"
    },
    {
        "title": "The New Embedded System Design Methodology For Improving Design Process\n  Performance",
        "authors": [
            "Maman Abdurohman",
            " Kuspriyanto",
            "Sarwono Sutikno",
            "Arif Sasongko"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Time-to-market pressure and productivity gap force vendors and researchers to\nimprove embedded system design methodology. Current used design method,\nRegister Transfer Level (RTL), is no longer be adequate to comply with embedded\nsystem design necessity. It needs a new methodology for facing the lack of RTL.\nIn this paper, a new methodology of hardware embedded system modeling process\nis designed for improving design process performance using Transaction Level\nModeling (TLM). TLM is a higher abstraction design concept model above RTL\nmodel. Parameters measured include design process time and accuracy of design.\nFor implementing RTL model used Avalon and Wishbone buses, both are System on\nChip bus. Performance improvement measured by comparing TLM and RTL model\nprocess. The experiment results show performance improvements for Avalon RTL\nusing new design methodology are 1,03 for 3-tiers, 1,47 for 4-tiers and 1,69\nfor 5-tiers. Performance improvements for Wishbone RTL are 1,12 for 3-tiers,\n1,17 for 4-tiers and 1,34 for 5-tiers. These results show the trend of design\nprocess improvement.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0931v1"
    },
    {
        "title": "Implementation of the Six Channel Redundancy to achieve fault tolerance\n  in testing of satellites",
        "authors": [
            "H. S. Aravinda",
            "H. D. Maheshappa",
            "Ranjan Moodithaya"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper aims to implement the six channel redundancy to achieve fault\ntolerance in testing of satellites with acoustic spectrum. We mainly focus here\non achieving fault tolerance. An immediate application is the microphone data\nacquisition and to do analysis at the Acoustic Test Facility (ATF) centre,\nNational Aerospace Laboratories. It has an 1100 cubic meter reverberation\nchamber in which a maximum sound pressure level of 157 dB is generated. The six\nchannel Redundancy software with fault tolerant operation is devised and\ndeveloped. The data are applied to program written in C language. The program\nis run using the Code Composer Studio by accepting the inputs. This is tested\nwith the TMS 320C 6727 DSP, Pro Audio Development Kit (PADK).\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0959v1"
    },
    {
        "title": "Tunable Multifunction Filter Using Current Conveyor",
        "authors": [
            "Manish Kumar",
            "M. C. Srivastava",
            "Umesh Kumar"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The paper presents a current tunable multifunction filter using current\nconveyor. The proposed circuit can be realized as on chip tunable low pass,\nhigh pass, band pass and elliptical notch filter. The circuit employs two\ncurrent conveyors, one OTA, four resistors and two grounded capacitors, ideal\nfor integration. It has only one output terminal and the number of input\nterminals may be used. Further, there is no requirement for component matching\nin the circuit. The resonance frequency ({\\omega}0) and bandwidth ({\\omega}0\n/Q) enjoy orthogonal tuning. The cutoff frequency of the filter is tunable by\nchanging the bias current, which makes it on chip tunable filter. The circuit\nis realized by using commercially available current conveyor AD844 and OTA\nLM13700. A HSPICE simulation of circuit is also studied for the verification of\ntheoretical results.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.0963v1"
    },
    {
        "title": "CrystalGPU: Transparent and Efficient Utilization of GPU Power",
        "authors": [
            "Abdullah Gharaibeh",
            "Samer Al-Kiswany",
            "Matei Ripeanu"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  General-purpose computing on graphics processing units (GPGPU) has recently\ngained considerable attention in various domains such as bioinformatics,\ndatabases and distributed computing. GPGPU is based on using the GPU as a\nco-processor accelerator to offload computationally-intensive tasks from the\nCPU. This study starts from the observation that a number of GPU features (such\nas overlapping communication and computation, short lived buffer reuse, and\nharnessing multi-GPU systems) can be abstracted and reused across different\nGPGPU applications. This paper describes CrystalGPU, a modular framework that\ntransparently enables applications to exploit a number of GPU optimizations.\nOur evaluation shows that CrystalGPU enables up to 16x speedup gains on\nsynthetic benchmarks, while introducing negligible latency overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.1695v1"
    },
    {
        "title": "Defuzzification Method for a Faster and More Accurate Control",
        "authors": [
            "S. Sanyal",
            "S. Iyengar",
            "A. A. Roy",
            "N. N. Karnik",
            "N. M. Mengale",
            "S. B. Menon",
            "Wu Geng Feng"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Today manufacturers are using fuzzy logic in everything from cameras to\nindustrial process control. Fuzzy logic controllers are easier to design and so\nare cheaper to produce. Fuzzy logic captures the impreciseness inherent in most\ninput data. Electromechanical controllers respond better to imprecise input if\ntheir behavior was modeled on spontaneous human reasoning. In a conventional\nPID controller, what is modeled is the system or process being controlled,\nwhereas in the Fuzzy logic controller, the focus is the human operator\nbehavior. In the first case, the system is modeled analytically by a set of\ndifferential equations and their solutions tells the PID controllers how to\nadjust the system's control parameters for each type of behavior required 3. In\nthe Fuzzy controller these adjustments are handled by a Fuzzy rule based expert\nsystem. A logical model of the thinking process a person might go through in\nthe course of manipulating the system. This shift in focus from process to\nperson involved changes the entire approach to automatic control problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.2499v1"
    },
    {
        "title": "A Discussion of Thin Client Technology for Computer Labs",
        "authors": [
            "Jess Martnez-Mateo",
            "Susana Munoz-Hernandez",
            "David Prez-Rey"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Computer literacy is not negotiable for any professional in an increasingly\ncomputerised environment. Educational institutions should be equipped to\nprovide this new basic training for modern life. Accordingly, computer labs are\nan essential medium for education in almost any field. Computer labs are one of\nthe most popular IT infrastructures for technical training in primary and\nsecondary schools, universities and other educational institutions all over the\nworld. Unfortunately, a computer lab is expensive, in terms of both initial\npurchase and annual maintenance costs, and especially when we want to run the\nlatest software. Hence, research efforts addressing computer lab efficiency,\nperformance or cost reduction would have a worldwide repercussion. In response\nto this concern, this paper presents a survey on thin client technology for\ncomputer labs in educational environments. Besides setting out the advantages\nand drawbacks of this technology, we aim to refute false prejudices against\nthin clients, identifying a set of educational scenarios where thin clients are\na better choice and others requiring traditional solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.2534v1"
    },
    {
        "title": "On the Module of Internet Banking System",
        "authors": [
            "Hamdan. O. Alanazi",
            "Rami Alnaqeib",
            "Ali K. Hmood",
            "M. A. Zaidan",
            "Yahya Al-Nabhani"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Because of the speed, flexibility, and efficiency that it offers, the\nInternet has become the means for conducting growing numbers of transactions\nbetween suppliers and large international corporations. In this way, the\nInternet has opened new markets to the world and has accelerated the diffusion\nof knowledge. The meaning of Internet markets or online business has been\nwidely used in these days. The success of the business depends on its\nflexibility, availability and security. Since that the web-based systems should\nhave a special way to design the system and implement it. Nowadays, the\nInternet Banking System widely used and the banks looking to provide the best\nquality system with highly available, fast response, secure and safe to use.\nThe Unified Modelling Language (UML) is the uniquely language which is used to\nanalyse and design any system. In this paper, the UML diagrams has been\nproposed to illustrate the design phase for any banking system. The authors,\npresented two types of architecture which is used for the Internet Banking\nSystem.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4029v1"
    },
    {
        "title": "Reduction in iron losses in Indirect Vector-Controlled IM Drive using\n  FLC",
        "authors": [
            "C. Srisailam",
            "Mukesh Tiwari",
            "Anurag Trivedi"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper describes the use of fuzzy logic controller for efficiency\noptimization control of a drive while keeping good dynamic response. At\nsteady-state light-load condition, the fuzzy controller adaptively adjusts the\nexcitation current with respect to the torque current to give the minimum total\ncopper and iron loss. The measured input power such that, for a given load\ntorque and speed, the drive settles down to the minimum input power, i.e.,\noperates at maximum efficiency. The low-frequency pulsating torque due to\ndecrementation of flux is compensated in a feed forward manner. If the load\ntorque or speed commands changes, the efficiency search algorithm is abandoned\nand the rated flux is established to get the best dynamic response. The drive\nsystem with the proposed efficiency optimization controller has been simulated\nwith lossy models of converter and machine, and its performance has been\nthoroughly investigated.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4265v1"
    },
    {
        "title": "E-Speed Governors For Public Transport Vehicles",
        "authors": [
            "C. S. Sridhar",
            "R. ShashiKumar",
            "S. Madhava Kumar",
            "Manjula Sridhar",
            "Varun. D"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  An accident is unexpected, unusual, unintended and identifiable external\nevent which occurs at any place and at any time. The major concern faced by the\ngovernment and traffic officials is over speeding at limited speed zones like\nhospitals, schools or residential places leading to causalities and more deaths\non the roads. Hence the speed of the vehicles is to be regulated and confined\nto the limits as prescribed by the traffic regulations. In this paper we\npropose a solution in the form of providing E-speed governor fitted with a\nwireless communication system consisting of a Rx which receives the information\nregarding the speed regulation for their zones. The TX will be made highly\nintelligent and decide when receiver should be made active to regulate the\nspeed and unwarranted honking from the vehicles which can be deactivated in the\nsilent zones.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4290v1"
    },
    {
        "title": "Effective Query Retrieval System In Mobile Business Environment",
        "authors": [
            "R. Sivaraman",
            "R. M. Chandrasekaran"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Web Based Query Management System (WBQMS) is a methodology to design and to\nimplement Mobile Business, in which a server is the gateway to connect\ndatabases with clients which sends requests and receives responses in a\ndistributive manner. The gateway, which communicates with mobile phone via GSM\nModem, receives the coded queries from users and sends packed results back. The\nsoftware which communicates with the gateway system via SHORT MESSAGE, packs\nusers' requests, IDs and codes, and sends the package to the gateway; then\ninterprets the packed data for the users to read on a page of GUI. Whenever and\nwherever they are, the customer can query the information by sending messages\nthrough the client device which may be mobile phone or PC. The mobile clients\ncan get the appropriate services through the mobile business architecture in\ndistributed environment. The messages are secured through the client side\nencoding mechanism to avoid the intruders. The gateway system is programmed by\nJava, while the software at clients by J2ME and the database is created by\nOracle for reliable and interoperable services.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4584v1"
    },
    {
        "title": "A Novel Algorithm for Informative Meta Similarity Clusters Using Minimum\n  Spanning Tree",
        "authors": [
            "S. John Peter",
            "S. P. Victor"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The minimum spanning tree clustering algorithm is capable of detecting\nclusters with irregular boundaries. In this paper we propose two minimum\nspanning trees based clustering algorithm. The first algorithm produces k\nclusters with center and guaranteed intra-cluster similarity. The radius and\ndiameter of k clusters are computed to find the tightness of k clusters. The\nvariance of the k clusters are also computed to find the compactness of the\nclusters. The second algorithm is proposed to create a dendrogram using the k\nclusters as objects with guaranteed inter-cluster similarity. The algorithm is\nalso finds central cluster from the k number of clusters. The first algorithm\nuses divisive approach, where as the second algorithm uses agglomerative\napproach. In this paper we used both the approaches to find Informative Meta\nsimilarity clusters.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4585v1"
    },
    {
        "title": "Radio Frequency Identifiers: What are the Possibilities?",
        "authors": [
            "Ahmed Elmorshidy"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper defines the components of radio frequency identifiers (RFID). It\nalso explores the different areas and sectors where RFID can be beneficial. The\npaper discusses the uses and advantages of RFID in deference, consumer packaged\ngoods (CPG), healthcare, logistics, manufacturing, and retail.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.5129v1"
    },
    {
        "title": "Towards MKM in the Large: Modular Representation and Scalable Software\n  Architecture",
        "authors": [
            "Michael Kohlhase",
            "Florian Rabe",
            "Vyacheslav Zholudev"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  MKM has been defined as the quest for technologies to manage mathematical\nknowledge. MKM \"in the small\" is well-studied, so the real problem is to scale\nup to large, highly interconnected corpora: \"MKM in the large\". We contend that\nadvances in two areas are needed to reach this goal. We need representation\nlanguages that support incremental processing of all primitive MKM operations,\nand we need software architectures and implementations that implement these\noperations scalably on large knowledge bases.\n  We present instances of both in this paper: the MMT framework for modular\ntheory-graphs that integrates meta-logical foundations, which forms the base of\nthe next OMDoc version; and TNTBase, a versioned storage system for XML-based\ndocument formats. TNTBase becomes an MMT database by instantiating it with\nspecial MKM operations for MMT.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.5232v2"
    },
    {
        "title": "sTeXIDE: An Integrated Development Environment for sTeX Collections",
        "authors": [
            "Constantin Jucovschi",
            "Michael Kohlhase"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Authoring documents in MKM formats like OMDoc is a very tedious task. After\nyears of working on a semantically annotated corpus of sTeX documents (GenCS),\nwe identified a set of common, time-consuming subtasks, which can be supported\nin an integrated authoring environment. We have adapted the modular Eclipse IDE\ninto sTeXIDE, an authoring solution for enhancing productivity in contributing\nto sTeX based corpora. sTeXIDE supports context-aware command completion,\nmodule management, semantic macro retrieval, and theory graph navigation.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.5489v1"
    },
    {
        "title": "On the Utility of Directional Information for Repositioning Errant\n  Probes in Central Force Optimization",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Central Force Optimization is a global search and optimization algorithm that\nsearches a decision space by flying \"probes\" whose trajectories are\ndeterministically computed using two equations of motion. Because it is\npossible for a probe to fly outside the domain of feasible solutions, a simple\nerrant probe retrieval method has been used previously that does not include\nthe directional information contained in a probe's acceleration vector. This\nnote investigates the effect of adding directionality to the \"repositioning\nfactor\" approach. As a general proposition, it appears that doing so does not\nimprove convergence speed or accuracy. In fact, adding directionality to the\noriginal errant probe retrieval scheme appears to be highly inadvisable.\nNevertheless, there may be alternative probe retrieval schemes that do benefit\nfrom directional information, and the results reported here may assist in or\nencourage their development.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.5490v2"
    },
    {
        "title": "Rectangular and Circular Antenna Design on Thick Substrate",
        "authors": [
            "Harsh kumar",
            "Shweta Srivastava"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Millimeter wave technology being an emerging area is still very undeveloped.\nA substantial research needs to be done in this area as its applications are\nnumerous. In the present endeavor, a rectangular patch antenna is designed on\nthick substrate and simulated using SONNET software, also a novel analysis\ntechnique is developed for circular patch antenna for millimeter wave\nfrequency. The antenna is designed at 39 GHz on thick substrate and has been\nanalyzed and simulated.The results of the theoretical analysis are in good\nagreement with the simulated results.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0836v1"
    },
    {
        "title": "Mutual Coupling Reduction in Two-Dimensional Array of Microstrip\n  Antennas Using Concave Rectangular Patches",
        "authors": [
            "S. Mohanna",
            "A. Farahbakhsh",
            "S. Tavakoli"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Using concave rectangular patches, a new solution to reduce mutual coupling\nand return loss in two-dimensional array of microstrip antennas is proposed.\nThe effect of width and length concavity on mutual coupling and return loss is\nstudied. Also, the patch parameters as well as the amounts of width and length\nconcavity are optimized using an enhanced genetic algorithm. Simulation results\nshow that the resulting array antenna has low amounts of mutual coupling and\nreturn loss.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0839v1"
    },
    {
        "title": "Improving GPS Precision and Processing Time using Parallel and\n  Reduced-Length Wiener Filters",
        "authors": [
            "J. Garcia",
            "C. Zhou"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Increasing GPS precision at low cost has always been a challenge for the\nmanufacturers of the GPS receivers. This paper proposes the use of a Wiener\nfilter for increasing precision in substitution of traditional GPS/INS fusion\nsystems, which require expensive inertial systems. In this paper, we first\nimplement and compare three GPS signal processing schemes: a Kalman filter, a\nneural network and a Wiener filter and compare them in terms of precision and\nthe processing time. To further reduce the processing time of Wiener filter, we\npropose parallel and reduced-length implementations. Finally, we calculate the\nsampling frequency that would be required in every Wiener scheme in order to\nobtain the same total processing time as the Kalman filter and the neural\nnetwork.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0844v1"
    },
    {
        "title": "Novel method for planar microstrip antenna matching impedance",
        "authors": [
            "Mahdi Ali",
            "Abdennacer Kachouri",
            "Mounir Samet"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Because all microstrip antennas have to be matched to the standard generator\nimpedance or load, the input impedance matching method for antenna is\nparticularly important. In this paper a new methodology in achieving matching\nimpedance of a planar microstrip antenna for wireless application is described.\nThe method is based on embedding an Interdigital capacitor. The fine results\nobtained by using a microstrip Interdigital capacitor for matching antenna\nimpedance led to an efficient method to improve array antenna performance. In\nfact, a substantial saving on the whole surfaces as well as enhancement of the\ngain, the directivity and the power radiated was achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0856v1"
    },
    {
        "title": "To Optimally Design Microstrip Nonuniform Transmission Lines as Lowpass\n  Filters",
        "authors": [
            "M. Khalaj-Amirhosseini",
            "S. A. Akbarzadeh-Jahromi"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  A method is proposed to optimally design the Microstrip Nonuniform\nTransmission Line (MNTLs) as lowpass filters. Some electrical and physical\nrestrictions are used to design MNTLs. To optimally design the MNTLs, their\nstrip width is expanded as truncated Fourier series, firstly. Then, the optimum\nvalues of the coefficients of the series are obtained through an optimization\napproach. The performance of the proposed structure is studied by design and\nfabrication of two lowpass filters of cutoff frequency 2.0 GHz.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.0859v1"
    },
    {
        "title": "Implementing and Evaluating a Wireless Body Sensor System for Automated\n  Physiological Data Acquisition at Home",
        "authors": [
            "Chao Chen",
            "Carlos Pomalaza-Raez"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Advances in embedded devices and wireless sensor networks have resulted in\nnew and inexpensive health care solutions. This paper describes the\nimplementation and the evaluation of a wireless body sensor system that\nmonitors human physiological data at home. Specifically, a waist-mounted\ntriaxial accelerometer unit is used to record human movements. Sampled data are\ntransmitted using an IEEE 802.15.4 wireless transceiver to a data logger unit.\nThe wearable sensor unit is light, small, and consumes low energy, which allows\nfor inexpensive and unobtrusive monitoring during normal daily activities at\nhome. The acceleration measurement tests show that it is possible to classify\ndifferent human motion through the acceleration reading. The 802.15.4 wireless\nsignal quality is also tested in typical home scenarios. Measurement results\nshow that even with interference from nearby IEEE 802.11 signals and microwave\novens, the data delivery performance is satisfactory and can be improved by\nselecting an appropriate channel. Moreover, we found that the wireless signal\ncan be attenuated by housing materials, home appliances, and even plants.\nTherefore, the deployment of wireless body sensor systems at home needs to take\nall these factors into consideration.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.1178v1"
    },
    {
        "title": "Simple ROI untuk justifikasi investasi proyek Data Warehouse pada\n  perguruan tinggi swasta",
        "authors": [
            "Spits Warnars"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Decreasing new students for private high education push the management\nparticularly for high level management for making an information which can help\nthem to make decisions in order for competition with other high educations. One\nof way out by building with information technology approaching like data\nwarehouse for data handling and making the best decisions. Simple ROI is used\nfor project justification. Based on ROI value between 1,850.13% and cash flow\nRp. 22,081,297,308 then can be concluded that project data warehouse\ndevelopment in private high education can be implemented with the particular\nassumptions.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.1676v1"
    },
    {
        "title": "Rancangan Infrastruktur E-Bisnis Business Intelligence Pada Perguruan\n  Tinggi",
        "authors": [
            "Spits Warnars"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In order to compete with others, high education need complete their\ninfrastructure with Information technology support. High level management as a\ndecision maker need something that can boost the system to compete with other\nhigh education, they need IT knowledge that can support them to view the future\nand can help the whole system to improve their services. Business Intelligence\nis one of term of Decision Support System which can help the management by\nsomething that they can forecast and decide. High Education need infrastructure\ndesign to make good foundation for business intelligent implementation which\nwill be implemented on internet or e-business.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.1679v1"
    },
    {
        "title": "Sistem Pengambilan Keputusan Penanganan Bencana Alam Gempa Bumi Di\n  Indonesia",
        "authors": [
            "H. L. H Spits Warnars"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  After Aceh's quake many earthquakes have struck Indonesia alternately and\neven other disasters have been a threat for every citizen in this country.\nActually an everyday occurrence on earth and more than 3 million earthquakes\noccur every year, about 8,000 a day, or one every 11 seconds in Indonesia there\nare 5 to 30 quakes prediction everyday. Government's responsibility to protect\nthe citizen has been done by making National body of disaster management.\nPreparing, saving and distribution logistic become National body of disaster\nmanagement's responsibility to build information management. Many law's\nproducts have been produced as a government's responsibility to give secure\nlife for the citizen. We can not prevent them totally, we have to learn to live\nwith them and need to be prepared all the time, need to learn how to mitigate\nrisk of losses in such events by managing crisis and emergencies correctly.\nAfter disaster happens respond must be rapidly and at an optimal level to save\nlives and help to victims. DSS is information technology environment which can\nbe used to help human in order to learn from past earthquake, record it, learn\nand plan for future mitigation and hope will reduce the disaster risk in the\nfuture. Using web technology for DSS will give value added where not only make\na strategic decision for the decision maker, but for others who need national\nearthquake information like citizen, scholars, researches and people around the\nworld.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.1704v2"
    },
    {
        "title": "Efektifitas Teknologi Informasi Dalam Proses Belajar Mengajar Pada\n  Universitas Budi Luhur",
        "authors": [
            "H. L. H Spits Warnars"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In general, however, IT will empower students to have greater control over\nthe learning process, with all the benefits associated with active learning and\npersonal responsibility. Not only will students decide when to learn and how to\nlearn, increasingly they will also decide what to learn and how that learning\nis to be certified. Traditionally, higher education institutions have combined\nseveral functions in their faculty. Faculty are architects as they design\nlearning programs; navigators as they help advise students in their course of\nstudy; instructors when they lecture; mentors when they help students form a\nsense of connectedness to the world; and evaluators and certifiers as they\ndecide to grant students grades or degrees.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.2074v1"
    },
    {
        "title": "Pemanfaatan Teknologi Sistem Informasi Geografis Untuk Menunjang\n  Pembangunan Daerah",
        "authors": [
            "Fedro Antonius Pardede",
            "H. L. H Spits Warnars"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The territory development will depend on that territory itself, where the\nword of autonomy for each province or territory will give contribution how\nIndonesian will responsible for development their territory. In order to\ndevelop territory, the information technology can be used as a boost or tools\nto give and deliver the best information and Geographic Information System is\none of the information technology tools which can be used to push every each\nterritory to speed the territory development. As a tool Geographic Information\nSystem has an ability to save, process, analysis and deliver information right\nin time and help the decision maker to make better decision.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.2085v1"
    },
    {
        "title": "Pembobolan website KPU (Komisi Pemilihan Umum) Apakah melanggar UU RI\n  no.36 tahun 1999 tentang telekomunikasi ?",
        "authors": [
            "Spits Warnars H. L. H"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Information Technology KPU (Indonesia Electoral Commision) is a project in\nsupporting democratization process in Indonesia. It is a part of General\nElection program of KPU-Indonesian Government. The aim of IT KPU is to build\nthe transparency of the ballot result to the public (citizen and international\nworld) and as the embrio of e government in Indonesia. It also has the aim for\ninfluence the citizen with Information Technology and the use of computer.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.2107v1"
    },
    {
        "title": "Virtual On-demand Test Lab using Cloud based Architecture",
        "authors": [
            "Rohit Kewlani"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Over a past few decades, VM's or Virtual machines have sort of gained a lot\nof momentum, especially for large scale enterprises where the need for resource\noptimization & power save is humongous, without compromising with performance\nor quality. They are a perfect environment to experiment with new\napplications/technologies in a completely secure and closed environment. This\npaper discusses how the VM technology can be leveraged to solve day to day\nrequirement of an odd hundreds or thousands of people, organization-wide, with\nnew computational resources using a cluster of heterogeneous low or high-end\nmachines, independent of underlying OS, thereby maximizing resource\nutilization. It takes into account both opensource (like VirtualBox) & other\nproprietary technologies (like VMWare Workstations) available till date to\npropose a viable solution using cloud computing concept. The ease of\nscalability to multiple folds for optimizing performance & catering to an even\nlarger set are some of the salient features of this approach. Using the\nsnapshot feature, the state of any VM instance could be saved & served back\nagain on request. Now, this implementation is also served by VMWare ESX server\nbut again it's a costly solution & requires dedicated high-end machines to work\nwith.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.2802v1"
    },
    {
        "title": "High Speed Reconfigurable FFT Design by Vedic Mathematics",
        "authors": [
            "Ashish Raman",
            "Anvesh Kumar",
            "R. K. Sarin"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The Fast Fourier Transform (FFT) is a computationally intensive digital\nsignal processing (DSP) function widely used in applications such as imaging,\nsoftware-defined radio, wireless communication, instrumentation. In this paper,\na reconfigurable FFT design using Vedic multiplier with high speed and small\narea is presented. Urdhava Triyakbhyam algorithm of ancient Indian Vedic\nMathematics is utilized to improve its efficiency. In the proposed\narchitecture, the 4x4 bit multiplication operation is fragmented reconfigurable\nFFT modules. The 4x4 multiplication modules are implemented using small 2x2bit\nmultipliers. Reconfigurability at run time is provided for attaining power\nsaving. The reconfigurable FFT has been designed, optimized and implemented on\nan FPGA based system. This reconfigurable FFT is having the high speed and\nsmall area as compared to the conventional FFT.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.2811v1"
    },
    {
        "title": "Effect of Distributed Shield Insertion on Crosstalk in Inductively\n  Coupled VLSI Interconnects",
        "authors": [
            "Divya Mishra",
            "Shailendra Mishra",
            "Praggya Agnihotry",
            "B. K. Kaushik"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Crosstalk in VLSI interconnects is a major constrain in DSM and UDSM\ntechnology. Among various strategies followed for its minimization, shield\ninsertion between Aggressor and Victim is one of the prominent options. This\npaper analyzes the extent of crosstalk in inductively coupled interconnects and\nminimizes the same through distributed shield insertion. Comparison is drawn\nbetween signal voltage and crosstalk voltage in three different conditions i.e.\nprior to shield insertion, after shield insertion and after additional ground\ntap insertion at shield terminal.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.2820v1"
    },
    {
        "title": "The Forecasting of 3G Market in India Based on Revised Technology\n  Acceptance Model",
        "authors": [
            "Sudha Singh",
            "D. K. Singh",
            "M. K. Singh",
            "Sujeet Kumar Singh"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  3G, processor of 2G services, is a family of standards for mobile\ntelecommunications defined by the International Telecommunication Union [1]. 3G\nservices include wide-area wireless voice telephone, video calls, and wireless\ndata, all in a mobile environment. It allows simultaneous use of speech and\ndata services and higher data rates.3G is defined to facilitate growth,\nincreased bandwidth and support more diverse applications. The focus of this\nstudy is to examine the factors affecting the adoption of 3G services among\nIndian people. The study adopts the revised Technology Acceptance Model by\nadding five antecedents-perceived risks, cost of adoption, perceived service\nquality, subjective norms, and perceived lack of knowledge. Data have collected\nfrom more than 400 school/college/Institution students & employees of various\nGovernment/Private sectors using interviews & various convenience sampling\nprocedures and analyzed using MS excel and MATLAB. Result shows that perceived\nusefulness has the most significant influence on attitude towards using 3G\nservices, which is consistent with prior studies. Of the five antecedents,\nperceived risk and cost of adoption are found to be significantly influencing\nattitude towards use. The outcome of this study would be beneficial to private\nand public telecommunication organizations, various service providers, business\ncommunity, banking services and people of India. Research findings and\nsuggestions for future research are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.3609v1"
    },
    {
        "title": "Analysis of Microprocessor Based Protective Re-lay's (MBPR) Differential\n  Equation Algorithms",
        "authors": [
            "Bruno Osorno"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper analyses and explains from the systems point of view,\nmicroprocessor based protective relay (MBPR) systems with emphasis on\ndifferential equation algorithms. Presently, the application of protective\nrelaying in power systems, using MBPR systems, based on the differential\nequation algorithm is valued more than the protection relaying based on any\nother type of algorithm, because of advantages in accuracy and implementation.\nMBPR differential equation approach can tolerate some errors caused by power\nsystem abnormality such as DC offset. This paper shows that the algorithm is a\nsystem description based and it is immune from distortions such as DC-offset.\nDifferential equation algorithms implemented in MBPR are widely used in the\nprotection of transmission and distribution lines, transformers, buses, motors,\netc. The parameters from the system, utilized in these algorithms, are obtained\nfrom the power system current i(t) or voltage v(t), which are abnormal values\nunder fault or distortion situations. So, an error study for the algorithm is\nconsidered necessary.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4444v1"
    },
    {
        "title": "Algorithm and Implementation of the Blog-Post Supervision Process",
        "authors": [
            "Kamanashis Biswas",
            "Md. Liakat Ali",
            "S. A. M. Harun"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  A web log or blog in short is a trendy way to share personal entries with\nothers through website. A typical blog may consist of texts, images, audios and\nvideos etc. Most of the blogs work as personal online diaries, while others may\nfocus on specific interest such as photographs (photoblog), art (artblog),\ntravel (tourblog), IT (techblog) etc. Another type of blogging called\nmicroblogging is also very well known now-a-days which contains very short\nposts. Like the developed countries, the users of blogs are gradually\nincreasing in the developing countries e.g. Bangladesh. Due to the nature of\nopen access to all users, some people misuse it to spread fake news to achieve\nindividual or political goals. Some of them also post vulgar materials that\nmake an embarrass situation for other bloggers. Even, sometimes it indulges the\nreputation of the victim. The only way to overcome this problem is to bring all\nthe posts under supervision of the blog moderator. But it totally contradicts\nwith blogging concepts. In this paper, we have implemented an algorithm that\nwould help to prevent the offensive entries from being posted. These entries\nwould go through a supervision process to justify themselves as legal posts.\nFrom the analysis of the result, we have shown that this approach can eliminate\nthe chaotic situations in blogosphere at a great extent. Our experiment shows\nthat about 90% of offensive posts can be detected and stopped from being\npublished using this approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4542v1"
    },
    {
        "title": "Gender Based Emotion Recognition System for Telugu Rural Dialects Using\n  Hidden Markov Models",
        "authors": [
            "Prasad Reddy P. V. G. D",
            "A. Prasad",
            "Y. Srinivas",
            "P. Brahmaiah"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Automatic emotion recognition in speech is a research area with a wide range\nof applications in human interactions. The basic mathematical tool used for\nemotion recognition is Pattern recognition which involves three operations,\nnamely, pre-processing, feature extraction and classification. This paper\nintroduces a procedure for emotion recognition using Hidden Markov Models\n(HMM), which is used to divide five emotional states: anger, surprise,\nhappiness, sadness and neutral state. The approach is based on standard speech\nrecognition technology using hidden continuous markov model by selection of low\nlevel features and the design of the recognition system. Emotional Speech\nDatabase from Telugu Rural Dialects of Andhra Pradesh (TRDAP) was designed\nusing several speaker's voices comprising the emotional states. The accuracy of\nrecognizing five different emotions for both genders of classification is 80%\nfor anger-emotion which is achieved by using the best combination of\n39-dimensioanl feature vector for every frame (13 MFCCs, 13 Delta Coefficients\nand 13 Acceleration Coefficients) and a classifier using HMM. This outcome very\nmuch matches with that acquired with the same database with subjective\nevaluation by human judges. Both gender-dependent and gender-independent\nexperiments are conducted on TRDAP emotional speech database.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4548v1"
    },
    {
        "title": "Search Engine Optimization Techniques Practiced in Organizations: A\n  Study of Four Organizations",
        "authors": [
            "Muhammad Akram",
            "Imran Sohail",
            "Sikandar Hayat",
            "M. Imran Shafi",
            "Umer Saeed"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Web spammers used Search Engine Optimization (SEO) techniques to increase\nsearch-ranking of web sites. In this paper we have study the essentials SEO\ntechniques, such as; directory submission, keyword generation and link\nexchanges. The impact of SEO techniques can be applied as marketing technique\nand to get top listing in major search engines like Google, Yahoo, and MSN. Our\nstudy focuses on these techniques from four different companies' perspectives\nof United Kingdom and Pakistan. According to the these companies, these\ntechniques are low cost and high impacts in profit, because mostly customers\nfocus on major search engine to find different products on internet, so SEO\ntechnique provides best opportunity to grow their business. This paper also\ndescribes the pros and cons of using these searh engine optimization techniques\nin above four companies. We have concluded that these techniques are essential\nto increase their business profit and minimize their marketing cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4558v1"
    },
    {
        "title": "Analytical Study on Internet Banking System",
        "authors": [
            "Fadhel. S. AlAbdullah",
            "Fahad H. Alshammari",
            "Rami Alnaqeib",
            "Hamid A. Jalab",
            "A. A. Zaidan",
            "B. B. Zaidan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The Internet era is a period in the information age in which communication\nand commerce via the Internet became a central focus for businesses, consumers,\ngovernment, and the media. The Internet era also marks the convergence of the\ncomputer and communications industries and their associated services and\nproducts. Nowadays, the availability of the Internet make it widely used for\neveryday life. In order to led business to success, the business and specially\nthe services should provide comfort use to its costumer. The bank system is one\nof the most important businesses who may use the website. The using for the\nweb-based systems should contain special requirements to achieve the business\ngoal. Since that the paper will present the functional and non-functional for\nthe web-based banking system.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4559v1"
    },
    {
        "title": "Optimization of reversible sequential circuits",
        "authors": [
            "Abu Sadat Md. Sayem",
            "Masashi Ueda"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In recent years reversible logic has been considered as an important issue\nfor designing low power digital circuits. It has voluminous applications in the\npresent rising nanotechnology such as DNA computing, Quantum Computing, low\npower VLSI and quantum dot automata. In this paper we have proposed optimized\ndesign of reversible sequential circuits in terms of number of gates, delay and\nhardware complexity. We have designed the latches with a new reversible gate\nand reduced the required number of gates, garbage outputs, and delay and\nhardware complexity. As the number of gates and garbage outputs increase the\ncomplexity of reversible circuits, this design will significantly enhance the\nperformance. We have proposed reversible D-latch and JK latch which are better\nthan the existing designs available in literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.4570v1"
    },
    {
        "title": "Critical Success factors for Enterprise Resource Planning implementation\n  in Indian Retail Industry: An Exploratory study",
        "authors": [
            "Poonam Garg"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Enterprise resource Planning (ERP) has become a key business driver in\ntoday's world. Retailers are also trying to reap in the benefits of the ERP. In\nmost large Indian Retail Industry ERP systems have replaced nonintegrated\ninformation systems with integrated and maintainable software. Retail ERP\nsolution integrates demand and supply effectively to help improve bottom line.\nThe implementation of ERP systems in such firms is a difficult task. So far,\nERP implementations have yielded more failures than successes. Very few\nimplementation failures are recorded in the literature because few companies\nwish to publicize their implementation failure. This paper explores and\nvalidates the existing literature empirically to find out the critical success\nfactors that lead to the success of ERP in context to Indian retail industry.\nThe findings of the results provide valuable insights for the researchers and\npractitioners who are interested in implementing Enterprise Resource Planning\nsystems in retail industry, how best they can utilize their limited resources\nand to pay adequate attention to those factors that are most likely to have an\nimpact upon the implementation of the ERP system.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.5749v1"
    },
    {
        "title": "Scheduling Periodic Real-Time Tasks with Heterogeneous Reward\n  Requirements",
        "authors": [
            "I-Hong Hou",
            "P. R. Kumar"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  We study the problem of scheduling periodic real-time tasks so as to meet\ntheir individual minimum reward requirements. A task generates jobs that can be\ngiven arbitrary service times before their deadlines. A task then obtains\nrewards based on the service times received by its jobs. We show that this\nmodel is compatible to the imprecise computation models and the increasing\nreward with increasing service models. In contrast to previous work on these\nmodels, which mainly focus on maximize the total reward in the system, we aim\nto fulfill different reward requirements by different tasks, which offers\nbetter fairness and allows fine-grained tradeoff between tasks. We first derive\na necessary and sufficient condition for a system, along with reward\nrequirements of tasks, to be feasible. We also obtain an off-line feasibility\noptimal scheduling policy. We then studies a sufficient condition for a policy\nto be feasibility optimal or achieves some approximation bound. This condition\ncan serve as a guideline for designing on-line scheduling policy and we obtains\na greedy policy based on it. We prove that the on-line policy is feasibility\noptimal when all tasks have the same periods and also obtain an approximation\nbound for the policy under general cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.0683v1"
    },
    {
        "title": "Channel Sounding for the Masses: Low Complexity GNU 802.11b Channel\n  Impulse Response Estimation",
        "authors": [
            "Mohammad H. Firooz",
            "Dustin Maas",
            "Junxing Zhang",
            "Neal Patwari",
            "Sneha K. Kasera"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  New techniques in cross-layer wireless networks are building demand for\nubiquitous channel sounding, that is, the capability to measure channel impulse\nresponse (CIR) with any standard wireless network and node. Towards that goal,\nwe present a software-defined IEEE 802.11b receiver and CIR estimation system\nwith little additional computational complexity compared to 802.11b reception\nalone. The system implementation, using the universal software radio peripheral\n(USRP) and GNU Radio, is described and compared to previous work. By overcoming\ncomputational limitations and performing direct-sequence spread-spectrum\n(DS-SS) matched filtering on the USRP, we enable high-quality yet inexpensive\nCIR estimation. We validate the channel sounder and present a drive test\ncampaign which measures hundreds of channels between WiFi access points and an\nin-vehicle receiver in urban and suburban areas.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.3476v1"
    },
    {
        "title": "The Dynamics of Vehicular Networks in Urban Environments",
        "authors": [
            "Nicholas Loulloudes",
            "George Pallis",
            "Marios D. Dikaiakos"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Vehicular Ad hoc NETworks (VANETs) have emerged as a platform to support\nintelligent inter-vehicle communication and improve traffic safety and\nperformance. The road-constrained, high mobility of vehicles, their unbounded\npower source, and the emergence of roadside wireless infrastructures make\nVANETs a challenging research topic. A key to the development of protocols for\ninter-vehicle communication and services lies in the knowledge of the\ntopological characteristics of the VANET communication graph. This paper\nexplores the dynamics of VANETs in urban environments and investigates the\nimpact of these findings in the design of VANET routing protocols. Using both\nreal and realistic mobility traces, we study the networking shape of VANETs\nunder different transmission and market penetration ranges. Given that a number\nof RSUs have to be deployed for disseminating information to vehicles in an\nurban area, we also study their impact on vehicular connectivity. Through\nextensive simulations we investigate the performance of VANET routing protocols\nby exploiting the knowledge of VANET graphs analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1007.4106v2"
    },
    {
        "title": "WLAN PIDS",
        "authors": [
            "Deng Bin"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper discuss two structures of WLAN system fit to Passenger Information\nDisplay System which is partly of subway.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.0092v1"
    },
    {
        "title": "Contributions of PDM Systems in Organizational Technical Data Management",
        "authors": [
            "Zeeshan Ahmed",
            "Detlef Gerhard"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Product Data Management (PDM) claims of producing desktop and web based\nsystems to maintain the organizational data to increase the quality of products\nby improving the process of development, business process flows, change\nmanagement, product structure management, project tracking and resource\nplanning. Moreover PDM helps in reducing the cost and effort required in\nengineering. This paper discusses PDM desktop and web based system, needed\ninformation and important guidelines for PDM system development, functional\nrequirements, basic components in detail and some already implemented PDM\nSys-tems. In the end paper investigates and briefly concludes major currently\nfaced challenges to Product Data Management (PDM) community.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.1321v1"
    },
    {
        "title": "Semantic Oriented Intelligent Electronic Learning",
        "authors": [
            "Zeeshan Ahmed",
            "Detlef Gerhard"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this research paper we describe semantic oriented information engineering\nand knowledge management based solution towards E-Learning systems. We also try\nto justify the importance of proposed solution with respect to the E-Learning\nApproaches .i.e., Behavior, Objectivism, Cognitive and Construction. Moreover\nwe briefly describe E-Learning, information engineering, knowledge management\nand some old and newly available technologies supporting development of\nE-Learning Systems in this research paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.1330v1"
    },
    {
        "title": "Web to Semantic Web & Role of Ontology",
        "authors": [
            "Zeeshan Ahmed",
            "Detlef Gerhard"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this research paper we are briefly presenting current major web problems\nand introducing semantic web technologies with the claim of solving existing\nweb's problems. Furthermore we are describing Ontology as the main building\nblock of semantic web and focusing on its contributions to semantic web\nprogress and current limitations.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.1331v1"
    },
    {
        "title": "How Does Ontology Contribute in Semantic Web Development?",
        "authors": [
            "Zeeshan Ahmed",
            "Detlef Gerhard"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper investigates and briefly describes the major currently existing\nproblems with World Wide Web .i.e., Information filtration and Security became\nthe main reasons of semantic web's invention. The semantic web claims of\nproviding the semantic based solutions towards current web problems. Semantic\nweb have introduced and relies on a main building block \"Ontology\" to provide\nthe information in machine processable semantic models and produce semantically\nmodelled knowledge representation systems. This paper also describes the role,\nconstruction process and the contributions of ontology in providing some in\ntime proposed and implemented solutions. Furthermore paper concludes with the\ncurrently existing limitations in Ontology and the areas which need\nimprovements.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.1334v1"
    },
    {
        "title": "I-SOAS towards Product Data Management (PDM) based Application's\n  Problems",
        "authors": [
            "Zeeshan Ahmed",
            "Detlef Gerhard"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this research paper we address the importance of Product Data Management\n(PDM) with respect to the industrial contributional point of view and its major\nobjectives. Moreover we also present some currently available major challenges\nto the Product Data Management based communities, and targeting those\nchallenges we discuss an already proposed conceptual architectural based\nhelpful approach and briefly describe how this approach can be helpful in\nsolving the PDM communities faced problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.1336v1"
    },
    {
        "title": "Efficient Wrapper/TAM Co-Optimization for SOC Using Rectangle Packing",
        "authors": [
            "Md. Rafiqul Islam",
            "Muhammad Rezaul Karim",
            "Abdullah Al Mahmud",
            "Md. Saiful Islam",
            "Hafiz Md. Hasan Babu"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The testing time for a system-on-chip(SOC) largely depends on the design of\ntest wrappers and the test access mechanism(TAM).Wrapper/TAM co-optimization is\ntherefore necessary to minimize SOC testing time . In this paper, we propose an\nefficient algorithm to construct wrappers that reduce testing time for cores.\nWe further propose a new approach for wrapper/TAM co-optimization based on\ntwo-dimensional rectangle packing. This approach considers the diagonal length\nof the rectangles to emphasize on both TAM widths required by a core and its\ncorresponding testing time.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.3320v1"
    },
    {
        "title": "Implementation of the Trigonometric LMS Algorithm using Original Cordic\n  Rotation",
        "authors": [
            "Nasrin Akhter",
            "Kaniz Fatema",
            "Lilatul Ferdouse",
            "Faria Khandaker"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The LMS algorithm is one of the most successful adaptive filtering\nalgorithms. It uses the instantaneous value of the square of the error signal\nas an estimate of the mean-square error (MSE). The LMS algorithm changes\n(adapts) the filter tap weights so that the error signal is minimized in the\nmean square sense. In Trigonometric LMS (TLMS) and Hyperbolic LMS (HLMS), two\nnew versions of LMS algorithms, same formulations are performed as in the LMS\nalgorithm with the exception that filter tap weights are now expressed using\ntrigonometric and hyperbolic formulations, in cases for TLMS and HLMS\nrespectively. Hence appears the CORDIC algorithm as it can efficiently perform\ntrigonometric, hyperbolic, linear and logarithmic functions. While\nhardware-efficient algorithms often exist, the dominance of the software\nsystems has kept those algorithms out of the spotlight. Among these hardware-\nefficient algorithms, CORDIC is an iterative solution for trigonometric and\nother transcendental functions. Former researches worked on CORDIC algorithm to\nobserve the convergence behavior of Trigonometric LMS (TLMS) algorithm and\nobtained a satisfactory result in the context of convergence performance of\nTLMS algorithm. But revious researches directly used the CORDIC block output in\ntheir simulation ignoring the internal step-by-step rotations of the CORDIC\nprocessor. This gives rise to a need for verification of the convergence\nperformance of the TLMS algorithm to investigate if it actually performs\nsatisfactorily if implemented with step-by-step CORDIC rotation. This research\nwork has done this job. It focuses on the internal operations of the CORDIC\nhardware, implements the Trigonometric LMS (TLMS) and Hyperbolic LMS (HLMS)\nalgorithms using actual CORDIC rotations. The obtained simulation results are\nhighly satisfactory and also it shows that convergence behavior of HLMS is much\nbetter than TLMS.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.3328v3"
    },
    {
        "title": "Wrapper/TAM Co-Optimization and Test Scheduling for SOCs Using Rectangle\n  Bin Packing Considering Diagonal Length of Rectangles",
        "authors": [
            "Md. Rafiqul Islam",
            "Muhammad Rezaul Karim",
            "Abdullah Al Mahmud",
            "Md. Saiful Islam",
            "Hafiz Md. Hasan Babu"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper describes an integrated framework for SOC test automation. This\nframework is based on a new approach for Wrapper/TAM co-optimization based on\nrectangle packing considering the diagonal length of the rectangles to\nemphasize on both TAM widths required by a core and its corresponding testing\ntime. In this paper, we propose an efficient algorithm to construct wrappers\nthat reduce testing time for cores. We then use rectangle packing to develop an\nintegrated scheduling algorithm that incorporates power constraints in the test\nschedule. The test power consumption is important to consider since exceeding\nthe system's power limit might damage the system.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.4446v1"
    },
    {
        "title": "Wrapper/TAM Co-Optimization and constrained Test Scheduling for SOCs\n  Using Rectangle Bin Packing",
        "authors": [
            "Hafiz Md. Hasan Babu",
            "Md. Rafiqul Islam",
            "Muhammad Rezaul Karim",
            "Abdullah Al Mahmud",
            "Md. Saiful Islam"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper describes an integrated framework for SOC test automation. This\nframework is based on a new approach for Wrapper/TAM co-optimization based on\nrectangle packing considering the diagonal length of the rectangles to\nemphasize on both TAM widths required by a core and its corresponding testing\ntime .In this paper, an efficient algorithm has been proposed to construct\nwrappers that reduce testing time for cores. Rectangle packing has been used to\ndevelop an integrated scheduling algorithm that incorporates power constraints\nin the test schedule. The test power consumption is important to consider since\nexceeding the system's power limit might damage the system.\n",
        "pdf_link": "http://arxiv.org/pdf/1008.4448v1"
    },
    {
        "title": "Towards Autopoietic Computing",
        "authors": [
            "Gerard Briscoe",
            "Paolo Dini"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  A key challenge in modern computing is to develop systems that address\ncomplex, dynamic problems in a scalable and efficient way, because the\nincreasing complexity of software makes designing and maintaining efficient and\nflexible systems increasingly difficult. Biological systems are thought to\npossess robust, scalable processing paradigms that can automatically manage\ncomplex, dynamic problem spaces, possessing several properties that may be\nuseful in computer systems. The biological properties of self-organisation,\nself-replication, self-management, and scalability are addressed in an\ninteresting way by autopoiesis, a descriptive theory of the cell founded on the\nconcept of a system's circular organisation to define its boundary with its\nenvironment. In this paper, therefore, we review the main concepts of\nautopoiesis and then discuss how they could be related to fundamental concepts\nand theories of computation. The paper is conceptual in nature and the emphasis\nis on the review of other people's work in this area as part of a longer-term\nstrategy to develop a formal theory of autopoietic computing.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.0797v1"
    },
    {
        "title": "A Note on the Membrane Computer",
        "authors": [
            "Ammar Adl",
            "Amr Badr",
            "Ibrahim Farag"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Inspired by the emergent membrane computing (P Systems) concepts, some\nefforts are carried out introducing simulation models, some are software\noriented, and others are hardware, yet all are applied with the current vision\nof the conventional computers, based on \"Von Neumann architecture\", which is a\nsequential design in its essence. We think that these models will need \"as a\nconsequent result\" to a new architecture exposing a true parallel design, in\nthis paper; we try to investigate and introduce a global view for how it would\nbe like to have such architecture. The main goal is to point out to this\ndirection broadly, suggesting that it might be useful considering some aspects,\nlike the need for a new definition of an operating system and its programs,\nwhich will eventually lead to a higher scope: the membrane computer.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.0923v1"
    },
    {
        "title": "Home Automation",
        "authors": [
            "Zeeshan Ahmed"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper I briefly discuss the importance of home automation system.\nGoing in to the details I briefly present a real time designed and implemented\nsoftware and hardware oriented house automation research project, capable of\nautomating house's electricity and providing a security system to detect the\npresence of unexpected behavior.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.2000v1"
    },
    {
        "title": "Aero Fighter - 2D Gaming",
        "authors": [
            "Zeeshan Ahmed"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Designing and developing quality based computer game is always a challenging\ntask for developers. In this paper I briefly discuss aero fighting war game\nbased on simple 2D gaming concepts and developed in C & C++ programming\nlanguages, using old bitmapping concepts. Going into the details of the game\ndevelopment, I discuss the designed strategies, flow of game and implemented\nprototype version of game, especially for beginners of game programming.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.2002v1"
    },
    {
        "title": "Testing of Bridging Faults in AND-EXOR based Reversible Logic Circuits",
        "authors": [
            "Avik Chakraborty"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Reversible circuits find applications in many areas of Computer Science\nincluding Quantum Computation. This paper examines the testability of an\nimportant subclass of reversible logic circuits that are composed of k-wire\ncontrolled NOT (k-CNOT with k >/- 1) gates. A reversible k-CNOT gate can be\nimplemented using an irreversible k-input AND gate and an EXOR gate. A\nreversible k-CNOT circuit where each k-CNOT gate is realized using irreversible\nk-input AND and EXOR gate, has been considered. One of the most commonly used\nSingle Bridging Fault model (both wired-AND and wired-OR) has been assumed to\nbe type of fault for such circuits. It has been shown that an (n+p)-input\nAND-EXOR based reversible logic circuit with p observable outputs, can be\ntested for single bridging faults (SBF) using (3n + \\lefthalfcap log2p\n\\righthalfcap + 2) tests.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.5098v1"
    },
    {
        "title": "ARMrayan Multimedia Mobile CMS: a Simplified Approach towards\n  Content-Oriented Mobile Application Designing",
        "authors": [
            "Ali Reza Manashty",
            "Mohammad Reza Ahmadzadeh Raji",
            "Zahra Forootan Jahromi",
            "Amir Rajabzadeh"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The ARMrayan Multimedia Mobile CMS (Content Management System) is the first\nmobile CMS that gives the opportunity to users for creating multimedia J2ME\nmobile applications with their desired content, design and logo; simply,\nwithout any need for writing even a line of code. The low-level programming and\ncompatibility problems of the J2ME, along with UI designing difficulties, makes\nit hard for most people -even programmers- to broadcast their content to the\nwidespread mobile phones used by nearly all people. This system provides\nuser-friendly, PC-based tools for creating a tree index of pages and inserting\nmultiple multimedia contents (e.g. sound, video and picture) in each page for\ncreating a J2ME mobile application. The output is a stand-alone Java mobile\napplication that has a user interface, shows texts and pictures and plays music\nand videos regardless of the type of devices used as long as the devices\nsupport the J2ME platform. Bitmap fonts have also been used thus Middle Eastern\nlanguages can be easily supported on all mobile phone devices. We omitted\nprogramming concepts for users in order to simplify multimedia content-oriented\nmobile application designing for use in educational, cultural or marketing\ncenters. Ordinary operators can now create a variety of multimedia mobile\napplications such as tutorials, catalogues, books, and guides in minutes rather\nthan months. Simplicity and power has been the goal of this CMS. In this paper,\nwe present the software engineered-designed concepts of the ARMrayan MCMS along\nwith the implementation challenges faces and solutions adapted.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.5347v1"
    },
    {
        "title": "A Mobile Application for Smart House Remote Control System",
        "authors": [
            "Amir Rajabzadeh",
            "Ali Reza Manashty",
            "Zahra Forootan Jahromi"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  At the start of the second decade of 21th century, the time has come to make\nthe Smart Houses a reality for regular use. The different parts of a Smart\nHouse are researched but there are still distances from an applicable system,\nusing the modern technology. In this paper we present an overview of the Smart\nHouse subsystems necessary for controlling the house using a mobile application\nefficiently and securely. The sequence diagram of the mobile application\nconnecting to the server application and also the use-cases possible are\npresented. The challenges faced in designing the mobile application and\nillustrating the updated house top plane view in that application, are\ndiscussed and solutions are adapted for it. Finally the designed mobile\napplication was implemented and the important sections of it were described,\nsuch as the interactive house top view map which indicates the status of the\ndevices using predefined icons. The facilities to manage the scheduled tasks\nand defined rules are also implemented in this mobile application that was\ndeveloped for use in Windows Mobile platform. This application has the\ncapability of connecting to the main server using GPRS mobile internet and SMS.\nThis system is expected to be an important step towards a unified system\nstructure that can be used efficiently in near future regular houses.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.5557v1"
    },
    {
        "title": "Heuristic approach to optimize the number of test cases for simple\n  circuits",
        "authors": [
            "SM. Thamarai",
            "K. Kuppusamy",
            "T. Meyyappan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper a new solution is proposed for testing simple stwo stage\nelectronic circuits. It minimizes the number of tests to be performed to\ndetermine the genuinity of the circuit. The main idea behind the present\nresearch work is to identify the maximum number of indistinguishable faults\npresent in the given circuit and minimize the number of test cases based on the\nnumber of faults that has been detected. Heuristic approach is used for test\nminimization part, which identifies the essential tests from overall test\ncases. From the results it is observed that, test minimization varies from 50%\nto 99% with the lowest one corresponding to a circuit with four gates .Test\nminimization is low in case of circuits with lesser input leads in gates\ncompared to greater input leads in gates for the boolean expression with same\nnumber of symbols. Achievement of 99% reduction is due to the fact that the\nlarge number of tests find the same faults. The new approach is implemented for\nsimple circuits. The results show potential for both smaller test sets and\nlower cpu times.\n",
        "pdf_link": "http://arxiv.org/pdf/1009.6186v1"
    },
    {
        "title": "Nations At War I: Why do we keep building weapons?",
        "authors": [
            "Vikram Dhillon"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper is the first in series of four papers that present an analytical\napproach to war using game theory. We try to explore why is it that \"true\npeace\" can't be achieved and all or any efforts we make towards that goal will\nhave huge road-blocks. A fairly simplistic and non technical overview of our\napproach is given in this paper using prisoner's dilemma.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.0454v2"
    },
    {
        "title": "Statistical Modelling of ft to Process Parameters in 30 nm Gate Length\n  Finfets",
        "authors": [
            "B. Lakshmi",
            "R. Srinivasan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper investigates the effect of process variations on unity gain\nfrequency (ft) in 30 nm gate length FinFET by performing extensive TCAD\nsimulations. Six different geometrical parameters, channel doping, source/drain\ndoping and gate electrode work function are studied for their sensitivity on\nft. It is found that ft is more sensitive to gate length, underlap, gate-oxide\nthickness, channel and Source/Drain doping and less sensitive to source/drain\nwidth and length, and work function variations. Statistical modelling has been\nperformed for ft through design of experiment with respect to sensitive\nparameters. The model has been validated through a comparison between random\nset of experimental data simulations and predicted values obtained from the\nmodel.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.0471v1"
    },
    {
        "title": "Server Consolidation: An Approach to make Data Centers Energy Efficient\n  and Green",
        "authors": [
            "Mueen Uddin",
            "Azizah Abdul Rahman"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Data centers are the building blocks of IT business organizations providing\nthe capabilities of centralized repository for storage, management, networking\nand dissemination of data. With the rapid increase in the capacity and size of\ndata centers, there is a continuous increase in the demand for energy\nconsumption. These data centers not only consume a tremendous amount of energy\nbut are riddled with IT inefficiencies. All data center are plagued with\nthousands of servers as major components. These servers consume huge energy\nwithout performing useful work. In an average server environment, 30% of the\nservers are \"dead\" only consuming energy, without being properly utilized.\nTheir utilization ratio is only 5 to 10 percent. This paper focuses on the use\nof an emerging technology called virtualization to achieve energy efficient\ndata centers by providing a solution called server consolidation. It increases\nthe utilization ratio up to 50% saving huge amount of energy. Server\nconsolidation helps in implementing green data centers to ensure that IT\ninfrastructure contributes as little as possible to the emission of green house\ngases, and helps to regain power and cooling capacity, recapture resilience and\ndramatically reducing energy costs and total cost of ownership.\n",
        "pdf_link": "http://arxiv.org/pdf/1010.5037v1"
    },
    {
        "title": "Level Shifter Design for Low Power Applications",
        "authors": [
            "Manoj Kumar",
            "Sandeep K. Arya",
            "Sujata Pandey"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  With scaling of Vt sub-threshold leakage power is increasing and expected to\nbecome significant part of total power consumption In present work three new\nconfigurations of level shifters for low power application in 0.35{\\mu}m\ntechnology have been presented. The proposed circuits utilize the merits of\nstacking technique with smaller leakage current and reduction in leakage power.\nConventional level shifter has been improved by addition of three NMOS\ntransistors, which shows total power consumption of 402.2264pW as compared to\n0.49833nW with existing circuit. Single supply level shifter has been modified\nwith addition of two NMOS transistors that gives total power consumption of\n108.641pW as compared to 31.06nW. Another circuit, contention mitigated level\nshifter (CMLS) with three additional transistors shows total power consumption\nof 396.75pW as compared to 0.4937354nW. Three proposed circuit's shows better\nperformance in terms of power consumption with a little conciliation in delay.\nOutput level of 3.3V has been obtained with input pulse of 1.6V for all\nproposed circuits.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.0507v1"
    },
    {
        "title": "Automatic Short -Answer Grading System (ASAGS)",
        "authors": [
            "P. Selvi",
            "A. K. Bnerjee"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Automatic assessment needs short answer based evaluation and automated\nassessment. Various techniques used are Ontology, Semantic similarity matching\nand Statistical methods. An automatic short answer assessment system is\nattempted in this paper. Through experiments performed on a data set, we show\nthat the semantic ASAGS outperforms methods based on simple lexical matching;\nresulting is up to 59 percent with respect to the traditional vector-based\nsimilarity metric.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.1742v1"
    },
    {
        "title": "Reusing optical supports using a simple software",
        "authors": [
            "Davide Quatrini",
            "Roberta De Angelis"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In this paper we show how it is possible to reuse optical supports (CDs,\nDVDs, etc.) without using chemical or physical transformation, only employing a\nsoftware that can easily run on domestic computers. This software can make\nobsolete optical supports useful again, converting de facto WEEE (Waste\nelectric and electronic equipment) into EEE (Electric and electronic\nequipment). A massive use of such a software can lead to a significant change\nin EEE every-day use, reducing its production to sustainable levels.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.1874v1"
    },
    {
        "title": "Towards Greener and Safer Mines",
        "authors": [
            "Dhruv Srivastava"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Miniaturised sensors and networking are technical proven concepts. Both the\ntechnologies are proven and various components e.g., sensors, controls, etc.\nare commercially available. Technology scene in above areas presents enormous\npossibilities for developing innovative applications for real life situations.\nMining operations in many countries have lot of scope for improving\nenvironmental and safety measures. Efforts have been made to develop a system\nto efficiently monitor a particular environment by deploying a wireless sensor\nnetwork using commercially available components. Wireless Sensor Network has\nbeen integrated with telecom network through a gateway using a suitable\ntopology which can be selected at the application layer. The developed system\ndemonstrates a way to connect wireless sensor network to external network which\nenables the distant administrator to access real time data and act expediently\nfrom long-distance to improve the environmental situation or prevent a\ndisaster. Potentially, it can be used to avoid the awful situations leading to\nterrible environment in underground mines. Keywords: Wireless sensor network,\nMine safety, Environment monitoring and telecom.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.2105v1"
    },
    {
        "title": "Biopsym : a learning environment for transrectal ultrasound guided\n  prostate biopsies",
        "authors": [
            "Janssoone Thomas",
            "Grgoire Chevreau",
            "Lucile Vadcard",
            "Pierre Mozer",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper describes a learning environment for image-guided prostate\nbiopsies in cancer diagnosis; it is based on an ultrasound probe simulator\nvirtually exploring real datasets obtained from patients. The aim is to make\nthe training of young physicians easier and faster with a tool that combines\nlectures, biopsy simulations and recommended exercises to master this medical\ngesture. It will particularly help acquiring the three-dimensional\nrepresentation of the prostate needed for practicing biopsy sequences. The\nsimulator uses a haptic feedback to compute the position of the virtual probe\nfrom three-dimensional (3D) ultrasound recorded data. This paper presents the\ncurrent version of this learning environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.2107v1"
    },
    {
        "title": "Usability Meets Instant Gratification on the Semantic Web",
        "authors": [
            "David Aumueller"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper presents a semantic wiki prototype application named SHAWN [later\nWikSAR] that allows structuring concepts within a wiki environment. To entice\nthe use of Semantic Web technologies applications need to offer both high\nusability and instant gratification. Concept creation is exceptionally easy in\nSHAWN since metadata as well as plain text is entered within a single edit box\non each wiki page in a self-explaining fashion. The entered data is immediately\nused for rendering sophisticated navigational means on the wiki. By editing\nsimple wiki pages ontologies emerge.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.2386v1"
    },
    {
        "title": "The emergence of the physical world from information processing",
        "authors": [
            "B. Whitworth"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper links the conjecture that the physical world is a virtual reality\nto the findings of modern physics. What is usually the subject of science\nfiction is here proposed as a scientific theory open to empirical evaluation.\nWe know from physics how the world behaves, and from computing how information\nbehaves, so whether the physical world arises from ongoing information\nprocessing is a question science can evaluate. A prima facie case for the\nvirtual reality conjecture is presented. If a photon is a pixel on a\nmulti-dimensional grid that gives rise to space, the speed of light could\nreflect its refresh rate. If mass, charge and energy all arise from processing,\nthe many conservation laws of physics could reduce to a single law of dynamic\ninformation conservation. If the universe is a virtual reality, then its big\nbang creation could be simply when the system was booted up. Deriving core\nphysics from information processing could reconcile relativity and quantum\ntheory, with the former how processing creates the space-time operating system\nand the latter how it creates energy and matter applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.3436v1"
    },
    {
        "title": "iCare: A Mobile Health Monitoring System for the Elderly",
        "authors": [
            "Ziyu Lv",
            "Feng Xia",
            "Guowei Wu",
            "Lin Yao",
            "Zhikui Chen"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper describes a mobile health monitoring system called iCare for the\nelderly. We use wireless body sensors and smart phones to monitor the wellbeing\nof the elderly. It can offer remote monitoring for the elderly anytime anywhere\nand provide tailored services for each person based on their personal health\ncondition. When detecting an emergency, the smart phone will automatically\nalert pre-assigned people who could be the old people's family and friends, and\ncall the ambulance of the emergency centre. It also acts as the personal health\ninformation system and the medical guidance which offers one communication\nplatform and the medical knowledge database so that the family and friends of\nthe served people can cooperate with doctors to take care of him/her. The\nsystem also features some unique functions that cater to the living demands of\nthe elderly, including regular reminder, quick alarm, medical guidance, etc.\niCare is not only a real-time health monitoring system for the elderly, but\nalso a living assistant which can make their lives more convenient and\ncomfortable.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.3852v1"
    },
    {
        "title": "The Use of Rapid Digital Game Creation to Learn Computational Thinking",
        "authors": [
            "Praveen Kuruvada",
            "Daniel Asamoah",
            "Nikunj Dalal",
            "Subhash Kak"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Computational Thinking (CT) has been described as a universally applicable\nability such as reading and writing. In this paper, we describe an innovative\npedagogy using Rapid Digital Game Creation (RDGC) for learning CT skills. RDGC\ninvolves the rapid building of digital games with high-level software that\nrequires little or no programming knowledge. We analyze how RDGC supports\nvarious CT concepts and how it may be mapped to equivalent Java concepts by\nbuilding the same game using both RDGC and Java. We discuss the potential\nbenefits of this approach for attracting computing majors, as a precursor to\nlearning formal programming languages, for learning domain knowledge, and for\nbridging the digital divide. We present the implications of this work for\nteachers and researchers.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.4093v1"
    },
    {
        "title": "VHDL Implementation and Verification of ARINC-429 Core",
        "authors": [
            "M. Kamaraju",
            "A. V. N. Tilak",
            "K. Lal Kishore",
            "K. Baburao"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Modern Avionics are controlled by sophisticated mission components in the\nAircraft. The control function is implemented via a standard ARINC-429 bus\ninterface. It is a two-wire point-topoint serial data bus for control\ncommunications in Avionics. The bus operates 12.5 or 100kb/sec, the\nimplementation is envisaged for one transmits and receive channel respectively.\nFurther the code can be modified for more no of independent Tx and Rx channels.\nAn on chip memory allotment on the FPGA will provide a buffer bank for storing\nthe incoming or outgoing data. For this purpose SRAM based FPGAs are utilized.\nThis flexible ARINC429 solution gives exactly what is needed for real time\napplications. The IP can be programmed to send an interrupt to the host and\nalso prepare it to process the data. Majority of the hardware function of\ndigital natures are embedded into a single FPGA by saving in terms of PCB board\nspace, power consumption and volume results. This paper deals with the\ndevelopment, implementation, simulation, and verification of ARINC_429 formats.\nThe IP core development is described in VHDL.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.5374v1"
    },
    {
        "title": "Simulating space and time",
        "authors": [
            "B. Whitworth"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This chapter asks if a virtual space-time could appear to those within it as\nour space-time does to us. A processing grid network is proposed to underlie\nnot just matter and energy, but also space and time. The suggested \"screen\" for\nour familiar three dimensional world is a hyper-sphere surface simulated by a\ngrid network. Light and matter then travel, or are transmitted, in the\n\"directions\" of the grid architecture. The processing sequences of grid nodes\ncreate time, as the static states of movies run together emulate events. Yet\nhere what exists are not the static states, but the dynamic processing between\nthem. Quantum collapse is the irreversible event that gives time its direction.\nIn this model, empty space is null processing, directions are node links, time\nis processing cycles, light is a processing wave, objects are wave tangles and\nenergy is the processing transfer rate. It describes a world where empty space\nis not empty, space warps, time dilates, and everything began when this virtual\nuniverse \"booted up\".\n",
        "pdf_link": "http://arxiv.org/pdf/1011.5499v1"
    },
    {
        "title": "Using the C4ISR Architecture Framework as a Tool to Facilitate VV&A for\n  Simulation Systems within the Military Application Domain",
        "authors": [
            "Andreas Tolk"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  To harmonize the individual architectures of the different commands,\nservices, and agencies dealing with the development and procurement of Command,\nControl, Communications, Computing, Surveillance, Reconnaissance, and\nIntelligence (C4ISR) systems, the C4ISR Architecture Framework was developed\nbased on existing and matured modeling techniques and methods. Within a short\nperiod, NATO adapted this method family as the NATO Consultation, Command, and\nControl (C3) System Architecture Framework to harmonize the efforts of the\ndifferent nations. Based on these products, for every system to be fielded to\nbe used in the US Armed Forces, a C4I Support Plan (C4ISP) has to be developed\nenabling the integration of the special system into the integrated C4I\nArchitecture. The tool set proposed by these architecture frameworks connects\noperational views of the military user, system views of the developers, and the\ntechnical views for standards and integration methods needed to make the\nnetwork centric system of systems work. The tools are therefore logically a\nvaluable backbone for Verification, Validation, and Accreditation (VV&A). Their\napplication is not limited to C4ISR systems; they can be used to define\nrequirements and connected solutions and algorithms of Modeling and Simulation\n(M&S) systems as well. Especially for M&S systems to be used in connection with\nC4ISR system, the use of the C4ISR Architecture Framework would not only be a\nhelp, but can nearly be seen to be necessary to avoid double work and foster\nreuse and interoperability from the first stages of a project on. To enable the\nreader to build his own picture, the respective tools used and their\napplication in the context of VV&A will be explained in form of an overview.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.5656v1"
    },
    {
        "title": "Decision Support Systems - Technical Prerequisites and Military\n  Requirements",
        "authors": [
            "Andreas Tolk",
            "Dietmar Kunde"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Decision Support Systems in the sense of online alternative course of action\n(ACAO) development and analysis as well as tools for online Development of\nDoctrine and Tactics Techniques, and Procedures (DTTP) for support to\noperations make it possible to evaluate and forecast the command and control\nprocesses and the performance capabilities of the friendly and enemy forces and\nother decision relevant factors, support the military commander (brigade and\nhigher) and his staff in their headquarter by increasing their ability to\nidentify own opportunities, support all phases of the command and control\nprocess, use computer based, automatic and closed models, that can be adapted\nto the current situation.\n  Objective of the paper is to present the results of studies conducted in\nGermany on behalf of the German Ministry of Defense with the objective to work\nout the conceptual basis for decision support systems and to evaluate, how this\ntechnique will influence the command and control system of the army of the\nfederal armed forces. In addition, international works are considered as well.\nIn this paper, technical and operational requirements are derived and described\nin detail that have to be met in order to support the warfighter by integrated\nmeans of applied Operations Research ranging from simple optimization\nalgorithms to complex simulation federations comprising different systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.5661v1"
    },
    {
        "title": "The Light of Existence",
        "authors": [
            "B. Whitworth"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This chapter derives the properties of light from the properties of\nprocessing, including its ability to be both a wave and a particle, to respond\nto objects it doesn't physically touch, to take all paths to a destination, to\nchoose a route after it arrives, and to spin both ways at once as it moves.\nHere a photon is an entity program spreading as a processing wave of instances.\nIt becomes a \"particle\" if any part of it overloads the grid network that runs\nit, causing the photon program to reboot and restart at a new node. The\n\"collapse of the wave function\" is how quantum processing creates what we call\na physical photon. This informational approach gives insights into issues like\nthe law of least action, entanglement, superposition, counterfactuals, the\nholographic principle and the measurement problem. The conceptual cost is that\nphysical reality is a quantum processing output, i.e. virtual.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.5705v2"
    },
    {
        "title": "Extending ArXiv.org to Achieve Open Peer Review and Publishing",
        "authors": [
            "Axel Boldt"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Today's peer review process for scientific articles is unnecessarily opaque\nand offers few incentives to referees. Likewise, the publishing process is\nunnecessarily inefficient and its results are only rarely made freely available\nto the public. Here we outline a comparatively simple extension of arXiv.org,\nan online preprint archive widely used in the mathematical and physical\nsciences, that addresses both of these problems. Under the proposal, editors\ninvite referees to write public and signed reviews to be attached to the posted\npreprints, and then elevate selected articles to \"published\" status.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.6590v1"
    },
    {
        "title": "Functional Categories of Support to Operations in Military Information\n  Systems",
        "authors": [
            "Andreas Tolk"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  In order to group the functional requirements for support to operations by\nmodern information systems systematically, the NATO Code of best Practise\n(COBP) for C2 Assessment defines three domain areas: Battlespace Visualization,\nDecision Making, and Battle Management Functions. In addition, within an domain\noverlapping information grid of the information system, necessary functions for\nassessing and disseminating the information are capsulated. For all three\ndomains, including the overlapping information grid, the respective\nrequirements for functional support have to be met be future command, control,\ncommunications, and intelligence (C3I) systems.\n  The paper describes the functional categories of the three domains having\nbeen defined for article 5 operations, extends them to meet the requirements\nfor operations other than war (OOTW), and gives some examples how modules of\nsimulation systems can deliver respective support functions. In addition,\nreferences defining migration procedures for legacy systems to enable a smooth\nchange from the old to the new C3I paradigm are given.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.6670v1"
    },
    {
        "title": "Avoiding another Green Elephant - A Proposal for the Next Generation HLA\n  based on the Model Driven Architecture",
        "authors": [
            "Andreas Tolk"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  When looking through the proceedings of the recent Simulation\nInteroperability Workshops, a lot of papers - some of them even awarded by the\ncommittee - are dealing with alternative concepts outside or beyond the High\nLevel Architecture (HLA): Web Services, the extensible Markup Language (XML),\nJava Beans, Simple Object Access Protocol (SOAP), etc. Similarly, requirements\ndriven by interoperability issues have resulted in the need to use meta\nmodeling, adaptive models, and common repositories. The use of the Unified\nModeling Language (UML) as a model description language is also rapidly\nbecoming a standard. All these concepts have relations to the HLA, but they are\nnot part of it. There seems to be the danger that HLA is overrun by respective\ndevelopments of the free market and will become irrelevant finally. ... This\npaper introduces the MDA concept and shows, how the HLA can be integrated to\nbecome a standard stub for simulation applications of legacy systems, systems\nunder development, and systems of the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1011.6671v1"
    },
    {
        "title": "Communication model of emuStudio emulation platform",
        "authors": [
            "Peter Jakubo",
            "Slavomr imok",
            "Norbert dm"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Within the paper a description of communication model of plug-in based\nemuStudio emulation platform is given. The platform mentioned above allows the\nemulation of whole computer systems, configurable to the level of its\ncomponents, represented by the plug-in modules of the platform. Development\ntasks still are in progress at the home institution of the authors. Currently\nthe platform is exploited for teaching purposes within subjects aimed at\nmachine-oriented languages and computer architectures. Versatility of the\nplatform, given by its plug-in based architecture is a big advantage, when used\nas a teaching support tool. The paper briefly describes the emuStudio platform\nat its introductory part and then the mechanisms of inter-module communication\nare described.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.0047v1"
    },
    {
        "title": "Towards a Spiking Neural P Systems OS",
        "authors": [
            "Ammar Adl",
            "Amr Badr",
            "Ibrahim Farag"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper is an attempt to incorporate the idea of spiking neural P systems\nas an early seed into the area of Operating System Design, regarding their\ncapability to solve some classical computer science problems. It is reflecting\nthe power of such systems to simulate well known parallel computational models,\nlike logic gates, arithmetic operation, and sorting. In these devices, the time\n(when the neurons fire and/or spike) plays an essential role. For instance, the\nresult of a computation is the time between the moments when a specified neuron\nspikes. Seen as number computing devices, SN P systems are shown to be\ncomputationally complete, and with such capabilities, arithmetic operations,\nlogic, and timing, some first steps could be taken towards an OS design.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.0326v1"
    },
    {
        "title": "Fundamentals of Semantic Web Technologies in Medical Environments: a\n  case in breast cancer risk estimation",
        "authors": [
            "Iker Huerga",
            "Ainhoa Serna",
            "Jon Kepa Gerrikagoitia"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Risk estimation of developing breast cancer poses as the first prevention\nmethod for early diagnosis. Furthermore, data integration from different\ndepartments involved in the process plays a key role. In order to guarantee\npatient safety, the whole process should be orchestrated and monitored\nautomatically. Support for the solution will be a linked data cloud, composed\nby all the departments that take part in the process, combined with rule\nengines.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.1636v1"
    },
    {
        "title": "semanticSBML 2.0 - A Collection of Online Services for SBML Models",
        "authors": [
            "Falko Krause",
            "Marvin Schulz",
            "Timo Lubitz",
            "Wolfram Liebermeister"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  semanticSBML 2.0 is an online collection of services for the work with\nbiochemical network models in SBML format.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.1664v1"
    },
    {
        "title": "Instantaneous, non-squeezed, noise-based logic",
        "authors": [
            "Ferdinand Peper",
            "Laszlo B. Kish"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Noise-based logic, by utilizing its multidimensional logic hyperspace, has\nsignificant potential for low-power parallel operations in beyond-Moore-chips.\nHowever universal gates for Boolean logic thus far had to rely on either time\naveraging to distinguish signals from each other or, alternatively, on squeezed\nlogic signals, where the logic-high was represented by a random process and the\nlogic-low was a zero signal. A major setback is that squeezed logic variables\nare unable to work in the hyperspace, because the logic-low zero value sets the\nhyperspace product vector to zero. This paper proposes Boolean universal logic\ngates that alleviate such shortcomings. They are able to work with non-squeezed\nlogic values where both the high and low values are encoded into nonzero,\nbipolar, independent random telegraph waves. Non-squeezed universal Boolean\nlogic gates for spike-based brain logic are also shown. The advantages vs.\ndisadvantages of the two logic types are compared.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.3531v1"
    },
    {
        "title": "Solving a real-life large-scale energy management problem",
        "authors": [
            "Steffen Godskesen",
            "Thomas Sejr Jensen",
            "Niels Kjeldsen",
            "Rune Larsen"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper introduces a three-phase heuristic approach for a large-scale\nenergy management and maintenance scheduling problem. The problem is concerned\nwith scheduling maintenance and refueling for nuclear power plants up to five\nyears into the future, while handling a number of scenarios for future demand\nand prices. The goal is to minimize the expected total production costs. The\nfirst phase of the heuristic solves a simplified constraint programming model\nof the problem, the second performs a local search, and the third handles\noverproduction in a greedy fashion.\n  This work was initiated in the context of the ROADEF/EURO Challenge 2010, a\ncompetition organized jointly by the French Operational Research and Decision\nSupport Society, the European Operational Research Society, and the European\nutility company Electricite de France. In the concluding phase of the\ncompetition our team ranked second in the junior category and sixth overall.\n  After correcting an implementation bug in the program that was submitted for\nevaluation, our heuristic solves all ten real-life instances, and the solutions\nobtained are all within 2.45% of the currently best known solutions. The\nresults given here would have ranked first in the original competition.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.4691v1"
    },
    {
        "title": "Software Oriented Data Monitoring System",
        "authors": [
            "Phani Nandan K",
            "Pavan Kumar K"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This project \"Software Oriented Data Monitoring System\" deals with real time\nmonitoring of patients' parameters like body temperature, heart rate etc. The\nparameters are checked at regular intervals and Short Messaging Service (SMS)\nis sent to concerned doctor regarding the measured values. If the obtained\nparameters are above or below critical values, an alert SMS is also sent to the\nconcerned doctor. This system is very much useful in hospitals, which saves the\nvaluable time of the doctor who otherwise will have to monitor the patients\nthroughout the day. Here the analog data from the sensors is first converted\ninto digital form and is fed to the parallel port of the computer. This data\nobtained is converted into useful parameters, which is monitored and checked\nfor safe limits. Appropriate SMS is sent to the doctor depending on whether the\nrequest is from an alert or routine signal. This is possible by interfacing a\nmobile phone (Siemens c35i) to the serial port of the computer. The SMS is sent\nfrom the computer using proper AT commands.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.4739v2"
    },
    {
        "title": "Universal regular autonomous asynchronous systems: omega-limit sets,\n  invariance and basins of attraction",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The asynchronous systems are the non-deterministic real time-binary models of\nthe asynchronous circuits from electrical engineering. Autonomy means that the\ncircuits and their models have no input. Regularity means analogies with the\ndynamical systems, thus such systems may be considered to be the real time\ndynamical systems with a 'vector field' {\\Phi}:{0,1}^2 \\rightarrow {0,1}^2.\nUniversality refers to the case when the state space of the system is the\ngreatest possible in the sense of the inclusion. The purpose of the paper is\nthat of defining, by analogy with the dynamical systems theory, the\n{\\omega}-limit sets, the invariance and the basins of attraction of the\nuniversal regular autonomous asynchronous systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.5838v1"
    },
    {
        "title": "The model of the ideal rotary element of Morita",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Reversible computing is a concept reflecting physical reversibility. Until\nnow several reversible systems have been investigated. In a series of papers\nKenichi Morita defines the rotary element RE, that is a reversible logic\nelement. By reversibility, he understands that 'every computation process can\nbe traced backward uniquely from the end to the start. In other words, they are\nbackward deterministic systems'. He shows that any reversible Turing machine\ncan be realized as a circuit composed of RE's only. Our purpose in this paper\nis to use the asynchronous systems theory and the real time for the modeling of\nthe ideal rotary element\n",
        "pdf_link": "http://arxiv.org/pdf/1012.5842v3"
    },
    {
        "title": "A Chronology of Torah Cryptography",
        "authors": [
            "Grenville J. Croll"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Regarding some papers and notes submitted to, or presented at, the second\ncongress of the International Torah Codes Society in Jerusalem, Israel, June\n2000.\n",
        "pdf_link": "http://arxiv.org/pdf/1101.5313v1"
    },
    {
        "title": "Computer Aided Tolerancing Based on Analysis and Synthetizes of\n  Tolerances Method",
        "authors": [
            "Abdessalem Hassani",
            "Nizar Aifaoui",
            "Abdelmajid Benamara",
            "Serge Samper"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The tolerancing step has a great importance in the design process. It\ncharacterises the relationship between the different sectors of the product\nlife cycle: Design, Manufacturing and Control. We can distinguish several\nmethods to assist the tolerancing process in the design. Based on arithmetic\nand statistical method, this paper presents a new approach of analysis and\nverification of tolerances. The chosen approach is based on the Worst Case\nMethod as an arithmetic method and Monte Carlo method as a statistical method.\nIn this paper, we compare these methods and we present our main approach, which\nis validated using an example of 1 D tolerancing.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.3112v1"
    },
    {
        "title": "Numerical investigation of a solar greenhouse tunnel drier for drying of\n  copra",
        "authors": [
            "S. Sadodin",
            "T. T. Kashani"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  A numerical investigation of a solar greenhouse tunnel drier (SGTD) has been\nperformed. In the present study, the geometry of the tunnel roof is assumed\nsemi-circular which is covered with a UV (200\\mu) stabilized polyethylene film.\nThe simulated SGTD reduces moisture of copra from 52.2% to 8% in 55 h under\nfull load conditions. A system of partial differential equations describing\nheat and moisture transfer during drying copra in the solar greenhouse dryer\nwas developed and this system of non-linear partial differential equations was\nsolved numerically using the finite difference method (FDM). The numerical\nsolution was programmed in Compaq Visual FORTRAN version 6.5. The simulated\nresults reasonably agreed with the experimental data for solar drying copra.\nThis model can be used to provide the design data and is also essential for\noptimal design of the dryer. For instance the user is able to change the\nradiation properties of the roof cover for different materials of roof cover.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.4522v1"
    },
    {
        "title": "P ORTOLAN: a Model-Driven Cartography Framework",
        "authors": [
            "Vincent Mahe",
            "Salvador Martinez Perez",
            "Guillaume Doux",
            "Hugo Brunelire",
            "Jordi Cabot"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Processing large amounts of data to extract useful information is an\nessential task within companies. To help in this task, visualization techniques\nhave been commonly used due to their capacity to present data in synthesized\nviews, easier to understand and manage. However, achieving the right\nvisualization display for a data set is a complex cartography process that\ninvolves several transformation steps to adapt the (domain) data to the\n(visualization) data format expected by visualization tools. To maximize the\nbenefits of visualization we propose Portolan, a generic model-driven\ncartography framework that facilitates the discovery of the data to visualize,\nthe specification of view definitions for that data and the transformations to\nbridge the gap with the visualization tools. Our approach has been implemented\non top of the Eclipse EMF modeling framework and validated on three different\nuse cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.4684v1"
    },
    {
        "title": "An Autonomous Long Range Monitoring System For Emergency Operators",
        "authors": [
            "Matteo Lanati",
            "Davide Curone",
            "Emanuele Lindo Secco",
            "Giovanni Magenes",
            "Paolo Gamba"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Miniaturization and portability of new electronics lead up to wearable\ndevices embedded within garments: a European program called ProeTEX developed\nmulti-purpose sensors integrated within emergency operators' garments in order\nto monitor their health state and the surrounding environment. This work deals\nwith the development of an autonomous Long Range communication System (LRS),\nsuitable to transmit data between operators' equipment and the local command\npost, where remote monitoring software is set up. The LRS infrastructure is\nbased on Wi-Fi protocol and modular architecture. Field tests carried out on\nthe developed prototype showed a high reliability in terms of correctly\nexchanged data and recovering capabilities in case of temporary disconnection,\ndue to the operator's movements.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.5670v1"
    },
    {
        "title": "Modelling dynamic route choice of pedestrians to assess the criticality\n  of building evacuation",
        "authors": [
            "A. U. Kemloh Wagoum",
            "A. Seyfried",
            "S. Holl"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  This paper presents an event-driven way finding algorithm for pedestrians in\nan evacuation scenario, which operates on a graph-based structure. The\nmotivation of each pedestrian is to leave the facility. The events used to\nredirect pedestrians include the identification of a jam situation and/or\nidentification of a better route than the current. This study considers two\ntypes of pedestrians: familiar and unfamiliar with the facility. Four\nstrategies are modelled to cover those groups. The modelled strategies are the\nshortest path (local and global); They are combined with a quickest path\napproach, which is based on an observation principle. In the quickest path\napproach, pedestrians take their decisions based on the observed environment\nand are routed dynamically in the network using an appropriate cost benefit\nanalysis function. The dynamic modelling of route choice with different\nstrategies and types of pedestrians considers the manifold of in uences which\nappears in the real system and raises questions about the criticality of an\nevacuation process. To address this question criteria are elaborated. The\ncriteria we focus on in this contribution are the evacuation time, the\nindividual times spent in jam, the jam size evolution and the overall jam size\nitself. The in uences of the different strategies on those evaluation criteria\nare investigated. The sensibility of the system to disturbances (e.g. broken\nescape route) is also analysed. Keywords: pedestrian dynamics, routing,\nquickest path, evacuation, jam, critical state\n",
        "pdf_link": "http://arxiv.org/pdf/1103.4080v1"
    },
    {
        "title": "Medical Image Denoising using Adaptive Threshold Based on Contourlet\n  Transform",
        "authors": [
            "S. Satheesh",
            "KVSVR Prasad"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Image denoising has become an essential exercise in medical imaging\nespecially the Magnetic Resonance Imaging (MRI). This paper proposes a medical\nimage denoising algorithm using contourlet transform. Numerical results show\nthat the proposed algorithm can obtained higher peak signal to noise ratio\n(PSNR) than wavelet based denoising algorithms using MR Images in the presence\nof AWGN.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.4907v1"
    },
    {
        "title": "Generating contour lines using different elevation data file formats",
        "authors": [
            "P. S. Hiremath",
            "B. G. Kodge"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  In terrain mapping, there are so many ways to measure and estimate the\nterrain measurements like contouring, vertical profiling, hill shading,\nhypsometric tinting, perspective view, etc. Here in this paper we are using the\ncontouring techniques to generate the contours for the different digital\nelevation data like DEM, HGT, IMG etc. The elevation data is captured in dem,\nhgt and img formats of the same projected area and the contour is generated\nusing the existing techniques and applications. The exact differences, errors\nof elevation (contour) intervals, slopes and heights are analyzed and\nrecovered.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.4914v1"
    },
    {
        "title": "Distributed k-Core Decomposition",
        "authors": [
            "Alberto Montresor",
            "Francesco De Pellegrini",
            "Daniele Miorandi"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Among the novel metrics used to study the relative importance of nodes in\ncomplex networks, k-core decomposition has found a number of applications in\nareas as diverse as sociology, proteinomics, graph visualization, and\ndistributed system analysis and design. This paper proposes new distributed\nalgorithms for the computation of the k-core decomposition of a network, with\nthe purpose of (i) enabling the run-time computation of k-cores in \"live\"\ndistributed systems and (ii) allowing the decomposition, over a set of\nconnected machines, of very large graphs, that cannot be hosted in a single\nmachine. Lower bounds on the algorithms complexity are given, and an exhaustive\nexperimental analysis on real-world graphs is provided.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.5320v2"
    },
    {
        "title": "Performance evaluation of FD-SOI Mosfets for different metal gate work\n  function",
        "authors": [
            "Deepesh Ranka",
            "Ashwani K. Rana",
            "Rakesh Kumar Yadav",
            "Kamalesh Yadav",
            "Devendra Giri"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Fully depleted (FD) Silicon on Insulator (SOI) metal oxide Field Effect\nTransistor (MOSFET) Is the Leading Contender for Sun 65nm Regime. This paper\npresents a study of effects of work functions of metal gate on the performance\nof FD-SOI MOSFET. Sentaurus TCAD simulation tool is used to investigate the\neffect of work function of gates ont he performance FDSOI MOSFET. Specific\nchannel length of the device that had been concentrated is 25nm. From\nsimulation we observed that by changing the work function of the metal gates of\nFD-SOI MOSFET we can change the threshold voltage. Hence by using this\ntechnique we can set the appropriate threshold voltage of FD-SOI MOSFET at same\nvoltage and we can decrease the leakage current, gate tunneling current and\nshort channel effects and increase drive current.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.0824v1"
    },
    {
        "title": "Simulation and Performance Analysis of Adaptive Filtering Algorithms in\n  Noise Cancellation",
        "authors": [
            "Lilatul Ferdouse",
            "Nasrin Akhter",
            "Tamanna Haque Nipa",
            "Fariha Tasmin Jaigirdar"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Noise problems in signals have gained huge attention due to the need of\nnoise-free output signal in numerous communication systems. The principal of\nadaptive noise cancellation is to acquire an estimation of the unwanted\ninterfering signal and subtract it from the corrupted signal. Noise\ncancellation operation is controlled adaptively with the target of achieving\nimproved signal to noise ratio. This paper concentrates upon the analysis of\nadaptive noise canceller using Recursive Least Square (RLS), Fast Transversal\nRecursive Least Square (FTRLS) and Gradient Adaptive Lattice (GAL) algorithms.\nThe performance analysis of the algorithms is done based on convergence\nbehavior, convergence time, correlation coefficients and signal to noise ratio.\nAfter comparing all the simulated results we observed that GAL performs the\nbest in noise cancellation in terms of Correlation Coefficient, SNR and\nConvergence Time. RLS, FTRLS and GAL were never evaluated and compared before\non their performance in noise cancellation in terms of the criteria we\nconsidered here.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.1962v1"
    },
    {
        "title": "Evolutionary Foundations of Mathematics",
        "authors": [
            "Ruhi Tuncer"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  We propose a simple cognitive model where qualitative and quantitative com-\nparisons enable animals to identify objects, associate them with their\nproperties held in memory and make naive inference. Simple notions like\nequivalence re- lations, order relations are used. We then show that such\nprocesses are at the root of human mathematical reasoning by showing that the\nelements of totally ordered sets satisfy the Peano axioms. The process through\nwhich children learn counting is then formalized. Finally association is\nmodeled as a Markov process leading to a stationary distribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1104.3525v1"
    },
    {
        "title": "Access Control Mechanisms for Semantic Web services-A Discussion on\n  Requirements & Future Directions",
        "authors": [
            "Mandeep Kaur Gondara"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Semantic Web is an open, distributed, and dynamic environment where access to\nresources cannot be controlled in a safe manner unless the access decision\ntakes into account during discovery of web services. Security becomes the\ncrucial factor for the adoption of the semantic based web services. An access\ncontrol means that the users must fulfill certain conditions in order to gain\naccess over web services. Access control is important in both perspectives i.e.\nlegal and security point of view. This paper discusses important requirements\nfor effective access control in semantic web services which have been extracted\nfrom the literature surveyed. I have also discussed open research issues in\nthis context, focusing on access control policies and models in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.0141v1"
    },
    {
        "title": "Comparative analysis of the accuracy of the distance to the observed\n  object for geometric methods",
        "authors": [
            "Sergey Alexandrovich Pyunninen"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The article presents a comparative analysis of the accuracy of the distance\nto the observed object for geometric methods in noisy observations of\nbearings-only information.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.0200v1"
    },
    {
        "title": "Impact of Limited Feedback on MIMO-OFDM Systems using Joint Beamforming",
        "authors": [
            "Najoua Achoura And Ridha Bouallegue"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  In multi input multi output antenna systems, beamforming is a technique for\nguarding against the negative effects of fading. However, this technique\nrequires the transmitter to have perfect knowledge of the channel which is\noften not available a priori. A solution to overcome this problem is to design\nthe beamforming vector using a limited number of feedback bits sent from the\nreceiver to the transmitter. In the case of limited feedback, the beamforming\nvector is limited to lie in a codebook that is known to both the transmitter\nand receiver.When the feedback is strictly limited, important issues are how to\nquantize the information needed at the transmitter and how much improvement in\nassociated performance can be obtained as a function of the amount of feedback\navailable.In this paper channel quantization schema using simple approach to\ncodebook design (random vector quantization)is illustrated. Performance results\nshow that even with a few bits of feedback, performance can be close to that\nwith perfect channel knowledge at the transmitter.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.0362v1"
    },
    {
        "title": "Design of Thin-Film-Transistor (TFT) arrays using current mirror\n  circuits for Flat Panel Detectors (FPDs)",
        "authors": [
            "Nur Sultan Salahuddin",
            "Michel Paindavoine",
            "Nurul Huda",
            "Michel Parmentier"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  We designed 4x4 matrix TFTs arrays using current mirror amplifiers.\nAdvantages of current mirror amplifiers are they need less requiring switches\nand the conversion time is short. The TFTs arrays 4x4 matrix using current\nmirror circuits have been fabricated and tested with success. The TFTs array\ndirectly can process signals coming from 16 pixels in the same node. This\nenables us to make the summation of the light intensities of close pixels\nduring a reading.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.1407v1"
    },
    {
        "title": "Development of Active Pixel Photodiode Sensors for Gamma Camera\n  Application",
        "authors": [
            "Nur Sultan Salahuddin",
            "Michel Paindavoine",
            "Brahmantyo Heruseto",
            "Michel Parmentier"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  We designed new photodiodes sensors including current mirror amplifiers.\nThese photodiodes have been fabricated using a CMOS 0.6 micrometers process\nfrom Austria Micro System (AMS). The Photodiode areas are respectiveley 1mm x\n1mm and 0.4mm x 0.4mm with fill factor 98 % and total chip area is 2 square\nmillimetres. The sensor pixels show a logarithmic response in illumination and\nare capable of detecting very low blue light (less than 0.5 lux) . These\nresults allow to use our sensor in new Gamma Camera solid-state concept.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.1412v1"
    },
    {
        "title": "A Novel Method for Calculating Demand Not Served for Transmission\n  Expansion Planning",
        "authors": [
            "Neeraj Gupta",
            "Rajiv Shekhar",
            "Prem Kumar Kalra"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Restructuring of the power market introduced demand uncertainty in\ntransmission expansion planning (TEP), which in turn also requires an accurate\nestimation of demand not served (DNS). Unfortunately, the graph theory based\nminimum-cut maximum-flow (MCMF) approach does not ensure that electrical laws\nare followed. Nor can it be used for calculating DNS at individual buses. In\nthis letter, we propose a generalized load flow based methodology for\ncalculating DNS. This procedure is able to calculate simultaneously generation\nnot served (GNS) and wheeling loss (WL). Importantly, the procedure is able to\nincorporate the effect of I2R losses, excluded in MCMF approach. Case study on\na 5-bus IEEE system shows the effectiveness of the proposed approach over\nexisting method.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.3162v1"
    },
    {
        "title": "Book review: Katy Brner, Atlas of Science: Visualizing What We Know.\n  Cambridge, MA/ London UK: The MIT Press, 2010",
        "authors": [
            "Loet Leydesdorff"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Katy B\\\"orner has written a wonderful book about visualization that makes our\nfield of scientometrics accessible to much larger audiences. The book is to be\nread in relation to the ongoing series of exhibitions entitled \"Places &\nSpaces: Mapping Science\" currently touring the world. The book also provides\nthe scholarly background to the exhibitions. It celebrates scientometrics as\nthe discipline in the background that enables us to visualize the evolution of\nknowledge as the acumen of human civilization.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.3469v1"
    },
    {
        "title": "A Knowledge base model for complex forging die machining",
        "authors": [
            "Kwamiwi Mawussi",
            "Laurent Pierre Tapie"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Recent evolutions on forging process induce more complex shape on forging\ndie. These evolutions, combined with High Speed Machining (HSM) process of\nforging die lead to important increase in time for machining preparation. In\nthis context, an original approach for generating machining process based on\nmachining knowledge is proposed in this paper. The core of this approach is to\ndecompose a CAD model of complex forging die in geometric features.\nTechnological data and topological relations are aggregated to a geometric\nfeature in order to create machining features. Technological data, such as\nmaterial, surface roughness and form tolerance are defined during forging\nprocess and dies design. These data are used to choose cutting tools and\nmachining strategies. Topological relations define relative positions between\nthe surfaces of the die CAD model. After machining features identification\ncutting tools and machining strategies currently used in HSM of forging die,\nare associated to them in order to generate machining sequences. A machining\nprocess model is proposed to formalize the links between information imbedded\nin the machining features and the parameters of cutting tools and machining\nstrategies. At last machining sequences are grouped and ordered to generate the\ncomplete die machining process. In this paper the identification of geometrical\nfeatures is detailed. Geometrical features identification is based on machining\nknowledge formalization which is translated in the generation of maps from STL\nmodels. A map based on the contact area between cutting tools and die shape\ngives basic geometrical features which are connected or not according to the\ncontinuity maps. The proposed approach is illustrated by an application on an\nindustrial study case which was accomplished as part of collaboration.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.4958v1"
    },
    {
        "title": "Relaxing Tight Frame Condition in Parallel Proximal Methods for Signal\n  Restoration",
        "authors": [
            "Nelly Pustelnik",
            "Jean-Christophe Pesquet",
            "Caroline Chaux"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  A fruitful approach for solving signal deconvolution problems consists of\nresorting to a frame-based convex variational formulation. In this context,\nparallel proximal algorithms and related alternating direction methods of\nmultipliers have become popular optimization techniques to approximate\niteratively the desired solution. Until now, in most of these methods, either\nLipschitz differentiability properties or tight frame representations were\nassumed. In this paper, it is shown that it is possible to relax these\nassumptions by considering a class of non necessarily tight frame\nrepresentations, thus offering the possibility of addressing a broader class of\nsignal restoration problems. In particular, it is possible to use non\nnecessarily maximally decimated filter banks with perfect reconstruction, which\nare common tools in digital signal processing. The proposed approach allows us\nto solve both frame analysis and frame synthesis problems for various noise\ndistributions. In our simulations, it is applied to the deconvolution of data\ncorrupted with Poisson noise or Laplacian noise by using (non-tight) discrete\ndual-tree wavelet representations and filter bank structures.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.5275v4"
    },
    {
        "title": "Publicity of the intimate text (the blog studying and publication)",
        "authors": [
            "Yulia V. Buldakova"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  One of the important problems of a modern society - communications. At all\nreadiness of this question both humanitarian, and engineering science, process\nof transfer and information reception remains in the centre of attention of\nresearchers. The dialogue phenomenon in a network becomes the significant\nfactor of such attention. The fact of the publication of blogs and increasing\npopularity of bloggers is connected, in our opinion, with an increasing\nopenness of a blog sphere (each record can be commented any user), and\naccordingly, the Internet as a whole.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.5875v1"
    },
    {
        "title": "Re-thinking Enrolment in Identity Card Schemes",
        "authors": [
            "Ali M. Al-Khouri"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Many countries around the world have initiated national ID card programs in\nthe last decade. These programs are considered of strategic value to\ngovernments due to its contribution in enhancing existing identity management\nsystems. Considering the total cost of such programs which goes up to billions\nof dollars, the success in attaining their objectives is a crucial element in\nthe agendas of political systems in countries worldwide. Our experience in the\nfield shows that many of such projects have been challenged to deliver their\nprimary objectives of population enrolment, and therefore resulted in failing\nto meet deadlines and keeping up with budgetary constraints. The purpose of\nthis paper is to explain the finding of a case study action research aimed to\nintroduce a new approach to how population are enrolled in national ID\nprograms. This is achieved through presenting a case study of a business\nprocess reengineering initiative undertaken in the UAE national ID program. The\nscope of this research is limited to the enrolment process within the program.\nThis article also intends to explore the possibilities of significant results\nwith the new proposed enrolment approach with the application of BPR. An\noverview of the ROI study has been developed to illustrate such efficiencies.\n",
        "pdf_link": "http://arxiv.org/pdf/1105.6361v1"
    },
    {
        "title": "A Comparative Study Between a Micromechanical Cantilever Resonator and\n  MEMS-based Passives for Band-pass Filtering Application",
        "authors": [
            "J. Basu",
            "A. Bhattacharya",
            "S. Chakraborty",
            "T. K. Bhattacharyya"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Over the past few years, significant growth has been observed in using MEMS\nbased passive components in the RF microelectronics domain, especially in\ntransceiver components. This is due to some excellent properties of the MEMS\ndevices like low loss, excellent isolation etc. in the microwave frequency\ndomain where the on-chip passives normally tend to become leakier and degrades\nthe transceiver performance. This paper presents a comparative analysis between\nMEMS-resonator based and MEMS-passives based band-pass filter configurations\nfor RF applications, along with their design, simulation, fabrication and\ncharacterization. The filters were designed to have a center frequency of 455\nkHz, meant for use as the intermediate frequency (IF) filter in superheterodyne\nreceivers. The filter structures have been fabricated in PolyMUMPs process, a\nthree-polysilicon layer surface micromachining process.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.1894v1"
    },
    {
        "title": "Characterization of 3D surface topography in 5-axis milling",
        "authors": [
            "Yann Quinsat",
            "Sylvain Lavernhe",
            "Claire Lartigue"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Within the context of 5-axis free-form machining, CAM software offers various\nways of tool-path generation, depending on the geometry of the surface to be\nmachined. Therefore, as the manufactured surface quality results from the\nchoice of the machining strategy and machining parameters, the prediction of\nsurface roughness in function of the machining conditions is an important issue\nin 5-axis machining. The objective of this paper is to propose a simulation\nmodel of material removal in 5-axis based on the N-buffer method and\nintegrating the Inverse Kinematics Transformation. The tooth track is linked\nwith the velocity giving the surface topography resulting from actual machining\nconditions. The model is assessed thanks to a series of sweeping over planes\naccording to various tool axis orientations and cutting conditions. 3D surface\ntopography analyses are performed through the new areal surface roughness\nparameters proposed by recent standards.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.2077v1"
    },
    {
        "title": "Optimisation de la taille de la srie: illustration par un cas\n  industriel de sous-traitance mcanique",
        "authors": [
            "Barbara Lyonnet",
            "Maurice Pillet",
            "Magali Pralus"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Reducing costs of manufactured products is one of the key issues of\ncompanies. Bar turning companies (mechanical subcontracting companies) are\nfaced with the following dilemma: use a pull strategy or use a push strategy.\nInstinctively these companies produce more than demand required by customers.\nThis strategy allows them to respond to requests forecasts and reduce their\ncost of changeover time. These companies make a bet on sales opportunities and\nthink to realize an additional profit. We have tried to find in this study to\nprovide elements to know the limits of this strategy. Our proposal focuses on\ndeveloping a model to support the decision taking into account the mix of\nopportunities, economic constraints and mean constraints. This model features\nthe particular importance of high rates of ownership and the risk of not\nselling.\n  R\\'eduire les co\\^uts de revient des produits fabriqu\\'es est une des\nprobl\\'ematiques essentielles des entreprises d'aujourd'hui. Les entreprises de\nd\\'ecolletage (entreprises de sous-traitance m\\'ecanique) sont confront\\'ees au\ndilemme suivant : produire juste la demande client ou produire plus.\nInstinctivement ces entreprises, dont les temps de changement de s\\'erie sont\n\\'elev\\'es, cherchent \\`a produire plus que la demande exig\\'ee par le client.\nCette strat\\'egie leur permet de r\\'epondre \\`a des demandes pr\\'evisionnelles\net r\\'eduire ainsi le co\\^ut de revient des produits. Ces entreprises\nr\\'ealisent un pari sur les opportunit\\'es de vente et pensent r\\'ealiser un\ngain suppl\\'ementaire en r\\'ealisant des stocks. Nous avons cherch\\'e dans\ncette \\'etude \\`a fournir des \\'el\\'ements de d\\'ecision pour conna\\^itre les\nlimites de cette r\\`egle de gestion. Notre proposition porte sur le\nd\\'eveloppement d'un mod\\`ele d'aide \\`a la d\\'ecision prenant en\nconsid\\'eration le mixte entre opportunit\\'es commerciales, contraintes\n\\'economiques et contraintes de moyen. Ce mod\\`ele souligne l'importance\nparticuli\\`ere du taux de possession et du risque de non vente.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.2207v1"
    },
    {
        "title": "A new DFM approach to combine machining and additive manufacturing",
        "authors": [
            "Olivier Kerbrat",
            "Pascal Mognol",
            "Jean-Yves Hascot"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Design For Manufacturing (DFM) approaches aim to integrate manufacturability\naspects during the design stage. Most of DFM approaches usually consider only\none manufacturing process, but products competitiveness may be improved by\ndesigning hybrid modular products, in which products are seen as 3-D puzzles\nwith modules realized aside by the best manufacturing process and further\ngathered. A new DFM system is created in order to give quantitative information\nduring the product design stage of which modules will benefit in being machined\nand which ones will advantageously be realized by an additive process (such as\nSelective Laser Sintering or laser deposition). A methodology for a\nmanufacturability evaluation in case of a subtractive or an additive\nmanufacturing process is developed and implemented in a CAD software. Tests are\ncarried out on industrial products from automotive industry.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.3176v1"
    },
    {
        "title": "Adaptive Monte Carlo applied to uncertainty estimation in a five axis\n  machine tool link errors identification",
        "authors": [
            "Loc Andolfatto",
            "Ren Mayer",
            "Sylvain Lavernhe"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Knowledge of a machine tool axis to axis location errors allows compensation\nand correcting actions to be taken to enhance its volumetric accuracy. Several\nprocedures exist, involving either lengthy individual test for each geometric\nerror or faster single tests to identify all errors at once. This study focuses\non the closed kinematic Cartesian chain method which uses a single setup test\nto identify the eight link errors of a five axis machine tool. The\nidentification is based on volumetric error measurements for different poses\nwith a non-contact measuring instrument called CapBall, developed in house. In\norder to evaluate the uncertainty on each identified error, a multi-output\nMonte Carlo approach is implemented. Uncertainty sources in the measurement and\nidentification chain - such as sensors output, machine drift and frame\ntransformation uncertainties - can be included in the model and propagated to\nthe identified errors. The estimated uncertainties are finally compared to\nexperimental results to assess the method. It shows that the effect of the\ndrift, a disturbance, must be simulated as a function of time the Monte Carlo\napproach. The machine drift is found to be an important uncertainty in sources\nfor the machine tested.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.3326v1"
    },
    {
        "title": "The impact of energy constraints on the medium access",
        "authors": [
            "Lazaros Gkatzikis",
            "Georgios S. Paschos",
            "Iordanis Koutsopoulos"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Contemporary mobile devices are battery powered and due to their shrinking\nsize and increasing complexity operate on a tight energy budget. Thus, energy\nconsumption is becoming one of the major concerns regarding the current and\nupcoming wireless communication systems. On the other hand, the available\nbandwidth resources are limited and modern applications are throughput\ndemanding, leading thus to strong competition for the medium. In this\ndirection, we consider a stochastic contention based medium access scheme,\nwhere the devices may choose to turn off for some time in order to save energy.\nWe perform an analysis for a slotted ALOHA scenario and we show that the energy\nconstraints, if properly exploited, may reduce contention for the medium. Our\nresults give valuable insights on the energy--throughput tradeoff for any\ncontention based system.\n",
        "pdf_link": "http://arxiv.org/pdf/1106.5988v1"
    },
    {
        "title": "A novel methodology for antenna design and optimization: Variable Zo",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  This paper describes \"Variable Zo,\" a novel and proprietary approach to\nantenna design and optimization. The new methodology is illustrated by applying\nit to the design of a resistively-loaded bowtie antenna and to two broadband\nYagi-Uda arrays. Variable Zo is applicable to any antenna design or\noptimization methodology. Using it will result in generally better antenna\ndesigns across any user-specified set of performance objectives.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.1437v2"
    },
    {
        "title": "Cloud Computing Future Framework for e-management of NGO's",
        "authors": [
            "Harjit Singh Lamba",
            "Gurdev Singh"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Cloud computing is an emerging new computing paradigm for delivering\ncomputing services. This computing approach relies on a number of existing\ntechnologies, e.g., the Internet, virtualization, grid computing, Web services,\netc. Cloud Computing aims to provide scalable and inexpensive on-demand\ncomputing infrastructures with good quality of service levels. It represents a\nshift away from computing as a product that is purchased, to computing as a\nservice that is delivered to consumers from the cloud. It helps an organization\nin saving costs and creating new business opportunities.This paper provides a\nframework, Education Cloud for the e- management of NGO's. The Education Cloud\ncan transform a nonprofit, or an entire sector of nonprofits, achieves its\nmission and creates lasting impact in its communities. This paper also presents\nthe case study of Kalgidhar trust, Baru Sahib, Himachal Pradesh, NGO which is\nusing the education as the tool to solve the social issues.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.3217v1"
    },
    {
        "title": "Feed drive modelling for the simulation of tool path tracking in\n  multi-axis High Speed Machining",
        "authors": [
            "David Prvost",
            "Sylvain Lavernhe",
            "Claire Lartigue",
            "Didier Dumur"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Within the context of High Speed Machining, it is essential to manage the\ntrajectory generation to achieve both high surface quality and high\nproductivity. As feed drives are one part of the set Machine tool - Numerical\nController, it is necessary to improve their performances to optimize feed\ndrive dynamics during trajectory follow up. Hence, this paper deals with the\nmodelling of the feed drive in the case of multi axis machining. This model can\nbe used for the simulation of axis dynamics and tool-path tracking to tune\nparameters and optimize new frameworks of command strategies. A procedure of\nidentification based on modern NC capabilities is presented and applied to\nindustrial HSM centres. Efficiency of this modelling is assessed by\nexperimental verifications on various representative trajectories. After\nimplementing a Generalized Predictive Control, reliable simulations are\nperformed thanks to the model. These simulations can then be used to tune\nparameters of this new framework according to the tool-path geometry.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.3229v1"
    },
    {
        "title": "Evaluation of servo, geometric and dynamic error sources on five axis\n  high-speed machine tool",
        "authors": [
            "Loc Andolfatto",
            "Sylvain Lavernhe",
            "Ren Mayer"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Many sources of errors exist in the manufacturing process of complex shapes.\nSome approximations occur at each step from the design geometry to the machined\npart. The aim of the paper is to present a method to evaluate the effect of\nhigh speed and high dynamic load on volumetric errors at the tool center point.\nThe interpolator output signals and the machine encoder signals are recorded\nand compared to evaluate the contouring errors resulting from each axis\nfollow-up error. The machine encoder signals are also compared to the actual\ntool center point position as recorded with a non-contact measuring instrument\ncalled CapBall to evaluate the total geometric errors. The novelty of the work\nlies in the method that is proposed to decompose the geometric errors in two\ncategories: the quasi-static geometric errors independent from the speed of the\ntrajectory and the dynamic geometric errors, dependent on the programmed feed\nrate and resulting from the machine structure deflection during the\nacceleration of its axes. The evolution of the respective contributions for\ncontouring errors, quasi-static geometric errors and dynamic geomet- ric errors\nis experimentally evaluated and a relation between programmed feed rate and\ndynamic errors is highlighted.\n",
        "pdf_link": "http://arxiv.org/pdf/1107.3541v1"
    },
    {
        "title": "UWB Array Design Using Variable Zo Technology and Central Force\n  Optimization",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  This note applies Variable Zo technology to the design of an Ultra Wideband\n(UWB) Yagi-Uda array optimized using Central Force Optimization. Variable Zo is\na novel and proprietary approach to antenna design and optimization that treats\nthe feed system characteristic impedance, Zo, as a design variable instead of a\nfixed design parameter as is traditionally done. Variable Zo is applicable to\nany antenna design or optimization methodology, and using it will generally\nproduce better antenna designs across any user-specified set of performance\nobjectives.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.0901v2"
    },
    {
        "title": "The Impact of Information Technology in Nigeria's Banking Industry",
        "authors": [
            "Oluwagbemi Oluwatolani",
            "Abah Joshua",
            "Achimugu Philip"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Today, information technology (IT) has become a key element in economic\ndevelopment and a backbone of knowledge-based economies in terms of operations,\nquality delivery of services and productivity of services. Therefore, taking\nadvantage of information technologies (IT) is an increasing challenge for\ndeveloping countries. There is now growing evidence that Knowledge-driven\ninnovation is a decisive factor in the competitiveness of nations, industries,\norganizations and firms. Organizations like the banking sector have benefited\nsubstantially from e-banking, which is one among the IT applications for\nstrengthening the competitiveness. This paper presents the current trend in the\napplication of IT in the banking industries in Nigeria and gives an insight\ninto how quality banking has been enhanced via IT. The paper further reveals\nthat the deployment of IT facilities in the Nigerian Banking industry has\nbrought about fundamental changes in the content and quality of banking\nbusiness in the country. This analysis and clarification of how Nigerian Banks\nhave used IT to reengineer their operations is detailed through literature\nreview and observation. Three categories of variables that relate to the use\nand implementation of information technology devices were considered in this\npaper. These include the nature and degree of adoption of innovative\ntechnologies; degree of utilization of the identified technologies; and the\nimpact of the adoption of IT devices on the bank operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.1153v1"
    },
    {
        "title": "System Support for Managing Invalid Bindings",
        "authors": [
            "Lachhman Das",
            "Yasir Arfat",
            "Azhar Shah",
            "Khalil Khoumbati"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Context-aware adaptation is a central aspect of pervasive computing\napplications, enabling them to adapt and perform tasks based on contextual\ninformation. One of the aspects of context-aware adaptation is reconfiguration\nin which bindings are created between application component and remote services\nin order to realize new behaviour in response to contextual information.\nVarious research efforts provide reconfiguration support and allow the\ndevelopment of adaptive context-aware applications from high-level\nspecifications, but don't consider failure conditions that might arise during\nexecution of such applications, making bindings between application and remote\nservices invalid. To this end, we propose and implement our design approach to\nreconfiguration to manage invalid bindings. The development and modification of\nadaptive context-aware applications is a complex task, and an issue of an\ninvalidity of bindings further complicates development efforts. To reduce the\ndevelopment efforts, our approach provides an application-transparent solution\nwhere the issue of the invalidity of bindings is handled by our system,\nPolicy-Based Contextual Reconfiguration and Adaptation (PCRA), not by an\napplication developer. In this paper, we present and describe our approach to\nmanaging invalid bindings and compare it with other approaches to this problem.\nWe also provide performance evaluation of our approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.1472v1"
    },
    {
        "title": "Knowledge Audit Framework",
        "authors": [
            "P. Di Maio"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  KAF consists of a process and some templates to guide the planning and\nexecution of audits of knowledge resources, with emphasis on sharing. KAF is\nbased on methodological blueprint provided by the Data Audit Framework\n(DAF)conceived by the JISC-funded DAFD project.KAF enables organisations to\nfind out what knowledge resources are associated with the project, and how they\nare shared.KAF is available in two versionsKAF-g (generic, domain independent)\nKAF-se (targets systems enegineering knowledge)\n",
        "pdf_link": "http://arxiv.org/pdf/1108.1490v1"
    },
    {
        "title": "A New System Architecture for Pervasive Computing",
        "authors": [
            "Anis Ismail",
            "Abd El Salam Al Hajjar",
            "Ziad Ismail"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  We present new system architecture, a distributed framework designed to\nsupport pervasive computing applications. We propose a new architecture\nconsisting of a search engine and peripheral clients that addresses issues in\nscalability, data sharing, data transformation and inherent platform\nheterogeneity. Key features of our application are a type-aware data transport\nthat is capable of extract data, and present data through handheld devices (PDA\n(personal digital assistant), mobiles, etc). Pervasive computing uses web\ntechnology, portable devices, wireless communications and nomadic or ubiquitous\ncomputing systems. The web and the simple standard HTTP protocol that it is\nbased on, facilitate this kind of ubiquitous access. This can be implemented on\na variety of devices - PDAs, laptops, information appliances such as digital\ncameras and printers. Mobile users get transparent access to resources outside\ntheir current environment. We discuss our system's architecture and its\nimplementation. Through experimental study, we show reasonable performance and\nadaptation for our system's implementation for the mobile devices.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.2389v1"
    },
    {
        "title": "Classification of Emergency Scenarios",
        "authors": [
            "Mathieu Muench"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  In most of today's emergency scenarios information plays a crucial role.\nTherefore, information has to be constantly collected and shared among all\nrescue team members and this requires new innovative technologies. In this\npaper a classification of emergency scenarios is presented, describing their\nspecial characteristics and common strategies employed by rescue units to\nhandle them. Based on interviews with professional firefighters, requirements\nfor new systems are listed. The goal of this article is to support developers\ndesigning new systems by providing them a deeper look into the work of first\nresponders.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.2634v1"
    },
    {
        "title": "Modeling Smart Grid using Generalized Stochastic Petri Net",
        "authors": [
            "Amrita Dey",
            "Nabendu Chaki",
            "Sugata Sanyal"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Building smart grid for power system is a major challenge for safe, automated\nand energy efficient usage of electricity. The full implementation of the smart\ngrid will evolve over time. However, before a new set of infrastructures are\ninvested to build the smart grid, proper modeling and analysis is needed to\navoid wastage of resources. Modeling also helps to identify and prioritize\nappropriate systems parameters. In this paper, an all comprehensive model of\nsmart grid have been proposed using Generalized Stochastic Petri Nets (GSPN).\nThe model is used to analyze the constraints and deliverables of the smart\npower grid of future.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.4139v1"
    },
    {
        "title": "Quality Evaluation of Conceptual Level Object Multidimensional Data\n  Model",
        "authors": [
            "Supriya Chakrabarty",
            "Nabendu Chaki"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The advancement of technology facilitates explosive growth of mobile usage in\nthe last decade. Numerous applications have been developed to support its\nusage. However, gap in technology exists in obtaining correct and trusted\nvalues for evaluation indexes of the precise amount of usage. The claims of\nloss in revenue by the service providers could be more due to unexpected\nbehaviour of the hardware. A similar mistrust is often observed in the users of\nthe services. A trustworthy subscription scheme is in demand for consumers\nwhereas revenue needs to be assured of the service providers. Multiple\nAuthorizations by Multiple Owners (MAMO) has already been introduced as a\ntechnology to build trust in the third party billing system. In this paper,\nMAMO is extended to ensure trustworthiness of the parameters for subscription.\nAlong with call transaction data are reconciled to assure the proper revenue\ngeneration.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.5466v1"
    },
    {
        "title": "Food Redistribution as Optimization",
        "authors": [
            "Caleb Phillips",
            "Rhonda Hoenigman",
            "Becky Higbee"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  In this paper we study the simultaneous problems of food waste and hunger in\nthe context of the possible solution of food (waste) rescue and redistribution.\nTo this end, we develop an empirical model that can be used in Monte Carlo\nsimulations to study the dynamics of the underlying problem. Our model's\nparameters are derived from a unique data set provided by a large food bank and\nfood rescue organization in north central Colorado. We find that food supply is\na non-parametric heavy-tailed process that is well-modeled with an extreme\nvalue peaks-over-threshold model. Although the underlying process is\nstochastic, the basic approach of food rescue and redistribution appears to be\nfeasible both at small and large scales. The ultimate efficacy of this model is\nintimately tied to the rate at which food expires and hence the ability to\npreserve and quickly transport and redistribute food. The cost of the\nredistribution is tied to the number and density of participating suppliers,\nand costs can be reduced (and supply increased) simply by recruiting additional\ndonors to participate. Our results show that with sufficient funding and\nmanpower, a significant amount of food can be rescued from the waste stream and\nused to feed the hungry.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.5768v2"
    },
    {
        "title": "A binary noisy channel to model errors in printing process",
        "authors": [
            "V. N. Gorbachev",
            "E. S. Yakovleva"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  To model printing noise a binary noisy channel and a set of controlled gates\nare introduced. The channel input is an image created by a halftoning algorithm\nand its output is the printed picture. Using this channel robustness to noise\nbetween halftoning algorithms can be studied. We introduced relative entropy to\ndescribe immunity of the algorithm to noise and tested several halftoning\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.0463v1"
    },
    {
        "title": "Fault Tolerant Matrix Pencil Method for Direction of Arrival Estimation",
        "authors": [
            "T. Yerriswamy",
            "S. N. Jagadeesha"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Continuing to estimate the Direction-of-arrival (DOA) of the signals\nimpinging on the antenna array, even when a few elements of the underlying\nUniform Linear Antenna Array (ULA) fail to work will be of practical interest\nin RADAR, SONAR and Wireless Radio Communication Systems. This paper proposes a\nnew technique to estimate the DOAs when a few elements are malfunctioning. The\ntechnique combines Singular Value Thresholding (SVT) based Matrix Completion\n(MC) procedure with the Direct Data Domain (D^3) based Matrix Pencil (MP)\nMethod. When the element failure is observed, first, the MC is performed to\nrecover the missing data from failed elements, and then the MP method is used\nto estimate the DOAs. We also, propose a very simple technique to detect the\nlocation of elements failed, which is required to perform MC procedure. We\nprovide simulation studies to demonstrate the performance and usefulness of the\nproposed technique. The results indicate a better performance, of the proposed\nDOA estimation scheme under different antenna failure scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.1627v1"
    },
    {
        "title": "Biological Computation as the Revolution of Complex Engineered Systems",
        "authors": [
            "Nelson Alfonso Gmez-Cruz",
            "Carlos Eduardo Maldonado"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Provided that there is no theoretical frame for complex engineered systems\n(CES) as yet, this paper claims that bio-inspired engineering can help provide\nsuch a frame. Within CES bio-inspired systems play a key role. The disclosure\nfrom bio-inspired systems and biological computation has not been sufficiently\nworked out, however. Biological computation is to be taken as the processing of\ninformation by living systems that is carried out in polynomial time, i.e.,\nefficiently; such processing however is grasped by current science and research\nas an intractable problem (for instance, the protein folding problem). A remark\nis needed here: P versus NP problems should be well defined and delimited but\nbiological computation problems are not. The shift from conventional\nengineering to bio-inspired engineering needs bring the subject (or problem) of\ncomputability to a new level. Within the frame of computation, so far, the\nprevailing paradigm is still the Turing-Church thesis. In other words,\nconventional engineering is still ruled by the Church-Turing thesis (CTt).\nHowever, CES is ruled by CTt, too. Contrarily to the above, we shall argue here\nthat biological computation demands a more careful thinking that leads us\ntowards hypercomputation. Bio-inspired engineering and CES thereafter, must\nturn its regard toward biological computation. Thus, biological computation can\nand should be taken as the ground for engineering complex non-linear systems.\nBiological systems do compute in terms of hypercomputation, indeed. If so, then\nthe focus is not algorithmic or computational complexity but\ncomputation-beyond-the-Church-Turing-barrier. We claim that we need a new\ncomputational theory that encompasses biological processes wherein the\nTuring-Church thesis is but a particular case.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.3316v1"
    },
    {
        "title": "An Efficient Approach towards Mitigating Soft Errors Risks",
        "authors": [
            "Muhammad Sheikh Sadi",
            "Md. Mizanur Rahman Khan",
            "Md. Nazim Uddin",
            "Jan Jrjens"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Smaller feature size, higher clock frequency and lower power consumption are\nof core concerns of today's nano-technology, which has been resulted by\ncontinuous downscaling of CMOS technologies. The resultant 'device shrinking'\nreduces the soft error tolerance of the VLSI circuits, as very little energy is\nneeded to change their states. Safety critical systems are very sensitive to\nsoft errors. A bit flip due to soft error can change the value of critical\nvariable and consequently the system control flow can completely be changed\nwhich leads to system failure. To minimize soft error risks, a novel\nmethodology is proposed to detect and recover from soft errors considering only\n'critical code blocks' and 'critical variables' rather than considering all\nvariables and/or blocks in the whole program. The proposed method shortens\nspace and time overhead in comparison to existing dominant approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.3969v1"
    },
    {
        "title": "The Axiomatic Foundation of Space in GFO",
        "authors": [
            "Ringo Baumann",
            "Heinrich Herre"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Space and time are basic categories of any top-level ontology. They are\nfundamental assumptions for the mode of existence of those individuals which\nare said to be in space and time. In the present paper the ontology of space in\nthe General Formal Ontology (GFO) is expounded. This ontology is represented as\na theory BT (Brentano Theory), which is specified by a set of axioms formalized\nin first-order logic. This theory uses four primitive relations: SReg(x) (x is\nspace region), spart(x, y) (x is spatial part of y), sb(x, y) (x is spatial\nboundary of y), and scoinc(x, y) (x and y spatially coincide). This ontology is\ninspired by ideas of Franz Brentano. The investigation and exploration of Franz\nBrentano's ideas on space and time began about twenty years ago by work of R.M.\nChisholm, B. Smith and A. Varzi. The present paper takes up this line of\nresearch and makes a further step in establishing an ontology of space which is\nbased on rigorous logical methods and on principles of the new philosophical\napproach of integrative realism.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.5832v1"
    },
    {
        "title": "Generation of Test Vectors for Sequential Cell Verification",
        "authors": [
            "Santanu Bhowmick",
            "S. Bhattacherjee",
            "Nandakumar G. N"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  For Application Specific Integrated Circuits (ASIC) and System-on-Chip (SOC)\ndesigns, Cell - Based Design (CBD) is the most prevalent practice as it\nguarantees a shorter design cycle, minimizes errors and is easier to maintain.\nIn modern ASIC design, standard cell methodology is practiced with sizable\nlibraries of cells, each containing multiple implementations of the same logic\nfunctionality, in order to give the designer differing options based on area,\nspeed or power consumption. For such library cells, thorough verification of\nfunctionality and timing is crucial for the overall success of the chip, as\neven a small error can prove fatal due to the repeated use of the cell in the\ndesign. Both formal and simulation based methods are being used in the industry\nfor cell verification. We propose a method using the latter approach that\ngenerates an optimized set of test vectors for verification of sequential\ncells, which are guaranteed to give complete Single Input Change transition\ncoverage with minimal redundancy. Knowledge of the cell functionality by means\nof the State Table is the only prerequisite of this procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/1110.6105v1"
    },
    {
        "title": "Gas turbine diagnostic system",
        "authors": [
            "Shuvatov Talgat",
            "Suleimenov Batrbek"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The creation of the systems models is very actual at present time, because it\nallow to simulate the work of some complex equipment without any additional\nspends. The given model of gas turbine is allowed to test and optimize the\nsoftware for gas turbine automation systems, study station personal, like\noperators and engineers and will be useful for diagnostics and prediction tasks\nto analyze the efficiency of the gas turbine.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.0233v2"
    },
    {
        "title": "A Stochastic Net Model for Controlling Bullwhip Effect in Virtual\n  Multi-Tier Retail Network",
        "authors": [
            "Bidyut Biman Sarkar",
            "Sugata Sanyal",
            "Nabendu Chaki"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Supply Chain operation is an integrated business process starting from\nprimary supplier to end user and the process produce products, services and\ninformation. A successful chain will explore technology, lean operations, and\nquality management by adding value for customers and stakeholders. It is a\nstrategic alliance among the partnering enterprises without geographical\nboundary. Every chain has its own unique set of market demands and operating\nchallenges. Retailing is one such service domain of Supply Chain vulnerable to\nbullwhip effects. Demand uncertainty is one of the root causes of Bullwhip\neffects. This paper calls for modeling of a demand driven multi-tier stochastic\nRetail Chain to work against the Bullwhip effect. The proposed model of the\noperational chain will ensure significant return of share to the retailer\nthrough the sophisticated transaction management, real-time inventory\nmanagement and the ability to track all inventory movements.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.0427v2"
    },
    {
        "title": "Quantum/Relativistic Computation of Security and Efficiency of\n  Electrical Power System for a Day-Ahead",
        "authors": [
            "Stefan Z. Stefanov"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  An algorithm for Electric Power System (EPS) quantum/relativistic security\nand efficiency computation for a day-ahead via perturbative renormalization of\nthe EPS, finding the computation flowcharts, verification and validation is\nbuilt in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.0808v2"
    },
    {
        "title": "Solar Power Systems Web Monitoring",
        "authors": [
            "Bimal Aklesh Kumar"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  All over the world the peak demand load is increasing and the load factor is\ndecreasing year-by-year. The fossil fuel is considered insufficient thus solar\nenergy systems are becoming more and more useful, not only in terms of\ninstallation but monitoring of these systems is very crucial. Monitoring\nbecomes very important when there are a large number of solar panels.\nMonitoring would allow early detection if the output falls below required level\nor one of the solar panel out of 1000 goes down. In this study the target is to\nmonitor and control a developed solar panel by using available internet\nfoundation. This web-enabled software will provide more flexibility over the\nsystem such as transmitting data from panel to the host computer and\ndisseminating information to relevant stake holders barring any geographical\nbarrier. The software would be built around web server with dynamic HTML and\nJAVA, this paper presents the preliminary design of the proposed system.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.1605v1"
    },
    {
        "title": "Architecture and Design of Medical Processor Units for Medical Networks",
        "authors": [
            "Syed V. Ahamed",
            "Syed Shawon M. Rahman"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  This paper introduces analogical and deductive methodologies for the design\nmedical processor units (MPUs). From the study of evolution of numerous earlier\nprocessors, we derive the basis for the architecture of MPUs. These specialized\nprocessors perform unique medical functions encoded as medical operational\ncodes (mopcs). From a pragmatic perspective, MPUs function very close to CPUs.\nBoth processors have unique operation codes that command the hardware to\nperform a distinct chain of subprocesses upon operands and generate a specific\nresult unique to the opcode and the operand(s). In medical environments, MPU\ndecodes the mopcs and executes a series of medical sub-processes and sends out\nsecondary commands to the medical machine. Whereas operands in a typical\ncomputer system are numerical and logical entities, the operands in medical\nmachine are objects such as such as patients, blood samples, tissues, operating\nrooms, medical staff, medical bills, patient payments, etc. We follow the\nfunctional overlap between the two processes and evolve the design of medical\ncomputer systems and networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.1768v1"
    },
    {
        "title": "Using Scalp Electrical Biosignals to Control an Object by Concentration\n  and Relaxation Tasks: Design and Evaluation",
        "authors": [
            "Laurent George",
            "Fabien Lotte",
            "Raquel Viciana Abad",
            "Anatole Lcuyer"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  In this paper we explore the use of electrical biosignals measured on scalp\nand corresponding to mental relaxation and concentration tasks in order to\ncontrol an object in a video game. To evaluate the requirements of such a\nsystem in terms of sensors and signal processing we compare two designs. The\nfirst one uses only one scalp electroencephalographic (EEG) electrode and the\npower in the alpha frequency band. The second one uses sixteen scalp EEG\nelectrodes and machine learning methods. The role of muscular activity is also\nevaluated using five electrodes positioned on the face and the neck. Results\nshow that the first design enabled 70% of the participants to successfully\ncontrol the game, whereas 100% of the participants managed to do it with the\nsecond design based on machine learning. Subjective questionnaires confirm\nthese results: users globally felt to have control in both designs, with an\nincreased feeling of control in the second one. Offline analysis of face and\nneck muscle activity shows that this activity could also be used to distinguish\nbetween relaxation and concentration tasks. Results suggest that the\ncombination of muscular and brain activity could improve performance of this\nkind of system. They also suggest that muscular activity has probably been\nrecorded by EEG electrodes.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.5285v1"
    },
    {
        "title": "A Novel Approach for Periodic Assessment of Business Process\n  Interoperability",
        "authors": [
            "Elmir Badr",
            "Bounabat Bouchaib"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Business collaboration networks provide collaborative organizations a\nfavorable context for automated business process interoperability. This paper\naims to present a novel approach for assessing interoperability of process\ndriven services by considering the three main aspects of interoperation:\npotentiality, compatibility and operational performance. It presents also a\nsoftware tool that supports the proposed assessment method. In addition to its\ncapacity to track and control the evolution of interoperation degree in time,\nthe proposed tool measures the required effort to reach a planned degree of\ninteroperability. Public accounting of financial authority is given as an\nillustrative case study of interoperability monitoring in public collaboration\nnetwork.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.5288v1"
    },
    {
        "title": "Reference Model for Performance Management in Service-Oriented Virtual\n  Organization Breeding Environments",
        "authors": [
            "Zbigniew Paszkiewicz",
            "Willy Picard"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Performance management (PM) is a key function of virtual organization (VO)\nmanagement. A large set of PM indicators has been proposed and evaluated within\nthe context of virtual breeding environments (VBEs). However, it is currently\ndifficult to describe and select suitable PM indicators because of the lack of\na common vocabulary and taxonomies of PM indicators. Therefore, there is a need\nfor a framework unifying concepts in the domain of VO PM. In this paper, a\nreference model for VO PM is presented in the context of service-oriented VBEs.\nIn the proposed reference model, both a set of terms that could be used to\ndescribe key performance indicators, and a set of taxonomies reflecting various\naspects of PM are proposed. The proposed reference model is a first attempt and\na work in progress that should not be supposed exhaustive.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.5741v1"
    },
    {
        "title": "Social Protocols for Agile Virtual Teams",
        "authors": [
            "Willy Picard"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Despite many works on collaborative networked organizations (CNOs), CSCW,\ngroupware, workflow systems and social networks, computer support for virtual\nteams is still insufficient, especially support for agility, i.e. the\ncapability of virtual team members to rapidly and cost efficiently adapt the\nway they interact to changes. In this paper, requirements for computer support\nfor agile virtual teams are presented. Next, an extension of the concept of\nsocial protocol is proposed as a novel model supporting agile interactions\nwithin virtual teams. The extended concept of social protocol consists of an\nextended social network and a workflow model.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.5765v1"
    },
    {
        "title": "Modeling Virtual Organization Architecture with the Virtual Organization\n  Breeding Methodology",
        "authors": [
            "Zbigniew Paszkiewicz",
            "Willy Picard"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  While Enterprise Architecture Modeling (EAM) methodologies become more and\nmore popular, an EAM methodology tailored to the needs of virtual organizations\n(VO) is still to be developed. Among the most popular EAM methodologies, TOGAF\nhas been chosen as the basis for a new EAM methodology taking into account\ncharacteristics of VOs presented in this paper. In this new methodology,\nreferred as Virtual Organization Breeding Methodology (VOBM), concepts\ndeveloped within the ECOLEAD project, e.g. the concept of Virtual Breeding\nEnvironment (VBE) or the VO creation schema, serve as fundamental elements for\ndevelopment of VOBM. VOBM is a generic methodology that should be adapted to a\ngiven VBE. VOBM defines the structure of VBE and VO architectures in a\nservice-oriented environment, as well as an architecture development method for\nvirtual organizations (ADM4VO). Finally, a preliminary set of tools and methods\nfor VOBM is given in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.5778v1"
    },
    {
        "title": "Enhancing Information Systems Security in Educational Organizations in\n  KSA through proposing security model",
        "authors": [
            "Hussain A. H. Awad",
            "Fadi M. Battah"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  It is well known that technology utilization is not restricted for one sector\nthan the other anymore, Educational organizations share many parts of their\ninformation systems with commercial organizations. In this paper we will try to\nidentify the main characteristics of information systems in educational\norganizations, then we will propose a model of two parts to enhance the\ninformation systems security, the first part of the model will handle the\npolicy and laws of the information system, the second part will provide a\ntechnical approach on how to audit and subsequently maintain the security of\ninformation system.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.6757v1"
    },
    {
        "title": "Multimedia-based Medicinal Plants Sustainability Management System",
        "authors": [
            "Zacchaeus Omogbadegun",
            "Charles Uwadia",
            "Charles Ayo",
            "Victor Mbarika",
            "Nicholas Omoregbe",
            "Efe Otofia",
            "Frank Chieze"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Medicinal plants are increasingly recognized worldwide as an alternative\nsource of efficacious and inexpensive medications to synthetic\nchemo-therapeutic compound. Rapid declining wild stocks of medicinal plants\naccompanied by adulteration and species substitutions reduce their efficacy,\nquality and safety. Consequently, the low accessibility to and\nnon-affordability of orthodox medicine costs by rural dwellers to be healthy\nand economically productive further threaten their life expectancy. Finding\ncomprehensive information on medicinal plants of conservation concern at a\nglobal level has been difficult. This has created a gap between computing\ntechnologies' promises and expectations in the healing process under\ncomplementary and alternative medicine. This paper presents the design and\nimplementation of a Multimedia-based Medicinal Plants Sustainability Management\nSystem addressing these concerns. Medicinal plants' details for designing the\nsystem were collected through semi-structured interviews and databases. Unified\nModelling Language, Microsoft-Visual-Studio.Net, C#3.0,\nMicrosoft-Jet-Engine4.0, MySQL, Loquendo Multilingual Text-to-Speech Software,\nYouTube, and VLC Media Player were used. Keywords: Complementary and\nAlternative Medicine, conservation, extinction, medicinal plant, multimedia,\nphytoconstituents, rural dwellers\n",
        "pdf_link": "http://arxiv.org/pdf/1111.6911v1"
    },
    {
        "title": "Two Squares of Opposition: for Analytic and Synthetic Propositions",
        "authors": [
            "Andrew Schumann"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  In the paper I prove that there are two squares of opposition. The\nunconventional one is built up for synthetic propositions. There a, i are\ncontrary, a, o (resp. e, i) are contradictory, e, o are subcontrary, a, e\n(resp. i, o) are said to stand in the subalternation.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.0961v1"
    },
    {
        "title": "On an Approach to the Design of a Logical Model of Innovation Project\n  Data",
        "authors": [
            "L. Mylnikov",
            "A. Trusov"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Questions concerning the development of a logical model of innovation project\ndata, as well as those concerning the design of information systems for\ndecision-making support in the management of innovation projects, are\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.1546v1"
    },
    {
        "title": "Being, space and time in the Web",
        "authors": [
            "Michalis Vafopoulos"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The Web initially emerged as an \"antidote\" to accumulated scientific\nknowledge since it enables global representation and communication with minimum\ncosts. Its gigantic scale and interdependence incommode our ability to find\nrelevant information and develop trustworthy contexts. It is time for science\nto compensate by providing an epistemological \"antidote\" to Web issues.\nPhilosophy should be in the front line by forming the salient questions and\nanalysis. The scope of our research is to provide a theory about the Web being\nthat will bridge philosophical thinking and engineering. We analyze existence\nand spatiotemporality in the Web and how it transforms the traditional\nactualities. The Web space is specified by incoming and outgoing links. The\nprimordial role of visiting durations in Web's existence is approximated by\nBergsonian time. The physical space becomes more discoverable. The human\nactivity can be asynchronous, synchronous and continuous. Networked individuals\noperate in a flexible and spatially dispersed environment. The resulting issues\nconcern the self-determination of a being and the way in which the Web could be\na free and open platform for innovation and participation.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.2250v2"
    },
    {
        "title": "Employees Adoption of E-Procurement System: An Empirical Study",
        "authors": [
            "Inder Singh",
            "Devendra Kumar Punia"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Today, organizations are investing a lot in their IT infrastructure and\nreengineering their business processes by digitizing firms. If organizational\nemployees will not optimum utilize its IT infrastructure, the productivity gain\nreduced enormously. In Uttarakhand e-procurement system implemented by public\nsector under e-governance integrated mission mode projects. So, there is need\nto find the determinants which influence employee's adoption and uses of\ne-procurement systems. This research study assesses the organizational and\nindividual determinants that influence the use of e-procurement system in\nUttarakhand public sector. This study provides managers with the valuable\ninformation to take intervention programs to achieve greater acceptance and\nusage of e-procurement system. Data collected for this study by the means of a\nsurvey conducted in Uttarakhand state in 2011. A total 1200 questionnaire forms\nwere distributed personally and online to employees using e-procurement system\nin Uttarakhand.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.2699v1"
    },
    {
        "title": "Partial order approach to compute shortest paths in multimodal networks",
        "authors": [
            "Andrew Ensor",
            "Felipe Lillo"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Many networked systems involve multiple modes of transport. Such systems are\ncalled multimodal, and examples include logistic networks, biomedical\nphenomena, manufacturing process and telecommunication networks. Existing\ntechniques for determining optimal paths in multimodal networks have either\nrequired heuristics or else application-specific constraints to obtain\ntractable problems, removing the multimodal traits of the network during\nanalysis. In this paper weighted coloured--edge graphs are introduced to model\nmultimodal networks, where colours represent the modes of transportation.\nOptimal paths are selected using a partial order that compares the weights in\neach colour, resulting in a Pareto optimal set of shortest paths. This approach\nis shown to be tractable through experimental analyses for random and real\nmultimodal networks without the need to apply heuristics or constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.3366v1"
    },
    {
        "title": "Multi databases in Health Care Networks",
        "authors": [
            "Nadir K. Salih",
            "Tianyi Zang",
            "Mingrui Sun"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  E-Health is a relatively recent term for healthcare practice supported by\nelectronic processes and communication, dating back to at least 1999. E-Health\nis greatly impacting on information distribution and availability within the\nhealth services, hospitals and to the public. E-health was introduced as the\ndeath of telemedicine, because - in the context of a broad availability of\nmedical information systems that can interconnect and communicate -\ntelemedicine will no longer exist as a specific field. The same could also be\nsaid for any other traditional field in medical informatics, including\ninformation systems and electronic patient records. E-health presents itself as\na common name for all such technological fields. In this paper we focuses in\nmulti database by determined some sites and distributed it in Homogenous way.\nThis will be followed by an illustrative example as related works. Finally, the\npaper concludes with general remarks and a statement of further work.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.4099v1"
    },
    {
        "title": "Informatics Perspectives on Decision Taking, a Case Study on Resolving\n  Process Product Ambiguity",
        "authors": [
            "J. A. Bergstra"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  A decision is an act or event of decision taking. Decision making always\nincludes decision taking, the latter not involving significant exchanges with\nnon-deciding agents. A decision outcome is a piece of storable information\nconstituting the result of a decision. Decision outcomes are typed, for\ninstance: plan, command, assertion, or boolean reply to a question. Decision\noutcomes are seen by an audience and autonomous actions from the audience is\nsupposed to realize the putting into effect of a decision outcome, thus leading\nto so-called decision effects. Decision outcomes are supposedly expected by the\ndecider. Using a model or a theory concerning the causal chain leading from a\ndecision outcome to one or more decision effects may support a decision taker\ndecision taker in predicting plausible decision effects for candidate decision\noutcomes. Decision taking is positioned amidst many related notions including:\ndecision making, decision process, decision making process, decision process\nmaking, decision engineering, decision progression, and decision progression\nproduction.\n",
        "pdf_link": "http://arxiv.org/pdf/1112.5840v2"
    },
    {
        "title": "Channel Estimation Study for Block - Pilot Insertion in OFDM Systems\n  under Slowly Time Varying Conditions",
        "authors": [
            "Aida Zaier",
            "Ridha Bouallegue"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, we propose a study of performance of the channel estimation\nusing LS, MMSE, LMMSE and Lr-LMMSE algorithms in OFDM (Orthogonal Frequency\nDivision Multiplexing) system which, as known suffers from the time variation\nof the channel under high mobility conditions, using block pilot insertion. The\nloss of sub channel orthogonality leads to inter-carrier interference (ICI).\nUsing many algorithms for channel estimation, we will show that, for a 16- QAM\nmodulation, the LMMSE algorithm performs well to achieve this estimation but\nwhen the SNR (Signal Noise Rate) is high, the four algorithms (LS, MMSE, LMMSE\nand Lr-LMMSE) perform similarly, this is not always the case for another scheme\nof modulation. We will improve also the mean squared error for these\nalgorithms. It will be illustrious in this paper that the LMMSE algorithm\nperforms well with the block- pilot insertion as well as its low rank version\nwhich behave very good even when the size of FFT is very high.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.1552v1"
    },
    {
        "title": "Design of wireless electronic stethoscope based on zigbee",
        "authors": [
            "D. D. Kadam Patil",
            "R. K. Shastri"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Heart sound stethoscope is primary stage to access diseases. In this paper\ndesign of an electronic stethoscope with the functions of wireless transmission\nis discussed. This electronic stethoscope based on embedded processor. The data\ncan be transmitted through wireless transmission using Zigbee module. A\nmicrophone is used to pick up the sound of the heart beat. Acoustic stethoscope\ncan be changed into a digital stethoscope by inserting an electric capacity\nmicrophone into its head. The signal is processed and amplified to play with or\nwithout earphone. Heart sounds are processed, sampled and sent wirelessly using\nZigbee module so that multiple doctors can do auscultation. PC connectivity is\nprovided through serial port where from audio and video can be made available\nthrough LAN and internet for telemedicine consultation. Heart beat signals are\nsensed, sent, displayed, monitored, stored, reviewed, and analysed with ease.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.1680v1"
    },
    {
        "title": "Design and Fabrication of Micromachined Resonators",
        "authors": [
            "Ritesh Ray Chaudhuri",
            "Joydeep Basu",
            "Tarun Kanti Bhattacharyya"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Microelectromechanical system (MEMS) based on-chip resonators offer great\npotential for sensing and high frequency signal processing applications due to\ntheir exceptional features like small size, large frequency-quality factor\nproduct, integrability with CMOS ICs, low power consumption etc. This work is\nmainly aimed at the design, modeling, simulation, and fabrication of\nmicromachined polysilicon disk resonators exhibiting radial-contour mode\nvibrations. A few other bulk mode modified resonator geometries are also being\nexplored. The resonator structures have been designed and simulated in\nCoventorWare finite-element platform and fabricated by the PolyMUMPs surface\nmicromachining process.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.3048v1"
    },
    {
        "title": "Towards Maximum Spanning Tree Model in Web 3.0 Design and Development\n  for Students using Discriminant Analysis",
        "authors": [
            "S. Padma",
            "Ananthi Seshasaayee"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Web 3.0 is an evolving extension of the web 2.0 scenario. The perceptions\nregarding web 3.0 is different from person to person . Web 3.0 Architecture\nsupports ubiquitous connectivity, network computing, open identity, intelligent\nweb, distributed databases and intelligent applications. Some of the\ntechnologies which lead to the design and development of web 3.0 applications\nare Artificial intelligence, Automated reasoning, Cognitive architecture,\nSemantic web . An attempt is made to capture the requirements of Students\ninline with web 3.0 so as to bridge the gap between the design and development\nof web 3.0 applications and requirements among Students. Maximum Spanning Tree\nmodeling of the requirements facilitate the identification of key areas and key\nattributes in the design and development of software products for Students in\nWeb 3.0 using Discriminant analysis. Keywords : Web 3.0, Discriminant analysis,\nDesign and Development, Model, Maximum Spanning Tree 1.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.3386v1"
    },
    {
        "title": "Innovative SQA Service Maturity Model using CMMI and ITIL",
        "authors": [
            "G. Shankar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This Journal details a maturity model for SQA services which has been\ndeveloped during QMS implementation in the IT division of a large multinational\norganization. The scope of the engagement was to establish a standard set of\nprocesses based on CMMI\\textregistered and ITIL\\textregistered Framework across\nfour business verticals scattered in Europe, United States and Asia. The\nservices of Software Quality Analyst (SQA) from different vendors were\nleveraged to facilitate implementation of processes which was referred to as\nthe Quality Management System (QMS). To co-ordinate and support QMS\nimplementation, a Software Quality Assurance Group (SQAG) was established at\nthe organizational level. Considering the large number of applications, the\nbusiness verticals proposed that process implementation should be owned and\nmanaged by practitioners themselves so that the mass deployment of QMS can be\nachieved at a faster rate with the same SQA capacity. This called for a need to\ndevise an innovative implementation solution before moving to a process\nimplementation model which proposed Project Managers implementing processes\nthemself. While there are process models and frameworks available in the market\nfor establishing processes in an organization, there is no model that\nelaborates activities to be performed by the SQA for effective implementation\nof processes. SQA service maturity model was proposed as a solution based on\nCMMI\\textregistered and developed to eventually proceed towards a 'Process\nImplementation Model proposing Project Managers implementing processes\nthemself'.\n  SQA Service Maturity Model is a Software Quality Assurance implementation\nframework that enables organisations to increase Efficiencies in Software\nQuality Assurance, reduce the Cost of Defects and ultimately Increasing Return\non Investment in IT.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.4941v1"
    },
    {
        "title": "Computer applications in clinical psychology",
        "authors": [
            "Alina Oana Zamoteanu"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The computer-assisted analysis is not currently a novelty, but a necessity in\nall areas of psychology. A number of studies that examine the limits of the\ncomputer assisted and analyzed interpretations, also its advantages. A series\nof studies aim to assess how the computer assisting programs are able to\nestablish a diagnosis referring to the presence of certain mental disorders. We\nwill present the results of one computer application in clinical psychology\nregarding the assessment of Theory of Mind capacity by animation.\n",
        "pdf_link": "http://arxiv.org/pdf/1202.5944v2"
    },
    {
        "title": "Verification and Diagnosis Infrastructure of SoC HDL-model",
        "authors": [
            "Vladimir Hahanov",
            "Wajeb Gharibi",
            "Eugenia Litvinova",
            "Svetlana Chumachenko"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This article describes technology for diagnosing SoC HDL-models, based on\ntransactional graph. Diagnosis method is focused to considerable decrease the\ntime of fault detection and memory for storage of diagnosis matrix by means of\nforming ternary relations in the form of test, monitor, and functional\ncomponent. The following problems are solved: creation of digital system model\nin the form of transaction graph and multi-tree of fault detection tables, as\nwell as ternary matrices for activating functional components in tests,\nrelative to the selected set of monitors; development of a method for analyzing\nthe activation matrix to detect the faults with given depth and synthesizing\nlogic functions for subsequent embedded hardware fault diagnosing.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.0665v1"
    },
    {
        "title": "Analysis of neighbour and isolated node of intersection area based\n  geocasting protocol (IBGP) in VANET",
        "authors": [
            "Sanjoy Das",
            "D . K. Lobiyal"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Geocasting is a special variant of multicasting, where data packet or message\nis transmitted to a predefined geographical location i.e., known as geocast\nregion. The applications of geocasting in VANET are to disseminate information\nlike, collision warning, advertising, alerts message, etc. In this paper, we\nhave proposed a model for highway scenario where the highway is divided into\nnumber of cells. The intersection area between two successive cells is computed\nto find the number of common nodes. Therefore, probabilistic analysis of the\nnodes present and void occurrence in the intersection area is carried out.\nFurther, we have defined different forwarding zones to restrict the number of\nparticipated nodes for data delivery. Number of nodes present and void\noccurrence in the different forwarding zones have also been analysed based on\nvarious node density in the network to determine the successful delivery of\ndata. Our analytical results show that in a densely populated network, data can\nbe transmitted with low radio transmission range. In a densely populated\nnetwork smaller forwarding zones will be selected for data delivery.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.1981v1"
    },
    {
        "title": "Spread spectrum magnetic resonance imaging",
        "authors": [
            "Gilles Puy",
            "Jose P. Marques",
            "Rolf Gruetter",
            "Jean-Philippe Thiran",
            "Dimitri Van De Ville",
            "Pierre Vandergheynst",
            "Yves Wiaux"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  We propose a novel compressed sensing technique to accelerate the magnetic\nresonance imaging (MRI) acquisition process. The method, coined spread spectrum\nMRI or simply s2MRI, consists of pre-modulating the signal of interest by a\nlinear chirp before random k-space under-sampling, and then reconstructing the\nsignal with non-linear algorithms that promote sparsity. The effectiveness of\nthe procedure is theoretically underpinned by the optimization of the coherence\nbetween the sparsity and sensing bases. The proposed technique is thoroughly\nstudied by means of numerical simulations, as well as phantom and in vivo\nexperiments on a 7T scanner. Our results suggest that s2MRI performs better\nthan state-of-the-art variable density k-space under-sampling approaches\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2205v1"
    },
    {
        "title": "An Optimum Time Quantum Using Linguistic Synthesis for Round Robin\n  Scheduling Algorithm",
        "authors": [
            "Supriya Raheja",
            "Reena Dadhich",
            "Smita Rajpal"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In Round Robin CPU scheduling algorithm the main concern is with the size of\ntime quantum and the increased waiting and turnaround time. Decision for these\nis usually based on parameters which are assumed to be precise. However, in\nmany cases the values of these parameters are vague and imprecise. The\nperformance of fuzzy logic depends upon the ability to deal with Linguistic\nvariables. With this intent, this paper attempts to generate an Optimal Time\nQuantum dynamically based on the parameters which are treated as Linguistic\nvariables. This paper also includes Mamdani Fuzzy Inference System using\nTrapezoidal membership function, results in LRRTQ Fuzzy Inference System. In\nthis paper, we present an algorithm to improve the performance of round robin\nscheduling algorithm. Numerical analysis based on LRRTQ results on proposed\nalgorithm show the improvement in the performance of the system by reducing\nunnecessary context switches and also by providing reasonable turnaround time.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2247v1"
    },
    {
        "title": "System on Programable Chip for Performance Estimation of Loom Machine",
        "authors": [
            "Gurpreet Singh",
            "Ajay Kumar Roy",
            "Surekha K S",
            "S. Pujari"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  System on programmable chip for the performance estimation of loom machine,\nwhich calculates the efficiency and meter count for weaved cloth automatically.\nAlso it calculates the efficiency of loom machine. Previously the same was done\nusing manual process which was not efficient. This article is intended for loom\nmachines which are not modern.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2272v1"
    },
    {
        "title": "Modified Quine-McCluskey Method",
        "authors": [
            "Vitthal Jadhav",
            "Amar Buchade"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The digital gates are basic electronic component of any digital circuit.\nDigital circuit should be simplified in order to reduce its cost by reducing\nnumber of digital gates required to implement it. To achieve this, we use\nBoolean expression that helps in obtaining minimum number of terms and does not\ncontain any redundant pair. Karnaugh map(K-map) and Quine-McCluskey(QM) methods\nare well known methods to simplify Boolean expression. K-map method becomes\ncomplex beyond five variable Boolean expression. Quine-McCluskey method is\ncomputer based technique for minimization of Boolean function and it is faster\nthan K-map method. This paper proposes E-sum based optimization to\nQuine-McCluskey Method to increase its performance by reducing number of\ncomparisons between mintermlist in determination of prime implicants. Modified\nQuine-McCluskey method(MQM) can be implemented to any number of variable.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2289v1"
    },
    {
        "title": "Institutional repository `eKMAIR': establishing and populating a\n  research repository for the National University \"Kyiv Mohyla Academy\"",
        "authors": [
            "Tetiana Yaroshenko"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  University libraries have an increasingly important role to play in\nsupporting open access publishing and dissemination of research outputs.1 In\nparticular, many libraries are playing a leading role in establishing and\nmanaging institutional repositories. Institutional repositories are, most\noften, Open Access Initiative (OAI)-compliant databases of a university or\nother research institution's intellectual output, most typically research\npapers, although many other forms of digital media can also be stored and\ndisseminated. Their main function is to provide improved access to the full\ntext of research articles and improve retrieval of relevant research.\n  The National University \"Kyiv Mohyla Academy\" is a small-sized institution\nwith approximately 3,000 students and 500 academic staff. Although it is a\nteaching-intensive university, developing research and knowledge-transfer\ncapacity is a strategic priority and four research institutes have been\nestablished, with further research activity going on in the academic schools\nand research centres.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2434v2"
    },
    {
        "title": "High Speed, Low Power Current Comparators with Hysteresis",
        "authors": [
            "Neeraj K. Chasta"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper, presents a novel idea for analog current comparison which\ncompares input signal current and reference currents with high speed, low power\nand well controlled hysteresis. Proposed circuit is based on current mirror and\nvoltage latching techniques which produces rail to rail output voltage as a\nresult of current comparison. The same design can be extended to a simple\ncurrent comparator without hysteresis (or very less hysteresis), where\ncomparator gives high accuracy (less than 50nA) and speed at the cost of\nmoderate power consumption. The comparators are designed optimally and studied\nat 180nm CMOS process technology for a supply voltage of 3V.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.2999v1"
    },
    {
        "title": "A Semantic Without Syntax 1",
        "authors": [
            "Farzad Didehvar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Here, by introducing a version of \"Unexpected hanging paradox\" we try to open\na new way and a new explanation for paradoxes, similar to liar paradox. Also,\nwe will show that we have a semantic situation which no syntactical logical\nsystem could support that. In the end, we propose a claim as a question. Based\non this claim, having an axiomatic system for computability theory is not\npossible. In fact we will show that the method applied here could yields us as\na generalized result, some Theories like Physic is not axiomatizable.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.3125v1"
    },
    {
        "title": "On the Impact of Information Technologies on Society: an Historical\n  Perspective through the Game of Chess",
        "authors": [
            "Frederic Prost"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The game of chess as always been viewed as an iconic representation of\nintellectual prowess. Since the very beginning of computer science, the\nchallenge of being able to program a computer capable of playing chess and\nbeating humans has been alive and used both as a mark to measure\nhardware/software progresses and as an ongoing programming challenge leading to\nnumerous discoveries. In the early days of computer science it was a topic for\nspecialists. But as computers were democratized, and the strength of chess\nengines began to increase, chess players started to appropriate to themselves\nthese new tools. We show how these interactions between the world of chess and\ninformation technologies have been herald of broader social impacts of\ninformation technologies. The game of chess, and more broadly the world of\nchess (chess players, literature, computer softwares and websites dedicated to\nchess, etc.), turns out to be a surprisingly and particularly sharp indicator\nof the changes induced in our everyday life by the information technologies.\nMoreover, in the same way that chess is a modelization of war that captures the\nraw features of strategic thinking, chess world can be seen as small society\nmaking the study of the information technologies impact easier to analyze and\nto grasp.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.3434v1"
    },
    {
        "title": "Designing of RF Single Balanced Mixer with a 65nm CMOS Technology\n  Dedicated to Low Power Consumption Wireless Applications",
        "authors": [
            "Raja Mahmou",
            "Khalid Faitah"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The present work consists of designing a Single Balanced Mixer(SBM) with the\n65 nm CMOS technology, this for a 1.9 GHz RF channel, dedicated to wireless\napplications. This paper shows; the polarization chosen for this structure,\nmodels of evaluating parameters of the mixer, then simulation of the circuit in\n65nm CMOS technology and comparison with previously treated. Keywords: SBM\nMixer, Radio Frequency, 65 nm CMOS Technology, Non-Linearity, Power\nConsumption.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.3722v1"
    },
    {
        "title": "An Open Question about Dependency of Life Time of Hardware Components\n  and Dynamic Voltage Scaling",
        "authors": [
            "Nasrin Jaberi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Open question about Dependency of Life Time of Hardware Components and\nDynamic Voltage Scaling (A primary idea)\n",
        "pdf_link": "http://arxiv.org/pdf/1203.3909v4"
    },
    {
        "title": "Building Healthcare - Patient Relationship with CRM 2.0: Lesson Learnt\n  from Prita Mulyasari's Case",
        "authors": [
            "Muhammad Anshari",
            "Mohammad Nabil Almunawar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Healthcare is implementing CRM as a strategy for managing interactions and\ncommunication with patients which involves using Information and Communication\nTechnology (ICT) to organize, automate, and coordinate business processes. CRM\nwith the Web technology provides healthcare the ability to broaden service\nbeyond its usual practices, and thus provides a particular advantageous\nenvironment for them that want to use ICT to achieve complex healthcare goal.\nThis paper we will discuss and demonstrate how a new approach in CRM will help\nthe healthcare increasing their customer support, and promoting better health\nto patient. The patients benefited from the customized personal service so that\nthey have full information access to perform self managed their own health and\nthe healthcare provider will have a loyal and retains the right customer. A\nconceptual framework of approach will be highlighted. Customer centric paradigm\nin social network's era and value creation of healthcare's business process\nwill be taken into consideration.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.3919v2"
    },
    {
        "title": "Health Information Systems (HIS): Concept and Technology",
        "authors": [
            "Mohammad Nabil Almunawar",
            "Muhammad Anshari"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  A health information system (HIS) is the intersection of between healthcare's\nbusiness process, and information systems to deliver better healthcare\nservices. The nature of healthcare industry, which is highly influenced by\neconomic, social, politic, and technological factors, has changed over time.\nThis paper will address some important concepts of healthcare and related\nterminologies to provide a holistic view for HIS. Related technological\nmilestones and major events are briefly summarized. The trends and rapid\ndevelopment of health information technologies are also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.3923v1"
    },
    {
        "title": "CRM 2.0 within E-Health Systems: Towards Achieving Health Literacy &\n  Customer Satisfaction",
        "authors": [
            "Muhammad Anshari",
            "Mohammad Nabil Almunawar",
            "Patrick Kim Cheng Low"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Customer Relationship Management (CRM) within healthcare organization can be\nviewed as a strategy to attract new customers and retaining them throughout\ntheir entire lifetime of relationships. At the same time, the advancement of\nWeb technology known as Web 2.0 plays a significant part in the CRM transition\nwhich drives social change that impacts all institutions including business and\nhealthcare organizations. This new paradigm has been named as Social CRM or CRM\n2.0 because it is based on Web 2.0. We conducted survey to examine the features\nof CRM 2.0 in healthcare scenario to the customer in Brunei Darussalam. We draw\nthe conclusion that the CRM 2.0 in healthcare technologies has brought a\npossibility to extend the services of e-health by enabling patients, patient's\nfamilies, and community at large to participate more actively in the process of\nhealth education; it helps improve health literacy through empowerment, social\nnetworking process, and online health educator. This paper is based on our\nworks presented at ICID 2011.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.4309v2"
    },
    {
        "title": "Autonomic Model for Self-Configuring C#.NET Applications",
        "authors": [
            "Youssef Bassil",
            "Paul Semaan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  With the advances in computational technologies over the last decade, large\norganizations have been investing in Information Technology to automate their\ninternal processes to cut costs and efficiently support their business\nprojects. However, this comes to a price. Business requirements always change.\nLikewise, IT systems constantly evolves as developers make new versions of\nthem, which require endless administrative manual work to customize and\nconfigure them, especially if they are being used in different contexts, by\ndifferent types of users, and for different requirements. Autonomic computing\nwas conceived to provide an answer to these ever-changing requirements.\nEssentially, autonomic systems are self-configuring, self-healing,\nself-optimizing, and self-protecting; hence, they can automate all complex IT\nprocesses without human intervention. This paper proposes an autonomic model\nbased on Venn diagram and set theory for self-configuring C#.NET applications,\nnamely the self-customization of their GUI, event-handlers, and security\npermissions. The proposed model does not require altering the source-code of\nthe original application; rather, it uses an XML-based customization file to\nturn on and off the internal attributes of the application. Experiments\nconducted on the proposed model, showed a successful automatic customization\nfor C# applications and an effective self-adaption based on dynamic business\nrequirements. As future work, other programming languages such as Java and C++\nare to be supported, in addition to other operating systems such as Linux and\nMac so as to provide a standard platform-independent autonomic self-configuring\nmodel.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.5259v1"
    },
    {
        "title": "A 100 mA Low Voltage Linear Regulators for Systems on Chip Applications\n  Using 0.18 m CMOS Technology",
        "authors": [
            "Krit Salah-ddine",
            "Zared Kamal",
            "Qjidaa Hassan",
            "Zouak Mohcine"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  A novel design for a low dropout (LDO) voltage regulator is presented and\ndedicated to power many sections of a typical cellular handset. However, these\nbaseband, RF, and audio sections have different requirements that influence\nwhich LDO is most appropriate. After discussion of the specific requirements,\ndifferent LDOs are recommended. Also, some LDO design techniques are briefly\ndiscussed to demonstrate how an LDO may be optimized for a specific level of\nperformance. Cellular phone designs require linear regulators with lowdropout,\nlow-noise, high PSRR, low quiescent current (Iq), and low-cost. They need to\ndeliver a stable output and use smallvalue output capacitors. Ideally, one\ndevice would have all these characteristics and one low-dropout linear\nregulator (LDO) could be used anywhere in the phone without worry. But in\npractice, the various cell phone blocks are best powered by LDOs with different\nperformance characteristics. This paper provides a new design methodology to\nchoosing the right LDO to power each cell phone and especially for the Voltage\nPhase-Locked loops (VPLLs) blocks. Fabricated in a 0.18 {\\mu}m CMOS process,\nthe measured results show the adopted topology achieves a better phase noise\nthan the conventional saturation current source. and the spread of the current\nlimitation (without matching) is 100mA, the VPLLs system demonstrates a phase\nnoise of 782 nv/sqrtHz at 100-kHz, and 33 nv/sqrtHz at 1 MHz, while quiescent\ncurrent 33 {\\mu}A from a 2.6 V supply voltage.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.5778v1"
    },
    {
        "title": "A Scheme for Automation of Telecom Data Processing for Business\n  Application",
        "authors": [
            "T. R. Gopalakrishnan Nair",
            "Vithal. J. Sampagar",
            "V. Suma",
            "Ezhilarasan Maharajan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  As the telecom industry is witnessing a large scale growth, one of the major\nchallenges faced in the domain deals with the analysis and processing of\ntelecom transactional data which are generated in large volumes by embedded\nsystem communication controllers having various functions. This paper deals\nwith the analysis of such raw data files which are made up of the sequences of\nthe tokens. It also depicts the method in which the files are parsed for\nextracting the information leading to the final storage in predefined data base\ntables. The parser is capable of reading the file in a line structured way and\nstore the tokens into the predefined tables of data bases. The whole process is\nautomated using the SSIS tools available in the SQL server. The log table is\nmaintained in each step of the process which will enable tracking of the file\nfor any risk mitigation. It can extract, transform and load data resulting in\nthe processing.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6438v1"
    },
    {
        "title": "Critical Task Re-assignment under Hybrid Scheduling Approach in\n  Multiprocessor Real-Time Systems",
        "authors": [
            "Gopalakrishnan T. R. Nair",
            "Christy A. Persya"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Embedded hard real time systems require substantial amount of emergency\nprocessing power for the management of large scale systems like a nuclear power\nplant under the threat of an earth quake or a future transport systems under a\nperil. In order to meet a fully coordinated supervisory control of multiple\ndomains of a large scale system, it requires the scenario of engaging\nmultiprocessor real time design. There are various types of scheduling schemes\nexisting for meeting the critical task assignment in multiple processor\nenvironments and it requires the tracking of faulty conditions of the subsystem\nto avoid system underperformance from failure patterns. Hybrid scheduling\nusually engages a combined scheduling philosophy comprising of a static\nscheduling of a set of tasks and a highly pre-emptive scheduling for another\nset of tasks in different situations of process control. There are instances\nwhere highly critical tasks need to be introduced at a least expected\ncatastrophe and it cannot be ensured to meet all deadline in selected\nprocessors because of the arrival pattern of such tasks and they bear low\ntolerance of time to meet the required target. In such circumstances an\neffective switching of processors for this set of task is feasible and we\ndescribe a method to achieve this effectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.6719v1"
    },
    {
        "title": "A Simulation Approach Paradigm: An Optimization and Inventory Challenge\n  Case Study",
        "authors": [
            "Heru Susanto",
            "Mohammad Nabil Almunawar",
            "Mehmet Sabih Aksoy",
            "Yong Chee Tuan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The paper presents a simulation on automotive inventory and stock issue,\nfollowed by evaluated performance of automotif Sector Company, focused on\ngetting optimum profit from supply and demand balancing. Starting by evaluating\nand verification of customer's document until car delivered to customer.\nSimulation method of performance is used to evaluate company activity. excess\ndemand of car by customer, not eligible customer to rented a car, number of\ncustomer who served and number of customer who served including the driver, the\nlast result is number of optimum demand that match with the stock or supply of\ncar by the company. Finally, board of management should be making decision; the\nfirst decision is buy the new car for meet with the demand or second decision\nis recruit new staff for increasing customer service or customer care.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.0225v1"
    },
    {
        "title": "A procedural framework and mathematical analysis for solid sweeps",
        "authors": [
            "Bharat Adsul",
            "Jinesh Machchhar",
            "Milind Sohoni"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Sweeping is a powerful and versatile method of designing objects. Boundary of\nvolumes (henceforth envelope) obtained by sweeping solids have been extensively\ninvestigated in the past, though, obtaining an accurate parametrization of the\nenvelope remained computationally hard. The present work reports our approach\nto this problem as well as the important problem of identifying\nself-intersections within the envelope. Parametrization of the envelope is, of\ncourse, necessary for its use in most current CAD systems. We take the more\ninteresting case when the solid is composed of several faces meeting smoothly.\nWe show that the face structure of the envelope mimics locally that of the\nsolid. We adopt the procedural approach at defining the geometry in this work\nwhich has the advantage of being accurate as well as computationally efficient.\nThe problem of detecting local self-intersections is central to a robust\nimplementation of the solid sweep. This has been addressed by computing a\nsubtle mathematical invariant which detects self-intersections, and which is\ncomputationally benign and requires only point queries.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.0908v1"
    },
    {
        "title": "Exploring Application Logs",
        "authors": [
            "Janusz Sosnowski"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper deals with the problem of analyzing application event logs in\nrelevance to dependability evaluation. We present the significance of\napplication logs as a valuable source of information on operational profiles,\nanomalies and errors. They can enhance classical approaches based on monitoring\nsystem logs and performance variables. Keywords; event monitoring, operational\nprofiles, anomalies\n",
        "pdf_link": "http://arxiv.org/pdf/1204.1169v1"
    },
    {
        "title": "Towards Quranic reader controlled by speech",
        "authors": [
            "Yacine Yekache",
            "Yekhlef Mekelleche",
            "Belkacem Kouninef"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper we describe the process of designing a task-oriented continuous\nspeech recognition system for Arabic, based on CMU Sphinx4, to be used in the\nvoice interface of Quranic reader. The concept of the Quranic reader controlled\nby speech is presented, the collection of the corpus and creation of acoustic\nmodel are described in detail taking into account a specificities of Arabic\nlanguage and the desired application.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.1566v1"
    },
    {
        "title": "Mobile Web - Strategy for Enterprise Success",
        "authors": [
            "Jitendra Maan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Today, enterprises are faced with increased global competition in an\nenvironment where customers are demanding faster delivery, better service and\nalso want to gain significant and immediate business value by increasing\nproductivity and reducing operational cost. Spurred by unprecedented customer\ndemand, each Industry cluster has developed its own source of comparative\nadvantage. Even within a single organization, the business value chain is\ngeographically fragmented. Such diversification and fragmentation of value\nchain drives the need for cross-platform Web applications over mobile channel.\nMobile Web is the next logical transition in this evolutionary process and\nMobile Web applications will continue to gain more prominence in the\nenterprises not just to improve the return on investment in their existing\nsystem landscape, but also to expand global reach and improve operational\nefficiency of their mobile workforce. This paper outlines the critical business\nneeds to rapidly create flexible Mobile web solutions across all lines of\nbusiness. The paper enlightens the benefits offered by enabling web\napplications on Mobile devices and also addresses the current business\nchallenges in developing Mobile Web applications. This paper is intended for\nall business domains irrespective of application portfolios.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.1802v1"
    },
    {
        "title": "Design and Implementation of BCM Rule Based on Spike-Timing Dependent\n  Plasticity",
        "authors": [
            "Mostafa Rahimi Azghadi",
            "Said Al-Sarawi",
            "Nicolangelo Iannella",
            "Derek Abbott"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The Bienenstock-Cooper-Munro (BCM) and Spike Timing-Dependent Plasticity\n(STDP) rules are two experimentally verified form of synaptic plasticity where\nthe alteration of synaptic weight depends upon the rate and the timing of pre-\nand post-synaptic firing of action potentials, respectively. Previous studies\nhave reported that under specific conditions, i.e. when a random train of\nPoissonian distributed spikes are used as inputs, and weight changes occur\naccording to STDP, it has been shown that the BCM rule is an emergent property.\nHere, the applied STDP rule can be either classical pair-based STDP rule, or\nthe more powerful triplet-based STDP rule. In this paper, we demonstrate the\nuse of two distinct VLSI circuit implementations of STDP to examine whether BCM\nlearning is an emergent property of STDP. These circuits are stimulated with\nrandom Poissonian spike trains. The first circuit implements the classical\npair-based STDP, while the second circuit realizes a previously described\ntriplet-based STDP rule. These two circuits are simulated using 0.35 um CMOS\nstandard model in HSpice simulator. Simulation results demonstrate that the\nproposed triplet-based STDP circuit significantly produces the threshold-based\nbehaviour of the BCM. Also, the results testify to similar behaviour for the\nVLSI circuit for pair-based STDP in generating the BCM.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.1840v1"
    },
    {
        "title": "Construction of Community Web Directories based on Web usage Data",
        "authors": [
            "Ramancha Sandhyarani",
            "Bodakuntla Rajkumar",
            "Jayadev Gyani"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper support the concept of a community Web directory, as a Web\ndirectory that is constructed according to the needs and interests of\nparticular user communities. Furthermore, it presents the complete method for\nthe construction of such directories by using web usage data. User community\nmodels take the form of thematic hierarchies and are constructed by employing\nclustering approach. We applied our methodology to the ODP directory and also\nto an artificial Web directory, which was generated by clustering Web pages\nthat appear in the access log of an Internet Service Provider. For the\ndiscovery of the community models, we introduced a new criterion that combines\na priori thematic informativeness of the Web directory categories with the\nlevel of interest observed in the usage data. In this context, we introduced\nand evaluated new clustering method. We have tested the methodology using\naccess log files which are collected from the proxy servers of an Internet\nService Provider and provided results that indicates the usability of the\ncommunity Web directories. The proposed clustering methodology is evaluated\nboth on a specialized artificial and a community Web directory, indicating its\nvalue to the user of the web.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.2225v1"
    },
    {
        "title": "Introducing convex layers to the Traveling Salesman Problem",
        "authors": [
            "Sing Liew"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, we will propose convex layers to the Traveling Salesman\nProblem (TSP). Firstly, we will focus on human performance on the TSP.\nExperimental data shows that untrained humans appear to have the ability to\nperform well in the TSP. On the other hand, experimental data also supports the\nhypothesis of convex hull i.e. human relies on convex hull to search for the\noptimal tour for the TSP. Secondly, from the paper published by Bonabeau,\nDorigo and Theraulaz, social insect behavior would be able to help in some of\nthe optimizing problems, especially the TSP. Thus, we propose convex layers to\nthe TSP based on the argument that, by the analogy to the social insect\nbehavior, untrained humans' cognition should be able to help in the TSP.\nLastly, we will use Tour Improvement algorithms on convex layers to search for\nan optimal tour for a 13-cities problem to demonstrate the idea.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.2348v1"
    },
    {
        "title": "Applying convex layers, nearest neighbor and triangle inequality to the\n  Traveling Salesman Problem (TSP)",
        "authors": [
            "Sing Liew"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The author would like to propose a simple but yet effective method, convex\nlayers, nearest neighbor and triangle inequality, to approach the Traveling\nSalesman Problem (TSP). No computer is needed in this method. This method is\ndesigned for plain folks who faced the TSP everyday but do not have the\nsophisticated knowledge of computer science, programming language or applied\nmathematics. The author also hopes that it would give some insights to\nresearchers who are interested in the TSP.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.2350v1"
    },
    {
        "title": "Optimal tree for Genetic Algorithms in the Traveling Salesman Problem\n  (TSP)",
        "authors": [
            "Sing Liew"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, the author proposes optimal tree as a \"gauge\" for the\ngeneration of the initial population at random in the Genetic Algorithms (GA)\nto benchmark against the good and the bad parent tours. Thus, without having\nthe so-called bad parent tours in the initiate population, it will speed up the\nGA. The characteristics of the gauge (algorithm, complexity time, trade-off,\netc.) will be discussed in this paper as well.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.2352v1"
    },
    {
        "title": "Cloud Computing For Microfinances",
        "authors": [
            "Suma. V",
            "Bhagavant Deshpande",
            "Vaidehi. M",
            "T. R. Gopalakrishnan Nair"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Evolution of Science and Engineering has led to the growth of several\ncommercial applications. The wide spread implementation of commercial based\napplications has in turn directed the emergence of advanced technologies such\nas cloud computing. India has well proven itself as a potential hub for\nadvanced technologies including cloud based industrial market. Microfinance\nsystem has emerged out as a panacea to Indian economy since the population\nencompasses of people who come under poverty and below poverty index. However,\none of the key challenges in successful operation of microfinance system in\nIndia has given rise to integration of financial services using sophisticated\ncloud computing model. This paper, therefore propose a fundamental cloud-based\nmicrofinance model in order to reduce high transaction risks involved during\nmicrofinance operations in an inexpensive and efficient manner.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.2613v1"
    },
    {
        "title": "Teaching Chemistry in a Social Learning Environment: Facing Drivers and\n  Barriers",
        "authors": [
            "Cornelia Castro",
            "Antonio Andrade"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The Portuguese Technological Plan for Education (TPE) was established to\nmodernize schools and to consolidate the role of Information and Communication\nTechnologies (ICT) in order to promote the academic success of students and\nallow schools to be transformed into technological enriched environments\nthrough a significant learning and knowledge building in a participatory,\ncollaborative and sharing logic. With this work we aimed to establish dynamical\ninteractions students-content- teacher in order to overcome a diagnosed\nstudents' lack of effort towards studying curriculum chemistry content. Our\nmethodology design is a theoretical and descriptive one, carried out in a\nsecondary school during the 2009/2010 school year, in order to answer the\nquestion \"How to improve the engagement of K-12 students in chemistry\nclasses?\". Students, gathered in small groups were asked to create digital\nlearning resources (DLR) during classes. The teacher assumed the role of the\nsupervisor, coacher and facilitator of every task that had to be taken or\nchosen by the students. To enhance interaction student-student and\nstudent-teacher, a Twitter account and a Ning site were created for the class.\nBoth supported the Social Learning Environment (SLE) that was intended to be\ncreated. The data collected led us to satisfactory results in what concerns the\ngoals of the study. The affordances and constraints of SLE as an open\narchitecture that has potential to facilitate collaborative learning are\ndelineated. Future work should focus on mechanisms that allow assessment both\nof the methodology used and the students' generated content in order to improve\nstudents' learning in this environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3164v1"
    },
    {
        "title": "Towards Fuzzy-Hard Clustering Mapping Processes",
        "authors": [
            "Minyar Sassi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Although the validation step can appear crucial in the case of clustering\nadopting fuzzy approaches, the problem of the partition validity obtained by\nthose adopting the hard ones was not tackled. To cure this problem, we propose\nin this paper fuzzy-hard mapping processes of clustering while benefitting from\nthose adopting the fuzzy case. These mapping processes concern: (1) local and\nglobal clustering evaluation measures: the first for the detection of the\n\"worst\" clusters to merging or splitting them. The second relates to the\nevaluation of the obtained partition for each iteration, (2) merging and\nsplitting processes taking into account the proposed measures, and (3)\nautomatic clustering algorithms implementing these new concepts.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3224v1"
    },
    {
        "title": "Improving Customer Service in Healthcare with CRM 2.0",
        "authors": [
            "Mohammad Nabil Almunawar",
            "Muhammad Anshari"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The Healthcare industry is undergoing a paradigm shift from healthcare\ninstitution-centred care to a citizen-centred care that emphasises on\ncontinuity of care from prevention to rehabilitation. The recent development of\nInformation and Communication Technology (ICT), especially the Internet and its\nrelated technologies has become the main driver of the paradigm shift. Managing\nrelationship with customers (patients) is becoming more important in the new\nparadigm. The paper discusses Customer Relationship Management (CRM) in\nhealthcare and proposes a Social CRM or CRM 2.0 model to take advantage of the\nmulti-way relationships created by Web 2.0 and its widespread use in improving\ncustomer services for mutual benefits between healthcare providers and their\ncustomers.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3685v1"
    },
    {
        "title": "E-Health Initiative and Customer's Expectation: Case Brunei",
        "authors": [
            "Mohammad Nabil Almunawar",
            "Zaw Wint",
            "Patrick Kim Cheng Low",
            "Muhammad Anshari"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper is to determine the dimension of e-health services in Brunei\nDarussalam (Brunei) from customers' perspective. It is to identify, understand,\nanalyze and evaluate public's expectation on e-health in Brunei. A\nquestionnaire was designed to gather quantitative and qualitative data to\nsurvey patients, patient's family, and health practitioners at hospitals,\nclinics, or home care centers in Brunei starting from February to March, 2011.\nA 25-item Likert-type survey instrument was specifically developed for this\nstudy and administered to a sample of 366 patients. The data were analyzed to\nprovide initial ideas and recommendation to policy makers on how to move\nforward with the e-health initiative as a mean to improve healthcare services.\nThe survey revealed that there exists a high demand and expectation from people\nin Brunei to have better healthcare services accessible through an e-health\nsystem in order to improve health literacy as well as quality and efficiency of\nhealthcare. Regardless of the limitations of the survey, the general public has\nresponded with a great support for the capabilities of an e-health system\nlisted from the questionnaires. The results of the survey provide a solid\nfoundation for our on going research project to proceed further to develop a\nmodel of e-health and subsequently develop a system prototype that incorporate\nexpectations from the people.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3691v1"
    },
    {
        "title": "Stimulus and correlation matching measurement technique in computer\n  based characterization testing",
        "authors": [
            "A. M. Dorman"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Constructive theory of characterization test is considered. The theory is\napplicable to a nano devices characterization: current-voltage, Auger current\ndependence. Generally small response of device under test on an applied\nstimulus is masked by an unknown deterministic background and a random noise.\nCharacterization test in this signal corruption scenario should be based on\ncorrelation measurement technique of device response on applied optimal\nstimulus with optimal reference signal. Co-synthesis solution of stimulus and\nreference signal is proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.3881v1"
    },
    {
        "title": "A Cost- Effective Design of Reversible Programmable Logic Array",
        "authors": [
            "Pradeep Singla",
            "Naveen Kr. Malik"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In the recent era, Reversible computing is a growing field having\napplications in nanotechnology, optical information processing, quantum\nnetworks etc. In this paper, the authors show the design of a cost effective\nreversible programmable logic array using VHDL. It is simulated on xilinx ISE\n8.2i and results are shown. The proposed reversible Programming logic array\ncalled RPLA is designed by MUX gate [10] & Feynman gate for 3- inputs, which is\nable to perform any reversible 3- input logic function or Boolean function.\nFurthermore the quantized analysis with camparitive finding is shown for the\nrealized RPLA against the existing one. The result shows improvement in the\nquantum cost and total logical caculation in proposed RPLA.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.5525v1"
    },
    {
        "title": "Towards the Solution of Power Dissipation in Electronics Systems through\n  Thermodynamics",
        "authors": [
            "Pradeep Singla",
            " Satyan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Power loss in the electronic system is a very crucial limiting factor that\ncan be reduced or minimized with the help of using the reversible logics \"a\nconcept came from Thermodynamics\". In this paper the authors shows the concept\nof reversible logics for the Electronics system. The logical and physical\ndesigning approach is given in the paper in detail. The contradiction of\nlogical and physical reversibility with the conventional CMOS designing is also\nshows and the solution of that contradiction is also proposed by the authors\nusing adiabatic logic. This Paper gives a complete and clear idea if the\nthermodynamical concept for the electronics industries for power reduction.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.5526v2"
    },
    {
        "title": "Specification and Verification of Uplink Framework for Application of\n  Software Engineering using RM-ODP",
        "authors": [
            "Krit Salahddine",
            "Laassiri Jalal",
            "El Hajji Said"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper present a survey and discussion of the Reference Model for Open\nDistributed Processing (RM-ODP) viewpoints; oriented approaches to requirements\nengineering viewpoint and a presentation of new work in the application\nwireless mobile phone, this area which has been designed with practical\napplication using the Unified Modelling Language (UML)/VHDL_AMS (VHSIC Hardware\nDescription Language Analog and Mixed-Signal). We mainly focus on rising and\nfulling time, action, uplink behaviour constraints (sequentiality, non\ndeterminism and concurrency constraints).We discuss the practical problems of\nintroducing viewpoint; oriented requirements engineering into industrial\nsoftware engineering practice and why these have prevented the widespread use\nof existing approaches. The goal of this article is to check the uplink path\nusing the MIC (Microphone amplifier) with all analog inputs, and check the\namplifier gain. This paper provides an example of using the Uplink Framework to\nbuild a comprehensive, good solution for Application Wireless Mobile Phone.\nFinally, we discuss how well this approach addresses some outstanding problems\nin requirements engineering (RE) and the practical industrial problems of\nintroducing new requirements engineering methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1204.6729v1"
    },
    {
        "title": "A Novel Window Function Yielding Suppressed Mainlobe Width and Minimum\n  Sidelobe Peak",
        "authors": [
            "Md Abdus Samad"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In many applications like FIR filters, FFT, signal processing and\nmeasurements, we are required (~45 dB) or less side lobes amplitudes. However,\nthe problem is usual window based FIR filter design lies in its side lobes\namplitudes that are higher than the requirement of application. We propose a\nwindow function, which has better performance like narrower main lobe width,\nminimum side lobe peak compared to the several commonly used windows. The\nproposed window has slightly larger main lobe width of the commonly used\nHamming window, while featuring 6.2\\ sim 22.62 dB smaller side lobe peak. The\nproposed window maintains its maximum side lobe peak about -58.4 \\sim -52.6 dB\ncompared to -35.8 \\sim -38.8 dB of Hamming window for M=10~14, while offering\nroughly equal main lobe width. Our simulated results also show significant\nperformance upgrading of the proposed window compared to the Kaiser, Gaussian,\nand Lanczos windows. The proposed window also shows better performance than\nDolph-Chebyshev window. Finally, the example of designed low pass FIR filter\nconfirms the efficiency of the proposed window.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1618v1"
    },
    {
        "title": "Visitor schedule management system- an intelligent decision support\n  system",
        "authors": [
            "Srinivas Nidhra",
            "Likith Poovanna",
            "Vinay Sudha Ethiraj"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Travelling salesman problem is a problem which is of high interest for\nresearchers, industry professionals, and academicians. Visitor or salesman used\nto face lot of problems with respect to scheduling based on meeting top ranked\nclients. Even excel sheet made the work tedious. So these flaws propelled us to\ndesign an intelligent decision support system. This paper reports the problem\ndefinition we tried to address and possible solution to this problem. We even\nexplained the project design and implementation of our visitor schedule\nmanagement system.. Our system made a major contribution in terms of valuable\nresources such as time and satisfying high ranked clients efficiently. We used\noptimization via mathematical programming to solve these issues.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1632v1"
    },
    {
        "title": "Traductor Writing System Web",
        "authors": [
            "Jose Texier",
            "Bermudez Manuel"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  A compilator is a program which is development in a programming language that\nread a file known as source. After this file have to translate and have to\nconvert in other program known as object or to generate a exit. The best way\nfor to know any programming language is analizing a compilation process which\nis same in all programming paradigm existents. To like to generate a tool that\npermit a learning in university course. This course could explain in any\nplataform such as Linux o Windows. This goal is posible through development a\nWeb aplication which is unite with a compilator, it is Traductor Writing System\n(Sistema de Escritura de Traductores). This system is complete and permit\nextend and modify the compilator. The system is a module in Moodle which is a\nCourse Management System (CMS) that help teachers for to create comunities of\nlearning in line. This software is in free software license (GPL).\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1642v1"
    },
    {
        "title": "The necessities for building a model to evaluate Business Intelligence\n  projects- Literature Review",
        "authors": [
            "Vahid Farrokhi",
            "Laszlo Pokoradi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In recent years Business Intelligence (BI) systems have consistently been\nrated as one of the highest priorities of Information Systems (IS) and business\nleaders. BI allows firms to apply information for supporting their processes\nand decisions by combining its capabilities in both of organizational and\ntechnical issues. Many of companies are being spent a significant portion of\nits IT budgets on business intelligence and related technology. Evaluation of\nBI readiness is vital because it serves two important goals. First, it shows\ngaps areas where company is not ready to proceed with its BI efforts. By\nidentifying BI readiness gaps, we can avoid wasting time and resources. Second,\nthe evaluation guides us what we need to close the gaps and implement BI with a\nhigh probability of success. This paper proposes to present an overview of BI\nand necessities for evaluation of readiness. Key words: Business intelligence,\nEvaluation, Success, Readiness\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1643v1"
    },
    {
        "title": "The impact of pharmacybernetic in reducing medication error",
        "authors": [
            "Muhammad Shahzad Aslam"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Doctors and Pharmacists play a foremost role in safe, effective use of\nmedication in health care. Still, there is no database available through which\nDoctor can communicate with all field of pharmacy such as hospital Pharmacy,\nClinical Pharmacy, Community Pharmacy, Nutrition Pharmacy and Drug research\ncenter so that they would like to cooperate with pharmacists in Medication\nerror prevention, Drug-Disease management, Nutrition management, and\npharmacotherapy. The authors examined the comprehensive project of implementing\nElectronic Drug Information Record (EDIR), introduce the new term\nPharmacybernetic and how to reduce the medication error by integrated\nmanagement system (IMS). This paper presented EDIR conceptual model and the\nflow sheet of the Pharmacybernetic system, which describes the integration of\ndifferent Pharmaceutical related aspect in the field of Cybernetic.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1649v1"
    },
    {
        "title": "Factors affecting acceptance of web-based training system: Using\n  extended UTAUT and structural equation modeling",
        "authors": [
            "Thamer A. Alrawashdeh",
            "Mohammad I. Muhairat",
            "Sokyna M. Alqatawnah"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Advancement in information system leads organizations to apply e-learning\nsystem to train their employees in order to enhance its performance. In this\nrespect, applying web based training will enable the organization to train\ntheir employees quickly, efficiently and effectively anywhere at any time. This\nresearch aims to extend Unified Theory of Acceptance and Use Technology (UTAUT)\nusing some factors such flexibility of web based training system, system\ninteractivity and system enjoyment, in order to explain the employees'\nintention to use web based training system. A total of 290 employees have\nparticipated in this study. The findings of the study revealed that performance\nexpectancy, facilitating conditions, social influence and system flexibility\nhave direct effect on the employees' intention to use web based training\nsystem, while effort expectancy, system enjoyment and system interactivity have\nindirect effect on employees' intention to use the system.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1904v1"
    },
    {
        "title": "Dynamic Grouping of Web Users Based on Their Web Access Patterns using\n  ART1 Neural Network Clustering Algorithm",
        "authors": [
            "C. Ramya",
            "G. Kavitha",
            "K. S. Shreedhara"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, we propose ART1 neural network clustering algorithm to group\nusers according to their Web access patterns. We compare the quality of\nclustering of our ART1 based clustering technique with that of the K-Means and\nSOM clustering algorithms in terms of inter-cluster and intra-cluster\ndistances. The results show the average inter-cluster distance of ART1 is high\ncompared to K-Means and SOM when there are fewer clusters. As the number of\nclusters increases, average inter-cluster distance of ART1 is low compared to\nK-Means and SOM which indicates the high quality of clusters formed by our\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.1938v1"
    },
    {
        "title": "Analysis of WiMAX Physical Layer Using Spatial Multiplexing",
        "authors": [
            "Pavani Sanghoi",
            "Lavish Kansal"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Broadband Wireless Access (BWA) has emerged as a promising solution for\nproviding last mile internet access technology to provide high speed internet\naccess to the users in the residential as well as in the small and medium sized\nenterprise sectors. IEEE 802.16e is one of the most promising and attractive\ncandidate among the emerging technologies for broadband wireless access. The\nemergence of WiMAX protocol has attracted various interests from almost all the\nfields of wireless communications. MIMO systems which are created according to\nthe IEEE 802.16-2005 standard (WiMAX) under different fading channels can be\nimplemented to get the benefits of both the MIMO and WiMAX technologies. In\nthis paper analysis of higher level of modulations (i.e. M-PSK and M-QAM for\ndifferent values of M) with different code rates and on WiMAX-MIMO system is\npresented for Rayleigh channel by focusing on spatial multiplexing MIMO\ntechnique. Signal-to Noise Ratio (SNR) vs Bit Error Rate (BER) analysis has\nbeen done.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.2053v1"
    },
    {
        "title": "A Greedy Double Swap Heuristic for Nurse Scheduling",
        "authors": [
            "Murphy Choy",
            "Michelle Cheong"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  One of the key challenges of nurse scheduling problem (NSP) is the number of\nconstraints placed on preparing the timetable, both from the regulatory\nrequirements as well as the patients' demand for the appropriate nursing care\nspecialists. In addition, the preferences of the nursing staffs related to\ntheir work schedules add another dimension of complexity. Most solutions\nproposed for solving nurse scheduling involve the use of mathematical\nprogramming and generally considers only the hard constraints. However, the\npsychological needs of the nurses are ignored and this resulted in subsequent\ninterventions by the nursing staffs to remedy any deficiency and often results\nin last minute changes to the schedule. In this paper, we present a staff\npreference optimization framework which is solved with a greedy double swap\nheuristic. The heuristic yields good performance in speed at solving the\nproblem. The heuristic is simple and we will demonstrate its performance by\nimplementing it on open source spreadsheet software.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.2200v1"
    },
    {
        "title": "Maximum Spanning Tree Model on Personalized Web Based Collaborative\n  Learning in Web 3.0",
        "authors": [
            "S. Padma",
            "Ananthi Seshasaayee"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Web 3.0 is an evolving extension of the current web environme bnt.\nInformation in web 3.0 can be collaborated and communicated when queried. Web\n3.0 architecture provides an excellent learning experience to the students. Web\n3.0 is 3D, media centric and semantic. Web based learning has been on high in\nrecent days. Web 3.0 has intelligent agents as tutors to collect and\ndisseminate the answers to the queries by the students. Completely Interactive\nlearner's query determine the customization of the intelligent tutor. This\npaper analyses the Web 3.0 learning environment attributes. A Maximum spanning\ntree model for the personalized web based collaborative learning is designed.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.2263v1"
    },
    {
        "title": "Juppix: a Linux Live-CD for Undergraduate Students",
        "authors": [
            "Juliusz Chroboczek",
            "Sylvain Lebresne"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Juppix is a Linux Live-CD with a comfortable programming environment for the\nJava, C and O'Caml programming languages that has been distributed to hundreds\nof undergaduate students at the University of Paris 7 over the last few years.\nWe describe the lessons we learnt while compiling and distributing Juppix, and\noutline our future plans.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.2748v1"
    },
    {
        "title": "Finite State Machine based Vending Machine Controller with Auto-Billing\n  Features",
        "authors": [
            "Ana Monga",
            "Balwinder Singh"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Nowadays, Vending Machines are well known among Japan, Malaysia and\nSingapore. The quantity of machines in these countries is on the top worldwide.\nThis is due to the modern lifestyles which require fast food processing with\nhigh quality. This paper describes the designing of multi select machine using\nFinite State Machine Model with Auto-Billing Features. Finite State Machine\n(FSM) modelling is the most crucial part in developing proposed model as this\nreduces the hardware. In this paper the process of four state (user Selection,\nWaiting for money insertion, product delivery and servicing) has been modelled\nusing MEALY Machine Model. The proposed model is tested using Spartan 3\ndevelopment board and its performance is compared with CMOS based machine.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.3642v1"
    },
    {
        "title": "Adaptive Reduced-Rank LCMV Beamforming Algorithms Based on Joint\n  Iterative Optimization of Filters: Design and Analysis",
        "authors": [
            "R. C. de Lamare",
            "L. Wang",
            "R. Fa"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper presents reduced-rank linearly constrained minimum variance (LCMV)\nbeamforming algorithms based on joint iterative optimization of filters. The\nproposed reduced-rank scheme is based on a constrained joint iterative\noptimization of filters according to the minimum variance criterion. The\nproposed optimization procedure adjusts the parameters of a projection matrix\nand an adaptive reducedrank filter that operates at the output of the bank of\nfilters. We describe LCMV expressions for the design of the projection matrix\nand the reduced-rank filter. We then describe stochastic gradient and develop\nrecursive least-squares adaptive algorithms for their efficient implementation\nalong with automatic rank selection techniques. An analysis of the stability\nand the convergence properties of the proposed algorithms is presented and\nsemi-analytical expressions are derived for predicting their mean squared error\n(MSE) performance. Simulations for a beamforming application show that the\nproposed scheme and algorithms outperform in convergence and tracking the\nexisting full-rank and reduced-rank algorithms while requiring comparable\ncomplexity\n",
        "pdf_link": "http://arxiv.org/pdf/1205.4391v1"
    },
    {
        "title": "CloudPass - a passport system based on Cloud Computing and Near Field\n  Communication",
        "authors": [
            "Adethya Sudarsanan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Wireless communication has penetrated into all fields of technology,\nespecially in mobility, where wireless transactions are gaining importance with\nimprovements in standards like 3G and 4G. There are many technologies that\nsupport the wireless forms of interactions between devices. One among them is\nNFC - Near Field Communication. In addition to NFC, other external technologies\nlike Quick Response (QR) Codes assist in establishing interactions among\nparticipating devices. In this paper, we examine an approach that will involve\nstandards and technologies like NFC, QR Codes and Cloud Infrastructure to\ndesign a mobile application which will perform desired functionalities. Cloud\nStorage is used as a reservoir to store the artifacts used by the application.\nDevelopment and testing of the application is initially carried out on\nemulators or simulators followed by testing on real handsets/devices.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.4900v1"
    },
    {
        "title": "Determination of RF source power in WPSN using modulated backscattering",
        "authors": [
            "K. Sreedhar",
            "Y. Sreenivasulu"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  A wireless sensor network (WSN) is a wireless network consisting of spatially\ndistributed autonomous devices using sensors to cooperatively monitor physical\nor environmental conditions, such as temperature, sound, vibration, pressure,\nmotion or pollutants, at different locations. During RF transmission energy\nconsumed by critically energy-constrained sensor nodes in a WSN is related to\nthe life time system, but the life time of the system is inversely proportional\nto the energy consumed by sensor nodes. In that regard, modulated\nbackscattering (MB) is a promising design choice, in which sensor nodes send\ntheir data just by switching their antenna impedance and reflecting the\nincident signal coming from an RF source. Hence wireless passive sensor\nnetworks (WPSN) designed to operate using MB do not have the lifetime\nconstraints. In this we are going to investigate the system analytically. To\nobtain interference-free communication connectivity with the WPSN nodes number\nof RF sources is determined and analyzed in terms of output power and the\ntransmission frequency of RF sources, network size, RF source and WPSN node\ncharacteristics. The results of this paper reveal that communication coverage\nand RF Source Power can be practically maintained in WPSN through careful\nselection of design parameters\n",
        "pdf_link": "http://arxiv.org/pdf/1205.4984v1"
    },
    {
        "title": "MIPS code compression",
        "authors": [
            "Tommi Hirvola"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  MIPS machine code is very structured: registers used before are likely to be\nused again, some instructions and registers are used more heavily than others,\nsome instructions often follow each other and so on. Standard file compression\nutilities, such as gzip and bzip2, does not take full advantage of the\nstructure because they work on byte-boundaries and don't see the underlying\ninstruction fields. My idea is to filter opcodes, registers and immediates from\nMIPS binary code into distinct streams and compress them individually to\nachieve better compression ratios. Several different ways to split MIPS code\ninto streams are considered. The results presented in this paper shows that a\nsimple filter can reduce final compressed size by up to 10 % with gzip and\nbzip2.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.6680v1"
    },
    {
        "title": "Open source based cadastral information system : ANCFCC-MOROCCO",
        "authors": [
            "Hicham Elasri",
            "Neknane Mehdi",
            "Aatab Jamila",
            "Ganoun Karima"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This present project is developing a geographic information system to support\nthe cadastral business. This system based on open source solutions which\ndeveloped within the National Agency of Land Registry, Cadastre and Cartography\n(ANCFCC) enabling monitoring and analysis of cadastral procedures as well as\noffering consumable services by other information systems: consultation and\nquerying spatial data. The project will also assist the various user profiles\nin the completion of production tasks and the possibility to eliminate the\ndeficiencies identified to ensure an optimum level of productivity\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0142v1"
    },
    {
        "title": "DSTN (Distributed Sleep Transistor Network) for Low Power Programmable\n  Logic array Design",
        "authors": [
            "Pradeep Singla",
            "Kamya Dhingra",
            "Naveen Kr. Malik"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  With the high demand of the portable electronic products, Low- power design\nof VLSI circuits & Power dissipation has been recognized as a challenging\ntechnology in the recent years. PLA (Programming logic array) is one of the\nimportant off shelf part in the industrial application. This paper describes\nthe new design of PLA using power gating structure sleep transistor at circuit\nlevel implementation for the low power applications. The important part of the\npower gating design i.e. header and footer switch selection is also describes\nin the paper. The simulating results of the proposed architecture of the new\nPLA is shown and compared with the conventional PLA. This paper clearly shows\nthe optimization in the reduction of power dissipation in the new design\nimplementation of the PLA. The transient response of the power gates structure\nof PLA is also illustrate in the paper by using TINA-PRO software.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0169v1"
    },
    {
        "title": "An Architecture for Context-Aware Knowledge Flow Management Systems",
        "authors": [
            "Ali Jarrahi",
            "Mohammad Reza Kangavari"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The organizational knowledge is one of the most important and valuable assets\nof organizations. In such environment, organizations with broad, specialized\nand up-to-date knowledge, adequately using knowledge resources, will be more\nsuccessful than their competitors. For effective use of knowledge, dynamic\nknowledge flow from the sources to destinations is essential. In this regard, a\nnovel complex concept in knowledge management is the analysis, design and\nimplementation of knowledge flow management systems. One of the major\nchallenges in such systems is to explore the knowledge flow from the source to\nthe recipient and control the flow for quality improvements concerning the\nusers' needs as possible. Therefore, the purpose of this paper is to provide an\narchitecture in order to solve this challenge. For this purpose, in addition to\nthe architecture for knowledge flow management systems, a new node selection\nstrategy is provided with higher success rate compared to previous strategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0184v2"
    },
    {
        "title": "Dynamic Threshold Optimization - A New Approach?",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Dynamic Threshold Optimization (DTO) adaptively \"compresses\" the decision\nspace (DS) in a global search and optimization problem by bounding the\nobjective function from below. This approach is different from \"shrinking\" DS\nby reducing bounds on the decision variables. DTO is applied to Schwefel's\nProblem 2.26 in 2 and 30 dimensions with good results. DTO is universally\napplicable, and the author believes it may be a novel approach to global search\nand optimization.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0414v2"
    },
    {
        "title": "Transformation of Traditional Marketing Communications in to Paradigms\n  of Social Media Networking",
        "authors": [
            "T. R. Gopalakrishnan Nair",
            "Kumarashvari Subramaniam"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Effective Communication for marketing is a vital field in business\norganizations, which is used to convey the details about their products and\nservices to the market segments and subsequently to build long lasting customer\nrelationships. This paper focuses on an emerging component of the integrated\nmarketing communication, ie. social media networking, as it is increasingly\nbecoming the trend. In 21st century, the marketing communication platforms show\na tendency to shift towards innovative technology bound people networking which\nis becoming an acceptable domain of interaction. Though the traditional\nchannels like TV, print media etc. are still active and prominent in marketing\ncommunication, the presences of the Internet and more specifically the Social\nMedia Networking, has started influencing the way individuals and business\nenterprises communicate. It has become evident that more individuals and\nbusiness enterprises are engaging the social media networking sites either to\naccelerate the sales of their products and services or to provide post-purchase\nfeedbacks. This shift in scenario has motivated this research which took six\nmonths (June 2011 - December 2011), using empirical analysis which is carried\nout based on several primary and secondary evidences. The research paper also\nanalyzes the factors that govern the social media networking sites to influence\nconsumers and subsequently enable their purchase decisions. The secondary data\npresented for this research were those pertaining to the period between the\nyear 2005 and year 2011. The study revealed promising facts like the transition\nto marketing through SMN gives visible advantages like bidirectional\ncommunication, interactive product presentation, and a firm influence on\ncustomer who has a rudimentary interest...\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0425v1"
    },
    {
        "title": "Implementation of a Real Time Passenger Information System",
        "authors": [
            "K. Ganesh",
            "M. Thrivikraman",
            "Joy Kuri",
            "Haresh Dagale",
            "G. Sudhakar",
            "Sugata Sanyal"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Intelligent Transportation Systems (ITS) are gaining recognition in\ndeveloping countries like India. This paper describes the various components of\nour prototype implementation of a Real-time Passenger Information System\n(RTPIS) for a public transport system like a fleet of buses. Vehicle-mounted\nunits, bus station units and a server located at the transport company premises\ncomprise the system. The vehicle unit reports the current position of the\nvehicle to a central server periodically via General Packet Radio Service\n(GPRS). An Estimated Time of Arrival (ETA) algorithm running on the server\npredicts the arrival times of buses at their stops based on real-time\nobservations of the buses' current Global Positioning System (GPS) coordinates.\nThis information is displayed and announced to passengers at stops using\nstation units, which periodically fetch the required ETA from the server via\nGPRS. Novel features of our prototype include: (a) a route creator utility\nwhich automatically creates new routes from scratch when a bus is driven along\nthe new route, and (b) voice tagging of stops and points of interest along any\nroute. Besides, the prototype provides: (i) web-based applications for\npassengers, providing useful information like a snapshot of present bus\nlocations on the streets, and (ii) web-based analysis tools for the transport\nauthority, providing information useful for fleet management, like number of\ntrips undertaken by a specific bus. The prototype has been demonstrated in a\ncampus environment, with four-wheelers and two-wheelers emulating buses. The\nautomatic real-time passenger information system has the potential of making\nthe public transport system an attractive alternative for city-dwellers,\nthereby contributing to fewer private vehicles on the road, leading to lower\ncongestion levels and less pollution.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0447v1"
    },
    {
        "title": "ICT's role in e-Governance in India and Malaysia: A Review",
        "authors": [
            "Ganesh Ch Deka",
            "Jasni Mohamad Zain",
            "Prabhat Mahanti"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Information and Communication Technologies (ICTs) play a key role in\nDevelopment & Economic growth of the Developing countries of the World.\nPolitical, Cultural, Socio-economic Developmental & Behavioral decisions today\nrests on the ability to access, gather, analyze and utilize Information and\nKnowledge. Government of India is having an ambitious objective of transforming\nthe citizen-government interaction at all levels to by the electronic mode by\n2020.Similarly according to the Vision 2020-The Way Forward presented by His\nExcellency YAB Dato' Seri Dr Mahathir Mohamad at the Malaysian Business Council\n\"By the year 2020, Malaysia can be a united nation, with a confident Malaysian\nsociety, infused by strong moral and ethical values, living in a society that\nis democratic, liberal and tolerant, caring, economically just and equitable,\nprogressive and prosperous, and in full possession of an economy that is\ncompetitive, dynamic, robust and resilient\". This paper presents a comparative\nstudy and review relating to e-Governance and application of ICT development\nbetween India & Malaysia.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0681v1"
    },
    {
        "title": "Soft Computing in Product Recovery: A Survey Focusing on Remanufacturing\n  System",
        "authors": [
            "Bo Xing",
            "Wen-Jing Gao",
            "Fulufhelo V. Nelwamondo",
            "Kimberly Battle",
            "Tshilidzi Marwala"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper focuses on the application of soft computing in remanufacturing\nsystem, in which end-of-life products are disassembled into basic components\nand then remanufactured for both economic and environmental reasons. The\ndisassembly activities include disassembly sequencing and planning, while the\nremanufacturing process is composed of product design, production planning &\nscheduling, and inventory management. This paper presents a review of the\nrelated articles and suggests the corresponding further research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.0908v1"
    },
    {
        "title": "Iterated tabu search for the circular open dimension problem",
        "authors": [
            "Zhanghua Fu",
            "Wenqi Huang",
            "Zhipeng Lv"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper mainly investigates the circular open dimension problem (CODP),\nwhich consists of packing a set of circles of known radii into a strip of fixed\nwidth and unlimited length without overlapping. The objective is to minimize\nthe length of the strip. An iterated tabu search approach, named ITS, is\nproposed. ITS starts from a randomly generated solution and attempts to gain\nimprovements by a tabu search procedure. After that, if the obtained solution\nis not feasible, a perturbation operator is subsequently employed to\nreconstruct the incumbent solution and an acceptance criterion is implemented\nto determine whether or not accept the perturbed solution. This process is\nrepeated until a feasible solution has been found or the allowed computation\ntime has been elapsed. Computational experiments based on well-known benchmark\ninstances show that ITS produces quite competitive results with respect to the\nbest known results. For 18 representative CODP instances taken from the\nliterature, ITS succeeds in improving 13 best known results within reasonable\ntime. In addition, for another challenging related variant: the problem of\npacking arbitrary sized circles into a circular container, ITS also succeeds in\nimproving many best known results. Supplementary experiments are also provided\nto analyze the influence of the perturbation operator, as well as the\nacceptance criterion.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.1004v1"
    },
    {
        "title": "Reciprocally induced coevolution: A computational metaphor in\n  Mathematics",
        "authors": [
            "Siby Abraham",
            "Sugata Sanyal",
            "Mukund Sanglikar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Natural phenomenon of coevolution is the reciprocally induced evolutionary\nchange between two or more species or population. Though this biological\noccurrence is a natural fact, there are only few attempts to use this as a\nsimile in computation. This paper is an attempt to introduce reciprocally\ninduced coevolution as a mechanism to counter problems faced by a typical\ngenetic algorithm applied as an optimization technique. The domain selected for\ntesting the efficacy of the procedure is the process of finding numerical\nsolutions of Diophantine equations. Diophantine equations are polynomial\nequations in Mathematics where only integer solutions are sought. Such\nequations and its solutions are significant in three aspects-(i) historically\nthey are important as Hilbert's tenth problem with a background of more than\ntwenty six centuries; (ii) there are many modern application areas of\nDiophantine equations like public key cryptography and data dependency in super\ncomputers (iii) it has been proved that there does not exist any general method\nto find solutions of such equations. The proposed procedure has been tested\nwith Diophantine equations with different powers and different number of\nvariables.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.1247v1"
    },
    {
        "title": "Analytical Study for Seeking Relation Between Customer Relationship\n  Management and Enterprise Resource Planning",
        "authors": [
            "Asif Perwej"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Enterprise Resource Planning (ERP) is a integration of various resources of\nany organization. It is computer software. All kinds of organization data that\nis relating to each and every function of the organization are available in\nERP. So most of the big business organizations are implementing ERP and some of\nthe medium, small scale companies are also using ERP system. CRM in an\norganization helps to retain their existing customers as well as capturing new\ncustomers for their products. So it makes the organization to produce those\ngoods required by their consumers. This paper focuses mainly on the merging of\nCRM and ERP through Neural Networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.1447v1"
    },
    {
        "title": "C-Band VSAT Data Communication System and RF Impairments",
        "authors": [
            "T. P. Surekha",
            "T. Ananthapadmanabha",
            "C. Puttamadappa"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper is concerned with modelling and simulation of VSAT (very small\naperture terminal) data messaging network operating in India at Karnataka with\nextended C-band. VSATs in Karnataka of KPTCL use VSATS 6.875-6.9465G Hz uplinks\nand 4.650- 4.7215 GHz downlinks. These frequencies are dedicated to fixed\nservices. The Satellite is Intelsat -3A, the hub has a 7.2 m diameter antenna\nand uses 350W or 600W TWTA (Travelling wave Tube Amplifier). The VSAT's are 1.2\nm with RF power of 1W or 2W depending on their position in the uplink beam with\ndata rate of 64 or 128 K bit/s. The performance of the system is analysed by\nthe error probability called BER (Bit Error Rate) and results are derived from\nEarth station to hub and hub to Earth station using satellite Transponder as\nthe media of communication channel. The Link budgets are developed for a single\none-way satellite link.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.1722v1"
    },
    {
        "title": "The Use of Fuzzy Cognitive Maps in Analyzing and Implementation of ITIL\n  Processes",
        "authors": [
            "Hamid Zarrazvand",
            "Mohammad Shojafar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Information Technology Infrastructure Library (ITIL) is series of best\npractices that helps Information technology Organizations to provide\nInformation technology (IT) services for their customers with better\nperformances and quality. This article is looking for a way to implement ITIL\nin an organization and also using Fuzzy Cognitive Maps (FCM) to model the\nproblem for better understanding of environment. ITIL helps to improve the\nperformance of IT services in order to gain business objectives and Fuzzy\nCognitive Maps will help to model the problem of needing ITIL processes for\nthose objectives. First, it defines the concept of FCM and ITIL in two separate\nsections and then, it will describe the relationship and the way that FCM helps\nto implement ITIL. The paper will measure the cost of service support that is\ndepended on the metrics like changes Authorization Degree, Process Oriented\nactivities degree, Response time and Interrupt time. This paper will be used as\na part of gap analyzes step in implementing ITIL in each organizations.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.2297v1"
    },
    {
        "title": "Combining configuration and recommendation to define an interactive\n  product line configuration approach",
        "authors": [
            "Camille Salinesi",
            "Raouia Triki",
            "Raul Mazo"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper is interested in e-commerce for complex configurable\nproducts/systems. In e-commerce, satisfying the customer needs is a vital\nconcern. One particular way to achieve this is to offer customers a panel of\noptions among which they can select their preferred ones. While solution\nexists, they are not adapted for highly complex configurable systems such as\nproduct lines. This paper proposes an approach that combines two complementary\nforms of guidance: configuration and recommendation, to help customers define\ntheir own products out of a product line specification. The proposed approach,\ncalled interactive configuration supports the combination by organizing the\nconfiguration process in a series of partial configurations where decisions are\nmade by the recommendation.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.2520v1"
    },
    {
        "title": "Information Security Awareness Within Business Environment: An IT Review",
        "authors": [
            "Heru Susanto",
            "Mohammad Nabil Almunawar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The beauty of Information Technology (IT) is with its multifunction nature;\nit is a support system, a networking system, a storage system, as well as an\ninformation facilitator. Aided with their broad line of services, an IT system\naims to support or even drive organizations towards desired paths. Trends of IT\nand information security awareness (ISA) in society today, particularly within\nthe business environment is quite interesting phenomenon. The overviews of the\nrole of IT in the modern world as well as the perception towards ISA are\ninitially introduced. A series of scope are outlined, and also further\nexamination on matter of IT and ISA in the business environment-emphasis on\nrevolution of business with ISA, security threats such as identity thefts,\nhacking and web harassment, and the different mode of protections that are\napplied in different business environments. Unfortunately, the advancement of\nIT is not followed by the awareness of its security issues properly, especially\nin the context of the business settings and functions. This research and review\nis expected to influence the awareness of information security issues in\nbusiness processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.2597v1"
    },
    {
        "title": "Pricing of insurance policies against cloud storage price rises",
        "authors": [
            "Loretta Mastroeni",
            "Maurizio Naldi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  When a company migrates to cloud storage, the way back is neither easy nor\ncheap. The company is then locked up in the storage contract and exposed to\nupward market prices, which reduce the company's profit and may even bring it\nbelow zero. We propose a protection means based on an insurance contract, by\nwhich the cloud purchaser is indemnified when the current storage price exceeds\na pre-defined threshold. By applying the financial options theory, we provide a\nformula for the insurance price (the premium). By using historical data on\nmarket prices for disks, we apply the formula in realistic scenarios. We show\nthat the premium grows nearly quadratically with the length of the coverage\nperiod as long as this is below one year, but grows more slowly, though faster\nthan linearly, over longer coverage periods.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.4283v1"
    },
    {
        "title": "Defining the symmetry of the universal semi-regular autonomous\n  asynchronous systems",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The regular autonomous asynchronous systems are the non-deterministic Boolean\ndynamical systems and universality means the greatest in the sense of the\ninclusion. The paper gives four definitions of symmetry of these systems in a\nslightly more general framework, called semi-regularity and also many examples.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.4598v2"
    },
    {
        "title": "On the basins of attraction of the regular autonomous asynchronous\n  systems",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The Boolean autonomous dynamical systems, also called regular autonomous\nasynchronous systems are systems whose 'vector field' is a function\n{\\Phi}:{0,1}^{n}{\\to}{0,1}^{n} and time is discrete or continuous. While the\nsynchronous systems have their coordinate functions {\\Phi}_{1},...,{\\Phi}_{n}\ncomputed at the same time:\n{\\Phi},{\\Phi}{\\circ}{\\Phi},{\\Phi}{\\circ}{\\Phi}{\\circ}{\\Phi},... the\nasynchronous systems have {\\Phi}_{1},...,{\\Phi}_{n} computed independently on\neach other. The purpose of the paper is that of studying the basins of\nattraction of the fixed points, of the orbits and of the {\\omega}-limit sets of\nthe regular autonomous asynchronous systems. The bibliography consists in\nanalogies.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.4710v2"
    },
    {
        "title": "Universal Regular Autonomous Asynchronous Systems: Fixed Points,\n  Equivalencies and Dynamic Bifurcations",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The asynchronous systems are the non-deterministic models of the asynchronous\ncircuits from the digital electrical engineering. In the autonomous version,\nsuch a system is a set of functions x:R{\\to}{0,1}^{n} called states (R is the\ntime set). If an asynchronous system is defined by making use of a so called\ngenerator function {\\Phi}:{0,1}^{n}{\\to}{0,1}^{n}, then it is called regular.\nThe property of universality means the greatest in the sense of the inclusion.\nThe purpose of the paper is that of defining and of characterizing the fixed\npoints, the equivalencies and the dynamical bifurcations of the universal\nregular autonomous asynchronous systems. We use analogies with the dynamical\nsystems theory.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.4713v2"
    },
    {
        "title": "The decomposition of the regular asynchronous systems as parallel\n  connection of regular asynchronous systems",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The asynchronous systems are the non-deterministic models of the asynchronous\ncircuits from the digital electrical engineering, where non-determinism is a\nconsequence of the fact that modelling is made in the presence of unknown and\nvariable parameters. Such a system is a multi-valued function f that assigns to\nan (admissible) input u:R{\\to}{0,1}^{m} a set f(u) of (possible) states\nx:R{\\to}{0,1}^{n}. When this assignment is defined by making use of a so-called\ngenerator function {\\Phi}:{0,1}^{n}{\\times}{0,1}^{m}{\\to}{0,1}^{n}, then the\nasynchronous system f is called regular. The generator function {\\Phi} acts in\nthis asynchronous framework similarly with the next state function from a\nsynchronous framework. The parallel connection of the asynchronous systems f'\nand f\" is the asynchronous system (f'||f\")(u)=f'(u){\\times}f\"(u). The purpose\nof the paper is to give the circumstances under which a regular asynchronous\nsystem f may be written as a parallel connection of regular asynchronous\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.4717v1"
    },
    {
        "title": "Usage and Impact of ICT in Education Sector; A Study of Pakistan",
        "authors": [
            "M. Nisar Wasif",
            "Ehsan Ullah Munir",
            "Shafqat Ali Shad"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In many countries, information and communication technology (ICT) has a lucid\nimpact on the development of educational curriculum. This is the era of\nInformation Communication Technology, so to perk up educational planning it is\nindispensable to implement the ICT in Education sector. Student can perform\nwell throughout the usage of ICT. ICT helps the students to augment their\nknowledge skills as well as to improve their learning skills. To know with\nreference to the usage and Impact of ICT in Education sector of Pakistan, we\naccumulate data from 429 respondents from 5 colleges and universities, we use\nconvenient sampling to accumulate the data from district Rawalpindi of\nPakistan. The consequences show that Availability and Usage of ICT improves the\nknowledge and learning skills of students. This indicates that existence of ICT\nis improving the educational efficiency as well as obliging for making policies\nregarding education sector.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.5132v2"
    },
    {
        "title": "It takes two to tango. A Review of the Empirical Literature on\n  Information Technology Outsourcing Relationship Satisfaction",
        "authors": [
            "Jorg Verbaas"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  There is growing recognition that the overall client-vendor relationship, and\nnot only the contract, plays a critical role in Information Technology\nOutsourcing (ITO) success. However, our understanding of how ITO relationships\nfunction is limited. This paper contributes to this understanding by reviewing\nempirical literature on ITO success in terms of relationship satisfaction. A\nkey finding is that the majority of reviewed studies concentrates on client\nsatisfaction, thus neglecting the vendor perspective. We argue that this raises\nquestions about the construct validity of these studies. Consequently, concerns\nexist about the validity and reliability of their empirical findings. Some\nscholars have acknowledged the problem and use a dyadic perspective. However, a\nreview of these studies reveals that the authors have underestimated their\ncontributions and do not explain why there is a problem. Therefore, the purpose\nof this paper is to highlight their contributions by comparing the findings of\nthe dyadic perspective studies with those of the \"client perspective\" research.\nIn doing so, we assess whether the dyadic studies produce better explanations\nfor ITO success than the client-oriented studies. We argue that this is indeed\nthe case, by producing a better view on how underlying mechanisms of ITO\nrelationships work.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.5483v1"
    },
    {
        "title": "Topological model for machining of parts with complex shapes",
        "authors": [
            "Laurent Tapie",
            "Kwamiwi Mawussi",
            "Alain Bernard"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Complex shapes are widely used to design products in several industries such\nas aeronautics, automotive and domestic appliances. Several variations of their\ncurvatures and orientations generate difficulties during their manufacturing or\nthe machining of dies used in moulding, injection and forging. Analysis of\nseveral parts highlights two levels of difficulties between three types of\nshapes: prismatic parts with simple geometrical shapes, aeronautic structure\nparts composed of several shallow pockets and forging dies composed of several\ndeep cavities which often contain protrusions. This paper mainly concerns High\nSpeed Machining (HSM) of these dies which represent the highest complexity\nlevel because of the shapes' geometry and their topology. Five axes HSM is\ngenerally required for such complex shaped parts but 3 axes machining can be\nsufficient for dies. Evolutions in HSM CAM software and machine tools lead to\nan important increase in time for machining preparation. Analysis stages of the\nCAD model particularly induce this time increase which is required for a wise\nchoice of cutting tools and machining strategies. Assistance modules for\nprismatic parts machining features identification in CAD models are widely\nimplemented in CAM software. In spite of the last CAM evolutions, these kinds\nof CAM modules are undeveloped for aeronautical structure parts and forging\ndies. Development of new CAM modules for the extraction of relevant machining\nareas as well as the definition of the topological relations between these\nareas must make it possible for the machining assistant to reduce the machining\npreparation time. In this paper, a model developed for the description of\ncomplex shape parts topology is presented. It is based on machining areas\nextracted for the construction of geometrical features starting from CAD models\nof the parts. As topology is described in order to assist machining assistant\nduring machining process generation, the difficulties associated with tasks he\ncarried out are analyzed at first. The topological model presented after is\nbased on the basic geometrical features extracted. Topological relations which\nrepresent the framework of the model are defined between the basic geometrical\nfeatures which are gathered afterwards in macro-features. Approach used for the\nidentification of these macro-features is also presented in this paper.\nDetailed application on the construction of the topological model of forging\ndies is presented in the last part of the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.0288v1"
    },
    {
        "title": "Prediction of under pickling defects on steel strip surface",
        "authors": [
            "Valentina Colla",
            "Nicola Matarese",
            "Gianluca Nastasi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  An extremely important part of the finishing line is the pickling process, in\nwhich oxides formed during the hot rolling stage are removed from the surface\nof the steel sheets. The efficiency of the pickling process is mainly dependent\non the nature of the oxide present at the surface of the steel, but, also, on\nprocess parameters such as bath composition and time duration are relevant.\nWhen acid concentration, solution temperatures and line speed are not properly\nbalanced, in fact, sheet defects like under pickling or over pickling may\nhappen and their occurrence does have a very serious effect on cold-reduction\nperformance and surface appearance of the finished product. Furthermore,\nproduct damage from handling or improper equipment adjustment can render the\nsteel unsuitable for further processing. This is the reason why it is important\nthat process significant parameters are controlled and maintained as accurately\nas possible in order to avoid these undesired phenomena. In the present work, a\ncontrol algorithm, composed by two different modules, i.e. decision tree and\nrectangular Basis Function Network, has been implemented to aim of predicting\npickling defects and suggesting the optimal speed or the admissible speed range\nof the steel strip in the process line. In this way the most suitable line\nspeed value can be set in an automatic way or by the technical personnel.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.0911v1"
    },
    {
        "title": "Design and Performance Analysis Of Ultra Low Power 6T SRAM Using\n  Adiabatic Technique",
        "authors": [
            "Sunil Jadav",
            " Vikrant",
            "Munish Vashisath"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Power consumption has become a critical concern in both high performance and\nportable applications. Methods for power reduction based on the application of\nadiabatic techniques to CMOS circuits have recently come under renewed\ninvestigation. In thermodynamics, an adiabatic energy transfer through a\ndissipative medium is one in which losses are made arbitrarily small by causing\nthe transfer to occur sufficiently slowly. In this work adiabatic technique is\nused for reduction of average power dissipation. Simulation of 6T SRAM cell has\nbeen done for 180nm CMOS technology. It shows that average power dissipation is\nreduced up to 75% using adiabatic technique and also shows the effect on static\nnoise margin.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.3302v1"
    },
    {
        "title": "Design and Development of Low Cost PC Based Real Time Temperature and\n  Humidity Monitoring System",
        "authors": [
            "Nungleppam Monoranjan Singh",
            "Kanak Chandra Sarma"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper presents the design and development of a low cost Data Acquisition\nSystem (DAS) using PIC12F675 microcontroller for real time temperature and\nhumidity monitoring. The designed DAS has 4 analog input channels having 10-bit\nresolution and was interfaced through the serial port of the PC. A precision\nintegrated temperature sensor and an instrumentation-quality RH (Relative\nHumidity) sensor were used for sensing the temperature and humidity\nrespectively. The firmware was written in Basic and compiled using Oshonsoft\nPIC IDE and downloaded to the microcontroller by using PICkit2 programmer. An\napplication program was also developed using Visual Basic 6, which allows\ndisplaying the waveform of the signal(s) in real time and the data can be saved\ninto the hard disk of the computer for future use and analysis. It can also be\ninterfaced to the USB port of the PC or laptop using USB to serial adapter BAFO\nBF-810. Thus, the designed low cost device works with the legacy hardware as\nwell as the modern USB interface.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.3433v1"
    },
    {
        "title": "Statistical Simulation Models for Cascaded Rayleigh Fading Channels",
        "authors": [
            "Yazan Ibdah",
            "Yanwu Ding"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, we present statistical simulators for cascaded Rayleigh fading\nchannels with and without line-of-sight (LOS). These simulators contain two\nindividual summations and are therefore easy to implement with lower\ncomplexity. Detailed statistical properties, including auto- and\ncross-correlations of the in-phase, quadrature components of the channels,\nenvelopes, and squared envelopes, are derived. The time-average statistical\nproperties and the corresponding variance are also investigated to justify that\nthe proposed simulators achieve good convergence performance.\n  Extensive Monte Carlo simulations are performed for various statistical\nproperties to validate the proposed simulators. Results show that the\nsimulators provide fast convergence to all desired statistical properties,\nincluding the probability density function (PDF), various auto- and\ncross-correlations, level crossing rate (LCR), and average fading duration\n(AFD).\n  While various tests and measurements in dense scattering urban and forest\nenvironments indicate that mobile-to-mobile channels may experience cascaded\nRayleigh fading, the proposed statistical models can be applied to simulate the\nunderlying channels.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.3713v1"
    },
    {
        "title": "Acquiring IT Solutions through Open Source Software",
        "authors": [
            "Mohammad Nabil Almunawar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Open source software is free software that provides user freedom to use,\nreplicate, modify, and distribute for any purpose. The quality of well-known\nopen source software is very high and they are used by big companies such as\nIBM, Google and Amazon.com. Recently the number of open source software project\ngrowing very fast, which indicates that adoption of open source software is\ngrowing although still limited. Businesses should consider open source software\nas alternative solutions to their business problems or opportunities. An\nexample of a very good open source software for office suite is discussed and\ncompared with the well-known proprietary counterpart.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.4247v1"
    },
    {
        "title": "Developing an Activity-Based Costing Approach to Maximize the Efficiency\n  of Customer Relationship Management Projects",
        "authors": [
            "Mahmood Shafiee",
            "Golriz Amooee",
            "Yaghoub Farjami"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In today's competitive environment, profitability analysis is not just about\nlooking at the profit and loss statement. It is more about knowing which of\nyour customers are making you money and which are losing you money. This paper\nconsiders how activity-based costing approach may complement a customer\nrelationship management effort. The model presented in this paper combines the\nprinciples of activity-based costing with performance measurement. Applying\nthis model helps managers understand the true costs of providing products and\nservices, and the factors that drive these costs, while addressing other\nconcerns such as customer satisfaction. This approach has the potential to\nintegrate all business processes around the requirements of significant\nprofitable customers, a fact that most of the previous researches fail to\nacknowledge.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.5108v1"
    },
    {
        "title": "Clown: a Microprocessor Simulator for Operating System Studies",
        "authors": [
            "Dmitry Zinoviev"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, I present the design and implementation of Clown--a simulator\nof a microprocessor-based computer system specifically optimized for teaching\noperating system courses at undergraduate or graduate levels. The package\nincludes the simulator itself, as well as a collection of basic I/O devices, an\nassembler, a linker, and a disk formatter. The simulator architecturally\nresembles mainstream microprocessors from the Intel 80386 family, but is much\neasier to learn and program. The simulator is fast enough to be used as an\nemulator--in the direct user interaction mode.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.5176v1"
    },
    {
        "title": "The Effectiveness of Virtual R&D Teams in SMEs: Experiences of Malaysian\n  SMEs",
        "authors": [
            "Nader Ale Ebrahim",
            "Salwa Hanim Abdul Rashid",
            "Shamsuddin Ahmed",
            "Zahari Taha"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The number of small and medium enterprises (SMEs), especially those involved\nwith research and development (R&D) programs and employed virtual teams to\ncreate the greatest competitive advantage from limited labor are increasing.\nGlobal and localized virtual R&D teams are believed to have high potential for\nthe growth of SMEs. Due to the fast-growing complexity of new products coupled\nwith new emerging opportunities of virtual teams, a collaborative approach is\nbelieved to be the future trend. This research explores the effectiveness of\nvirtuality in SMEs' virtual R&D teams. Online questionnaires were emailed to\nMalaysian manufacturing SMEs and 74 usable questionnaires were received,\nrepresenting a 20.8 percent return rate. In order to avoid biases which may\nresult from pre-suggested answers, a series of open-ended questions were\nretrieved from the experts. This study was focused on analyzing an open-ended\nquestion, whereby four main themes were extracted from the experts'\nrecommendations regarding the effectiveness of virtual teams for the growth and\nperformance of SMEs. The findings of this study would be useful to product\ndesign managers of SMEs in order to realize the key advantages and significance\nof virtual R&D teams during the new product development (NPD) process. This in\nturn, leads to increased effectiveness in new product development's procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/1207.6832v1"
    },
    {
        "title": "Universal Numeric Segment Display for Indian Scheduled Languages: an\n  Architectural View",
        "authors": [
            "Partha Pratim Ray"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  India is country of several hundred different languages. Though twenty two\nlanguages have only been devised as scheduled to the Eighth Schedule of Indian\nConstitution in 2007. But as there is yet no proposed compact display\narchitecture to display all the scheduled language numerals at a time, this\npaper proposes a uniform display architecture to display all twenty two\ndifferent language digits with higher accuracy and simplicity by using a\n17-segment display, which is an improvement over the 16-segment display.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.0755v1"
    },
    {
        "title": "Portals and Task Innovation: A Theoretical Framework Founded on Business\n  Intelligence Thinking",
        "authors": [
            "Dima Jalal",
            "Mutaz M. Al-Debei"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The main aim of this study is to develop a theoretical framework for the\nsuccess of Web portals in promoting task innovation. This is deemed significant\nas yet little research has tackled this important domain from the business\nintelligence perspective. The D&M IS Success Model was used as a foundational\ntheory and then was refined to match the context of the current research.\nImportantly, in this study, system quality and information quality constructs\nwere defined on the basis of portals' characteristics since a mapping was\nconducted between the most significant functions and features of Web portals\nand quality constructs. The developed framework is deemed useful for theory and\npractice. From theoretical perspective, the dimensions that affect the\nperceived quality of Web portals are identified, and the measures that affect\neach quality dimension are also defined. On the practical level, contributions\ngained by this study can be observed in terms of the benefits decision makers,\nstrategists, operational employees and IT developers can gain. Assessing\nportals success in improving task innovation is important to help managers\n(i.e. decision makers) in making appropriate decisions concerning the adoption\nof portals' technology, by weighing its benefits against the costs needed to\nestablish and run such a technology. Moreover, assessing Web portals' success\ngives some insight to IT developers and designers concerning what aspects\nshould be taken when designing and establishing high quality portals, and what\nfunctions and features should be contained that would affect the perceived\nquality of portals and therefore users' intention to use portals.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.0892v1"
    },
    {
        "title": "Establishing Virtual R&D Teams: Obliged Policy",
        "authors": [
            "Nader Ale Ebrahim",
            "Shamsuddin Ahmed",
            "Zahari Taha"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In a global and technology oriented world the requirements that products and\nservices have to fulfill are increasing and are getting more complicated.\nResearch and development (R&D) is becoming increasingly important in creating\nthe knowledge that makes research and business more competitive. Companies are\nobliged to produce more rapidly, more effectively and more efficiently. In\norder to meet these requirements and to secure the viability of business\nprocesses, services and products R&D teams need to access and retrieve\ninformation from as many sources as possible. From the other perspective\nvirtual teams are important mechanisms for organizations seeking to leverage\nscarce resources across geographic and other boundaries moreover; virtual\ncollaboration has become vital for most organizations. This is particularly\ntrue in the context of designing new product and service innovation. Such\ncollaboration often involves a network of partners located around the world.\nHowever at the R&D project level, dealing with such distributed teams\nchallenges both managers and specialists. In new product development, it is\nnecessary to put together the growing different capabilities and services with\nthe goal, through cooperation between suppliers and customers, service\nproviders and scientific institutions to achieve innovations of high quality.\nIn this paper based on comprehensive literature review of recent articles, at\nthe first step provides an primary definition and characterization of virtual\nR&D team; next, the potential value created by virtual R&D teams for new\nproduct development is explored and lastly along with a guide line for future\nstudy, it is argued that the establishing of virtual R&D teams should be given\nconsideration in the management of R&D projects.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.0944v1"
    },
    {
        "title": "Performance of MIMO Relay DCSK-CD Systems over Nakagami Fading Channels",
        "authors": [
            "Yi Fang",
            "Jing Xu",
            "Lin Wang",
            "Guanrong Chen"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  A multi-access multiple-input multiple-output (MIMO) relay differential chaos\nshift keying cooperative diversity (DCSK-CD) system is proposed in this paper\nas a comprehensive cooperation scheme, in which the relay and destination both\nemploy multiple antennas to strengthen the robustness against signal fading in\na wireless network. It is shown that, with spatial diversity gains, the bit\nerror rate (BER) performance of the proposed system is remarkably better than\nthe conventional DCSK non-cooperation (DCSK-NC) and DCSK cooperative\ncommunication (DCSK-CC) systems. Moreover, the exact BER and close-form\nexpressions of the proposed system are derived over Nakagami fading channels\nthrough the moment generating function (MGF), which is shown to be highly\nconsistent with the simulation results. Meanwhile, this paper illustrates a\ntrade-off between the performance and the complexity, and provides a threshold\nfor the number of relay antennas keeping the user consumed energy constant. Due\nto the above-mentioned advantages, the proposed system stands out as a good\ncandidate or alternative for energy-constrained wireless communications based\non chaotic modulation, especially for low-power and low-cost wireless personal\narea networks (WPANs).\n",
        "pdf_link": "http://arxiv.org/pdf/1208.1350v1"
    },
    {
        "title": "Compressed Sensing based Protocol for Efficient Reconstruction of Sparse\n  Superimposed Data in a Multi-Hop Wireless Sensor Network",
        "authors": [
            "Megumi Kaneko",
            "Khaldoun Al Agha"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  We consider a multi-hop wireless sensor network that measures sparse events\nand propose a simple forwarding protocol based on Compressed Sensing (CS) which\ndoes not need any sophisticated Media Access Control (MAC) scheduling, neither\na routing protocol, thereby making significant overhead and energy savings. By\nmeans of flooding, multiple packets with different superimposed measurements\nare received simultaneously at any node. Thanks to our protocol, each node is\nable to recover each measurement and forward it while avoiding cycles.\nNumerical results show that our protocol achieves close to zero reconstruction\nerrors at the sink, while greatly reducing overhead. This initial research\nreveals a new and promising approach to protocol design through CS for wireless\nmesh and sensor networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.1410v1"
    },
    {
        "title": "Deploying Health Monitoring ECU Towards Enhancing the Performance of\n  In-Vehicle Network",
        "authors": [
            "Geetishree Mishra",
            "Rajeshwari Hegde",
            "K. S. Gurumurthy"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Electronic Control Units (ECUs) are the fundamental electronic building\nblocks of any automotive system. They are multi-purpose, multi-chip and\nmulticore computer systems where more functionality is delivered in software\nrather than hardware. ECUs are valuable assets for the vehicles as critical\ntime bounded messages are communicated through. Looking into the safety\ncriticality, already developed mission critical systems such as ABS, ESP etc,\nrely fully on electronic components leading to increasing requirements of more\nreliable and dependable electronic systems in vehicles. Hence it is inevitable\nto maintain and monitor the health of an ECU which will enable the ECUs to be\nfollowed, assessed and improved throughout their life-cycle starting from their\ninception into the vehicle. In this paper, we propose a Health monitoring ECU\nthat enables the early trouble shooting and servicing of the vehicle prior to\nany catastrophic failure.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.1429v1"
    },
    {
        "title": "Design For Change: Information-Centric Architecture to Support Agile\n  Disaster Response",
        "authors": [
            "Yan Shvartzshnaider",
            "Maximilian Ott"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper presents a case for the adoption of an information-centric\narchitecture for a global disaster management system. Drawing from a case study\nof the 2010/2011 Queensland floods, we describe the challenges in providing\nevery participant with relevant and actionable information. We use various\nexamples to argue for a more flexible information dissemination framework which\nis designed from the ground up to minimise the effort needed to fix the\nunexpected and unavoidable information acquisition, quality, and dissemination\nchallenges posed by any real disaster.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.1569v1"
    },
    {
        "title": "Analysis of Trim Commands on Overprovisioning and Write Amplification in\n  Solid State Drives",
        "authors": [
            "Tasha Frankie",
            "Gordon Hughes",
            "Ken Kreutz-Delgado"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper presents a performance model of the ATA/ATAPI SSD Trim command\nunder various types of user workloads, including a uniform random workload, a\nworkload with hot and cold data, and a workload with N temperatures of data. We\nfirst examine the Trim-modified uniform random workload to predict utilization,\nthen use this result to compute the resultant level of effective\noverprovisioning. This allows modification of models previously suggested to\npredict write amplification of a non-Trim uniform random workload under greedy\ngarbage collection. Finally, we expand the theory to cover a workload\nconsisting of hot and cold data (and also N temperatures of data), providing\nformulas to predict write amplification in these scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.1794v1"
    },
    {
        "title": "`CodeAliker' - Plagiarism Detection on the Cloud",
        "authors": [
            "Nitish Upreti"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Plagiarism is a burning problem that academics have been facing in all of the\nvaried levels of the educational system. With the advent of digital content,\nthe challenge to ensure the integrity of academic work has been amplified. This\npaper discusses on defining a precise definition of plagiarized computer code,\nvarious solutions available for detecting plagiarism and building a cloud\nplatform for plagiarism disclosure. 'CodeAliker', our application thus\ndeveloped automates the submission of assignments and the review process\nassociated for essay text as well as computer code. It has been made available\nunder the GNU's General Public License as a Free and Open Source Software.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.2486v1"
    },
    {
        "title": "Empowered Customers in E-Health Business Process",
        "authors": [
            "Muhammad Anshari",
            "Mohammad Nabil Almunawar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  E-health innovations support empowered customers. It offers the ability for\ncustomers to have greater control and ready access applications of health\ninformation, clinical information, and social interaction between interested\ngroups. However, providing empowerment in any state of interaction levels to\ncustomers (patients) in a healthcare organization is challenging tasks.\nCustomers are empowered in the sense of controlling the process of interaction\nbetween a firm with its customers, and among customers themselves. This paper\ndiscusses dimension of customers' empowerment in e-health business process. We\npropose reference model of Personal Health Cycle (PHC) as a holistic view of\nhealthcare business process. The PHC is used to define and distinct electronic\nhealth record (EHR) from electronic medical record (EMR) and customers\nempowerment.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.2620v1"
    },
    {
        "title": "Personal Safety Triggering System on Android Mobile Platform",
        "authors": [
            "Ashokkumar Ramalingam",
            "Prabhu Dorairaj",
            "Saranya Ramamoorthy"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Introduction of Smart phones redefined the usage of mobile phones in the\ncommunication world. Smart phones are equipped with various sophisticated\nfeatures such as Wi-Fi, GPS navigation, high resolution camera, touch screen\nwith broadband access which helps the mobile phone users to keep in touch with\nthe modern world. Many of these features are primarily integrated with the\nmobile operating system which is out of reach to public, by which the users\ncan't manipulate those features. Google came up with an innovative operation\nsystem termed as ANDROID, which is open system architecture with customizable\nthird party development and debugging environment which helps the user's to\nmanipulate the features and to create their own customizable applications. In\nthis paper, 'Emergency Based Remote Collateral Tracking System' application\nusing Google's Android Mobile Platform is addressed. Emergency is divided into\nthree categories: heart beat based emergency, security threats like personal\nsafety and road accidents. This application is targeted to a person who is\ndriving a vehicle. Heart rate monitoring device is integrated with our\napplication to sense the heart beat of a person driving the vehicle and if\nthere is any abnormalities in the heart beat, then our application performs a\ndual role. One in which, application uses a GPS to track the location\ninformation of the user and send those location information as a message via\nSMS, email and post it on Facebook wall Simultaneously, an emergency signal is\nsent to Arduino Microcontroller.This application is written in JAVA programming\nlanguage which runs on Eclipse Integrated Development Kit.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.3138v1"
    },
    {
        "title": "Adding Methodological Testing to Naur's Anti-formalism",
        "authors": [
            "S. J. Meyer"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Peter Naur is the leading critic of formalist computing because of his\nextensive writings that disprove the now dominate characterization of human\nthought as cognitive information processing. Naur criticizes the ideological\nposition that only discourse that adopts computer inspired forms are\nacceptable. Lakatosian philosophy of the methodology of scientific research\nprogrammes (MSRP) is added to Naur's studies to allow testing of computing\ntheories. After discussing Naur's criticism of mechanical cognitive information\nprocessing, I show how to add MSRP competition to Naur's descriptive\nphilosophy. Next, Naur's claim that computing can not become scientific until\norganizational issues involving ideological suppression of discussions of\ncomputing and human thinking are solved is corroborated by institutional\nsuppression of my 1970s attempts to criticize structured programming (SP).\n  Various problems in computing related philosophy are discussed. First, I\nargue that my MSRP based degenerating research programme disproof of SP is\nbetter than Naur's programming as a human activity, Demillo's social processes\nand Fetzer's unprovable causal nature. Three areas for post ideologically based\ncomputing study are discussed: computing as a path to rediscovering 19th\ncentury conceptions of infinity, axiom of choice testing facilitated by\ncomputing and relation to physical theory, and testing concrete complexity\nmethods based on efficiency proof analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.3739v1"
    },
    {
        "title": "Business Intelligence: A Rapidly Growing Option through Web Mining",
        "authors": [
            "Priyanka Rahi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The World Wide Web is a popular and interactive medium to distribute\ninformation in this scenario. The web is huge, diverse, ever changing, widely\ndisseminated global information service center. We are familiar with terms like\ne-commerce, e-governance, e-market, e-finance, e-learning, e-banking etc. for\nan organization it is new challenge to maintain direct contact with customers\nbecause of the rapid growth in e-commerce, e-publishing and electronic service\ndelivery. To deal with this there is need of intelligent marketing strategies\nand CRM (customer relationship management) i.e. the effective way of\nintegrating enterprise applications in real time. Web mining is the vast field\nthat helps to understand various concepts of different fields. Web usage mining\ntechniques are attempted to reason about different materialized issues of\nBusiness Intelligence which include marketing expertise as domain knowledge and\nare specifically designed for electronic commerce purposes. To this end, the\nchapter provides an introduction to the field of Web mining and examines\nexisting as well as potential Web mining applications applicable for different\nbusiness function, like marketing, human resources, and fiscal administration.\nSuggestions for improving information technology infrastructure are made, which\ncan help businesses interested in Web mining hit the ground running.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.5875v1"
    },
    {
        "title": "Resonant Clocking Circuits for Reversible Computation",
        "authors": [
            "Raj K. Jana",
            "Gregory L. Snider",
            "Debdeep Jena"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  A mechanism for the reduction of dynamic energy dissipation in the computing\ncircuit is described. The resonant circuit with controlled switches conserves\nthe stored energy by recovering upto 90% of energy that would be otherwise lost\nduring logic state transitions. This energy-conserving approach preserves\nthermodynamic entropy, ideally preventing heat generation in the system. This\napproach is used in a proposed resonant clocking and logic application without\ndynamic energy dissipation.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.5889v2"
    },
    {
        "title": "A Review Paper on Microprocessor Based Controller Programming",
        "authors": [
            "Jaswinder Singh Dilawari",
            "Gurpreet Singh Sandhu"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Designing of microprocessor based controllers requires specific hardware as\nwell as software programming. Programming depends upon type of the software\nwhether operating software or application software. Programming requires\nknowledge of system configuration and controller specific programming. Programs\nare always in digital form so microprocessor can control directly at digital\nlevel called Direct Digital Control (DDC).\n",
        "pdf_link": "http://arxiv.org/pdf/1210.0576v1"
    },
    {
        "title": "Integration of CAD and rapid manufacturing for sand casting optimisation",
        "authors": [
            "Alain Bernard",
            "Jean-Charles Delplace",
            "Nicolas Perry",
            "Serge Gabriel"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In order to reduce the time and costs of the products development in the sand\ncasting process, the SMC Colombier Fontaine company has carried out a study\nbased on tooling manufacturing with a new rapid prototyping process. This\nevolution allowed the adequacy of the geometry used for the simulation to the\ntooling employed physically in the production. This allowed a reduction of the\nwall thickness to 4mm and retained reliable manufacturing process.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2089v1"
    },
    {
        "title": "Customised high-value document generation",
        "authors": [
            "Niek Du Preez",
            "Nicolas Perry",
            "Alexandre Candlot",
            "Alain Bernard",
            "Wilhelm Uys",
            "Louis Louw"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Contributions of different experts to innovation projects improve enterprise\nvalue, captured in documents. A subset of them is the centre of expert\nconstraint convergence. Their production needs to be tailored case by case.\nDocuments are often considered as knowledge transcription. As the base of a\nstructured knowledge-based information environment, this paper presents a\nglobal approach that helps knowledge-integration tool deployment. An example,\nbased on process plan in aircraft manufacturing, indicates how fundamental\nunderstanding of domain infrastructure contributes to a more coherent\narchitecture of knowledge-based information environments. A comparison with an\nexperiment in insurance services generalised the application of presented\nprinciples.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2090v1"
    },
    {
        "title": "VCS: Value Chains Simulator, a Tool for Value Analysis of Manufacturing\n  Enterprise Processes (A Value-Based Decision Support Tool)",
        "authors": [
            "Magali Mauchand",
            "Ali Siadat",
            "Nicolas Perry",
            "Alain Bernard"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Manufacturing enterprises are facing a competitive challenge. This paper\nproposes the use of a value chain based approach to support the modelling and\nsimulation of manufacturing enterprise processes. The aim is to help experts to\nmake relevant decisions on product design and/or product manufacturing process\nplanning. This decision tool is based on the value chain modelling, by\nconsidering the product requirements. In order to evaluate several performance\nindicators, a simulation of various potential value chains adapted to market\ndemand was conducted through a Value Chains Simulator (VCS). A discrete event\nsimulator is used to perform the simulation of these scenarios and to evaluate\nthe value as a global performance criterion (balancing cost, quality, delivery\ntime, services, etc.). An Analytical Hierarchy Process module supports the\nanalysis process. The value chain model is based on activities and uses the\nconcepts of resource consumption, while integrating the benefiting entities\nview point. A case study in the microelectronic field is carried out to\ncorroborate the validity of the proposed VCS.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2091v1"
    },
    {
        "title": "Minimum Component Based First-Order Inverting and Non-inverting Outputs\n  of All-Pass Filter at the Same Circuit",
        "authors": [
            "J. Mohan",
            "S. Maheshwari",
            "D. S. Chauhan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, a new voltage-mode first order all-pass filter using minimum\nactive and passive components is presented. The proposed circuit employs one\nfully differential second generation current conveyor (FDCCII), one grounded\ncapacitor, one resistor and offers the following advantages: the use of only\ngrounded capacitor which is attractive for integrated circuit implementation,\nlow active and passive sensitivities, providing inverting and non-inverting\nvoltage-mode all-pass responses simultaneously from the single circuit and no\nrequirement for component matching conditions. The theory is validated through\nPSPICE simulation using TSMC 0.35micrometer CMOS process parameters.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2485v1"
    },
    {
        "title": "Minimum Grounded Component Based Voltage-Mode Quadrature Oscillator\n  using DVCC",
        "authors": [
            "J. Mohan",
            "S. Maheshwari",
            "D. S. Chauhan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, a new voltage-mode quadrature oscillator using minimum number\nof active and passive component is proposed. The proposed circuit employs\nsingle modified DVCC, two grounded capacitor and two grounded resistors, which\nis ideal for IC implementation. The active and passive sensitivity are no more\nthan unity. The proposed circuit is verified through PSPICE simulation results.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.2514v1"
    },
    {
        "title": "Performance Evaluation of Mobile U-Navigation based on GPS/WLAN\n  Hybridization",
        "authors": [
            "Wan Mohd Yaakob Wan Bejuri",
            "Mohd Murtadha Mohamad",
            "Maimunah Sapri",
            "Mohd Adly Rosly"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper present our mobile u-navigation system. This approach utilizes\nhybridization of wireless local area network and Global Positioning System\ninternal sensor which to receive signal strength from access point and the same\ntime retrieve Global Navigation System Satellite signal. This positioning\ninformation will be switched based on type of environment in order to ensure\nthe ubiquity of positioning system. Finally we present our results to\nillustrate the performance of the localization system for an indoor/ outdoor\nenvironment set-up.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.3091v1"
    },
    {
        "title": "Microelectromechanical system cantilever-based frequency doublers",
        "authors": [
            "Joydeep Basu",
            "Tarun K. Bhattacharyya"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Microelectromechanical system (MEMS) based on-chip resonators offer great\npotential for high frequency signal processing circuits like reference\noscillators and filters. This is due to their exceptional features like small\nsize, large frequency-quality factor product, integrability with CMOS ICs, low\npower consumption, low cost batch fabrication etc. A capacitively transduced\ncantilever beam resonator is one such popular MEMS resonator topology. In this\nletter, the inherent square-law nonlinearity of the voltage-to-force transfer\nfunction of a cantilever resonator's capacitive transducer has been employed\nfor the realization of frequency doubling effect. Using this concept, frequency\ndoubling of input signals of 500 kHz to 1 MHz, and 227.5 kHz to 455 kHz has\nbeen experimentally demonstrated for two cantilever beams of length 51.75 and\n76.75 micrometer respectively. The MEMS cantilevers have been fabricated with\npolysilicon using the PolyMUMPs surface micromachining process, and their\ntesting has been performed using Laser Doppler Vibrometry. The test results\nobtained are in reasonable compliance with the analytical and CoventorWare\nfinite-element simulation results. The high efficiency demonstrated by the\ncantilever frequency doubler makes it a promising choice for signal generation\nat high frequencies.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.3491v1"
    },
    {
        "title": "Varactor-Based Dynamic Load Modulation of High Power Amplifiers",
        "authors": [
            "Ali Soltani Tehrani",
            "Hossein Mashad Nemati",
            "Haiying Cao",
            "Thomas Eriksson",
            "Christian Fager"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this work, dynamic load modulation of high power amplifiers using a\nvaractor-based tunable matching network is presented. The feasibility of\ndynamic tuning and efficiency enhancement of this technique is demonstrated\nusing a modular design approach for two existing high efficiency power\namplifiers (PA), a 7-W class-E, and a 10-W class-J power amplifier PA at 1 GHz.\nFor this purpose and for each of the PAs, a simple quasi-static inverse model\nis developed allowing an efficiency-optimized control of the PA and the\nvaractor-based tunable matching network. Modulated measurements using a single\ncarrier WCDMA signal with 11.3 dB peak-to-average ratio (PAR) indicate about 10\nto 14 percentage units improvements in the average power-added efficiency (PAE)\nfor the complete architecture.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.3494v2"
    },
    {
        "title": "conomie des biens immatriels - Economics of Intangible Goods",
        "authors": [
            "Laurent Fournier"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  We introduce a new economic system suited for Intangible Goods ({\\sc ig}). We\nargue that such system can now be implemented in the real world using advance\ntechnics in distributed network computing and cryptography. The specification\nof the so called \\net{} is presented. To Limit the number of financial\ntransactions, the system is forced to define its own currency, with many\nbenefits. The new \"cup\" currency, extended worldwide, is dedicated to {\\sc ig},\navailable only for person-to-person trading, protected from speculation and\nadapted for tax recovery with no additional computation. Those nices features\nmakes the \\net{} a new democratic tool, fixing specific issues in {\\sc ig}\ntrading and reviving a whole domain activity. We emphasis on the fact that all\nproposed documentation, algorithm, program in any language related to this\nproposal shall be open-source without any possibility to post any patent of any\nsort on the system or subsystem. This new trading model should be considered as\na pure intellectual construction, like parts of Mathematics and then belongs to\nnobody or everybody, like $1+1=2$. Next step will be to test, validate the\nsecurity of various implementations details, and to ask for legal rules\nadaptations. The first draft paper is written in French language and posted to\narXiv.org and hal.archive-ouverte.fr . We expect to provide an English\ntranslation before Christmas.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.4014v3"
    },
    {
        "title": "Dimensions and issues of mobile agent technology",
        "authors": [
            "Yashpal Singh",
            "Kapil Gulati",
            "S. Niranjan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Mobile Agent is a type of software system which acts \"intelligently\" on one's\nbehalf with the feature of autonomy, learning ability and most importantly\nmobility. Now mobile agents are gaining interest in the research community. In\nthis article mobile agents will be addressed as tools for mobile computing.\nMobile agents have been used in applications ranging from network management to\ninformation management. We present mobile agent concept, characteristics,\nclassification, need, applications and technical constraints in the mobile\ntechnology. We also provide a brief case study about how mobile agent is used\nfor information retrieval.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.4644v1"
    },
    {
        "title": "A Robust Lot Sizing Problem with Ill-known Demands",
        "authors": [
            "Romain Guillaume",
            "Przemyslaw Kobylanski",
            "Pawel Zielinski"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The paper deals with a lot sizing problem with ill-known demands modeled by\nfuzzy intervals whose membership functions are possibility distributions for\nthe values of the uncertain demands. Optimization criteria, in the setting of\npossibility theory, that lead to choose robust production plans under fuzzy\ndemands are given. Some algorithms for determining optimal robust production\nplans with respect to the proposed criteria, and for evaluating production\nplans are provided. Some computational experiments are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.5386v1"
    },
    {
        "title": "Propuesta de sistema GeoInformtico con representacin de escenarios\n  para auxiliar en la nueva metodologa propuesta por INETER y la UNI para el\n  estudio a gran escala de la vulnerabilidad y daos debido a sismos en las\n  edificaciones",
        "authors": [
            "Federico-Vladimir Gutierrez-Corea",
            "Adolfo-Javier Urrutia-Zambrana"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  A GIS based software is presented which permits the estimation of seismic\nvulnerability and the presentation of results in digital maps for single\nhouses, groups of buildings, parts of settlements or even complete towns.\nNicaragua is a country with a high seismic activity. The assessment of seismic\nvulnerability requires the execution of distinct tasks, e.g. recollection of\nfield data, integration of data from the municipal cadastre, reprocessing or\nscreening to test the reliability of the data, definition of calculation of\nvulnerability functions, calculation of vulnerability for single objects as\nhouses or buildings, calculation of mean vulnerability for certain areas as\nbarrios or squares. In order to reduce time and effort to be spent with several\nunspecialized tools and procedures, an integrated software system was created,\nthe user of which has not to care about separate software tools for each part\nof the process. The main advantage of the software is the combination of\nGeographical Information System (GIS) with the logics that surrounds the\nspecific methodologies of seismic vulnerability index, index of damages and\npresentation of results. The new software uses a connection with an external\ncentralized Enterprise Data Base which stores all the input information and\ncalculation results and which is automatically synchronized for the\npresentation of results using GIS. The cadastral information contains data on\nthe constructive type of the house, dimensions, year of construction, type of\nwalls, roof, number of inhabitants, etc.. The system also allows to present\ndamage scenarios for specific seismic events with given hypocenter and\nmagnitude. The documentation of the software serves as a guide for students\nworking on object oriented software engineering by using unified modeling\nlanguage (UML) and software logic architecture (3-tiers).\n",
        "pdf_link": "http://arxiv.org/pdf/1210.6154v2"
    },
    {
        "title": "Designing a High Efficiency Pulse Width Modulation Step-Down DC/DC\n  Converter for Mobile Phone Applications",
        "authors": [
            "Benlafkih Abdessamad",
            "Krit Salah-ddine",
            "Chafik Elidrissi Mohamed"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper presents the design and analysis of a high efficiency, PWM\n(Pulse-Width-Modulation) Buck converters for mobile phone applications. The\nsteady-state and average-value models for the proposed converter are developed\nand simulated. A practical design approach which aims at systematizing the\nprocedure for the selection of the control parameters is introduced. The\nswitching losses are reduced by using soft switching, additionally, a simple\nanalog and digital form of the controller for practical realization is\nprovided. It is found that this controller adopts a structure similar to the\nconventional PWM voltage mode controller. The proposed circuit uses a\ncurrent-mode control and a voltage-to-pulse converter for the PWM. The circuit,\nfabricated using a 0.18-{\\mu}m CMOS technology, reaches a peak load regulation\nof 20 mV/V and line regulation of 0.5 mV/V at Current load equal 300 mA. The\nused 10{\\mu}H inductance and 22{\\mu}F capacitor and requires clock and\nVref/Vramp input of 1,23V.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.6231v1"
    },
    {
        "title": "Modified Stage-Gate: A Conceptual Model of Virtual Product Development\n  Process",
        "authors": [
            "Nader Ale Ebrahim",
            "Shamsuddin Ahmed",
            "Zahari Taha"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In today s dynamic marketplace, manufacturing companies are under strong\npressure to introduce new products for long-term survival with their\ncompetitors. Nevertheless, every company cannot cope up progressively or\nimmediately with the market requirements due to knowledge dynamics being\nexperienced in the competitive milieu. Increased competition and reduced\nproduct life cycles put force upon companies to develop new products faster. In\nresponse to these pressing needs, there should be some new approach compatible\nin flexible circumstances. This paper presents a solution based on the popular\nStage-Gate system, which is closely linked with virtual team approach. Virtual\nteams can provide a platform to advance the knowledge-base in a company and\nthus to reduce time-to-market. This article introduces conceptual product\ndevelopment architecture under a virtual team umbrella. The paper describes all\nthe major aspects of new product development (NPD), NPD process and its\nrelationship with virtual teams, Stage-Gate system finally presents a modified\nStage-Gate system to cope up with the changing needs. It also provides the\nguidelines for the successful implementation of virtual teams in new product\ndevelopment.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.7482v1"
    },
    {
        "title": "Plagiarism Detection: Keeping Check on Misuse of Intellectual Property",
        "authors": [
            "Iti Mathur",
            "Nisheeth Joshi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Today, Plagiarism has become a menace. Every journal editor or conference\norganizers has to deal with this problem. Simply Copying or rephrasing of text\nwithout giving due credit to the original author has become more common. This\nis considered to be an Intellectual Property Theft. We are developing a\nPlagiarism Detection Tool which would deal with this problem. In this paper we\ndiscuss the common tools available to detect plagiarism and their short comings\nand the advantages of our tool over these tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.7678v1"
    },
    {
        "title": "Virtual Collaborative R&D Teams in Malaysia Manufacturing SMEs",
        "authors": [
            "Nader Ale Ebrahim",
            "Shamsuddin Ahmed",
            "Salwa Hanim Abdul Rashid",
            "Zahari Taha",
            "M. A. Wazed"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper presents the results of empirical research conducted during March\nto September 2009. The study focused on the influence of virtual research and\ndevelopment teams within Malaysian manufacturing small and medium sized\nenterprises (SMEs). The specific objective of the study is better understanding\nof the application of collaborative technologies in business, to find the\neffective factors to assist SMEs to remain competitive in the future. The paper\nstresses to find an answer for a question Is there any relationship between\ncompany size, Internet connection facility and virtuality?. The survey data\nshows SMEs are now technologically capable of performing the virtual\ncollaborative team, but the infrastructure usage is less. SMEs now have the\nnecessary technology to begin the implementation process of collaboration tools\nto reduce research and development time, costs and increase productivity. So,\nthe manager of R and D should take the potentials of virtual teams into\naccount.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.7889v1"
    },
    {
        "title": "Bayesian inference and the world mind",
        "authors": [
            "John O. Campbell"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Knowledge is a central concept within both Bayesian inference and the\nmathematical and philosophical program of logic and semiotics initiated by\nCharles Sanders Peirce and further developed by George Spencer-Brown and Louis\nKauffman. The latter school is more philosophical than is usual with the\npractitioners of Bayesian inference and claims the existence of a world mind.\nWhen these two disciplines inform each other semiotics is provided with\nmathematical mechanism and Bayesian inference is seen to be closely related to\nthe act of distinction, the fundamental basis of logic in the work of\nSpencer-Brown. This hybridization also suggests a definition for knowledge\nwithin Bayesian inference; a definition that has been curiously lacking. Given\nthat Darwinian processes are physical implementations of Bayesian inference and\nare utilized within numerous scientific theories across a wide range of\ndisciplines as mechanisms for the creation and evolution of knowledge we may\nview the conjunction of these theories, within universal Darwinism, as\ndescriptive of a world mind. Placing the world mind in this context provides\ndetailed support from the scientific literature and goes some way to refute the\ncharges of mysticism which have been leveled at the semiotic approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.8031v1"
    },
    {
        "title": "Project G.N.O.S.I.S.: Geographical Network Of Synoptic Information\n  System",
        "authors": [
            "Pietro Oliva"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Everybody knows how much synoptic maps are useful today. An excellent example\nabove all is Google Earth: its simplicity and friendly interface allows every\nuser to have the Earth maps ready in just one simple layout; nevertheless a\ncrucial dimension is missing in Google Earth: the time. This doesn't mean we\nsimply aim to add history to Google Earth (though it could be already a nice\ngoal): the main idea behind GNOSIS project is to produce applications to \"dress\nup\" the Globe with a set of skin-maps representing the most various different\nkind of histories like the evolution of geology, genetics, agriculture,\nethnology, linguistics, musicology, metallurgy and so forth, in time. It may be\ninteresting in the near future to have such a possibility to watch on the map\nthe positions and movements of the armies during the battles of Waterloo or\nThermopylae, the spreading of the cultivation of corn in time, the rise and\nfall of Roman Empire or the diffusion of Smallpox together with the spread of a\nreligion, a specific dialect, the early pottery techniques or the natural\nresources available to pre-Columbian civilizations on a Google-Earth-map-like,\nthat is to say to have at one's hand the ultimate didactic-enciclopedic tool.\nTo do so we foresee the use of a general-purpose intermediate/high level\nprogramming language, possibly object-oriented such C++ or Java.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.0645v1"
    },
    {
        "title": "An Evaluation of Arabic Language Learning Websites",
        "authors": [
            "Hadhemi Achour",
            "Wahiba Ben Abdessalem"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  As a result of ICT development and the increasingly growing use of the\nInternet in particular, practices of language teaching and learning are about\nto evolve significantly. Our study focuses on the Arabic language, and aims to\nexplore and evaluate Arabic language learning websites. To reach these goals,\nwe propose in a first step, to define an evaluation model, based on a set of\ncriteria for assessing the quality of websites dedicated to teaching and\nlearning Arabic. We subsequently apply our model on a set of Arabic sites\navailable on the web and give an assessment of these web sites. We finally\ndiscuss their strengths and limitations.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.0716v1"
    },
    {
        "title": "Information and Communication Technology in Combating Counterfeit Drugs",
        "authors": [
            "Haruna Isah"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Pharma frauds are on the rise, counterfeit drugs are giving sleepless nights\nto patients, pharmaceutical companies and governments. The laws prohibiting the\nsales of counterfeit drugs cannot succeed without technological interventions.\nSeveral analytical techniques and tools including spectroscopy, holograms,\nbarcoding, differentiated packing, radio frequency identification,\nfingerprints, hyperspectral imaging etc. have been employed over the years in\ncombating this menace; however this challenge is becoming more sophisticated\nwith the evolution of the World Wide Web and online pharmacies. This paper\npresents a review on the contribution of Information and Communication\nTechnology (ICT) as a drug counterfeit countermeasure.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.1242v1"
    },
    {
        "title": "A Semi-Structured Tailoring-Driven Approach for ERP Selection",
        "authors": [
            "Abdelilah Khaled",
            "Mohammed Abdou Janati Idrissi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  It has been widely reported that selecting an inappropriate system is a major\nreason for ERP implementation failures. The selection of an ERP system is\ntherefore critical. While the number of papers related to ERP implementation is\nsubstantial, ERP evaluation and selection approaches have received few\nattention. Motivated by the adaptation concept of the ERP systems, we propose\nin this paper a semi-structured approach for ERP system selection that differs\nfrom existing models in that it has a more holistic focus by simultaneously 1)\nconsidering the anticipated fitness of ERP solutions after the optimal\nresolution, within limited resources, of a set of the identified mismatches and\n2) evaluating candidate products according to both functional and\nnon-functional requirements. The approach consists of an iterative selection\nprocess model and an evaluation methodology based on 0-1 linear programming and\nMACBETH technique to elaborate multi-criteria performance expressions.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.2445v1"
    },
    {
        "title": "Performance Evaluation of DOA Estimation using MATLAB",
        "authors": [
            "Sai Suhas Balabadrapatruni"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper presents the performance analysis of directions of arrival\nestimation techniques, Subspace and the Non-Subspace methods. In this paper,\nexploring the analysis category of high resolution and super resolution\nalgorithms, presentation of description, comparison and the performance and\nresolution analyses of these algorithms are made. Sensitivity to various\nperturbations and the effect of parameters related to the design of the sensor\narray itself such as the number of array elements and their spacing are also\ninvestigated.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.4442v1"
    },
    {
        "title": "Online Energy Generation Scheduling for Microgrids with Intermittent\n  Energy Sources and Co-Generation",
        "authors": [
            "Lian Lu",
            "Jinlong Tu",
            "Chi-Kin Chau",
            "Minghua Chen",
            "Xiaojun Lin"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Microgrids represent an emerging paradigm of future electric power systems\nthat can utilize both distributed and centralized generations. Two recent\ntrends in microgrids are the integration of local renewable energy sources\n(such as wind farms) and the use of co-generation (i.e., to supply both\nelectricity and heat). However, these trends also bring unprecedented\nchallenges to the design of intelligent control strategies for microgrids.\nTraditional generation scheduling paradigms rely on perfect prediction of\nfuture electricity supply and demand. They are no longer applicable to\nmicrogrids with unpredictable renewable energy supply and with co-generation\n(that needs to consider both electricity and heat demand). In this paper, we\nstudy online algorithms for the microgrid generation scheduling problem with\nintermittent renewable energy sources and co-generation, with the goal of\nmaximizing the cost-savings with local generation. Based on the insights from\nthe structure of the offline optimal solution, we propose a class of\ncompetitive online algorithms, called CHASE (Competitive Heuristic Algorithm\nfor Scheduling Energy-generation), that track the offline optimal in an online\nfashion. Under typical settings, we show that CHASE achieves the best\ncompetitive ratio among all deterministic online algorithms, and the ratio is\nno larger than a small constant 3.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.4473v2"
    },
    {
        "title": "From the Closed Classical Algorithmic Universe to an Open World of\n  Algorithmic Constellations",
        "authors": [
            "Mark Burgin",
            "Gordana Dodig-Crnkovic"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper we analyze methodological and philosophical implications of\nalgorithmic aspects of unconventional computation. At first, we describe how\nthe classical algorithmic universe developed and analyze why it became closed\nin the conventional approach to computation. Then we explain how new models of\nalgorithms turned the classical closed algorithmic universe into the open world\nof algorithmic constellations, allowing higher flexibility and expressive\npower, supporting constructivism and creativity in mathematical modeling. As\nGoedels undecidability theorems demonstrate, the closed algorithmic universe\nrestricts essential forms of mathematical cognition. In contrast, the open\nalgorithmic universe, and even more the open world of algorithmic\nconstellations, remove such restrictions and enable new, richer understanding\nof computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.4547v1"
    },
    {
        "title": "Secured Ontology Mapping",
        "authors": [
            "Manjula Shenoy. K",
            "K. C. Shet",
            "U. Dinesh Acharya"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Todays market evolution and high volatility of business requirements put an\nincreasing emphasis on the ability for systems to accommodate the changes\nrequired by new organizational needs while maintaining security objectives\nsatisfiability. This is all the more true in case of collaboration and\ninteroperability between different organizations and thus between their\ninformation systems. Ontology mapping has been used for interoperability and\nseveral mapping systems have evolved to support the same. Usual solutions do\nnot take care of security. That is almost all systems do a mapping of\nontologies which are unsecured.We have developed a system for mapping secured\nontologies using graph similarity concept. Here we give no importance to the\nstrings that describe ontology concepts, properties etc. Because these strings\nmay be encrypted in the secured ontology. Instead we use the pure graphical\nstructure to determine mapping between various concepts of given two secured\nontologies. The paper also gives the measure of accuracy of experiment in a\ntabular form in terms of precision, recall and F-measure.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.4705v1"
    },
    {
        "title": "Memoization technique for optimizing functions with stochastic input",
        "authors": [
            "Edin H. Mulali",
            "Miomir S. Stankovi",
            "Radomir S. Stankovi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper we present a strategy for optimization functions with\nstochastic input. The main idea is to take advantage of decomposition in\ncombination with a look-up table. Deciding what input values should be used for\nmemoization is determined based on the underlying probability distribution of\ninput variables. Special attention is given to difficulties caused by\ncombinatorial explosion.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.5173v1"
    },
    {
        "title": "Understanding Complex Service Systems Through Different Lenses: An\n  Overview",
        "authors": [
            "Gerard Briscoe",
            "Krista Keranen",
            "Glenn Parry"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The 2011 Grand Challenge in Service conference aimed to explore, analyse and\nevaluate complex service systems, utilising a case scenario of delivering on\nimproved perception of safety in the London Borough of Sutton, which provided a\ncommon context to link the contributions. The key themes that emerged included\nvalue co-creation, systems and networks, ICT and complexity, for which we\nsummarise the contributions. Contributions on value co-creation are based\nmainly on empirical research and provide a variety of insights including the\nimportance of better understanding collaboration within value co-creation.\nContributions on the systems perspective, considered to arise from networks of\nvalue co-creation, include efforts to understand the implications of the\ninteractions within service systems, as well as their interactions with social\nsystems, to co-create value. Contributions within the technological sphere,\nproviding ever greater connectivity between entities, focus on the creation of\nnew value constellations and new demand being fulfilled through hybrid\nofferings of physical assets, information and people. Contributions on\ncomplexity, arising from the value co- creation networks of technology enabled\nservices systems, focus on the challenges in understanding, managing and\nanalysing these complex service systems. The theory and applications all show\nthe importance of understanding service for the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.5402v1"
    },
    {
        "title": "Value, Variety and Viability: New Business Models for Co-Creation in\n  Outcome-based Contracts",
        "authors": [
            "Irene Ng",
            "Gerard Briscoe"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  We propose that designing a manufacturer's equipment-based service value\nproposition in outcome-based contracts is the design of a new business model\ncapable of managing threats to the firm's viability that can arise from the\ncontextual variety of use that customers may subject the firm's value\npropositions. Furthermore, manufacturers need to understand these emerging\nbusiness models as the capability of managing both asset and service provision\nto achieve use outcomes with customers, including emotional outcomes such as\ncustomer experience. Service-Dominant Logic proposes that all \"goods are a\ndistribution mechanism for service provision\", upon which we propose a\nvalue-centric approach to understanding the interactions between the asset and\nservice provision, and suggest a viable systems approach towards reorganising\nthe firm to achieve such a business model. Three case studies of B2B\nequipment-based service systems were analysed to understand customers'\nco-creation activities in achieving outcomes, in which we found that the\nco-creation of complex multi-dimensional value could be delivered through the\ndifferent value propositions of the firm catering to different aspects\n(dimensions) of the value to be co-created. The study provides a way for\nmanagers to understand the effectiveness (rather than efficiency) of firms in\nadopting emerging business models that design for value co-creation in what are\nultimately complex socio- technical systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1211.5407v1"
    },
    {
        "title": "Performance Improvement by Changing Modulation Methods for Software\n  Defined Radios",
        "authors": [
            "Bhalchandra B. Godbole",
            "Dilip S. Aldar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper describes an automatic switching of modulation method to\nreconfigure transceivers of Software Defined Radio (SDR) based wireless\ncommunication system. The programmable architecture of Software Radio promotes\na flexible implementation of modulation methods. This flexibility also\ntranslates into adaptively, which is used here to optimize the throughput of a\nwireless network, operating under varying channel conditions. It is robust and\nefficient with processing time overhead that still allows the SDR to maintain\nits real-time operating objectives. This technique is studied for digital\nwireless communication systems. Tests and simulations using an AWGN channel\nshow that the SNR threshold is 5dB for the case study.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0114v1"
    },
    {
        "title": "Centralized Integrated Spectrum Sensing for Cognitive Radios",
        "authors": [
            "Dilip s. Aldar"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Spectrum sensing is the challenge for cognitive radio design and\nimplementation, which allows the secondary user to access the primary bands\nwithout interference with primary users. Cognitive radios should decide on the\nbest spectrum band to meet the Quality of service requirements over all\navailable spectrum bands. This paper investigates the integrated centralized\nspectrum sensing techniques in multipath fading environment and the performance\nwas analyzed with energy detection and wavelet based sensing techniques for\nunknown signal. Keywords: Cognitive Radio, Spectrum Sensing, Signal Detection,\nPrimary User, Secondary User\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0116v1"
    },
    {
        "title": "Review of Knowledge Management Systems As Socio-Technical System",
        "authors": [
            "Setiawan Assegaff",
            "Ab Razak Che Hussin"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Knowledge Management Systems as socio-technical systemperspectives has\nrecognized for decades. Practitioners and scholars belief Knowledge Management\nis best carried out throught the optimization both technological and\nsocial-aspect.Lacking of understand and consider both aspects could lead\norganizations in misinterpretation while developing andimplementing Knowledge\nManagement System. There is a need for practical guidance how Knowledge\nManagement System should implement in organizations. We propose a framework\nthat could use by practitioner and manager as guidance in developing and\nimplementing Knowledge Management System as Socio-Technical Systems. The\nframework developed base on Pan and Scarborough view of Knowledge Management as\nSocio-Technical system. Our framework consists of: Infrastructure(technology),\nInfo structure (organizational structure) and Info culture (organizational\nculture). This concept would lead practitioners get clear understand aspect\ncontribute to Knowledge Management System success as Socio-Technical System.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0387v1"
    },
    {
        "title": "BigFoot: Analysis, monitoring, tracking and sharing of bio-medical\n  features of human appendages using consumer-grade home and office based\n  imaging devices",
        "authors": [
            "Sam Mavandadi",
            "Steve Feng",
            "Frank Yu",
            "Richard Yu",
            "Aydogan Ozcan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Here we describe a system for personal and professional management and\nanalysis of bio-medical images captured using off-the-shelf, consumer-grade\nimaging devices such as scanners, digital cameras, cellphones, webcams and\ntablet PCs. Specifically, we describe an implementation of this system for the\nanalysis, monitoring and tracking of conditions and features of human feet\nusing a flatbed scanner as the image capture device and a custom-designed set\nof algorithms and software to manage and analyze the acquired data.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.0992v1"
    },
    {
        "title": "Hidden Markov Estimation of Bistatic Range From Cluttered Ultra-wideband\n  Impulse Responses",
        "authors": [
            "Merrick McCracken",
            "Neal Patwari"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Ultra-wideband (UWB) multistatic radar can be used for target detection and\ntracking in buildings and rooms. Target detection and tracking relies on\naccurate knowledge of the bistatic delay. Noise, measurement error, and the\nproblem of dense, overlapping multipath signals in the measured UWB channel\nimpulse response (CIR) all contribute to make bistatic delay estimation\nchallenging. It is often assumed that a calibration CIR, that is, a measurement\nfrom when no person is present, is easily subtracted from a newly captured CIR.\nWe show this is often not the case. We propose modeling the difference between\na current set of CIRs and a set of calibration CIRs as a hidden Markov model\n(HMM). Multiple experimental deployments are performed to collect CIR data and\ntest the performance of this model and compare its performance to existing\nmethods. Our experimental results show an RMSE of 2.85 ns and 2.76 ns for our\nHMM-based approach, compared to a thresholding method which, if the ideal\nthreshold is known a priori, achieves 3.28 ns and 4.58 ns. By using the\nBaum-Welch algorithm, the HMM-based estimator is shown to be very robust to\ninitial parameter settings. Localization performance is also improved using the\nHMM-based bistatic delay estimates.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.1080v1"
    },
    {
        "title": "Foundations of scientific research (Foundations of Research Activities)",
        "authors": [
            "N. M. Glazunov"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  During years 2008 to 2011 author gives several courses on Foundations of\nScientific Research at Computer Science Faculty of the National Aviation\nUniversity in Kiev. This text presents material to lectures of the courses. It\nconsists of 18 sections and some ideas of the manual can be seen from their\ntitles. These include: General notions about scientific research. Ontologies\nand upper ontologies. Ontologies of object domains. Examples of Research\nActivity. Some Notions of the Theory of Finite and Discrete Sets. Algebraic\nOperations and Algebraic Structures. Elements of the Theory of Graphs and Nets.\nScientific activity on the example of Information and its investigation.\nScientific research in Artificial Intelligence. Compilers and compilation.\nObjective, Concepts and History of Computer security. Methodological and\ncategorical apparatus of scientific research. Methodology and methods of\nscientific research. Scientific idea and significance of scientific research.\nForms of scientific knowledge organization and principles of scientific\nresearch. Theoretical study, applied study and creativity. Types of scientific\nresearch: theoretical study, applied study. Types of scientific research: forms\nof representation of material. Some sections of the text contain enough\nmaterial to lectures, but in some cases these are sketchs without references to\nFoundations of Research Activities. Really this is the first version of the\nmanual and author plans to edit, modify and extend the version. Some reasons\nimpose the author to post it as e-print. . Author compiled material from many\nsources and hope that it gives various points of view on Foundations of\nResearch Activities.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.1651v1"
    },
    {
        "title": "Controlling Home Appliances Remotely through Voice Command",
        "authors": [
            "Faisal Baig",
            "Saira Beg",
            "Muhammad Fahad Khan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Controlling appliances is a main part of automation. The main object of Home\nautomation is to provide a wireless communication link of home appliances to\nthe remote user. The main objective of this work is to make such a system which\ncontrols the home appliances remotely. This paper discusses two methods of\ncontrolling home appliances one is via voice to text SMS and other is to use\nthe mobile as a remote control, this system will provide a benefit to the\nelderly and disable people and also to those who are unaware of typing an SMS.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.1790v1"
    },
    {
        "title": "Generating Strategic IS: Towards the Winning Strategy",
        "authors": [
            "Maria Elfida",
            "Mahyuddin K. M. Nasution"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In modern era, the role of information system in organization has been taken\nmany discussions. The models of information system are constantly updated.\nHowever, most of them can not face the changing world. This paper discusses an\napproach to generating of strategic information system based on features in\norganization. We proposed an approach by using disadvantages in some tools of\nanalysis whereby the lack of analysis appear as behaviour of relation between\norganisation and the world.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.1882v1"
    },
    {
        "title": "Enhanced Image Analysis Using Cached Mobile Robots",
        "authors": [
            "Kabeer Mohammed",
            "Dr. Bhaskara Reddy"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In the field of Artificial intelligence Image processing plays a vital role\nin Decision making. Nowadays Mobile robots work as a Network sharing\nCentralized Database. All Image inputs are compared against this database and\ndecision is made. In some cases the Centralized database is in other side of\nthe globe and Mobile robots compare Input image through satellite link this\nsometime results in delays in decision making which may result in castrophe.\nThis Research paper is about how to make image processing in mobile robots less\ntime consuming and fast decision making. This research paper compares search\ntechniques employed currently and optimum search method which we are going to\nstate. Nowadays Mobile robots are extensively used in environments which are\ndangerous to human beings. In this dangerous situations quick Decision making\nmakes the difference between Hit and Miss this can also results in Day to day\ntasks performed by Mobile robots Successful or Failure.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.2531v1"
    },
    {
        "title": "Brain Connectivity Analysis Methods for Better Understanding of Coupling",
        "authors": [
            "Revati Shriram",
            "Dr. M. Sundhararajan",
            "Nivedita Daimiwal"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Action, cognition, emotion and perception can be mapped in the brain by using\nset of techniques. Translating unimodal concepts from one modality to another\nis an important step towards understanding the neural mechanisms. This paper\nprovides a comprehensive survey of multimodal analysis of brain signals such as\nfMRI, EEG, MEG, NIRS and motivations, assumptions and pitfalls associated with\nit. All these non-invasive brain modalities complement and restrain each other\nand hence improve our understating of functional and neuronal organization. By\ncombining the various modalities together, we can exploit the strengths and\nflaws of individual brain imaging methods. Integrated anatomical analysis and\nfunctional measurements of human brain offer a powerful paradigm for the brain\nmapping. Here we provide the brief review on non invasive brain modalities,\ndescribe the future of co-analysis of these brain signals.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.3786v1"
    },
    {
        "title": "Voltage Temperature Monitoring System (VTMS) for a BTS Room",
        "authors": [
            "Sadeque Reza Khan",
            "Siddique Reza Khan",
            "Arifa Ferdousi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Although Cellular communication is getting more and more popular in our\ncountry present days, but its network improvement is hampered by the crysis of\nelectricity. The recent decision of present Government is that they will not\nprovide any electricity from the grid to any new BTS rooms of any Celluler\noperator companies like Grammen Phone, Robi, Airtel etc. These companies have\nto develop their own power stations either by using generators or by developing\nsolar plants. Now a days most of the BTS rooms, that the cellular operators are\ninstalling with a generator and 48 volt battery backup. So for the\nsynchronisation of the operation of PDB, Generator and battery, they require a\ndevice called Voltage Temperature Monitoring System or VTMS. It is a\nMicrocontroller based controlling unit which controlls the operation of\ngenerator and battery when PDB in not available in the BTS room.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.4913v1"
    },
    {
        "title": "Binary Sequences with Minimum Peak Sidelobe Level up to Length 68",
        "authors": [
            "Anatolii Leukhin",
            "Egor Potehin"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Results of an exhaustive search for minimum peak sidelobe level binary\nsequences are presented. Several techniques for efficiency implementation of\nsearch algorithm are described. A table of number of non-equivalent optimal\nbinary sequences with minimum peak sidelobe (MPS) level up to length 68 is\ngiven. This number can be used in prediction of the longest length for a given\nsidelobe level of binary sequences. The examples of optimal binary MPS\nsequences having high merit factor are shown.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.4930v1"
    },
    {
        "title": "Guadalupe: a browser design for heterogeneous hardware",
        "authors": [
            "Zhen Wang",
            "Felix Xiaozhu Lin",
            "Lin Zhong",
            "Mansoor Chishtie"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Mobile systems are embracing heterogeneous architectures by getting more\ntypes of cores and more specialized cores, which allows applications to be\nfaster and more efficient. We aim at exploiting the hardware heterogeneity from\nthe browser without requiring any changes to either the OS or the web\napplications. Our design, Guadalupe, can use hardware processing units with\ndifferent degrees of capability for matched browser services. It starts with a\nweak hardware unit, determines if and when a strong unit is needed, and\nseamlessly migrates to the strong one when necessary. Guadalupe not only makes\nmore computing resources available to mobile web browsing but also improves its\nenergy proportionality. Based on Chrome for Android and TI OMAP4, We provide a\nprototype browser implementation for resource loading and rendering. Compared\nto Chrome for Android, we show that Guadalupe browser for rendering can\nincrease other 3D application's frame rate by up to 767% and save 4.7% of the\nentire system's energy consumption. More importantly, by using the two cases,\nwe demonstrate that Guadalupe creates the great opportunity for many browser\nservices to get better resource utilization and energy proportionality by\nexploiting hardware heterogeneity.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.5170v1"
    },
    {
        "title": "Green WSUS",
        "authors": [
            "Seifedine Kadry",
            "Chibli Joumaa"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The new era of information and communication technology (ICT) calls for a\ngreater understanding of the environmental impacts of recent technology. With\nincreasing energy cost and growing environmental concerns, green IT is\nreceiving more and more attention. Network and system design play a crucial\nrole in both computing and telecommunication systems. Significant part of this\nenergy cost goes to system update by downloading regularly patches and bug\nfixes to solve security problems and to assure that the operating system and\nother systems function properly. This paper describes a new design of Windows\nServer Update Services (WSUS), system responsible of downloads of the mentioned\npatches and updates from Microsoft Update website and then distributes them to\ncomputers on a network. The general idea behind our proposed design is simple.\nInstead of the periodical check done by the WSUS servers to ensure update form\nMicrosoft main servers, we rather propose to reverse the scenario in order to\nreduce energy consumption. In the proposed design, the Microsoft main server(s)\nsends signal to all WSUS servers to inform them about new updates. Once the\nsignal received, WSUS can contact the main server to start downloading.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6046v1"
    },
    {
        "title": "Design and Performance Study of Smart Antenna Systems for WIMAX\n  Applications",
        "authors": [
            "Ayman Abdallah",
            "Seifedine Kadry",
            "Chibli Joumaa"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper we propose an approach that uses homodyne receivers to design\nsmart antenna systems. The receivers functions are to detect angles of arrivals\nof seven incoming RF signals using MUSIC or ESPRIT algorithms. The\ncharacteristics of each algorithm are critical for the systems precision as\nwell as receivers types. Results are deduced from the simulation of each\nsystem, using the Advanced Design System (ADS) and MATLAB. These are compared\nto results deduced from real systems in the WIMAX (3.5GHz) domains.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6056v1"
    },
    {
        "title": "Beamforming Techniques for Multichannel audio Signal Separation",
        "authors": [
            "Hidri Adel",
            "Meddeb Souad",
            "Abdulqadir Alaqeeli",
            "Amiri Hamid"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Beamforming is a signal processing technique. It has been studied in many\nareas such as radar, sonar, seismology and wireless communications, to name but\na few. It can be used for a myriad of purposes, such as detecting the presence\nof a signal, estimating the direction of arrival, and enhancing a desired\nsignal from its measurements corrupted by noise, competing sources and\nreverberation. Actually, Beamforming has been adopted by the audio research\nsociety, mostly to separate or extract speech for noisy environment.\nBeamforming techniques basically approach the problem from a spatial point of\nview. A microphone array is used to form a spatial filter which can extract a\nsignal from a specific direction and reduce the contamination of signals from\nother directions. In this paper we survey some Beamforming techniques used for\nmultichannel audio signal separation.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6080v1"
    },
    {
        "title": "Development of Low Cost Private Office Access Control System (OACS)",
        "authors": [
            "Sadeque Reza Khan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Over the years, access control systems have become more and more\nsophisticated and several security measures have been employed to combat the\nmenace of insecurity of lives and property. This is done by preventing\nunauthorized entrance into buildings through entrance doors using conventional\nand electronic locks, discrete access code, and biometric methods such as the\nfinger prints, thumb prints, the iris and facial recognition. We have designed\na flexible and low cost modular system based on integration of keypad, magnetic\nlock and a controller. PIC 16F876A which is an 8-bit Microcontroller, is used\nhere as a main controller. An advanced simulation based compiler Flowcode V4 is\nused to develop the software part in this project.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6196v1"
    },
    {
        "title": "Building design in tropical climates. Elaboration of the ECODOM standard\n  in the french tropical islands",
        "authors": [
            "Franois Garde",
            "Harry Boyer",
            "Robert Celaire",
            "Laurent Seauve"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper deals with the elaboration of global quality standards for natural\nand low energy cooling in french tropical island buildings. Electric load\nprofiles of tropical islands in developed countries are characterised by\nmorning, midday and evening peaks arising from all year round high power demand\nin the commercial and residential sectors, mostly due to air conditioning\nappliances and bad thermal conception of the building. In early 1995, a DSM\npilot initiative has been launched in the french islands of Guadeloupe and\nReunion through a partnership between the French Public Utility EDF,\ninstitutions involved in energy conservation, environment preservation (ADEME)\nand construction quality improvment, the University of Reunion Island and\nseveral other public and private partners (low cost housing institutions,\narchitects, energy consultant, etc...) to set up a standard in the thermal\nconception of buildings in tropical climates. This has led to definition of\noptimized bioclimatic urban planning and architectural design, the use of\npassive cooling architectural components, natural ventilation and energy\nefficient systems. The impact of each technical solution on the thermal comfort\nwithin the building was evaluated with an airflow and thermal building\nsimulation software (CODYRUN). These technical solutions have been edited in a\npedagogical reference document and have been implemented in 300 new pilot\ndwelling projects through the year 1996 in Reunion Island and in Guadeloupe\nisland. An experimental follow up is still in process in the first ECODOM\ndwellings for an experimental validation of the impact of the passive cooling\nsolutions on the comfort of the occupants and to modify them if necessary.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6241v1"
    },
    {
        "title": "YAGI Antenna Design for Signal Phone Jammer",
        "authors": [
            "Y. Fitriyani",
            "A. B. Mutiara",
            "R. Refianti"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Mobile phone is one of the most widely used today in mobile communications.\nThis technology is very useful for communication but this raises several\nproblems in a situation where silence is required such as in libraries, places\nof worship, classrooms and others. Mobile phone jammer is a device that used to\nblock the incoming signal to a mobile phone from the base station. If the\nmobile phone jammer is turned on then it can not form the incoming or outgoing\ncalls even sms. In this research, we designed a Yagi antenna (900MHz) to expand\nthe range of jamming because Yagi has a great gain. Results of impedance by\ngamma match are 50.16 Om. Obtained the value of VSWR Yagi is 1.46:1 and jamming\ndistance that can be taken approximately 16 meters, It is different from the\njamming distance of helical antenna on a mobile phone jammer itself is about 4\nmeters.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6299v1"
    },
    {
        "title": "URI Identity and Web Architecture Revisited",
        "authors": [
            "Xiaoshu Wang"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This document reexamined the URI's identity issue and the debate regarding\nthe nature of \"information resource\". By making emphasis on the abstract nature\nof resource and the role of URI as an interface to the web, this article\npresented an alternative viewpoint about the architecture of the web that would\nallow us to objectively and consistently treat all kinds of resources.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6372v1"
    },
    {
        "title": "On Neighborhood Tree Search",
        "authors": [
            "Houda Derbel",
            "Bilel Derbel"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  We consider the neighborhood tree induced by alternating the use of different\nneighborhood structures within a local search descent. We investigate the issue\nof designing a search strategy operating at the neighborhood tree level by\nexploring different paths of the tree in a heuristic way. We show that allowing\nthe search to 'backtrack' to a previously visited solution and resuming the\niterative variable neighborhood descent by 'pruning' the already explored\nneighborhood branches leads to the design of effective and efficient search\nheuristics. We describe this idea by discussing its basic design components\nwithin a generic algorithmic scheme and we propose some simple and intuitive\nstrategies to guide the search when traversing the neighborhood tree. We\nconduct a thorough experimental analysis of this approach by considering two\ndifferent problem domains, namely, the Total Weighted Tardiness Problem\n(SMTWTP), and the more sophisticated Location Routing Problem (LRP). We show\nthat independently of the considered domain, the approach is highly\ncompetitive. In particular, we show that using different branching and\nbacktracking strategies when exploring the neighborhood tree allows us to\nachieve different trade-offs in terms of solution quality and computing cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1212.6510v1"
    },
    {
        "title": "Application of polynomial vector (pv) processing to improve the\n  estimation performance of bio diesel in variable compression ratio diesel\n  engine",
        "authors": [
            "M. Suresh",
            "Maheswar Dutta",
            "S. Purushothaman"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper presents the implementation of polynomial vector back propagation\nalgorithm (PVBPA) for estimating the power, torque, specific fuel consumption\nand presence of carbon monoxide, hydrocarbons in the emission of a direct\ninjection diesel engine. Experimental readings were obtained using the\nbiodiesel prepared form the waste low quality cooking oil collected from the\ncanteen of Sri Sairam Engineering College, India.. This waste cooking oil was\ndue to the preparation of varieties of food (vegetables fried and non\nvegetarian). Over more than a week, trans esterification was done in chemical\nlab and the biodiesel was obtained. The biodiesel was mixed in proportions of\n10%, 20%, 30%, 40%, 50% with remaining combinations of the diesel supplied by\nthe Indian government. Variable compression ratio (VCR) diesel engine with\nsingle cylinder, four stroke diesel type was used. The outputs of the engine as\npower, torque and specific fuel consumption were obtained from the\ncomputational facility attached to the engine. The data collected for different\ninput conditions of the engine was further used to train (PVBPA). The trained\nPVBPA network was further used to predict the power, torque and brake specific\nfuel consumption (SFC) for different speed, biodiesel and diesel combinations\nand full load condition. The estimation performance of the PVBPA network is\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.1261v1"
    },
    {
        "title": "Microelectromechanical Resonators for Radio Frequency Communication\n  Applications",
        "authors": [
            "Joydeep Basu",
            "Tarun Kanti Bhattacharyya"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Over the past few years, microelectromechanical system (MEMS) based on-chip\nresonators have shown significant potential for sensing and high frequency\nsignal processing applications. This is due to their excellent features like\nsmall size, large frequency-quality factor product, low power consumption, low\ncost batch fabrication, and integrability with CMOS IC technology. Radio\nfrequency communication circuits like reference oscillators, filters, and\nmixers based on such MEMS resonators can be utilized for meeting the increasing\ncount of RF components likely to be demanded by the next generation\nmulti-band/multi-mode wireless devices. MEMS resonators can provide a feasible\nalternative to the present day well established quartz crystal technology that\nis riddled with major drawbacks like relatively large size, high cost, and low\ncompatibility with IC chips. This article presents a survey of the developments\nin this field of resonant MEMS structures with detailed enumeration on the\nvarious micromechanical resonator types, modes of vibration, equivalent\nmechanical and electrical models, materials and technologies used for\nfabrication, and the application of the resonators for implementing oscillators\nand filters. These are followed by a discussion on the challenges for RF MEMS\ntechnology in comparison to quartz crystal technology; like high precision,\nstability, reliability, need for hermetic packaging etc. which remain to be\naddressed for enabling the inclusion of micromechanical resonators into\ntomorrow's highly integrated communication systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.2780v1"
    },
    {
        "title": "Generic System Verilog Universal Verification Methodology based Reusable\n  Verification Environment for Efficient Verification of Image Signal\n  Processing IPs/SoCs",
        "authors": [
            "Abhishek Jain",
            "Giuseppe Bonanno",
            "Hima Gupta",
            "Ajay Goyal"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper,we present Generic System Verilog Universal Verification\nMethodology based Reusable Verification Environment for efficient verification\nof Image Signal Processing IP's/SoC's. With the tight schedules on all projects\nit is important to have a strong verification methodology which contributes to\nFirst Silicon Success. Deploy methodologies which enforce full functional\ncoverage and verification of corner cases through pseudo random test scenarios\nis required. Also, standardization of verification flow is needed. Previously,\ninside imaging group of ST, Specman (e)/Verilog based Verification Environment\nfor IP/Subsystem level verification and C/C++/Verilog based Directed\nVerification Environment for SoC Level Verification was used for Functional\nVerification. Different Verification Environments were used at IP level and SoC\nlevel. Different Verification/Validation Methodologies were used for SoC\nVerification across multiple sites. Verification teams were also looking for\nthe ways how to catch bugs early in the design cycle? Thus, Generic System\nVerilog Universal Verification Methodology (UVM) based Reusable Verification\nEnvironment is required to avoid the problem of having so many methodologies\nand provides a standard unified solution which compiles on all tools. The main\naim of development of this Generic and automatic verification environment is to\ndevelop an efficient and unified verification environment (at IP/Subsystem/SoC\nLevel) which reuses the already developed Verification components and also\nsequences written at IP/Subsystem level can be reused at SoC Level both with\nHost BFM and actual Core using Incisive Software Extension (ISX) and Virtual\nRegister Interface (VRI)/Verification Abstraction Layer (VAL) approaches.\nIP-XACT based tools are used for automatically configuring the environment for\nvarious imaging IPs/SoCs.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.2858v1"
    },
    {
        "title": "Aplikasi belajar membaca iqro' berbasis mobile",
        "authors": [
            "Muhamd Sobri",
            "Leon Andretti Abdillah"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  IPTEK and IMTAQ should be followed by knowledge of the ability in reading the\nhijaiyah letters as Al Qur-an base. Current people are so busy with their\nactivities thats way authors develop this mobile application using pocket pc.\nThe development of this research using waterfall model. Authors use the\nprogramming language of Microsoft Visual BASIC.Net. Authors also use Photoshop\nto prepare the image of every letter. In Indonesia, there six level in reading\nAl Qur-an, but for the purpose of thi research authors only use Iqro-1 until\nIqro-4. This mobile application also enriched with the voice for every letter\nimage.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.6319v1"
    },
    {
        "title": "MFLP: Most Frequent Least Power Encoding",
        "authors": [
            "Mehdi Taassori",
            "Meysam Taassori",
            "Sener Uysal"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper has been withdrawn by the authors. In this paper, we propose a new\nlow power coding technique by decreasing the number of switching activities on\nthe buses which use transition signaling to transmit data. This approach\ndedicates the symbols with less ones to high probability data. MFLP unlike the\nmost low power encoding does not rely on spatial redundancy. Due to this\nsuperiority, MFLP is unique in power decreasing in the Network on Chip (NoC).\nNot only does this algorithm reduce the power consumption, but also it can\ncompress the data. It offers a tradeoff to designers to choose between\ncompression and power; that is, the more power consumption decrease we need,\nthe less compression we earn. This coding uses tree based infrastructure in\norder to decrease the number of ones to reduce the switching activities, and\nthe power consumption consequently. The proposed algorithm constructs the tree\nwith this contribution that code words with less ones are allocated to more\nfrequent data. The experimental results for the outside and inside of the NoC\nindicate that the proposed coding algorithm reduces the switching activity up\nto 30 and 45%, the link power consumption up to 35 and 46% and the total power\ndissipation up to 34.9 and 16% for the outside and inside of the NoC,\nrespectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.6946v2"
    },
    {
        "title": "Data Analysis on the High-Frequency Pollution Data Collected in India",
        "authors": [
            "Lamling Venus Shum",
            "Manik Gupta",
            "Pachamuthu Rajalakshmi"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Fine grained 1Hz Carbon Monoxide pollution data were collected on a busy road\nin Hyderabad, India. In this paper we report the findings from analysing the\nexperimental data, in which it was found that the data were log-normally\ndistributed and nonlinear. The dominant frequencies at peak hours were caused\nby the pattern of traffic flow.\n",
        "pdf_link": "http://arxiv.org/pdf/1301.7231v1"
    },
    {
        "title": "Analisis laporan tugas akhir mahasiswa Diploma I dari sudut pandang\n  kaidah ilmiah dan penggunaan teknologi informasi",
        "authors": [
            "Leon Andretti Abdillah",
            " Emigawaty"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The purposes of this research are: 1) to analyze final report from scientific\nrole, 2) the use of information technology (IT), and 3) to conduct academic\nathmosphere in research area. This research gives contributions to study\nprogram of MI-DI, such as: 1) to know the pattern of student final report from\nscientific role and the use of IT, 2) give input to study program for next\nfinal report scheme, and 3) can be used for next research reference. If we look\nto the quality of final report, there are several focuses to be prepared on\ntittle, literature review, methodology, results of report, discussion and also\nconclusion. But for the use of IT is already good but the varian is decrease.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.0338v1"
    },
    {
        "title": "Circuit proposition for copying the value of a resistor into a\n  memristive device supported by HSPICE simulation",
        "authors": [
            "Farshad Merrikh-Bayat",
            "Nafiseh Mirebrahimi",
            "Farhad Bayat"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Memristor is the fourth fundamental passive circuit element with potential\napplications in development of analog memories, artificial brains (with the\ncapacity of hardware training) and neuro-science. In most of these applications\nthe memristance of the device should be set to the desired value, which is\ncurrently performed by trial and error. The aim of this paper is to propose a\ncircuit for copying the value of the given resistor into a memristive device.\nHSPICE simulations are also presented to confirm the efficiency of the proposed\ncircuit.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.1005v1"
    },
    {
        "title": "Improving Mixed-Criticality System Consistency and Behavior on\n  Multiprocessor Platforms by Means of Multi-Moded Approaches",
        "authors": [
            "Franois Santy",
            "Geoffrey Nelissen",
            "Jol Goossens"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Recent research in the domain of real-time scheduling theory has tackled the\nproblem of scheduling mixed-criticality systems upon uniprocessor or\nmultiprocessor platforms, with the main objective being to respect the\ntimeliness of the most critical tasks, at the expense of the requirements of\nthe less critical ones. In particular, the less critical tasks are carelessly\ndiscarded when the computation demand of (some of) the high critical tasks\nincreases. This might nevertheless result in system failure, as these less\ncritical tasks could be accessing data, the consistency of which should be\npreserved. In this paper, we address this problem and propose a method to\ncautiously handle task suspension. Furthermore, it is usually assumed that the\nless critical tasks will never be re-enabled once discarded. In this paper, we\nalso address this concern by proposing an approach to re-enable the less\ncritical tasks, without jeopardizing the timeliness of the high critical ones.\nThe suggested approaches apply to systems having two or more criticality\nlevels.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.1010v1"
    },
    {
        "title": "An Approach to Select Cost-Effective Risk Countermeasures Exemplified in\n  CORAS",
        "authors": [
            "Le Minh Sang Tran",
            "Bjrnar Solhaug",
            "Ketil Stlen"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Risk is unavoidable in business and risk management is needed amongst others\nto set up good security policies. Once the risks are evaluated, the next step\nis to decide how they should be treated. This involves managers making\ndecisions on proper countermeasures to be implemented to mitigate the risks.\nThe countermeasure expenditure, together with its ability to mitigate risks, is\nfactors that affect the selection. While many approaches have been proposed to\nperform risk analysis, there has been less focus on delivering the prescriptive\nand specific information that managers require to select cost-effective\ncountermeasures. This paper proposes a generic approach to integrate the cost\nassessment into risk analysis to aid such decision making. The approach makes\nuse of a risk model which has been annotated with potential countermeasures,\nestimates for their cost and effect. A calculus is then employed to reason\nabout this model in order to support decision in terms of decision diagrams. We\nexemplify the instantiation of the generic approach in the CORAS method for\nsecurity risk analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.4689v2"
    },
    {
        "title": "Perangkat lunak bantu mengenal huruf arab melayu ke bentuk huruf latin\n  bahasa Indonesia",
        "authors": [
            "Nuril Aini",
            "Leon Andretti Abdillah",
            " Jemakmun"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The development of computer science has contributed greatly for increasing of\nefficiency and effectively. Many areas are covered by computer science,\nincluded education. The purpose of this research is to introduce jawi a type of\nIndonesian letters. Jawis letter is one of the most popular letter in the past.\nBut right now few people can read and understand it. Many documents in the past\nwas written in Jawi. The writer develop or build the software using Pressman\nmethod, and tools such as Microsoft Visual Basic, and Microsoft Access. This\nsoftware can introduce Jawi then people can learn it easily.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.5511v1"
    },
    {
        "title": "Embedding of Deterministic Test Data for In-Field Testing",
        "authors": [
            "Nan Li",
            "Elena Dubrova"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper presents a new feedback shift register-based method for embedding\ndeterministic test patterns on-chip suitable for complementing conventional\nBIST techniques for in-field testing. Our experimental results on 8 real\ndesigns show that the presented approach outperforms the bit-flipping approach\nby 24.7% on average. We also show that it is possible to exploit the uneven\ndistribution of don't care bits in test patterns in order to reduce the area\nrequired for storing deterministic test patterns more than 3 times with less\nthan 2% fault coverage drop.\n",
        "pdf_link": "http://arxiv.org/pdf/1302.6454v1"
    },
    {
        "title": "Adaptive Modulation (QPSK, QAM)",
        "authors": [
            "Rao Farhat Masood"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper, introduced below are the concepts of digital modulation used\nin many communication systems today. Techniques described include quadrature\nphase shift keying (QPSK) and quadrature amplitude modulation (QAM) and how\nthese techniques can be used to increase the capacity and speed of a wireless\nnetwork. These modulation techniques are the basis of communications for\nsystems like cable modems, DSL modems, CDMA, 3G, Wi-Fi* (IEEE 802.11) and\nWiMAX* (IEEE 802.16).\n",
        "pdf_link": "http://arxiv.org/pdf/1302.7145v1"
    },
    {
        "title": "Energy Aware Task Scheduling for Soft Real Time Systems using an\n  Analytical Approach for Energy Estimation",
        "authors": [
            "Namita Sharma",
            "Vineet Sahula",
            "C. P. Ravikumar"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Embedded systems have pervaded all walks of our life. With the increasing\nimportance of mobile embedded systems and flexible applications, considerable\nprogress in research has been made for power management. Power constraints are\nincreasingly becoming the critical component of the design specifications of\nthese systems. It helps in pre-determining the suitable hardware architecture\nfor the target application. The aim of this paper is to present a technique to\nestimate 'pre-run time' and 'power' of a software mapped onto a hardware\nsystem; guaranteeing the compliance of temporal constraints while generating a\nschedule of tasks of software. Real time systems must handle several\nindependent macro-tasks, each represented by a task graph, which includes\ncommunications and precedence constraints. We propose a novel approach for\npower estimation of embedded software using the Control Data Flow Graph (CDFG)\nor task graph model. This methodology uses an existing Hierarchical Concurrent\nFlow Graph (HCFG) technique for the power analysis of the CDFGs. We have\nevaluated our technique for energy efficient scheduling over various task graph\nbenchmarks. The results obtained prove the utility and efficacy of our proposed\napproach for power analysis of embedded software. We also present a methodology\nto obtain an energy optimal voltage assignment and perform scheduling by taking\nadvantage of the relaxation in execution time of tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.0725v1"
    },
    {
        "title": "Joint Ultra-wideband and Signal Strength-based Through-building Tracking\n  for Tactical Operations",
        "authors": [
            "Merrick McCracken",
            "Maurizio Bocca",
            "Neal Patwari"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Accurate device free localization (DFL) based on received signal strength\n(RSS) measurements requires placement of radio transceivers on all sides of the\ntarget area. Accuracy degrades dramatically if sensors do not surround the\narea. However, law enforcement officers sometimes face situations where it is\nnot possible or practical to place sensors on all sides of the target room or\nbuilding. For example, for an armed subject barricaded in a motel room, police\nmay be able to place sensors in adjacent rooms, but not in front of the room,\nwhere the subject would see them. In this paper, we show that using two\nultra-wideband (UWB) impulse radios, in addition to multiple RSS sensors,\nimproves the localization accuracy, particularly on the axis where no sensors\nare placed (which we call the x-axis). We introduce three methods for combining\nthe RSS and UWB data. By using UWB radios together with RSS sensors, it is\nstill possible to localize a person through walls even when the devices are\nplaced only on two sides of the target area. Including the data from the UWB\nradios can reduce the localization area of uncertainty by more than 60%.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.1418v1"
    },
    {
        "title": "A Multi-objective Perspective for Operator Scheduling using Fine-grained\n  DVS Architecture",
        "authors": [
            "Rajdeep Mukherjee",
            "Priyankar Ghosh",
            "Pallab Dasgupta",
            "Ajit Pal"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The stringent power budget of fine grained power managed digital integrated\ncircuits have driven chip designers to optimize power at the cost of area and\ndelay, which were the traditional cost criteria for circuit optimization. The\nemerging scenario motivates us to revisit the classical operator scheduling\nproblem under the availability of DVFS enabled functional units that can\ntrade-off cycles with power. We study the design space defined due to this\ntrade-off and present a branch-and-bound(B/B) algorithm to explore this state\nspace and report the pareto-optimal front with respect to area and power. The\nscheduling also aims at maximum resource sharing and is able to attain\nsufficient area and power gains for complex benchmarks when timing constraints\nare relaxed by sufficient amount. Experimental results show that the algorithm\nthat operates without any user constraint(area/power) is able to solve the\nproblem for most available benchmarks, and the use of power budget or area\nbudget constraints leads to significant performance gain.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.1645v1"
    },
    {
        "title": "A Digital Automatic Sliding Door with a Room Light Control System",
        "authors": [
            "A. M. Zungeru",
            "P. O. Abraham-Attah"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Automatic door is an automated movable barrier installed in the entry of a\nroom or building to restrict access, provide ease of opening a door or provide\nvisual privacy. As a result of enhanced civilization and modernization, the\nhuman nature demands more comfort to his life. The man seeks ways to do things\neasily and which saves time. So thus, the automatic gates are one of the\nexamples that human nature invent to bring comfort and ease in its daily life.\nTo this end, we model and design an automatic sliding door with a room light\ncontrol system to provide the mentioned needs. This was achieved by considering\nsome factors such as economy, availability of components and research\nmaterials, efficiency, compatibility and portability and also durability in the\ndesign process. The performance of the system after test met design\nspecifications. This system works on the principle of breaking an infrared beam\nof light, sensed by a photodiode. It consists of two transmitting infrared\ndiodes and two receiving photo-diodes. The first one is for someone coming in\nand the second one is for someone going out of the room. The photodiodes are\nconnected to comparators, which give a lower output when the beam is broken and\nhigh output when transmitting normally. The general operation of the work and\nperformance is dependent on the presence of an intruder entering through the\ndoor and how close he/she is in closer to the door. The door is meant to open\nautomatically but in a case where there is no power supply trying to force the\ndoor open would damage the mechanical control system of the unit. The overall\nwork was implemented with a constructed work, tested working and perfectly\nfunctional.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.1728v1"
    },
    {
        "title": "An electronic digital combination lock: A precise and reliable security\n  system",
        "authors": [
            "A. M. Zungeru"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The increasing rate of crime, attacks by thieves, intruders and vandals,\ndespite all forms of security gadgets and locks still need the attention of\nresearchers to find a permanent solution to the well being of lives and\nproperties of individuals. To this end, we design a cheap and effective\nsecurity system for buildings, cars, safes, doors and gates, so as to prevent\nunauthorized person from having access to ones properties through the use of\ncodes, we therefore experiment the application of electronic devices as locks.\nHowever, a modular approach was employed in the design in which the combination\nlock was divided into units and each unit designed separately before being\ncoupled to form a whole functional system. During the design, we conducted\nTwenty tests with the first eight combinations being four in number, the next\nseven tests being five and the last five combinations being six. This was done\nbecause of the incorporation of 2 dummy switches in the combinations. From the\nresult obtained, combinations 8, 11, 13 gave the correct output combination.\nHowever, 8 being the actual combination gave the required output. The general\noperation of the system and performance is dependent on the key combinations.\nThe overall system was constructed and tested and it works perfectly.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.1734v1"
    },
    {
        "title": "Speaking Plant Approach for Automatic Fertigation System in Greenhouse",
        "authors": [
            "Usman Ahmad",
            "Dewa Made Subrata",
            "Chusnul Arif"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Nowadays, many vegetables are grown insidegreenhouses in which environment is\ncontrolled and nutrition can be supplied through water supply using electrical\npump, namely fertigation. Dosage of nutrition in water for many vegetable\nplants are also known so that by controllingwater supply all the needsfor the\nplants to grow are available. Furthermore, water supply can be controlled using\nelectrical pump which is activated according to theplants conditionin relation\nwith water supply. In order to supply water and nutrition in the right amount\nand time, plants condition can be observed using a CCD camera attached to image\nprocessing facilitiesto develop a speaking plant approach. In this study,\nplants development during their growing periodare observedusing image\nprocessing. Three populationsof tomato plants, with less, enough, and exceeded\nnutrition in water,are captured using a CCD camera every three days, and the\nimages were analyzed using a developed computer program for the heightof\nplants. The results showed that the development of the plants can be monitored\nusing this method. After that, the responseof plant growth in the same\ncondition was monitored, and the responsewas used as input for the fertigation\nsystem to turn electrical pump automatically on and off, so the fertigation\nsystem could maintain the growth of the plants.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.1869v1"
    },
    {
        "title": "Proposition d'une technique de gestion de projet dans les startups",
        "authors": [
            "Djallel Bouneffouf"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This project is part of the development of mobile CRM. It aims to develop a\nmanagement application client named NOMALYS. This application allows the\ncommercial and business leaders to see their CRM Mobile. We have focused in\nthis project on the techniques of projects management, this study allowed to\nclassify different techniques for managing software projects and proposed the\nmost closely technique that match the needs of the studied company.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.2317v1"
    },
    {
        "title": "Multi-User Multi-Carrier Differential Chaos Shift Keying Communication\n  System",
        "authors": [
            "Georges Kaddoum",
            "Francois-Dominique Richardson",
            "Sarra Adouni",
            "Francois Gagnon",
            "Claude Thibeault"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper, a multi user Multi-Carrier Differential Chaos Shift Keying\n(MC-DCSK) modulation is presented. The system endeavors to provide a good\ntrade-off between robustness, energy efficiency and high data rate, while still\nbeing simple. In this architecture of MC-DCSK system, for each user, chaotic\nreference sequence is transmitted over a predefined subcarrier frequency.\nMultiple modulated data streams are transmitted over the remaining subcarriers\nallocated for each user. This transmitter structure saves energy and increases\nthe spectral efficiency of the conventional DCSK system.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.2552v3"
    },
    {
        "title": "Adaptive Transmission Techniques for Mobile Satellite Links",
        "authors": [
            "Jesus Arnau",
            "Alberto Rico-Alvario",
            "Carlos Mosquera"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Adapting the transmission rate in an LMS channel is a challenging task\nbecause of the relatively fast time variations, of the long delays involved,\nand of the difficulty in mapping the parameters of a time-varying channel into\ncommunication performance. In this paper, we propose two strategies for dealing\nwith these impairments, namely, multi-layer coding (MLC) in the forward link,\nand open-loop adaptation in the return link. Both strategies rely on\nphysical-layer abstraction tools for predicting the link performance. We will\nshow that, in both cases, it is possible to increase the average spectral\nefficiency while at the same time keeping the outage probability under a given\nthreshold. To do so, the forward link strategy will rely on introducing some\nlatency in the data stream by using retransmissions. The return link, on the\nother hand, will rely on a statistical characterization of a physical-layer\nabstraction measure.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.3110v1"
    },
    {
        "title": "Design and Analysis of a Multi-Carrier Differential Chaos Shift Keying\n  Communication System",
        "authors": [
            "Georges Kaddoum",
            "Francois-Dominique Richardson",
            "Francois Gagnon"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A new Multi-Carrier Differential Chaos Shift Keying (MC-DCSK) modulation is\npresented in this paper. The system endeavors to provide a good trade-off\nbetween robustness, energy efficiency and high data rate, while still being\nsimple compared to conventional multi-carrier spread spectrum systems. This\nsystem can be seen as a parallel extension of the DCSK modulation where one\nchaotic reference sequence is transmitted over a predefined subcarrier\nfrequency. Multiple modulated data streams are transmitted over the remaining\nsubcarriers. This transmitter structure increases the spectral efficiency of\nthe conventional DCSK system and uses less energy. The receiver design makes\nthis system easy to implement where no radio frequency (RF) delay circuit is\nneeded to demodulate received data. Various system design parameters are\ndiscussed throughout the paper, including the number of subcarriers, the\nspreading factor, and the transmitted energy. Once the design is explained, the\nbit error rate performance of the MC-DCSK system is computed and compared to\nthe conventional DCSK system under an additive white Gaussian noise (AWGN) and\nRayleigh channels. Simulation results confirm the advantages of this new hybrid\ndesign.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.3177v4"
    },
    {
        "title": "Performance Analysis of LMS Filter for SSPA Linearization in Different\n  Modulation Conditions",
        "authors": [
            "J. N. Swaminathan",
            "P. Kumar",
            "M. Vinoth"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The SSPA has wide application in Communication system, but its high output\npower varies due to its non linear gain. Pre-distortion method plays major role\nin power amplifier linearization. Polynomial is one of the methods used. The\nerror estimation in Polynomial method is carried out by LMS Filter. Our main\nwork is to analysis the error estimation performance of the LMS Filter for the\nSolid state power amplifiers (SSPA) in different modulation conditions. Here we\nare calculating the ACP and analyzing how effectively the memoryless non\nlinearity has been reduced for all digital modulation techniques. All the\nanalysis and results are taken using Matlab software.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.3263v1"
    },
    {
        "title": "Device-Free Person Detection and Ranging in UWB Networks",
        "authors": [
            "Yakup Kilic",
            "Henk Wymeersch",
            "Arjan Meijerink",
            "Mark J. Bentum",
            "William G. Scanlon"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We present a novel device-free stationary person detection and ranging\nmethod, that is applicable to ultra-wide bandwidth (UWB) networks. The method\nutilizes a fixed UWB infrastructure and does not require a training database of\ntemplate waveforms. Instead, the method capitalizes on the fact that a human\npresence induces small low-frequency variations that stand out against the\nbackground signal, which is mainly affected by wideband noise. We analyze the\ndetection probability, and validate our findings with numerical simulations and\nexperiments with off-the-shelf UWB transceivers in an indoor environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4092v2"
    },
    {
        "title": "Medical Process Modeling: an Artifact-Centric Approach",
        "authors": [
            "Dmitry Solomakhin"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this position paper we argue that just as traditional business process\nmodeling has been adopted to deal with clinical pathways, also the\nartifact-centric process modeling technique may be successfully used to model\nvarious kinds of medical processes: physiological processes, disease behavior\nand treatment processes. We also discuss how a proposed approach may be used to\ndeal with an interplay of all the processes a patient is subject to and what\nare the queries that might be imposed over an overall patient model.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4461v1"
    },
    {
        "title": "Using UWB for Human Trajectory Extraction",
        "authors": [
            "Gonalo Vasconcelos",
            "Marcelo Petry",
            "Joo Emlio Almeida",
            "Rosaldo J. F. Rossetti",
            "Antnio Lea Coelho"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper we report on a methodology to model pedestrian behaviours\nwhilst aggregate variables are concerned, with potential applications to\ndifferent situations, such as evacuating a building in emergency events. The\napproach consists of using UWB (ultra-wide band) based data collection to\ncharacterise behaviour in specific scenarios. From a number of experiments\ncarried out, we detail the single-file scenario to demonstrate the ability of\nthis approach to represent macroscopic characteristics of the pedestrian flow.\nResults are discussed and we can conclude that UWB-based data collection shows\ngreat potential and suitability for human trajectory extraction, when compared\nto other traditional approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4696v1"
    },
    {
        "title": "Universal Numerical Encoder and Profiler Reduces Computing's Memory Wall\n  with Software, FPGA, and SoC Implementations",
        "authors": [
            "Albert Wegener"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In the multicore era, the time to computational results is increasingly\ndetermined by how quickly operands are accessed by cores, rather than by the\nspeed of computation per operand. From high-performance computing (HPC) to\nmobile application processors, low multicore utilization rates result from the\nslowness of accessing off-chip operands, i.e. the memory wall. The APplication\nAXcelerator (APAX) universal numerical encoder reduces computing's memory wall\nby compressing numerical operands (integers and floats), thereby decreasing CPU\naccess time by 3:1 to 10:1 as operands stream between memory and cores. APAX\nencodes numbers using a low-complexity algorithm designed both for time series\nsensor data and for multi-dimensional data, including images. APAX encoding\nparameters are determined by a profiler that quantifies the uncertainty\ninherent in numerical datasets and recommends encoding parameters reflecting\nthis uncertainty. Compatible software, FPGA, and systemon-chip (SoC)\nimplementations efficiently support encoding rates between 150 MByte/sec and\n1.5 GByte/sec at low power. On 25 integer and floating-point datasets, we\nachieved encoding rates between 3:1 and 10:1, with average correlation of\n0.999959, while accelerating computational \"time to results.\"\n",
        "pdf_link": "http://arxiv.org/pdf/1303.4994v1"
    },
    {
        "title": "Principle \"synthesis\" for the solution of tasks of class NP",
        "authors": [
            "Rustem Valeyev"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Initial contours of the non-standard approach to reception of the answer of\nany task on discrete structures are considered: the algorithm independently\ncreates such answer from separate fragments.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.6311v1"
    },
    {
        "title": "Development of a Device for Remote Monitoring of Heart Rate and Body\n  Temperature",
        "authors": [
            "Mohammad Ashekur Rahman",
            "Atanu Barai",
            "Md. Asadul Islam",
            "M. M. A Hashem"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We present a new integrated, portable device to provide a convenient solution\nfor remote monitoring heart rate at the fingertip and body temperature using\nEthernet technology and widely spreading internet. Now a days, heart related\ndisease is rising. Most of the times in these cases, patients may not realize\ntheir actual conditions and even it is a common fact that there are no doctors\nby their side, especially in rural areas, but now a days most of the diseases\nare curable if detected in time.\n  We have tried to make a system which may give information about one's\nphysical condition and help him or her to detect these deadly but curable\ndiseases. The system gives information of heart rate and body temperature\nsimultaneously acquired on the portable side in real time and transmits results\nto web. In this system, the condition of heart and body temperature can be\nmonitored from remote places. Eventually, this device provides a low cost,\neasily accessible human health monitor solution bridging the gaps between\npatients and doctors.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.0156v1"
    },
    {
        "title": "Hubs and Authorities of the English Premier League for 2010-2011",
        "authors": [
            "Michael Leznik"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this work author applies well known web search algorithm Hyperlink -\nInduced Topic Search (HITS) to problem of ranking football teams in English\nPremier League (EPL). The algorithm allows the ranking of the teams using the\nnotions of hubs and authorities well known for ranking pages in the World Wide\nWeb. Results of the games introduced as a graph where losing team 'gives a\nlink' to a winning team and, if draw registered both team give links to each\nother. In case of a win link is weighted as three points in adjacent matrix and\nin case of draw as one point. Author uses notion of authority in order to\ndefine team which win a game and hub as a team which lose a game, the winner of\nthe competition defined as the 'worst' hub, team that didn't reinforced any\nother team. Using this ranking system, the champion's team, which is a 'worst\nhub' must not lose, or draw games to other 'good authorities' teams. If by the\nend of the competition there are teams with an equal number of wins and losses\nthen the team which has beaten more teams with higher authority ranks, wins.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.0727v1"
    },
    {
        "title": "A Simulation and Modeling of Access Points with Definition Language",
        "authors": [
            "Tairen Sun"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This submission has been withdrawn by arXiv administrators because it\ncontains fictitious content and was submitted under a pseudonym, which is\nagainst arXiv policy.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.1836v2"
    },
    {
        "title": "Scheduling Cutting Process for Large Paper Rolls",
        "authors": [
            "Mehmet E. Aydin",
            "Osman Taylan"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Paper cutting is a simple process of slicing large rolls of paper,\njumbo-reels, into various sub-rolls with variable widths based on demands risen\nby customers. Since the variability is high due to collected various orders\ninto a pool, the process turns to be production scheduling problem, which\nrequires optimisation so as to minimise the final remaining amount of paper\nwasted. The problem holds characteristics similar one-dimensional bin-packing\nproblem to some extends and differs with some respects. This paper introduces a\nmodelling attempt as a scheduling problem with an integer programming approach\nfor optimisation purposes. Then, a constructive heuristic algorithm revising\none of well-known approaches, called Best-fit algorithm, is introduced to solve\nthe problem. The illustrative examples provided shows the near optimum solution\nprovided with very low complexity .\n",
        "pdf_link": "http://arxiv.org/pdf/1304.2015v1"
    },
    {
        "title": "Design and Development of a Heart Rate Measuring Device using Fingertip",
        "authors": [
            "M. M. A. Hashem",
            "Rushdi Shams",
            "Md. Abdul Kader",
            "Md. Abu Sayed"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper, we presented the design and development of a new integrated\ndevice for measuring heart rate using fingertip to improve estimating the heart\nrate. As heart related diseases are increasing day by day, the need for an\naccurate and affordable heart rate measuring device or heart monitor is\nessential to ensure quality of health. However, most heart rate measuring tools\nand environments are expensive and do not follow ergonomics. Our proposed Heart\nRate Measuring (HRM) device is economical and user friendly and uses optical\ntechnology to detect the flow of blood through index finger. Three phases are\nused to detect pulses on the fingertip that include pulse detection, signal\nextraction, and pulse amplification. Qualitative and quantitative performance\nevaluation of the device on real signals shows accuracy in heart rate\nestimation, even under intense of physical activity. We compared the\nperformance of HRM device with Electrocardiogram reports and manual pulse\nmeasurement of heartbeat of 90 human subjects of different ages. The results\nshowed that the error rate of the device is negligible.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.2475v1"
    },
    {
        "title": "Hardware Acceleration of the Gipps Model for Real-Time Traffic\n  Simulation",
        "authors": [
            "Salim Farah",
            "Magdy Bayoumi"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Traffic simulation software is becoming increasingly popular as more cities\nworldwide use it to better manage their crowded traffic networks. An important\nrequirement for such software is the ability to produce accurate results in\nreal time, requiring great computation resources. This work proposes an\nASIC-based hardware accelerated approach for the AIMSUN traffic simulator,\ntaking advantage of repetitive tasks in the algorithm. Different system\nconfigurations using this accelerator are also discussed. Compared with the\ntraditional software simulator, it has been found to improve the performance by\nas much as 9x when using a single processing element approach, or more\ndepending on the chosen hardware configuration.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.3507v1"
    },
    {
        "title": "Graphical Methods for Defense Against False-data Injection Attacks on\n  Power System State Estimation",
        "authors": [
            "Suzhi Bi",
            "Ying Jun",
            " Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The normal operation of power system relies on accurate state estimation that\nfaithfully reflects the physical aspects of the electrical power grids.\nHowever, recent research shows that carefully synthesized false-data injection\nattacks can bypass the security system and introduce arbitrary errors to state\nestimates. In this paper, we use graphical methods to study defending\nmechanisms against false-data injection attacks on power system state\nestimation. By securing carefully selected meter measurements, no false data\ninjection attack can be launched to compromise any set of state variables. We\ncharacterize the optimal protection problem, which protects the state variables\nwith minimum number of measurements, as a variant Steiner tree problem in a\ngraph. Based on the graphical characterization, we propose both exact and\nreduced-complexity approximation algorithms. In particular, we show that the\nproposed tree-pruning based approximation algorithm significantly reduces\ncomputational complexity, while yielding negligible performance degradation\ncompared with the optimal algorithms. The advantageous performance of the\nproposed defending mechanisms is verified in IEEE standard power system\ntestcases.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.4151v4"
    },
    {
        "title": "Marketplaces for Energy Demand-Side Management based on Future-Internet\n  Technology",
        "authors": [
            "Luigi Briguglio",
            "Frank Eichinger",
            "Massimiliano Nigrelli",
            "Javier Lucio Ruiz-Andino"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Renewable energies become more important, and they contribute to the EU's\ngoals for greenhouse-gas reduction. However, their fluctuating nature calls for\ndemand-side-management techniques, which balance energy generation and\nconsumption. Such techniques are currently not broadly deployed. This paper\ndescribes the latest results from the FINSENY project on how Future-Internet\nenablers and market mechanisms can be used to realise such systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5346v1"
    },
    {
        "title": "Patterns to analyze requirements of a Decisional Information System",
        "authors": [
            "Sabri Aziza",
            "Kjiri Laila"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The domain of analysis and conception of Decisional Information System (DIS)\nis, highly, applying new techniques and methods to succeed the process of the\ndecision and minimizing the time of conception. Our objective in this paper is\nto define a group of patterns to ensure a systematic reuse of our approach to\nanalyse a DIS s business requirements. We seek, through this work, to guide the\ndiscovery of an organizations business requirements, expressed as goals by\nintroducing the notion of context, to promote good processes design for a DIS,\nto capitalize the process and models proposed in our approach and systematize\nreuse steps of this approach to analyze similar projects or adapt them as\nneeded. The patterns are at the same time the process s patterns and product s\npatterns as they capitalize models and their associated processes. These\npatterns are represented according to the PSIGMA formalism.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5389v1"
    },
    {
        "title": "Policy Aware Geospatial Data",
        "authors": [
            "Puneet Kishor",
            "Oshani Seneviratne",
            "Noah Giansiracusa"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Digital Rights Management (DRM) prevents end-users from using content in a\nmanner inconsistent with its creator's wishes. The license describing these\nuse-conditions typically accompanies the content as its metadata. A resulting\nproblem is that the license and the content can get separated and lose track of\neach other. The best metadata have two distinct qualities--they are created\nautomatically without user intervention, and they are embedded within the data\nthat they describe. If licenses are also created and transported this way, data\nwill always have licenses, and the licenses will be readily examinable. When\ntwo or more datasets are combined, a new dataset, and with it a new license,\nare created. This new license is a function of the licenses of the component\ndatasets and any additional conditions that the person combining the datasets\nmight want to impose. Following the notion of a data-purpose algebra, we model\nthis phenomenon by interpreting the transfer and conjunction of data as\ninducing an algebraic operation on the corresponding licenses. When a dataset\npasses from one source to the next its license is transformed in a\ndeterministic way, and similarly when datasets are combined the associated\nlicenses are combined in a non-trivial algebraic manner. Modern,\ncomputer-savvy, licensing regimes such as Creative Commons allow writing the\nlicense in a special kind of language called Creative Commons Rights Expression\nLanguage (ccREL). ccREL allows creating and embedding the license using RDFa\nutilizing XHTML. This is preferred over DRM which includes the rights in a\nbinary file completely opaque to nearly all users. The colocation of metadata\nwith human-visible XHTML makes the license more transparent. In this paper we\ndescribe a methodology for creating and embedding licenses in geographic data\nutilizing ccREL, and programmatically examining embedded licenses in component\ndata...\n",
        "pdf_link": "http://arxiv.org/pdf/1304.5755v1"
    },
    {
        "title": "Priority Based Pre-emptive Task Scheduling for Android Operating System",
        "authors": [
            "Deepali Kayande",
            "Urmila Shrawankar"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Android mobile operating system which is based on Linux Kernel 2.6, has open\nsource license and adaptability to user driven applications. As all other\noperating systems it has all the basic features like process scheduling, memory\nmanagement, process management etc associated with it. Any mobile platform\nworks smoothly when the process scheduling is performed in a proper way. Ideal\nplatform is that in which no resource conflict occurs. Thus scheduling in every\nmanner is essential for the operating system to adapt itself with the\nrequirement of a particular application. In this paper, priority based\npre-emptive task scheduling is proposed for the SMS application. The idea is to\ndefine High priority to required contacts, for ex. Contact numbers of parents\nor teachers will be given High priority. If in case, any SMS from these High\npriority contacts is received, the application would flash the SMS on the\nactive screen and redirect this High priority SMS to the Priority Inbox.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.7889v1"
    },
    {
        "title": "Object Oriented Model for Evaluation of On-Chip Networks",
        "authors": [
            "Sheraz Anjum",
            "Ehsan Ullah Munir",
            "Waqas Anwar",
            "Nadeem Javaid"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The Network on Chip (NoC) paradigm is rapidly replacing bus based System on\nChip (SoC) designs due to their inherent disadvantages such as non-scalability,\nsaturation and congestion. Currently very few tools are available for the\nsimulation and evaluation of on-chip architectures. This study proposes a\ngeneric object oriented model for performance evaluation of on-chip\ninterconnect architectures and algorithms. The generic nature of the proposed\nmodel can help the researchers in evaluation of any kind of on-chip switching\nnetworks. The model was applied on 2D-Mesh and 2D-Diagonal-Mesh on-chip\nswitching networks for verification and selection of best out of both the\nanalyzed architectures. The results show the superiority of 2D-Diagonal-Mesh\nover 2D-Mesh in terms of average packet delay.\n",
        "pdf_link": "http://arxiv.org/pdf/1304.8006v1"
    },
    {
        "title": "A Compact Dual Band Dielectric Resonator Antenna For Wireless\n  Applications",
        "authors": [
            "H. Raggad",
            "M. Latrach",
            "A. Gharsallah",
            "T. Razban"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper presents the design of a dual band rectangular Dielectric\nResonator Antenna (DRA) coupled to narrow slot aperture that is fed by\nmicrostrip line. The fundamental TE111 mode and higher-order TE113 mode are\nexcited with their resonant frequencies respectively. These frequencies can be\ncontrolled by changing the DRA dimensions. A dielectric resonator with high\npermittivity is used to miniaturize the global structure. The proposed antenna\nis designed to have dual band operation suitable for both DCS (1710 - 1880 MHz)\nand WLAN (2400 - 2484 MHz) applications. The return loss, radiation pattern and\ngain of the proposed antenna are evaluated. Reasonable agreement between\nsimulation and experimental results is obtained.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.1335v1"
    },
    {
        "title": "Stable equilibrium study cascaded one bit sigma-delta modulator",
        "authors": [
            "Evgenii Khokhryakov"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In the paper defines a boundary of stability zone for sigma-delta modulator.\nThe boundary depends from inner sigma-delta modulator coefficients. For\ndesigning purposes such result could be used to find or compare some\nappropriate schemes with each other. It is proved some statements and showed\nthat boundary could be found theoretically for any order of sigma-delta\nmodulator, but practically till 5-th order.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.1702v1"
    },
    {
        "title": "An Optimized Design of Reversible Sequential Digital Circuits",
        "authors": [
            "Pradeep Singla",
            "Aakash Gupta",
            "Ashutosh Bhardwaj",
            "Pulkit Basia"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In the today's era, reversible logics are the promising technology for the\ndesigning of low power digital logic system having major application in the\nfield of nanotechnology, quantum computation, DNA and other low power digital\ncircuits. Reversible logics provide zero power dissipation (Ideally) in the\ndigital operations. There are numbers of circuit designed by the reversible\nlogics and sequential circuits have their own importance in the digital\nsystems. In this paper authors provides a optimized approach and optimized\ndesign for the sequential circuit (counter as an example) by using the MUX gate\n(a reversible gate) which provides the better results against the previous\ndesigns discussed in the literature. The proposed design has lower quantum\ncost, garbage output, constant input and total number of logical calculations\nperforming by the design.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.2556v1"
    },
    {
        "title": "Valuating Surface Surveillance Technology for Collaborative\n  Multiple-Spot Control of Airport Departure Operations",
        "authors": [
            "Pierrick Burgain",
            "Sang Hyun Kim",
            "Eric Feron"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Airport departure operations are a source of airline delays and passenger\nfrustration. Excessive surface traffic is a cause of increased controller and\npilot workload. It is also a source of increased emissions and delays, and does\nnot yield improved runway throughput. Leveraging the extensive past research on\nairport departure management, this paper explores the environmental and safety\nbenefits that improved surveillance technologies can bring in the context of\ngate- or spot-release strategies. The paper shows that improved surveillance\ntechnologies can yield 4% to 6% reduction of aircraft on taxiway, and therefore\nemissions, in addition to the savings currently observed by implementing\nthreshold starategies under evaluation at Boston Logan Airport and other busy\nairports during congested periods. These calculated benefits contrast sharply\nwith our previous work, which relied on simplified airport ramp areas with a\nsingle departure spot, and where fewer environmental and economic benefits of\nadvanced surface surveillance systems could be established. Our work is\nillustrated by its application to New-York LaGuardia and Seattle Tacoma\nairports.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.3426v1"
    },
    {
        "title": "Impact of Gate Assignment on Gate-Holding Departure Control Strategies",
        "authors": [
            "Sang Hyun Kim",
            "Eric Feron"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Gate holding reduces congestion by reducing the number of aircraft present on\nthe airport surface at any time, while not starving the runway. Because some\ndeparting flights are held at gates, there is a possibility that arriving\nflights cannot access the gates and have to wait until the gates are cleared.\nThis is called a gate conflict. Robust gate assignment is an assignment that\nminimizes gate conflicts by assigning gates to aircraft to maximize the time\ngap between two consecutive flights at the same gate; it makes gate assignment\nrobust, but passengers may walk longer to transfer flights. In order to\nsimulate the airport departure process, a queuing model is introduced. The\nmodel is calibrated and validated with actual data from New York La Guardia\nAirport (LGA) and a U.S. hub airport. Then, the model simulates the airport\ndeparture process with the current gate assignment and a robust gate assignment\nto assess the impact of gate assignment on gate-holding departure control. The\nresults show that the robust gate assignment reduces the number of gate\nconflicts caused by gate holding compared to the current gate assignment.\nTherefore, robust gate assignment can be combined with gate-holding departure\ncontrol to improve operations at congested airports with limited gate\nresources.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.3429v1"
    },
    {
        "title": "Roughening Methods to Prevent Sample Impoverishment in the Particle PHD\n  Filter",
        "authors": [
            "Tiancheng Li",
            "Tariq P. Sattar",
            "Qing Han",
            "Shudong Sun"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Mahler's PHD (Probability Hypothesis Density) filter and its particle\nimplementation (as called the particle PHD filter) have gained popularity to\nsolve general MTT (Multi-target Tracking) problems. However, the resampling\nprocedure used in the particle PHD filter can cause sample impoverishment. To\nrejuvenate the diversity of particles, two easy-to-implement roughening\napproaches are presented to enhance the particle PHD filter. One termed as\n\"separate-roughening\" is inspired by Gordon's roughening procedure that is\napplied on the resampled particles. Another termed as \"direct-roughening\" is\nimplemented by increasing the simulation noise of the state propagation of\nparticles. Four proposals are presented to customize the roughening approach.\nSimulations are presented showing that the roughening approach can benefit the\nparticle PHD filter, especially when the sample size is small.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.3875v1"
    },
    {
        "title": "A Comparative study of Analog and digital Controller On DC/DC Buck-Boost\n  Converter Four Switch for Mobile Device Applications",
        "authors": [
            "Benlafkih Abdessamad",
            "Krit Salah-ddine",
            "Chafik Elidrissi Mohamed"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper presents comparative performance between Analog and digital\ncontroller on DC/DC buck-boost converter four switch. The design of power\nelectronic converter circuit with the use of closed loop scheme needs modeling\nand then simulating the converter using the modeled equations. This can easily\nbe done with the help of state equations and MATLAB/SIMULINK as a tool for\nsimulation of those state equations. DC/DC Buckboost converter in this study is\noperated in buck (step-down) and boost (step-up) modes.\n",
        "pdf_link": "http://arxiv.org/pdf/1306.5180v1"
    },
    {
        "title": "On Two Conversion Methods of Decimal-to-Binary",
        "authors": [
            "Zhengjun Cao"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Decimal-to-binary conversion is important to modern binary computers. The\nclassical method to solve this problem is based on division operation. In this\npaper, we investigate a decimal-to-binary conversion method based on addition\noperation. The method is very easily implemented by software. The cost analysis\nshows that the latter is more preferable than the classical method. Thus the\ncurrent Input/Output translation hardware to convert between the internal digit\npairs and the external standard BCD codes can be reasonably removed.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.0555v1"
    },
    {
        "title": "Introduction to Management Information system",
        "authors": [
            "Umakant Mishra"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A Management Information System (MIS) is a systematic organization and\npresentation of information that is generally required by the management of an\norganization for taking better decisions for the organization. The MIS data may\nbe derived from various units of the organization or from other sources.\nHowever it is very difficult to say the exact structure of MIS as the structure\nand goals of different types of organizations are different. Hence both the\ndata and structure of MIS is dependent on the type of organization and often\ncustomized to the specific requirement of the management.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.1797v2"
    },
    {
        "title": "A New Mattress Development Based on Pressure Sensors for Body-contouring\n  Uniform Support",
        "authors": [
            "Hsiu-Chen Hsu",
            "Rong-Chin Lo"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  For getting good sleep quality, an improved approach of new mattress\ndevelopment based on the pressure sensors for body-contouring uniform support\nis proposed in this paper. This method solved the problems of innerspring\nmattresses that cannot allow body-contouring uniform support, and foam\nmattresses that cannot provide everybody equal comfort from the same mattress.\nBy the buried pressure sensor array and actuator array in foam layer of a\nmattress, both are connected to a controller to generate the pressure\ndistribution mapping of a human body on the mattress, then from the data of\nthis mapping, some of the actuators are driven up or down by the controller to\ngenerate a body-contouring uniform support. By the aid of mathematical\nmorphology algorithms, user can also choose a different support mode by another\nwireless controller with touch-screen to accommodate personal favorite firmness\nof the mattress and to take his tensed mood and pressure off with good sleep\nuntil daylight. Moreover, some other homecare functions, such as temperature\nmeasurement, sleep on posture correction and fall down prevention, can approach\nby additional hardware and software as user requirement in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.2196v1"
    },
    {
        "title": "Services in Android can Share Your Personal Information in Background",
        "authors": [
            "Manoj Kumar",
            "Sheshendra Rathi"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Mobile phones have traveled a very long journey in a very short span of time\nsince its inception in 1973.This wonderful toy of 20th century has started\nplaying significant role in daily life.More than 5 billion mobile users are\nthere around the world and almost 90 percent of the entire earth is under the\nmobile coverage now.These days smart phones are equipped with numerous\nfeatures,faster processors and high storage capacity.Android is a latest trend\nin this series whose popularity is growing by leaps and bounds.Android has a\nnumber of components which helps Application developers to embed distinguish\nfeatures in applications.This paper explains how the Service component of\nAndroid can share your personal information to others without users\ninteraction.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.4486v1"
    },
    {
        "title": "How to implement Marketing 2.0 Successfully",
        "authors": [
            "Abdulrahman Aldhaheri",
            "Christian Bach"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The purpose of this research is to develop a model that would close the gap\nbetween marketing plans and strategies from one side and the advanced online\ncollaboration applications platforms known as WEB 2.0 in order to implement\nmarketing 2.0 smoothly without disrupting the working environment. We started\nby examining published articles related to marketing, Web 2.0, Customer\nRelationship Management Systems, CRM, and social media in a step to conduct an\nextensive review of the available literature. Then, we presented critique of\nthe articles we have examined. After that, we have been able to develop the\nmodel we are proposing in this research. As this paper shows, the proposed\nmodel will help in transforming marketing plans and strategies from its\ntraditional approach into, what we would like to call, marketing 2.0 approach\nsmoothly. There are some unavoidable limitations due to the given time and\nscope constrains. The factors included in the proposed model does not cover\nevery related aspect, however, they cover the most important ones.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.4894v1"
    },
    {
        "title": "Numerical Analysis of Gate Conflict Duration and Passenger Transit Time\n  in Airport",
        "authors": [
            "Sang Hyun Kim",
            "Eric Feron"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Robustness is as important as efficiency in air transportation. All\ncomponents in the air traffic system are connected to form an interactive\nnetwork. So, a disturbance that occurs in one component, for example, a severe\ndelay at an airport, can influence the entire network. Delays are easily\npropagated between flights through gates, but the propagation can be reduced if\ngate assignments are robust against stochastic delays. In this paper, we\nanalyze gate delays and suggest an approach that involves assigning gates while\nmaking them robust against stochastic delays. We extract an example flight\nschedule from data source and generate schedules with increased traffic to\nanalyze how the compact flight schedules impact the robustness of gate\nassignment. Simulation results show that our approach improves the robustness\nof gate assignment. Particularly, the robust gate assignment reduces average\nduration of gate conflicts by 96.3% and the number of gate conflicts by 96.7%\ncompared to the baseline assignment. However, the robust gate assignment\nresults in longer transit time for passengers, and a trade-off between the\nrobustness of gate assignment and passenger transit time is presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.6217v1"
    },
    {
        "title": "Implementation and optimization of Wavelet modulation in Additive\n  Gaussian channels",
        "authors": [
            "Rad Niazadeh",
            "Sahar Nassirpour",
            "Mohammad B. Shamsollahi"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper, we investigate the implementation of wavelet modulation (WM)\nin a digital communication system and propose novel methods to improve its\nperformance. We will put particular focus on the structure of an optimal\ndetector in AWGN channels and address two main methods for inserting the\nsamples of the message signal in different frequency layers. Finally, computer\nbased algorithms are described in order to implement and optimize receivers and\ntransmitters.\n",
        "pdf_link": "http://arxiv.org/pdf/1308.6251v1"
    },
    {
        "title": "Multiparameter Monitoring and Fault Indication Using Inductive Power\n  Transfer System",
        "authors": [
            "K. P. Shaji",
            "I. Alsheba",
            "Y. A. Syed Khadar",
            "S. Kannan"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The paper aims at demonstrating communication capabilities of IPT. For this\ndata communication is performed between two modules using the concept of IPT.\nIPT was deemed to be the best solution to the system houses a multi parameter\nacquisition module such as temperature, speed, voltage, current and data\ntransfer from the motor. The receiver side is another microcontroller coupled\nto an inductive coil that gets the data and displays in the LCD. A brief\nbackground to IPT Inductive Power Transfer technology and its applications is\ngiven and the design criteria for the paper are defined in detail. To be\naccurate, IPT data communication helps to reduce unnecessary wire connections\nand data is transmitted without any touch. Further the paper can be enhanced by\nlooking for fault analysis inside the motor. This can be done by analyzing\nvarious parameters of the motor. A novel two-way IPT communication system was\ndesigned, which worked on the concept of pulsing the system on and off to send\ndata serially. The paper involves transmission of data through inductive flux\nwithout any contact between the two modules. Further as no frequency tunings or\nany calibration is required between different modules a single system can be\nused with multiple clients. This reduces a lot of hazards such as interference\nwith other modules and RF transmitters in the vicinity.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.0589v1"
    },
    {
        "title": "Survey of Insurance Fraud Detection Using Data Mining Techniques",
        "authors": [
            "H. Lookman Sithic",
            "T. Balasubramanian"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  With an increase in financial accounting fraud in the current economic\nscenario experienced, financial accounting fraud detection has become an\nemerging topics of great importance for academics, research and industries.\nFinancial fraud is a deliberate act that is contrary to law, rule or policy\nwith intent to obtain unauthorized financial benefit and intentional\nmisstatements or omission of amounts by deceiving users of financial\nstatements, especially investors and creditors. Data mining techniques are\nproviding great aid in financial accounting fraud detection, since dealing with\nthe large data volumes and complexities of financial data are big challenges\nfor forensic accounting. Financial fraud can be classified into four: bank\nfraud, insurance fraud, securities and commodities fraud. Fraud is nothing but\nwrongful or criminal trick planned to result in financial or personal gains.\nThis paper describes the more details on insurance sector related frauds and\nrelated solutions. In finance, insurance sector is doing important role and\nalso it is unavoidable sector of every human being.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.0806v1"
    },
    {
        "title": "Design and Implementation of Wireless Energy Meter System for Monitoring\n  the Single Phase Supply",
        "authors": [
            "Prashanth B. U. V"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Wireless energy meter is a system developed to serve as a basic single-phase\nenergy meter with advanced functionalities such as Peak hour setting, Peak load\nsetting Wireless reading transmission; further the system eliminates the role\nof a Meter Reader.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.1832v1"
    },
    {
        "title": "DyPS: Dynamic Processor Switching for Energy-Aware Video Decoding on\n  Multi-core SoCs",
        "authors": [
            "Yahia Benmoussa",
            "Jalil Boukhobza",
            "Eric Senn",
            "Djamel Benazzouz",
            "Yassine Hadjadj-Aoul"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In addition to General Purpose Processors (GPP), Multicore SoCs equipping\nmodern mobile devices contain specialized Digital Signal Processor designed\nwith the aim to provide better performance and low energy consumption\nproperties. However, the experimental measurements we have achieved revealed\nthat system overhead, in case of DSP video decoding, causes drastic\nperformances drop and energy efficiency as compared to the GPP decoding. This\npaper describes DyPS, a new approach for energy-aware processor switching (GPP\nor DSP) according to the video quality . We show the pertinence of our solution\nin the context of adaptive video decoding and describe an implementation on an\nembedded Linux operating system with the help of the GStreamer framework. A\nsimple case study showed that DyPS achieves 30% energy saving while sustaining\nthe decoding performance\n",
        "pdf_link": "http://arxiv.org/pdf/1309.2387v1"
    },
    {
        "title": "Analytical and experimental stability investigation of a\n  hardware-in-the-loop satellite docking simulator",
        "authors": [
            "M. Zebenaya",
            "T. Boge",
            "R. Krenn",
            "D. Choukroun"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The European Proximity Operation Simulator (EPOS) of the DLR-German Aerospace\nCenter is a robotics-based simulator that aims at validating and verifying a\nsatellite docking phase. The generic concept features a robotics tracking\nsystem working in closed loop with a force/torque feedback signal. Inherent\ndelays in the tracking system combined with typical high stiffness at contact\nchallenge the stability of the closed-loop system. The proposed concept of\noperations is hybrid: the feedback signal is a superposition of a measured\nvalue and of a virtual value that can be tuned in order to guarantee a desired\nbehavior. This paper is concerned with an analytical study of the system's\nclosed-loop stability, and with an experimental validation of the hybrid\nconcept of operations in one dimension (1D). The robotics simulator is modeled\nas a second-order loop-delay system and closed-form expressions for the\ncritical delay and associated frequency are derived as a function of the\nsatellites' mass and the contact dynamics stiffness and damping parameters. A\nnumerical illustration sheds light on the impact of the parameters on the\nstability regions. A first-order Pade approximation provides additional means\nof stability investigation. Experiments were performed and tests results are\ndescribed for varying values of the mass and the damping coefficients. The\nempirical determination of instability is based on the coefficient of\nrestitution and on the observed energy. There is a very good agreement between\nthe critical damping values predicted by the analysis and observed during the\ntests...\n",
        "pdf_link": "http://arxiv.org/pdf/1309.3512v1"
    },
    {
        "title": "Inadmissible Class of Boolean Functions under Stuck-at Faults",
        "authors": [
            "Debesh K. Das",
            "Debabani Chowdhury",
            "Bhargab B. Bhattacharya",
            "Tsutomu Sasao"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Many underlying structural and functional factors that determine the fault\nbehavior of a combinational network, are not yet fully understood. In this\npaper, we show that there exists a large class of Boolean functions, called\nroot functions, which can never appear as faulty response in irredundant\ntwo-level circuits even when any arbitrary multiple stuck-at faults are\ninjected. Conversely, we show that any other Boolean function can appear as a\nfaulty response from an irredundant realization of some root function under\ncertain stuck-at faults. We characterize this new class of functions and show\nthat for n variables, their number is exactly equal to the number of\nindependent dominating sets (Harary and Livingston, Appl. Math. Lett., 1993) in\na Boolean n-cube. We report some bounds and enumerate the total number of root\nfunctions up to 6 variables. Finally, we point out several open problems and\npossible applications of root functions in logic design and testing.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.3993v1"
    },
    {
        "title": "A Simple Solution To The Uncertain Delay Problem in USRP Based SDR-Radar\n  Systems",
        "authors": [
            "Andriyan Bayu Suksmono"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We propose a simple solution to the uncertain delay problem in USRP\n(Universal Software Radio Peripheral)-based SDR (Software-Defined Radio)-radar\nsystems. Instead of time-synchronization as employed in (pseudo-) passive radar\nconfigurations, which require at least two synchronized receivers, we use\ndirect reception signal in a single receiver system as a reference to the exact\nlocation of the target echoes. After finding the reference position, reordering\nof the echoes is conducted by circular shift so that the reference moved to the\norigin. We demonstrate the effectiveness of the proposed method by simulating\nthe problem on Matlab and implementing a 128 length random code radar on a\nUSRP. The random code is constructed from zero padded Barker sequence product.\nExperiments on measuring multiple echoes of the targets at precise range bins\nconfirm the applicability of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.4843v1"
    },
    {
        "title": "Context-dependent Trust Decisions with Subjective Logic",
        "authors": [
            "Federico Cerutti",
            "Alice Toniolo",
            "Nir Oren",
            "Timothy J. Norman"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A decision procedure implemented over a computational trust mechanism aims to\nallow for decisions to be made regarding whether some entity or information\nshould be trusted. As recognised in the literature, trust is contextual, and we\ndescribe how such a context often translates into a confidence level which\nshould be used to modify an underlying trust value. J{\\o}sang's Subjective\nLogic has long been used in the trust domain, and we show that its operators\nare insufficient to address this problem. We therefore provide a\ndecision-making approach about trust which also considers the notion of\nconfidence (based on context) through the introduction of a new operator. In\nparticular, we introduce general requirements that must be respected when\ncombining trustworthiness and confidence degree, and demonstrate the soundness\nof our new operator with respect to these properties.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.4994v1"
    },
    {
        "title": "A Calibration Algorithm for Microelectromechanical Systems\n  Accelerometers in Inertial Navigation Sensors",
        "authors": [
            "Svetoslav Nakov",
            "Tihomir Ivanov"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In the present work we develop an algorithm for calibrating MEMS sensors,\nwhich accounts for the nonorthogonality of the accelerometers' axis, as well as\nfor the constant bias and scaling errors. We derive an explicit formula for\ncomputing the calibrated acceleration, given data from the sensors. We also\nstudy the error, that is caused by the nonorthogonality of the axis.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5075v1"
    },
    {
        "title": "Formal Contexts, Formal Concept Analysis, and Galois Connections",
        "authors": [
            "Jeffrey T. Denniston",
            "Austin Melton",
            "Stephen E. Rodabaugh"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Formal concept analysis (FCA) is built on a special type of Galois\nconnections called polarities. We present new results in formal concept\nanalysis and in Galois connections by presenting new Galois connection results\nand then applying these to formal concept analysis. We also approach FCA from\nthe perspective of collections of formal contexts. Usually, when doing FCA, a\nformal context is fixed. We are interested in comparing formal contexts and\nasking what criteria should be used when determining when one formal context is\nbetter than another formal context. Interestingly, we address this issue by\nstudying sets of polarities.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5134v1"
    },
    {
        "title": "Human Resource Management System",
        "authors": [
            "A. S. Syed Navaz",
            "A. S. Syed Fiaz",
            "C. Prabhadevi",
            "V. Sangeetha",
            "S. Gopalakrishnan"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The paper titled HUMAN RESOURCE MANAGEMENT SYSTEM is basically concerned with\nmanaging the Administrator of HUMAN RESOURCE Department in a company. A Human\nResource Management System, refers to the systems and processes at the\nintersection between human resource management and information technology. It\nmerges HRM as a discipline and in particular its basic HR activities and\nprocesses with the information technology field, whereas the programming of\ndata processing systems evolved into standardized routines and packages of\nenterprise resource planning software. The main objective of this paper is to\nreduce the effort of Administrator to keep the daily events such as attendance,\nprojects, works, appointments, etc. This paper deals with the process of\nidentifying the employees, recording their attendance hourly and calculating\ntheir effective payable hours or days. This paper should maintain the records\nof each and every employee and their time spend in to company, which can be\nused for performance appraisal. Based on that transfer, removal, promotion can\nbe done.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5351v1"
    },
    {
        "title": "Evolution of choices over time: The U.S. Presidential election 2012 and\n  the NY City Mayoral Election, 2013",
        "authors": [
            "Mukkai Krishnamoorthy",
            "Wesley Miller",
            "Raju Krishnamoorthy"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We conducted surveys before and after the 2012 U.S. Presidential election and\nprior to the NY City Mayoral election in 2013. The surveys were done using\nAmazon Turk. This poster describes the results of our analysis of the surveys\nand predicts the winner of the NY City Mayoral Election.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.1118v2"
    },
    {
        "title": "Optical Disk with Blu-Ray Technology",
        "authors": [
            "T. Ravi Kumar",
            "R. V. Krishnaiah"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Blu-ray is the name of a next-generation optical disc format jointly\ndeveloped by the Blu-ray Disc Association a group of the world's leading\nconsumer electronics, personal computer and media manufacturers. The format was\ndeveloped to enable recording, rewriting and playback of high-definition video,\nas well as storing large amounts of data. This extra capacity combined with the\nuse of advanced video and audio codec will offer consumers an unprecedented HD\nexperience. While current optical disc technologies such as DVD and DVDRAM rely\non a red laser to read and write data, the new format uses a blue-violet laser\ninstead, hence the name Blu-ray. Blu ray also promises some added security,\nmaking ways for copyright protections. Blu-ray discs can have a unique ID\nwritten on them to have copyright protection inside the recorded streams. Blu\n.ray disc takes the DVD technology one step further, just by using a laser with\na nice color.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.1551v1"
    },
    {
        "title": "Emergency and Normal Navigation in Confined Spaces",
        "authors": [
            "Huibo Bi"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Emergency navigation algorithms direct evacuees to exits when disastrous\nevents such as fire take place. Due to the spread of hazards, latency in\ninformation updating and unstable flows of civilians, emergency evacuation is\nabsolutely a complex transshipment problem involving numerous sources and\nmultiple destinations. Previous algorithms which commonly need either a full\ngraph search or a convergence process suffer from high computational and\ncommunication overheads. This research report surveys the current emergency\nnavigation algorithms and adapts the concept of Cognitive Packet Network (CPN)\nto the context of emergency evacuation. By using random neural networks, the\nCPN based algorithm can explore optimal routes rapidly and adaptively in a\nhighly dynamic emergency environment with low expense. Simultaneously, in\nemergency situations there are typically different categories of evacuees such\nas people of different age groups. However, current algorithms only consider\n\"normal\" evacuees and do not meet the specific requirements of diverse\nevacuees. Our algorithms make use of the flexibility of CPN which can operate\nwith different user-defined goals to customize appropriate paths for each\ncategory. The CPN algorithm is simulated in a graph based discrete-event\nsimulator and Dijkstra's shortest path algorithm is taken as reference. The\nresults show that the CPN algorithm reaches the performance of ideal\npath-finding algorithm and quality of service is improved by using specific\ngoal functions for diverse categories of evacuees. Finally, we present a future\nplan for further research.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.2886v1"
    },
    {
        "title": "Implementation of the Cluster Based Tunable Sleep Transistor Cell Power\n  Gating Technique for a 4x4 Multiplier Circuit",
        "authors": [
            "Dipankar Saha",
            "Subhramita Basak",
            "Sagar Mukherjee",
            "Sayan Chatterjee",
            "C. K. Sarkar"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A modular, programmable, and high performance Power Gating strategy, called\ncluster based tunable sleep transistor cell Power Gating, has been introduced\nin the present paper with a few modifications. Furthermore, a detailed\ncomparison of its performance with some of the other conventional Power Gating\nschemes; such as Cluster Based Sleep Transistor Design (CBSTD), Distributed\nSleep Transistor Network (DSTN) etc.; has also been presented here. Considering\nthe constraints of power consumption, performance, and the area overhead, while\ndoing the actual implementation of any Power Gating scheme, it becomes\nimportant to deal with the various design issues like the proper sizing of the\nsleep transistors (STs), controlling the voltage drop (IR drop) across the STs,\nand obviously maintaining a desired performance with lower amount of delay\ndegradation. With this notion, we tried to find out an efficient Power Gating\nstrategy which can reduce the overall power consumption of any CMOS circuit by\nvirtue of reducing the standby mode leakage current. Taking the different\nperformance parameters into account, for an example circuit, which is actually\nthe conventional 4x4 multiplier design, we found that the modified tunable\nsleep transistor cell Power Gating gives very much promising results. The\nreported architecture of the 4x4 multiplier with the tunable sleep transistor\ncell Power Gating, is designed using 45 nm technology and it consumes\n1.3638x10-5 Watt of Average Power while being operated with the nominal case of\nthe bit configuration word, that is, 1000. ...........\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3203v1"
    },
    {
        "title": "Value-chain oriented identification of indicators to establish a\n  comprehensive process improvement framework",
        "authors": [
            "Ute Riemann"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The process development and optimization potential needs to be driven by the\nindividial coporate value chain. The identification of this specific value\nchain and the related indicators is essential to limit the scope of any\nanalysis and optimization to the core business The process framework consisting\nof clearly defined value chain, the related processes and the corresponding\nindicators is a pre-requisite for a meaningful and efficient process analysis\nand continuous process optimization.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3230v1"
    },
    {
        "title": "Optimal Energy Consumption Model for Smart Grid Households with Energy\n  Storage",
        "authors": [
            "Jayaprakash Rajasekharan",
            "Visa Koivunen"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper, we propose to model the energy consumption of smart grid\nhouseholds with energy storage systems as an intertemporal trading economy.\nIntertemporal trade refers to transaction of goods across time when an agent,\nat any time, is faced with the option of consuming or saving with the aim of\nusing the savings in the future or spending the savings from the past. Smart\nhomes define optimal consumption as either balancing/leveling consumption such\nthat the utility company is presented with a uniform demand or as minimizing\nconsumption costs by storing energy during off-peak time periods when prices\nare lower and use the stored energy during peak time periods when prices are\nhigher. Due to the varying nature of energy requirements of household and\nmarket energy prices over different time periods in a day, households face a\ntrade-off between consuming to meet their current energy requirements and/or\nstoring energy for future consumption and/or spending energy stored in the\npast. These trade-offs or consumption preferences of the household are modeled\nas utility functions using consumer theory. We introduce two different utility\nfunctions, one for cost minimization and another for consumption\nbalancing/leveling, that are maximized subject to respective budget,\nconsumption, storage and savings constraints to solve for the optimum\nconsumption profile. The optimization problem of a household with energy\nstorage is formulated as a geometric program for consumption\nbalancing/leveling, while cost minimization is formulated as a linear\nprogramming problem. Simulation results show that the proposed model achieves\nextremely low peak to average ratio in the consumption balancing/leveling\nscheme with about 8% reduction in consumption costs and the least possible\namount for electricity bill with about 12% reduction in consumption costs in\nthe cost minimization scheme.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.3424v1"
    },
    {
        "title": "Ear-Phone: A Context-Aware Noise Mapping using Smart Phones",
        "authors": [
            "Rajib Rana",
            "Chun Tung Chou",
            "Nirupama Bulusu",
            "Salil Kanhere",
            "Wen Hu"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A noise map facilitates the monitoring of environmental noise pollution in\nurban areas. However, state-of-the-art techniques for rendering noise maps in\nurban areas are expensive and rarely updated, as they rely on population and\ntraffic models rather than on real data. Smart phone based urban sensing can be\nleveraged to create an open and inexpensive platform for rendering up-to- date\nnoise maps. In this paper, we present the design, implementation and\nperformance evaluation of an end-to-end, context-aware, noise mapping system\ncalled Ear-Phone. Ear-Phone investigates the use of different interpolation and\nregularization methods to address the fundamental problem of recovering the\nnoise map from incomplete and random samples obtained by crowdsourcing data\ncollection. Ear-Phone, implemented on Nokia N95, N97 and HP iPAQ, HTC One\nmobile devices, also addresses the challenge of collecting accurate noise\npollution readings at a mobile device. A major challenge of using smart phones\nas sensors is that even at the same location, the sensor reading may vary\ndepending on the phone orientation and user context (for example, whether the\nuser is carrying the phone in a bag or holding it in her palm). To address this\nproblem, Ear-Phone leverages context-aware sensing. We develop classifiers to\naccurately determine the phone sensing context. Upon context discovery,\nEar-Phone automatically decides whether to sense or not. Ear-phone also\nimplements in-situ calibration which performs simple calibration that can be\ncarried out without any technical skills whatsoever required on the user's\npart. Extensive simulations and outdoor experiments demonstrate that Ear-Phone\nis a feasible platform to assess noise pollution, incurring reasonable system\nresource consumption at mobile devices and providing high reconstruction\naccuracy of the noise map.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.4270v1"
    },
    {
        "title": "Gait Velocity Estimation using time interleaved between Consecutive\n  Passive IR Sensor Activations",
        "authors": [
            "Rajib Rana",
            "Daniel Austin",
            "Peter G. Jacobs",
            "Mohanraj Karunanithi",
            "Jeffrey Kaye"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Gait velocity has been consistently shown to be an important indicator and\npredictor of health status, especially in older adults. It is often assessed\nclinically, but the assessments occur infrequently and do not allow optimal\ndetection of key health changes when they occur. In this paper, we show that\nthe time gap between activations of a pair of Passive Infrared (PIR) motion\nsensors installed in the consecutively visited room pair carry rich latent\ninformation about a person's gait velocity. We name this time gap transition\ntime and show that despite a six second refractory period of the PIR sensors,\ntransition time can be used to obtain an accurate representation of gait\nvelocity.\n  Using a Support Vector Regression (SVR) approach to model the relationship\nbetween transition time and gait velocity, we show that gait velocity can be\nestimated with an average error less than 2.5 cm/sec. This is demonstrated with\ndata collected over a 5 year period from 74 older adults monitored in their own\nhomes.\n  This method is simple and cost effective and has advantages over competing\napproaches such as: obtaining 20 to 100x more gait velocity measurements per\nday and offering the fusion of location-specific information with time stamped\ngait estimates. These advantages allow stable estimates of gait parameters\n(maximum or average speed, variability) at shorter time scales than current\napproaches. This also provides a pervasive in-home method for context-aware\ngait velocity sensing that allows for monitoring of gait trajectories in space\nand time.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.4880v2"
    },
    {
        "title": "Flickers Forecasting In CRT Using Stochastic Analysis",
        "authors": [
            "Adnan Alam Khan",
            "Safeeullah Soomro",
            "Abdul Ghafoor Memon"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Videos are composed of sequence of interrelated frames. There is a minute\ndifference among frames. Flicker is an error which is found in every video. It\nis like a checker box in a video, there are several reasons behind flickers\ngeneration, one of the main reasons is refresh rate of the monitor and second\nreason is number of frames per second in a video. The main objective of this\nstudy is to propose and develop a framework that identifies flicker location\nand minimizes the flickers rate. Analysis shows that flickers can be minimize\nby adjusting the persistence of pixel and higher refresh rate of CRT monitor.\nFurther we have compared different isotopes of phosphorous pixels and generate\nits graphs. This paper highlighted the cause of flicker and its avoidance\n.Statistical research proves that proposed algorithm improves the video quality\nand reduce flickers ratio up to 90%.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.5478v1"
    },
    {
        "title": "Using CamiTK for rapid prototyping of interactive Computer Assisted\n  Medical Intervention applications",
        "authors": [
            "Emmanuel Promayon",
            "Celine Fouard",
            "Mathieu Bailet",
            "Aurelien Deram",
            "Gaelle Fiard",
            "Nikolai Hungr",
            "Vincent Luboz",
            "Yohan Payan",
            "Johan Sarrazin",
            "Nicolas Saubat",
            "Sonia Yuki Selmi",
            "Sandrine Voros",
            "Philippe Cinquin",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Computer Assisted Medical Intervention (CAMI hereafter) is a complex\nmulti-disciplinary field. CAMI research requires the collaboration of experts\nin several fields as diverse as medicine, computer science, mathematics,\ninstrumentation, signal processing, mechanics, modeling, automatics, optics,\netc.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.5497v1"
    },
    {
        "title": "The Energetic Reasoning Checker Revisited",
        "authors": [
            "Alban Derrien",
            "Thierry Petit"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Energetic Reasoning (ER) is a powerful filtering algorithm for the Cumulative\nconstraint. Unfortunately, ER is generally too costly to be used in practice.\nOne reason of its bad behavior is that many intervals are considered as\nrelevant by the checker of ER, although most of them should be ignored. In this\npaper, we provide a sharp characterization that allows to reduce the number of\nintervals by a factor seven. Our experiments show that associating this checker\nwith a Time-Table filtering algorithm leads to promising results.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.5564v1"
    },
    {
        "title": "Multivalued Logic Circuit Design for Binary Logic Interface",
        "authors": [
            "Hitesh Gupta",
            "Dr. S. C. Jain"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Binary logic and devices have been in used since inception with advancement\nand technology and millennium gate design era. The development in binary logic\nhas become tedious and cumbersome. Multivalued logic enables significant more\ninformation to be packed within a single digit. The design and development of\nlogic circuit becomes very compact and easier. Attempts are being made to\nfabricate multivalued logic based devices. Since present devices can be\nimplemented only in binary system,it is necessary to evolve a system that can\nbuilt the circuit in multivalued logic system and convert in binary logic\nsystem. In multivalued logic system logic gates differ in different logic\nsystem, a quaternary has become mature in terms of logic algebra and gates.\nHence logic design based on above system can be done using standard procedure.\nIn this dissertation a logic circuit design entry based on multivalued logic\nsystem has been taken up that can provide the ease of circuit design in\nmultivalued system and output as binary valued circuit. The named \"MVL-DEV\"\noffers editing, storage and conversion into binary facility.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.5697v1"
    },
    {
        "title": "Stacked Patch Antenna With Cross Slot Electronic Band Gap Structure",
        "authors": [
            "N. S Raghava",
            "Asok De",
            "Nitish Kataria",
            "Sarthak Chatterjee"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A cross slotted electronic band gap (EBG) with stacked rectangular patches\nshorted with a shorting pin is proposed in this paper. The study is being done\non how the various parameters are varied by changing the probe feed location.\nThe design is constructed by using stacking of patches, shorting pin and cross\nslotted EBG to form an optimized antenna design with antenna efficiency of\napproximately 99.06%. The radiation patterns are given at 2.586 GHz which can\nbe used for wireless communications.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.6259v1"
    },
    {
        "title": "E-Business Implications for Productivity and Competitiveness",
        "authors": [
            "Pece Mitrevski",
            "Olivera Kostoska",
            "Marjan Angeleski"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Information and Communication Technology (ICT) affects to a great extent the\noutput and productivity growth. Evidence suggests that investment growth in ICT\nhas rapidly accelerated the TFP (total factor productivity) growth within the\nEuropean Union. Such progress is particularly essential for the sectors which\nthemselves produce new technology, but it is dispersing to other sectors, as\nwell. Nevertheless, decrease in ICT investment does not necessarily decline the\nICT contribution to output and productivity growth. These variations come out\nfrom the problems related to the particular phenomenon proper assessment, but\npredominantly from the companies' special requirements, as well as the\nnecessary adjustments of labour employed. Hence, this paper aims at estimating\nthe huge distinction in terms of ICT and TFB contributions to labour\nproductivity growth among some of the European member states, as well as the\nfactors which might stand behind the particular findings.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.7962v1"
    },
    {
        "title": "On the Optimum Energy Efficiency for Flat-fading Channels with\n  Rate-dependent Circuit Power",
        "authors": [
            "Tao Wang",
            "Luc Vandendorpe"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper investigates the optimum energy efficiency (EE) and the\ncorresponding spectral efficiency (SE) for a communication link operating over\na flat-fading channel. The EE is evaluated by the total energy consumption for\ntransmitting per message bit. Three channel cases are considered, namely static\nchannel with channel state information available at transmitter (CSIT),\nfast-varying (FV) channel with channel distribution information available at\ntransmitter (CDIT), and FV channel with CSIT. A general circuit power model is\nconsidered. For all the three channel cases, the tradeoff between the EE and SE\nis studied. It is shown that the EE improves strictly as the SE increases from\n0 to the optimum SE, and then strictly degrades as the SE increases beyond the\noptimum SE. The impact of {\\kappa}, {\\rho} and other system parameters on the\noptimum EE and corresponding SE is investigated to obtain insight.Some of the\nimportant and interesting results for all the channel cases include: (1) when\n{\\kappa} increases the SE corresponding to the optimum EE should keep unchanged\nif {\\phi}(R) = R, but reduced if {\\phi}(R) is strictly convex of R; (2) when\nthe rate-independent circuit power {\\rho} increases, the SE corresponding to\nthe optimum EE has to be increased. A polynomial-complexity algorithm is\ndeveloped with the bisection method to find the optimum SE. The insight is\ncorroborated and the optimum EE for the three cases are compared by simulation\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1310.8342v1"
    },
    {
        "title": "Automatic Airspace Sectorisation: A Survey",
        "authors": [
            "Pierre Flener",
            "Justin Pearson"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Airspace sectorisation provides a partition of a given airspace into sectors,\nsubject to geometric constraints and workload constraints, so that some cost\nmetric is minimised. We survey the algorithmic aspects of methods for automatic\nairspace sectorisation, for an intended readership of experts on air traffic\nmanagement.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.0653v1"
    },
    {
        "title": "SolarStat: Modeling Photovoltaic Sources through Stochastic Markov\n  Processes",
        "authors": [
            "Marco Miozzo",
            "Davide Zordan",
            "Paolo Dini",
            "Michele Rossi"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper, we present a methodology and a tool to derive simple but yet\naccurate stochastic Markov processes for the description of the energy\nscavenged by outdoor solar sources. In particular, we target photovoltaic\npanels with small form factors, as those exploited by embedded communication\ndevices such as wireless sensor nodes or, concerning modern cellular system\ntechnology, by small-cells. Our models are especially useful for the\ntheoretical investigation and the simulation of energetically self-sufficient\ncommunication systems including these devices. The Markov models that we derive\nin this paper are obtained from extensive solar radiation databases, that are\nwidely available online. Basically, from hourly radiance patterns, we derive\nthe corresponding amount of energy (current and voltage) that is accumulated\nover time, and we finally use it to represent the scavenged energy in terms of\nits relevant statistics. Toward this end, two clustering approaches for the raw\nradiance data are described and the resulting Markov models are compared\nagainst the empirical distributions. Our results indicate that Markov models\nwith just two states provide a rough characterization of the real data traces.\nWhile these could be sufficiently accurate for certain applications, slightly\nincreasing the number of states to, e.g., eight, allows the representation of\nthe real energy inflow process with an excellent level of accuracy in terms of\nfirst and second order statistics. Our tool has been developed using Matlab(TM)\nand is available under the GPL license at[1].\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1025v1"
    },
    {
        "title": "Road Accident Prevention Unit: An prototyping approach towards\n  mitigating an omnipresent threat",
        "authors": [
            "Dibakar Barua",
            "Pranshu Jain",
            "Jitesh Gupta",
            "Dhananjay V. Gadre"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  An intelligent multisensor front end based on the ARM Cortex M3. It deduces a\ndriver's configuration, ascertains his ability to drive safely and contacts\nnear ones with location data for urgent disaster mitigation. Prevention\nmeasures are undertaken through external display modules and provision for\nbeing vehicle-powered through external voltage regulated supplies. The proof of\nconcept for this paper is an ALL INDIA THIRD PRIZE WINNER at the Texas\nInstruments Analog Design Contest 2012-13 National Finals and this paper is due\nfor digital publication in IEEE Xplore. All documentation is property of Texas\nInstruments, the Texas Instruments Analog Design Contest 2012-13 and IEEE\nXplore.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1089v1"
    },
    {
        "title": "Unfaithful Glitch Propagation in Existing Binary Circuit Models",
        "authors": [
            "Matthias Fgger",
            "Thomas Nowak",
            "Ulrich Schmid"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We show that no existing continuous-time, binary value-domain model for\ndigital circuits is able to correctly capture glitch propagation. Prominent\nexamples of such models are based on pure delay channels (P), inertial delay\nchannels (I), or the elaborate PID channels proposed by Bellido-D\\'iaz et al.\nWe accomplish our goal by considering the solvability/non-solvability border of\na simple problem called Short-Pulse Filtration (SPF), which is closely related\nto arbitration and synchronization. On one hand, we prove that SPF is solvable\nin bounded time in any such model that provides channels with non-constant\ndelay, like I and PID. This is in opposition to the impossibility of solving\nbounded SPF in real (physical) circuit models. On the other hand, for binary\ncircuit models with constant-delay channels, we prove that SPF cannot be solved\neven in unbounded time; again in opposition to physical circuit models.\nConsequently, indeed none of the binary value-domain models proposed so far\n(and that we are aware of) faithfully captures glitch propagation of real\ncircuits. We finally show that these modeling mismatches do not hold for the\nweaker eventual SPF problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1423v1"
    },
    {
        "title": "Tasks and architecture of documentation subsystem in multi-level\n  modeling environment MARS",
        "authors": [
            "T. V. Gandzha",
            "S. A Panov"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The article describes the automated documentation system designed to generate\nreports on research conducted by computer complex technical objects and systems\nin multi-level modeling environment {\\guillemotleft}MARS{\\guillemotright}. We\ndefined the purposes, tasks and abilities of documentation system and examined\nthe types and structure of documents, and gave an example of its practical use\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1587v1"
    },
    {
        "title": "Une reprsentation en graphe pour l'enseignement de XML",
        "authors": [
            "Emmanuel Desmontils"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Currently, XML is a format widely used. In the context of computer science\nteaching, it is necessary to introduce students to this format and, especially,\nat its eco-system. We have developed a model to support the teaching of XML. We\npropose to represent an XML schema as a graph highlighting the structural\ncharacteristics of the valide documents. We present in this report different\ngraphic elements of the model and the improvements it brings to data modeling\nin XML.---XML est un format actuellement tr\\`es utilis\\'e. Dans le cadre des\nformations en informatique, il est indispensable d'initier les \\'etudiants \\`a\nce format et, surtout, \\`a tout son \\'eco-syst\\`eme. Nous avons donc mis au\npoint un mod\\`ele permettant d'appuyer l'enseignement de XML. Ce mod\\`ele\npropose de repr\\'esenter un sch\\'ema XML sous la forme d'un graphe mettant en\nvaleur les caract\\'eristiques structurelles des documents valides. Nous\npr\\'esentons dans ce rapport les diff\\'erents \\'el\\'ements graphique du\nmod\\`ele et les am\\'eliorations qu'il apporte \\`a la mod\\'elisation de\ndonn\\'ees en XML.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.1793v2"
    },
    {
        "title": "The structure and functions of an automated project management system\n  for the centers of scientific and technical creativity of students",
        "authors": [
            "V. M. Dmitriev",
            "T. V. Gandzha",
            "V. V. Gandzha",
            "S. A. Panov"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This article discusses the possibility of automating of the student's\nprojecting through the use of automated project management system. There are\ndescribed the purpose, structure and formalism of automated workplace of\nstudent-designer (AWSD), and shown its structural-functional diagram.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.2056v1"
    },
    {
        "title": "Smart: Semantically mashup rest web services",
        "authors": [
            "Rima Kilany Maroun Chamoun"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A mashup is a combination of information from more than one source, mixed up\nin a way to create something new, or at least useful. Anyone can find mashups\non the internet, but these are always specifically designed for a predefined\npurpose. To change that fact, we implemented a new platform we called the SMART\nplatform. SMART enables the user to make his own choices as for the REST web\nservices he needs to call in order to build an intelligent personalized mashup,\nfrom a Google-like simple search interface, without needing any programming\nskills. In order to achieve this goal, we defined an ontology that can hold\nREST web services descriptions. These descriptions encapsulate mainly, the\ninput type needed for a service, its output type, and the kind of relation that\nties the input to the output. Then, by matching the user input query keywords,\nwith the REST web services definitions in our ontology, we can find registered\nservices individuals in this ontology, and construct the raw REST query for\neach service found. The wrap up from the keywords, into semantic definitions,\nin order to find the matching service individual, then the wrap down from the\nsemantic service description of the found individual, to the raw REST call, and\nfinally the wrap up of the result again into semantic individuals, is done for\ntwo main purposes: the first to let the user use simple keywords in order to\nbuild complex mashups, and the second to benefit from the ontology inference\nengine in a way, where services instances can be tied together into an\nintelligent mashup, simply by making each service output individuals, stand as\nthe next service input.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3078v1"
    },
    {
        "title": "Current Services In Cloud Computing: A Survey",
        "authors": [
            "Mohamed Magdy Mosbah",
            "Hany Soliman",
            "Mohamad Abou El-Nasr"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Due to the fast development of the Cloud Computing technologies, the rapid\nincrease of cloud services are became very remarkable. The fact of integration\nof these services with many of the modern enterprises cannot be ignored.\nMicrosoft, Google, Amazon, SalesForce.com and the other leading IT companies\nare entered the field of developing these services. This paper presents a\ncomprehensive survey of current cloud services, which are divided into eleven\ncategories. Also the most famous providers for these services are listed.\nFinally, the Deployment Models of Cloud Computing are mentioned and briefly\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3319v1"
    },
    {
        "title": "Wireless Computing and IT Ecosystems",
        "authors": [
            "William R Simpson"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We have evolved an IT system that is ubiquitous and pervasive and integrated\ninto most aspects of our lives. Many of us are working on 4th and 5th level\nrefinements in efficiency and functionality. But, we stand on the shoulders of\nthose who came before and this restricts our freedom of action. The prior work\nhas left us with an ecosystem which is the living embodiment of our\nstate-of-the-art. While we work on integration, refinement, broader application\nand efficiency, the results must move seamlessly into the ecosystem.\nFundamental concepts are being researched in the lab and may rebuild the world\nwe all live in, until that happens, we must work within the ecosystem.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3548v1"
    },
    {
        "title": "Intuitionistic Neutrosophic Soft Set",
        "authors": [
            "Broumi Said",
            "Florentin Smarandache"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In this paper we study the concept of intuitionistic neutrosophic set of\nBhowmik and Pal. We have introduced this concept in soft sets and defined\nintuitionistic neutrosophic soft set. Some definitions and operations have been\nintroduced on intuitionistic neutrosophic soft set. Some properties of this\nconcept have been established.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.3562v1"
    },
    {
        "title": "Routing Diverse Evacuees with Cognitive Packets",
        "authors": [
            "Huibo Bi",
            "Erol Gelenbe"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper explores the idea of smart building evacuation when evacuees can\nbelong to different categories with respect to their ability to move and their\nhealth conditions. This leads to new algorithms that use the Cognitive Packet\nNetwork concept to tailor different quality of service needs to different\nevacuees. These ideas are implemented in a simulated environment and evaluated\nwith regard to their effectiveness.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.4818v2"
    },
    {
        "title": "An Improved Variable Step-size Affine Projection Sign Algorithm for Echo\n  Cancellation",
        "authors": [
            "Jianming Liu",
            "Steven L. Grant"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper proposes an improved variable step-size (VSS) algorithm for the\nrecently introduced affine projection sign algorithm (APSA) based on the\nrecovery of the near-end signal energy in the error signal. Simulation results\ndemonstrate that, compared to the previous VSS for APSA, the proposed approach\nprovides both more robustness to impulse interference and better tracking\nability of echo path change.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.5242v1"
    },
    {
        "title": "Classification of ST and Q Type MI variant using thresholding and\n  neighbourhood estimation method after cross wavelet based analysis",
        "authors": [
            "Swati Banerjee",
            "Madhuchhanda Mitra"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper proposes a cross wavelet transform based method for\nElectrocardiogram signal analysis where parameters are identified from wavelet\ncross spectrum and wavelet cross coherence of ECG patterns. Most of the ECG\nanalysing systems use explicit time plane features for cardiac pattern\nclassification. Application of this proposed technique for classification\neliminates the need for extraction of various explicit time plane features and\nhence reduces the complexity of the system. The cross-correlation is the\nmeasure of similarity between two waveforms or two time series and the cross\nexamination reveals localized similarities in time and scale. Parameters\nextracted from Wavelet Cross Spectrum (WCS) and Wavelet Coherence (WCOH) is\nused for classification. A pathologically varying pattern in QT zone of\ninferior lead III shows the presence of Inferior Myocardial Infarction (IMI).\nThe Cross Wavelet Transform and Wavelet Coherence is used for the cross\nexamination of single normal and abnormal (IMI) beats. A normal template beat\nis selected as the absolute normal pattern. Computation of the WCS and WCOH of\nthe selected normal template and various other normal and abnormal beats\nreveals the existence of variation among patterns under study. The Wavelet\ncross spectrum and Wavelet coherence of various ECG patterns shows\ndistinguishing characteristics over two specific regions R1 and R2, where R1 is\nthe QRS complex location and R2 is the T wave region. Parameters are identified\nfor classification of Type 1 IMI (non Q type, with ST elevation and attenuated\nQRS complex) and Type 2 IMI (Q type MI with deep Q and inverted T) and normal\nsubjects. Accuracy of the proposed classification method is obtained as 99.43%\nfor normal and abnormal class and 88.5% and 87.02% for Type I and Type II\nrespectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.5639v1"
    },
    {
        "title": "Criticality estimation of IT business functions with the Business\n  Continuity Testing Points method for implementing effective recovery\n  exercises of crisis scenarios",
        "authors": [
            "Athanasios Podaras",
            "Tomas Zizka"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The primary goal of the present paper is the introduction of a new approach\nof defining IT unit business functions exact criticality levels and\nrespectively categorize them to the appropriate recovery tests, prior to their\nthorough documentation which includes actual desired recovery time frames. The\nmethod is entitled as Business Continuity Testing Points and it is based on the\nconcept of Use Case Points, a fundamental project estimation tool utilized for\nsizing of object-oriented system development. The aim of the contribution is to\nameliorate the existing manual way of determining recovery time of IT business\nfunctions that is based exclusively on experience of IT personnel, by\nintroducing a calculation method of multiple factors that can negatively affect\nthe recovery process. The elimination of damage as a result of tested immediate\nresponse action in a crisis situation that disrupts core IT operations\nconstitutes the aimed advantage of the proposed contribution\n",
        "pdf_link": "http://arxiv.org/pdf/1311.5677v1"
    },
    {
        "title": "Simulation Model Of Functional Stability Of Business Processes",
        "authors": [
            "Yuri Monakhov",
            "Olga Fayman"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Functioning of business processes of high-tech enterprise is in a constant\ninteraction with the environment. Herewith a wide range of such interaction\nrepresents a variety of conflicts affecting the achievement of the goals of\nbusiness processes. All these things lead to the disruption of functioning of\nbusiness processes. That's why modern enterprises should have mechanisms to\nprovide a new property of business processes - ability to maintain and/or\nrestore functions in various adverse effects. This property is called\nfunctional stability of business processes (FSBP). In this article we offer,\nshowcase and test the new approach to assessing the results of business process\nre-engineering by simulating their functional stability before and after\nre-engineering.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6550v1"
    },
    {
        "title": "Spreading huge free software without internet connection, via\n  self-replicating USB keys",
        "authors": [
            "Thierry Monteil"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We describe and discuss an affordable way to spread huge software without\nrelying on internet connection, via the use of self-replicating live USB keys.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6754v1"
    },
    {
        "title": "Distributed Power Loss Minimization in Residential Micro Grids: a\n  Communications Perspective",
        "authors": [
            "Riccardo Bonetto",
            "Stefano Tomasin",
            "Michele Rossi"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The constantly increasing number of power generation devices based on\nrenewables is calling for a transition from the centralized control of\nelectrical distribution grids to a distributed control scenario. In this\ncontext, distributed generators (DGs) are exploited to achieve other objectives\nbeyond supporting loads, such as the minimization of the power losses along the\ndistribution lines. The aim of this work is that of designing a full-fledged\nsystem that extends existing state of the art algorithms for the distributed\nminimization of power losses. We take into account practical aspects such as\nthe design of a communication and coordination protocol that is resilient to\nlink failures and manages channel access, message delivery and DG coordination.\nThus, we analyze the performance of the resulting optimization and\ncommunication scheme in terms of power loss reduction, reduction of aggregate\npower demand, convergence rate and resilience to communication link failures.\nAfter that, we discuss the results of a thorough simulation campaign, obtained\nusing topologies generated through a statistical approach that has been\nvalidated in previous research, by also assessing the performance deviation\nwith respect to localized schemes, where the DGs are operated independently.\nOur results reveal that the convergence and stability performance of the\nselected algorithms vary greatly. However, configurations exist for which\nconvergence is possible within five to ten communication steps and, when just\n30% of the nodes are DGs, the aggregate power demand is roughly halved. Also,\nsome of the considered approaches are quite robust against link failures as\nthey still provide gains with respect to the localized solutions for failure\nrates as high as 50%.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.6949v1"
    },
    {
        "title": "A Fraud Detection Visualization System Utilizing Radial Drawings and\n  Heat-maps",
        "authors": [
            "Evmorfia N. Argyriou",
            "Antonios Symvonis",
            "Vassilis Vassiliou"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We present a prototype system developed in cooperation with a business\norganization that combines information visualization and pattern-matching\ntechniques to detect fraudulent activity by employees. The system is built upon\ncommon fraud patterns searched while trying to detect occupational fraud\nsuggested by internal auditors of a business company. The main visualization of\nthe system consists of a multi-layer radial drawing that represents the\nactivity of the employees and clients. Each layer represents a different\nexamined pattern whereas heat-maps indicating suspicious activity are\nincorporated in the visualization. The data are first preprocessed based on a\ndecision tree generated by the examined patterns and each employee is assigned\na value indicating whether or not there exist indications of fraud. The\nvisualization is presented as an animation and the employees are visualized one\nby one according to their severity values together with their related clients.\n",
        "pdf_link": "http://arxiv.org/pdf/1311.7259v1"
    },
    {
        "title": "Theoretical Foundation for Research in Communication using Information\n  and Communication Technology Devices in Healthcare: An Interdisciplinary\n  Scoping Review",
        "authors": [
            "Arun Keepanasseril",
            "Kathleen Ann McKibbon",
            "Alfonso Iorio"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Faulty communication between team members is one of the most important\nfactors preventing substantial improvement in patient safety. Aviation, nuclear\npower and defense have been able to improve their safety record by adopting\ntheory and model based solutions. In contrast, healthcare's thrust towards\nmodern communication devices is largely devoid of theoretical foundation. The\nobjective of this scoping review is to compile communication theories,\nframeworks, and models used by high risk organizations outside healthcare to\nstudy and resolve workplace communication issues. The healthcare databases\nsearched included Medline, CINAHL, EMBASE, and PsycInfo. In addition, we\nsearched engineering and science literature to include articles in the fields\nof information sciences, computer sciences, nuclear power generation, aviation,\nthe military and other domains such as sociology that address the science and\ntheory of communication. Comprehensive searching was also done in the\ncommunication studies literature. We also reviewed conference proceedings and\ngrey literature and conducted citation tracking. Our initial systematic search\nyielded 15,365 articles. Hand searching and reviewing references resulted in a\nset of 181 articles. 144 full text articles were read and 40 of them were\nselected to be included in the review. We were able to identify 14 theories and\n12 models which could be applied in hospital communication research. However,\nit must be noted that most of them have not yet been applied in biomedical\nresearch in hospital communication and as such their applicability can only be\nsuggested-a gap which future research may be able to address. Formulation of a\ncustom model representing the unique features and complexities of communication\nwithin hospitals is recommended.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.0520v1"
    },
    {
        "title": "FELFCNCA: Fast & Efficient Log File Compression Using Non Linear\n  Cellular Automata Classifier",
        "authors": [
            "P. Kiran Sree",
            "Inampudi Ramesh Babu",
            "SSSN Usha Devi N"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Log Files are created for Traffic Analysis, Maintenance, Software debugging,\ncustomer management at multiple places like System Services, User Monitoring\nApplications, Network servers, database management systems which must be kept\nfor long periods of time. These Log files may grow to huge sizes in this\ncomplex systems and environments. For storage and convenience log files must be\ncompressed. Most of the existing algorithms do not take temporal redundancy\nspecific Log Files into consideration. We propose a Non Linear based Classifier\nwhich introduces a multidimensional log file compression scheme described in\neight variants, differing in complexity and attained compression ratios. The\nFELFCNCA scheme introduces a transformation for log file whose compressible\noutput is far better than general purpose algorithms. This proposed method was\nfound lossless and fully automatic. It does not impose any constraint on the\nsize of log file\n",
        "pdf_link": "http://arxiv.org/pdf/1312.1889v1"
    },
    {
        "title": "A New Variable Step-size Zero-point Attracting Projection Algorithm",
        "authors": [
            "Jianming Liu",
            "Steven L Grant"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper proposes a new variable step-size (VSS) scheme for the recently\nintroduced zero-point attracting projection (ZAP) algorithm. The proposed\nvariable step-size ZAPs are based on the gradient of the estimated filter\ncoefficients sparseness that is approximated by the difference between the\nsparseness measure of current filter coefficients and an averaged sparseness\nmeasure. Simulation results demonstrate that the proposed approach provides\nboth faster convergence rate and better tracking ability than previous ones.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.2612v1"
    },
    {
        "title": "Personalized real time weather forecasting",
        "authors": [
            "Abhishek Kumar SIngh",
            "Aditi Sharma",
            "Rahul Mishra"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Temperature forecasting and rain forecasting in today's environment is\nplaying a major role in many fields like transportation, tour planning and\nagriculture. The purpose of this paper is to provide a real time forecasting to\nthe user according to their current position and requirement. The simplest\nmethod of forecasting the weather, persistence, relies upon today's conditions\nto forecast the conditions tomorrow i.e. analyzing historical data for\npredicting future weather conditions. The weather data used for the DM research\ninclude daily temperature, daily pressure and monthly rainfall.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.2808v1"
    },
    {
        "title": "Abridged Petri Nets",
        "authors": [
            "Vitali Volovoi"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A new graphical framework, Abridged Petri Nets (APNs) is introduced for\nbottom-up modeling of complex stochastic systems. APNs are similar to\nStochastic Petri Nets (SPNs) in as much as they both rely on component-based\nrepresentation of system state space, in contrast to Markov chains that\nexplicitly model the states of an entire system. In both frameworks, so-called\ntokens (denoted as small circles) represent individual entities comprising the\nsystem; however, SPN graphs contain two distinct types of nodes (called places\nand transitions) with transitions serving the purpose of routing tokens among\nplaces. As a result, a pair of place nodes in SPNs can be linked to each other\nonly via a transient stop, a transition node. In contrast, APN graphs link\nplace nodes directly by arcs (transitions), similar to state space diagrams for\nMarkov chains, and separate transition nodes are not needed.\n  Tokens in APN are distinct and have labels that can assume both discrete\nvalues (\"colors\") and continuous values (\"ages\"), both of which can change\nduring simulation. Component interactions are modeled in APNs using triggers,\nwhich are either inhibitors or enablers (the inhibitors' opposites).\nHierarchical construction of APNs rely on using stacks (layers) of submodels\nwith automatically matching color policies. As a result, APNs provide at least\nthe same modeling power as SPNs, but, as demonstrated by means of several\nexamples, the resulting models are often more compact and transparent,\ntherefore facilitating more efficient performance evaluation of complex\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.2865v1"
    },
    {
        "title": "Maturity Model for IT Service Outsourcing in Higher Education\n  Institutions",
        "authors": [
            "Victoriano Valencia Garca",
            "Eugenio J. Fernndez Vicente",
            "Luis Usero Aragons"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The current success of organizations depends on the successful implementation\nof Information and Comunication Technologies (ICTs). Good governance and ICT\nmanagement are essential for delivering value, managing technological risks,\nmanaging resources and performance measurement. In addition, outsourcing is a\nstrategic option which complements IT services provided internally in\norganizations. This paper proposes the design of a new holistic maturity model\nbased on standards ISO/IEC 20000 and ISO/IEC 38500, the frameworks and best\npractices of ITIL and COBIT, with a specific focus on IT outsourcing. This\nmodel is validated by practices in the field of higher education, using a\nquestionnaire and a metrics table among other measurement tools. Models,\nstandards and guidelines are proposed in the model for facilitating adaptation\nto universities and achieving excellence in the outsourcing of IT services. The\napplicability of the model allows an effective transition to a model of good\ngovernance and management of outsourced IT services which, aligned with the\ncore business of universities (teaching, research and innovation), affect the\neffectiveness and efficiency of its management, optimizes its value and\nminimizes risks.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.2868v1"
    },
    {
        "title": "Various models of process of the learning, based on the numerical\n  solution of the differential equations",
        "authors": [
            "R. V. Mayer"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The principles on which can be based computer model of process of training\nare formulated. Are considered: 1) the unicomponent model, which is recognizing\nthat educational information consists of equal elements; 2) the multicomponent\nmodel, which is considering that knowledge is assimilate with a various\nstrength, and on lesson weak knowledge becomes strong; 3) the generalized\nmulticomponent model which considers change of working capacity of the pupil\nand various complexity of studied elements of a training material. Typical\nresults of imitating modeling of learning process are presented in article.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.3116v1"
    },
    {
        "title": "Vulnerability of LTE to Hostile Interference",
        "authors": [
            "Marc Lichtman",
            "Jeffrey H. Reed",
            "T. Charles Clancy",
            "Mark Norton"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  LTE is well on its way to becoming the primary cellular standard, due to its\nperformance and low cost. Over the next decade we will become dependent on LTE,\nwhich is why we must ensure it is secure and available when we need it.\nUnfortunately, like any wireless technology, disruption through radio jamming\nis possible. This paper investigates the extent to which LTE is vulnerable to\nintentional jamming, by analyzing the components of the LTE downlink and uplink\nsignals. The LTE physical layer consists of several physical channels and\nsignals, most of which are vital to the operation of the link. By taking into\naccount the density of these physical channels and signals with respect to the\nentire frame, as well as the modulation and coding schemes involved, we come up\nwith a series of vulnerability metrics in the form of jammer to signal ratios.\nThe ``weakest links'' of the LTE signals are then identified, and used to\nestablish the overall vulnerability of LTE to hostile interference.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.3681v2"
    },
    {
        "title": "The solution of complex problems on calculation of the electrostatic\n  fields on lessons on computer modeling",
        "authors": [
            "Robert V Mayer"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In article the following tasks on computer modeling of electric fields are\nanalyzed: 1) calculation of distribution of potential for the field created by\ntwo parallel plates and charged bodies in the non-uniform environment; 2)\ncalculation of distribution of potential and force lines of electric field in\nwhich are brought the cylinder, a pipe, a plate, a rectangular parallelepiped\nfrom dielectric, and also the metal cylinder; 3) calculation of distribution of\npotential in the one-dimensional nonuniform environment; 4) the solution of the\nequation of Poisson in spherical coordinates; 5) calculation of distribution of\npotential in cylindrical coordinates with the subsequent creation of\nequipotential surfaces and force lines.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.3700v1"
    },
    {
        "title": "Technical Report: A New Multi-Device Wireless Power Transfer Scheme\n  Using an Intermediate Energy Storage Circuit",
        "authors": [
            "Changseok Yoon",
            "Sung Sik Nam",
            "Sung Ho Cho"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A new multi-device wireless power transfer scheme that reduces the overall\ncharging time is presented. The proposed scheme employs the intermediated\nenergy storage (IES) circuit which consists of a constant power driving circuit\nand a super-capacitor. By utilizing the characteristic of high power density of\nthe super-capacitor, the receiver can receive and store the energy in short\nduration and supply to the battery for long time. This enables the overlap of\ncharging duration between all receivers. As a result, the overall charging time\ncan be reduced.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.4410v3"
    },
    {
        "title": "Cyclostationary Spectrum Sensing in Cognitive Radios Using FRESH Filters",
        "authors": [
            "Hemant Saggar",
            "D. K. Mehra"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper deals with spectrum sensing in Cognitive Radios to enable\nunlicensed secondary users to opportunistically access a licensed band. The\nability to detect the presence of a primary user at a low signal to noise ratio\n(SNR) is a challenging prerequisite to spectrum sensing and earlier proposed\ntechniques like energy detection and cyclostationary detection have only been\npartially successful. This paper proposes the use of FRESH (FREquency SHift)\nfilters [1] to enable spectrum sensing at low SNR by optimally estimating a\ncyclostationary signal using its spectral coherence properties. We establish\nthe mean square error convergence of the adaptive FRESH filter through\nsimulation. Subsequently, we formulate a cyclostationarity based binary\nhypothesis test on the filtered signal and observe the resultant detection\nperformance. Simulation results show that the proposed approach performs better\nthan energy detection and cyclostationary detection techniques for spectrum\nsensing.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.5257v1"
    },
    {
        "title": "Heuristics for Routing and Spiral Run-time Task Mapping in NoC-based\n  Heterogeneous MPSOCs",
        "authors": [
            "Mohammed kamel Benhaoua",
            "Abbou El Hassen Benyamina",
            "Pierre Boulet"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper describes a new Spiral Dynamic Task Mapping heuristic for mapping\napplications onto NoC-based Heterogeneous MPSoC. The heuristic proposed in this\npaper attempts to map the tasks of an applications that are most related to\neach other in spiral manner and to find the best possible path load that\nminimizes the communication overhead. In this context, we have realized a\nsimulation environment for experimental evaluations to map applications with\nvarying number of tasks onto an 8x8 NoC-based Heterogeneous MPSoCs platform, we\ndemonstrate that the new mapping heuristics with the new modified dijkstra\nrouting algorithm proposed are capable of reducing the total execution time and\nenergy consumption of applications when compared to state-of the-art run-time\nmapping heuristics reported in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.5764v1"
    },
    {
        "title": "Advanced Data Processing in the Business Network System",
        "authors": [
            "Daniel Ritter"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The discovery, representation and reconstruction of Business Networks (BN)\nfrom Network Mining (NM) raw data is a difficult problem for enterprises. This\nis due to huge amounts of e.g. complex business processes within and across\nenterprise boundaries, heterogeneous technology stacks, and fragmented data. To\nremain competitive, visibility into the enterprise and partner networks on\ndifferent, interrelated abstraction levels is desirable.\n  We show the query and data processing capabilities of a novel data discovery,\nmining and network inference system, called Business Network System (BNS) that\nreconstructs the BN--integration and business process networks - from raw data,\nhidden in the enterprises' landscapes. The paper covers both the foundation and\nthe key data processing characteristics features of BNS, including its\nunderlying technologies, its overall system architecture, and data provenance\napproach.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7436v1"
    },
    {
        "title": "A Novel Carrier Waveform Inter-Displacement Modulation Method in\n  Underwater Communication Channel",
        "authors": [
            "Hai-Peng Ren",
            "Yang Zhao"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  As the main way of underwater wireless communication, underwater acoustic\ncommunication is one of the focuses of ocean research. Compared with the free\nspace wireless communication channel, the underwater acoustic channel suffers\nfrom more severe multipath effect, the less available bandwidth and the even\ncomplex noise. The underwater acoustic channel is one of the most complicated\nwireless communication channels. To achieve a reliable underwater acoustic\ncommunication, Phase Shift Keying (PSK) modulation and Passive Time Reversal\nMirror (PTRM) equalization are considered to be a suitable scheme. However, due\nto the serious distortion of the received signal caused by the channel, this\nscheme suffers from a high Bit Error Rate (BER) under the condition of the low\nSignal to Noise Ratio (SNR). To solve this problem, we proposes a Carrier\nWaveform Inter-Displacement (CWID) modulation method based on the Linear\nFrequency Modulation (LFM) PSK and PTRM scheme. The new communication scheme\nreduces BER by increasing the difference from the carrier waveform for\ndifferent symbols. Simulation results show the effectiveness and superiority of\nthe proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7441v1"
    },
    {
        "title": "Effect of Carouseling on Angular Rate Sensor Error Processes",
        "authors": [
            "Jussi Collin",
            "Martti Kirkko-Jaakkola",
            "Jarmo Takala"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Carouseling is an efficient method to mitigate the measurement errors of\ninertial sensors, particularly MEMS gyroscopes. In this article, the effect of\ncarouseling on the most significant stochastic error processes of a MEMS\ngyroscope, i.e., additive bias, white noise, 1/f noise, and rate random walk,\nis investigated. Variance propagation equations for these processes under\naveraging and carouseling are defined. Furthermore, a novel approach to\ngenerating 1/f noise is presented. The experimental results show that\ncarouseling reduces the contributions of additive bias, 1/f noise, and rate\nrandom walk significantly in comparison with plain averaging, which can be\nutilized to improve the accuracy of dead reckoning systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.7839v3"
    },
    {
        "title": "Planar Shielded-Loop Resonators",
        "authors": [
            "Brian B. Tierney",
            "Anthony Grbic"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The design and analysis of planar shielded-loop resonators for use in\nwireless non-radiative power transfer systems is presented. The difficulties\nassociated with coaxial shielded-loop resonators for wireless power transfer\nare discussed and planar alternatives are proposed. The currents along these\nplanar structures are analyzed and first-order design equations are presented\nin the form of a circuit model. In addition, the planar structures are\nsimulated and fabricated. Planar shielded-loop resonators are compact and\nsimple to fabricate. Moreover, they are well-suited for printed circuit board\ndesigns or integrated circuits\n",
        "pdf_link": "http://arxiv.org/pdf/1402.1219v1"
    },
    {
        "title": "Deployment of an Innovative Resource Choice Method for Process Planning",
        "authors": [
            "Alexandre Candlot",
            "Nicolas Perry",
            "Alain Bernard",
            "Samar Ammar-Khodja"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Designers, process planners and manufacturers naturally consider different\nconcepts for a same object. The stiffness of production means and the design\nspecification requirements mark out process planners as responsible of the\ncoherent integration of all constraints. First, this paper details an\ninnovative solution of resource choice, applied for aircraft manufacturing\nparts. In a second part, key concepts are instanced for the considered\nindustrial domain. Finally, a digital mock up validates the solution viability\nand demonstrates the possibility of an in-process knowledge capitalisation and\nuse. Formalising the link between Design and Manufacturing allows to hope\nenhancements of simultaneous Product / Process developments.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.1438v1"
    },
    {
        "title": "Real Time Industrial Monitoring System",
        "authors": [
            "Rahul D. Chavhan",
            "Sachin U. Chavhan",
            "Ganesh B. Chavan"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Industries are the biggest workplace all over the world, also there are large\nnumber of peoples involves as a worker and most of them are work as a machine\noperator. There are many systems developed for industrial work place, some of\nthem, monitors machine processes and some do monitoring and control of machine\nparameters. Such as speed, temperature, production batch count etc. However\nthere is no such system available that provides monitoring of operator during\ntheir work is in progress at workplace. This paper proposes the monitoring of\nthe operators and the machines, by Real time Operator -Machine Allocation and\nmonitoring system (Omams). Omams allocates a work machine to worker at entry\npoint itself. It uses automation with RFID and one of the standards of wireless\ncommunication method. The system can be industry specific. Through this\nresearch paper our approach is to make fair allocation of machine to the\noperator in industry and reduce hassle for efficiency calculations.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.1693v1"
    },
    {
        "title": "dRTI: Directional Radio Tomographic Imaging",
        "authors": [
            "Bo Wei",
            "Ambuj Varshney",
            "Wen Hu",
            "Neal Patwari",
            "Thiemo Voigt",
            "Chun Tung Chou"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Radio tomographic imaging (RTI) enables device free localisation of people\nand objects in many challenging environments and situations. Its basic\nprinciple is to detect the changes in the statistics of some radio quality\nmeasurements in order to infer the presence of people and objects in the radio\npath. However, the localisation accuracy of RTI suffers from complicated radio\npropagation behaviours such as multipath fading and shadowing. In order to\nimprove RTI localisation accuracy, we propose to use inexpensive and energy\nefficient electronically switched directional (ESD) antennas to improve the\nquality of radio link behaviour observations, and therefore, the localisation\naccuracy of RTI. We implement a directional RTI (dRTI) system to understand how\ndirectional antennas can be used to improve RTI localisation accuracy. We also\nstudy the impact of the choice of antenna directions on the localisation\naccuracy of dRTI and propose methods to effectively choose informative antenna\ndirections to improve localisation accuracy while reducing overhead. We\nevaluate the performance of dRTI in diverse indoor environments and show that\ndRTI significantly outperforms the existing RTI localisation methods based on\nomni-directional antennas.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.2744v1"
    },
    {
        "title": "Tasks for Temporal Graph Visualisation",
        "authors": [
            "Natalie Kerracher",
            "Jessie Kennedy",
            "Kevin Chalmers"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In [1], we describe the design and development of a task taxonomy for\ntemporal graph visualisation. This paper details the full instantiation of that\ntask taxonomy. Our task taxonomy is based on the Andrienko framework [2], which\nuses a systematic approach to develop a formal task framework for visual tasks\nspecifically associated with Exploratory Data Analysis. The Andrienko framework\nis intended to be applicable to all types of data, however, it does not\nconsider relational (graph) data. We therefore extended both their data model\nand task framework for temporal graph data, and instantiated the extended\nversion to produce a comprehensive list of tasks of interest during exploratory\nanalysis of temporal graph data. As expected, our instantiation of the\nframework resulted in a very large task list; with more than 144 variations of\nattribute based tasks alone, it is too large to fit in a standard journal\npaper, hence we provide the detailed listing in this document.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.2867v1"
    },
    {
        "title": "Evaluating ECG Capturing Using Sound-Card of PC/Laptop",
        "authors": [
            "Bhavikkumar Patel",
            "Dhrumil Shah"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The purpose of the Evaluating ECG capturing using sound-card of PC/Laptop is\nprovided portable and low cost ECG monitoring system using laptop and mobile\nphones. There is no need to interface micro controller or any other device to\ntransmit ECG data. This research is based on hardware design, implementation,\nsignal capturing and Evaluation of an ECG processing and analyzing system which\nattend the physicians in heart disease diagnosis. Some important modification\nis given in design part to avoid all definitive ECG instrument problems faced\nin previous designs. Moreover, attenuate power frequency noise and noise that\nproduces from patient's body have required additional developments. The\nhardware design has basically three units: transduction and conditioning Unit,\ninterfacing unit and data processing unit.The most focusing factor is the ECG\nsignal/data transmits in laptop/PC via microphone pin. The live simulation is\npossible using SOUNDSCOPE software in PC/Laptop. The software program that is\nwritten in MATLAB and LAB-View performs data acquisition (record, stored,\nfiltration) and several tasks such as QRS detection, calculate heart rate.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3651v1"
    },
    {
        "title": "QTC3D: Extending the Qualitative Trajectory Calculus to Three Dimensions",
        "authors": [
            "Nikolaos Mavridis",
            "Nicola Bellotto",
            "Konstantinos Iliopoulos",
            "Nico Van de Weghe"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Spatial interactions between agents (humans, animals, or machines) carry\ninformation of high value to human or electronic observers. However, not all\nthe information contained in a pair of continuous trajectories is important and\nthus the need for qualitative descriptions of interaction trajectories arises.\nThe Qualitative Trajectory Calculus (QTC) (Van de Weghe, 2004) is a promising\ndevelopment towards this goal. Numerous variants of QTC have been proposed in\nthe past and QTC has been applied towards analyzing various interaction\ndomains. However, an inherent limitation of those QTC variations that deal with\nlateral movements is that they are limited to two-dimensional motion;\ntherefore, complex three-dimensional interactions, such as those occurring\nbetween flying planes or birds, cannot be captured. Towards that purpose, in\nthis paper QTC3Dis presented: a novel qualitative trajectory calculus that can\ndeal with full three-dimensional interactions. QTC3D is based on\ntransformations of the Frenet-Serret frames accompanying the trajectories of\nthe moving objects. Apart from the theoretical exposition, including definition\nand properties, as well as computational aspects, we also present an\napplication of QTC3D towards modeling bird flight. Thus, the power of QTC is\nnow extended to the full dimensionality of physical space, enabling succinct\nyet rich representations of spatial interactions between agents.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.3779v1"
    },
    {
        "title": "Control Loop Feedback Mechanism for Generic Array Logic Chip\n  Multiprocessor",
        "authors": [
            "V. Karthikeyan V. J. Vijayalakshmi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Control Loop Feedback Mechanism for Generic Array Logic Chip Multiprocessor\nis presented. The approach is based on control-loop feedback mechanism to\nmaximize the efficiency on exploiting available resources such as CPU time,\noperating frequency, etc. Each Processing Element (PE) in the architecture is\nequipped with a frequency scaling module responsible for tuning the frequency\nof processors at run-time according to the application requirements. We show\nthat generic array logic Chip Multiprocessors with large inter-processor First\nIn First Outputs (First In First Outs) buffers can inherently hide much of the\nGeneric Array Logic performance penalty while executing applications that have\nbeen mapped with few communication loops. In fact, the penalty can be driven to\nzero with sufficiently large First In First Outs and the removal of\nmultiple-loop communication links. We present an example mesh-connected Generic\nArray Logic chip multiprocessor and show it has a less than 1% performance\n(throughput) reduction on average compared to the corresponding synchronous\nsystem for many DSP workloads. Furthermore, adaptive clock and voltage scaling\nfor each processor provides an approximately 40% power savings without any\nperformance reduction.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.5617v1"
    },
    {
        "title": "A Hybrid Estimation of Distribution Algorithm with Random Walk local\n  Search for Multi-mode Resource-Constrained Project Scheduling problems",
        "authors": [
            "Omar S. Soliman",
            "Elshimaa A. R. Elgendi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Multi-mode resource-constrained project scheduling problems (MRCPSPs) are\nclassified as NP-hard problems, in which a task has different execution modes\ncharacterized by different resource requirements. Estimation of distribution\nalgorithm (EDA) has shown an effective performance for solving such real-world\noptimization problems but it fails to find the desired optima. This paper\nintegrates a novel hybrid local search technique with EDA to enhance their\nlocal search ability. The new local search is based on delete-then-insert\noperator and a random walk (DIRW) to enhance exploitation abilities of EDA in\nthe neighborhoods of the search space. The proposed algorithm is capable to\nexplore and exploit the search mechanism in the search space through its outer\nand inner loops. The proposed algorithm is tested and evaluated using benchmark\ntest problems of the project scheduling problem library PSPLIB. Simulation\nresults of the proposed algorithm are compared with the classical EDA\nalgorithm. The obtained results showed that the effectiveness of the proposed\nalgorithm and outperformed the compared EDA algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.5645v1"
    },
    {
        "title": "Recommendation System for Outfit Selection (RSOS)",
        "authors": [
            "Shiv H. Sutar",
            "Akshata H. Khade"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  We propose a system which will be able to recommend the user to choose\nappropriate outfits suits to their personality. The necessity of this system is\nto reduce the outfit selection and purchasing time; this will also help to\ncreate tailor made outfits as per the personality traits. The guidelines for\nselection of their respective outfits are based upon various bodily parameters\nthat evolve with the learning of available labeled and unlabeled data. The\nsystem is based on two modules of processes; first one is to recognize the\nfeatures for usage of outfits like traditional, western, functional, daytime or\nnight etc, second is to calculate the body measurement parameters. The proposed\nsystem will have image capturing by using HAAR feature or input device for\ngetting body parameters. We intend to classify and extract the best possible\noutfits from the system by using HIGEN MINER algorithm. The applications of\noutfit selection will be ranging from manual gender selection, image processing\nwith body feature extractions, Value comparison with database by using\ndifferent statistical techniques and data mining algorithms. After that it will\nrecommend best outfits as per body parameters, inputs and availability\n",
        "pdf_link": "http://arxiv.org/pdf/1402.6692v1"
    },
    {
        "title": "Complex Beauty",
        "authors": [
            "Massimo Franceschet"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Complex systems and their underlying convoluted networks are ubiquitous, all\nwe need is an eye for them. They pose problems of organized complexity which\ncannot be approached with a reductionist method. Complexity science and its\nemergent sister network science both come to grips with the inherent complexity\nof complex systems with an holistic strategy. The relevance of complexity,\nhowever, transcends the sciences. Complex systems and networks are the focal\npoint of a philosophical, cultural and artistic turn of our tightly\ninterrelated and interdependent postmodern society. Here I take a different,\naesthetic perspective on complexity. I argue that complex systems can be\nbeautiful and can the object of artification - the neologism refers to\nprocesses in which something that is not regarded as art in the traditional\nsense of the word is changed into art. Complex systems and networks are\npowerful sources of inspiration for the generative designer, for the artful\ndata visualizer, as well as for the traditional artist. I finally discuss the\nbenefits of a cross-fertilization between science and art.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.6712v1"
    },
    {
        "title": "Three Experiments to Analyze the Nature of the Heat Spreader",
        "authors": [
            "Seema Sethia",
            "Shouri Chatterjee",
            "Sunil Kale",
            "Amit Gupta",
            "Smruti R. Sarangi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper, we describe ongoing work to investigate the properties of the\nheat spreader, and its implication on architecture research. In specific, we\nconduct two experiments to quantify the heat distribution across the surface of\na spreader during normal operation. The first experiment uses T-type\nthermocouples, to find the temperature difference across different points on\nthe spreader. We observe about a 6 degree celsius temperature difference on\naverage. In the second experiment, we try to capture the temperature gradients\nusing an infrared camera. However, this experiment was inconclusive because of\nsome practical constraints such as the low emissivity of the spreader. We\nconclude that to properly model the spreader, it is necessary to conduct\ndetailed finite element simulations. We describe a method to accurately measure\nthe thermal conductivity of the heat spreader such that it can be used to\ncompute the steady state temperature distribution across the spreader.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.6903v1"
    },
    {
        "title": "A Three-State Received Signal Strength Model for Device-free\n  Localization",
        "authors": [
            "Ossi Kaltiokallio",
            "Hseyin Yiitler",
            "Riku Jntti"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The indoor radio propagation channel is typically modeled as a two-state\ntime-variant process where one of the states represents the channel when the\nenvironment is static, whereas the other state characterizes the medium when it\nis altered by people. In this paper, the aforementioned process is augmented\nwith an additional state. It is shown that the changes in received signal\nstrength are dictated by: i) electronic noise, when a person is not present in\nthe monitored area; ii) reflection, when a person is moving in the close\nvicinity of the line-of-sight; iii) shadowing, when a person is obstructing the\nline-of-sight component of the transmitter-receiver pair. Statistical and\nspatial models for the three states are derived and the models are empirically\nvalidated. Based on the models, a simplistic device-free localization\napplication is designed which aims to: first, estimate the temporal state of\nthe channel using a hidden Markov model; second, track a person using a\nparticle filter. The results suggest that the tracking accuracy is enhanced by\nat least 65% while the link's sensitivity region is increased by 100% or more\nwith respect to empirical models presented in earlier works.\n",
        "pdf_link": "http://arxiv.org/pdf/1402.7019v1"
    },
    {
        "title": "On the Behavioral Interpretation of System-Environment Fit and\n  Auto-Resilience",
        "authors": [
            "Vincenzo De Florio"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Already 71 years ago Rosenblueth, Wiener, and Bigelow introduced the concept\nof the \"behavioristic study of natural events\" and proposed a classification of\nsystems according to the quality of the behaviors they are able to exercise. In\nthis paper we consider the problem of the resilience of a system when deployed\nin a changing environment, which we tackle by considering the behaviors both\nthe system organs and the environment mutually exercise. We then introduce a\npartial order and a metric space for those behaviors, and we use them to define\na behavioral interpretation of the concept of system-environment fit. Moreover\nwe suggest that behaviors based on the extrapolation of future environmental\nrequirements would allow systems to proactively improve their own\nsystem-environment fit and optimally evolve their resilience. Finally we\ndescribe how we plan to express a complex optimization strategy in terms of the\nconcepts introduced in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.0339v1"
    },
    {
        "title": "Frequency-Shift Filtering for OFDM Signal Recovery in Narrowband Power\n  Line Communications",
        "authors": [
            "Nir Shlezinger",
            "Ron Dabora"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Power line communications (PLC) has been drawing considerable interest in\nrecent years due to the growing interest in smart grid implementation.\nSpecifically, network control and grid applications are allocated the frequency\nband of 0-500 kHz, commonly referred to as the narrowband PLC channel. This\nfrequency band is characterized by strong periodic noise which results in low\nsignal to noise ratio (SNR). In this work we propose a receiver which uses\nfrequency shift filtering to exploit the cyclostationary properties of both the\nnarrowband power line noise, as well as the information signal, digitally\nmodulated using orthogonal frequency division multiplexing. An adaptive\nimplementation for the proposed receiver is presented as well. The proposed\nreceiver is compared to existing receivers via analysis and simulation. The\nresults show that the receiver proposed in this work obtains a substantial\nperformance gain over previously proposed receivers, without requiring any\ncoordination with the transmitter.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.1061v1"
    },
    {
        "title": "The Unambiguous Distance in a Phase-based Ranging System with Hopping\n  Frequencies",
        "authors": [
            "Yue Zhang",
            "Wangdong Qi",
            "Su Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  It is a challenge to specify unambiguous distance (UD) in a phase-based\nranging system with hopping frequencies (PRSHF). In this letter, we propose to\ncharacterize the UD in a PRSHF by the probability that it takes on its maximum\nvalue. We obtain a very simple and elegant expression of the probability with\ngrowth estimation techniques from analytic number theory. It is revealed that\nthe UD in a PRSHF usually takes on the maximum value with as few as 10\nfrequencies in measurement, almost independent of the specific distribution of\navailable bandwidth.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.1923v1"
    },
    {
        "title": "ARM 7 Based Controller Area Network for Accident Avoidance in\n  Automobiles",
        "authors": [
            "Kashyap Joshi",
            "Vipul Gohil"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Based on requirements of modern vehicle, in- vehicle Controller Area Network\n(CAN) architecture has been implemented. In order to reduce point to point\nwiring harness in vehicle automation, CAN is suggested as a means for data\ncommunication within the vehicle environment. The benefits of CAN bus based\nnetwork over traditional point to point schemes will offer increased\nflexibility and expandability for future technology insertions.\n  This paper describes system which uses sensors to measure various parameters\nof the car like speed, distance from the other car, presence of alcohol in car\nand accidental change of lane and sends a warning signal to the driver if any\nof the parameter goes out of range to avoid accidents . In addition to this if\naccident occurs in any remote area then using bump sensor accident is detected\nand SMS is send immediately using GSM. A situation that provides a good example\nof how the system works is when a driver is about to change lanes, and there is\na car in his blind spot. The sensors will detect that car and inform the driver\nbefore he starts turning, preventing him from potentially getting into a\nserious accident.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.3156v1"
    },
    {
        "title": "Distributed Transformer Monitoring System Based On Zigbee Technology",
        "authors": [
            "Rakesh Kumar Pandey",
            "Dilip Kumar"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  A Distributed transformer networks remote monitoring system is developed and\nconstructed,for monitor and record the parameters like temperature, oil level\nstatus, of a distribution transformer.The system consists of a micro controller\nbased circuit,with solid-state components for handling sensors,power\nback-up,real time clock and data communication module which based on ZigBee\nprotocol.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.3547v1"
    },
    {
        "title": "Behavior, Organization, Substance: Three Gestalts of General Systems\n  Theory",
        "authors": [
            "Vincenzo De Florio"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The term gestalt, when used in the context of general systems theory, assumes\nthe value of \"systemic touchstone\", namely a figure of reference used to\ncategorize the properties or qualities of a set of systems. Typical gestalts\nused in biology are those based on anatomical or physiological characteristics,\nwhich correspond respectively to architectural and organizational design\nchoices in natural and artificial systems. In this paper we discuss three\ngestalts of general systems theory: behavior, organization, and substance,\nwhich refer respectively to the works of Wiener, Boulding, and Leibniz. Our\nmajor focus here is the system introduced by the latter. Through a discussion\nof some of the elements of the Leibnitian System, and by means of several novel\ninterpretations of those elements in terms of today's computer science, we\nhighlight the debt that contemporary research still has with this Giant among\nthe giant scholars of the past.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.4077v2"
    },
    {
        "title": "Load flow analysis of radial distribution network using linear data\n  structure",
        "authors": [
            "Ritu Parasher"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Distribution systems hold a very significant position in the power system\nsince it is the main point of link between bulk power and consumers. A planned\nand effective distribution network is the key to cope up with the ever\nincreasing demand for domestic, industrial and commercial load. The load-flow\nstudy of radial distribution network is of prime importance for effective\nplanning of load transfers. Power companies are interested in finding the most\nefficient configuration for minimization of real power loses and load balancing\namong distribution feeders to save energy and enhance the over all performance\nof distribution system.\n  This thesis presents a fast and efficient method for load-flow analysis of\nradial distribution networks. The proposed method is based on linear data\nstructure. The order of time and space complexity is reported here. There is\nsignificant saving in no. of steps execution. Using graph theory concept and\nexploiting multi-cores architecture, the proposed method for load flow can be\nfurther investigated for obtaining more optimized solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.4702v1"
    },
    {
        "title": "Mapping parcel-level urban areas for a large geographical area",
        "authors": [
            "Ying Long",
            "Yao Shen"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  As a vital indicator for measuring urban development, urban areas are\nexpected to be identified explicitly and conveniently with widely available\ndataset thereby benefiting the planning decisions and relevant urban studies.\nExisting approaches to identify urban areas normally based on mid-resolution\nsensing dataset, socioeconomic information (e.g. population density) generally\nassociate with low-resolution in space, e.g. cells with several square\nkilometers or even larger towns/wards. Yet, few of them pay attention to\ndefining urban areas with micro data in a fine-scaled manner with large extend\nscale by incorporating the morphological and functional characteristics. This\npaper investigates an automated framework to delineate urban areas in the\nparcel level, using increasingly available ordnance surveys for generating all\nparcels (or geo-units) and ubiquitous points of interest (POIs) for inferring\ndensity of each parcel. A vector cellular automata model was adopted for\nidentifying urban parcels from all generated parcels, taking into account\ndensity, neighborhood condition, and other spatial variables of each parcel. We\napplied this approach for mapping urban areas of all 654 Chinese cities and\ncompared them with those interpreted from mid-resolution remote sensing images\nand inferred by population density and road intersections. Our proposed\nframework is proved to be more straight-forward, time-saving and fine-scaled,\ncompared with other existing ones, and reclaim the need for consistency,\nefficiency and availability in defining urban areas with well-consideration of\nomnipresent spatial and functional factors across cities.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.5864v1"
    },
    {
        "title": "Marine Buoy Location Finding and Tracking System for Linux Supporting\n  Mobiles",
        "authors": [
            "Harikrishnan. R",
            "Shajna S. Hammed",
            "P. Malini"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Marine buoy is an important part of underwater acoustic communication system.\nIt is of great significance to track and locate it. It is widely used in ocean\nenvironment three - dimensional monitoring, underwater multimedia\ncommunication, underwater mobile carrier navigation and positioning, marine\nresources detection, remote control of submarine topography mapping and\noffshore oil industry, data acquisition, etc. This paper describes the\napplication of the monitoring service of GPRS / GPS module at Marine buoy. It\ncan achieve real - time location of underwater acoustic communication devices\nand route tracking to avoid the loss of the device, as well as assist to\nretrieve the lost device.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.6919v1"
    },
    {
        "title": "Multiple-Population Moment Estimation: Exploiting Inter-Population\n  Correlation for Efficient Moment Estimation in Analog/Mixed-Signal Validation",
        "authors": [
            "Chenjie Gu",
            "Manzil Zaheer",
            "Xin Li"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Moment estimation is an important problem during circuit validation, in both\npre-Silicon and post-Silicon stages. From the estimated moments, the\nprobability of failure and parametric yield can be estimated at each circuit\nconfiguration and corner, and these metrics are used for design optimization\nand making product qualification decisions. The problem is especially difficult\nif only a very small sample size is allowed for measurement or simulation, as\nis the case for complex analog/mixed-signal circuits. In this paper, we propose\nan efficient moment estimation method, called Multiple-Population Moment\nEstimation (MPME), that significantly improves estimation accuracy under small\nsample size. The key idea is to leverage the data collected under different\ncorners/configurations to improve the accuracy of moment estimation at each\nindividual corner/configuration. Mathematically, we employ the hierarchical\nBayesian framework to exploit the underlying correlation in the data. We apply\nthe proposed method to several datasets including post-silicon measurements of\na commercial high-speed I/O link, and demonstrate an average error reduction of\nup to 2$\\times$, which can be equivalently translated to significant reduction\nof validation time and cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1403.7872v1"
    },
    {
        "title": "Cognitive Coordination of Global Service Delivery",
        "authors": [
            "Lav R. Varshney",
            "Shivali Agarwal",
            "Yi-Min Chee",
            "Renuka R. Sindhgatta",
            "Daniel V. Oppenheim",
            "Juhnyoung Lee",
            "Krishna Ratakonda"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Formal coordination mechanisms are of growing importance as human-based\nservice delivery becomes more globalized and informal mechanisms are no longer\neffective. Further it is becoming apparent that business environments,\ncommunication among distributed teams, and work performance are all subject to\nendogenous and exogenous uncertainty.\n  This paper describes a stochastic model of service requests in global service\ndelivery and then puts forth a cognitive approach for coordination in the face\nof uncertainty, based on a perception-action loop and receding horizon control.\nOptimization algorithms used are a mix of myopic dynamic programming and\nconstraint-based programming. The coordination approach described has been\ndeployed by a globally integrated enterprise in a very large-scale global\ndelivery system and has been demonstrated to improve work efficiency by 10-15%\nas compared to manual planning.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0215v1"
    },
    {
        "title": "VirtuMob : Remote Desktop Virtualization Solution for Smarphones",
        "authors": [
            "M H Soorajprasad",
            "Balapradeep K N",
            "Antony P J"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Mobility is an important attribute in todays computing world. Mobile\ndevices,smartphone and tablet PC are becoming an integral part of human life\nbecause they are most effective and convenient communication tools. This paper\nproposes a system to connect and access the desktops of remote computer systems\nusing an android based Smartphone. Virtual Network Computing based architecture\nis used to develop the proposed system. Through a VirtuMob viewer provided on\nthe users Smartphone, the user will be able to access and manipulate the\ndesktops of remote computers. Several functionality such as viewing the\ndesktop, mouse operations, keyboard operations, manipulation of documents can\nbe performed from the Smartphone. VirtuMob server should be running on the\nremote system and it must be attached to a network. VirtuMob Accelerator is\nused to process the RFB frames of the desktop, perform Encoding of the frames\nand then relay the frames to the viewer over the internet. Several Encoding\ntechniques are studied and analysed to determine which is best suited for the\nproposed system.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0253v1"
    },
    {
        "title": "Optimizing the flash-RAM energy trade-off in deeply embedded systems",
        "authors": [
            "James Pallister",
            "Kerstin Eder",
            "Simon Hollis"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Deeply embedded systems often have the tightest constraints on energy\nconsumption, requiring that they consume tiny amounts of current and run on\nbatteries for years. However, they typically execute code directly from flash,\ninstead of the more energy efficient RAM. We implement a novel compiler\noptimization that exploits the relative efficiency of RAM by statically moving\ncarefully selected basic blocks from flash to RAM. Our technique uses integer\nlinear programming, with an energy cost model to select a good set of basic\nblocks to place into RAM, without impacting stack or data storage.\n  We evaluate our optimization on a common ARM microcontroller and succeed in\nreducing the average power consumption by up to 41% and reducing energy\nconsumption by up to 22%, while increasing execution time. A case study is\npresented, where an application executes code then sleeps for a period of time.\nFor this example we show that our optimization could allow the application to\nrun on battery for up to 32% longer. We also show that for this scenario the\ntotal application energy can be reduced, even if the optimization increases the\nexecution time of the code.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0403v2"
    },
    {
        "title": "A.Q.M.E.I.S.: Air Quality Meteorological and Enviromental Information\n  System in Western Macedonia, Hellas",
        "authors": [
            "Ioannis A. Skordas",
            "George F. Fragulis",
            "Athanassios G. Triantafyllou"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  An operational monitoring, as well as high resolution local-scale\nmeteorological and air quality forecasting information system for Western\nMacedonia, Hellas, has been developed and is operated by the Laboratory of\nAtmospheric Pollution and Environmental Physics / TEI Western Macedonia since\n2002, continuously improved. In this paper the novelty of information system is\npresented, in a dynamic, easily accessible and user-friendly manner. It\nconsists of a structured system that users have access to and they can\nmanipulate thoroughly, as well as of a system for accessing and managing\nresults of measurements in a direct and dynamic way. It provides updates about\nthe weather and pollution forecast for the next few days (based on current day\ninformation) in Western Macedonia. These forecasts are displayed through\ndynamic-interactive web charts and the visual illustration of the atmospheric\npollution of the region in a map using images and animation images.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.0975v1"
    },
    {
        "title": "Load Hiding of Household's Power Demand",
        "authors": [
            "Dominik Egarter",
            "Christoph Prokop",
            "Wilfried Elmenreich"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  With the development and introduction of smart metering, the energy\ninformation for costumers will change from infrequent manual meter readings to\nfine-grained energy consumption data. On the one hand these fine-grained\nmeasurements will lead to an improvement in costumers' energy habits, but on\nthe other hand the fined-grained data produces information about a household\nand also households' inhabitants, which are the basis for many future privacy\nissues. To ensure household privacy and smart meter information owned by the\nhousehold inhabitants, load hiding techniques were introduced to obfuscate the\nload demand visible at the household energy meter. In this work, a\nstate-of-the-art battery-based load hiding (BLH) technique, which uses a\ncontrollable battery to disguise the power consumption and a novel load hiding\ntechnique called load-based load hiding (LLH) are presented. An LLH system uses\nan controllable household appliance to obfuscate the household's power demand.\nWe evaluate and compare both load hiding techniques on real household data and\nshow that both techniques can strengthen household privacy but only LLH can\nincrease appliance level privacy.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.2534v1"
    },
    {
        "title": "Faithful Glitch Propagation in Binary Circuit Models",
        "authors": [
            "Matthias Fgger",
            "Robert Najvirt",
            "Thomas Nowak",
            "Ulrich Schmid"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Modern digital circuit design relies on fast digital timing simulation tools\nand, hence, on accurate binary-valued circuit models that faithfully model\nsignal propagation, even throughout a complex design. Unfortunately, it was\nrecently proved [F\\\"ugger et al., ASYNC'13] that no existing binary-valued\ncircuit model proposed so far, including the two most commonly used pure and\ninertial delay channels, faithfully captures glitch propagation: For the simple\nShort-Pulse Filtration (SPF) problem, which is related to a circuit's ability\nto suppress a single glitch, we showed that the quite broad class of bounded\nsingle-history channels either contradict the unsolvability of SPF in bounded\ntime or the solvability of SPF in unbounded time in physical circuits.\n  In this paper, we propose a class of binary circuit models that do not suffer\nfrom this deficiency: Like bounded single-history channels, our involution\nchannels involve delays that may depend on the time of the previous output\ntransition. Their characteristic property are delay functions which are based\non involutions, i.e., functions that form their own inverse. A concrete example\nof such a delay function, which is derived from a generalized first-order\nanalog circuit model, reveals that this is not an unrealistic assumption. We\nprove that, in sharp contrast to what is possible with bounded single-history\nchannels, SPF cannot be solved in bounded time due to the nonexistence of a\nlower bound on the delay of involution channels, whereas it is easy to provide\nan unbounded SPF implementation. It hence follows that binary-valued circuit\nmodels based on involution channels allow to solve SPF precisely when this is\npossible in physical circuits. To the best of our knowledge, our model is hence\nthe very first candidate for a model that indeed guarantees faithful glitch\npropagation.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.2544v1"
    },
    {
        "title": "Optimal Gaussian Filter for Effective Noise Filtering",
        "authors": [
            "Sunil Kopparapu",
            "M Satish"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper we show that the knowledge of noise statistics contaminating a\nsignal can be effectively used to choose an optimal Gaussian filter to\neliminate noise. Very specifically, we show that the additive white Gaussian\nnoise (AWGN) contaminating a signal can be filtered best by using a Gaussian\nfilter of specific characteristics. The design of the Gaussian filter bears\nrelationship with the noise statistics and also some basic information about\nthe signal. We first derive a relationship between the properties of the\nGaussian filter, noise statistics and the signal and later show through\nexperiments that this relationship can be used effectively to identify the\noptimal Gaussian filter that can effectively filter noise.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.3172v1"
    },
    {
        "title": "Integration of Legacy Appliances into Home Energy Management Systems",
        "authors": [
            "Dominik Egarter",
            "Andrea Monacchi",
            "Tamer Khatib",
            "Wilfried Elmenreich"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The progressive installation of renewable energy sources requires the\ncoordination of energy consuming devices. At consumer level, this coordination\ncan be done by a home energy management system (HEMS). Interoperability issues\nneed to be solved among smart appliances as well as between smart and\nnon-smart, i.e., legacy devices. We expect current standardization efforts to\nsoon provide technologies to design smart appliances in order to cope with the\ncurrent interoperability issues. Nevertheless, common electrical devices affect\nenergy consumption significantly and therefore deserve consideration within\nenergy management applications. This paper discusses the integration of smart\nand legacy devices into a generic system architecture and, subsequently,\nelaborates the requirements and components which are necessary to realize such\nan architecture including an application of load detection for the\nidentification of running loads and their integration into existing HEM\nsystems. We assess the feasibility of such an approach with a case study based\non a measurement campaign on real households. We show how the information of\ndetected appliances can be extracted in order to create device profiles\nallowing for their integration and management within a HEMS.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.3252v1"
    },
    {
        "title": "Simulation of Pedestrian Movements Using Fine Grid Cellular Automata\n  Model",
        "authors": [
            "Siamak Sarmady",
            "Fazilah Haron",
            "Abdullah Zawawi Talib"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Crowd simulation is used for evacuation and crowd safety inspections, study\nof performance in crowd systems and animations. Cellular automata has been\nextensively used in modelling the crowd. In regular cellular automata models,\neach pedestrian occupies a single cell with the size of a pedestrian body.\nSince the space is divided into relatively large cells, the movements of\npedestrians look like the movements of pieces on a chess board. Furthermore,\nall pedestrians have the same body size and speed. In this paper, a method\ncalled fine grid cellular automata is proposed in which smaller cells are used\nand pedestrian body may occupy several cells. The model allows the use of\ndifferent body sizes, shapes and speeds for pedestrian.\n  The proposed model is used for simulating movements of pedestrians toward a\ntarget. A typical walkway scenario is used to test and evaluate the model. The\nmovements of pedestrians are smoother because of the finer grain discretization\nof movements and the simulation results match empirical speed-density graphs\nwith good accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.3567v1"
    },
    {
        "title": "High Performance Network-on-Chips (NoCs) Design: Performance Modeling,\n  Routing Algorithm and Architecture Optimization",
        "authors": [
            "Zhiliang Qian"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  With technology scaling down, hundreds and thousands processing elements\n(PEs) can be integrated on a single chip. Network-on-chip (NoC) has been\nproposed as an efficient solution to handle this distinctive challenge. In this\nthesis, we have explored the high performance NoC design for MPSoC and CMP\nstructures from the performance modeling in the offline design phase to the\nrouting algorithm and NoC architecture optimization. More specifically, we\nfirst deal with the issue of how to estimate an NoC design fast and accurately\nin the synthesis inner loop. For this purpose, we propose a machine learning\nbased latency regression model to evaluate the NoC designs with respect to\ndifferent configurations. Then, for high performance NoC designs, we tackle one\nof the most important problems, i.e., the routing algorithms design. For\navoiding temperature hotspots, a thermal-aware routing algorithm is proposed to\nachieve an even temperature profile for application-specific Network-on-chips\n(NoCs). For improving the reliability, a routing algorithm to achieve maximum\nperformance under fault is proposed. Finally, in the architecture level, we\npropose two new NoC structures using bi-directional links for the performance\noptimization. In particular, we propose a flit-level speedup scheme to enhance\nthe network-on-chip(NoC) performance utilizing bidirectional channels. We also\npropose a flexible NoC architecture which takes advantage of a dynamic\ndistributed routing algorithm and improves the NoC communication performance\nwith moderate energy overhead. From the simulation results on both synthetic\ntraffic and real workload traces, significant performance improvement in terms\nof latency and throughput can be achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.3790v1"
    },
    {
        "title": "Implementation of Tic-Tac-Toe Game in LabVIEW",
        "authors": [
            "Lalitha Saroja Thota",
            "Manal Elsayeed",
            "Naseema Shaik",
            "Tayf Abdullah Ghawa",
            "Ahlam Rashed",
            "Mona Refdan",
            "Wejdan Mohammed",
            "Rawan Ali",
            "Suresh Babu Changalasetty"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Tic-Tac-Toe game can be played by two players where the square block (3 x 3)\ncan be filled with a cross (X) or a circle (O). The game will toggle between\nthe players by giving the chance for each player to mark their move. When one\nof the players make a combination of 3 same markers in a horizontal, vertical\nor diagonal line the program will display which player has won, whether X or O.\nIn this paper, we implement a 3x3 tic-tac-toe game in LabVIEW. The game is\ndesigned so that two players can play tic-tac-toe using LabVIEW software. The\nprogram will contain a display function and a select function to place the\nsymbol as well as toggle between the symbols allowing each player a turn to\nplay the game. The program will update after each player makes their move and\ncheck for the conditions of game as it goes on. Overall program works without\nany bugs and is able to use\n",
        "pdf_link": "http://arxiv.org/pdf/1406.5177v1"
    },
    {
        "title": "Midiendo la calidad de la informacion gestionada: algunas reflexiones\n  conceptuales-metodologicas",
        "authors": [
            "C. L. Gonzlez-Valiente"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The study, based on a documental classic analysis, presents conceptual and\nmethodological guidelines concerning the design of methodologies that help to\nmeasure the quality of information that is managed in organizations. It is\ndescribed the process of information management and the importance of\nimplementing quality principles in it. There are exposed the four dimensions of\ninformation quality as part of an indicators integration which characterize the\ninformational contents. There are defined each of the phases in the\nmethodological design to evaluate the information. There also are indicated the\nimplications of this activity for information professionals.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.6277v1"
    },
    {
        "title": "Big Models: From Beijing to the whole China",
        "authors": [
            "Ying Long",
            "Kang Wu",
            "Jianghao Wang",
            "Zhenjiang Shen"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper propose the concept of big model as a novel research paradigm for\nregional and urban studies. Big models are fine-scale regional/urban simulation\nmodels for a large geographical area, and they overcome the trade-off between\nsimulated scale and spatial unit by tackling both of them at the same time\nenabled by emerging big/open data, increasing computation power and matured\nregional/urban modeling methods. The concept, characteristics, and potential\napplications of big models have been elaborated. We addresse several case\nstudies to illustrate the progress of research and utilization on big models,\nincluding mapping urban areas for all Chinese cities, performing parcel-level\nurban simulation, and several ongoing research projects. Most of these\napplications can be adopted across the country, and all of them are focusing on\na fine-scale level, such as a parcel, a block, or a township (sub-district),\nwhich is not the same with the existing studies using conventional models that\nare only suitable for a certain single or two cities or regions, or for a\nlarger area but have to significantly sacrifice the data resolution. It is\nexpected that big models will mark a promising new era for the urban and\nregional study in the age of big data.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.6417v1"
    },
    {
        "title": "Low-Complexity Variable Forgetting Factor Constrained Constant Modulus\n  RLS Algorithm for Adaptive Beamforming",
        "authors": [
            "Q. Boya",
            "Y. Cai",
            "B. Champagne",
            "R. C. de Lamare",
            "M. Zhao"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper, a recursive least squares (RLS) based blind adaptive\nbeamforming algorithm that features a new variable forgetting factor (VFF)\nmechanism is presented. The beamformer is designed according to the constrained\nconstant modulus (CCM) criterion, and the proposed adaptive algorithm operates\nin the generalized sidelobe canceler (GSC) structure. A detailed study of its\noperating properties is carried out, including a convexity analysis and a mean\nsquared error (MSE) analysis of its steady-state behavior. The results of\nnumerical experiments demonstrate that the proposed VFF mechanism achieves a\nsuperior learning and tracking performance compared to other VFF mechanisms.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.6998v1"
    },
    {
        "title": "E-Learning Quality Criteria and Aspects",
        "authors": [
            "Reema Ajmera",
            "Dinesh Kumar dharamdasani"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  As IT grows the impact of new technology reflects in more or less every\nfield. Education also gets new dimensions with the advancement in IT sector.\nNowadays education is not limited to books and black boards only it gets a new\nway i.e. electronic media. Although with e-learning, the education having\nbroader phenomena, yet it is in budding stage. Quality is a crucial issue for\neducation as well as e-learning. It is required to serve qualitative and\nstandardization education. Quality cannot be expressed and set by a simple\ndefinition, since in itself quality is a very abstract notion. The specified\ncontext and the perspectives of users need to be taken into account when\ndefining quality in e-learning. It is also essential to classify suitable\ncriteria to address quality.\n",
        "pdf_link": "http://arxiv.org/pdf/1406.7744v1"
    },
    {
        "title": "Triple Patterning Lithography (TPL) Layout Decomposition using\n  End-Cutting (JM3 Special Session)",
        "authors": [
            "Bei Yu",
            "Subhendu Roy",
            "Jhih-Rong Gao",
            "David Z. Pan"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Triple patterning lithography (TPL) is one of the most promising techniques\nin the 14nm logic node and beyond. Conventional LELELE type TPL technology\nsuffers from native conflict and overlapping problems. Recently, as an\nalternative process, triple patterning lithography with end cutting (LELE-EC)\nwas proposed to overcome the limitations of LELELE manufacturing. In LELE-EC\nprocess the first two masks are LELE type double patterning, while the third\nmask is used to generate the end-cuts. Although the layout decomposition\nproblem for LELELE has been well-studied in the literature, only few attempts\nhave been made to address the LELE-EC layout decomposition problem. In this\npaper we propose the comprehensive study for LELE-EC layout decomposition.\nConflict graph and end-cut graph are constructed to extract all the geometrical\nrelationships of both input layout and end-cut candidates. Based on these\ngraphs, integer linear programming (ILP) is formulated to minimize the conflict\nnumber and the stitch number. The experimental results demonstrate the\neffectiveness of the proposed algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.0407v1"
    },
    {
        "title": "Precision of Pulse-Coupled Oscillator Synchronization on FPGA-Based\n  Radios",
        "authors": [
            "Gnther Brandner",
            "Johannes Klinglmayr",
            "Udo Schilcher",
            "Dominik Egarter",
            "Christian Bettstetter"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The precision of synchronization algorithms based on the theory of\npulse-coupled oscillators is evaluated on FPGA-based radios for the first time.\nMeasurements show that such algorithms can reach precision in the low\nmicrosecond range when being implemented in the physical layer. Furthermore, we\npropose an algorithm extension accounting for phase rate deviations of the\nhardware and show that an improved precision below one microsecond is possible\nwith this extension in the given setup. The resulting algorithm can thus be\napplied in ad hoc wireless systems for fully distributed synchronization of\ntransmission slots or sleep cycles, in particular, if centralized\nsynchronization is impossible.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.0652v2"
    },
    {
        "title": "e-Installation: Synesthetic Documentation of Media Art via Telepresence\n  Technologies",
        "authors": [
            "Jess Muoz Morcillo",
            "Florian Faion",
            "Antonio Zea",
            "Uwe D. Hanebeck",
            "Caroline Y. Robertson-von Trotha"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper, a new synesthetic documentation method that contributes to\nmedia art conservation is presented. This new method is called e-Installation\nin analogy to the idea of the e-Book as the electronic version of a real book.\nAn e-Installation is a virtualized media artwork that reproduces all\nsynesthesia, interaction, and meaning levels of the artwork. Advanced 3D\nmodeling and telepresence technologies with a very high level of immersion\nallow the virtual re-enactment of works of media art that are no longer\nperformable or rarely exhibited. The virtual re-enactment of a media artwork\ncan be designed with a scalable level of complexity depending on whether it\naddresses professionals such as curators, art restorers, and art theorists or\nthe general public. An e-Installation is independent from the artwork's\nphysical location and can be accessed via head-mounted display or similar data\ngoggles, computer browser, or even mobile devices. In combination with\ninformational and preventive conservation measures, the e-Installation offers\nan intermediate and long-term solution to archive, disseminate, and pass down\nthe milestones of media art history as a synesthetic documentation when the\noriginal work can no longer be repaired or exhibited in its full function.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.1362v1"
    },
    {
        "title": "Stress-Minimizing Orthogonal Layout of Data Flow Diagrams with Ports",
        "authors": [
            "Ulf Regg",
            "Steve Kieffer",
            "Tim Dwyer",
            "Kim Marriott",
            "Michael Wybrow"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  We present a fundamentally different approach to orthogonal layout of data\nflow diagrams with ports. This is based on extending constrained stress\nmajorization to cater for ports and flow layout. Because we are minimizing\nstress we are able to better display global structure, as measured by several\ncriteria such as stress, edge-length variance, and aspect ratio. Compared to\nthe layered approach, our layouts tend to exhibit symmetries, and eliminate\ninter-layer whitespace, making the diagrams more compact.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.4626v1"
    },
    {
        "title": "Tools and Techniques for Efficient High-Level System Design on FPGAs",
        "authors": [
            "Adrian J. Chung",
            "Kathryn Cobden",
            "Mark Jervis",
            "Martin Langhammer",
            "Bogdan Pasca"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In order for FPGAs to be successful outside traditional markets, tools which\nenable software programmers to achieve high levels of system performance while\nabstracting away the FPGA-specific details are needed. DSPB Builder Advanced\n(DSPBA) is one such tool. DSPBA provides model-based design environment using\nMatlab's Simulink frontend that decouples the fully-algorithmic design\ndescription from the details of FPGA system generation. DSPBA offers several\nlevels of debugging: from Simulink scopes to bit-accurate-simulation and silver\nreference models. It also offers the most comprehensive set of fixed-point,\nfloating-point and signal-processing IPs available today. The combination of 7\nfloating-point precisions, fused-datapath support, custom operator support and\nautomated folding allows exploring the best tradeoffs between accuracy, size\nand throughput. The DSPBA backend protects users from the details of\ndevice-dependent operator mapping offering both efficiency and prompt support\nfor new devices and features such as the Arria10 floating-point cores. The\ncollection of features available in DSPBA allows both unexperienced and expert\nusers to efficiently migrate performance-crucial systems to the FPGA\narchitecture.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.4797v1"
    },
    {
        "title": "OpenHEC: A Framework for Application Programmers to Design FPGA-based\n  Systems",
        "authors": [
            "Zhilei Chai",
            "Zhibin Wang",
            "Wenmin Yang",
            "Shuai Ding",
            "Yuanpu Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Today, there is a trend to incorporate more intelligence (e.g., vision\ncapabilities) into a wide range of devices, which makes high performance a\nnecessity for computing systems. Furthermore, for embedded systems, low power\nconsumption should be generally considered together with high computing\nperformance. FPGAs, as programmable logic devices able to support different\ntypes of fine-grained parallelisms, their power and performance advantages were\nrecognized widely. However, designing applications on FPGA-based systems is\ntraditionally far from a task can be carried out by software programmers.\nGenerally, hardware engineers and even system-level software engineers have\nmore hardware/architectural knowledge but fewer algorithm and application\nknowledge. Thus, it is critical for computing systems to allow\napplication-level programmers to realize their idea conveniently, which is\npopular in computing systems based on the general processor. In this paper, the\nOpenHEC (Open Framework for High-Efficiency Computing) framework is proposed to\nprovide a design framework for application-level software programmers to use\nFPGA-based platforms. It frees users from hardware and architectural details to\nlet them focus more on algorithms/applications. This framework was integrated\nwith the commercial Xilinx ISE/Vivado to make it to be used immediately. After\nimplementing a widely-used feature detection algorithm on OpenHEC from the\nperspective of software programmers, it shows this framework is applicable for\napplication programmers with little hardware knowledge.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5347v1"
    },
    {
        "title": "High-Level Design of Portable and Scalable FPGA Accelerators",
        "authors": [
            "Markus Weinhardt",
            "Rainer Hckmann",
            "Thomas Kinder"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper presents our approach for making FPGA accelerators accessible to\nsoftware (SW) programmers. It is intended as a starting point for\ncollaborations with other groups pursuing similar objectives. We report on our\ncurrent SAccO platform (Scalable Accelerator platform Osnabr\\\"uck) and the\nplanned project extending this platform.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5383v1"
    },
    {
        "title": "Stream Processor Generator for HPC to Embedded Applications on\n  FPGA-based System Platform",
        "authors": [
            "Kentaro Sano",
            "Hayato Suzuki",
            "Ryo Ito",
            "Tomohiro Ueno",
            "Satoru Yamamoto"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper presents a stream processor generator, called SPGen, for\nFPGA-based system-on-chip platforms. In our research project, we use an FPGA as\na common platform for applications ranging from HPC to embedded/robotics\ncomputing. Pipelining in application-specific stream processors brings FPGAs\npower-efficient and high-performance computing. However, poor productivity in\ndeveloping custom pipelines prevents the reconfigurable platform from being\nwidely and easily used. SPGen aims at assisting developers to design and\nimplement high-throughput stream processors by generating their HDL codes with\nour domain-specific high-level stream processing description, called SPD.With\nan example of fluid dynamics computation, we validate SPD for describing a real\napplication and verify SPGen for synthesis with a pipelined data-flow graph. We\nalso demonstrate that SPGen allows us to easily explore a design space for\nfinding better implementation than a hand-designed one.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5386v1"
    },
    {
        "title": "High-Level Synthesis Case Study: Implementation of a Memcached Server",
        "authors": [
            "Kimon Karras",
            "Michaela Blott",
            "Kees Vissers"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  High-Level Synthesis (HLS) aspires to raise the level of abstraction in\nhardware design without sacrificing hardware efficiency. It has so far been\nsuccessfully employed in signal and video processing but has found only limited\nuse in other areas. This paper utilizes a commercial HLS tool, namely Vivado(R)\nHLS, to implement the processing of a common data center application, the\nKey-Value Store (KVS) application memcached, as a deeply pipelined dataflow\narchitecture. We compared our results to a fully equivalent RTL implementation\ndone previously in our group and found that it matches its performance, yields\ntangible improvements in latency (between 7-30%) and resource consumption (22%\nin LUTs and 35% in registers), all while requiring 3x less lines of code and 2x\nless development time. The implementation was validated in hardware on a\nXilinx(R) VC709 development board, meeting timing requirements for 10Gbps line\nrate processing.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.5387v1"
    },
    {
        "title": "SFA Referee Allocation Scheme",
        "authors": [
            "Nikolaos Polatidis"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  For many sports, the allocation of officials to matches is performed manually\nand is a very time consuming procedure. For the Scottish Football Association\n(SFA), the allocation of referees and other officials to matches is governed by\na number of rules specifying the expertise required from the different types of\nofficial at each level, e.g. Scottish Premiership League referee must be a\ngrade 1 with high experience. The allocation requires an SFA secretary to\nexpend several hours to find suitable officials, contact them and assign them.\nMost of the time, the secretary is a volunteer who performs the allocation as a\nhobby and it would be useful to reduce his costs and time.\n  The project aims to reduce the burden on SFA, and potentially other\nsecretaries, by developing a program to assign SFA officials. A suitable\nalgorithm must be devised to search through the set of data about matches and\nofficials and find a potential allocation. The program then updates the\ndatabase with the new data, and provides a web interface for both secretaries\nand officials.\n  A prototype system using the new greedy algorithm has been implemented and\nevaluated with SFA secretaries. A final usable referee allocation system has\nbeen designed that uses the greedy algorithm, and is extended after evaluation\nof the prototype. The final allocation system based provides both a command\nline and a web interface and has also been evaluated by SFA secretaries. In\ntheir letters of recommendation in Appendix F the SFA secretaries indicate that\nthe final allocation system it will be used again in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.6661v1"
    },
    {
        "title": "Systems, Resilience, and Organization: Analogies and Points of Contact\n  with Hierarchy Theory",
        "authors": [
            "Vincenzo De Florio"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Aim of this paper is to provide preliminary elements for discussion about the\nimplications of the Hierarchy Theory of Evolution on the design and evolution\nof artificial systems and socio-technical organizations. In order to achieve\nthis goal, a number of analogies are drawn between the System of Leibniz; the\nsocio-technical architecture known as Fractal Social Organization; resilience\nand related disciplines; and Hierarchy Theory. In so doing we hope to provide\nelements for reflection and, hopefully, enrich the discussion on the above\ntopics with considerations pertaining to related fields and disciplines,\nincluding computer science, management science, cybernetics, social systems,\nand general systems theory.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.0092v3"
    },
    {
        "title": "Semantic-based Detection of Segment Outliers and Unusual Events for\n  Wireless Sensor Networks",
        "authors": [
            "Lianli Gao",
            "Michael Bruenig",
            "Jane Hunter"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Environmental scientists have increasingly been deploying wireless sensor\nnetworks to capture valuable data that measures and records precise information\nabout our environment. One of the major challenges associated with wireless\nsensor networks is the quality of the data and more specifically the detection\nof segment outliers and unusual events. Most previous research has focused on\ndetecting outliers that are errors that are caused by unreliable sensors and\nsensor nodes. However, there is an urgent need for the development of new tools\ncapable of identifying, tagging and visualizing erroneous segment outliers and\nunusual events from sensor data streams. In this paper, we present a SOUE\nDetector (Segment Outlier and Unusual Event-Detector) system for wireless\nsensor networks that combines statistical analyses using Dynamic Time Warping\n(DTW) with domain expert knowledge (captured via an ontology and semantic\ninferencing rules). The resulting Web portal enables scientist to efficiently\nsearch across a collection of wireless sensor data streams and identify,\nretrieve and display segment outliers (both erroneous and genuine) within the\ndata streams. In this paper, we firstly describe the detection algorithms, the\nimplementation details and the functionality of the SOUE Detector system.\nSecondly we evaluate our approach using data that comprises sensor observations\ncollected from a sensor network deployed in the Springbrook National Park in\nQueensland, Australia. The experimental results show that the SOUE-Detector can\nefficiently detect segment outliers and unusual events with high levels of\nprecision and recall.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.2188v1"
    },
    {
        "title": "High gain two-stage amplifier with positive capacitive feedback\n  compensation",
        "authors": [
            "Alireza Mesri",
            "Mahmoud Mahdipour Pirbazari",
            "Khayrollah Hadidi",
            "Abdollah Khoei"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  A novel topology for a high gain two-stage amplifier is proposed. The\nproposed circuit is designed in a way that the non-dominant pole is at output\nof the first stage. A positive capacitive feedback (PCF) around the second\nstage introduces a left half plane (LHP) zero which cancels the phase shift\nintroduced by the non-dominant pole, considerably. The dominant pole is at the\noutput node which means that increasing the load capacitance has minimal effect\non stability. Moreover, a simple and effective method is proposed to enhance\nslew rate. Simulation shows that slew rate is improved by a factor of 2.44\nusing the proposed method. The proposed amplifier is designed in a 0.18um CMOS\nprocess. It consumes 0.86mW power from a 1.8V power supply and occupies\n3038.5um2 of chip area. The DC gain is 82.7dB and gain bandwidth (GBW) is 88.9\nMHz when driving a 5pF capacitive load. Also low frequency CMRR and PSRR+ are\n127dB and 83.2dB, respectively. They are 24.8dB and 24.2dB at GBW frequency,\nwhich are relatively high and are other important properties of the proposed\namplifier. Moreover, Simulations show convenient performance of the circuit in\nprocess corners and also presence of mismatch.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.3506v1"
    },
    {
        "title": "Routing Diverse Crowds in Emergency with Dynamic Grouping",
        "authors": [
            "Olumide J. Akinwande",
            "Huibo Bi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Evacuee routing algorithms in emergency typically adopt one single criterion\nto compute desired paths and ignore the specific requirements of users caused\nby different physical strength, mobility and level of resistance to hazard. In\nthis paper, we present a quality of service (QoS) driven multi-path routing\nalgorithm to provide diverse paths for different categories of evacuees. This\nalgorithm borrows the concept of Cognitive Packet Network (CPN), which is a\nflexible protocol that can rapidly solve optimal solution for any user-defined\ngoal function. Spatial information regarding the location and spread of hazards\nis taken into consideration to avoid that evacuees be directed towards\nhazardous zones. Furthermore, since previous emergency navigation algorithms\nare normally insensitive to sudden changes in the hazard environment such as\nabrupt congestion or injury of civilians, evacuees are dynamically assigned to\nseveral groups to adapt their course of action with regard to their on-going\nphysical condition and environments. Simulation results indicate that the\nproposed algorithm which is sensitive to the needs of evacuees produces better\nresults than the use of a single metric. Simulations also show that the use of\ndynamic grouping to adjust the evacuees' category and routing algorithms with\nregard for their on-going health conditions and mobility, can achieve higher\nsurvival rates.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.3949v2"
    },
    {
        "title": "A dynamic mechanism of Alzheimer based on artificial neural network",
        "authors": [
            "Zhi Cheng"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper, we provide another angle to analyze the reasons why Alzheimer\nDisease exists. We analyze the dynamic mechanism of Alzheimer Disease based on\nthe cognitive model that established from artificial neural network. We can\nprovide some theoretic explanations to Alzheimer Disease through the analyzing\nof this model.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.4221v1"
    },
    {
        "title": "Hostile Intent Enumeration using Soft Computing Techniques",
        "authors": [
            "Souham Biswas",
            "Manisha J. Nene"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In any tactical scenario, the successful quantification and triangulation of\npotential hostile elements is instrumental to minimize any casualties which\nmight be incurred. The most commonly deployed infrastructures to cater to this\nhave mostly been surveillance systems which only extract some data pertaining\nto the targets of interest in the area of observation and convey the\ninformation to the human operators. Accordingly, with the ever increasing rate\nat which warfare tactics are evolving, there has been a growing need for\nsmarter solutions to this problem of hostile intent enumeration. Recently, a\nnumber of developments have been made to ameliorate the efficacy and the\ncertitude with which this task is performed. This paper discusses two of the\nmost prominent approaches which address this problem and posits the outline of\na novel solution which seeks to address the shortcomings faced by the existing\napproaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.5228v1"
    },
    {
        "title": "Spatiotemporal Modeling of a Pervasive Game",
        "authors": [
            "Kim J. L. Nevelsteen"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Given pervasive games that maintain a virtual spatiotemporal model of the\nphysical world, game designers must contend with space and time in the virtual\nand physical, but an integrated conceptual model is lacking. Because the\nproblem domains of GIS and Pervasive Games overlap, Peuquet's Triad\nRepresentational Framework is exapted, from the domain of GIS, and applied to\nPervasive Games. Using Dix et al.'s three types of space and Langran's notion\nof time, virtual time and space are then be mapped to the physical world and\nvice versa. The approach is evaluated using the pervasive game called Codename:\nHeroes, as case study.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.6907v4"
    },
    {
        "title": "Qubit Data Structures for Analyzing Computing Systems",
        "authors": [
            "Vladimir Hahanov",
            "Wajeb Gharibi",
            "Svetlana Chumachenko",
            "Eugenia Litvinova"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Qubit models and methods for improving the performance of software and\nhardware for analyzing digital devices through increasing the dimension of the\ndata structures and memory are proposed. The basic concepts, terminology and\ndefinitions necessary for the implementation of quantum computing when\nanalyzing virtual computers are introduced. The investigation results\nconcerning design and modeling computer systems in a cyberspace based on the\nuse of two-component structure <memory - transactions> are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.1402v1"
    },
    {
        "title": "Autonomous Load Disaggregation Approach based on Active Power\n  Measurements",
        "authors": [
            "Dominik Egarter",
            "Wilfried Elmenreich"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  With the help of smart metering valuable information of the appliance usage\ncan be retrieved. In detail, non-intrusive load monitoring (NILM), also called\nload disaggregation, tries to identify appliances in the power draw of an\nhousehold. In this paper an unsupervised load disaggregation approach is\nproposed that works without a priori knowledge about appliances. The proposed\nalgorithm works autonomously in real time. The number of used appliances and\nthe corresponding appliance models are learned in operation and are\nprogressively updated. The proposed algorithm is considering each useful and\nsuitable detected power state. The algorithm tries to detect power states\ncorresponding to on/off appliances as well as to multi-state appliances based\non active power measurements in 1s resolution. We evaluated the novel\nintroduced load disaggregation approach on real world data by testing the\npossibility to disaggregate energy demand on appliance level.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.2877v2"
    },
    {
        "title": "Personal Multi-threading",
        "authors": [
            "Jan A. Bergstra"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Multi-threading allows agents to pursue a heterogeneous collection of tasks\nin an orderly manner. The view of multi-threading that emerges from thread\nalgebra is applied to the case where a single agent, who may be human,\nmaintains a hierarchical multithread as an architecture of its own activities.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.3579v1"
    },
    {
        "title": "Domotic Embedded System",
        "authors": [
            "Lidia Dobrescu"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper presents an original domotic embedded system for room temperature\nmonitoring. The OpenRemote is the main software interface between the user and\nthe system, but other software components and communication protocols are used,\nsuch as 1-Wire protocol for temperature monitoring devices, RS-232 for the\ncentral PC unit and OWFS software for remote control using Android mobile\ndevices. The system architecture consists in hardware and software components\nto remote control a room temperature parameter for energy efficiency\nincreasing.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.4406v1"
    },
    {
        "title": "Cloud Enabled Emergency Navigation Using Faster-than-real-time\n  Simulation",
        "authors": [
            "Huibo Bi",
            "Erol Gelenbe"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  State-of-the-art emergency navigation approaches are designed to evacuate\ncivilians during a disaster based on real-time decisions using a pre-defined\nalgorithm and live sensory data. Hence, casualties caused by the poor decisions\nand guidance are only apparent at the end of the evacuation process and cannot\nthen be remedied. Previous research shows that the performance of routing\nalgorithms for evacuation purposes are sensitive to the initial distribution of\nevacuees, the occupancy levels, the type of disaster and its as well its\nlocations. Thus an algorithm that performs well in one scenario may achieve bad\nresults in another scenario. This problem is especially serious in\nheuristic-based routing algorithms for evacuees where results are affected by\nthe choice of certain parameters. Therefore, this paper proposes a\nsimulation-based evacuee routing algorithm that optimises evacuation by making\nuse of the high computational power of cloud servers. Rather than guiding\nevacuees with a predetermined routing algorithm, a robust Cognitive Packet\nNetwork based algorithm is first evaluated via a cloud-based simulator in a\nfaster-than-real-time manner, and any \"simulated casualties\" are then re-routed\nusing a variant of Dijkstra's algorithm to obtain new safe paths for them to\nexits. This approach can be iterated as long as corrective action is still\npossible.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.7059v2"
    },
    {
        "title": "Modified Design of Microstrip Patch Antenna for WiMAX Communication\n  System",
        "authors": [
            "Nidhi Kumari Lal",
            "Ashutosh Kumar Singh"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper, a new design for U-shaped microstrip patch antenna is\nproposed, which can be used in WiMAX communication systems. The aim of this\npaper is to optimize the performance of microstrip patch antenna. Nowadays,\nWiMAX communication applications are widely using U-shaped microstrip patch\nantenna and it has become very popular. Our proposed antenna design uses 4-4.5\nGHZ frequency band and it is working at narrowband within this band. RT/DUROID\n5880 material is used for creating the substrate of the microstrip antenna.\nThis modified design of the microstrip patch antenna gives high performance in\nterms of gain and return loss.\n",
        "pdf_link": "http://arxiv.org/pdf/1412.8561v1"
    },
    {
        "title": "ECPR: Environment- and Context-aware Combined Power and Rate Distributed\n  Congestion Control for Vehicular Communications",
        "authors": [
            "Bengi Aygun",
            "Mate Boban",
            "Alexander M. Wyglinski"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Safety and efficiency applications in vehicular networks rely on the exchange\nof periodic messages between vehicles. These messages contain position, speed,\nheading, and other vital information that makes the vehicles aware of their\nsurroundings. The drawback of exchanging periodic cooperative messages is that\nthey generate significant channel load. Decentralized Congestion Control (DCC)\nalgorithms have been proposed to minimize the channel load. However, while the\nrationale for periodic message exchange is to improve awareness, existing DCC\nalgorithms do not use awareness as a metric for deciding when, at what power,\nand at what rate the periodic messages need to be sent in order to make sure\nall vehicles are informed. We propose an environment- and context-aware DCC\nalgorithm combines power and rate control in order to improve cooperative\nawareness by adapting to both specific propagation environments (e.g., urban\nintersections, open highways, suburban roads) as well as application\nrequirements (e.g., different target cooperative awareness range). Studying\nvarious operational conditions (e.g., speed, direction, and application\nrequirement), ECPR adjusts the transmit power of the messages in order to reach\nthe desired awareness ratio at the target distance while at the same time\ncontrolling the channel load using an adaptive rate control algorithm. By\nperforming extensive simulations, including realistic propagation as well as\nenvironment modeling and realistic vehicle operational environments (varying\ndemand on both awareness range and rate), we show that ECPR can increase\nawareness by 20% while keeping the channel load and interference at almost the\nsame level. When permitted by the awareness requirements, ECPR can improve the\naverage message rate by 18% compared to algorithms that perform rate adaptation\nonly.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.00054v2"
    },
    {
        "title": "E-BLOW: E-Beam Lithography Overlapping aware Stencil Planning for MCC\n  System",
        "authors": [
            "Bei Yu",
            "Kun Yuan",
            "Jhih-Rong Gao",
            "David Z. Pan"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Electron beam lithography (EBL) is a promising maskless solution for the\ntechnology beyond 14nm logic node. To overcome its throughput limitation,\nindustry has proposed character projection (CP) technique, where some complex\nshapes (characters) can be printed in one shot. Recently the traditional EBL\nsystem is extended into multi-column cell (MCC) system to further improve the\nthroughput. In MCC system, several independent CPs are used to further speed-up\nthe writing process. Because of the area constraint of stencil, MCC system\nneeds to be packed/planned carefully to take advantage of the characters. In\nthis paper, we prove that the overlapping aware stencil planning (OSP) problem\nis NP-hard. To solve OSP problem in MCC system, we present a tool, E-BLOW, with\nseveral novel speedup techniques, such as successive relaxation, dynamic\nprogramming, and KD-Tree based clustering. Experimental results show that,\ncompared with previous works, E-BLOW demonstrates better performance for both\nconventional EBL system and MCC system.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.00621v1"
    },
    {
        "title": "CHAOS: Accurate and Realtime Detection of Aging-Oriented Failure Using\n  Entropy",
        "authors": [
            "Pengfei Chen",
            "Yong Qi",
            "Di Hou"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Even well-designed software systems suffer from chronic performance\ndegradation, also named \"software aging\", due to internal (e.g. software bugs)\nand external (e.g. resource exhaustion) impairments. These chronic problems\noften fly under the radar of software monitoring systems before causing severe\nimpacts (e.g. system failure). Therefore it's a challenging issue how to timely\ndetect these problems to prevent system crash. Although a large quantity of\napproaches have been proposed to solve this issue, the accuracy and\neffectiveness of these approaches are still far from satisfactory due to the\ninsufficiency of aging indicators adopted by them. In this paper, we present a\nnovel entropy-based aging indicator, Multidimensional Multi-scale Entropy\n(MMSE). MMSE employs the complexity embedded in runtime performance metrics to\nindicate software aging and leverages multi-scale and multi-dimension\nintegration to tolerate system fluctuations. Via theoretical proof and\nexperimental evaluation, we demonstrate that MMSE satisfies Stability,\nMonotonicity and Integration which we conjecture that an ideal aging indicator\nshould have. Based upon MMSE, we develop three failure detection approaches\nencapsulated in a proof-of-concept named CHAOS. The experimental evaluations in\na Video on Demand (VoD) system and in a real-world production system,\nAntVision, show that CHAOS can detect the failure-prone state in an\nextraordinarily high accuracy and a near 0 Ahead-Time-To-Failure (ATTF).\nCompared to previous approaches, CHAOS improves the detection accuracy by about\n5 times and reduces the ATTF even by 3 orders of magnitude. In addition, CHAOS\nis light-weight enough to satisfy the realtime requirement.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.00781v1"
    },
    {
        "title": "Etude des dterminants psychologiques de la persistance dans l'usage\n  d'un jeu srieux : valuation de l'environnement optimal d'apprentissage\n  avec Mecagenius?",
        "authors": [
            "Jean Heutte",
            "Michel Galaup",
            "Catherine Lelardeux",
            "Pierre Lagarrigue",
            "Fabien Fenouillet"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The aim of this paper is to show the relevance of motivational key concepts\nin evaluating the use of serious game. This research involves 115 students\ntraining with Mecagenius (serious game in mechanical engineering). The results\nof the exploratory study also confirm the relevance of the use of flow in\nEducation scale (EduFlow) to evaluate the optimal learning experienc ewith a\nserious game. It also appears that EduFlow is related to specific actions\nwithin the school context such as self-efficacy, motivational climate and\ninterest.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.01818v1"
    },
    {
        "title": "FRAME: Fast and Realistic Attacker Modeling and Evaluation for Temporal\n  Logical Correlation in Static Noise",
        "authors": [
            "Sungroh Yoon",
            "Nahmsuk Oh",
            "Peivand Tehrani",
            "Eui-Young Chung",
            "Giovanni De Micheli"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  We propose a method called Fast and Realistic Attacker Modeling and\nEvaluation (FRAME) that can reduce pessimism in static noise analysis by\nexploiting temporal logical correlation of attackers and using novel techniques\ntermed envelopes and $\\sigma$ functions. Unlike conventional pruning-based\napproaches, FRAME efficiently considers all relevant attackers, thereby\nproducing more realistic results. FRAME was tested with complex industrial\ndesign and successfully reduced the pessimism of conventional techniques by\n30.4% on average, with little computational overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.02236v1"
    },
    {
        "title": "Physical Biomodeling: a new field enabled by 3-D printing in biomodeling",
        "authors": [
            "Promita Chakraborty"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Accurate physical modeling with 3D-printing techniques could lead to new\napproaches to study structure and dynamics of biological systems complementing\ncomputational methods. Computational biology has become an important part of\nresearch over the last couple of decades. Now 3D printing technology opens the\ndoor for a new field, Physical Biomodeling, at the intersection of experimental\ndata, computational biology and physical modeling for study of biological\nsystems, such as protein folding at nano-scale. Here I explore this new domain\nof precision physical modeling and correlate it with existing visualization and\ncomputational systems and future possibilities. Dynamic physical models can be\ndesigned to-scale that can serve as research tools in future along with\nexisting biocomputational tools and databases, adding a third angle to tackle\nunsolved scientific problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.04687v2"
    },
    {
        "title": "Privately Information Sharing with Delusive Paths for Data Forwarding in\n  Vehicular Networks",
        "authors": [
            "Zhong Li",
            "Cheng Wang",
            "Lu Shao",
            "Changjun Jiang"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  We discuss how to efficiently forward data in vehicular networks. Existing\nsolutions do not make full use of trajectory planning of nearby vehicles, or\nsocial attributes. The development of onboard navigation system provides\ndrivers some traveling route information. The main novelty of our approach is\nto envision sharing partial traveling information to the encountered vehicles\nfor better service. Our data forwarding algorithm utilizes this lightweight\ninformation under the delusive paths privacy preservation together with the\nsocial community structure in vehicular networks. We assume that data\ntransmission is carried by vehicles and road side units (RSUs), while cellular\nnetwork manages and coordinates relevant global information. The approximate\ndestination set is the set of RSUs that are often passed by the destination\nvehicle. RSU importance is raised by summing encounter ratios of RSUs in the\nsame connected component. We first define a concept of space-time\napproachability which is derived from shared partial traveling route and\nencounter information. It describes the capability of a vehicle to advance\nmessages toward destination. Then, we design a novel data forwarding algorithm,\ncalled approachability based algorithm, which combines the space-time\napproachability with the social community attribute in vehicular networks. We\nevaluate our approachability based algorithm on data sets from San Francisco\nCabspotting and Shanghai Taxi Movement. Results show that the partially shared\ntraveling information plays a positive role in data forwarding in vehicular\nnetworks. Approachability based data forwarding algorithm achieves a better\nperformance than existing social based algorithms in vehicular networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.05551v2"
    },
    {
        "title": "Analysis of Lithography Based Approaches In development of Semi\n  Conductors",
        "authors": [
            "Jatin Chopra"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The end of the 19th century brought about a change in the dynamics of\ncomputing by the development of the microprocessor. Huge bedroom size computers\nbegan being replaced by portable, smaller sized desktops. Today the world is\ndominated by silicon, which has circumscribed chip development for computers\nthrough microprocessors. Majority of the integrated circuits that are\nmanufactured at present are developed using the concept of Lithography. This\npaper presents a detailed analysis of multiple Lithography methodologies as a\nmeans for advanced integrated circuit development. The study paper primarily\nrestricts to examples in the context of Lithography, surveying the various\nexisting techniques of Lithography in literature, examining feasible and\nefficient methods, highlighting the various pros and cons of each of them.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.05887v2"
    },
    {
        "title": "Converting ECG and other paper legated biomedical maps into digital\n  signals",
        "authors": [
            "A. R. Gomes e Silva",
            "H. M. de Oliveira",
            "R. D. Lins"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This paper presents a digital signal processing tool developed using\nMatlabTM, which provides a very low-cost and effective strategy for\nanalog-to-digital conversion of legated paper biomedical maps without requiring\ndedicated hardware. This software-based approach is particularly helpful for\ndigitalizing biomedical signals acquired from analogical devices equipped with\na plottingter. Albeit signals used in biomedical diagnosis are the primary\nconcern, this imaging processing tool is suitable to modernize facilities in a\nnon-expensive way. Legated paper ECG and EEG charts can be fast and efficiently\ndigitalized in order to be added in existing up-to-date medical data banks,\nimproving the follow-up of patients.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.05906v2"
    },
    {
        "title": "Improved Model for Wire-Length Estimation in Stochastic Wiring\n  Distribution",
        "authors": [
            "Mohamed S. Hefeida",
            "Masud H. Chowdhury"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This paper presents a pair of improved stochastic wiring distribution model\nfor better estimation of on-chip wire lengths. The proposed models provide 28 -\n50% reduction in error when estimating the average on-chip wire length compared\nto the estimation using the existing models. The impact of Rent's exponent on\nthe average wire length estimation is also investigated to demonstrate\nlimitations of the approximations used in some of the current models. To\nimprove the approximations of the model a new threshold for Rent's constant is\nrecommended. Simulation results demonstrate that proposed models with the new\nthreshold reduce the error of estimation by 38 to 75 percent compared to the\nprevious works.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.05931v1"
    },
    {
        "title": "Euclidean Distance Matrices: Essential Theory, Algorithms and\n  Applications",
        "authors": [
            "Ivan Dokmanic",
            "Reza Parhizkar",
            "Juri Ranieri",
            "Martin Vetterli"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Euclidean distance matrices (EDM) are matrices of squared distances between\npoints. The definition is deceivingly simple: thanks to their many useful\nproperties they have found applications in psychometrics, crystallography,\nmachine learning, wireless sensor networks, acoustics, and more. Despite the\nusefulness of EDMs, they seem to be insufficiently known in the signal\nprocessing community. Our goal is to rectify this mishap in a concise tutorial.\nWe review the fundamental properties of EDMs, such as rank or\n(non)definiteness. We show how various EDM properties can be used to design\nalgorithms for completing and denoising distance data. Along the way, we\ndemonstrate applications to microphone position calibration, ultrasound\ntomography, room reconstruction from echoes and phase retrieval. By spelling\nout the essential algorithms, we hope to fast-track the readers in applying\nEDMs to their own problems. Matlab code for all the described algorithms, and\nto generate the figures in the paper, is available online. Finally, we suggest\ndirections for further research.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07541v2"
    },
    {
        "title": "GREAT Process Modeller user manual",
        "authors": [
            "Urko Rueda",
            "Sergio Espaa",
            "Marcela Ruiz"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This report contains instructions to install, uninstall and use GREAT Process\nModeller, a tool that supports Communication Analysis, a communication-oriented\nbusiness process modelling method. GREAT allows creating communicative event\ndiagrams (i.e. business process models), specifying message structures (which\ndescribe the messages associated to each communicative event), and\nautomatically generating a class diagram (representing the data model of an\ninformation system that would support such organisational communication). This\nreport briefly describes the methodological background of the tool. This\nhandbook explains the modelling techniques in detail: Espa\\~na, S., A.\nGonz\\'alez, \\'O. Pastor and M. Ruiz (2012). Communication Analysis modelling\ntechniques. Technical report ProS-TR-2012-02, PROS Research Centre, Universitat\nPolit\\`ecnica de Val\\`encia, Spain, arXiv:1205.0987.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07693v1"
    },
    {
        "title": "Globally Optimal Crowdsourcing Quality Management",
        "authors": [
            "Akash Das Sarma",
            "Aditya Parameswaran",
            "Jennifer Widom"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  We study crowdsourcing quality management, that is, given worker responses to\na set of tasks, our goal is to jointly estimate the true answers for the tasks,\nas well as the quality of the workers. Prior work on this problem relies\nprimarily on applying Expectation-Maximization (EM) on the underlying maximum\nlikelihood problem to estimate true answers as well as worker quality.\nUnfortunately, EM only provides a locally optimal solution rather than a\nglobally optimal one. Other solutions to the problem (that do not leverage EM)\nfail to provide global optimality guarantees as well. In this paper, we focus\non filtering, where tasks require the evaluation of a yes/no predicate, and\nrating, where tasks elicit integer scores from a finite domain. We design\nalgorithms for finding the global optimal estimates of correct task answers and\nworker quality for the underlying maximum likelihood problem, and characterize\nthe complexity of these algorithms. Our algorithms conceptually consider all\nmappings from tasks to true answers (typically a very large number), leveraging\ntwo key ideas to reduce, by several orders of magnitude, the number of mappings\nunder consideration, while preserving optimality. We also demonstrate that\nthese algorithms often find more accurate estimates than EM-based algorithms.\nThis paper makes an important contribution towards understanding the inherent\ncomplexity of globally optimal crowdsourcing quality management.\n",
        "pdf_link": "http://arxiv.org/pdf/1502.07710v2"
    },
    {
        "title": "Parameter Estimation of Jelinski-Moranda Model Based on Weighted\n  Nonlinear Least Squares and Heteroscedasticity",
        "authors": [
            "Jingwei Liu",
            "Yi Liu",
            "Meizhi Xu"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Parameter estimation method of Jelinski-Moranda (JM) model based on weighted\nnonlinear least squares (WNLS) is proposed. The formulae of resolving the\nparameter WNLS estimation (WNLSE) are derived, and the empirical weight\nfunction and heteroscedasticity problem are discussed. The effects of\noptimization parameter estimation selection based on maximum likelihood\nestimation (MLE) method, least squares estimation (LSE) method and weighted\nnonlinear least squares estimation (WNLSE) method are also investigated. Two\nstrategies of heteroscedasticity decision and weighting methods embedded in JM\nmodel prediction process are also investigated. The experimental results on\nstandard software reliability analysis database-Naval Tactical Data System\n(NTDS) and three datasets used by J.D. Musa demonstrate that WNLSE method can\nbe superior to LSE and MLE under the relative error (RE) criterion.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.00094v1"
    },
    {
        "title": "Google-based Mode Choice Modeling Approach",
        "authors": [
            "Zohreh Ghasemi"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Microsimulation based frameworks have become very popular in many research\nareas including travel demand modeling where activity-based models have been in\nthe center of attention for the past decade. Advanced activity-based models\nsynthesize the entire population of the study region and simulate their\nactivities in a way that they can keep track of agents resources as well as\ntheir spatial location. However, the models that are built for these frameworks\ndo not take into account this information mainly because they do not have them\nat the modeling stage. This paper tries to describe the importance of this\ninformation by analyzing a travel survey and generate the actual alternatives\nthat individuals had when making their trips. With a focus on transit, the\nstudy reveals how transit alternatives are limited\\unavailable in certain areas\nwhich must be taken in to account in our mode choice models. Some statistics\nregarding available alternatives and the constraints people encounter when\nmaking a choice are presented with a comprehensive choice set formation. A mode\nchoice model is then developed based on this approach to represent the\nimportance of such information.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.00208v1"
    },
    {
        "title": "What Is an Emerging Technology?",
        "authors": [
            "Daniele Rotolo",
            "Diana Hicks",
            "Ben R. Martin"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  There is considerable and growing interest in the emergence of novel\ntechnologies, especially from the policy-making perspective. Yet as an area of\nstudy, emerging technologies lacks key foundational elements, namely a\nconsensus on what classifies a technology as 'emergent' and strong research\ndesigns that operationalize central theoretical concepts. The present paper\naims to fill this gap by developing a definition of 'emerging technologies' and\nlinking this conceptual effort with the development of a framework for the\noperationalisation of technological emergence. The definition is developed by\ncombining a basic understanding of the term and in particular the concept of\n'emergence' with a review of key innovation studies dealing with definitional\nissues of technological emergence. The resulting definition identifies five\nattributes that feature in the emergence of novel technologies. These are: (i)\nradical novelty, (ii) relatively fast growth, (iii) coherence, (iv) prominent\nimpact, and (v) uncertainty and ambiguity. The framework for operationalising\nemerging technologies is then elaborated on the basis of the proposed\nattributes. To do so, we identify and review major empirical approaches (mainly\nin, although not limited to, the scientometric domain) for the detection and\nstudy of emerging technologies (these include indicators and trend analysis,\ncitation analysis, co-word analysis, overlay mapping, and combinations thereof)\nand elaborate on how these can be used to operationalise the different\nattributes of emergence.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.00673v4"
    },
    {
        "title": "Modeling and Improving the Energy Performance of GPS Receivers for\n  Mobile Applications",
        "authors": [
            "Kongyang Chen",
            "Guang Tan"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Integrated GPS receivers have become a basic module in today's mobile\ndevices. While serving as the cornerstone for location based services, GPS\nmodules have a serious battery drain problem due to high computation load. This\npaper aims to reveal the impact of key software parameters on hardware energy\nconsumption, by establishing an energy model for a standard GPS receiver\narchitecture as found in both academic and industrial designs. In particular,\nour measurements show that the receiver's energy consumption is in large part\nlinear with the number of tracked satellites. This leads to a design of\nselective tracking algorithm that provides similar positioning accuracy (around\n12m) with a subset of selected satellites, which translates to an energy saving\nof 20.9-23.1\\% on the Namuru board.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.02656v2"
    },
    {
        "title": "When In-Memory Computing is Slower than Heavy Disk Usage",
        "authors": [
            "Kamran Karimi",
            "Diwakar Krishnamurthy",
            "Parissa Mirjafari"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Disk access latency and transfer times are often considered to have a major\nand detrimental impact on the running time of software. Developers are often\nadvised to favour in-memory operations and minimise disk access. Furthermore,\ndiskless computer architectures are being studied and designed to remove this\nbottleneck all together, to improve application performance in areas such as\nHigh Performance Computing, Big Data, and Business Intelligence. In this paper\nwe use code inspired by real, production software, to show that in-memory\noperations are not always a guarantee for high performance, and may actually\ncause a considerable slow-down. We also show how small code changes can have\ndramatic effects on running times. We argue that a combination of system-level\nimprovements and better developer awareness and coding practices are necessary\nto ensure in-memory computing can achieve its full potential.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.02678v2"
    },
    {
        "title": "Hardware Probing Interface and Test Robustness",
        "authors": [
            "A. M. Dorman"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Computerized integrity test of an electronic product hardware interface and\nproduct probing validation are considered. Integrity testing is based on a\ncurrent voltage characteristic measurement, when a small voltage and/or current\nstimuli are applied to the product pads including power supply circuitry pads,\nso that the product is not normally powered on. Test fixture needles validation\nis a part of a self test maintenance scenario designed to predict deterioration\nof product probing.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.03113v1"
    },
    {
        "title": "Synthesis of all Maximum Length Cellular Automata of Cell Size up to 12",
        "authors": [
            "Jaydeb Bhaumik"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Maximum length CA has wide range of applications in design of linear block\ncode, cryptographic primitives and VLSI testing particularly in\nBuilt-In-Self-Test. In this paper, an algorithm to compute all $n$-cell maximum\nlength CA-rule vectors is proposed. Also rule vectors for each primitive\npolynomial in GF(2^2) to GF(2^{12} have been computed by simulation and they\nhave been listed.Programmable rule vectors based maximum length CA can be used\nto design cryptographic primitives.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.04006v1"
    },
    {
        "title": "Designing and Building a Three-dimensional Projective Scanner for\n  Smartphones",
        "authors": [
            "Marios Papachristou"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  One of the frustrating things in the digital fabrication era is that its\nmedia are neither affordable nor easily accessible and usable.\nThree-dimensional (3D) fabrication media (DFM) such as 3D Printers and 3D\nScanners have experienced an upsurge in popularity, while the latter remain\nexpensive and hard to function. With this paper, we aim to present you the\nRhoScanner Project - a an affordable and efficient Three-dimensional Projective\nScanner for Smart-phones, hence shedding light on the extended capabilities of\ndigital fabrication media on popular use.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.04315v1"
    },
    {
        "title": "Feeder Load Balancing using Fuzzy Logic and Combinatorial\n  Optimization-based Implementation",
        "authors": [
            "A. Ukil",
            "W. Siti"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The distribution system problems, such as planning, loss minimization, and\nenergy restoration, usually involve the phase balancing or network\nreconfiguration procedures. The determination of an optimal phase balance is,\nin general, a combinatorial optimization problem. This paper proposes a novel\nreconfiguration of the phase balancing using the fuzzy logic and the\ncombinatorial optimization-based implementation step back to back. Input to the\nfuzzy step is the total load per phase of the feeders. Output of the fuzzy step\nis the load change values, negative value for load releasing and positive value\nfor load receiving. The output of the fuzzy step is the input to the load\nchanging system. The load changing system uses combinatorial optimization\ntechniques to translate the change values (kW) into number of load points and\nthen selects the specific load points. It also performs the inter-changing of\nthe load points between the releasing and the receiving phases in an optimal\nfashion. Application results using the distribution feeder network of South\nAfrica are presented in this paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05273v1"
    },
    {
        "title": "Adjusted Haar Wavelet for Application in the Power Systems Disturbance\n  Analysis",
        "authors": [
            "A. Ukil",
            "R. Zivanovic"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Abrupt change detection based on the wavelet transform and threshold method\nis very effective in detecting the abrupt changes and hence segmenting the\nsignals recorded during disturbances in the electrical power network. The\nwavelet method estimates the time-instants of the changes in the signal model\nparameters during the pre-fault condition, after initiation of fault, after\ncircuit-breaker opening and auto-reclosure. Certain kinds of disturbance\nsignals do not show distinct abrupt changes in the signal parameters. In those\ncases, the standard mother wavelets fail to achieve correct event-specific\nsegmentations. A new adjustment technique to the standard Haar wavelet is\nproposed in this paper, by introducing 2n adjusting zeros in the Haar wavelet\nscaling filter, n being a positive integer. This technique is quite effective\nin segmenting those fault signals into pre- and post-fault segments, and it is\nan improvement over the standard mother wavelets for this application. This\npaper presents many practical examples where recorded signals from the power\nnetwork in South Africa have been used.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05287v1"
    },
    {
        "title": "A software controlled voltage tuning system using multi-purpose ring\n  oscillators",
        "authors": [
            "Steve Kerrison",
            "Kerstin Eder"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This paper presents a novel software driven voltage tuning method that\nutilises multi-purpose Ring Oscillators (ROs) to provide process variation and\nenvironment sensitive energy reductions. The proposed technique enables voltage\ntuning based on the observed frequency of the ROs, taken as a representation of\nthe device speed and used to estimate a safe minimum operating voltage at a\ngiven core frequency. A conservative linear relationship between RO frequency\nand silicon speed is used to approximate the critical path of the processor.\n  Using a multi-purpose RO not specifically implemented for critical path\ncharacterisation is a unique approach to voltage tuning. The parameters\ngoverning the relationship between RO and silicon speed are obtained through\nthe testing of a sample of processors from different wafer regions. These\nparameters can then be used on all devices of that model. The tuning method and\nsoftware control framework is demonstrated on a sample of XMOS XS1-U8A-64\nembedded microprocessors, yielding a dynamic power saving of up to 25% with no\nperformance reduction and no negative impact on the real-time constraints of\nthe embedded software running on the processor.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.05733v1"
    },
    {
        "title": "Normalization: A Preprocessing Stage",
        "authors": [
            "S. Gopal Krishna Patro",
            "Kishore Kumar Sahu"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  As we know that the normalization is a pre-processing stage of any type\nproblem statement. Especially normalization takes important role in the field\nof soft computing, cloud computing etc. for manipulation of data like scale\ndown or scale up the range of data before it becomes used for further stage.\nThere are so many normalization techniques are there namely Min-Max\nnormalization, Z-score normalization and Decimal scaling normalization. So by\nreferring these normalization techniques we are going to propose one new\nnormalization technique namely, Integer Scaling Normalization. And we are going\nto show our proposed normalization technique using various data sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06462v1"
    },
    {
        "title": "Practical Denoising of MEG Data using Wavelet Transform",
        "authors": [
            "A. Ukil"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Magnetoencephalography (MEG) is an important noninvasive, nonhazardous\ntechnology for functional brain mapping, measuring the magnetic fields due to\nthe intracellular neuronal current flow in the brain. However, the inherent\nlevel of noise in the data collection process is large enough to obscure the\nsignal(s) of interest most often. In this paper, a practical denoising\ntechnique based on the wavelet transform and the multiresolution signal\ndecomposition technique is presented. The proposed technique is substantiated\nby the application results using three different mother wavelets on the\nrecorded MEG signal.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06618v1"
    },
    {
        "title": "Optimization of gridshell bar orientation using a simplified genetic\n  approach",
        "authors": [
            "Lina Bouhaya",
            "Olivier Baverel",
            "Jean-Franois Caron"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Gridshells are defined as structures that have the shape and rigidity of a\ndouble curvature shell but consist of a grid instead of a continuous surface.\nThis study concerns those obtained by elastic deformation of an initially flat\ntwo-way grid. This paper presents a novel approach to generate gridshells on an\nimposed shape under imposed boundary conditions. A numerical tool based on a\ngeometrical method, the compass method, is developed. It is coupled with\ngenetic algorithms to optimize the orientation of gridshell bars in order to\nminimize the stresses and therefore to avoid bar breakage during the\nconstruction phase. Examples of application are shown.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.06729v1"
    },
    {
        "title": "A parametric study of window-to-floor ratio of three window types using\n  dynamic simulation",
        "authors": [
            "Ana Rita Amaral",
            "Eugnio Rodrigues",
            "Adlio Rodrigues Gaspar",
            "lvaro Gomes"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The windows can be responsible for unnecessary energy consumption in a\nbuilding, if incorrectly designed, shadowed or oriented. Considering an annual\nthermal comfort assessment of a space, if windows are over-dimensioned, they\ncan contribute to the increase of the heating needs due to heat losses, and\nalso to the increase of cooling needs due to over-exposure to solar radiation.\nWhen under-dimensioned, the same space may benefit from reduced heat losses\nthrough the glazing surface but does not benefit from solar radiation gains.\nTherefore, it is important to find the optimum design that minimizes both the\nheating and cooling needs. This paper presents a parametric study of window\ntype (single, double and triple glazing), orientation and opening size, located\nin the city of Coimbra, Portugal. An annual and a seasonal assessment were\ndone, in order to obtain the set of optimum values around 360 degree\norientation.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.07016v1"
    },
    {
        "title": "Preprint Traffic Management and Forecasting System Based on 3D GIS",
        "authors": [
            "Xiaoming Li",
            "Zhihan Lv",
            "Jinxing Hu",
            "Baoyun Zhang",
            "Ling Yin",
            "Chen Zhong",
            "Weixi Wang",
            "Shengzhong Feng"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This is the preprint version of our paper on 2015 15th IEEE/ACM International\nSymposium on Cluster, Cloud and Grid Computing (CCGrid). This paper takes\nShenzhen Futian comprehensive transportation junction as the case, and makes\nuse of continuous multiple real-time dynamic traffic information to carry out\nmonitoring and analysis on spatial and temporal distribution of passenger flow\nunder different means of transportation and service capacity of junction from\nmulti-dimensional space-time perspectives such as different period and special\nperiod. Virtual reality geographic information system is employed to present\nthe forecasting result.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.01375v3"
    },
    {
        "title": "Definition and Research of Internet Neurology",
        "authors": [
            "Feng Liu"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  More and more scientific research shows that there is a close correlation\nbetween the Internet and brain science. This paper presents the idea of\nestablishing the Internet neurology, which means to make a cross-contrast\nbetween the two in terms of physiology and psychology, so that a complete\ninfrastructure system of the Internet is established, predicting the\ndevelopment trend of the Internet in the future as well as the brain structure\nand operation mechanism, and providing theoretical support for the generation\nprinciple of intelligence, cognition and emotion. It also proposes the\nviewpoint that the Internet can be divided into Internet neurophysiology,\nInternet neuropsychology, Brain Internet physiology, Brain Internet psychology\nand the Internet in cognitive science.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.02842v1"
    },
    {
        "title": "Android based security and home automation system",
        "authors": [
            "Sadeque Reza Khan",
            "Farzana Sultana Dristy"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The smart mobile terminal operator platform Android is getting popular all\nover the world with its wide variety of applications and enormous use in\nnumerous spheres of our daily life. Considering the fact of increasing demand\nof home security and automation, an Android based control system is presented\nin this paper where the proposed system can maintain the security of home main\nentrance and also the car door lock. Another important feature of the designed\nsystem is that it can control the overall appliances in a room. The mobile to\nsecurity system or home automation system interface is established through\nBluetooth. The hardware part is designed with the PIC microcontroller.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.03564v1"
    },
    {
        "title": "An Improved Variable Step-size Zero-point Attracting Projection\n  Algorithm",
        "authors": [
            "Jianming Liu",
            "Steven L. Grant"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This paper proposes an improved variable step-size (VSS) scheme for\nzero-point attracting projection (ZAP) algorithm. The proposed VSS is\nproportional to the sparseness difference between filter coefficients and the\ntrue impulse response. Meanwhile, it works for both sparse and non-sparse\nsystem identification, and simulation results demonstrate that the proposed\nalgorithm could provide both faster convergence rate and better tracking\nability than previous ones.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.03664v1"
    },
    {
        "title": "A parametric study on window-to-floor ratio of double window glazing and\n  its shadowing using dynamic simulation",
        "authors": [
            "Ana Rita Amaral",
            "Eugnio Rodrigues",
            "Adlio Rodrigues Gaspar",
            "lvaro Gomes"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  When incorrectly designed, windows can be responsible for unnecessary energy\nconsumption in a building. This may result from its dimensions, orientation and\nshadowing. In a moderate climate like the Portuguese, and considering an annual\nthermal comfort assessment of a space, if windows are under-dimensioned or\nover-shadowed, they can contribute to the increase of heating needs. However,\nwhen over-dimensioned or under-shadowed, they contribute to the increase of\ncooling requirements. Therefore, it is important to find the optimum design\nthat balances orientation, dimension and shadowing, contributing to minimize\nboth the heating and cooling needs. This study presents a parametric analysis\nof a double glazing window in its orientation and dimension, located in the\nPortuguese city of Coimbra. For each window orientation and dimension, the\noptimum overhang depth is determined. The objective is to minimize degree-hours\nof thermal discomfort. Results show that overhangs are mainly a corrective\nmechanism to over-dimensioned openings, thus allowing that building\npractitioners may choose a wider range of windows dimensions.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.04174v1"
    },
    {
        "title": "STC: Coarse-Grained Vehicular Data Based Travel Speed Sensing by\n  Leveraging Spatial-Temporal Correlation",
        "authors": [
            "Lu Shao",
            "Cheng Wang",
            "Changjun Jiang"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  As an important information for traffic condition evaluation, trip planning,\ntransportation management, etc., average travel speed for a road means the\naverage speed of vehicles travelling through this road in a given time\nduration. Traditional ways for collecting travel-speed oriented traffic data\nalways depend on dedicated sensors and supporting infrastructures, and are\ntherefore financial costly. Differently, vehicular crowdsensing as an\ninfrastructure-free way, can be used to collect data including real-time\nlocations and velocities of vehicles for road travel speed estimation, which is\na quite low-cost way. However, vehicular crowdsensing data is always\ncoarse-grained. This coarseness can lead to the incompleteness of travel\nspeeds. Aiming to handle this problem as well as estimate travel speed\naccurately, in this paper, we propose an approach named STC that exploits the\nspatial-temporal correlation among travel speeds for roads by introducing the\ntime-lagged cross correlation function. The time lagging factor describes the\ntime consumption of traffic feature diffusion along roads. To properly\ncalculate cross correlation, we novelly make the determination of the time\nlagging factor self-adaptive by recording the locations of vehicles at\ndifferent roads. Then, utilizing the local stationarity of cross correlation,\nwe further reduce the problem of single-road travel speed vacancy completion to\na minimization problem. Finally, we fill all the vacancies of travel speed for\nroads in a recursive way using the geometric structure of road net. Elaborate\nexperiments based on real taxi trace data show that STC can settle the\nincompleteness problem of vehicle crowdsensing data based travel speed\nestimation and ensure the accuracy of estimated travel speed better, in\ncomparison with representative existing methods such as KNN, Kriging and ARIMA.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.04433v3"
    },
    {
        "title": "A Simple and General Problem and its Optimal Randomized Online Algorithm\n  Design with Competitive Analysis",
        "authors": [
            "Ying Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The online algorithm design was proposed to handle the caching problem when\nthe future information is unknown. And currently, it draws more and more\nattentions from the researchers from the areas of microgrid, where the\nproduction of renewables are unpredictable.\n  In this note, we present a framework of randomized online algorithm design\nfor the \\textit{simple and tractable} problem. This framework hopes to provide\na tractable design to design a randomized online algorithm, which can be proved\nto achieve the best competitive ratio by \\textit{Yao's Principle}.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.05305v1"
    },
    {
        "title": "Signal filtering to obtain number of Hamiltonian paths",
        "authors": [
            "Bryce Kim"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This paper consists of two parts. First, the (undirected) Hamiltonian path\nproblem is reduced to a signal filtering problem - number of Hamiltonian paths\nbecomes amplitude at zero frequency for (a combination of) sinusoidal signal\nf(t) that encodes a graph. Then a 'divide and conquer' strategy to filtering\nout wide bandwidth components of a signal is suggested - one filters out\nangular frequency 1/2 to 1, then 1/4 to 1/2, then 1/8 to 1/4 and so on. An\nactual implementation of this strategy involves careful local polynomial\nextrapolation using numerical differentiation filters. When conjectures\nregarding required number of samples for specified filter designs and time\ncomplexity of obtaining filter coefficients hold, P=NP conditionally.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.05429v11"
    },
    {
        "title": "State of the Art of the Intra-Task Dynamic Voltage and Frequency Scaling\n  Technique",
        "authors": [
            "Rawlinson S. Gonalves",
            "Raimundo da Silva Barreto"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  In recent years there has been an increasing use of embedded systems because\nof advances in technology, the reduction of the costs of electronic equipment\nand mainly the popularity of mobile devices. Many of these systems implement\nlow power consumption policies to extend their autonomy, usually because they\nhave a reduced amount of resources and the great majority of them use electric\npower from batteries. One way to minimize the power consumption of these\ndevices is through of the application of low power consumption techniques. From\nthe various techniques presented in the literature - the intra-task Dynamic\nVoltage and Frequency Scaling (DVFS) has played an important role. The main aim\nof DVFS is to allow each task to manage the minimum resources necessary for\ntasks execution, this way reducing the processor power consumption and, at the\nsame time, respecting the task deadlines when considered a real-time system\ncontext. Therefore, this paper aims to apply a systematic literature review\nwith the goal of identifying and presenting the main methods using the\nintra-task DVFS technique, applied in the context of real-time systems to\nreduce energy consumption on the processor. Finally, this work will show the\nadvantages and disadvantages of each cataloged methodology.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06177v1"
    },
    {
        "title": "The Fallacy of Favoring Gradual Replacement Mind Uploading Over\n  Scan-and-Copy",
        "authors": [
            "Keith B. Wiley",
            "Randal A. Koene"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Mind uploading speculation and debate often concludes that a procedure\ndescribed as gradual in-place replacement preserves personal identity while a\nprocedure described as destructive scan-and-copy produces some other identity\nin the target substrate such that personal identity is lost along with the\nbiological brain. This paper demonstrates a chain of reasoning that establishes\nmetaphysical equivalence between these two methods in terms of preserving\npersonal identity.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06320v4"
    },
    {
        "title": "Aashiyana: Design and Evaluation of a Smart Demand-Response System for\n  Highly-stressed Grids",
        "authors": [
            "Noman Bashir",
            "Zohaib Sharani",
            "Khushboo Qayyum",
            "Affan A. Syed"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This paper targets the unexplored problem of demand response within the\ncontext of power-grids that are allowed to regularly enforce blackouts as a\nmean to balance supply with demand:highly-stressed grids. Currently these\nutilities use as a cyclic and binary (power/no-power) schedule over consumer\ngroups leading to significant wastage of capacity and long hours of no-power.\nWe present here a novel building DLC system, Aashiyana, that can enforce\nseveral user-defined low-power states. We evaluate distributed and centralized\nload-shedding schemes using Aashiyana that can, compared to current\nload-shedding strategy, reduce the number of homes with no power by 80% for\nminor change in the fraction of homes with full-power.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.06975v3"
    },
    {
        "title": "Server component installation and testing of the university information\n  and educational environment on the Moodle LMS platform",
        "authors": [
            "Irina Erjomina",
            "Aleksandr Rozentsvaig",
            "Rushan Ziatdinov"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The informational educational environment (IEE) of an institution is a\ncomplex multilevel system which, along with methodical, organizational and\ncultural resources, accumulates the intellectual and technical potential of a\nuniversity, as well as the informative and activity components of the learners\nand teachers. In practice, the formation of IEE is actually based on the\ncreation of information technologies and their integration into the existing\neducational environment of the institution. The management of this system is\ncarried out using specialized equipment and software. For the successful\nformation and operation of IEE, in the present work we review software products\nthat form the basis of the organization of interactive and web interactions\nbetween students, teachers and all participants of the educational process. We\nanalyse the technical capabilities that have provided users with IEE services\nsuch as the Apache web server with connected modules PHP, MySQL, the Java\nvirtual machine and the Red5 server. We demonstrate the possibility of\nobtaining results from the interaction of these products, and reports on users'\nwork in webinars, video conferences and web conferences.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.00422v1"
    },
    {
        "title": "Preprint Virtual Reality GIS and Cloud Service Based Traffic Analysis\n  Platform",
        "authors": [
            "Xiaoming Li",
            "Zhihan Lv",
            "Weixi Wang",
            "Chen Wu",
            "Jinxing Hu"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This is the preprint version of our paper on The 23rd International\nConference on Geoinformatics (Geoinformatics2015). City traffic data has\nseveral characteristics, such as large scale, diverse predictable and\nreal-time, which falls in the range of definition of Big Data. This paper\nproposed a cloud service platform which targets for wise transportation is to\ncarry out unified management and mining analysis of the huge number of the\nmultivariate and heterogeneous dynamic transportation information, provides\nreal-time transportation information, increase the utilization efficiency of\ntransportation, promote transportation management and service level of travel\ninformation and provide decision support of transportation management by\nvirtual reality as visual.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.01056v2"
    },
    {
        "title": "A Monte Carlo Study of Pairwise Comparisons",
        "authors": [
            "M. W. Herman",
            "W. W. Koczkodaj"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Consistent approximations obtained by geometric means ($GM$) and the\nprincipal eigenvector ($EV$), turned out to be close enough for 1,000,000\nnot-so-inconsistent pairwise comparisons matrices. In this respect both methods\nare accurate enough for most practical applications. As the enclosed Table 1\ndemonstrates, the biggest difference between average deviations of $GM$ and\n$EV$ solutions is 0.00019 for the Euclidean metric and 0.00355 for the\nTchebychev metric.\n  For practical applications, this precision is far better than expected. After\nall we are talking, in most cases, about relative subjective comparisons and\none tenth of a percent is usually below our threshold of perception.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.01888v1"
    },
    {
        "title": "An LP-based inconsistency monitoring of pairwise comparison matrices",
        "authors": [
            "S. Bozoki",
            "J. Fulop",
            "W. W. Koczkodaj"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  A distance-based inconsistency indicator, defined by the third author for the\nconsistency-driven pairwise comparisons method, is extended to the incomplete\ncase. The corresponding optimization problem is transformed into an equivalent\nlinear programming problem. The results can be applied in the process of\nfilling in the matrix as the decision maker gets automatic feedback. As soon as\na serious error occurs among the matrix elements, even due to a misprint, a\nsignificant increase in the inconsistency index is reported. The high\ninconsistency may be alarmed not only at the end of the process of filling in\nthe matrix but also during the completion process. Numerical examples are also\nprovided.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.01902v1"
    },
    {
        "title": "An Algorithm for the Optimal Consistent Approximation to a Pairwise\n  Comparisons Matrix by Orthogonal Projections",
        "authors": [
            "W. W. Koczkodaj",
            "M. Orlowski"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The algorithm for finding the optimal consistent approximation of an\ninconsistent pairwise comparisons matrix is based on a logarithmic\ntransformation of a pairwise comparisons matrix into a vector space with the\nEuclidean metric. Orthogonal basis is introduced in the vector space. The\northogonal projection of the transformed matrix onto the space formed by the\nimages of consistent matrices is the required consistent approximation.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.01903v1"
    },
    {
        "title": "FPGA-Based Bandwidth Selection for Kernel Density Estimation Using High\n  Level Synthesis Approach",
        "authors": [
            "Artur Gramacki",
            "Marek Sawerwain",
            "Jarosaw Gramacki"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  FPGA technology can offer significantly hi\\-gher performance at much lower\npower consumption than is available from CPUs and GPUs in many computational\nproblems. Unfortunately, programming for FPGA (using ha\\-rdware description\nlanguages, HDL) is a difficult and not-trivial task and is not intuitive for\nC/C++/Java programmers. To bring the gap between programming effectiveness and\ndifficulty the High Level Synthesis (HLS) approach is promoting by main FPGA\nvendors. Nowadays, time-intensive calculations are mainly performed on GPU/CPU\narchitectures, but can also be successfully performed using HLS approach. In\nthe paper we implement a bandwidth selection algorithm for kernel density\nestimation (KDE) using HLS and show techniques which were used to optimize the\nfinal FPGA implementation. We are also going to show that FPGA speedups,\ncomparing to highly optimized CPU and GPU implementations, are quite\nsubstantial. Moreover, power consumption for FPGA devices is usually much less\nthan typical power consumption of the present CPUs and GPUs.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.02100v2"
    },
    {
        "title": "UbiBreathe: A Ubiquitous non-Invasive WiFi-based Breathing Estimator",
        "authors": [
            "Heba Abdelnasser",
            "Khaled A. Harras",
            "Moustafa Youssef"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Monitoring breathing rates and patterns helps in the diagnosis and potential\navoidance of various health problems. Current solutions for respiratory\nmonitoring, however, are usually invasive and/or limited to medical facilities.\nIn this paper, we propose a novel respiratory monitoring system, UbiBreathe,\nbased on ubiquitous off-the-shelf WiFi-enabled devices. Our experiments show\nthat the received signal strength (RSS) at a WiFi-enabled device held on a\nperson's chest is affected by the breathing process. This effect extends to\nscenarios when the person is situated on the line-of-sight (LOS) between the\naccess point and the device, even without holding it. UbiBreathe leverages\nthese changes in the WiFi RSS patterns to enable ubiquitous non-invasive\nrespiratory rate estimation, as well as apnea detection.\n  We propose the full architecture and design for UbiBreathe, incorporating\nvarious modules that help reliably extract the hidden breathing signal from a\nnoisy WiFi RSS. The system handles various challenges such as noise\nelimination, interfering humans, sudden user movements, as well as detecting\nabnormal breathing situations. Our implementation of UbiBreathe using\noff-the-shelf devices in a wide range of environmental conditions shows that it\ncan estimate different breathing rates with less than 1 breaths per minute\n(bpm) error. In addition, UbiBreathe can detect apnea with more than 96%\naccuracy in both the device-on-chest and hands-free scenarios. This highlights\nits suitability for a new class of anywhere respiratory monitoring.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.02388v1"
    },
    {
        "title": "Unique Sense: Smart Computing Prototype",
        "authors": [
            "Vijaykumar S.",
            "Saravanakumar S. G.",
            "M. Balamurugan"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Unique sense: Smart computing prototype is a part of unique sense computing\narchitecture, which delivers alternate solution for todays computing\narchitecture. This computing is one step towards future generation needs, which\nbrings extended support to the ubiquitous environment. This smart computing\nprototype is the light weight compact architecture which is designed to satisfy\nall the needs of this society. The proposed solution is based on the hybrid\ncombination of cutting edge technologies and techniques from the various\nlayers. In addition it achieves low cost architecture and eco-friendly to meet\nall the levels of peoples needs.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.04157v1"
    },
    {
        "title": "Advances in Computational Biology: A Real Boost or a Wishful Thinking",
        "authors": [
            "Emanuel Diamant"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Computational biology is on the verge of a paradigm shift in its research\npractice - from a data-based (computational) paradigm to an information-based\n(cognitive) paradigm. As in the other research fields, this transition is\nimpeded by lack of a right understanding about what is actually hidden behind\nthe term \"information\". The paper is intended to clarify this issue and\nintroduces two new notions of \"physical information\" and \"semantic\ninformation\", which together constitute the term \"information\". Some\nimplications of this introduction are considered.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.05186v1"
    },
    {
        "title": "Managing Null Entries in Pairwise Comparisons",
        "authors": [
            "W. W. Koczkodaj",
            "M. W. Herman",
            "M. Orlowski"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This paper shows how to manage null entries in pairwise comparisons matrices.\nAlthough assessments can be imprecise, since subjective criteria are involved,\nthe classical pairwise comparisons theory expects all of them to be available.\nIn practice, some experts may not be able (or available) to provide all\nassessments. Therefore managing null entries is a necessary extension of the\npairwise comparisons method. It is shown that certain null entries can be\nrecovered on the basis of the transitivity property which each pairwise\ncomparisons matrix is expected to satisfy.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.05334v1"
    },
    {
        "title": "Lossless Layout Image Compression Algorithms for Electron-Beam\n  Direct-Write Lithography",
        "authors": [
            "Narendra Chaudhary",
            "Yao Luo",
            "Serap A. Savari",
            "Roger McCay"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Electron-beam direct-write (EBDW) lithography systems must in the future\ntransmit terabits of information per second to be viable for commercial\nsemiconductor manufacturing. Lossless layout image compression algorithms with\nhigh decoding throughputs and modest decoding resources are tools to address\nthe data transfer portion of the throughput problem. The earlier lossless\nlayout image compression algorithm Corner2 is designed for binary layout images\non raster-scanning systems. We propose variations of Corner2 collectively\ncalled Corner2-EPC and Paeth-EPC which apply to electron-beam proximity\ncorrected layout images and offer interesting trade-offs between compression\nratios and decoding speeds. Most of our algorithms achieve better overall\ncompression performance than PNG, Block C4 and LineDiffEntropy while having low\ndecoding times and resources.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.06494v2"
    },
    {
        "title": "A Novel Geographic Partitioning System for Anonymizing Health Care Data",
        "authors": [
            "William Lee Croft",
            "Wei Shi",
            "Jorg-Rudiger Sack",
            "Jean-Pierre Corriveau"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  With large volumes of detailed health care data being collected, there is a\nhigh demand for the release of this data for research purposes. Hospitals and\norganizations are faced with conflicting interests of releasing this data and\nprotecting the confidentiality of the individuals to whom the data pertains.\nSimilarly, there is a conflict in the need to release precise geographic\ninformation for certain research applications and the requirement to censor or\ngeneralize the same information for the sake of confidentiality. Ultimately the\nchallenge is to anonymize data in order to comply with government privacy\npolicies while reducing the loss in geographic information as much as possible.\nIn this paper, we present a novel geographic-based system for the anonymization\nof health care data. This system is broken up into major components for which\ndifferent approaches may be supplied. We compare such approaches in order to\nmake recommendations on which of them to select to best match user\nrequirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.06939v1"
    },
    {
        "title": "Fixed Rank Kriging for Cellular Coverage Analysis",
        "authors": [
            "Hajer Braham",
            "Sana Ben Jemaa",
            "Gersende Fort",
            "Eric Moulines",
            "Berna Sayrac"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Coverage planning and optimization is one of the most crucial tasks for a\nradio network operator. Efficient coverage optimization requires accurate\ncoverage estimation. This estimation relies on geo-located field measurements\nwhich are gathered today during highly expensive drive tests (DT); and will be\nreported in the near future by users' mobile devices thanks to the 3GPP\nMinimizing Drive Tests (MDT) feature~\\cite{3GPPproposal}. This feature consists\nin an automatic reporting of the radio measurements associated with the\ngeographic location of the user's mobile device. Such a solution is still\ncostly in terms of battery consumption and signaling overhead. Therefore,\npredicting the coverage on a location where no measurements are available\nremains a key and challenging task. This paper describes a powerful tool that\ngives an accurate coverage prediction on the whole area of interest: it builds\na coverage map by spatially interpolating geo-located measurements using the\nKriging technique. The paper focuses on the reduction of the computational\ncomplexity of the Kriging algorithm by applying Fixed Rank Kriging (FRK). The\nperformance evaluation of the FRK algorithm both on simulated measurements and\nreal field measurements shows a good trade-off between prediction efficiency\nand computational complexity. In order to go a step further towards the\noperational application of the proposed algorithm, a multicellular use-case is\nstudied. Simulation results show a good performance in terms of coverage\nprediction and detection of the best serving cell.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.07062v2"
    },
    {
        "title": "An Analogy Based Method for Freight Forwarding Cost Estimation",
        "authors": [
            "Kevin A. Straight"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The author explored estimation by analogy (EBA) as a means of estimating the\ncost of international freight consignment. A version of the k-Nearest Neighbors\nalgorithm (k-NN) was tested by predicting job costs from a database of over\n5000 actual jobs booked by an Irish freight forwarding firm over a seven year\nperiod. The effect of a computer intensive training process on overall accuracy\nof the method was found to be insignificant when the method was implemented\nwith four or fewer neighbors. Overall, the accuracy of the analogy based\nmethod, while still significantly less accurate than manually working up\nestimates, might be worthwhile to implement in practice, depending labor costs\nin an adopting firm. A simulation model was used to compare manual versus\nanalytical estimation methods. The point of indifference occurs when it takes a\nfirm more than 1.5 worker hours to prepare a manual estimate (at current Irish\nlabor costs). Suggestions are given for future experiments to improve the\nsampling policy of the method to improve accuracy and to improve overall\nscalability.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.08088v1"
    },
    {
        "title": "Improving Time Estimation by Blind Deconvolution: with Applications to\n  TOFD and Backscatter Sizing",
        "authors": [
            "Roberto H. Herrera",
            "Zhaorui Liu",
            "Natasha Raffa",
            "Paul Christensen",
            "Adrianus Elvers"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  In this paper we present a blind deconvolution scheme based on statistical\nwavelet estimation. We assume no prior knowledge of the wavelet, and do not\nselect a reflector from the signal. Instead, the wavelet (ultrasound pulse) is\nstatistically estimated from the signal itself by a kurtosis-based metric. This\nwavelet is then used to deconvolve the RF (radiofrequency) signal through\nWiener filtering, and the resultant zero phase trace is subjected to spectral\nbroadening by Autoregressive Spectral Extrapolation (ASE). These steps increase\nthe time resolution of diffraction techniques. Results on synthetic and real\ncases show the robustness of the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1505.08107v1"
    },
    {
        "title": "Determining rural areas vulnerable to illegal dumping using GIS\n  techniques. Case study: Neamt county, Romania",
        "authors": [
            "Florin-Constantin Mihai",
            "Adrian Ursu",
            "Pavel Ichim",
            "Dan-Adrian Chelaru"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The paper aims to mapping the potential vulnerable areas to illegal dumping\nof household waste from rural areas in the extra- Carpathian region of Neamt\nCounty. These areas are ordinary in the proximity of built-up areas and buffers\nareas of 1 km were delimited for every locality. Based on various map layers in\nvector formats (land use, rivers, built-up areas, roads etc) an assessment\nmethod is performed to highlight the potential areas vulnerable to illegal\ndumping inside these buffer areas at local scale. The results are correlated to\nfield observations and current situation of waste management systems. The maps\noutline local disparities due to various geographical conditions of county.\nThis approach is a necessary tool in EIA studies particularly for rural waste\nmanagement systems at local and regional scale which are less studied in\ncurrent literature than urban areas.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.00627v1"
    },
    {
        "title": "Fractal surfaces from simple arithmetic operations",
        "authors": [
            "Vladimir Garcia-Morales"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Fractal surfaces ('patchwork quilts') are shown to arise under most general\ncircumstances involving simple bitwise operations between real numbers. A\ntheory is presented for all deterministic bitwise operations on a finite\nalphabet. It is shown that these models give rise to a roughness exponent $H$\nthat shapes the resulting spatial patterns, larger values of the exponent\nleading to coarser surfaces.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.01444v3"
    },
    {
        "title": "On environments as systemic exoskeletons: Crosscutting optimizers and\n  antifragility enablers",
        "authors": [
            "Vincenzo De Florio"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Classic approaches to General Systems Theory often adopt an individual\nperspective and a limited number of systemic classes. As a result, those\nclasses include a wide number and variety of systems that result equivalent to\neach other. This paper introduces a different approach: First, systems\nbelonging to a same class are further differentiated according to five major\ngeneral characteristics. This introduces a \"horizontal dimension\" to system\nclassification. A second component of our approach considers systems as nested\ncompositional hierarchies of other sub-systems. The resulting \"vertical\ndimension\" further specializes the systemic classes and makes it easier to\nassess similarities and differences regarding properties such as resilience,\nperformance, and quality-of-experience. Our approach is exemplified by\nconsidering a telemonitoring system designed in the framework of Flemish\nproject \"Little Sister\". We show how our approach makes it possible to design\nintelligent environments able to closely follow a system's horizontal and\nvertical organization and to artificially augment its features by serving as\ncrosscutting optimizers and as enablers of antifragile behaviors.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.01869v4"
    },
    {
        "title": "Can JSP Code be Generated Using XML Tags?",
        "authors": [
            "Neha Bothra",
            "Kritika Jain",
            "Sanjay Chakraborty"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Over the years, a variety of web services have started using server-side\nscripting to deliver results back to a client as a paid or free service; one\nsuch server-side scripting language is Java Server Pages (JSP). Also Extensible\nmarkup language (XML), is being adopted by most web developers as a tool to\ndescribe data.Therefore, we present a conversion method which uses predefined\nXML tags as input and generates the corresponding JSP code. However, the end\nusers are required to have a basic experience with web pages. This conversion\nmethod aims to reduce the time and effort spent by the user (web developer) to\nget acquainted with JSP. The conversion process abstracts the user from the\nintricacies of JSP and enables him to focus on the business logic.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.02557v1"
    },
    {
        "title": "Cracking Intel Sandy Bridge's Cache Hash Function",
        "authors": [
            "Zhipeng Wei",
            "Zehan Cui",
            "Mingyu Chen"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  On Intel Sandy Bridge processor, last level cache (LLC) is divided into cache\nslices and all physical addresses are distributed across the cache slices using\nan hash function. With this undocumented hash function existing, it is\nimpossible to implement cache partition based on page coloring. This article\ncracks the hash functions on two types of Intel Sandy processors by converting\nthe problem of cracking the hash function to the problem of classifying data\nblocks into different groups based on eviction relationship existing between\ndata blocks that are mapped to the same cache set. Based on the cracking\nresult, this article proves that it's possible to implement cache partition\nbased on page coloring on cache indexed by hashing.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.03767v1"
    },
    {
        "title": "Passenger Flow Predictions at Sydney International Airport: A\n  Data-Driven Queuing Approach",
        "authors": [
            "Harold Nikoue",
            "Aude Marzuoli",
            "John-Paul Clarke",
            "Eric Feron",
            "Jim Peters"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Time spent in processing zones at an airport are an important part of the\npassenger's airport experience. It undercuts the time spent in the rest of the\nairport, and therefore the revenue that could be generated from shopping and\ndining. It can also result in passengers missing flights and connections, which\nhas significant operational repercussions. Inadequate staffing levels are often\nto blame for large congestion at an airport. In this paper, we present a\nstochastic simulation that estimates the operational uncertainty in passenger\nprocessing at immigration. Congestion and delays are estimated on arrivals and\ndepartures based on scheduled flight departures and arrivals. We demonstrate\nthe use of cellular tracking data in refining the model, and an approach to\ncontrolling congestion by adjusting staffing levels.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.04839v1"
    },
    {
        "title": "GCC-Plugin for Automated Accelerator Generation and Integration on\n  Hybrid FPGA-SoCs",
        "authors": [
            "Markus Vogt",
            "Gerald Hempel",
            "Jeronimo Castrillon",
            "Christian Hochberger"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  In recent years, architectures combining a reconfigurable fabric and a\ngeneral purpose processor on a single chip became increasingly popular. Such\nhybrid architectures allow extending embedded software with application\nspecific hardware accelerators to improve performance and/or energy efficiency.\nAiding system designers and programmers at handling the complexity of the\nrequired process of hardware/software (HW/SW) partitioning is an important\nissue. Current methods are often restricted, either to bare-metal systems, to\nsubsets of mainstream programming languages, or require special coding\nguidelines, e.g., via annotations. These restrictions still represent a high\nentry barrier for the wider community of programmers that new hybrid\narchitectures are intended for. In this paper we revisit HW/SW partitioning and\npresent a seamless programming flow for unrestricted, legacy C code. It\nconsists of a retargetable GCC plugin that automatically identifies code\nsections for hardware acceleration and generates code accordingly. The proposed\nworkflow was evaluated on the Xilinx Zynq platform using unmodified code from\nan embedded benchmark suite.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.00025v2"
    },
    {
        "title": "A Comparison of High-Level Design Tools for SoC-FPGA on Disparity Map\n  Calculation Example",
        "authors": [
            "Shaodong Qin",
            "Mladen Berekovic"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Modern SoC-FPGA that consists of FPGA with embedded ARM cores is being\npopularized as an embedded vision system platform. However, the design approach\nof SoC-FPGA applications still follows traditional hardware-software separate\nworkflow, which becomes the barrier of rapid product design and iteration on\nSoC-FPGA. High-Level Synthesis (HLS) and OpenCL-based system-level design\napproaches provide programmers the possibility to design SoC-FGPA at\nsystem-level with an unified development environment for both hardware and\nsoftware. To evaluate the feasibility of high-level design approach especially\nfor embedded vision applications, Vivado HLS and Altera SDK for OpenCL,\nrepresentative and most popular commercial tools in market, are selected as\nevaluation design tools, disparity map calculation as targeting application. In\nthis paper, hardware accelerators of disparity map calculation are designed\nwith both tools and implemented on Zedboard and SoCKit development board,\nrespectively. Comparisons between design tools are made in aspects of\nsupporting directives, accelerator design process, and generated hardware\nperformance. The results show that both tools can generate efficient hardware\nfor disparity map calculation application with much less developing time.\nMoreover, we can also state that, more directives (e.g., interface type, array\nreshape, resource type specification) are supported, but more hardware\nknowledge is required, in Vivado HLS. In contrast, Altera SDK for OpenCL is\nrelatively easier for software programmers who is new to hardware, but with the\nprice of more resources usage on FPGA for similar hardware accelerator\ngeneration.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.00036v1"
    },
    {
        "title": "Target Tracking in Confined Environments with Uncertain Sensor Positions",
        "authors": [
            "Vladimir Savic",
            "Henk Wymeersch",
            "Erik G. Larsson"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  To ensure safety in confined environments such as mines or subway tunnels, a\n(wireless) sensor network can be deployed to monitor various environmental\nconditions. One of its most important applications is to track personnel,\nmobile equipment and vehicles. However, the state-of-the-art algorithms assume\nthat the positions of the sensors are perfectly known, which is not necessarily\ntrue due to imprecise placement and/or dropping of sensors. Therefore, we\npropose an automatic approach for simultaneous refinement of sensors' positions\nand target tracking. We divide the considered area in a finite number of cells,\ndefine dynamic and measurement models, and apply a discrete variant of belief\npropagation which can efficiently solve this high-dimensional problem, and\nhandle all non-Gaussian uncertainties expected in this kind of environments.\nFinally, we use ray-tracing simulation to generate an artificial mine-like\nenvironment and generate synthetic measurement data. According to our extensive\nsimulation study, the proposed approach performs significantly better than\nstandard Bayesian target tracking and localization algorithms, and provides\nrobustness against outliers.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.00238v1"
    },
    {
        "title": "Axiomatization of Inconsistency Indicators for Pairwise Comparisons",
        "authors": [
            "W. W. Koczkodaj",
            "J. -P. Magnot"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This study proposes revised axioms for defining inconsistency indicators in\npairwise comparisons. It is based on the new findings that \"PC submatrix cannot\nhave a worse inconsistency indicator than the PC matrix containing it\" and that\nthere must be a PC submatrix with the same inconsistency as the given PC\nmatrix.\n  This study also provides better reasoning for the need of normalization. It\nis a revision of axiomatization by Koczkodaj and Szwarc, 2014 which proposed\naxioms expressed informally with some deficiencies addressed in this study.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.03781v4"
    },
    {
        "title": "Validation of daylighting model in CODYRUN building simulation code",
        "authors": [
            "H. Boyer",
            "S. Guichard",
            "A. Jean",
            "T. Libelle",
            "Dimitri Bigot",
            "F. Miranville",
            "M. Boji"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  CODYRUN is a multi-zone software integrating thermal building simulation,\nairflow, and pollutant transfer. A first question thus arose as to the\nintegration of indoor lighting conditions into the simulation, leading to a new\nmodel calculating natural and artificial lighting. The results of this new\ndaylighting module were then compared with results of other simulation codes\nand experimental cases both in artificial and natural environments. Excellent\nagreements were obtained, such as the values for luminous efficiencies in a\ntropical and humid climate. In this paper, a comparison of the model output\nwith detailed measures is presented using a dedicated test cell in Reunion\nIsland (French overseas territory in the Indian Ocean), thus confirming the\ninterest for thermal and daylighting designs in low-energy buildings.\nIntroduction Several software packages are available for thermal and airflow\nsimulation in buildings. The most frequently used are ENERGY+ [1], ESP-r [2],\nand TRNSYS [3]. These applications allow an increasing number of models to be\nintegrated, such as airflow, pollutant transport, and daylighting. In the\nlatter category, we may note ENERGY+, ESP-r and ECOTECT [4] software. After\nmore than 20 years of developing a specific code named CODYRUN, we decided to\nadd a lighting module to our software. This paper therefore provides some\ndetails on this evolution and elements of validation. The CODYRUN initial\nsoftware and its validation Developed by the Physics and Mathematical\nEngineering Laboratory for Energy and Environment at the University of Reunion\nIsland, CODYRUN [5-14] is a multi-zone software program integrating ventilation\nand moisture transport transfer in buildings. The software employs a zone\napproach based on nodal analysis and resolves a coupled system describing\nthermal and airflow phenomena. Numerous validation tests of the CODYRUN code\nwere successfully applied to the software. Apart from the daylighting model,\nthe majority applied the BESTEST procedure [15]. The International Energy\nAgency (IEA) sponsors a number of programs to improve the use and associated\ntechnologies of energy. The National Renewable Energy Laboratory (NREL)\ndeveloped BESTEST, which is a method based on comparative testing of building\nsimulation programs, on the IEA's behalf. The procedure consists of a series of\ntest cases buildings that are designed to isolate individual aspects of\nbuilding energy and test the extremes of a program. As the modelling approach\nis very different between codes, the test cases are specified so that input\nequivalency can be defined thus allowing the different cases to be modelled by\nmost of codes. The basis for comparison is a range of results from a number of\nprograms considered to be a state-of-art in United States and Europe.\nAssociated with other specific comparisons, a very confident level of\nvalidation was obtained for the CODYRUN initial software [8].\n",
        "pdf_link": "http://arxiv.org/pdf/1509.04738v1"
    },
    {
        "title": "Problem of optimization of a transport traffic at preliminary\n  registration of queires with use of CBSMAP-model",
        "authors": [
            "Elizaveta V. Kondrashova"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The problem of optimization of a transport traffic at preliminary\nregistration of demands with use of the CBSMAP model is investigated. For the\nsolution of an objective application of the queueing theory and the theory of\ncontrolled processes is supposed.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.05022v1"
    },
    {
        "title": "A balanced rail-to-rail all digital comparator using only standard cells",
        "authors": [
            "Bo Wang",
            "Kezhi Li",
            "Zhongjian Chen",
            "Xinan Wang"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  An all-digital comparator with full input range is presented. It outperforms\nthe nowaday all-digital comparators with its large rail-to-rail input range.\nThis is achieved by the proposed Yin-yang balance mechanism between the two\nlogic gates: NAND3 and OAI (Or-And-Invert). The important design considerations\nto achieve this balance are presented, such as the driving strength\nmanipulation and the use of pre-distortion technique. Constructed only by\ncommercially available digital standard cells, the layout of the proposed\ncomparator is generated automatically by standard digital Place & Route routine\nwithin several minutes. The Verilog code for the proposed circuit is given, and\nthe circuit is successfully implemented in 130nm CMOS technology with the power\nconsumption of 0.176mW at the clock of 330MHz.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.05192v2"
    },
    {
        "title": "Properties of Farey Sequence and their Applications to Digital Image\n  Processing",
        "authors": [
            "Soham Das",
            "Kishaloy Halder",
            "Sanjoy Pratihar",
            "Partha Bhowmick"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Farey sequence has been a topic of interest to the mathematicians since the\nvery beginning of last century. With the emergence of various algorithms\ninvolving the digital plane in recent times, several interesting works related\nwith the Farey sequence have come up. Our work is related with the problem of\nsearching an arbitrary fraction in a Farey sequence and its relevance to image\nprocessing. Given an arbitrary fraction p/q (0 < p < q) and a Farey sequence Fn\nof order n, we propose a novel algorithm using the Regula Falsi method and the\nconcept of Farey table to efficiently find the fraction of Fn closest to p/q.\nAll computations are in the integer domain only, which is its added benefit.\nSome contemporary applications of image processing have also been shown where\nsuch concepts can be incorporated. Experimental results have been furnished to\ndemonstrate its efficiency and elegance.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.07757v1"
    },
    {
        "title": "Yield, Area and Energy Optimization in Stt-MRAMs using failure aware ECC",
        "authors": [
            "Zoha Pajouhi",
            "Xuanyao Fong",
            "Anand Raghunathan",
            "Kaushik Roy"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Spin Transfer Torque MRAMs are attractive due to their non-volatility, high\ndensity and zero leakage. However, STT-MRAMs suffer from poor reliability due\nto shared read and write paths. Additionally, conflicting requirements for data\nretention and write-ability (both related to the energy barrier height of the\nmagnet) makes design more challenging. Furthermore, the energy barrier height\ndepends on the physical dimensions of the free layer. Any variations in the\ndimensions of the free layer lead to variations in the energy barrier height.\nIn order to address poor reliability of STT-MRAMs, usage of Error Correcting\nCodes (ECC) have been proposed. Unlike traditional CMOS memory technologies,\nECC is expected to correct both soft and hard errors in STT_MRAMs. To achieve\nacceptable yield with low write power, stronger ECC is required, resulting in\nincreased number of encoded bits and degraded memory efficiency. In this paper,\nwe propose Failure aware ECC (FaECC), which masks permanent faults while\nmaintaining the same correction capability for soft errors without increased\nencoded bits. Furthermore, we investigate the impact of process variations on\nrun-time reliability of STT-MRAMs. We provide an analysis on the impact of\nprocess variations on the life-time of the free layer and retention failures.\nIn order to analyze the effectiveness of our methodology, we developed a\ncross-layer simulation framework that consists of device, circuit and array\nlevel analysis of STT-MRAM memory arrays. Our results show that using FaECC\nrelaxes the requirements on the energy barrier height, which reduces the write\nenergy and results in smaller access transistor size and memory array area.\nKeywords: STT-MRAM, reliability, Error Correcting Codes, ECC, magnetic memory\n",
        "pdf_link": "http://arxiv.org/pdf/1509.08806v2"
    },
    {
        "title": "Model-independent comparison of simulation output",
        "authors": [
            "Nuno Fachada",
            "Vitor V. Lopes",
            "Rui C. Martins",
            "Agostinho C. Rosa"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Computational models of complex systems are usually elaborate and sensitive\nto implementation details, characteristics which often affect their\nverification and validation. Model replication is a possible solution to this\nissue. It avoids biases associated with the language or toolkit used to develop\nthe original model, not only promoting its verification and validation, but\nalso fostering the credibility of the underlying conceptual model. However,\ndifferent model implementations must be compared to assess their equivalence.\nThe problem is, given two or more implementations of a stochastic model, how to\nprove that they display similar behavior? In this paper, we present a model\ncomparison technique, which uses principal component analysis to convert\nsimulation output into a set of linearly uncorrelated statistical measures,\nanalyzable in a consistent, model-independent fashion. It is appropriate for\nascertaining distributional equivalence of a model replication with its\noriginal implementation. Besides model-independence, this technique has three\nother desirable properties: a) it automatically selects output features that\nbest explain implementation differences; b) it does not depend on the\ndistributional properties of simulation output; and, c) it simplifies the\nmodelers' work, as it can be used directly on simulation outputs. The proposed\ntechnique is shown to produce similar results to the manual or empirical\nselection of output features when applied to a well-studied reference model.\n",
        "pdf_link": "http://arxiv.org/pdf/1509.09174v4"
    },
    {
        "title": "Evolvable Autonomic Management",
        "authors": [
            "Rossi Kamal"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Autonomic management is aimed at adapting to uncertainty. Hence, it is\ndevised as m-connected k-dominating set problem, resembled by dominator and\ndominate, such that dominators are resilient up to m-1 uncertainty among them\nand dominate are resilient up to k-1 uncertainty on their way to dominators.\nTherefore, an evolutionary algorithm GENESIS is proposed, which resolves\nuncertainty by evolving population of solutions, while considering uncertain\nconstraints as sub-problems, started by initial populations by a greedy\nalgorithm AVIDO. Theoretical analysis first justifies original problem as\nNP-hard problem. Eventually, the absence of polynomial time approximation\nscheme necessitates justification of original problem as multiobjective\noptimization problem. Furthermore, approximation to Pareto front is verified to\nbe decomposed into scalar optimization sub-problems, which lays out the\ntheoretical foundation for decomposition based evolutionary solution. Finally,\ncase-study, feasibility analysis and exemplary implication are presented for\nevolvable autonomic management in combined cancer treatment with in-vivo sensor\nnetworks.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.01179v1"
    },
    {
        "title": "Implications of Burn-In Stress on NBTI Degradation",
        "authors": [
            "Mohd Azman Abdul Latif",
            "Noohul Basheer Zain Ali",
            "Fawnizu Azmadi Hussin",
            "Mark Zwolinski"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Burn-in is accepted as a way to evaluate ageing effects in an accelerated\nmanner. It has been suggested that burn-in stress may have a significant effect\non the Negative Bias Temperature Instability (NBTI) of subthreshold CMOS\ncircuits. This paper analyses the effect of burn-in on NBTI in the context of a\nDigital to Analogue Converter (DAC) circuit. Analogue circuits require matched\ndevice pairs; NBTI may cause mismatches and hence circuit failure. The NBTI\ndegradation observed in the simulation analysis indicates that under severe\nstress conditions, a significant voltage threshold mismatch in the DAC beyond\nthe design specification of 2 mV limit can result. Experimental results confirm\nthe sensitivity of the DAC circuit design to NBTI resulting from burn-in.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.01370v1"
    },
    {
        "title": "Spatial Prediction Under Location Uncertainty In Cellular Networks",
        "authors": [
            "Hajer Braham",
            "Sana Ben Jemaa",
            "Gersende Fort",
            "Eric Moulines",
            "Berna Sayrac"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Coverage optimization is an important process for the operator as it is a\ncrucial prerequisite towards offering a satisfactory quality of service to the\nend-users. The first step of this process is coverage prediction, which can be\nperformed by interpolating geo-located measurements reported to the network by\nmobile users' equipments. In previous works, we proposed a low complexity\ncoverage prediction algorithm based on the adaptation of the Geo-statistics\nFixed Rank Kriging (FRK) algorithm. We supposed that the geo-location\ninformation reported with the radio measurements was perfect, which is not the\ncase in reality. In this paper, we study the impact of location uncertainty on\nthe coverage prediction accuracy and we extend the previously proposed\nalgorithm to include geo-location error in the prediction model. We validate\nthe proposed algorithm using both simulated and real field measurements. The\nFRK extended to take into account the location uncertainty proves to enhance\nthe prediction accuracy while keeping a reasonable computational complexity.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.03638v2"
    },
    {
        "title": "Fine-Grained Energy Modeling for the Source Code of a Mobile Application",
        "authors": [
            "Xueliang Li",
            "John P. Gallagher"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Energy efficiency has a significant influence on user experience of\nbattery-driven devices such as smartphones and tablets. The goal of an energy\nmodel for source code is to lay a foundation for the application of\nenergy-saving techniques during software development. The challenge is to\nrelate hardware energy consumption to high-level application code, considering\nthe complex run-time context and software stack. Traditional techniques build\nthe energy model by mapping a hardware energy model onto software constructs;\nthis approach faces obstacles when the software stack consists of a number of\nabstract layers. Another approach that has been followed is to utilize hardware\nor operating system features to estimate software energy information at a\ncoarse level of granularity such as blocks, methods or even applications. In\nthis paper, we explain how to construct a fine-grained energy model for the\nsource code, which is based on \"energy operations\" identified directly from the\nsource code and able to provide more valuable information for code\noptimization. We apply the approach to a class of applications based on a\ngame-engine, and explain the wider applicability of the method.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.04165v2"
    },
    {
        "title": "Wireless communication, identification and sensing technologies enabling\n  integrated logistics: a study in the harbor environment",
        "authors": [
            "Mario G. C. A. Cimino",
            "Nedo Celandroni",
            "Erina Ferro",
            "Davide La Rosa",
            "Filippo Palumbo",
            "Gigliola Vaglini"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  In the last decade, integrated logistics has become an important challenge in\nthe development of wireless communication, identification and sensing\ntechnology, due to the growing complexity of logistics processes and the\nincreasing demand for adapting systems to new requirements. The advancement of\nwireless technology provides a wide range of options for the maritime container\nterminals. Electronic devices employed in container terminals reduce the manual\neffort, facilitating timely information flow and enhancing control and quality\nof service and decision made. In this paper, we examine the technology that can\nbe used to support integration in harbor's logistics. In the literature, most\nsystems have been developed to address specific needs of particular harbors,\nbut a systematic study is missing. The purpose is to provide an overview to the\nreader about which technology of integrated logistics can be implemented and\nwhat remains to be addressed in the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.06175v1"
    },
    {
        "title": "The Virtual Experiences Lab - a platform for global collaborative\n  engineering and beyond",
        "authors": [
            "Ian D. Peake",
            "Jan Olaf Blech",
            "Ian Thomas",
            "Nicholas May",
            "Heinz W. Schmidt",
            "Lasith Fernando",
            "Ravi Sreenivasamurthy"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  We are developing the Virtual Experiences (Vx)Lab, a research and research\ntraining infrastructure and capability platform for global collaboration. VxLab\ncomprises labs with visualisation capabilities, including underpinning\nnetworking to global points of presence, videoconferencing and high-performance\ncomputation, simulation and rendering, and sensors and actuators such as\nrobotic instruments locally and in connected remote labs. VxLab has been used\nfor industry projects in industrial automation, experimental research in cloud\ndeployment, workshops and remote capability demonstrations, teaching\nadvanced-level courses in games development, and student software engineering\nprojects. Our goal is for resources to become a \"catalyst\" for IT-driven\nresearch results both within the university and with external industry\npartners. Use cases include: multi-disciplinary collaboration, prototyping and\ntroubleshooting requiring multiple viewpoints and architectures, dashboards and\ndecision support for global remote planning and operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1510.09077v1"
    },
    {
        "title": "Reliability of Checking an Answer Given by a Mathematical Expression in\n  Interactive Learning Systems",
        "authors": [
            "Vladimir G. Danilov",
            "Ilya S. Turuntaev"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In this article we address the problem of automatic answer checking in\ninteractive learning systems that support mathematical notation. This problem\nconsists of the problem of establishing identities in formal mathematical\nsystems and hence is formally unsolvable. However, there is a way to cope with\nthe issue. We suggest to reinforce the standard algorithm for function\ncomparison with an additional pointwise checking procedure. An error might\nappear in this case. The article provides a detailed analysis of the\nprobability of this error. It appears that the error probability is extremely\nlow in most common cases. Generally speaking, this means that such an\nadditional checking procedure can be quite successfully used in order to\nsupport standard algorithms for functions comparison. The results, obtained in\nthis article, help avoiding some sudden effects of the identity problem, and\nprovide a way to estimate the reliability of answer checking procedure in\ninteractive learning systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.00243v1"
    },
    {
        "title": "Improving Data Quality in Intelligent Transportation Systems",
        "authors": [
            "V. M. Megler",
            "Kristin Tufte",
            "David Maier"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Intelligent Transportation Systems (ITS) use data and information technology\nto improve the operation of our transportation network. ITS contributes to\nsustainable development by using technology to make the transportation system\nmore efficient; improving our environment by reducing emissions, reducing the\nneed for new construction and improving our daily lives through reduced\ncongestion. A key component of ITS is traveler information. The Oregon\nDepartment of Transportation (ODOT) recently implemented a new traveler\ninformation system on selected freeways to provide drivers with travel time\nestimates that allow them to make more informed decisions about routing to\ntheir destinations. The ODOT project aims to improve traffic flow and promote\nefficient traffic movement, which can reduce emissions rates and improve air\nquality. The new ODOT system is based on travel data collected from a\nrecently-increased set of sensors installed on its freeways. Our current\nproject investigates novel data cleaning methodologies and the integration of\nthose methodologies into the prediction of travel times. We use machine\nlearning techniques on our archive to identify suspect data, and calculate\nrevised travel times excluding this suspect data. We compare the resulting\ntravel time predictions to ground-truth data, and to predictions based on\nsimple, rule-based data cleaning. We report on the results of our study using\nqualitative and quantitative methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.03100v1"
    },
    {
        "title": "Customizable Precision of Floating-Point Arithmetic with Bitslice Vector\n  Types",
        "authors": [
            "Shixiong Xu",
            "David Gregg"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Customizing the precision of data can provide attractive trade-offs between\naccuracy and hardware resources. We propose a novel form of vector computing\naimed at arrays of custom-precision floating point data. We represent these\nvectors in bitslice format. Bitwise instructions are used to implement\narithmetic circuits in software that operate on customized bit-precision.\nExperiments show that this approach can be efficient for vectors of\nlow-precision custom floating point types, while providing arbitrary bit\nprecision.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.04716v1"
    },
    {
        "title": "Encoding Distortion Modeling For DWT-Based Wireless EEG Monitoring\n  System",
        "authors": [
            "Alaa Awad",
            "Medhat H. M. Elsayed",
            "Amr Mohamed"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Recent advances in wireless body area sensor net- works leverage wireless and\nmobile communication technologies to facilitate development of innovative\nmedical applications that can significantly enhance healthcare services and\nimprove quality of life. Specifically, Electroencephalography (EEG)-based\napplications lie at the heart of these promising technologies. However, the\ndesign and operation of such applications is challenging. Power consumption\nrequirements of the sensor nodes may turn some of these applications\nimpractical. Hence, implementing efficient encoding schemes are essential to\nreduce power consumption in such applications. In this paper, we propose an\nanalytical distortion model for the EEG-based encoding systems. Using this\nmodel, the encoder can effectively reconfigure its complexity by adjusting its\ncontrol parameters to satisfy application constraints while maintaining\nreconstruction accuracy at the receiver side. The simulation results illustrate\nthat the main parameters that affect the distortion are compression ratio and\nfilter length of the considered DWT-based encoder. Furthermore, it is found\nthat the wireless channel variations have a significant influence on the\nestimated distortion at the receiver side.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.04974v1"
    },
    {
        "title": "An Estimation Method Using Periodic Inspection of Indicators",
        "authors": [
            "Zheng Wang"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper proposes a new approach for estimating the failure time\ndistribution using the indicator data. The indicators, which are checked by\nperiodic inspection of a standby redundant system, only convey whether at least\none failure occurs per interval. The estimation procedure first obtains the\nestimation of the forward recurrence time using the indicator data. Then the\nmean is estimated based on its relationship with the forward recurrence time.\nAnd the estimation of the sampled Cdf is thus derived based on its relationship\nwith the forward recurrence time and the mean. Finally, the Cdf function is\nestimated using interpolation method. The simulation results showed that the\nestimation method performed well for the four Weibull distributions.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.05656v1"
    },
    {
        "title": "Spatio-Temporal Analysis of Team Sports -- A Survey",
        "authors": [
            "Joachim Gudmundsson",
            "Michael Horton"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Team-based invasion sports such as football, basketball and hockey are\nsimilar in the sense that the players are able to move freely around the\nplaying area; and that player and team performance cannot be fully analysed\nwithout considering the movements and interactions of all players as a group.\nState of the art object tracking systems now produce spatio-temporal traces of\nplayer trajectories with high definition and high frequency, and this, in turn,\nhas facilitated a variety of research efforts, across many disciplines, to\nextract insight from the trajectories. We survey recent research efforts that\nuse spatio-temporal data from team sports as input, and involve non-trivial\ncomputation. This article categorises the research efforts in a coherent\nframework and identifies a number of open research questions.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.06994v1"
    },
    {
        "title": "-MAPS: From spatio-temporal data to a weighted and lagged\n  network between functional domains",
        "authors": [
            "Ilias Fountalis",
            "Annalisa Bracco",
            "Bistra Dilkina",
            "Constantine Dovrolis",
            "Shella Keilholz"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  We propose {\\delta}-MAPS, a method that analyzes spatio-temporal data to\nfirst identify the distinct spatial components of the underlying system,\nreferred to as \"domains\", and second to infer the connections between them. A\ndomain is a spatially contiguous region of highly correlated temporal activity.\nThe core of a domain is a point or subregion at which a metric of local\nhomogeneity is maximum across the entire domain. We compute a domain as the\nmaximum-sized set of spatially contiguous cells that include the detected core\nand satisfy a homogeneity constraint, expressed in terms of the average\npairwise cross-correlation across all cells in the domain. Domains may be\nspatially overlapping. Different domains may have correlated activity,\npotentially at a lag, because of direct or indirect interactions. The proposed\nedge inference method examines the statistical significance of each lagged\ncross-correlation between two domains, infers a range of lag values for each\nedge, and assigns a weight to each edge based on the covariance of the two\ndomains. We illustrate the application of {\\delta}-MAPS on data from two\ndomains: climate science and neuroscience.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.07249v3"
    },
    {
        "title": "Philosophical Fictionalism and Problem of Artificial Intelligence",
        "authors": [
            "Sergey B. Kulikov"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The artificial intelligence received broad interpretation as a literary\nimage. This approach did not have unambiguous refering to the scopes of logical\nstudies and mathematical investigations. An author applied methods peculiar to\nthe semiotic approach, offered by Boris Uspensky and Yury Lotman. In addition,\nthe article presented the criticism of modern versions of educational\ntechnologies, which led to the unconditional expectations for possibilities of\ninformation and telecommunication technologies. Methodological culture's\ngrowth, which was described on the base of semiotics and functional approach to\nword formation of new meanings for the description of the studied subjects,\nprovided the development of pupils' thought. As a result, the research opened\nnew prospects on understanding of artificial intelligence within educational\npractice.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.07259v1"
    },
    {
        "title": "Investigating Drivers' Head and Glance Correspondence",
        "authors": [
            "Joonbum Lee",
            "Mauricio Muoz",
            "Lex Fridman",
            "Trent Victor",
            "Bryan Reimer",
            "Bruce Mehler"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The relationship between a driver's glance pattern and corresponding head\nrotation is highly complex due to its nonlinear dependence on the individual,\ntask, and driving context. This study explores the ability of head pose to\nserve as an estimator for driver gaze by connecting head rotation data with\nmanually coded gaze region data using both a statistical analysis approach and\na predictive (i.e., machine learning) approach. For the latter, classification\naccuracy increased as visual angles between two glance locations increased. In\nother words, the greater the shift in gaze, the higher the accuracy of\nclassification. This is an intuitive but important concept that we make\nexplicit through our analysis. The highest accuracy achieved was 83% using the\nmethod of Hidden Markov Models (HMM) for the binary gaze classification problem\nof (1) the forward roadway versus (2) the center stack. Results suggest that\nalthough there are individual differences in head-glance correspondence while\ndriving, classifier models based on head-rotation data may be robust to these\ndifferences and therefore can serve as reasonable estimators for glance\nlocation. The results suggest that driver head pose can be used as a surrogate\nfor eye gaze in several key conditions including the identification of\nhigh-eccentricity glances. Inexpensive driver head pose tracking may be a key\nelement in detection systems developed to mitigate driver distraction and\ninattention.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.07324v1"
    },
    {
        "title": "Loongson IoT Gateway: A Technical Review",
        "authors": [
            "Zhibang Xie",
            "Qingjin Deng"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  A prototype of Loongson IoT (Internet of Things) ZigBee gateway is already\ndesigned and implemented. However, this prototype is not perfect enough because\nof the lack of a number of functions. And a lot of things should be done to\nimprove this prototype, such as adding widely used IEEE 802.11 function, using\na fully open source ZigBee protocol stack to get rid of proprietary implement\nor using a fully open source embedded operating system to support 6LoWPAN, and\nimplementing multiple interfaces.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.07891v5"
    },
    {
        "title": "A General World Model with Poiesis: Poppers Three Worlds updated with\n  Software",
        "authors": [
            "Walter Hehl"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  With the famous Three Worlds of Karl Popper as template, the paper rigorously\nintroduces the concept of software to define the counterpart of the physical\nsubworld. Digesting the scientific-technical view of biology and neurology on a\nhigh level, results in an updated Three Worlds scheme consistent with an\ninformation technical view. Chance and mathematics complete the world model.\nSome simple examples illustrate the move from Poppers view of the world with\nphysics, psyche and World 3, to a new extended model with physics, extended\nsoftware (which we call Poiesis), and Geist (the notion which embodies spirit,\nmind and soul).\n",
        "pdf_link": "http://arxiv.org/pdf/1604.00360v1"
    },
    {
        "title": "Cooperative communications for sleep monitoring in wireless body area\n  networks",
        "authors": [
            "Samiya Shimly",
            "Samaneh Movassaghi",
            "David Smith"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper investigates the performance of cooperative receive diversity, for\nthe wireless body area network (WBAN) radio channel, compliant with the IEEE\n802.15.6 Standard, in the case of monitoring a sleeping person. Extensive WBAN\nmeasurements near the 2.4 GHz ISM band were used. Up to 7 dB and 20%\nimprovement for two-hop communications with the use of relays are empirically\ndemonstrated with respect to outage probability and outage duration, with\n3-branch cooperative selection combining and 3-branch cooperative\nswitch-and-examine combining.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.00818v1"
    },
    {
        "title": "Designing robust watermark barcodes for multiplex long-read sequencing",
        "authors": [
            "Joaqun Ezpeleta",
            "Flavia J. Krsticevic",
            "Pilar Bulacio",
            "Elizabeth Tapia"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  A method for designing sequencing barcodes that can withstand a large number\nof insertion, deletion and substitution errors and are suitable for use in\nmultiplex single-molecule real-time sequencing is presented. The manuscript\nfocuses on the design of barcodes for full-length single-pass reads, impaired\nby challenging error rates in the order of 11%. To the authors' knowledge, this\nis the first method to specifically address this problem without requiring\nupstream quality improvement. The proposed barcodes can multiplex hundreds or\nthousands of samples while achieving sample misassignment probabilities as low\nas $10^{-7}$, and are designed to be compatible with chemical constraints\nimposed by the sequencing process. Software for constructing watermark barcode\nsets and demultiplexing barcoded reads, together with example sets of barcodes\nand synthetic barcoded reads, are freely available at\nwww.cifasis-conicet.gov.ar/ezpeleta/NS-watermark.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.01344v1"
    },
    {
        "title": "A Framework for Predictive Analysis of Stock Market Indices : A Study of\n  the Indian Auto Sector",
        "authors": [
            "Jaydip Sen",
            "Tamal Datta Chaudhuri"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Analysis and prediction of stock market time series data has attracted\nconsiderable interest from the research community over the last decade. Rapid\ndevelopment and evolution of sophisticated algorithms for statistical analysis\nof time series data, and availability of high-performance hardware has made it\npossible to process and analyze high volume stock market time series data\neffectively, in real-time. Among many other important characteristics and\nbehavior of such data, forecasting is an area which has witnessed considerable\nfocus. In this work, we have used time series of the index values of the Auto\nsector in India during January 2010 to December 2015 for a deeper understanding\nof the behavior of its three constituent components, e.g., the trend, the\nseasonal component, and the random component. Based on this structural\nanalysis, we have also designed five approaches for forecasting and also\ncomputed their accuracy in prediction using suitably chosen training and test\ndata sets. Extensive results are presented to demonstrate the effectiveness of\nour proposed decomposition approaches of time series and the efficiency of our\nforecasting techniques, even in presence of a random component and a sharply\nchanging trend component in the time-series.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.04044v1"
    },
    {
        "title": "Real-Time Contingency Analysis with Corrective Transmission Switching -\n  Part II: Results and Discussion",
        "authors": [
            "Xingpeng Li",
            "Mostafa Sahraei-Ardakani",
            "Pranavamoorthy Balasubramanian",
            "Mojdeh Abdi-Khorsand",
            "Kory W. Hedman",
            "Robin Podmore"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper presents the performance of an AC transmission switching (TS)\nbased real-time contingency analysis (RTCA) tool that is introduced in Part I\nof this paper. The approach quickly proposes high quality corrective switching\nactions for relief of potential post-contingency network violations. The\napproach is confirmed by testing it on actual EMS snapshots of two large-scale\nsystems, the Electric Reliability Council of Texas (ERCOT) and the Pennsylvania\nNew Jersey Maryland (PJM) Interconnection; the approach is also tested on data\nprovided by the Tennessee Valley Authority (TVA). The results show that the\ntool effectively reduces post-contingency violations. Fast heuristics are used\nalong with parallel computing to reduce the computational difficulty of the\nproblem. The tool is able to handle the PJM system in about five minutes with a\nstandard desktop computer. Time-domain simulations are performed to check\nsystem stability with corrective transmission switching (CTS). In conclusion,\nthe paper shows that corrective switching is ripe for industry adoption. CTS\ncan provide significant reliability benefits that can be translated into\nsignificant cost savings.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.05571v1"
    },
    {
        "title": "Mobile phone data for public health: towards data-sharing solutions that\n  protect individual privacy and national security",
        "authors": [
            "Caroline O. Buckee",
            "Kenth Eng-Monsen"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  We outline the constraints faced by operators when deciding to share\nde-identified data with researchers or policy makers. We describe a\nconservative approach that we have taken to harness the value of CDRs for\ninfectious disease epidemiology while ensuring that identification of\nindividuals is impossible. We believe this approach serves as a useful and\nhighly conservative model for productive partnerships between mobile operators,\nresearchers, and public health practitioners.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.00864v1"
    },
    {
        "title": "Exploiting AIS Data for Intelligent Maritime Navigation: A Comprehensive\n  Survey",
        "authors": [
            "Enmei Tu",
            "Guanghao Zhang",
            "Lily Rachmawati",
            "Eshan Rajabally",
            "Guang-Bin Huang"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The Automatic Identification System (AIS) tracks vessel movement by means of\nelectronic exchange of navigation data between vessels, with onboard\ntransceiver, terrestrial and/or satellite base stations. The gathered data\ncontains a wealth of information useful for maritime safety, security and\nefficiency. This paper surveys AIS data sources and relevant aspects of\nnavigation in which such data is or could be exploited for safety of seafaring,\nnamely traffic anomaly detection, route estimation, collision prediction and\npath planning.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.00981v1"
    },
    {
        "title": "One-dimensional Cutting Stock Problem with Divisible Items",
        "authors": [
            "Deniz Tanir",
            "Onur Ugurlu",
            "Asli Guler",
            "Urfat Nuriyev"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper considers the one-dimensional cutting stock problem with divisible\nitems, which is a new problem in the cutting stock literature. The problem\nexists in steel industries. In the new problem, each item can be divided into\nsmaller pieces, then they can be recombined again by welding. The objective is\nto minimize both the trim loss and the number of the welds. We present a\nmathematical model and a dynamic programming based heuristic for the problem.\nFurthermore, a software, which is based on the proposed heuristic algorithm, is\ndeveloped to use in MKA company, and its performance is analyzed by solving\nreal-life problems in the steel industry. The computational experiments show\nthe efficiency of the proposed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.01419v1"
    },
    {
        "title": "Leveraging ERP Implementation to Create Intellectual Capital: the Role\n  of Organizational Learning Capability",
        "authors": [
            "Quang V Nguyen",
            "Mary Tate",
            "Philip Calvert",
            "Benoit Aubert"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The extent to which enterprise resource planning (ERP) systems deliver value\nfor organizations has been debated. In this study, we argue that the presence\nof appropriate organizational resources is essential for capturing the\npotential of ERP implementation. We investigate the relationship between ERP\nimplementation and two organizational resources, specifically, Intellectual\nCapital (IC) and Organizational Learning Capability (OLC) to enrich the\nunderstanding of the way the value of ERP implementations can be realized. A\nsample of 226 manufacturing firms in Vietnam was surveyed to test the\ntheoretical model. Structural equation modelling with partial least square\nmethod and two approaches for moderation analysis were used to analyze the\ndata. The results indicate that ERP implementation scope has a positive impact\non intellectual capital (IC). However, firms need to build a certain level of\nOLC to utilize ERP implementation for the enhancement of IC.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.01431v1"
    },
    {
        "title": "Undecidability and Irreducibility Conditions for Open-Ended Evolution\n  and Emergence",
        "authors": [
            "Santiago Hernndez-Orozco",
            "Francisco Hernndez-Quiroz",
            "Hector Zenil"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Is undecidability a requirement for open-ended evolution (OEE)? Using methods\nderived from algorithmic complexity theory, we propose robust computational\ndefinitions of open-ended evolution and the adaptability of computable\ndynamical systems. Within this framework, we show that decidability imposes\nabsolute limits to the stable growth of complexity in computable dynamical\nsystems. Conversely, systems that exhibit (strong) open-ended evolution must be\nundecidable, establishing undecidability as a requirement for such systems.\nComplexity is assessed in terms of three measures: sophistication, coarse\nsophistication and busy beaver logical depth. These three complexity measures\nassign low complexity values to random (incompressible) objects. As time grows,\nthe stated complexity measures allow for the existence of complex states during\nthe evolution of a computable dynamical system. We show, however, that finding\nthese states involves undecidable computations. We conjecture that for similar\ncomplexity measures that assign low complexity values, decidability imposes\ncomparable limits to the stable growth of complexity, and that such behaviour\nis necessary for non-trivial evolutionary systems. We show that the\nundecidability of adapted states imposes novel and unpredictable behaviour on\nthe individuals or populations being modelled. Such behaviour is irreducible.\nFinally, we offer an example of a system, first proposed by Chaitin, that\nexhibits strong OEE.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.01810v4"
    },
    {
        "title": "Big Data Refinement",
        "authors": [
            "Eerke A. Boiten"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  \"Big data\" has become a major area of research and associated funding, as\nwell as a focus of utopian thinking. In the still growing research community,\none of the favourite optimistic analogies for data processing is that of the\noil refinery, extracting the essence out of the raw data. Pessimists look for\ntheir imagery to the other end of the petrol cycle, and talk about the \"data\nexhausts\" of our society.\n  Obviously, the refinement community knows how to do \"refining\". This paper\nexplores the extent to which notions of refinement and data in the formal\nmethods community relate to the core concepts in \"big data\". In particular, can\nthe data refinement paradigm can be used to explain aspects of big data\nprocessing?\n",
        "pdf_link": "http://arxiv.org/pdf/1606.02017v1"
    },
    {
        "title": "Adaptive Quantization Matrices for HD and UHD Display Resolutions in\n  Scalable HEVC",
        "authors": [
            "Lee Prangnell",
            "Victor Sanchez"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  HEVC contains an option to enable custom quantization matrices, which are\ndesigned based on the Human Visual System and a 2D Contrast Sensitivity\nFunction. Visual Display Units, capable of displaying video data at High\nDefinition and Ultra HD display resolutions, are frequently utilized on a\nglobal scale. Video compression artifacts that are present due to high levels\nof quantization, which are typically inconspicuous in low display resolution\nenvironments, are clearly visible on HD and UHD video data and VDUs. The\ndefault QM technique in HEVC does not take into account the video data\nresolution, nor does it take into consideration the associated display\nresolution of a VDU to determine the appropriate levels of quantization\nrequired to reduce unwanted video compression artifacts. Based on this fact, we\npropose a novel, adaptive quantization matrix technique for the HEVC standard,\nincluding Scalable HEVC. Our technique, which is based on a refinement of the\ncurrent HVS-CSF QM approach in HEVC, takes into consideration the display\nresolution of the target VDU for the purpose of minimizing video compression\nartifacts. In SHVC SHM 9.0, and compared with anchors, the proposed technique\nyields important quality and coding improvements for the Random Access\nconfiguration, with a maximum of 56.5% luma BD-Rate reductions in the\nenhancement layer. Furthermore, compared with the default QMs and the Sony QMs,\nour method yields encoding time reductions of 0.75% and 1.19%, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.02042v2"
    },
    {
        "title": "Evaluating the predicted reliability of mechatronic systems: state of\n  the art",
        "authors": [
            "N. Bensaid Amrani",
            "L. Saintis",
            "D. Sarsri",
            "M. Barreau"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Reliability analysis of mechatronic systems is a recent field and a dynamic\nbranch of research. It is addressed whenever there is a need for reliable,\navailable, and safe systems. The studies of reliability must be conducted\nearlier during the design phase, in order to reduce costs and the number of\nprototypes required in the validation of the system. The process of reliability\nis then deployed throughout the full cycle of development. This process is\nbroken down into three major phases: the predictive reliability, the\nexperimental reliability and operational reliability. The main objective of\nthis article is a kind of portrayal of the various studies enabling a\nnoteworthy mastery of the predictive reliability. The weak points are\nhighlighted. Presenting an overview of all the quantitative and qualitative\napproaches concerned with modelling and evaluating the prediction of\nreliability is so important for future reliability studies and for academic\nresearch to come up with new methods and tools. The mechatronic system is a\nhybrid system, it is dynamic, reconfigurable, and interactive. The modeling\ncarried out of reliability prediction must take into account these criteria.\nSeveral methodologies have been developed in this track of research. In this\nregard, the aforementioned methodologies will be analytically sketched in this\npaper.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.05875v1"
    },
    {
        "title": "Some comments on the reliability of NOAA's Storm Events Database",
        "authors": [
            "Renato P. dos Santos"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Storms and other severe weather events can result in fatalities, injuries,\nand property damage. Therefore, preventing such outcomes to the extent possible\nis a key concern, and the scientific community faces an increasing demand for\nregularly updated appraisals of evolving climate conditions and extreme\nweather. NOAA's Storm Events Database is undoubtedly an invaluable resource to\nthe general public, to the professional, and to the researcher. Due to such\nimportance, the primary objective of this study was to explore this database\nand get clues about its reliability. A complete investigation of the damage\nestimates, injuries or fatalities figures is unfeasible due to the extension of\nthe database. However, an exploratory data analysis with the resources of the R\nstatistical data analysis language found that damage reports are missing in\nmore than half of the records, that part of the damage values are incorrect,\nand that, despite all efforts of standardizations, non-standard event type\nnames are still finding their way into the database. These few results are\nenough to demonstrate that the database suffers from incompleteness and\ninconsistencies and should not be used without taking reservations and\nappropriate precautions before advancing any inferences from the data.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.06973v2"
    },
    {
        "title": "Artificial Fun: Mapping Minds to the Space of Fun",
        "authors": [
            "Soenke Ziesche",
            "Roman V. Yampolskiy"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Yampolskiy and others have shown that the space of possible minds is vast,\nactually infinite (Yampolskiy, 2015). A question of interest is 'Which\nactivities can minds perform during their lifetime?' This question is very\nbroad, thus in this article restricted to 'Which non-boring activities can\nminds perform?' The space of potential non-boring activities has been called by\nYudkowsky 'fun space' (Yudkowsky, 2009). This paper aims to discuss the\nrelation between various types of minds and the part of the fun space, which is\naccessible for them.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.07092v1"
    },
    {
        "title": "Project Based Learning of Embedded Systems",
        "authors": [
            "Danco Davcev",
            "Biljana Stojkoska",
            "Slobodan Kalajdziski",
            "Kire Trivodaliev"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Traditional teaching, usually based on lectures and tutorials fosters the\nidea of instruction-driven learning model where students are passive listeners.\nBesides this approach, Project Based Learning (PBL) as a different learning\nparadigm is standing behind constructivism learning theory, where learning from\nreal-world situations is put on the first place. The purpose of this paper is\nto present our approach in learning embedded systems at our University. It is\nbased on combination of traditional (face-to-face) learning and PBL. Our PBL\nrepresents an interdisciplinary project based on wireless sensor monitoring of\nreal-world environment (greenhouse). The students use UML that was shown as an\nexcellent tool for developing such a projects. From the student perspective, we\nfound that this high level of interdisciplinary is very valuable from the point\nof view of facing the students with real-life problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.07498v2"
    },
    {
        "title": "Want Drugs? Use Python",
        "authors": [
            "Micha Nowotka",
            "George Papadatos",
            "Mark Davies",
            "Nathan Dedman",
            "Anne Hersey"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  We describe how Python can be leveraged to streamline the curation, modelling\nand dissemination of drug discovery data as well as the development of\ninnovative, freely available tools for the related scientific community. We\nlook at various examples, such as chemistry toolkits, machine-learning\napplications and web frameworks and show how Python can glue it all together to\ncreate efficient data science pipelines.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.00378v1"
    },
    {
        "title": "Probabilistic Programming and PyMC3",
        "authors": [
            "Peadar Coyle"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In recent years sports analytics has gotten more and more popular. We propose\na model for Rugby data - in particular to model the 2014 Six Nations\ntournament. We propose a Bayesian hierarchical model to estimate the\ncharacteristics that bring a team to lose or win a game, and predict the score\nof particular matches. This is intended to be a brief introduction to\nProbabilistic Programming in Python and in particular the powerful library\ncalled PyMC3.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.00379v1"
    },
    {
        "title": "PyCells for an Open Semiconductor Industry",
        "authors": [
            "Sepideh Alassi",
            "Bertram Winter"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In the modern semiconductor industry, automatic generation of parameterized\nand recurring layout structures plays an important role and should be present\nas a feature in Electronic Design Automation (EDA)-tools. Currently these\nlayout generators are developed with a proprietary programming language and can\nbe used with a specific EDA-tool. Therefore, the semiconductor companies find\nthe development of the layout generators that can be used in all state of the\nart EDA-tools which support OpenAccess database appealing. The goal of this\nproject is to develop computationally efficient layout generators with Python\n(PyCells), for ams AG technologies, that possess all the features of\ncomprehensive layout generators.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.00859v1"
    },
    {
        "title": "Accelerated Evaluation of Automated Vehicles in Car-Following Maneuvers",
        "authors": [
            "Ding Zhao",
            "Xianan Huang",
            "Huei Peng",
            "Henry Lam",
            "David J. LeBlanc"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The safety of Automated Vehicles (AVs) must be assured before their release\nand deployment. The current approach to evaluation relies primarily on (i)\ntesting AVs on public roads or (ii) track testing with scenarios defined in a\ntest matrix. These two methods have completely opposing drawbacks: the former,\nwhile offering realistic scenarios, takes too much time to execute; the latter,\nthough it can be completed in a short amount of time, has no clear correlation\nto safety benefits in the real world. To avoid the aforementioned problems, we\npropose Accelerated Evaluation, focusing on the car-following scenario. The\nstochastic human-controlled vehicle (HV) motions are modeled based on 1.3\nmillion miles of naturalistic driving data collected by the University of\nMichigan Safety Pilot Model Deployment Program. The statistics of the HV\nbehaviors are then modified to generate more intense interactions between HVs\nand AVs to accelerate the evaluation procedure. The Importance Sampling theory\nwas used to ensure that the safety benefits of AVs are accurately assessed\nunder accelerated tests. Crash, injury and conflict rates for a simulated AV\nare simulated to demonstrate the proposed approach. Results show that test\nduration is reduced by a factor of 300 to 100,000 compared with the\nnon-accelerated (naturalistic) evaluation. In other words, the proposed\ntechniques have great potential for accelerating the AV evaluation process.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.02687v2"
    },
    {
        "title": "Generating Cycloidal Gears for 3D Printing",
        "authors": [
            "Sunny Daniels"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  (Shortened version of abstract in article itself)\n  This article describes an algorithm for producing, for any desired resolution\nand any desired numbers of wheel and pinion teeth, polygonal approximations to\nthe shapes of a pair of cycloidal gears that mesh correctly. An Octave\nimplementation of the algorithm, mostly written in 2014, is included. The\nOctave implementation contains a (crude, but evidently adequate, at least for\nreasonable numbers of wheel and pinion teeth) solution of the problem of\niteratively finding the generating wheel angle corresponding to the tips of the\ntooth addenda.\n  However, this Octave implementation does not contain a good solution to the\nproblem of automatically determining the generating wheel angles required to\nproduce a polygon which approximates the curved addenda to a resolution\nspecified by the user. A proposed better solution to this problem, involving a\npriority queue, is discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.03739v1"
    },
    {
        "title": "8th European Conference on Python in Science (EuroSciPy 2015)",
        "authors": [
            "Nelle Varoquaux"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The 8th edition of the European Conference on Python in Science, EuroSciPy\nwas held for the second time in the beautiful city of Cambridge, UK from\nAugust, 26th to 29th, 2014. More than 200 participants, both from academia and\nindustry, attended the conference.\n  As usual, the conference kicked off with two days of tutorials, divided into\nan introductory and an advanced track. The introductory track, presented by\nJoris Vankerschaver, Valerio Maggio Joris Van den Bossche, Stijn Van Hoey and\nNicolas Rougier, gave a quick but thorough overview of the SciPy stack, while\nthe experience track focused on different advanced topics. This second track\nbegan with an introduction to Bokeh, by Bryan Van den Ven, followed by an image\nprocessing tutorial with scikit-image by Emmanuelle Gouillart and Juan\nNunez-Iglesias. The afternoon continued with two tutorials on data analysis:\nthe first, intitulated \"How 'good' is your model, and how can you make it\nbetter?\" (by Chih-Chun Chen, Dimitry Foures, Elena Chatzimichali, Giuseppe\nVettigli) focused on the challenges face while attempting model selections, and\nthe first day concluded with a statistics in python tutorial by Gael Varoquaux.\nDuring the second day, the attendees tackled an in depth 4 hour tutorial on\nCython, presented by Stefan Behnel, and a crash course on \"Evidence-Based\nTeaching: What We Know and How to Use It\", by Greg Wilson.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.03971v1"
    },
    {
        "title": "Characterizing Smartphone Power Management in the Wild",
        "authors": [
            "Mohammad A. Hoque",
            "Sasu Tarkoma"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  For better reliability and prolonged battery life, it is important that users\nand vendors understand the quality of charging and the performance of\nsmartphone batteries. Considering the diverse set of devices and user behavior\nit is a challenge. In this work, we analyze a large collection of battery\nanalytics dataset collected from 30K devices of 1.5K unique smartphone models.\nWe analyze their battery properties and state of charge while charging, and\nreveal the characteristics of different components of their power management\nsystems: charging mechanisms, state of charge estimation techniques, and their\nbattery properties. We explore diverse charging behavior of devices and their\nusers.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.06402v1"
    },
    {
        "title": "A Step towards Advanced Metering for the Smart Grid: A Survey of Energy\n  Monitors",
        "authors": [
            "Anwar Ul Haq",
            "Hans-Arno Jacobsen"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The smart grid initiative has encouraged utility companies worldwide to\nrollout new and smarter versions of energy meters. Before an extensive rollout,\nwhich is both labor-intensive and incurs high capital costs, consumers need to\nbe incentivized to reap the long-term benefits of smart grid. Off-the-shelf\nenergy monitors can provide consumers with an insight of such potential\nbenefits. Since energy monitors are owned by the consumer, the consumer has\ngreater control over data which significantly reduces privacy and data\nconfidentiality concerns. We evaluate several existing energy monitors using an\nonline technical survey and online product literature. For consumers, the use\nof different off-the-shelf energy monitors can help demonstrate the potential\ngains of smart grid. Our survey indicates a trend towards incorporation of\nstate-of-the-art capabilities, like appliance level monitoring through load\ndisaggregation in energy monitors, which can encourage effective consumer\nparticipation. Multiple sensor types and ratings allow some monitors to operate\nin various configurations and environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.07780v1"
    },
    {
        "title": "Example Data Sets and Collections for BeSpaceD Explained",
        "authors": [
            "Keith Foster",
            "Jan Olaf Blech"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In this report, we present example data sets and collections for the BeSpaceD\nplatform. BeSpaceD is a spatio-temporal modelling and reasoning software\nframework. We describe the content of a number of the data sets and how the\ndata was obtained. We also present the programming API in BeSpaceD used to\nstore and access these data sets so that future BeSpaceD users can utilise the\ndata collections in their own experiments with minimal effort and expand the\nlibrary of data collections for BeSpaceD.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.00433v1"
    },
    {
        "title": "RFID-Cloud Smart Cart System",
        "authors": [
            "Yerlan Berdaliyev",
            "Alex Pappachen James"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The main purpose of this work is in reducing the queuing delays in major\nsupermarkets or other shopping centers by means of an Electronic Smart Cart\nSystem which will introduce an intellectual approach to billing process through\nRFID technology. Smart Cart System is a cooperative performance of three\nseparate systems: a website developed for the shopping market, electronic smart\ncart device and anti-theft RFID gates. This project focuses on developing the\nelectronic smart cart device itself. It involves an embedded electronic\nhardware that consists of an OLED display, Arduino Mega 2560 board, a\nspecifically designed PCB, a Wi-Fi module, 13.56 MHz HF RFID reader, a power\nsupply and a shopping cart.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.03724v1"
    },
    {
        "title": "On the Origin of Samples: Attribution of Output to a Particular\n  Algorithm",
        "authors": [
            "Roman V. Yampolskiy"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  With unprecedented advances in genetic engineering we are starting to see\nprogressively more original examples of synthetic life. As such organisms\nbecome more common it is desirable to be able to distinguish between natural\nand artificial life forms. In this paper, we present this challenge as a\ngeneralized version of Darwin's original problem, which he so brilliantly\naddressed in On the Origin of Species. After formalizing the problem of\ndetermining origin of samples we demonstrate that the problem is in fact\nunsolvable, in the general case, if computational resources of considered\noriginator algorithms have not been limited and priors for such algorithms are\nknown to be equal. Our results should be of interest to astrobiologists and\nscientists interested in producing a more complete theory of life, as well as\nto AI-Safety researchers.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.06172v1"
    },
    {
        "title": "A Generalization of the Directed Graph Layering Problem",
        "authors": [
            "Ulf Regg",
            "Thorsten Ehlers",
            "Miro Spnemann",
            "Reinhard von Hanxleden"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The Directed Layering Problem (DLP) solves a step of the widely used\nlayer-based approach to automatically draw directed acyclic graphs. To cater\nfor cyclic graphs, usually a preprocessing step is used that solves the\nFeedback Arc Set Problem (FASP) to make the graph acyclic before a layering is\ndetermined. Here we present the Generalized Layering Problem (GLP), which\nsolves the combination of DLP and FASP simultaneously, allowing general graphs\nas input. We present an integer programming model and a heuristic to solve the\nNP-complete GLP and perform thorough evaluations on different sets of graphs\nand with different implementations for the steps of the layer-based approach.\nWe observe that GLP reduces the number of dummy nodes significantly, can\nproduce more compact drawings, and improves on graphs where DLP yields poor\naspect ratios.\n",
        "pdf_link": "http://arxiv.org/pdf/1608.07809v1"
    },
    {
        "title": "Energy Transparency for Deeply Embedded Programs",
        "authors": [
            "Kyriakos Georgiou",
            "Steve Kerrison",
            "Zbigniew Chamski",
            "Kerstin Eder"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Energy transparency is a concept that makes a program's energy consumption\nvisible, from hardware up to software, through the different system layers.\nSuch transparency can enable energy optimizations at each layer and between\nlayers, and help both programmers and operating systems make energy-aware\ndecisions. In this paper, we focus on deeply embedded devices, typically used\nfor Internet of Things (IoT) applications, and demonstrate how to enable energy\ntransparency through existing Static Resource Analysis (SRA) techniques and a\nnew target-agnostic profiling technique, without hardware energy measurements.\nOur novel mapping technique enables software energy consumption estimations at\na higher level than the Instruction Set Architecture (ISA), namely the LLVM\nIntermediate Representation (IR) level, and therefore introduces energy\ntransparency directly to the LLVM optimizer. We apply our energy estimation\ntechniques to a comprehensive set of benchmarks, including single- and also\nmulti-threaded embedded programs from two commonly used concurrency patterns,\ntask farms and pipelines. Using SRA, our LLVM IR results demonstrate a high\naccuracy with a deviation in the range of 1% from the ISA SRA. Our profiling\ntechnique captures the actual energy consumption at the LLVM IR level with an\naverage error of 3%.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.02193v3"
    },
    {
        "title": "DELTA: Data Extraction and Logging Tool for Android",
        "authors": [
            "Mauro Conti",
            "Elia Dal Santo",
            "Riccardo Spolaor"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In the past few years, the use of smartphones has increased exponentially,\nand so have the capabilities of such devices. Together with an increase in raw\nprocessing power, modern smartphones are equipped with a wide variety of\nsensors and expose an extensive set of API (Accessible Programming Interface).\nThese capabilities allow us to extract a wide spectrum of data that ranges from\ninformation about the environment (e.g., position, orientation) to user habits\n(e.g., which apps she uses and when), as well as about the status of the\noperating system itself (e.g., memory, network adapters). This data can be\nextremely valuable in many research fields such as user authentication,\nintrusion detection and detection of information leaks. For these reasons,\nresearchers need to use a solid and reliable logging tool to collect data from\nmobile devices.\n  In this paper, we first survey the existing logging tools available on the\nAndroid platform, comparing the features offered by different tools and their\nimpact on the system, and highlighting some of their shortcomings. Then, we\npresent DELTA - Data Extraction and Logging Tool for Android, which improves\nthe existing Android logging solutions in terms of flexibility, fine-grained\ntuning capabilities, extensibility, and available set of logging features. We\nperformed a full implementation of DELTA and we run a thorough evaluation on\nits performance. The results show that our tool has low impact on the\nperformance of the system, on battery consumption, and on user experience.\nFinally, we make the DELTA source code and toolset available to the research\ncommunity.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.02769v1"
    },
    {
        "title": "Knowledge management and measurement in Public Sector Organizations",
        "authors": [
            "Hector Perez Lopez-Portillo"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Knowledge Management (KM) is a strategic component that enables development,\ngrowth and continuous improvement of Public Sector Organizations (PSO). This\nthesis is bounded to this specific context. Indeed, we critically and\ncomprehensively study the factors that characterize KM strategies and those\nthat foster its development and success in PSO, then finally we propose metrics\nto measure and evaluate, in order to continuous and systematically improve KM\npractices in PSO. Main problems are related to the lack of academic literature\nthat explains the elements that KM address in the given context. In addition,\nit is identified as a problem the lack of criteria for measuring and evaluating\nKM in PSO, from a different viewpoint than business perspective. The\ncontribution of this thesis is that it provides valuable elements for an\nacademic debate on the previous factors, strategies and metrics to promote KM\ninitiatives in PSO. To achieve the research objective of this thesis we\nperformed a comprehensive systematic literature review in order to discover\nwhat the KM critical success factors are, and also we integrated and proposed\nsome metrics to evaluate and assess the performance of KM in PSO. We conducted\nan in-depth study among different Public Sector Organizations in order to learn\nwhat are the critical success factors that must be first considered before\nimplement KM initiatives. based on this. Finally, based on this methodological\nproposal and as a result of this research, we were able to analyze and explain\nthe critical success factors, we identified some strategies to encourage the\nsuccess of KM and integrated a proposal of metrics, from different approaches,\nfor KM in PSO.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.02995v1"
    },
    {
        "title": "Toward an Algebraic Theory of Systems",
        "authors": [
            "Christian Matt",
            "Ueli Maurer",
            "Christopher Portmann",
            "Renato Renner",
            "Bjrn Tackmann"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  We propose the concept of a system algebra with a parallel composition\noperation and an interface connection operation, and formalize\ncomposition-order invariance, which postulates that the order of composing and\nconnecting systems is irrelevant, a generalized form of associativity.\nComposition-order invariance explicitly captures a common property that is\nimplicit in any context where one can draw a figure (hiding the drawing order)\nof several connected systems, which appears in many scientific contexts. This\nabstract algebra captures settings where one is interested in the behavior of a\ncomposed system in an environment and wants to abstract away anything internal\nnot relevant for the behavior. This may include physical systems, electronic\ncircuits, or interacting distributed systems.\n  One specific such setting, of special interest in computer science, are\nfunctional system algebras, which capture, in the most general sense, any type\nof system that takes inputs and produces outputs depending on the inputs, and\nwhere the output of a system can be the input to another system. The behavior\nof such a system is uniquely determined by the function mapping inputs to\noutputs. We consider several instantiations of this very general concept. In\nparticular, we show that Kahn networks form a functional system algebra and\nprove their composition-order invariance.\n  Moreover, we define a functional system algebra of causal systems,\ncharacterized by the property that inputs can only influence future outputs,\nwhere an abstract partial order relation captures the notion of \"later\". This\nsystem algebra is also shown to be composition-order invariant and appropriate\ninstantiations thereof allow to model and analyze systems that depend on time.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.04293v2"
    },
    {
        "title": "Virtual Micromagnetics: A Framework for Accessible and Reproducible\n  Micromagnetic Simulation",
        "authors": [
            "Mark Vousden",
            "Marc-Antonio Bisotti",
            "Maximilian Albert",
            "Hans Fangohr"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Computational micromagnetics requires numerical solution of partial\ndifferential equations to resolve complex interactions in magnetic\nnanomaterials. The Virtual Micromagnetics project described here provides\nvirtual machine simulation environments to run open-source micromagnetic\nsimulation packages. These environments allow easy access to simulation\npackages that are often difficult to compile and install, and enable\nsimulations and their data to be shared and stored in a single virtual hard\ndisk file, which encourages reproducible research. Virtual Micromagnetics can\nbe extended to automate the installation of micromagnetic simulation packages\non non-virtual machines, and to support closed-source and new open-source\nsimulation packages, including packages from disciplines other than\nmicromagnetics, encouraging reuse. Virtual Micromagnetics is stored in a public\nGitHub repository under a three-clause Berkeley Software Distribution (BSD)\nlicense.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.05135v2"
    },
    {
        "title": "Organized Complexity: is Big History a Big Computation?",
        "authors": [
            "Jean-Paul Delahaye",
            "Clement Vidal"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The concept of \"logical depth\" introduced by Charles H. Bennett (1988) seems\nto capture, at least partially, the notion of organized complexity, so central\nin big history. More precisely, the increase in organized complexity refers\nhere to the wealth, variety and intricacy of structures, and should not be\nconfused with the increase of random complexity, formalized by Kolmogorov\n(1965). If Bennett is right in proposing to assimilate organized complexity\nwith \"computational content\", then the fundamental cause of the increase of\ncomplexity in the universe is the existence of computing mechanisms with\nmemory, and able to cumulatively create and preserve computational contents. In\nthis view, the universe computes, remembers its calculations, and reuses them\nto conduct further computations. Evolutionary mechanisms are such forms of\ncumulative computation with memory and we owe them the organized complexity of\nlife. Language, writing, culture, science and technology can also be analyzed\nas computation mechanisms generating, preserving and accelerating the increase\nin organized complexity. The main unifying theme for big history is the energy\nrate density, a metric based on thermodynamics. However useful, this metric\ndoes not provide much insight into the role that information and computation\nplay in our universe. The concept of \"logical depth\" provides a new lens to\nexamine the increase of organized complexity. We argue in this paper that\norganized complexity is a valid and useful way to make sense of big history.\nAdditionally, logical depth has a rigorous formal definition in theoretical\ncomputer science that hints at a broader research program to quantify\ncomplexity in the universe.\n  Keywords: organized complexity, Kolmogorov complexity, logical depth, big\nhistory, cosmic evolution, evolution, complexity, complexification,\ncomputation, artificial life, philosophy of information\n",
        "pdf_link": "http://arxiv.org/pdf/1609.07111v2"
    },
    {
        "title": "The curse of variety in computing, and what can be done about it",
        "authors": [
            "J Gerard Wolff"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Excess freedom in how computers are used creates problems that include: bit\nrot, problems with big data, problems in the creation and debugging of\nsoftware, and problems with cyber security. To tame excess freedom, \"tough\nlove\" is needed in the form of a {\\em universal framework for the\nrepresentation and processing of diverse kinds of knowledge} (UFK). The \"SP\nmachine\", based on the \"SP theory of intelligence\", has the potential to\nprovide that framework and to help solve the problems above. There is potential\nto reduce the near-4000 different kinds of computer file to one, and to reduce\nthe hundreds of different computer languages to one.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.08517v1"
    },
    {
        "title": "SWoTSuite: A Development Framework for Prototyping Cross-domain Semantic\n  Web of Things Applications",
        "authors": [
            "Pankesh Patel",
            "Amelie Gyrard",
            "Dhavalkumar Thakker",
            "Amit Sheth",
            "Martin Serrano"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Semantic Web of Things (SWoT) applications focus on providing a wide-scale\ninteroperability that allows the sharing of IoT devices across domains and the\nreusing of available knowledge on the web. However, the application development\nis difficult because developers have to do various tasks such as designing an\napplication, annotating IoT data, interpreting data, and combining application\ndomains.\n  To address the above challenges, this paper demonstrates SWoTSuite, a toolkit\nfor prototyping SWoT applications. It hides the use of semantic web\ntechnologies as much as possible to avoid the burden of designing SWoT\napplications that involves designing ontologies, annotating sensor data, and\nusing reasoning mechanisms to enrich data. Taking inspiration from sharing and\nreuse approaches, SWoTSuite reuses data and vocabularies. It leverages existing\ntechnologies to build applications. We take a hello world naturopathy\napplication as an example and demonstrate an application development process\nusing SWoTSuite. The demo video is available at URL:\nhttp://tinyurl.com/zs9flrt.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.09014v1"
    },
    {
        "title": "Non-Intrusive Load Monitoring: A Review and Outlook",
        "authors": [
            "Christoph Klemenjak",
            "Peter Goldsborough"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  With the roll-out of smart meters the importance of effective non-intrusive\nload monitoring (NILM) techniques has risen rapidly. NILM estimates the power\nconsumption of individual devices given their aggregate consumption. In this\nway, the combined consumption must only be monitored at a single, central point\nin the household, providing various advantages such as reduced cost for\nmetering equipment. In this paper we discuss the fundamental building-blocks of\nNILM, first giving a taxonomy of appliance models and device signatures and\nthen explaining common supervised and unsupervised learning methods.\nFurthermore, we outline a fundamental algorithm that tackles the task of NILM.\nSubsequently, this paper reviews recent research that has brought novel insight\nto the field and more effective techniques. Finally, we formulate future\nchallenges in the domain of NILM and smart meters.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.01191v1"
    },
    {
        "title": "Experimental Characterization of In Vivo Wireless Communication Channels",
        "authors": [
            "A. Fatih Demir",
            "Qammer H. Abbasi",
            "Z. Esat Ankarali",
            "Marwa Qaraqe",
            "Erchin Serpedin",
            "Huseyin Arslan"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In vivo wireless medical devices have a critical role in healthcare\ntechnologies due to their continuous health monitoring and noninvasive surgery\ncapabilities. In order to fully exploit the potential of such devices, it is\nnecessary to characterize the in vivo wireless communication channel which will\nhelp to build reliable and high-performance communication systems. This paper\npresents preliminary results of experimental characterization for this\nfascinating communications medium on a human cadaver and compares the results\nwith numerical studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.01516v1"
    },
    {
        "title": "CONE: Zero-Calibration Accurate Confidence Estimation for Indoor\n  Localization Systems",
        "authors": [
            "Rizanne Elbakly",
            "Moustafa Youssef"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Accurate estimation of the confidence of an indoor localization system is\ncrucial for a number of applications including crowd-sensing applications,\nmap-matching services, and probabilistic location fusion techniques; all of\nwhich lead to an enhanced user experience. Current approaches for quantifying\nthe output accuracy of a localization system in real-time either do not provide\na distance metric, require an extensive training process, and/or are tailored\nto a specific localization system. In this paper, we present the design,\nimplementation, and evaluation of CONE: a novel calibration-free accurate\nconfidence estimation system that can work in real-time with any location\ndetermination system. CONE builds on a sound theoretical model that allows it\nto trade the required user confidence with tight bound on the estimated\nconfidence radius. We also introduce a new metric for evaluating confidence\nestimation systems that can capture new aspects of their performance.\nEvaluation of CONE on Android phones in a typical testbed using the iBeacons\nBLE technology with a side-by-side comparison with traditional confidence\nestimation techniques shows that CONE can achieve a consistent median absolute\nerror difference accuracy of less than 2.7m while estimating the user position\nmore than 80% of the time within the confidence circle. This is significantly\nbetter than the state-of-the-art confidence estimation systems that are\ntailored to the specific localization system in use. Moreover, CONE does not\nrequire any calibration and therefore provides a scalable and ubiquitous\nconfidence estimation system for pervasive applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.02274v1"
    },
    {
        "title": "Doing Moore with Less -- Leapfrogging Moore's Law with Inexactness for\n  Supercomputing",
        "authors": [
            "Sven Leyffer",
            "Stefan M. Wild",
            "Mike Fagan",
            "Marc Snir",
            "Krishna Palem",
            "Kazutomo Yoshii",
            "Hal Finkel"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Energy and power consumption are major limitations to continued scaling of\ncomputing systems. Inexactness, where the quality of the solution can be traded\nfor energy savings, has been proposed as an approach to overcoming those\nlimitations. In the past, however, inexactness necessitated the need for highly\ncustomized or specialized hardware. The current evolution of commercial\noff-the-shelf(COTS) processors facilitates the use of lower-precision\narithmetic in ways that reduce energy consumption. We study these new\nopportunities in this paper, using the example of an inexact Newton algorithm\nfor solving nonlinear equations. Moreover, we have begun developing a set of\ntechniques we call reinvestment that, paradoxically, use reduced precision to\nimprove the quality of the computed result: They do so by reinvesting the\nenergy saved by reduced precision.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.02606v2"
    },
    {
        "title": "Highly Robust Clustering of GPS Driver Data for Energy Efficient Driving\n  Style Modelling",
        "authors": [
            "Michael Breu",
            "Laurent Hoeltgen",
            "Ali Sharifi Boroujerdi",
            "Ashkan Mansouri Yarahmadi"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper presents a novel approach to distinguish driving styles with\nrespect to their energy efficiency. A distinct property of our method is that\nit relies exclusively on Global Positioning System (GPS) logs of drivers. This\nsetting is highly relevant in practice as these data can easily be acquired.\n  Relying on positional data alone means that all derived features will be\ncorrelated, so we strive to find a single quantity that allows us to perform\nthe driving style analysis. To this end we consider a robust variation of the\nso called jerk of a movement. We show that our feature choice outperforms other\nmore commonly used jerk-based formulations and we discuss the handling of\nnoisy, inconsistent, and incomplete data as this is a notorious problem when\ndealing with real-world GPS logs.\n  Our solving strategy relies on an agglomerative hierarchical clustering\ncombined with an L-term heuristic to determine the relevant number of clusters.\nIt can easily be implemented and performs fast, even on very large, real-world\ndata sets. Experiments show that our approach is robust against noise and able\nto discern different driving styles.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.02815v1"
    },
    {
        "title": "Design and Implementation of an Antenna Model for the Cooja simulator",
        "authors": [
            "Vishwesh Rege"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  COOJA is a network simulator developed for wireless sensor networks. It can\nbe used for high-level algorithm development as well as low-level device driver\nimplementations for accurate simulation of wireless sensor networks before\ndeployment. However, in a simulation Cooja assumes that the nodes are only\nequipped with omnidirectional antennas. There is currently no support for\ndirectional antennas. Due to the growing interest in the use of directional or\nsmart antennas in wireless sensor networks, a model that can support\ndirectional antennas is essential for the realistic simulations of protocols\nrelying on directional communication. This paper presents work on extending\nCOOJA with a directional antenna model.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.06129v1"
    },
    {
        "title": "A Survey: Embedded Systems Supporting By Different Operating Systems",
        "authors": [
            "Qamar Jabeen",
            "Fazlullah Khan",
            "Muhammad Nouman Hayat",
            "Haroon Khan",
            "Syed Roohullah Jan",
            "Farman Ullah"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In these days embedded system have an important role in different Fields and\napplications like Network embedded system , Real-time embedded systems which\nsupports the mission-critical domains, mostly having the time constraints,\nStand-alone systems which includes the network router etc. A great deployment\nin the processors made for completing the demanding needs of the users. There\nis also a large-scale deployment occurs in sensor networks for providing the\nadvance facilities, for handled such type of embedded systems a specific\noperating system must provide. This paper presents some software\ninfrastructures that have the ability of supporting such types of embedded\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.07899v1"
    },
    {
        "title": "Perspectives and Networks",
        "authors": [
            "Mathilde Noual"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The perspective we take on a system determines the features and properties of\nthis system that we are focusing on. It determines where we search for causes\nto explain the effects on the system that we observe. It determines the terms\nin which we expect the information about the system to be expressed. And it can\nalso influence the choice of formalism that will be used to convey the\ninformation. using Boolean Automata Networks as prototypes of interaction\nsystems, this paper means to start making these considerations concrete in\norder to draw a practical benefit out of them.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.08765v1"
    },
    {
        "title": "Causality and Networks",
        "authors": [
            "Mathilde Noual"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Causality is omnipresent in scientists' verbalisations of their\nunderstanding, even though we have no formal consensual scientific definition\nfor it. In Automata Networks, it suffices to say that automata \"influence\" one\nanother to introduce a notion of causality. One might argue that this merely is\nan incidental side effect of preferring statements expressed in natural\nlanguages to mathematical formulae. The discussion of this paper shows that if\nthis is the case, then it is worth considering the effects of those preferences\non the contents of the statements we make and the formulae we derive. And if it\nis not the case, that causality is a mere incidental side effect of our\npreferences of formulation, then causality must be worth some scientific\nattention per se. In any case, the paper illustrates how the innate sense of\ncausality we have may be made deliberate and formal use of without having to\npin down the elusive notion of causality to anything fixed and formal that\nwouldn't do justice to the wide range of ways it is involved in science-making.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.08766v1"
    },
    {
        "title": "Novel Grid Topology Estimation Technique Exploiting PLC Modems",
        "authors": [
            "Federico Passerini",
            "Andrea M. Tonello"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  A fundamental requirement to develop routing strategies in power line\nnetworks is the knowledge of the network topology, which might not be complete.\nIn this work, we present a novel method to derive the topology of a\ndistribution network that exploits the capability of Power Line Communication\nmodems to measure the network admittance, and we report the most significant\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.09267v2"
    },
    {
        "title": "Stochastic Development Regression on Non-Linear Manifolds",
        "authors": [
            "Line Khnel",
            "Stefan Sommer"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  We introduce a regression model for data on non-linear manifolds. The model\ndescribes the relation between a set of manifold valued observations, such as\nshapes of anatomical objects, and Euclidean explanatory variables. The approach\nis based on stochastic development of Euclidean diffusion processes to the\nmanifold. Defining the data distribution as the transition distribution of the\nmapped stochastic process, parameters of the model, the non-linear analogue of\ndesign matrix and intercept, are found via maximum likelihood. The model is\nintrinsically related to the geometry encoded in the connection of the\nmanifold. We propose an estimation procedure which applies the Laplace\napproximation of the likelihood function. A simulation study of the performance\nof the model is performed and the model is applied to a real dataset of Corpus\nCallosum shapes.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.00291v1"
    },
    {
        "title": "A Survey on Non-Intrusive Load Monitoring Methodies and Techniques for\n  Energy Disaggregation Problem",
        "authors": [
            "Anthony Faustine",
            "Nerey Henry Mvungi",
            "Shubi Kaijage",
            "Kisangiri Michael"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The rapid urbanization of developing countries coupled with explosion in\nconstruction of high rising buildings and the high power usage in them calls\nfor conservation and efficient energy program. Such a program require\nmonitoring of end-use appliances energy consumption in real-time. The worldwide\nrecent adoption of smart-meter in smart-grid, has led to the rise of\nNon-Intrusive Load Monitoring (NILM); which enables estimation of\nappliance-specific power consumption from building's aggregate power\nconsumption reading. NILM provides households with cost-effective real-time\nmonitoring of end-use appliances to help them understand their consumption\npattern and become part and parcel of energy conservation strategy. This paper\npresents an up to date overview of NILM system and its associated methods and\ntechniques for energy disaggregation problem. This is followed by the review of\nthe state-of-the art NILM algorithms. Furthermore, we review several\nperformance metrics used by NILM researcher to evaluate NILM algorithms and\ndiscuss existing benchmarking framework for direct comparison of the state of\nthe art NILM algorithms. Finally, the paper discuss potential NILM use-cases,\npresents an overview of the public available dataset and highlight challenges\nand future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.00785v3"
    },
    {
        "title": "PACO: A System-Level Abstraction for On-Loading Contextual Data to\n  Mobile Devices",
        "authors": [
            "Nathaniel Wendt",
            "Christine Julien"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Spatiotemporal context is crucial in modern mobile applications that utilize\nincreasing amounts of context to better predict events and user behaviors,\nrequiring rich records of users' or devices' spatiotemporal histories.\nMaintaining these rich histories requires frequent sampling and indexed storage\nof spatiotemporal data that pushes the limits of resource-constrained mobile\ndevices. Today's apps offload processing and storing contextual information,\nbut this increases response time, often relies on the user's data connection,\nand runs the very real risk of revealing sensitive information. In this paper\nwe motivate the feasibility of on-loading large amounts of context and\nintroduce PACO (Programming Abstraction for Contextual On-loading), an\narchitecture for on-loading data that optimizes for location and time while\nallowing flexibility in storing additional context. The PACO API's innovations\nenable on-loading very dense traces of information, even given devices'\nresource constraints. Using real-world traces and our implementation for\nAndroid, we demonstrate that PACO can support expressive application queries\nentirely on-device. Our quantitative evaluation assesses PACO's energy\nconsumption, execution time, and spatiotemporal query accuracy. Further, PACO\nfacilitates unified contextual reasoning across multiple applications and also\nsupports user-controlled release of contextual data to other devices or the\ncloud; we demonstrate these assets through a proof-of-concept case study.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.03504v1"
    },
    {
        "title": "RapidProM: Mine Your Processes and Not Just Your Data",
        "authors": [
            "Wil M. P. van der Aalst",
            "Alfredo Bolt",
            "Sebastiaan J. van Zelst"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The number of events recorded for operational processes is growing every\nyear. This applies to all domains: from health care and e-government to\nproduction and maintenance. Event data are a valuable source of information for\norganizations that need to meet requirements related to compliance, efficiency,\nand customer service. Process mining helps to turn these data into real value:\nby discovering the real processes, by automatically identifying bottlenecks, by\nanalyzing deviations and sources of non-compliance, by revealing the actual\nbehavior of people, etc. Process mining is very different from conventional\ndata mining and machine learning techniques. ProM is a powerful open-source\nprocess mining tool supporting hundreds of analysis techniques. However, ProM\ndoes not support analysis based on scientific workflows. RapidProM, an\nextension of RapidMiner based on ProM, combines the best of both worlds.\nComplex process mining workflows can be modeled and executed easily and\nsubsequently reused for other data sets. Moreover, using RapidProM, one can\nbenefit from combinations of process mining with other types of analysis\navailable through the RapidMiner marketplace.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.03740v1"
    },
    {
        "title": "Algorithm/Architecture Co-design of Proportionate-type LMS Adaptive\n  Filters for Sparse System Identification",
        "authors": [
            "Subrahmanyam Mula",
            "Vinay Chakravarthi Gogineni",
            "Anindya Sundar Dhar"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This paper investigates the problem of implementing proportionate-type LMS\nfamily of algorithms in hardware for sparse adaptive filtering applications\nespecially the network echo cancelation. We derive a re-formulated\nproportionate type algorithm through algorithm-architecture co-design\nmethodology that can be pipelined and has an efficient architecture for\nhardware implementation. We study the convergence, steady-state and tracking\nperformances of these re-formulated algorithms for white, color and speech\ninputs before implementing them in hardware. To the best of our knowledge this\nis the first attempt to implement proportionate-type algorithms in hardware. We\nshow that Delayed $\\mu$-law Proportionate LMS (DMPLMS) algorithm for white\ninput and Delayed Wavelet MPLMS (DWMPLMS) for colored input are the robust VLSI\nsolutions for network echo cancellation where the sparsity of the echo paths\ncan vary with time. We implemented all the designs considering $16$-bit fixed\npoint representation in hardware, synthesized the designs and synthesis results\nshow that DMPLMS algorithm with $\\approx25\\%$ increase in hardware over\nconventional DLMS architecture, achieves $3X$ improvement in convergence rate\nfor white input and DWMPLMS algorithm with $\\approx58\\%$ increase in hardware\nachieves $15X$ improvement in convergence rate for correlated input conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.10658v1"
    },
    {
        "title": "Wireless Health Monitoring using Passive WiFi Sensing",
        "authors": [
            "U. M. Khan",
            "Z. Kabir",
            "S. A. Hassan"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This paper presents a two-dimensional phase extraction system using passive\nWiFi sensing to monitor three basic elderly care activities including breathing\nrate, essential tremor and falls. Specifically, a WiFi signal is acquired\nthrough two channels where the first channel is the reference one, whereas the\nother signal is acquired by a passive receiver after reflection from the human\ntarget. Using signal processing of cross-ambiguity function, various features\nin the signal are extracted. The entire implementations are performed using\nsoftware defined radios having directional antennas. We report the accuracy of\nour system in different conditions and environments and show that breathing\nrate can be measured with an accuracy of 87% when there are no obstacles. We\nalso show a 98% accuracy in detecting falls and 93% accuracy in classifying\ntremor. The results indicate that passive WiFi systems show great promise in\nreplacing typical invasive health devices as standard tools for health care.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.00620v1"
    },
    {
        "title": "Visual-Based Analysis of Classification Measures with Applications to\n  Imbalanced Data",
        "authors": [
            "Dariusz Brzezinski",
            "Jerzy Stefanowski",
            "Robert Susmaga",
            "Izabela Szczch"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  With a plethora of available classification performance measures, choosing\nthe right metric for the right task requires careful thought. To make this\ndecision in an informed manner, one should study and compare general properties\nof candidate measures. However, analysing measures with respect to complete\nranges of their domain values is a difficult and challenging task. In this\nstudy, we attempt to support such analyses with a specialized visualization\ntechnique, which operates in a barycentric coordinate system using a 3D\ntetrahedron. Additionally, we adapt this technique to the context of imbalanced\ndata and put forward a set of properties which should be taken into account\nwhen selecting a classification performance measure. As a result, we compare 22\npopular measures and show important differences in their behaviour. Moreover,\nfor parametric measures such as the F$_{\\beta}$ and IBA$_\\alpha$(G-mean), we\nanalytically derive parameter thresholds that change measure properties.\nFinally, we provide an online visualization tool that can aid the analysis of\ncomplete domain ranges of performance measures.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.07122v2"
    },
    {
        "title": "RootJS: Node.js Bindings for ROOT 6",
        "authors": [
            "Theo Beffart",
            "Maximilian Frh",
            "Christoph Haas",
            "Sachin Rajgopal",
            "Jonas Schwabe",
            "Christoph Wolff",
            "Marek Szuba"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  We present rootJS, an interface making it possible to seamlessly integrate\nROOT 6 into applications written for Node.js, the JavaScript runtime platform\nincreasingly commonly used to create high-performance Web applications. ROOT\nfeatures can be called both directly from Node.js code and by JIT-compiling C++\nmacros. All rootJS methods are invoked asynchronously and support callback\nfunctions, allowing non-blocking operation of Node.js applications using them.\nLast but not least, our bindings have been designed to platform-independent and\nshould therefore work on all systems supporting both ROOT 6 and Node.js.\n  Thanks to rootJS it is now possible to create ROOT-aware Web applications\ntaking full advantage of the high performance and extensive capabilities of\nNode.js. Examples include platforms for the quality assurance of acquired,\nreconstructed or simulated data, book-keeping and e-log systems, and even Web\nbrowser-based data visualisation and analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.07887v1"
    },
    {
        "title": "Participating in a Computer Science Linked-courses Learning Community\n  Reduces Isolation",
        "authors": [
            "Amber Settle",
            "James Doyle",
            "Theresa Steinbach"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In our previous work we reported on a linked-courses learning community for\nunderrepresented groups in computer science, finding differences in attitudes\nand resource utilization between students in the community and other\nprogramming students. Here we present the first statistically significant\ndifferences in pre- to post-quarter student attitudes between those in the\nlearning community and others taking equivalent programming classes. We find\nthat students in the learning community are less likely to feel isolated\npost-quarter than other programming students. We also present results showing\ndifferences in resource utilization by learning-community participants.\n",
        "pdf_link": "http://arxiv.org/pdf/1704.07898v1"
    },
    {
        "title": "A sub-mW IoT-endnode for always-on visual monitoring and smart\n  triggering",
        "authors": [
            "Manuele Rusci",
            "Davide Rossi",
            "Elisabetta Farella",
            "Luca Benini"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This work presents a fully-programmable Internet of Things (IoT) visual\nsensing node that targets sub-mW power consumption in always-on monitoring\nscenarios. The system features a spatial-contrast $128\\mathrm{x}64$ binary\npixel imager with focal-plane processing. The sensor, when working at its\nlowest power mode ($10\\mu W$ at 10 fps), provides as output the number of\nchanged pixels. Based on this information, a dedicated camera interface,\nimplemented on a low-power FPGA, wakes up an ultra-low-power parallel\nprocessing unit to extract context-aware visual information. We evaluate the\nsmart sensor on three always-on visual triggering application scenarios.\nTriggering accuracy comparable to RGB image sensors is achieved at nominal\nlighting conditions, while consuming an average power between $193\\mu W$ and\n$277\\mu W$, depending on context activity. The digital sub-system is extremely\nflexible, thanks to a fully-programmable digital signal processing engine, but\nstill achieves 19x lower power consumption compared to MCU-based cameras with\nsignificantly lower on-board computing capabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.00221v1"
    },
    {
        "title": "Reconstruction of Missing Big Sensor Data",
        "authors": [
            "Yongshuai Shao",
            "Zhe Chen"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  With ubiquitous sensors continuously monitoring and collecting large amounts\nof information, there is no doubt that this is an era of big data. One of the\nimportant sources for scientific big data is the datasets collected by Internet\nof things (IoT). It's considered that these datesets contain highly useful and\nvaluable information. For an IoT application to analyze big sensor data, it is\nnecessary that the data are clean and lossless. However, due to unreliable\nwireless link or hardware failure in the nodes, data loss in IoT is very\ncommon. To reconstruct the missing big sensor data, firstly, we propose an\nalgorithm based on matrix rank-minimization method. Then, we consider IoT with\nmultiple types of sensor in each node. Accounting for possible correlations\namong multiple-attribute sensor data, we propose tensor-based methods to\nestimate missing values. Moreover, effective solutions are proposed using the\nalternating direction method of multipliers. Finally, we evaluate the\napproaches using two real sensor datasets with two missing data-patterns, i.e.,\nrandom missing pattern and consecutive missing pattern. The experiments with\nreal-world sensor data show the effectiveness of the proposed methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.01402v1"
    },
    {
        "title": "Increasing the Discovery Power and Confidence Levels of Disease\n  Association Studies: A Survey",
        "authors": [
            "Layan Nahlawi"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The majority of common diseases are influenced by multiple genetic and\nenvironmental factors such as Cancer. Even though uncovering the main causes of\ndisease is deemed difficult due to the complexity of gene-gene and\ngene-environment interactions, major research efforts aim at identifying\ndisease risk factors, especially genetic ones. Over the past decade, disease\nassociation studies have been used to uncover the susceptibility, aetiology and\nmechanisms of action pertaining to common diseases. In disease association\nstudies, genetic data is analyzed in order to reveal the relationship between\ndifferent types of variants, and a disease of interest. The ultimate goal of\nassociation studies is to facilitate susceptibility testing for disease\nprediction, early diagnosis and enhanced prognosis . Susceptibility testing and\ndisease prediction are particularly important for diseases that can be\nprevented by diet, drugs or change in lifestyle. The discovered associations\nassist in understanding the molecular mechanisms influenced by the reported\nvariants, and in identifying important risk factors. Current association\nstudies suffer from several shortcomings. This report surveys the literature\nthat addresses the shortcomings of current methods the identify genetic disease\nassociations. In addition, it reviews the suggested solutions that either\nenhance some aspect of the methodologies, or complement them.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.03391v1"
    },
    {
        "title": "Hardware Automated Dataflow Deployment of CNNs",
        "authors": [
            "Kamel Abdelouahab",
            "Maxime Pelcat",
            "Jocelyn Serot",
            "Cedric Bourrasset",
            "Jean-Charles Quinton",
            "Franois Berry"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Deep Convolutional Neural Networks (CNNs) are the state of the art systems\nfor image classification and scene understating. However, such techniques are\ncomputationally intensive and involve highly regular parallel computation. CNNs\ncan thus benefit from a significant acceleration in execution time when running\non fine grain programmable logic devices. As a consequence, several studies\nhave proposed FPGA-based accelerators for CNNs. However, because of the huge\namount of the required hardware resources, none of these studies directly was\nbased on a direct mapping of the CNN computing elements onto the FPGA physical\nresources. In this work, we demonstrate the feasibility of this so-called\ndirect hardware mapping approach and discuss several associated implementation\nissues. As a proof of concept, we introduce the haddoc2 open source tool, that\nis able to automatically transform a CNN description into a platform\nindependent hardware description for FPGA implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.04543v3"
    },
    {
        "title": "Cloud-based Fault Detection and Classification for Oil & Gas Industry",
        "authors": [
            "Athar Khodabakhsh",
            "Ismail Ari",
            "Mustafa Bakir"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Oil & Gas industry relies on automated, mission-critical equipment and\ncomplex systems built upon their interaction and cooperation. To assure\ncontinuous operation and avoid any supervision, architects embed Distributed\nControl Systems (DCS), a.k.a. Supervisory Control and Data Acquisition (SCADA)\nsystems, on top of their equipment to generate data, monitor state and make\ncritical online & offline decisions.\n  In this paper, we propose a new Lambda architecture for oil & gas industry\nfor unified data and analytical processing on data received from DCS, discuss\ncloud integration issues and share our experiences with the implementation of\nsensor fault-detection and classification modules inside the proposed\narchitecture.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.04583v1"
    },
    {
        "title": "Zampa's systems theory: a comprehensive theory of measurement in dynamic\n  systems",
        "authors": [
            "Renata Rychtarikova",
            "Jan Urban",
            "Dalibor Stys"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The article outlines in memoriam Prof. Pavel Zampa's concepts of system\ntheory which enable to devise a measurement in dynamic systems independently of\nthe particular system behaviour. From the point of view of Zampa's theory,\nterms like system time, system attributes, system link, system element, input,\noutput, subsystems, and state variables are defined. In Conclusions, Zampa's\ntheory is discussed together with another mathematical approaches of\nqualitative dynamics known since the 19th century. In Appendices, we present\napplications of Zampa's technical approach to measurement of complex dynamical\n(chemical and biological) systems at the Institute of Complex Systems,\nUniversity of South Bohemia in Ceske Budejovice.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.04832v2"
    },
    {
        "title": "A Proposed Architecture for Big Data Driven Supply Chain Analytics",
        "authors": [
            "Sanjib Biswas",
            "Jaydip Sen"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Advancement in information and communication technology (ICT) has given rise\nto explosion of data in every field of operations. Working with the enormous\nvolume of data (or Big Data, as it is popularly known as) for extraction of\nuseful information to support decision making is one of the sources of\ncompetitive advantage for organizations today. Enterprises are leveraging the\npower of analytics in formulating business strategy in every facet of their\noperations to mitigate business risk. Volatile global market scenario has\ncompelled the organizations to redefine their supply chain management (SCM). In\nthis paper, we have delineated the relevance of Big Data and its importance in\nmanaging end to end supply chains for achieving business excellence. A Big\nData-centric architecture for SCM has been proposed that exploits the current\nstate of the art technology of data management, analytics and visualization.\nThe security and privacy requirements of a Big Data system have also been\nhighlighted and several mechanisms have been discussed to implement these\nfeatures in a real world Big Data system deployment in the context of SCM. Some\nfuture scope of work has also been pointed out. Keyword: Big Data, Analytics,\nCloud, Architecture, Protocols, Supply Chain Management, Security, Privacy.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.04958v1"
    },
    {
        "title": "Statistical Timing Analysis for Latch-Controlled Circuits with Reduced\n  Iterations and Graph Transformations",
        "authors": [
            "Bing Li",
            "Ning Chen",
            "Ulf Schlichtmann"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Level-sensitive latches are widely used in high- performance designs. For\nsuch circuits efficient statistical timing analysis algorithms are needed to\ntake increasing process vari- ations into account. But existing methods solving\nthis problem are still computationally expensive and can only provide the yield\nat a given clock period. In this paper we propose a method combining reduced\niterations and graph transformations. The reduced iterations extract setup time\nconstraints and identify a subgraph for the following graph transformations\nhandling the constraints from nonpositive loops. The combined algorithms are\nvery efficient, more than 10 times faster than other existing methods, and\nresult in a parametric minimum clock period, which together with the hold time\nconstraints can be used to compute the yield at any given clock period very\neasily.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.04980v1"
    },
    {
        "title": "Annotation of Car Trajectories based on Driving Patterns",
        "authors": [
            "Sobhan Moosavi",
            "Behrooz Omidvar-Tehrani",
            "R. Bruce Craig",
            "Rajiv Ramnath"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Nowadays, the ubiquity of various sensors enables the collection of\nvoluminous datasets of car trajectories. Such datasets enable analysts to make\nsense of driving patterns and behaviors: in order to understand the behavior of\ndrivers, one approach is to break a trajectory into its underlying patterns and\nthen analyze that trajectory in terms of derived patterns. The process of\ntrajectory segmentation is a function of various resources including a set of\nground truth trajectories with their driving patterns. To the best of our\nknowledge, no such ground-truth dataset exists in the literature. In this\npaper, we describe a trajectory annotation framework and report our results to\nannotate a dataset of personal car trajectories. Our annotation methodology\nconsists of a crowd-sourcing task followed by a precise process of aggregation.\nOur annotation process consists of two granularity levels, one to specify the\nannotation (segment border) and the other one to describe the type of the\nsegment (e.g. speed-up, turn, merge, etc.). The output of our project, Dataset\nof Annotated Car Trajectories (DACT), is available online at\nhttps://figshare.com/articles/dact_dataset_of_annotated_car_trajectories/5005289 .\n",
        "pdf_link": "http://arxiv.org/pdf/1705.05219v2"
    },
    {
        "title": "RAE: The Rainforest Automation Energy Dataset for Smart Grid Meter Data\n  Analysis",
        "authors": [
            "Stephen Makonin",
            "Z. Jane Wang",
            "Chris Tumpach"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Datasets are important for researchers to build models and test how well\ntheir machine learning algorithms perform. This paper presents the Rainforest\nAutomation Energy (RAE) dataset to help smart grid researchers test their\nalgorithms which make use of smart meter data. This initial release of RAE\ncontains 1Hz data (mains and sub-meters) from two a residential house. In\naddition to power data, environmental and sensor data from the house's\nthermostat is included. Sub-meter data from one of the houses includes heat\npump and rental suite captures which is of interest to power utilities. We also\nshow and energy breakdown of each house and show (by example) how RAE can be\nused to test non-intrusive load monitoring (NILM) algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.05767v4"
    },
    {
        "title": "An Overview of Data Mining Applications in Oil and Gas Exploration:\n  Structural Geology and Reservoir Property-Issues",
        "authors": [
            "Hamed Nikhalat Jahromi",
            "Alpio M. Jorge"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Low oil prices have motivated energy executives to look into cost reduction\nin their supply chains more seriously. To this end, a new technology that is\nexperimentally considered in hydrocarbon exploration is data mining. There are\ntwo major categories of geoscientific problems in which data mining is applied:\nstructural geology and reservoir property-issues. This research overviews these\ncategories by considering a variety of interesting works in each of them. The\nresult is an understanding of the specific geoscientific problems studied in\nthe literature, along with the relative data mining methods. This way, this\nwork tries to lay the ground for a mutual understanding on oil and gas\nexploration between the data miners and the geoscientists.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.06345v1"
    },
    {
        "title": "A data-driven workflow for predicting horizontal well production using\n  vertical well logs",
        "authors": [
            "Jorge Guevara",
            "Matthias Kormaksson",
            "Bianca Zadrozny",
            "Ligang Lu",
            "John Tolle",
            "Tyler Croft",
            "Mingqi Wu",
            "Jan Limbeck",
            "Detlef Hohl"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In recent work, data-driven sweet spotting technique for shale plays\npreviously explored with vertical wells has been proposed. Here, we extend this\ntechnique to multiple formations and formalize a general data-driven workflow\nto facilitate feature extraction from vertical well logs and predictive\nmodeling of horizontal well production. We also develop an experimental\nframework that facilitates model selection and validation in a realistic\ndrilling scenario. We present some experimental results using this methodology\nin a field with 90 vertical wells and 98 horizontal wells, showing that it can\nachieve better results in terms of predictive ability than kriging of known\nproduction values.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.06556v1"
    },
    {
        "title": "Optimal placement of mix zones in road networks",
        "authors": [
            "Imran Memon",
            "Qasim Ali Arain"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The road networks, vehicle users could enjoy numerous kind of services such\nas location based service in vehicle users can connected to Internet and\ncommunication of different users. Therefore, in order to acquire adequate\nprivacy level and quality of service, one must have to wisely place mix zones\nto connect vehicle users to internet or some other internetwork. According to\nthis research, we have analyzed the problem of optimal placement mix zones over\nroad network. To enhance the coverage capacity of vehicles, in order to reduce\nthe cost and communication delay. Further, it has also been discovered to\nminimize the cost of mix zone placement. Moreover, it has also been shown that,\nas the best deployment mix zones get minimized cost while at the same time the\naverage capacity of mix zone can be maximized also privacy level increased\nbecause of optimal placement and high traffic environment.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.11104v1"
    },
    {
        "title": "The Role of Data Analysis in the Development of Intelligent Energy\n  Networks",
        "authors": [
            "Zhanyu Ma",
            "Jiyang Xie",
            "Hailong Li",
            "Qie Sun",
            "Zhongwei Si",
            "Jianhua Zhang",
            "Jun Guo"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Data analysis plays an important role in the development of intelligent\nenergy networks (IENs). This article reviews and discusses the application of\ndata analysis methods for energy big data. The installation of smart energy\nmeters has provided a huge volume of data at different time resolutions,\nsuggesting data analysis is required for clustering, demand forecasting, energy\ngeneration optimization, energy pricing, monitoring and diagnostics. The\ncurrently adopted data analysis technologies for IENs include pattern\nrecognition, machine learning, data mining, statistics methods, etc. However,\nexisting methods for data analysis cannot fully meet the requirements for\nprocessing the big data produced by the IENs and, therefore, more comprehensive\ndata analysis methods are needed to handle the increasing amount of data and to\nmine more valuable information.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.11132v1"
    },
    {
        "title": "Relatrio Tcnico: Controle Distribudo de Trfego Baseado em\n  Veculos Conectados e Comunicaes Veiculares Centradas em Interesses",
        "authors": [
            "Fabrcio Barros Gonalves"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Although advanced traffic management systems can deal with the heterogeneous\ntraffic flows approaching of intersections, their performances are compromised,\nwhen the traffic volume is not distributed uniformly. To evenly distribute the\ntraffic flow, an advanced driver information system should be aware of the\ntraffic control operations. However, such requirement can not ultimately be\nsatisfied due to the gaps in state of the art in advanced traffic management\nsystems. Therefore, this study proposes a distributed traffic control system,\nin which agents embedded in connected vehicles, traffic signals, urban elements\nand a traffic control center interact with each other to provide a greater\ntraffic fluidity. Therefore, the agents depend strongly on a heterogeneous\nvehicular network. In this sense, this study also proposes a heterogeneous\nvehicular network whose communication protocol can satisfy the communication\nrequirements of intelligent transportation systems service applications.\nAccording to the results obtained from simulations, the distributed traffic\ncontrol system was able to maximize the flow of vehicles and the mean speed of\nthe vehicles, and minimize the wait time, travel time, fuel consume and\nemissions (CO, CO$_2$, HC, NOx and PMx).\n",
        "pdf_link": "http://arxiv.org/pdf/1708.00741v1"
    },
    {
        "title": "Implementation of the Logistic Map with FPGA using 32 bits fixed point\n  standard",
        "authors": [
            "Diego A. Silva",
            "Eduardo B. Pereira",
            "Erivelton G. Nepomuceno"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This article presents a design of the logistic map by means of FPGA (Field\nProgrammable Gate Ar-ray) under fixed-point standard and 32-bits of precision.\nThe design was carried out with Altera Quartus platform. The hardware\ndescription language VHDL-93 has been adopted and the results were simulated by\nmeans of Altera ModelSim package. The main of the project was to produce a\ncha-otic system with a low energy and time cost. Using the VHDL, it was\npossible to use only 1439 logical gates from 114480 available. The Lyapunov\nexponent has been calculated with good agreement with literature reference,\nwhich shows the effectiveness the proposed method.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.03518v1"
    },
    {
        "title": "Enhanced power grid evaluation through efficient stochastic model-based\n  analysis",
        "authors": [
            "Giulio Masetti"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Electrical infrastructures provide services at the basis of a number of\napplication sectors, several of which are critical from the perspective of\nhuman life, environment or financials. Following the increasing trend in\nelectricity generation from renewable sources, pushed by the need to meet\nsustainable energy goals in many countries, more sophisticated control\nstrategies are being adopted to regulate the operation of the electric power\nsystem, driving electrical infrastructures towards the so called Smart Grid\nscenario. It is therefore paramount to be assisted by technologies able to\nanalyze the Smart Grid behavior in critical scenarios, e.g. where cyber\nmalfunctions or grid disruptions occur. In this context, stochastic model-based\nanalysis are well suited to assess dependability and quality of service related\nindicators, and continuous improvements in modeling strategies and system\nmodels design are required. Thus, my PhD work addresses this topic by\ncontributing to study new Smart Grid scenarios, concerning the advanced\ninterplay between ICT and electrical infrastructures in presence of cyber\nfaults/attacks, define a new modeling approach, based on modularity and\ncomposition, and start to study how to improve the electrical grid dynamics\nrepresentation. In this article these studies are briefly presented and\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.04576v1"
    },
    {
        "title": "Optimizing Google Shopping Campaigns Structures With Query-Level\n  Matching",
        "authors": [
            "Mathieu Raffinot",
            "Romain Rivire"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  How to bid on a Google shopping account (set of shopping campaigns) with\nquery-level matching like in Google Adwords.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.04586v1"
    },
    {
        "title": "Neville's algorithm revisited",
        "authors": [
            "M. de Jong"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Neville's algorithm is known to provide an efficient and numerically stable\nsolution for polynomial interpolations. In this paper, an extension of this\nalgorithm is presented which includes the derivatives of the interpolating\npolynomial.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.06293v1"
    },
    {
        "title": "SigViewer: Visualizing Multimodal Signals Stored in XDF (Extensible Data\n  Format) Files",
        "authors": [
            "Yida Lin",
            "Clemens Brunner",
            "Paul Sajda",
            "Josef Faller"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Multimodal biosignal acquisition is facilitated by recently introduced\nsoftware solutions such as LabStreaming Layer (LSL) and its associated data\nformat XDF (Extensible Data Format). However, there are no stand-alone\napplications that can visualize multimodal time series stored in XDF files. We\nextended SigViewer, an open source cross-platform Qt C++ application with the\ncapability of loading, resampling, annotating, and visualizing signals stored\nin XDF files and successfully applied the tool for post-hoc visual verification\nof the accuracy of a system that aims to predict the phase of alpha\noscillations within the electroencephalogram in real-time.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.06333v1"
    },
    {
        "title": "D3NOC: Dynamic Data-Driven Network On Chip in Photonic Electronic\n  Hybrids",
        "authors": [
            "Armin Mehrabian",
            "Shuai Sun",
            "Vikram K. Narayana",
            "Volker J. Sorger",
            "Tarek El-Ghazawi"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In this paper, we present a reconfigurable hybrid Photonic-Plasmonic\nNetwork-on-Chip (NoC) based on the Dynamic Data Driven Application System\n(DDDAS) paradigm. In DDDAS computations and measurements form a dynamic closed\nfeedback loop in which they tune one another in response to changes in the\nenvironment. Our proposed system enables dynamic augmentation of a base\nelectrical mesh topology with an optical express bus during the run-time. In\naddition, the measurement process itself adjusts to the environment. In order\nto achieve lower latencies, lower dynamic power, and higher throughput, we take\nadvantage of a Configurable Hybrid Photonic Plasmonic Interconnect (CHyPPI) for\nour reconfigurable connections. We evaluate the performance and power of our\nsystem against kernels from NAS Parallel Benchmark (NPB) in addition to some\nsynthetically generated traffic. In comparison to a 16x16 base electrical mesh,\nD3NOC shows up to 89% latency and 67% dynamic power net improvements beyond\noverhead-corrected performance. It should be noted that the design-space of NoC\nreconfiguration is vast and the goal of this study is not design-space\nexploration. Our goal is to show the potentials of adaptive dynamic\nmeasurements when coupled with other reconfiguration techniques in the NoC\ncontext.\n",
        "pdf_link": "http://arxiv.org/pdf/1708.06721v1"
    },
    {
        "title": "A HelloWord \\textsc{Bib}\\negthinspace\\TeX~stile file .\\textbf{bst}",
        "authors": [
            "Makar Plakhotnyk"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  A HelloWord \\textsc{Bib}\\negthinspace\\TeX~stile file .\\textbf{bst} is\ndescribed\n",
        "pdf_link": "http://arxiv.org/pdf/1709.03643v1"
    },
    {
        "title": "Stackable vs Autonomous Cars for Shared Mobility Systems: a Preliminary\n  Performance Evaluation",
        "authors": [
            "Chiara Boldrini",
            "Raffaele Bruno"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Car sharing is one of the key elements of a Mobility-on-Demand system, but it\nstill suffers from several shortcomings, the most significant of which is the\nfleet unbalance during the day. What is typically observed in car sharing\nsystems, in fact, is a vehicle shortage in so-called hot spots (i.e., areas\nwith high demand) and vehicle accumulation in cold spots, due to the patterns\nin people flows during the day. In this work, we overview the main approaches\nto vehicle redistribution based on the type of vehicles the car sharing fleet\nis composed of, and we evaluate their performance using a realistic car sharing\ndemand derived for a suburban area around Lyon, France. The main result of this\npaper is that stackable vehicles can achieve a relocation performance close to\nthat of autonomous vehicles, significantly improving over the no-relocation\napproach and over traditional relocation with standard cars.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.09553v1"
    },
    {
        "title": "On Vague Computers",
        "authors": [
            "Apostolos Syropoulos"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Vagueness is something everyone is familiar with. In fact, most people think\nthat vagueness is closely related to language and exists only there. However,\nvagueness is a property of the physical world. Quantum computers harness\nsuperposition and entanglement to perform their computational tasks. Both\nsuperposition and entanglement are vague processes. Thus quantum computers,\nwhich process exact data without \"exploiting\" vagueness, are actually vague\ncomputers.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.10373v1"
    },
    {
        "title": "An Experimental Analysis of the Power Consumption of Convolutional\n  Neural Networks for Keyword Spotting",
        "authors": [
            "Raphael Tang",
            "Weijie Wang",
            "Zhucheng Tu",
            "Jimmy Lin"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Nearly all previous work on small-footprint keyword spotting with neural\nnetworks quantify model footprint in terms of the number of parameters and\nmultiply operations for a feedforward inference pass. These values are,\nhowever, proxy measures since empirical performance in actual deployments is\ndetermined by many factors. In this paper, we study the power consumption of a\nfamily of convolutional neural networks for keyword spotting on a Raspberry Pi.\nWe find that both proxies are good predictors of energy usage, although the\nnumber of multiplies is more predictive than the number of model parameters. We\nalso confirm that models with the highest accuracies are, unsurprisingly, the\nmost power hungry.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.00333v2"
    },
    {
        "title": "Detecting Disguised Plagiarism",
        "authors": [
            "Hatem A. Mahmoud"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Source code plagiarism detection is a problem that has been addressed several\ntimes before; and several tools have been developed for that purpose. In this\nresearch project we investigated a set of possible disguises that can be\nmechanically applied to plagiarized source code to defeat plagiarism detection\ntools. We propose a preprocessor to be used with existing plagiarism detection\ntools to \"normalize\" source code before checking it, thus making such disguises\nineffective.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.02149v1"
    },
    {
        "title": "(geo)graphs - Complex Networks as a shapefile of nodes and a shapefile\n  of edges for different applications",
        "authors": [
            "Leonardo B L Santos",
            "Aurelienne A S Jorge",
            "Marcio Rossato",
            "Jessica D Santos",
            "Onofre A Candido",
            "Wilson Seron",
            "Charles N de Santana"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Spatial dependency and spatial embedding are basic physical properties of\nmany phenomena modeled by networks. The most indicated computational\nenvironment to deal with spatial information is to use Georeferenced\nInformation System (GIS) and Geographical Database Management Systems (GDBMS).\nSeveral models have been proposed in this direction, however there is a gap in\nthe literature in generic frameworks for working with Complex Networks in\nGIS/GDBMS environments. Here we introduce the concept of (geo)graphs: graphs in\nwhich the nodes have a known geographical location and the edges have spatial\ndependence. We present case studies and two open source softwares (GIS4GRAPH\nand GeoCNet) that indicate how to retrieve networks from GIS data and how to\nrepresent networks over GIS data by using (geo)graphs.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.05879v1"
    },
    {
        "title": "The process of 3D-printed skull models for the anatomy education",
        "authors": [
            "Zhen Shen",
            "Yong Yao",
            "Yi Xie",
            "Chao Guo",
            "Xiuqin Shang",
            "Xisong Dong",
            "Yuqing Li",
            "Zhouxian Pan",
            "Shi Chen",
            "Hui Pan",
            "Gang Xiong"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Objective The 3D printed medical models can come from virtual digital\nresources, like CT scanning. Nevertheless, the accuracy of CT scanning\ntechnology is limited, which is 1mm. In this situation, the collected data is\nnot exactly the same as the real structure and there might be some errors\ncausing the print to fail. This study presents a common and practical way to\nprocess the skull data to make the structures correctly. And then we make a\nskull model through 3D printing technology, which is useful for medical\nstudents to understand the complex structure of skull. Materials and Methods\nThe skull data is collected by the CT scan. To get a corrected medical model,\nthe computer-assisted image processing goes with the combination of five 3D\nmanipulation tools: Mimics, 3ds Max, Geomagic, Mudbox and Meshmixer, to\nreconstruct the digital model and repair it. Subsequently, we utilize a\nlow-cost desktop 3D printer, Ultimaker2, with polylactide filament (PLA)\nmaterial to print the model and paint it based on the atlas. Result After the\nrestoration and repairing, we eliminate the errors and repair the model by\nadding the missing parts of the uploaded data within 6 hours. Then we print it\nand compare the model with the cadaveric skull from frontal, left, right and\nanterior views respectively. The printed model can show the same structures and\nalso the details of the skull clearly and is a good alternative of the\ncadaveric skull.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.07106v1"
    },
    {
        "title": "Obtaining the coefficients of a Vector Autoregression Model through\n  minimization of parameter criteria",
        "authors": [
            "Alfonso L. Castao",
            "Javier Cuenca",
            "Domingo Gimnez",
            "Jose J. Lpez-Espn",
            "Alberto Prez-Bernabeu"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  VAR models are a type of multi-equation model that have been widely applied\nin econometrics. With the arrival of Big Data, huge amounts of data are being\ncollected in numerous fields, making feasible the application of these kind of\nstatistical models. Tools exist to tackle this problem, but the large amount of\ndata, along with the availability of computational techniques and high\nperformance systems, advise an in-depth analysis of the computational aspects\nof VAR, so large models can be solved efficiently with today's computational\nsystems.\n  This work aims to solve a VAR model by obtaining the coefficients through\nheuristic and metaheuristic algorithms, minimizing one parameter criterion, and\nalso to compare with those coefficients obtained by OLS. Furthermore, we\nconsider different approaches to reduce the time required to find the model\nlike using matrix decompositions (QR or LQ), exploiting matrix structure, using\nhigh performance linear algebra subroutines (BLAS and LAPACK) or parallel\nmetaheuristics.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.09369v1"
    },
    {
        "title": "Treatment of Unicode canoncal decomposition among operating systems",
        "authors": [
            "Efstratios Rappos"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This article shows how the text characters that have multiple representations\nunder the Unicode standard are treated by popular operating systems. Whilst\nmost characters have a unique representation in Unicode, some characters such\nas the accented European letters, can have multiple representations due to a\nfeature of Unicode called normalization. These characters are treated\ndifferently by popular operating systems, leading to additional challenges\nduring interoperability of computer programs.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.10481v1"
    },
    {
        "title": "Rule based End-to-End Learning Framework for Urban Growth Prediction",
        "authors": [
            "Saptarshi Pal",
            "Soumya K Ghosh"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Due to the rapid growth of urban areas in the past decades, it has become\nincreasingly important to model and monitor urban growth in mega cities.\nAlthough several researchers have proposed models for simulating urban growth,\nthey have been primarily dependent on various manually selected spatial and\nnonspatial explanatory features for building models. A practical difficulty\nwith this approach is manual selection procedure, which tends to make model\ndesign process laborious and non-generic. Despite the fact that explanatory\nfeatures provide us with the understanding of a complex process, there has been\nno standard set of features in urban growth prediction over which scholars have\nconsensus. Hence, design and deploying of systems for urban growth prediction\nhave remained challenging tasks. In order to reduce the dependency on human\ndevised features, we have proposed a novel End-to-End prediction framework to\nrepresent remotely sensed satellite data in terms of rules of a cellular\nautomata model in order to improve the performance of urban growth prediction.\nUsing our End-to-End framework, we have achieved superior performance in Figure\nof Merit, Producer's accuracy, User's accuracy, and Overall accuracy metrics\nrespectively over existing learning based methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.10801v4"
    },
    {
        "title": "Explanation of an Invisible Common Constraint of Mind, Mathematics and\n  Computational Complexity",
        "authors": [
            "Asad Malik"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  There is a cognitive limit in Human Mind. This cognitive limit has played a\ndecisive role in almost all fields including computer sciences. The cognitive\nlimit replicated in computer sciences is responsible for inherent Computational\nComplexity. The complexity starts decreasing if certain conditions are met,\neven sometime it does not appears at all. Very simple Mechanical computing\nsystems are designed and implemented to demonstrate this idea and it is further\nsupported by Electrical systems. These verifiable and consistent systems\ndemonstrate the idea of computational complexity reduction. This work explains\na very important but invisible connection from Mind to Mathematical axioms\n(Peano Axioms etc.) and Mathematical axioms to computational complexity. This\nstudy gives a completely new perspective that goes well beyond Cognitive\nScience, Mathematics, Physics, Computer Sciences and Philosophy. Based on this\nnew insight some important predictions are made.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.10874v4"
    },
    {
        "title": "An optical solution for the set splitting problem",
        "authors": [
            "Mihai Oltean"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  We describe here an optical device, based on time-delays, for solving the set\nsplitting problem which is well-known NP-complete problem. The device has a\ngraph-like structure and the light is traversing it from a start node to a\ndestination node. All possible (potential) paths in the graph are generated and\nat the destination we will check which one satisfies completely the problem's\nconstrains.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.00651v1"
    },
    {
        "title": "OpenSEA: Semi-Formal Methods for Soft Error Analysis",
        "authors": [
            "Patrick Klampfl",
            "Robert Koenighofer",
            "Roderick Bloem",
            "Ayrat Khalimov",
            "Aiman Abu-Yonis",
            "Shiri Moran"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Alpha-particles and cosmic rays cause bit flips in chips. Protection circuits\nease the problem, but cost chip area and power, and so designers try hard to\noptimize them. This leads to bugs: an undetected fault can bring\nmiscalculations, the checker that alarms about harmless faults incurs\nperformance penalty. Such bugs are hard to find: circuit simulation with tests\nis inefficient since it enumerates the huge fault time-location space, and\nformal methods do not scale since they explore the whole inputs. In this paper,\nwe use formal methods on designer's input tests, while keeping time-location\nopen. This idea is at the core of the tool OpenSEA. OpenSEA can (i) find\nlatches vulnerable to and protected against faults, (ii) find tests that\nexhibit checker false alarms, (iii) use fixed and open inputs, and (iv) use\nenvironment assumptions. Evaluation on a number of industrial designs shows\nthat OpenSEA produces valuable results.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04291v1"
    },
    {
        "title": "The View from the Other Side: The Border Between Controversial Speech\n  and Harassment on Kotaku in Action",
        "authors": [
            "Shagun Jhaver",
            "Larry Chan",
            "Amy Bruckman"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In this paper, we use mixed methods to study a controversial Internet site:\nThe Kotaku in Action (KiA) subreddit. Members of KiA are part of GamerGate, a\ndistributed social movement. We present an emic account of what takes place on\nKiA who are they, what are their goals and beliefs, and what rules do they\nfollow. Members of GamerGate in general and KiA in particular have often been\naccused of harassment. However, KiA site policies explicitly prohibit such\nbehavior, and members insist that they have been falsely accused. Underlying\nthe controversy over whether KiA supports harassment is a complex disagreement\nabout what \"harassment\" is, and where to draw the line between freedom of\nexpression and censorship. We propose a model that characterizes perceptions of\ncontroversial speech, dividing it into four categories: criticism, insult,\npublic shaming, and harassment. We also discuss design solutions that address\nthe challenges of moderating harassment without impinging on free speech, and\ncommunicating across different ideologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.05851v2"
    },
    {
        "title": "\"Oh Tanenbaum, oh Tanenbaum...\": Technical Foundations of Xmas 4.0\n  Research",
        "authors": [
            "P. Reichl",
            "S. Claus"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Andrew Tanenbaum and his textbooks -- e.g. on Operating Systems, Computer\nNetworks, Structured Computer Organization and Distributed Systems, to name but\na few -- have had a tremendous impact on generations of computer science\nstudents (and teachers at the same time). Given this, it is striking to observe\nthat this comprehensive body of work apparently does not provide a single line\non a research topic that seems to be intimately related with his name (at least\nin German), i.e. Xmas Research (XR). Hence, the goal of this paper is to fill\nthis gap and provide insight into a number of paradigmatic XR research\nquestions, for instance: Can we today still count on Santa Claus? Or at least\non Xmas trees? And does this depend on basic tree structures, or can we rather\nfind solutions on the level of programming languages? By addressing such basic\nopen issues, we aim at providing a solid technical foundation for future steps\ntowards the imminent evolution of Xmas 4.0.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.06259v1"
    },
    {
        "title": "Effect of NBTI/PBTI Aging and Process Variations on Write Failures in\n  MOSFET and FinFET Flip-Flops",
        "authors": [
            "Usman Khalid",
            "Antonio Mastrandrea",
            "Mauro Olivieri"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The assessment of noise margins and the related probability of failure in\ndigital cells has growingly become essential, as nano-scale CMOS and FinFET\ntechnologies are confronting reliability issues caused by aging mechanisms,\nsuch as NBTI, and variability in process parameters. The influence of such\nphenomena is particularly associated to the Write Noise Margins (WNM) in memory\nelements, since a wrong stored logic value can result in an upset of the system\nstate. In this work, we calculated and compared the effect of process\nvariations and NBTI aging over the years on the actual WNM of various CMOS and\nFinFET based flip-flop cells. The massive transistor-level Monte Carlo\nsimulations produced both nominal (i.e. mean) values and associated standard\ndeviations of the WNM of the chosen flip-flops. This allowed calculating the\nconsequent write failure probability as a function of an input voltage shift on\nthe flip-flop cells, and assessing a comparison for robustness among different\ncircuit topologies and technologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.06934v1"
    },
    {
        "title": "Methodological Framework for Determining the Land Eligibility of\n  Renewable Energy Sources",
        "authors": [
            "David Severin Ryberg",
            "Martin Robinius",
            "Detlef Stolten"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The quantity and distribution of land which is eligible for renewable energy\nsources is fundamental to the role these technologies will play in future\nenergy systems. As it stands, however, the current state of land eligibility\ninvestigation is found to be insufficient to meet the demands of the future\nenergy modelling community. Three key areas are identified as the predominate\ncauses of this; inconsistent criteria definitions, inconsistent or unclear\nmethodologies, and inconsistent dataset usage. To combat these issues, a land\neligibility framework is developed and described in detail. The validity of\nthis framework is then shown via the recreation of land eligibility results\nfound in the literature, showing strong agreement in the majority of cases.\nFollowing this, the framework is used to perform an evaluation of land\neligibility criteria within the European context whereby the relative\nimportance of commonly considered criteria are compared.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.07840v1"
    },
    {
        "title": "Step Detection Algorithm For Accurate Distance Estimation Using Dynamic\n  Step Length",
        "authors": [
            "Ahmad Abadleh",
            "Eshraq Al-Hawari",
            "Esra'a Alkafaween",
            "Hamad Al-Sawalqah"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In this paper, a new Smartphone sensor based algorithm is proposed to detect\naccurate distance estimation. The algorithm consists of two phases, the first\nphase is for detecting the peaks from the Smartphone accelerometer sensor. The\nother one is for detecting the step length which varies from step to step. The\nproposed algorithm is tested and implemented in real environment and it showed\npromising results. Unlike the conventional approaches, the error of the\nproposed algorithm is fixed and is not affected by the long distance.\n  Keywords distance estimation, peaks, step length, accelerometer.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.02336v1"
    },
    {
        "title": "The Socket Store: An App Model for the Application-Network Interaction",
        "authors": [
            "Christos Liaskos",
            "Ageliki Tsioliaridou",
            "Sotiris Ioannidis"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  A developer of mobile or desktop applications is responsible for implementing\nthe network logic of his software. Nonetheless: i) Developers are not network\nspecialists, while pressure for emphasis on the visible application parts\nplaces the network logic out of the coding focus. Moreover, computer networks\nundergo evolution at paces that developers may not follow. ii) From the network\nresource provider point of view, marketing novel services and involving a broad\naudience is also challenge for the same reason. Moreover, the objectives of\nend-user networking logic are neither clear nor uniform. This constitutes the\ncentral optimization of network resources an additional challenge. As a\nsolution to these problems, we propose the Socket Store. The Store is a\nmarketplace containing end-user network logic in modular form. The Store\nmodules act as intelligent mediators between the end-user and the network\nresources. Each module has a clear, specialized objective, such as connecting\ntwo clients over the Internet while avoiding transit networks suspicious for\neavesdropping. The Store is populated and peer-reviewed by network specialists,\nwhose motive is the visibility, practical applicability and monetization\npotential of their work. A developer first purchases access to a given socket\nmodule. Subsequently, he incorporates it to his applications under development,\nobtaining state-of-the-art performance with trivial coding burden. A full Store\nprototype is implemented and a critical data streaming module is evaluated as a\ndriving case.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05611v1"
    },
    {
        "title": "StreetGen : In base city scale procedural generation of streets: road\n  network, road surface and street objects",
        "authors": [
            "Rmi Cura",
            "Julien Perret",
            "Nicolas Paparoditis"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Streets are large, diverse, and used for several (and possibly conflicting)\ntransport modalities as well as social and cultural activities. Proper planning\nis essential and requires data. Manually fabricating data that represent\nstreets (street reconstruction) is error-prone and time consuming. Automatising\nstreet reconstruction is a challenge because of the diversity, size, and scale\nof the details (few centimetres for cornerstone) required. The state-of-the-art\nfocuses on roads (no context, no urban features) and is strongly determined by\neach application (simulation, visualisation, planning). We propose a unified\nframework that works on real Geographic Information System (GIS) data and uses\na strong, yet simple modelling hypothesis when possible to robustly model\nstreets at the city level or street level. Our method produces a coherent\nstreet-network model containing topological traffic information, road surface\nand street objects. We demonstrate the robustness and genericity of our method\nby reconstructing the entire city of Paris streets and exploring other similar\nreconstruction (airport driveway).\n",
        "pdf_link": "http://arxiv.org/pdf/1801.05741v1"
    },
    {
        "title": "Mobility Based Routing Protocol with MAC Collision Improvement in\n  Vehicular Ad Hoc Networks",
        "authors": [
            "Zhihao Ding",
            "Pinyi Ren",
            "Qinghe Du"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Intelligent transportation system attracts a great deal of research attention\nbecause it helps enhance traffic safety, improve driving experiences, and\ntransportation efficiency. Vehicular Ad Hoc Network (VANET) supports wireless\nconnections among vehicles and offers information exchange, thus significantly\nfacilitating intelligent transportation systems. Since the vehicles move fast\nand often change lanes unpredictably, the network topology evolves rapidly in a\nrandom fashion, which imposes diverse challenges in routing protocol design\nover VANET. When it comes to the 5G era, the fulfilment of ultra low end-to-end\ndelay and ultra high reliability becomes more crucial than ever. In this paper,\nwe propose a novel routing protocol that incorporates mobility status and MAC\nlayer channel contention information. The proposed routing protocol determines\nnext hop by applying mobility information and MAC contention information which\ndiffers from existing greedy perimeter stateless routing (GPSR) protocol.\nSimulation results of the proposed routing protocol show its performance\nsuperiority over the existing approach.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.06502v1"
    },
    {
        "title": "Approximability in the GPAC",
        "authors": [
            "Diogo Poas",
            "Jeffery Zucker"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Most of the physical processes arising in nature are modeled by either\nordinary or partial differential equations. From the point of view of analog\ncomputability, the existence of an effective way to obtain solutions of these\nsystems is essential. A pioneering model of analog computation is the General\nPurpose Analog Computer (GPAC), introduced by Shannon as a model of the\nDifferential Analyzer and improved by Pour-El, Lipshitz and Rubel, Costa and\nGra\\c{c}a and others. Its power is known to be characterized by the class of\ndifferentially algebraic functions, which includes the solutions of initial\nvalue problems for ordinary differential equations. We address one of the\nlimitations of this model, concerning the notion of approximability, a\ndesirable property in computation over continuous spaces that is however absent\nin the GPAC. In particular, the Shannon GPAC cannot be used to generate\nnon-differentially algebraic functions which can be approximately computed in\nother models of computation. We extend the class of data types using networks\nwith channels which carry information on a general complete metric space $X$;\nfor example $X=C(R,R)$, the class of continuous functions of one real (spatial)\nvariable. We consider the original modules in Shannon's construction\n(constants, adders, multipliers, integrators) and we add \\emph{(continuous or\ndiscrete) limit} modules which have one input and one output. We then define an\nL-GPAC to be a network built with $X$-stream channels and the above-mentioned\nmodules. This leads us to a framework in which the specifications of such\nanalog systems are given by fixed points of certain operators on continuous\ndata streams. We study these analog systems and their associated operators, and\nshow how some classically non-generable functions, such as the gamma function\nand the zeta function, can be captured with the L-GPAC.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.07661v3"
    },
    {
        "title": "A cost effective and reliable environment monitoring system for HPC\n  applications",
        "authors": [
            "Peter Bernd Otte",
            "Dalibor Djukanovic"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  We present a slow control system to gather all relevant environment\ninformation necessary to effectively and reliably run an HPC (High Performance\nComputing) system at a high value over price ratio. The scalable and reliable\noverall concept is presented as well as a newly developed hardware device for\nsensor read out. This device incorporates a Raspberry Pi, an Arduino and PoE\n(Power over Ethernet) functionality in a compact form factor. The system is in\nuse at the 2 PFLOPS cluster of the Johannes Gutenberg-University and\nHelmholtz-Institute in Mainz.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.00724v1"
    },
    {
        "title": "Road Network Fusion for Incremental Map Updates",
        "authors": [
            "Rade Stanojevic",
            "Sofiane Abbar",
            "Saravanan Thirumuruganathan",
            "Gianmarco De Francisci Morales",
            "Sanjay Chawla",
            "Fethi Filali",
            "Ahid Aleimat"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In the recent years a number of novel, automatic map-inference techniques\nhave been proposed, which derive road-network from a cohort of GPS traces\ncollected by a fleet of vehicles. In spite of considerable attention, these\nmaps are imperfect in many ways: they create an abundance of spurious\nconnections, have poor coverage, and are visually confusing. Hence, commercial\nand crowd-sourced mapping services heavily use human annotation to minimize the\nmapping errors. Consequently, their response to changes in the road network is\ninevitably slow. In this paper we describe \\mapfuse, a system which fuses a\nhuman-annotated map (e.g., OpenStreetMap) with any automatically inferred map,\nthus effectively enabling quick map updates. In addition to new road creation,\nwe study in depth road closure, which have not been examined in the past. By\nleveraging solid, human-annotated maps with minor corrections, we derive maps\nwhich minimize the trajectory matching errors due to both road network change\nand imperfect map inference of fully-automatic approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.02351v1"
    },
    {
        "title": "A veracity preserving model for synthesizing scalable electricity load\n  profiles",
        "authors": [
            "Yunyou Huang",
            "Jianfeng Zhan",
            "Chunjie Luo",
            "Lei Wang",
            "Nana Wang",
            "Daoyi Zheng",
            "Fanda Fan",
            "Rui Ren"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Electricity users are the major players of the electric systems, and\nelectricity consumption is growing at an extraordinary rate. The research on\nelectricity consumption behaviors is becoming increasingly important to design\nand deployment of the electric systems. Unfortunately, electricity load\nprofiles are difficult to acquire. Data synthesis is one of the best approaches\nto solving the lack of data, and the key is the model that preserves the real\nelectricity consumption behaviors. In this paper, we propose a hierarchical\nmulti-matrices Markov Chain (HMMC) model to synthesize scalable electricity\nload profiles that preserve the real consumption behavior on three time scales:\nper day, per week, and per year. To promote the research on the electricity\nconsumption behavior, we use the HMMC approach to model two distinctive raw\nelectricity load profiles. One is collected from the resident sector, and the\nother is collected from the non-resident sectors, including different\nindustries such as education, finance, and manufacturing. The experiments show\nour model performs much better than the classical Markov Chain model. We\npublish two trained models online, and researchers can directly use these\ntrained models to synthesize scalable electricity load profiles for further\nresearches.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.03500v1"
    },
    {
        "title": "Predicting Transportation Modes of GPS Trajectories using Feature\n  Engineering and Noise Removal",
        "authors": [
            "Mohammad Etemad",
            "Amilcar Soares Junior",
            "Stan Matwin"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Understanding transportation mode from GPS (Global Positioning System) traces\nis an essential topic in the data mobility domain. In this paper, a framework\nis proposed to predict transportation modes. This framework follows a sequence\nof five steps: (i) data preparation, where GPS points are grouped in trajectory\nsamples; (ii) point features generation; (iii) trajectory features extraction;\n(iv) noise removal; (v) normalization. We show that the extraction of the new\npoint features: bearing rate, the rate of rate of change of the bearing rate\nand the global and local trajectory features, like medians and percentiles\nenables many classifiers to achieve high accuracy (96.5%) and f1 (96.3%)\nscores. We also show that the noise removal task affects the performance of all\nthe models tested. Finally, the empirical tests where we compare this work\nagainst state-of-art transportation mode prediction strategies show that our\nframework is competitive and outperforms most of them.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.10164v1"
    },
    {
        "title": "Prediction-Based Fast Thermoelectric Generator Reconfiguration for\n  Energy Harvesting from Vehicle Radiators",
        "authors": [
            "Hanchen Yang",
            "Feiyang Kang",
            "Caiwen Ding",
            "Ji Li",
            "Jaemin Kim",
            "Donkyu Baek",
            "Shahin Nazarian",
            "Xue Lin",
            "Paul Bogdan",
            "Naehyuck Chang"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Thermoelectric generation (TEG) has increasingly drawn attention for being\nenvironmentally friendly. A few researches have focused on improving TEG\nefficiency at the system level on vehicle radiators. The most recent\nreconfiguration algorithm shows improvement in performance but suffers from\nmajor drawback on computational time and energy overhead, and non-scalability\nin terms of array size and processing frequency. In this paper, we propose a\nnovel TEG array reconfiguration algorithm that determines near-optimal\nconfiguration with an acceptable computational time. More precisely, with\n$O(N)$ time complexity, our prediction-based fast TEG reconfiguration algorithm\nenables all modules to work at or near their maximum power points (MPP).\nAdditionally, we incorporate prediction methods to further reduce the runtime\nand switching overhead during the reconfiguration process. Experimental results\npresent $30\\%$ performance improvement, almost $100\\times$ reduction on\nswitching overhead and $13\\times$ enhancement on computational speed compared\nto the baseline and prior work. The scalability of our algorithm makes it\napplicable to larger scale systems such as industrial boilers and heat\nexchangers.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.01574v1"
    },
    {
        "title": "On the Energy Consumption Forecasting of Data Centers Based on Weather\n  Conditions: Remote Sensing and Machine Learning Approach",
        "authors": [
            "Georgios Smpokos",
            "Mohamed A. Elshatshat",
            "Athanasios Lioumpas",
            "Ilias Iliopoulos"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The energy consumption of Data Centers (DCs) is a very important figure for\nthe telecommunications operators, not only in terms of cost, but also in terms\nof operational reliability. A relation between the energy consumption and the\nweather conditions would indicate that weather forecast models could be used\nfor predicting energy consumption of DCs. A reliable forecast would result in a\nmore efficient management of the available energy and would make it easier to\ntake advantage of the modern types of power-grid based on renewable energy\nresources. In this ,paper, we exploit the capabilities provided by the\nFIESTA-IoT platform in order to investigate the correlation between the weather\nconditions and the energy consumption in DCs. Then, by using multi-variable\nlinear regression process, we model this correlation between the energy\nconsumption and the dominant weather conditions parameters in order to\neffectively forecast the energy consumption based on the weather forecast. We\nhave validated our results through live measurements from the RealDC testbed.\nResults from our proposed approach indicate that forecasting of energy\nconsumption based on weather conditions could help not only DC operators in\nmanaging their cooling systems and power usage, but also electricity companies\nin optimizing their power distribution systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.01754v2"
    },
    {
        "title": "Increased Prediction Accuracy in the Game of Cricket using Machine\n  Learning",
        "authors": [
            "Kalpdrum Passi",
            "Niravkumar Pandey"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Player selection is one the most important tasks for any sport and cricket is\nno exception. The performance of the players depends on various factors such as\nthe opposition team, the venue, his current form etc. The team management, the\ncoach and the captain select 11 players for each match from a squad of 15 to 20\nplayers. They analyze different characteristics and the statistics of the\nplayers to select the best playing 11 for each match. Each batsman contributes\nby scoring maximum runs possible and each bowler contributes by taking maximum\nwickets and conceding minimum runs. This paper attempts to predict the\nperformance of players as how many runs will each batsman score and how many\nwickets will each bowler take for both the teams. Both the problems are\ntargeted as classification problems where number of runs and number of wickets\nare classified in different ranges. We used na\\\"ive bayes, random forest,\nmulticlass SVM and decision tree classifiers to generate the prediction models\nfor both the problems. Random Forest classifier was found to be the most\naccurate for both the problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.04226v1"
    },
    {
        "title": "Aesthetical Attributes for Segmenting Arabic Word",
        "authors": [
            "Mohamed Hssini",
            "Azzeddine Lazrek"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The connected allograph representing calligraphic Arabic word does not appear\nindividually in any calligraphic resource but in association with other letters\nall adapted to each other. The graphic segmentation of the word by respecting\naesthetical attributes indicating the grapheme of every letter is far from\nbeing an obvious task. The question consists in discovering every letter\nconstituting the word, points of cutting which separate its grapheme from other\nconstituents of word's shape. The obtained segment must be a complete drawing\nof the represented letter. This segmentation according to contextual graphic\nand qualitative criteria connecting the attached allograph will have to satisfy\ntypographic constraints varying in conformity with the possibilities offered by\nthe wanted technology. In this paper, we develop an approach for segmenting\nArabic word from which the purpose is to extract graphemes respecting the\ndesign of Arabic letters such as it is in the calligraphic literature. The\nprocedure bases itself on the principle that the Arabic connected letters have\na common part included in the cursive area, which must not be lost during the\nprocess of cutting.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.04690v1"
    },
    {
        "title": "Problem of Multiple Diacritics Design for Arabic Script",
        "authors": [
            "Mohamed Hssini",
            "Azzeddine Lazrek"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This study focuses on the design of multiple Arabic diacritical marks and to\ndeveloping a model that generates the stacking of multiples Arabic diacritics\nin order to integrate it into a system of Arabic composition. The problem\nconcerns the presence of multiple diacritics on a single basic letter. This\nmodel is based on the layering composition. The combination of diacritics with\nletters requires a basic layering to combine any diacritics in the word with\ntheir base letter, without having to deal individually and separately each pair\nof base letter and diacritics.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.04691v1"
    },
    {
        "title": "SMT Solving for Vesicle Traffic Systems in Cells",
        "authors": [
            "Ashutosh Gupta",
            "Ankit Shukla",
            "Mandyam Srivas",
            "Mukund Thattai"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In biology, there are several questions that translate to combinatorial\nsearch. For example, vesicle traffic systems that move cargo within eukaryotic\ncells have been proposed to exhibit several graph properties such as three\nconnectivity. These properties are consequences of underlying biophysical\nconstraints. A natural question for biologists is: what are the possible\nnetworks for various combinations of those properties? In this paper, we\npresent novel SMT based encodings of the properties over vesicle traffic\nsystems and a tool that searches for the networks that satisfies the properties\nusing SMT solvers. In our experiments, we show that our tool can search for\nnetworks of sizes that are considered to be relevant by biologists.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.05414v1"
    },
    {
        "title": "Automatic Detection of Indoor and Outdoor Scenarios using NMEA Message\n  Data from GPS Receivers",
        "authors": [
            "R. S. Pissardini",
            "E. S. Fonseca Junior"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Detection of indoor and outdoor scenarios is an important resource for many\ntypes of activities such as multisensor navigation and location-based services.\nThis research presents the use of NMEA data provided by GPS receivers to\ncharacterize different types of scenarios automatically. A set of static tests\nwas performed to evaluate metrics such as number of satellites, positioning\nsolution geometry and carrier-to-receiver noise-density ratio values to detect\npossible patterns to determine indoor and outdoor scenarios. Subsequently,\nvalidation tests are applied to verify that parameters obtained are adequate.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.05907v1"
    },
    {
        "title": "Designing a cost-time-quality-efficient grinding process using MODM\n  methods",
        "authors": [
            "Meysam Mahjoob"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In this paper a multi-objective mathematical model has been used to optimize\ngrinding parameters include workpiece speed, depth of cut and wheel speed which\nhighly affect the final surface quality. The mathematical model of the\noptimization problem consists of three conflict objective functions subject to\nwheel wear and production rate constraints. Exact methods can solve the NLP\nmodel in few seconds, therefore using Meta-heuristic algorithms which provide\nnear optimal solutions in not suitable. Considering this, five Multi-Objective\nDecision Making methods have been used to solve the multi-objective\nmathematical model using GAMS software to achieve the optimal parameters of the\ngrinding process. The Multi-Objective Decision Making methods provide different\neffective solutions where the decision maker can choose each solution in\ndifferent situations. Different criteria have been considered to evaluate the\nperformance of the five Multi-Objective Decision Making methods. Also,\nTechnique for Order of Preference by Similarity to Ideal Solution method has\nbeen used to obtain the priority of each method and determine which\nMulti-Objective Decision Making method performs better considering all criteria\nsimultaneously. The results indicated that Weighted Sum Method and Goal\nprogramming method are the best Multi-Objective Decision Making methods. The\nWeighted Sum Method and Goal programming provided solutions which are\ncompetitive to each other. In addition, these methods obtained solutions which\nhave minimum grinding time, cost and surface roughness among other\nMulti-Objective Decision Making methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.10710v3"
    },
    {
        "title": "A Cyberinfrastructure for BigData Transportation Engineering",
        "authors": [
            "Md Johirul Islam",
            "Anuj Sharma",
            "Hridesh Rajan"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Big Data-driven transportation engineering has the potential to improve\nutilization of road infrastructure, decrease traffic fatalities, improve fuel\nconsumption, decrease construction worker injuries, among others. Despite these\nbenefits, research on Big Data-driven transportation engineering is difficult\ntoday due to the computational expertise required to get started. This work\nproposes BoaT, a transportation-specific programming language, and it's Big\nData infrastructure that is aimed at decreasing this barrier to entry. Our\nevaluation that uses over two dozen research questions from six categories show\nthat research is easier to realize as a BoaT computer program, an order of\nmagnitude faster when this program is run, and exhibits 12-14x decrease in\nstorage requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.00105v1"
    },
    {
        "title": "Investigating Power Outage Effects on Reliability of Solid-State Drives",
        "authors": [
            "Saba Ahmadian",
            "Farhad Taheri",
            "Mehrshad Lotfi",
            "Maryam Karimi",
            "Hossein Asad"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Solid-State Drives (SSDs) are recently employed in enterprise servers and\nhigh-end storage systems in order to enhance performance of storage subsystem.\nAlthough employing high speed SSDs in the storage subsystems can significantly\nimprove system performance, it comes with significant reliability threat for\nwrite operations upon power failures. In this paper, we present a comprehensive\nanalysis investigating the impact of workload dependent parameters on the\nreliability of SSDs under power failure for variety of SSDs (from top\nmanufacturers). To this end, we first develop a platform to perform two\nimportant features required for study: a) a realistic fault injection into the\nSSD in the computing systems and b) data loss detection mechanism on the SSD\nupon power failure. In the proposed physical fault injection platform, SSDs\nexperience a real discharge phase of Power Supply Unit (PSU) that occurs during\npower failure in data centers which was neglected in previous studies. The\nimpact of workload dependent parameters such as workload Working Set Size\n(WSS), request size, request type, access pattern, and sequence of accesses on\nthe failure of SSDs is carefully studied in the presence of realistic power\nfailures. Experimental results over thousands number of fault injections show\nthat data loss occurs even after completion of the request (up to 700ms) where\nthe failure rate is influenced by the type, size, access pattern, and sequence\nof IO accesses while other parameters such as workload WSS has no impact on the\nfailure of SSDs.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.00140v1"
    },
    {
        "title": "Characterizing the Temporal Dynamics of Information in Visually Guided\n  Predictive Control Using LSTM Recurrent Neural Networks",
        "authors": [
            "Kamran Binaee",
            "Anna Starynska",
            "Jeff B Pelz",
            "Christopher Kanan",
            "Gabriel Jacob Diaz"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Theories for visually guided action account for online control in the\npresence of reliable sources of visual information, and predictive control to\ncompensate for visuomotor delay and temporary occlusion. In this study, we\ncharacterize the temporal relationship between information integration window\nand prediction distance using computational models. Subjects were immersed in a\nsimulated environment and attempted to catch virtual balls that were\ntransiently \"blanked\" during flight. Recurrent neural networks were trained to\nreproduce subject's gaze and hand movements during blank. The models\nsuccessfully predict gaze behavior within 3 degrees, and hand movements within\n8.5 cm as far as 500 ms in time, with integration window as short as 27 ms.\nFurthermore, we quantified the contribution of each input source of information\nto motor output through an ablation study. The model is a proof of concept for\nprediction as a discrete mapping between information integrated over time and a\ntemporally distant motor output.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.05946v1"
    },
    {
        "title": "Autonomous Vehicle Scheduling At Intersections Based On Production Line\n  Technique",
        "authors": [
            "Nasser Aloufi"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This thesis considers the problem of scheduling autonomous vehicles at\nintersections. A new system is proposed which is more efficient and could\nreplace the recently introduced Autonomous Intersection Management (AIM) model.\nThe proposed system is based on the production line technique. The environment\nof the intersection, vehicles position, speeds, and turning are specified and\ndetermined in advance. The goal of the proposed system is to eliminate vehicle\ncollision and reduce the waiting time to cross the intersection. Three\ndifferent patterns of traffic flow towards the intersection have been tested.\nThe system requires less waiting time, compared to the other models, including\nthe random case where the flow is unpredictable. The K-Nearest Neighbors (KNN)\nalgorithm has been used to predict vehicles making a right turn at the\nintersection. The experimental results show there is no chance of collision\ninside the intersection using the proposed model; however, the system might\nrequire more space in the traffic lane for some specific traffic patterns.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.06033v1"
    },
    {
        "title": "Cost-Benefit Analysis of Data Intelligence -- Its Broader\n  Interpretations",
        "authors": [
            "Min Chen"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The core of data science is our fundamental understanding about data\nintelligence processes for transforming data to decisions. One aspect of this\nunderstanding is how to analyze the cost-benefit of data intelligence\nworkflows. This work is built on the information-theoretic metric proposed by\nChen and Golan for this purpose and several recent studies and applications of\nthe metric. We present a set of extended interpretations of the metric by\nrelating the metric to encryption, compression, model development, perception,\ncognition, languages, and news media.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.08575v2"
    },
    {
        "title": "Constraining the Synopsys Pin Access Checker Utility for Improved\n  Standard Cells Library Verification Flow",
        "authors": [
            "Yongfu Li",
            "Chin Hui Lee",
            "Wan Chia Ang",
            "Kok Peng Chua",
            "Yoong Seang Jonathan Ong",
            "Chiu Wing Colin Hui"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  While standard cell layouts are drawn with minimum design rules for maximum\nbenefit of design area shrinkage, the complicated design rules begin to cause\ndifficulties with signal routes accessing the pins in standard cell layouts.\nMultiple design iterations are required to resolve routing issues, thus\nincreasing the runtime and the overall chip area. To optimize the chip\nperformance, power and area (PPA) and improve the routability, it is necessary\nto consider the pin accessibility during standard cell development phase so\nthat each cell is designed to maximize the number of feasible pin-access\nsolutions available to the router. As part of the Synopsys IC Compiler Library\nPreparation Reference Methodology, the Synopsys Pin Access Checker (PAC)\nreports DRC violations associated with the standard cell. Based on Synopsys\nPAC's methodology, we demonstrate several methods to improve the probability of\ndetecting pin accessibility issues, such as reducing the number of cells\nrequired for each Synopsys 'testcell', increasing the complexity of the pin\nconnectivity assignment and recommending the router constraints.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10012v1"
    },
    {
        "title": "In Design DFM Rule Scoring and Fixing Method using ICV",
        "authors": [
            "Vikas Tripathi",
            "Yongfu Li",
            "Zhao Chuan Lee",
            "I-Lun Tseng",
            "Jason Khaw",
            "Jonathan Ong"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  As compared to DRC rules, DFM rules are a list of selected recommended rules\nwhich aim to improve the design margins for better manufacturability. In\nGLOBALFOUNDRIES, we use DFM scoring methodology as an effective technique to\nanalyze design quality in terms of manufacturability. Physical design engineers\ncan perform our Manufacturability Check Deck (MCD) to asset their design\nquality during the sign-off stage. In the past, Synopsys users have to convert\ntheir design though milkyway database to GDSII format and execute the\nverification through the third party EDA tools. This method is costly and\ntime-consuming for our Synopsys users. Today, we propose a new and easy-to-use\nintegrated flow which leverages on the ICV engine to provide DFM scoring and\nin-design fixing techniques. The new methodology address DFM violations early\nin the design flow and achieve DFM compliance design during sign-off phase.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10016v1"
    },
    {
        "title": "Advanced In-Design Auto-Fixing Flow for Cell Abutment Pattern Matching\n  Weakpoints",
        "authors": [
            "Yongfu Li",
            "Valerio Perez",
            "I-Lun Tseng",
            "Zhao Chuan Lee",
            "Vikas Tripathi",
            "Jason Khaw",
            "Yoong Seang Jonathan Ong"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Pattern matching design verification has gained noticeable attention in\nsemiconductor technologies as it can precisely identify more localized\nproblematic areas (weakpoints) in the layout. To address these weakpoints,\nengineers adopt 'Rip-up and Reroute' methodology to reroute the nets and avoid\nthese weakpoints. However, the technique is unable to address weakpoints due to\nthe cell placement. The only present approach is to manually shift or flip the\nstandard cells to eradicate the weakpoint. To overcome the challenge in going\nfrom a manual and laborious process to a fully automated fixing, we have\nproposed an in-design auto-fixing feature, tested with the commercial design\ntool, Synopsys IC Compiler. Our experimental result has demonstrated close to\none hundred percent lithography weakpoints fixing on all of our 14nm designs.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10283v1"
    },
    {
        "title": "IoT for Green Building Management",
        "authors": [
            "Wayes Tushar",
            "Nipun Wijerathne",
            "Wen-Tai Li",
            "Chau Yuen",
            "H. Vincent Poor",
            "Tapan Kumar Saha",
            "Kristin L. Wood"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Buildings consume 60% of global electricity. However, current building\nmanagement systems (BMSs) are highly expensive and difficult to justify for\nsmall to medium-sized buildings. As such, the Internet of Things (IoT), which\ncan monitor and collect a large amount of data on different contexts of a\nbuilding and feed the data to the processor of the BMS, provides a new\nopportunity to integrate intelligence into the BMS to monitor and manage the\nenergy consumption of the building in a cost-effective manner. Although an\nextensive literature is available on IoT based BMS and applications of signal\nprocessing techniques for some aspects of building energy management\nseparately, detailed study on their integration to address the overall BMS is\nquite limited. As such, the proposed paper will address this gap by providing\nan overview of an IoT based BMS leveraging signal processing and machine\nlearning techniques. It is demonstrated how to extract high-level building\noccupancy information through simple and low-cost IoT sensors and studied the\nimpact of human activities on energy usage of a building, which can be\nexploited to design energy conservation measures to reduce the building's\nenergy consumption.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10635v1"
    },
    {
        "title": "Multiple-Lithography-Compliant Verification for Standard Cell Library\n  Development Flow",
        "authors": [
            "Yongfu Li",
            "Wan Chia Ang",
            "Chin Hui Lee",
            "Kok Peng Chua",
            "Yoong Seang Jonathan Ong",
            "Chiu Wing Colin Hui"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Starting from 22-nm, a standard cell must be designed to be full\nlithography-compliant, which includes Design Rule Check,\nDesign-for-Manufacturability and Double-Patterning compliant. It has become a\ngreat challenge for physical layout designers to provide a full\nlithography-compliant standard cell layout that is optimized for area, power,\ntiming, signal integrity, and yield. This challenge is further exacerbated with\nabutted single- and multiple-height standard cells. At present, different\nfoundries and library vendors have different approaches for full\nlithography-compliant library preparation and validation. To the best of our\nknowledge, there is no single tool integrates all types of\nlithography-compliant check in standard cell libraries validation flow. In this\nwork, we will demonstrate multiple lithography-compliant verification for\nstandard cell library development flow. Validation flow and detailed algorithm\nimplementation will be explained to assist engineers to achieve full\nlithography-compliant standard cell libraries. An area-efficient standard cell\nplacement methodology will also be discussed to validate the issues arises from\nstandard cell abutment.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.10745v1"
    },
    {
        "title": "Standard Cell Library Evaluation with Multiple lithography-compliant\n  verification and Improved Synopsys Pin Access Checking Utility",
        "authors": [
            "Yongfu Li",
            "Wan Chia Ang",
            "Chin Hui Lee",
            "Kok Peng Chua",
            "Yoong Seang Jonathan Ong",
            "Chiu Wing Colin Hui"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  While standard cell layouts are drawn with minimum design rules to maximize\nthe benefit of design area shrinkage, the complicated design rules have caused\ndifficulties with signal routes accessing the pins in standard cell layouts. As\na result, it has become a great challenge for physical layout designers to\ndesign a standard cell layout that is optimized for area, power, timing, signal\nintegrity, and printability. Multiple design iterations are required to\nconsider pin accessibility during standard cells layout to increase the number\nof feasible solutions available to the router. In this work, we will\ndemonstrate several improvements with the Synopsys PAC methodology, such as\nreducing the number of cells required for each Synopsys 'testcell' with the\nsame cell abutment condition, increasing the complexity of the pin connection\nfor better pin accessibility evaluation. We also recommend additional\nconstraints to improve the probability of detecting pin accessibility issues.\nWe also integrate other physical verification methods to access the design rule\ncompliance and the printability of standard cells. We hope that the easy to use\nutility enables layout engineers to perform the verification, simplifying the\nverification methodology.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.11426v1"
    },
    {
        "title": "Quantum Adiabatic Evolution for Global Optimization in Big Data",
        "authors": [
            "Sahil Imtiyaz"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Big Data is characterized by Volume, Velocity, Veracity and Complexity. The\ninteraction between this huge data is complex with an associated free will\nhaving dynamic and non linear nature. We reduced big data based on its\ncharacteristics, conceptually driven by quantum field theory and utilizing the\nphysics of condensed matter theory in a complex nonlinear dynamic system:\nQuantum Topological Field Theory of Data. The model is formulated from the\ndynamics and evolution of single datum, eventually defining the global\nproperties and evolution of collective data space via action, partition\nfunction, green propagators in almost polynomially solvable O(nlogn)\ncomplexity. The simulated results show that the time complexity of our\nalgorithm for global optimization via quantum adiabatic evolution is almost in\nO(logn) Our algorithm first mines the space via greedy approach and makes a\nlist of all ground state Hamiltonians, then utilizing the tunnelling property\nof quantum mechanics optimizes the algorithm unlike up hill and iterative\ntechniques and doesnot let algorithm to get localized in local minima or sharp\nvalley due to adiabatic evolution of the system. The loss in quantumness, non\nrealizable, no clone, noise, decoherence, splitting of energy states due to\nelectric and magnetic fields, variant to perturbations and less lifetime makes\nit inefficient for practical implementation. The inefficiencies of qubit can be\novercome via property that remains invariant to perturbation and Cartesian\nindependent having well defined mathematical structure. It can be well\naddressed via topological field theory of data.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.11479v1"
    },
    {
        "title": "DATA:SEARCH'18 -- Searching Data on the Web",
        "authors": [
            "Paul Groth",
            "Laura Koesten",
            "Philipp Mayr",
            "Maarten de Rijke",
            "Elena Simperl"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This half day workshop explores challenges in data search, with a particular\nfocus on data on the web. We want to stimulate an interdisciplinary discussion\naround how to improve the description, discovery, ranking and presentation of\nstructured and semi-structured data, across data formats and domain\napplications. We welcome contributions describing algorithms and systems, as\nwell as frameworks and studies in human data interaction. The workshop aims to\nbring together communities interested in making the web of data more\ndiscoverable, easier to search and more user friendly.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.11883v1"
    },
    {
        "title": "A Guide to the SPHERE 100 Homes Study Dataset",
        "authors": [
            "Atis Elsts",
            "Tilo Burghardt",
            "Dallan Byrne",
            "Massimo Camplani",
            "Dima Damen",
            "Xenofon Fafoutis",
            "Sion Hannuna",
            "William Harwin",
            "Michael Holmes",
            "Balazs Janko",
            "Victor Ponce Lopez",
            "Alessandro Masullo",
            "Majid Mirmehdi",
            "George Oikonomou",
            "Robert Piechocki",
            "R. Simon Sherratt",
            "Emma Tonkin",
            "Niall Twomey",
            "Antonis Vafeas",
            "Przemyslaw Woznowski",
            "Ian Craddock"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The SPHERE project has developed a multi-modal sensor platform for health and\nbehavior monitoring in residential environments. So far, the SPHERE platform\nhas been deployed for data collection in approximately 50 homes for duration up\nto one year. This technical document describes the format and the expected\ncontent of the SPHERE dataset(s) under preparation. It includes a list of some\ndata quality problems (both known to exist in the dataset(s) and potential\nones), their workarounds, and other information important to people working\nwith the SPHERE data, software, and hardware. This document does not aim to be\nan exhaustive descriptor of the SPHERE dataset(s); it also does not aim to\ndiscuss or validate the potential scientific uses of the SPHERE data.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.11907v2"
    },
    {
        "title": "An Integrated View on the Future of Logistics and Information Technology",
        "authors": [
            "Paul Grefen",
            "Wout Hofman",
            "Remco Dijkman",
            "Albert Veenstra",
            "Sander Peters"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In this position paper, we present our vision on the future of the logistics\nbusiness domain and the use of information technology (IT) in this domain. The\nvision is based on extensive experience with Dutch and European logistics in\nvarious contexts and from various perspectives. We expect that the vision also\nholds for logistics outside Europe. We build our vision in a number of steps.\nFirst, we make an inventory of the most important trends in the logistics\ndomain - we call these mega-trends. Next, we do the same for the information\ntechnology domain, restricted to technologies that have relevance for\nlogistics. Then, we introduce logistics meta-concepts that we use to describe\nour vision and relate them to business engineering. We use these three\ningredients to analyze leading concepts that we currently observe in the\nlogistics domain. Next, we consolidate all elements into a model that\nrepresents our vision of the integrated future of logistics and IT. We\nelaborate on the role of data platforms and open standards in this integrated\nvision.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.12485v1"
    },
    {
        "title": "DATC RDF: An Open Design Flow from Logic Synthesis to Detailed Routing",
        "authors": [
            "Jinwook Jung",
            "Iris Hui-Ru Jiang",
            "Jianli Chen",
            "Shih-Ting Lin",
            "Yih-Lang Li",
            "Victor N. Kravets",
            "Gi-Joon Nam"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In this paper, we present DATC Robust Design Flow (RDF) from logic synthesis\nto detailed routing. Our goals are 1) to provide an open-source academic design\nflow from logic synthesis to detailed routing based on existing contest\nresults, 2) to construct a database for design benchmarks and point tool\nlibraries, and 3) to interact with industrial designs by using industrial\nstandard design input/output formats. We also demonstrate RDF in a scalable\ncloud infrastructure. Design methodology and cross-stage optimization research\ncan be conducted via RDF.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.01078v2"
    },
    {
        "title": "An Automated System for Checking Lithography Friendliness of Standard\n  Cells",
        "authors": [
            "I-Lun Tseng",
            "Yongfu Li",
            "Valerio Perez",
            "Vikas Tripathi",
            "Zhao Chuan Lee",
            "Jonathan Yoong Seang Ong"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  At advanced process nodes, lithography weakpoints can exist in physical\nlayouts of integrated circuit designs even if the layouts pass design rule\nchecking (DRC). Existence of lithography weakpoints in a physical layout can\ncause manufacturability issues, which in turn can result in yield losses. In\nour experiments, we have found that specific standard cells have tendencies to\ncreate lithography weakpoints after their cell instances are placed and routed,\neven though each of these cells does not contain any lithography weakpoint\nbefore performing placement and routing. In addition, our experiments have\nshown that abutted standard cell instances can induce lithography weakpoints.\nTherefore, in this paper, we propose methodologies that are used in a novel\nsoftware system for checking standard cells in terms of the aforementioned\nlithography issues. Specifically, the software system is capable of detecting\nand sorting problematic standard cells which are prone to generate lithography\nweakpoints, as well as reporting standard cells that should not be abutted.\nMethodologies proposed in this paper allow us to reduce or even prevent the\ngeneration of undesirable lithography weakpoints during the physical synthesis\nphase of designing a digital integrated circuit.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.01446v1"
    },
    {
        "title": "FSS++ Workshop Report: Handling Uncertainty for Data Quality Management",
        "authors": [
            "Anna Wilbik"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This report describes the results of the eSCF Awareness Workshop on Handling\nUncertainty for Data Quality Management - Challenges from Transport and Supply\nChain Management that was held on June 5, 2018 in Heeze, The Netherlands. The\ngoal of this workshop was to create and enhance awareness into data quality\nmanagement issues that are encountered in practice, for business organizations\nthat aim to integrate a data-analytical mind set into their operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.02091v1"
    },
    {
        "title": "Real-Time Fine-Grained Air Quality Sensing Networks in Smart City:\n  Design, Implementation and Optimization",
        "authors": [
            "Zhiwen Hu",
            "Zixuan Bai",
            "Kaigui Bian",
            "Tao Wang",
            "Lingyang Song"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Driven by the increasingly serious air pollution problem, the monitoring of\nair quality has gained much attention in both theoretical studies and practical\nimplementations. In this paper, we present the architecture, implementation and\noptimization of our own air quality sensing system, which provides real-time\nand fine-grained air quality map of the monitored area. As the major component,\nthe optimization problem of our system is studied in detail. Our objective is\nto minimize the average joint error of the established real-time air quality\nmap, which involves data inference for the unmeasured data values. A deep\nQ-learning solution has been proposed for the power control problem to\nreasonably plan the sensing tasks of the power-limited sensing devices online.\nA genetic algorithm has been designed for the location selection problem to\nefficiently find the suitable locations to deploy limited number of sensing\ndevices. The performance of the proposed solutions are evaluated by\nsimulations, showing a significant performance gain when adopting both\nstrategies.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.08514v2"
    },
    {
        "title": "Human-Competitive Awards 2018",
        "authors": [
            "W. B. Langdon"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Report on Humies competition at GECCO 2018 in Japan\n",
        "pdf_link": "http://arxiv.org/pdf/1810.09416v1"
    },
    {
        "title": "STAIRoute: Early Global Routing using Monotone Staircases for Congestion\n  Reduction",
        "authors": [
            "Bapi Kar",
            "Susmita Sur-Kolay",
            "Chittaranjan Mandal"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  With aggressively shrinking process nodes, physical design methods face\nsevere challenges due to poor convergence and uncertainty in getting an optimal\nsolution. An early detection of potential failures is thus mandated. This has\nencouraged to devise a feedback mechanism from a lower abstraction level of the\ndesign flow to the higher ones, such as placement driven synthesis, routability\n(timing) driven placement etc.\n  Motivated by this, we propose an early global routing framework using pattern\nrouting following the floorplanning stage. We assess feasibility of a floorplan\ntopology of a given design by estimating routability, routed wirelength and\nvias count while addressing the global congestion scenario across the layout.\nDifferent capacity profiles for the routing regions, such as uniform or\nnon-uniform different cases of metal pitch variation across the metals layers\nensures adaptability to technology scaling. The proposed algorithm STAIRoute\ntakes $O(n^2kt)$ time for a given design with $n$ blocks and $k$ nets having at\nmost $t$ terminals. Experimental results on a set of floorplanning benchmark\ncircuits show $100\\%$ routing completion, with no over-congestion in the\nrouting regions reported. The wirelength for the $t$-terminal ($t\\geq$ 2) nets\nis comparable with the Steiner length computed by FLUTE. An estimation on the\nnumber of vias for different capacity profiles is also presented, along with\ncongestion and runtime results.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.10412v2"
    },
    {
        "title": "Waveform Signal Entropy and Compression Study of Whole-Building Energy\n  Datasets",
        "authors": [
            "Thomas Kriechbaumer",
            "Hans-Arno Jacobsen"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Electrical energy consumption has been an ongoing research area since the\ncoming of smart homes and Internet of Things devices. Consumption\ncharacteristics and usages profiles are directly influenced by building\noccupants and their interaction with electrical appliances. Extracted\ninformation from these data can be used to conserve energy and increase user\ncomfort levels. Data analysis together with machine learning models can be\nutilized to extract valuable information for the benefit of occupants\nthemselves, power plants, and grid operators. Public energy datasets provide a\nscientific foundation to develop and benchmark these algorithms and techniques.\nWith datasets exceeding tens of terabytes, we present a novel study of five\nwhole-building energy datasets with high sampling rates, their signal entropy,\nand how a well-calibrated measurement can have a significant effect on the\noverall storage requirements. We show that some datasets do not fully utilize\nthe available measurement precision, therefore leaving potential accuracy and\nspace savings untapped. We benchmark a comprehensive list of 365 file formats,\ntransparent data transformations, and lossless compression algorithms. The\nprimary goal is to reduce the overall dataset size while maintaining an\neasy-to-use file format and access API. We show that with careful selection of\nfile format and encoding scheme, we can reduce the size of some datasets by up\nto 73%.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.10887v1"
    },
    {
        "title": "Estimating Traffic Conditions At Metropolitan Scale Using Traffic Flow\n  Theory",
        "authors": [
            "Weizi Li",
            "Meilei Jiang",
            "Yaoyu Chen",
            "Ming C. Lin"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The rapid urbanization and increasing traffic have serious social, economic,\nand environmental impact on metropolitan areas worldwide. It is of a great\nimportance to understand the complex interplay of road networks and traffic\nconditions. The authors propose a novel framework to estimate traffic\nconditions at the metropolitan scale using GPS traces. Their approach begins\nwith an initial estimation of network travel times by solving a convex\noptimization program based on traffic flow theory. Then, they iteratively\nrefine the estimated network travel times and vehicle traversed paths. Last,\nthe authors perform a bilevel optimization process to estimate traffic\nconditions on road segments that are not covered by GPS data. The evaluation\nand comparison of the authors' approach over two state-of-the-art methods show\nup to 96.57% relative improvements. The authors have further conducted field\ntests by coupling road networks of San Francisco and Beijing with real-world\nGIS data, which involve 128,701 nodes, 148,899 road segments, and over 26\nmillion GPS traces.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.12295v1"
    },
    {
        "title": "Early Routability Assessment in VLSI Floorplans: A Generalized Routing\n  Model",
        "authors": [
            "Bapi Kar",
            "Susmita Sur-Kolay",
            "Chittaranjan Mandal"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Multiple design iterations are inevitable in nanometer Integrated Circuit\n(IC) design flow until desired printability and performance metrics are\nachieved. This starts with placement optimization aimed at improving\nroutability, wirelength, congestion and timing in the design. Contrarily, no\nsuch practice exists on a floorplanned layout, during the early stage of the\ndesign flow. Recently, STAIRoute \\cite{karb2} aimed to address that by\nidentifying the shortest routing path of a net through a set of routing regions\nin the floorplan in multiple metal layers. Since the blocks in hierarchical\nASIC/SoC designs do not use all the permissible routing layers for the internal\nrouting corresponding to standard cell connectivity, the proposed STAIRoute\nframework is not an effective for early global routability assessment. This\nleads to improper utilization of routing area, specifically in higher routing\nlayers with fewer routing blockages, as the lack of placement of standard cells\ndoes not facilitates any routing of their interconnections.\n  This paper presents a generalized model for early global routability\nassessment, HGR, by utilizing the free regions over the blocks beyond certain\nmetal layers. The proposed (hybrid) routing model comprises of (a) the junction\ngraph model in STAIRoute routing through the block boundary regions in lower\nrouting layers, and (ii) the grid graph model for routing in higher layers over\nthe free regions of the blocks.\n  Experiment with the latest floorplanning benchmarks exhibit an average\nreduction of $4\\%$, $54\\%$ and $70\\%$ in netlength, via count, and congestion\nrespectively when HGR is used over STAIRoute. Further, we conducted another\nexperiment on an industrial design flow targeted for $45nm$ process, and the\nresults are encouraging with $~3$X runtime boost when early global routing is\nused in conjunction with the existing physical design flow.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.12789v1"
    },
    {
        "title": "Solving High Volume Capacitated Vehicle Routing Problem with Time\n  Windows using Recursive-DBSCAN clustering algorithm",
        "authors": [
            "Kamil Bujel",
            "Feiko Lai",
            "Michal Szczecinski",
            "Winnie So",
            "Miguel Fernandez"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This paper introduces a new approach to improve the performance of the\nCapacitated Vehicle Routing Problem with Time Windows (CVRPTW) solvers for a\nhigh number of nodes. It proposes to cluster nodes together using\nRecursive-DBSCAN - an algorithm that recursively applies DBSCAN until clusters\nbelow the preset maximum number of nodes are obtained. That approach leads to\n61% decrease in runtimes of the CVRPTW solver as benchmarked against Google\nOptimization Tools, while the difference of total distance and number of\nvehicles used by found solutions is below 7%. The improvement of runtimes with\nthe Recursive-DBSCAN method is because of splitting the node-set into\nconstituent clusters, which limits the number of solutions checked by the\nsolver, consequently reducing the runtime. The proposed method consumes less\nmemory and is able to find solutions for problems up to 5000 nodes, while the\nbaseline Google Optimisation Tools solves problems up to 2000 nodes.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.02300v2"
    },
    {
        "title": "Climate Anomalies vs Air Pollution: Carbon Emissions and Anomaly\n  Networks",
        "authors": [
            "Anshul Goyal",
            "Kartikeya Bhardwaj",
            "Radu Marculescu"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This project aims to shed light on how man-made carbon emissions are\naffecting global wind patterns by looking for temporal and geographical\ncorrelations between carbon emissions, surface temperatures anomalies, and wind\nspeed anomalies at high altitude. We use a networks-based approach and daily\ndata from 1950 to 2010 [1-3] to model and draw correlations between disparate\nregions of the globe.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.02634v1"
    },
    {
        "title": "An Interactive, Graphical CPU Scheduling Simulator for Teaching\n  Operating Systems",
        "authors": [
            "Joshua W. Buck",
            "Saverio Perugini"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  We present a graphical simulation tool for visually and interactively\nexploring the processing of various events handled by an operating system when\nrunning a program. Our graphical simulator is available for use on the web and\nlocally by both instructors and students for purposes of pedagogy. Instructors\ncan use it for live demonstrations of course concepts in class, while students\ncan use it outside of class to explore the concepts. The graphical simulation\ntool is implemented using the React library for the fancy ui elements of the\nNode.js framework and is available as a single page web application at\nhttps://cpudemo.azurewebsites.net. Assigning the development of the underling\ntext-based simulation engine, on which the graphical simulator runs, to\nstudents as a course project is also an effective approach to teach students\nthe concepts. The goals of this paper are to showcase the demonstrative\ncapabilities of the tool for instruction, share student experiences in\ndeveloping the engine underlying the simulation, and to inspire its use by\nother educators.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.05160v2"
    },
    {
        "title": "Schrdinger's Man",
        "authors": [
            "Luca Vigan",
            "Diego Sempreboni"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  What if someone built a \"box\" that applies quantum superposition not just to\nquantum bits in the microscopic but also to macroscopic everyday \"objects\",\nsuch as Schr\\\"odinger's cat or a human being? If that were possible, and if the\ndifferent \"copies\" of a man could exploit quantum interference to synchronize\nand collapse into their preferred state, then one (or they?) could in a sense\nchoose their future, win the lottery, break codes and other security devices,\nand become king of the world, or actually of the many-worlds. We set up the\nplot-line of a new episode of Black Mirror to reflect on what might await us if\none were able to build such a technology.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.05839v1"
    },
    {
        "title": "An intelligent household greenhouse system design based on Internet of\n  Things",
        "authors": [
            "Zhonghua Han",
            "Zhenbo Wu",
            "Shuo Lin",
            "Fangjun Luan"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In order to combine indoor greenery conservation with Internet of Things\n(IOT) Technologies, this paper designs an intelligent household greenhouse\nproject with the features of comprehensive sensing, reliable transmission and\nintelligent processing. Through the analysis of functional requirements of the\nintelligent household greenhouse system, an intelligent household greenhouse\nsystem is designed with the functions of greenhouse environmental data\ndetection, greenhouse environmental control regulation, data remote\ntransmission and human-computer interaction. Its sensor layer collects\nenvironmental data in real time based on the ZigBee wireless sensor network.\nThe network layer STM32 intelligent gateway coordinates with network server, so\nas to exchange data from sensor layer to application layer, and solve the\nproblems of non-blocking of data sending and receiving as well as concurrent\nrequests of multiple mobile terminals. The application layer is designed into\ntwo types. One is a desktop management system as a data storage and analysis\ncenter, and the other is a mobile terminal APP. At the same time, we design a\ncommunication protocol that is applicable to the interaction of the three-layer\nstructure of the Internet of Things, with the characteristics of simplicity,\nstability, readability, and scalability. It can avoid the mutual influence of\nmulti-level data exchange and ensure the correctness of data circulation. In\nthe design, the system sensor layer ensures stable transmission of various data\nand instructions, and the network layer has a high degree of concurrency and\nreal time. And various measurement and control data of the sensor layer can\ninteract with the data of mobile-terminal equipment of the application layer.\nThe desktop management system and mobile terminal APP can monitor greenhouse\ndata in real time and control various actuators in the greenhouse.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11230v1"
    },
    {
        "title": "Open Source Software Opportunities and Risks",
        "authors": [
            "John Sherlock",
            "Manoj Muniswamaiah",
            "Lauren Clarke",
            "Shawn Cicoria"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Open Source Software (OSS) history is traced to initial efforts in 1971 at\nMassachusetts Institute of Technology (MIT) Artificial Intelligence (AI) Lab,\nthe initial goals of OSS around Free vs. Freedom, and its evolution and impact\non commercial and custom applications. Through OSS history, much of the\nresearch and has been around contributors (suppliers) to OSS projects, the\ncommercialization, and overall success of OSS as a development process. In\nconjunction with OSS growth, intellectual property issues and licensing issues\nstill remain. The consumers of OSS, application architects, in developing\ncommercial or internal applications based upon OSS should consider license risk\nas they compose their applications using Component Based Software Development\n(CBSD) approaches, either through source code, binary, or standard protocols\nsuch as HTTP.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.11697v1"
    },
    {
        "title": "Optimal Clustering of Energy Consumers based on Entropy of the\n  Correlation Matrix between Clusters",
        "authors": [
            "Nameer Al Khafaf",
            "Mahdi Jalili",
            "Peter Sokolowski"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Increased deployment of residential smart meters has made it possible to\nrecord energy consumption data on short intervals. These data, if used\nefficiently, carry valuable information for managing power demand and\nincreasing energy consumption efficiency. However, analyzing smart meter data\nof millions of customers in a timely manner is quite challenging. An efficient\nway to analyze these data is to first identify clusters of customers, and then\nfocus on analyzing these clusters. Deciding on the optimal number of clusters\nis a challenging task. In this manuscript, we propose a metric to efficiently\nfind the optimal number of clusters. A genetic algorithm based feature\nselection is used to reduce the number of features, which are then fed into\nself-organizing maps for clustering. We apply the proposed clustering technique\non two electricity consumption datasets from Victoria, Australia and Ireland.\nThe numerical simulations reveal effectiveness of the proposed method in\nfinding the optimal clusters.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.01159v1"
    },
    {
        "title": "Anti-Turing Machine",
        "authors": [
            "Viacheslav Dubeyko"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The invention of CPU-centric computing paradigm was incredible breakthrough\nof computer science that revolutionized our everyday life dramatically.\nHowever, the CPU- centric paradigm is based on the Turing machine concept and,\nas a result, expensive and power-hungry data transferring between the memory\nand CPU core is inevitable operation. Anti-Turing machine paradigm can be based\non two fundamental principles: (1) data-centric computing, and (2)\ndecentralized computing. Anti-Turing machine is able to execute a special type\nof programs. The commands of such program have to be addressed to the 2D or 3D\npersistent memory space is able to process data in-place. This program should\nnot define the position or structure of data but it has to define the goal of\ndata processing activity. Generally speaking, it needs to consider the whole\nmemory space like the data transformation space. But the data placement,\nparticular algorithm implementation, and strategy of algorithm execution are\nout of scope of the program.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09653v1"
    },
    {
        "title": "Trustworthy Experimentation Under Telemetry Loss",
        "authors": [
            "Jayant Gupchup",
            "Yasaman Hosseinkashi",
            "Pavel Dmitriev",
            "Daniel Schneider",
            "Ross Cutler",
            "Andrei Jefremov",
            "Martin Ellis"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Failure to accurately measure the outcomes of an experiment can lead to bias\nand incorrect conclusions. Online controlled experiments (aka AB tests) are\nincreasingly being used to make decisions to improve websites as well as mobile\nand desktop applications. We argue that loss of telemetry data (during upload\nor post-processing) can skew the results of experiments, leading to loss of\nstatistical power and inaccurate or erroneous conclusions. By systematically\ninvestigating the causes of telemetry loss, we argue that it is not practical\nto entirely eliminate it. Consequently, experimentation systems need to be\nrobust to its effects. Furthermore, we note that it is nontrivial to measure\nthe absolute level of telemetry loss in an experimentation system. In this\npaper, we take a top-down approach towards solving this problem. We motivate\nthe impact of loss qualitatively using experiments in real applications\ndeployed at scale, and formalize the problem by presenting a theoretical\nbreakdown of the bias introduced by loss. Based on this foundation, we present\na general framework for quantitatively evaluating the impact of telemetry loss,\nand present two solutions to measure the absolute levels of loss. This\nframework is used by well-known applications at Microsoft, with millions of\nusers and billions of sessions. These general principles can be adopted by any\napplication to improve the overall trustworthiness of experimentation and\ndata-driven decision making.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.12470v1"
    },
    {
        "title": "Epistemological and Bibliometric Analysis of Ethics and Shared\n  Responsibility Health Policy and IoT Systems",
        "authors": [
            "Petar Radanliev",
            "David De Roure"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The focus in this paper is placed on shared responsibility and ethics in\nhealth policy, specific to Internet of Things (IoT) devices in healthcare\nsystems. The article assesses how the introduction of IoT brings risks to the\nsecurity of medical systems. The justification for this research emerges from\nthe opportunities emerging from digital technologies for medical services, but\nalso creating a range of new cyber risks in the shared healthcare\ninfrastructure. Such concerns are often not visible to individual departments\nin an integrated healthcare system. In addition, many healthcare organisations\ndo not possess cyber skills and are faced with barriers to the adoption of\nsmart manufacturing technologies, e.g., cost. These barriers trigger ethical\nconcerns related to responsibility of cyber risks in shared healthcare systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.12582v2"
    },
    {
        "title": "Value driven Analysis Framework of Service Ecosystem Evolution Mechanism",
        "authors": [
            "Xiao Xue",
            "Deyu Zhou",
            "Yaodan Guo",
            "Zhiyong Feng",
            "Lejun Zhang",
            "Lin Meng"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  With the development of cloud computing, service computing, IoT(Internet of\nThings) and mobile Internet, the diversity and sociality of services are\nincreasingly apparent. To meet the customized user demands, Service Ecosystem\nis emerging as a complex social-technology system, which is formed with various\nIT services through cross-border integration. However, how to analyze and\npromote the evolution mechanism of service ecosystem is still a serious\nchallenge in the field, which is of great significance to achieve the expected\nsystem evolution trends. Based on this, this paper proposes a value-driven\nanalysis framework of service ecosystem, including value creation, value\noperation, value realization and value distribution. In addition, a\ncomputational experiment system is established to verify the effectiveness of\nthe analysis framework, which stimulates the effect of different operation\nstrategies on the value network in the service ecosystem. The result shows that\nour analysis framework can provide new means and ideas for the analysis of\nservice ecosystem evolution, and can also support the design of operation\nstrategies. Index\n",
        "pdf_link": "http://arxiv.org/pdf/2008.01055v1"
    },
    {
        "title": "Value Entropy Model: Metric Method of Service Ecosystem Evolution",
        "authors": [
            "Xiao Xue",
            "Zhaojie Chen",
            "Shufang Wang",
            "Zhiyong Feng",
            "Yucong Duan",
            "Zhangbing Zhou"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  With the development of cloud computing, service computing, IoT(Internet of\nThings) and mobile Internet, the diversity and sociality of services are\nincreasingly apparent. To meet the customized user demands, service ecosystems\nbegins to emerge with the formation of various IT services collaboration\nnetwork. However, service ecosystem is a complex social-technology system with\nthe characteristics of natural ecosystems, economic systems and complex\nnetworks. Hence, how to realize the multi-dimensional evaluation of service\necosystem is of great significance to promote its sound development. Based on\nthis, this paper proposes a value entropy model to analyze the performance of\nservice ecosystem, which is conducive to integrate evaluation indicators of\ndifferent dimensions. In addition, a computational experiment system is\nconstructed to verify the effectiveness of value entropy model. The result\nshows that our model can provide new means and ideas for the analysis of\nservice ecosystem.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.02247v1"
    },
    {
        "title": "Quality Classification of Defective Parts from Injection Moulding",
        "authors": [
            "Adithya Venkatadri Hulagadri"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  This report examines machine learning algorithms for detecting short forming\nand weaving in plastic parts produced by injection moulding. Transfer learning\nwas implemented by using pretrained models and finetuning them on our dataset\nof 494 samples of 150 by 150 pixels images. The models tested were Xception,\nInceptionV3 and Resnet-50. Xception showed the highest overall accuracy\n(86.66%), followed by InceptionV3 (82.47%) and Resnet-50 (80.41%). Short\nforming was the easiest fault to identify, with the highest F1 score for each\nmodel.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.02872v1"
    },
    {
        "title": "Analysis of Fleet Management and Network Design for On-Demand Urban Air\n  Mobility Operations",
        "authors": [
            "Sheng Li",
            "Maxim Egorov",
            "Mykel J. Kochenderfer"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  A significant challenge in estimating operational feasibility of Urban Air\nMobility (UAM) missions lies in understanding how choices in design impact the\nperformance of a complex system-of-systems. This work examines the ability of\nthe UAM ecosystem and the operations within it to meet a variety of demand\nprofiles that may emerge in the coming years. We perform a set of simulation\ndriven feasibility and scalability analyses based on UAM operational models\nwith the goal of estimating capacity and throughput for a given set of\nparameters that represent an operational UAM ecosystem. UAM ecosystem design\nguidelines, vehicle constraints, and effective operational policies can be\ndrawn from our analysis. Results show that, while critical for enabling UAM,\nthe performance of the UAM ecosystem is robust to variations in ground\ninfrastructure and fleet design decisions, while being sensitive to decisions\nfor fleet and traffic management policies. We show that so long as the\necosystem design parameters for ground infrastructure and fleet design fall\nwithin a sensible range, the performance of the UAM ecosystem is affected by\nthe policies used to manage the UAM traffic.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.05535v1"
    },
    {
        "title": "Computational Framework for Behind-The-Meter DER Techno-Economic\n  Modeling and Optimization -- REopt Lite",
        "authors": [
            "Sakshi Mishra",
            "Josiah Pohl",
            "Nick Laws",
            "Dylan Cutler",
            "Ted Kwasnik",
            "William Becker",
            "Alex Zolan",
            "Kate Anderson",
            "Dan Olis",
            "Emma Elgqvist"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The global energy system is undergoing a major transformation. Renewable\nenergy generation is growing and is projected to accelerate further with the\nglobal emphasis on decarbonization. Furthermore, distributed generation is\nprojected to play a significant role in the new energy system, and energy\nmodels are playing a key role in understanding how distributed generation can\nbe integrated reliably and economically. The deployment of massive amounts of\ndistributed generation requires understanding the interface of technology,\neconomics, and policy in the energy modeling process. In this work, we present\nan end-to-end computational framework for distributed energy resource (DER)\nmodeling, REopt Lite which addresses this need effectively. We describe the\nproblem space, the building blocks of the model, the scaling capabilities of\nthe design, the optimization formulation, and the accessibility of the model.\nWe present a framework for accelerating the techno-economic analysis of\nbehind-the-meter distributed energy resources to enable rapid planning and\ndecision-making, thereby significantly boosting the rate the renewable energy\ndeployment. Lastly, but equally importantly, this computation framework is\nopen-sourced to facilitate transparency, flexibility, and wider collaboration\nopportunities within the worldwide energy modeling community.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.05873v1"
    },
    {
        "title": "Herramientas tecnolgicas en Android para la formacin de mapeadores\n  y promotores de Mapa Verde",
        "authors": [
            "Yosvany Medina Carb",
            "C. lvaro Celestino Alonso Vzquez",
            "Reina Mara Rodrguez Garca"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  When you talk about technologies and the environment, you usually imagine a\nlot of equipment, techniques, technologies and tools polluting the natural\nenvironment. The good and bad consequences of our development have been\nprojected on the planet for years, and part of that development is reflected in\nthe new technologies, among which is the mobile phone. In the municipality of\nConsolaci\\'on del Sur and from the Municipal University Center, the project\nImplementation of the Green Map Methodology in the management of environmental\neducation in console communities for the formation of an environmental culture\nfor sustainable development is created, creating awareness of care and\nprotection of the environment. The present work is given to solve the following\nproblem: how to contribute in the construction of a package of computer tools\nfor the implementation of the Green Map methodology in environmental management\nin console communities and the training of mappers and promoters of Green Map\nfor the development of green maps of the communities of the municipality\nConsolaci\\'on del Sur? For this purpose, two Android applications for mobile\ndevices based on the Green Map methodology were developed, thus responding to\nthe following objective: Develop a package of computer applications for the\nimplementation of the Green Map methodology in the management of environmental\neducation in console communities and the formation of mappers and promoters of\nthe Green Map that allows the development of the green maps of the communities\nof the Consolaci\\'on del Sur municipality.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.07458v1"
    },
    {
        "title": "IoT Applications in Urban Sustainability",
        "authors": [
            "Samiya Khan",
            "Mohammad Moazum Wani",
            "Mansaf Alam"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Internet of Things is one of the driving technologies behind the concept of\nSmart Cities and is capable of playing a significant role in facilitating urban\nsustainable development. This chapter explores the relationship between three\ncore concepts namely Smart Cities, Internet of Things and Sustainability;\nthereby identifying the challenges and opportunities that exist in the\nsynergistic use of Internet of Things for sustainability, in the Smart Cities\ncontext. Moreover, this chapter also presents some of the existing use cases\nthat apply Internet of Things for urban sustainable development, also\npresenting the vision for these applications as they continue to evolve in and\nadapt to the real world scenario. It is because of the interdisciplinary nature\nof these applications that a clear comprehension of the associated challenges\nbecomes quintessential. Study of challenges and opportunities in this area\nshall facilitate collaboration between different sectors of urban planning and\noptimize the utilization of Internet of Things for sustainability.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.10656v1"
    },
    {
        "title": "Investigating the Performance Gap between Testing on Real and Denoised\n  Aggregates in Non-Intrusive Load Monitoring",
        "authors": [
            "Christoph Klemenjak",
            "Stephen Makonin",
            "Wilfried Elmenreich"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Prudent and meaningful performance evaluation of algorithms is essential for\nthe progression of any research field. In the field of Non-Intrusive Load\nMonitoring (NILM), performance evaluation can be conducted on real-world\naggregate signals, provided by smart energy meters or artificial superpositions\nof individual load signals (i.e., denoised aggregates). It has long been\nsuspected that testing on these denoised aggregates provides better evaluation\nresults mainly due to the the fact that the signal is less complex. Complexity\nin real-world aggregate signals increases with the number of unknown/untracked\nload. Although this is a known performance reporting problem, an investigation\nin the actual performance gap between real and denoised testing is still\npending. In this paper, we examine the performance gap between testing on\nreal-world and denoised aggregates with the aim of bringing clarity into this\nmatter. Starting with an assessment of noise levels in datasets, we find\nsignificant differences in test cases. We give broad insights into our\nevaluation setup comprising three load disaggregation algorithms, two of them\nrelying on neural network architectures. The results presented in this paper,\nbased on studies covering three scenarios with ascending noise levels, show a\nstrong tendency towards load disaggregation algorithms providing significantly\nbetter performance on denoised aggregate signals. A closer look into the\noutcome of our studies reveals that all appliance types could be subject to\nthis phenomenon. We conclude the paper by discussing aspects that could be\ncausing these considerable gaps between real and denoised testing in NILM.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.10985v2"
    },
    {
        "title": "LED wristbands for Cell-based Crowd Evacuation: an Adaptive Exit-choice\n  Guidance System Architecture",
        "authors": [
            "Miguel A. Lopez-Carmona",
            "Alvaro Paricio"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Cell-based crowd evacuation systems provide adaptive or static exit-choice\nindications that favor a coordinated group dynamic, improving evacuation time\nand safety. While a great effort has been made to modeling its control logic by\nassuming an ideal communication and positioning infrastructure, the\narchitectural dimension and the influence of pedestrian positioning uncertainty\nhave been largely overlooked. In our previous research, a Cell-based crowd\nevacuation system (CellEVAC) was proposed that dynamically allocates exit gates\nto pedestrians in a cell-based pedestrian positioning infrastructure. This\nsystem provides optimal exit-choice indications through color-based indications\nand a control logic module built upon an optimized discrete-choice model. Here,\nwe investigate how location-aware technologies and wearable devices can be used\nfor a realistic deployment of CellEVAC. We consider a simulated real evacuation\nscenario (Madrid Arena) and propose a system architecture for CellEVAC that\nincludes: a controller node, a radio-controlled LED wristband subsystem, and a\ncell-node network equipped with active Radio Frequency Identification (RFID)\ndevices. These subsystems coordinate to provide control, display and\npositioning capabilities. We quantitatively study the sensitivity of evacuation\ntime and safety to uncertainty in the positioning system. Results showed that\nCellEVAC was operational within a limited range of positioning uncertainty.\nFurther analyses revealed that reprogramming the control logic module through a\nsimulation-optimization process, simulating the positioning system's expected\nuncertainty level, improved the CellEVAC performance in scenarios with poor\npositioning systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.11128v1"
    },
    {
        "title": "Two-stage optimization of urban rail transit formation and real-time\n  station control at comprehensive transportation hub",
        "authors": [
            "Hualing Ren",
            "Yingjie Song",
            "Shubin Li"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  This paper tries to discuss two strategies of dealing with this complex\npassenger demand from two aspects: transit train formation and real-time\nholding control. The genetic algorithm (GA) is designed to solve the integrated\ntwo-stage model of optimizing the number, timetable and real-time holding\ncontrol of the multi-marshalling operated trains. The numerical results show\nthat the combined two-stage model of multi-marshalling operation and holding\ncontrol at stations can better deal with the demand fluctuation of urban rail\ntransit connecting with the comprehensive transportation hub.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.12207v1"
    },
    {
        "title": "Modeling, Stability Analysis, and Testing of a Hybrid Docking Simulator",
        "authors": [
            "M. Zebenaya",
            "T. Boge",
            "D. Choukroun"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  A hybrid docking simulator is a hardware-in-the-loop (HIL) simulator that\nincludes a hardware element within a numerical simulation loop. One of the\ngoals of performing a HIL simulation at the European Proximity Operation\nSimulator (EPOS) is the verification and validation of the docking phase in an\non-orbit servicing mission.....\n",
        "pdf_link": "http://arxiv.org/pdf/1409.0562v1"
    },
    {
        "title": "Population spatialization and synthesis with open data",
        "authors": [
            "Ying Long",
            "Zhenjiang Shen"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Individuals together with their locations & attributes are essential to feed\nmicro-level applied urban models (for example, spatial micro-simulation and\nagent-based modeling) for policy evaluation. Existed studies on population\nspatialization and population synthesis are generally separated. In developing\ncountries like China, population distribution in a fine scale, as the input for\npopulation synthesis, is not universally available. With the open-government\ninitiatives in China and the emerging Web 2.0 techniques, more and more open\ndata are becoming achievable. In this paper, we propose an automatic process\nusing open data for population spatialization and synthesis. Specifically, the\nroad network in OpenStreetMap is used to identify and delineate parcel\ngeometries, while crowd-sourced POIs are gathered to infer urban parcels with a\nvector cellular automata model. Housing-related online Check-in records are\nthen applied to distinguish residential parcels from all of the identified\nurban parcels. Finally the published census data, in which the sub-district\nlevel of attributes distribution and relationships are available, is used for\nsynthesizing population attributes with a previously developed tool Agenter\n(Long and Shen, 2013). The results are validated with ground truth\nmanually-prepared dataset by planners from Beijing Institute of City Planning.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.0612v1"
    },
    {
        "title": "Evaluating the Electrification of Vehicle Fleets Using the Veins\n  Framework",
        "authors": [
            "Sebastian Schellenberg",
            "Rdiger Berndt",
            "Reinhard German",
            "David Eckhoff"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The case study discussed in this paper involves a company maintaining a\nvehicle fleet of one hundred vehicles. In this article we will discuss how we\nextend and deploy the Veins framework, which couples OMNeT++ and SUMO, to help\nin the process of electrifying this vehicle fleet, i.e., replacing combustion\nengine cars with electric vehicles to save money and lower CO$_2$ emissions.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.1003v1"
    },
    {
        "title": "Exercises for Children with Dyslalia-Software Infrastructure",
        "authors": [
            "Cristian-Eduard Belciug",
            "Ovidiu-Andrei Schipor",
            "Mirela Danubianu"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In order to help children with dyslalia we created a set of software\nexercises. This set has a unitary software block (data base, programming\nlanguage, programming philosophy). In this paper we present this software\ninfrastructure with its advantage and disadvantage. The exercises are part of a\nsoftware system named LOGOMON. Therefore, besides horizontal compatibilities\n(between exercises) vertical compatibilities are also presented (with LOGOMON\nsystem). Concerning database tables used for modulus of exercises, a part of\nthem is \"inherited\" from LOGOMON application and another are specific for\nexercises application. We also need to specify that there were necessary minor\nchanges of database tables used by LOGOMON. As programming language we used C#,\nimplemented in Visual Studio 2005. We developed specific interfaces elements\nand classes. We also used multimedia resources that were necessary for\nexercises (images, correct pronouncing obtained from speech therapist\nrecording, video clips). Another section of this application is related to\nloading of exercises on mobile devices (Pocket PC). A part of code has been\nimported directly, but there were a lot of files that need to be rewritten.\nAnyway, the multimedia resources were used without any processing.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.1699v1"
    },
    {
        "title": "V2V Propagation Modeling with Imperfect RSSI Samples",
        "authors": [
            "Silvija Kokalj-Filipovic",
            "Larry Greenstein",
            "Bin Cheng",
            "Marco Gruteser"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  We describe three in-field data collection efforts yielding a large database\nof RSSI values vs. time or distance from vehicles communicating with each other\nvia DSRC. We show several data processing schemes we have devised to develop\nVehicle-to-Vehicle (V2V) propagation models from such data. The database is\nlimited in several important ways, not least, the presence of a high noise\nfloor that limits the distance over which good modeling is feasible. Another is\nthe presence of interference from multiple active transmitters. Our methodology\nmakes it possible to obtain, despite these limitations, accurate models of\nmedian path loss vs. distance, shadow fading, and fast fading caused by\nmultipath. We aim not to develop a new V2V model, but to show the methods\nenabling such a model to be obtained from in-field RSSI data.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.1846v1"
    },
    {
        "title": "Design and Realization of an S-Band Microwave Low-Noise Amplifier for\n  Wireless RF Subsystems",
        "authors": [
            "Ardavan Rahimian",
            "Davood Momeni Pakdehi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This study undertakes the theoretical design, CAD modeling, realization, and\nperformance analysis of a microwave low-noise amplifier (LNA) which has been\naccurately developed for operation at 3.0 GHz (S-band). The objective of this\nresearch is to thoroughly analyze and develop a reliable microstrip LNA\nintended for a potential employment in wireless communication systems, and\nsatellite applications. The S-band microwave LNA demonstrates the\nappropriateness to develop a high-performance and well-established device\nrealization for wireless RF systems. The microwave amplifier simulations have\nbeen conducted using the latest version of the AWR Design Environment software.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.2141v2"
    },
    {
        "title": "Co-Emulation of Scan-Chain Based Designs Utilizing SCE-MI Infrastructure",
        "authors": [
            "Bill Jason Tomas",
            "Yingtao Jiang",
            "Mei Yang"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  As the complexity of the scan algorithm is dependent on the number of design\nregisters, large SoC scan designs can no longer be verified in RTL simulation\nunless partitioned into smaller sub-blocks. This paper proposes a methodology\nto decrease scan-chain verification time utilizing SCE-MI, a widely used\ncommunication protocol for emulation, and an FPGA-based emulation platform. A\nhigh-level (SystemC) testbench and FPGA synthesizable hardware transactor\nmodels are developed for the scan-chain ISCAS89 S400 benchmark circuit for\nhigh-speed communication between the host CPU workstation and the FPGA\nemulator. The emulation results are compared to other verification\nmethodologies (RTL Simulation, Simulation Acceleration, and Transaction-based\nemulation), and found to be 82% faster than regular RTL simulation. In\naddition, the emulation runs in the MHz speed range, allowing the incorporation\nof software applications, drivers, and operating systems, as opposed to the Hz\nrange in RTL simulation or sub-megahertz range as accomplished in\ntransaction-based emulation. In addition, the integration of scan testing and\nacceleration/emulation platforms allows more complex DFT methods to be\ndeveloped and tested on a large scale system, decreasing the time to market for\nproducts.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.3276v1"
    },
    {
        "title": "YoMo - The Arduino based Smart Metering Board",
        "authors": [
            "Christoph Klemenjak",
            "Dominik Egarter",
            "Wilfried Elmenreich"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Smart meters are an enabling technology for many smart grid applications.\nThis paper introduces a design for a low-cost smart meter system as well as the\nfundamentals of smart metering. The smart meter platform, provided as open\nhardware, is designed with a connector interface compatible to the Arduino\nplatform, thus opening the possibilities for smart meters with flexible\nhardware and computation features, starting from low-cost 8 bit micro\ncontrollers up to powerful single board computers that can run Linux. The\nmetering platform features a current transformer which allows a non-intrusive\ninstallation of the current measurement unit. The suggested design can switch\nloads, offers a variable sampling frequency, and provides measurement data such\nas active power, reactive and apparent power. Results indicate that measurement\naccuracy and resolution of the proposed metering platform are sufficient for a\nrange of different applications and loads from a few watts up to five\nkilowatts.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.3404v1"
    },
    {
        "title": "Profiling underprivileged residents with mid-term public transit\n  smartcard data of Beijing",
        "authors": [
            "Ying Long",
            "Xingjian Liu",
            "Jiangping Zhou",
            "Yizhen Gu"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Mobility of economically underprivileged residents in China has seldom been\nwell profiled due to privacy issue and the characteristics of Chinese over\npoverty. In this paper, we identify and characterize underprivileged residents\nin Beijing using ubiquitous public transport smartcard transactions in 2008 and\n2010, respectively. We regard these frequent bus/metro riders (FRs) in China,\nespecially in Beijing, as economically underprivileged residents. Our argument\nis tested against (1) the household travel survey in 2010, (2) a small-scale\nsurvey in 2012, as well as (3) our interviews with local residents in Beijing.\nCardholders' job and residence locations are identified using Smart Card Data\n(SCD) in 2008 and 2010. Our analysis is restricted to cardholders that use the\nsame cards in both years. We then classify all identified FRs into 20 groups by\nresidence changes (change, no change), workplace changes (change, no change,\nfinding a job, losing a job, and all-time employed) during 2008-2010 and\nhousing place in 2010 (within the fourth ring road or not). The underprivileged\ndegree of each FR is then evaluated using the 2014 SCD. To the best of our\nknowledge, this is one of the first studies for understanding long- or mid-term\nurban dynamics using immediate \"big data\", and also for profiling\nunderprivileged residents in Beijing in a fine-scale.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.5839v1"
    },
    {
        "title": "Poster Abstract: Bits and Watts: Improving energy disaggregation\n  performance using power line communication modems",
        "authors": [
            "Nipun Batra",
            "Manoj Gulati",
            "Puneet Jain",
            "Kamin Whitehouse",
            "Amarjeet Singh"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Non-intrusive load monitoring (NILM) or energy disaggregation, aims to\ndisaggregate a household's electricity consumption into constituent appliances.\nMore than three decades of work in NILM has resulted in the development of\nseveral novel algorithmic approaches. However, despite these advancements, two\ncore challenges still exist: i) disaggregating low power consumption appliances\nand ii) distinguishing between multiple instances of similar appliances. These\nchallenges are becoming increasingly important due to an increasing number of\nappliances and increased usage of electronics in homes. Previous approaches\nhave attempted to solve these problems using expensive hardware involving high\nsampling rates better suited to laboratory settings, or using additional number\nof sensors, limiting the ease of deployment. In this work, we explore using\ncommercial-off-the-shelf (COTS) power line communication (PLC) modems as an\ninexpensive and easy to deploy alternative solution to these problems. We use\nthe reduction in bandwidth between two PLC modems, caused due to the change in\nPLC modulation scheme when different appliances are operated as a signature for\nan appliance. Since the noise generated in the powerline is dependent both on\ntype and location of an appliance, we believe that our technique based on PLC\nmodems can be a promising addition for solving NILM.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.5907v2"
    },
    {
        "title": "Demo Abstract: NILMTK v0.2: A Non-intrusive Load Monitoring Toolkit for\n  Large Scale Data Sets",
        "authors": [
            "Jack Kelly",
            "Nipun Batra",
            "Oliver Parson",
            "Haimonti Dutta",
            "William Knottenbelt",
            "Alex Rogers",
            "Amarjeet Singh",
            "Mani Srivastava"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this demonstration, we present an open source toolkit for evaluating\nnon-intrusive load monitoring research; a field which aims to disaggregate a\nhousehold's total electricity consumption into individual appliances. The\ntoolkit contains: a number of importers for existing public data sets, a set of\npreprocessing and statistics functions, a benchmark disaggregation algorithm\nand a set of metrics to evaluate the performance of such algorithms.\nSpecifically, this release of the toolkit has been designed to enable the use\nof large data sets by only loading individual chunks of the whole data set into\nmemory at once for processing, before combining the results of each chunk.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.5908v3"
    },
    {
        "title": "Filtering from Observations on Stiefel Manifolds",
        "authors": [
            "Jeremie Boulanger",
            "Salem Said",
            "Nicolas Le Bihan",
            "Jonathan Manton"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper considers the problem of optimal filtering for partially observed\nsignals taking values on the rotation group. More precisely, one or more\ncomponents are considered not to be available in the measurement of the\nattitude of a 3D rigid body. In such cases, the observed signal takes its\nvalues on a Stiefel manifold. It is demonstrated how to filter the observed\nsignal through the anti-development built from observations. A particle filter\nimplementation is proposed to perform the estimation of the signal partially\nobserved and corrupted by noise. The sampling issue is also addressed and\ninterpolation methods are introduced. Illustration of the proposed technique on\nsynthetic data demonstrates the ability of the approach to estimate the angular\nvelocity of a partially observed 3D system partially observed.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.7442v1"
    },
    {
        "title": "An Application of Topological Data Analysis to Hockey Analytics",
        "authors": [
            "Daniel Goldfarb"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper applies the major computational tool from Topological Data\nAnalysis (TDA), persistent homology, to discover patterns in the data related\nto professional sports teams. I will use official game data from the\nNorth-American National Hockey League (NHL) 2013-2014 season to discover the\ncorrelation between the composition of NHL teams with the currently preferred\noffensive performance markers. Specifically, I develop and use the program\nTeamPlex (based on the JavaPlex software library) to generate the persistence\nbar-codes. TeamPlex is applied to players as data points in a multidimensional\n(up to 12-D) data space where each coordinate corresponds to a selected\nperformance marker.\n  The conclusion is that team's offensive performance (measured by the popular\ncharacteristic used in NHL called the Corsi number) correlates with two\nbar-code characteristics: greater \\textit{sparsity} reflected in the longer\nbars in dimension 0 and lower \\textit{tunneling} reflected in the low\nnumber/length of the 1-dimensional classes. The methodology can be used by team\nmanagers in identifying deficiencies in the present composition of the team and\nanalyzing player trades and acquisitions. We give an example of a proposed\ntrade which should improve the Corsi number of the team.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.7635v1"
    },
    {
        "title": "Modeling In vivo Wireless Path Loss",
        "authors": [
            "Yang Liu",
            "Thomas P. Ketterl",
            "Gabriel E. Arrobo",
            "Richard D. Gitlin"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Our long-term research goal is to model the in vivo wireless channel. As a\nfirst step towards this goal, in this paper we performed in vivo path loss\nmeasurements at 2.4GHz and make a comparison with free space path loss. We\ncalculate the path loss by using the electric field radiated by a\nHertzian-Dipole located inside the abdominal cavity. The simulations quantify\nand confirm that the path loss falls more rapidly inside the body than outside\nthe body. We also observe fluctuations of the path loss caused by the\ninhomogeneity of the human body. In comparison with the path loss measured with\nmonopole antennas, we conclude that the significant variations in Received\nSignal Strength is caused by both the angular dependent path loss and the\nsignificantly modified in vivo antenna effects.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.7971v1"
    },
    {
        "title": "A Smart Cushion for Real-Time Heart Rate Monitoring",
        "authors": [
            "Chacko John Deepu",
            "Zhihao Chen",
            "Ju Teng Teo",
            "Soon Huat Ng",
            "Xiefeng Yang",
            "Yong Lian"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper presents a smart cushion for real time heart rate monitoring. The\ncushion comprises of an integrated micro-bending fiber sensor, which records\nthe BCG (Ballistocardiogram) signal without direct skin-electrode contact, and\nan optical transceiver that does signal amplification, digitization, and\npre-filtering. To remove the artifacts and extract heart rate from BCG signal,\na computationally efficient heart rate detection algorithm is developed. The\nsystem doesn't require any pre-training and is highly responsive with the\noutputs updated every 3 sec and initial response within first 10 sec. Tests\nconducted on human subjects show the detected heart rate closely matches the\none from a commercial SpO2 device.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.8021v1"
    },
    {
        "title": "Asynchronous Linear Modulation Classification with Multiple Sensors via\n  Generalized EM Algorithm",
        "authors": [
            "O. Ozdemir",
            "T. Wimalajeewa",
            "B. Dulek",
            "P. K. Varshney",
            "W. Su"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper, we consider the problem of automatic modulation classification\nwith multiple sensors in the presence of unknown time offset, phase offset and\nreceived signal amplitude. We develop a novel hybrid maximum likelihood (HML)\nclassification scheme based on a generalized expectation maximization (GEM)\nalgorithm. GEM is capable of finding ML estimates numerically that are\nextremely hard to obtain otherwise. Assuming a good initialization technique is\navailable for GEM, we show that the classification performance can be greatly\nimproved with multiple sensors compared to that with a single sensor,\nespecially when the signal-to-noise ratio (SNR) is low. We further demonstrate\nthe superior performance of our approach when simulated annealing (SA) with\nuniform as well as nonuniform grids is employed for initialization of GEM in\nlow SNR regions. The proposed GEM based approach employs only a small number of\nsamples (in the order of hundreds) at a given sensor node to perform both time\nand phase synchronization, signal power estimation, followed by modulation\nclassification. We provide simulation results to show the computational\nefficiency and effectiveness of the proposed algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.8370v2"
    },
    {
        "title": "Control Flow Information Analysis in Process Model Matching Techniques",
        "authors": [
            "Christopher Klinkmler",
            "Ingo Weber"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Online Appendix to: \"Analyzing Control Flow Information to Improve the\nEffectiveness of Process Model Matching Techniques\" by the same authors.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.01089v1"
    },
    {
        "title": "Project Makespan Estimation: Computational Load of Interval and Point\n  Estimates",
        "authors": [
            "Maurizio Naldi",
            "Marta Flamini"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The estimation of project completion time is to be repeated several times in\nthe project planning phase to reach the optimal tradeoff between time, cost,\nand quality. Estimation procedures provide either an interval or a point\nestimate. The computational load of several estimation procedures is reviewed.\nA multiple polynomial regression model is provided for major interval\nestimation procedures and shows that the accuracy in the probability model for\nactivities is the most influential factor. The computational time does not\nappear to be an impeding factor, though it is larger for MonteCarlo simulation,\nso that the computational time can be traded off in search of a simpler\nestimation procedure.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.01880v1"
    },
    {
        "title": "Skin Temperature Measurement",
        "authors": [
            "Siamak Sarjoghian"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This report represents the design and implementation of a skin temperature\nmeasurement system. The system aims to measure the skin temperature from a\nsensor and send it to the PC using a USB cable to display on screen. The data\nneeds to be updated every second. The PIC18F4550 microcontroller has been used\nin this project to obtain data from the sensor and send it to the PC using USB\n2.0 that has been built into the microcontroller. The microcontroller has a\n10-bit Analog Digital Converting accuracy that is one of the important criteria\nfor this design as it is going to be used for medical purposes. As the project\nconcentrates more on designing software than hardware, the EasyPIC4 development\nboard was used which comes with all hardware required for this project. The\nJackson diagram method was used to design and implement the coding program for\nthe microcontroller software part of the system. The MikroC IDE has been used\nto compile and load the program into PIC18F4550 microcontroller. The program\nfor the microcontroller uses C language that aims to keep the USB link alive by\nusing interrupt function. A sensor collects data from sensor as 4 bits and send\nit to the PC every second using a USB cable. The data received from sensor,\nwill be sent by microcontroller to the PC. The Visual Basic software was used\nin the PC side of device to catch and output the data on the screen. A template\nfile for the Visual Basic program was generated by Easy HID wizard to make\nsoftware programming part easier for designer. The USBTrace analyzer has been\nused in the scenario any problems occur during or after the design and\nconstruction of the software. The software enables a user to monitor the data\non the USB bus that sends the data to the PC from microcontroller.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.02296v1"
    },
    {
        "title": "Duty to Delete on Non-Volatile Memory",
        "authors": [
            "Na-Young Ahn",
            "Dong Hoon Lee"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  We firstly suggest new cache policy applying the duty to delete invalid cache\ndata on Non-volatile Memory (NVM). This cache policy includes generating random\ndata and overwriting the random data into invalid cache data. Proposed cache\npolicy is more economical and effective regarding perfect deletion of data. It\nis ensure that the invalid cache data in NVM is secure against malicious\nhackers.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.02842v1"
    },
    {
        "title": "Ethics of autonomous information systems towards an artificial thinking",
        "authors": [
            "Jol Colloc"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Many projects relies on cognitives sciences, neurosciences, computer sciences\nand robotics. They concerned today the building of autonomous artificial beings\nable to think. This paper shows a model to compare the human thinking with an\nhypothetic numerical way of thinking based on four hierarchies : the\ninformation system classification, the cognitive pyramid, the linguistic\npyramid and the digital information hierarchy. After a state of art on the\nnature of human thinking, feasibility of autonomous multi-agent systems\nprovided with artificial consciousness which are able to think is discussed.\nThe ethical aspects and consequences for humanity of such systems is evaluated.\nThese systems lead the scientific community to react.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.05259v1"
    },
    {
        "title": "The Limits to Machine Consciousness",
        "authors": [
            "Subhash Kak"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  It is generally accepted that machines can replicate cognitive tasks\nperformed by conscious agents as long as they are not based on the capacity of\nawareness. We consider several views on the nature of subjective awareness,\nwhich is fundamental for self-reflection and review, and present reasons why\nthis property is not computable. We argue that consciousness is more than an\nepiphenomenon and assuming it to be a separate category is consistent with both\nquantum mechanics and cognitive science. We speak of two kinds of\nconsciousness, little-C and big-C, and discuss the significance of this\nclassification in analyzing the current academic debates in the field. The\ninteraction between the system and the measuring apparatus of the experimenter\nis examined both from the perspectives of decoherence and the quantum Zeno\neffect. These ideas are used as context to address the question of limits to\nmachine consciousness.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.06257v1"
    },
    {
        "title": "Meaningless comparisons lead to false optimism in medical machine\n  learning",
        "authors": [
            "Orianna DeMasi",
            "Konrad Kording",
            "Benjamin Recht"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  A new trend in medicine is the use of algorithms to analyze big datasets,\ne.g. using everything your phone measures about you for diagnostics or\nmonitoring. However, these algorithms are commonly compared against weak\nbaselines, which may contribute to excessive optimism. To assess how well an\nalgorithm works, scientists typically ask how well its output correlates with\nmedically assigned scores. Here we perform a meta-analysis to quantify how the\nliterature evaluates their algorithms for monitoring mental wellbeing. We find\nthat the bulk of the literature ($\\sim$77%) uses meaningless comparisons that\nignore patient baseline state. For example, having an algorithm that uses phone\ndata to diagnose mood disorders would be useful. However, it is possible to\nover 80% of the variance of some mood measures in the population by simply\nguessing that each patient has their own average mood - the patient-specific\nbaseline. Thus, an algorithm that just predicts that our mood is like it\nusually is can explain the majority of variance, but is, obviously, entirely\nuseless. Comparing to the wrong (population) baseline has a massive effect on\nthe perceived quality of algorithms and produces baseless optimism in the\nfield. To solve this problem we propose \"user lift\" that reduces these\nsystematic errors in the evaluation of personalized medical monitoring.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.06289v1"
    },
    {
        "title": "Modular AWG-based Optical Shuffle Network",
        "authors": [
            "Jingjie Ding",
            "Tong Ye",
            "Tony T. Lee",
            "Weisheng Hu"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This paper proposes an arrayed-waveguide grating (AWG) based\nwavelength-division-multiplexing (WDM) shuffle network. Compared with previous\noptical shuffle networks, our proposal is compact, easy to implement, highly\nscalable, and cost effective.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.09280v1"
    },
    {
        "title": "Proceedings of the X International Workshop on Locational Analysis and\n  Related Problems",
        "authors": [
            "Maria Albareda-Sambola",
            "Marta Baldomero-Naranjo",
            "Luisa I. Martnez-Merino",
            "Diego Ponce",
            "Miguel A. Pozo",
            "Justo Puerto",
            "Victoria Rebillas-Loredo."
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The International Workshop on Locational Analysis and Related Problems will\ntake place during January 23-24, 2020 in Seville (Spain). It is organized by\nthe Spanish Location Network and the Location Group GELOCA from the Spanish\nSociety of Statistics and Operations Research(SEIO). The Spanish Location\nNetwork is a group of more than 140 researchers from several Spanish\nuniversities organized into 7 thematic groups. The Network has been funded by\nthe Spanish Government since 2003.\n  One of the main activities of the Network is a yearly meeting aimed at\npromoting the communication among its members and between them and other\nresearchers, and to contribute to the development of the location field and\nrelated problems. The last meetings have taken place in C\\'adiz (January\n20-February 1, 2019), Segovia (September 27-29, 2017), M\\'alaga (September\n14-16, 2016), Barcelona (November 25-28, 2015), Sevilla (October 1-3, 2014),\nTorremolinos (M\\'alaga, June 19-21, 2013), Granada (May 10-12, 2012), Las\nPalmas de Gran Canaria (February 2-5, 2011) and Sevilla (February 1-3, 2010).\n  The topics of interest are location analysis and related problems. This\nincludes location models, networks, transportation, logistics, exact and\nheuristic solution methods, and computational geometry, among others.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.01702v1"
    },
    {
        "title": "On Orthogonal Projections on the Space of Consistent Pairwise\n  Comparisons Matrices",
        "authors": [
            "W. W. Koczkodaj",
            "R. Smarzewski",
            "J. Szybowski"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  In this study, the orthogonalization process for different inner products is\napplied to pairwise comparisons. Properties of consistent approximations of a\ngiven inconsistent pairwise comparisons matrix are examined. A method of a\nderivation of a priority vector induced by a pairwise comparison matrix for a\ngiven inner product has been introduced. The mathematical elegance of\northogonalization and its universal use in most applied sciences has been the\nmotivating factor for this study. However, the finding of this study that\napproximations depend on the inner product assumed, is of considerable\nimportance.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.06607v1"
    },
    {
        "title": "Proceedings of the VI International Workshop on Locational Analysis and\n  Related Problems",
        "authors": [
            "Maria Albareda-Sambola",
            "Luisa I. Martnez-Merino",
            "Antonio M. Rodrguez-Cha"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The International Workshop on Locational Analysis and Related Problems will\ntake place during November 25-27, 2015 in Barcelona (Spain). It is organized by\nthe Spanish Location Network and Location Group GELOCA (SEIO). GELOCA is a\nworking group on location belonging to the Statistics and Operations Research\nSpanish Society. The Spanish Location Network is a group of more than 140\nresearchers distributed into 16 nodes corresponding to several Spanish\nuniversities. The Network has been funded by the Spanish Government. Every\nyear, the Network organizes a meeting to promote the communication among its\nmembers and between them and other researchers, and to contribute to the\ndevelopment of the location field and related problems. Previous meetings took\nplace in Sevilla (October 1-3, 2014), Torremolinos (M\\'alaga, June 19-21,\n2013), Granada (May 10-12, 2012), Las Palmas de Gran Canaria (February 2-5,\n2011) and Sevilla (February 1-3, 2010). The topics of interest are location\nanalysis and related problems. This includes location, routing, networks,\ntransportation and logistics models; exact and heuristic solution methods, and\ncomputational geometry, among others.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08287v1"
    },
    {
        "title": "Proceedings of the VIII International Workshop on Locational Analysis\n  and Related Problems",
        "authors": [
            "Marta Baldomero-Naranjo",
            "Inmaculada Espejo-Miranda",
            "Luisa I. Martnez-Merino",
            "Antonio M. Rodrguez-Cha",
            "Diego Ruiz-Hernndez"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The International Workshop on Locational Analysis and Related Problems will\ntake place during September 27-29, 2017 in Segovia (Spain). It is organized by\nthe Spanish Location Network and Location Group GELOCA (SEIO). GELOCA is a\nworking group on location belonging to the Statistics and Operations Research\nSpanish Society. The Spanish Location Network is a group of more than 100\nresearchers distributed into 16 nodes corresponding to several Spanish\nuniversities. The Network has been funded by the Spanish Government. Every\nyear, the Network organizes a meeting to promote the communication between its\nmembers and between them and other researchers, and to contribute to the\ndevelopment of the location field and related problems. Previous meetings took\nplace in M\\'alaga (September 14-16, 2016), Barcelona (November 25-28, 2015),\nSevilla (October 1-3, 2014), Torremolinos (M\\'alaga, June 19-21, 2013), Granada\n(May 10-12, 2012), Las Palmas de Gran Canaria (February 2-5, 2011) and Sevilla\n(February 1-3, 2010). The topics of interest are location analysis and related\nproblems. It includes location, networks, transportation, routing, logistics\nmodels, as well as, exact and heuristic solution methods, and computational\ngeometry, among others.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08293v1"
    },
    {
        "title": "Proceedings of the IX International Workshop on Locational Analysis and\n  Related Problems",
        "authors": [
            "Marta Baldomero-Naranjo",
            "Inmaculada Espejo-Miranda",
            "Luisa I. Martnez-Merino",
            "Juan Manuel Muoz-Ocaa",
            "Antonio M. Rodrguez-Cha"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The International Workshop on Locational Analysis and Related Problems will\ntake place during January 30-February 1, 2019 in C\\'adiz (Spain). It is\norganized by the Spanish Location Network and Location Group GELOCA (SEIO).\nGELOCA is a working group on location belonging to the Statistics and\nOperations Research Spanish Society. The Spanish Location Network is a group of\nmore than 140 researchers distributed into 16 nodes corresponding to several\nSpanish universities. The Network has been funded by the Spanish Government.\nEvery year, the Network organizes a meeting to promote the communication\nbetween its members and between them and other researchers, and to contribute\nto the development of the location field and related problems. Previous\nmeetings took place in Segovia (September 27-29, 2017), M\\'alaga (September\n14-16, 2016), Barcelona (November 25-28, 2015), Sevilla (October 1-3, 2014),\nTorremolinos (M\\'alaga, June 19-21, 2013), Granada (May 10-12, 2012), Las\nPalmas de Gran Canaria (February 2-5, 2011) and Sevilla (February 1-3, 2010).\nThe topics of interest are location analysis and related problems. It includes\nlocation models, networks, transportation, logistics, exact and heuristic\nsolution methods, and computational geometry, among others.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.08300v1"
    },
    {
        "title": "Toward Predicting Success and Failure in CS2: A Mixed-Method Analysis",
        "authors": [
            "Lucas Layman",
            "Yang Song",
            "Curry Guinn"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Factors driving success and failure in CS1 are the subject of much study but\nless so for CS2. This paper investigates the transition from CS1 to CS2 in\nsearch of leading indicators of success in CS2. Both CS1 and CS2 at the\nUniversity of North Carolina Wilmington (UNCW) are taught in Python with annual\nenrollments of 300 and 150 respectively. In this paper, we report on the\nfollowing research questions: 1) Are CS1 grades indicators of CS2 grades? 2)\nDoes a quantitative relationship exist between CS2 course grade and a modified\nversion of the SCS1 concept inventory? 3) What are the most challenging aspects\nof CS2, and how well does CS1 prepare students for CS2 from the student's\nperspective? We provide a quantitative analysis of 2300 CS1 and CS2 course\ngrades from 2013--2019. In Spring 2019, we administered a modified version of\nthe SCS1 concept inventory to 44 students in the first week of CS2. Further, 69\nstudents completed an exit questionnaire at the conclusion of CS2 to gain\nqualitative student feedback on their challenges in CS2 and on how well CS1\nprepared them for CS2. We find that 56% of students' grades were lower in CS2\nthan CS1, 18% improved their grades, and 26% earned the same grade. Of the\nchanges, 62% were within one grade point. We find a statistically significant\ncorrelation between the modified SCS1 score and CS2 grade points. Students\nidentify linked lists and class/object concepts among the most challenging.\nStudent feedback on CS2 challenges and the adequacy of their CS1 preparations\nidentify possible avenues for improving the CS1-CS2 transition.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.11813v1"
    },
    {
        "title": "The Physical World as a Virtual Reality",
        "authors": [
            "Brian Whitworth"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper explores the idea that the universe is a virtual reality created\nby information processing, and relates this strange idea to the findings of\nmodern physics about the physical world. The virtual reality concept is\nfamiliar to us from online worlds, but our world as a virtual reality is\nusually a subject for science fiction rather than science. Yet logically the\nworld could be an information simulation running on a multi-dimensional\nspace-time screen. Indeed, if the essence of the universe is information,\nmatter, charge, energy and movement could be aspects of information, and the\nmany conservation laws could be a single law of information conservation. If\nthe universe were a virtual reality, its creation at the big bang would no\nlonger be paradoxical, as every virtual system must be booted up. It is\nsuggested that whether the world is an objective reality or a virtual reality\nis a matter for science to resolve. Modern information science can suggest how\ncore physical properties like space, time, light, matter and movement could\nderive from information processing. Such an approach could reconcile relativity\nand quantum theories, with the former being how information processing creates\nspace-time, and the latter how it creates energy and matter.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.0337v2"
    },
    {
        "title": "MRI/TRUS data fusion for prostate brachytherapy. Preliminary results",
        "authors": [
            "Christophe Reynier",
            "Jocelyne Troccaz",
            "Philippe Fourneret",
            "Andr Dusserre",
            "Ccile Gay-Jeune",
            "Jean-Luc Descotes",
            "Michel Bolla",
            "Jean-Yves Giraud"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Prostate brachytherapy involves implanting radioactive seeds (I125 for\ninstance) permanently in the gland for the treatment of localized prostate\ncancers, e.g., cT1c-T2a N0 M0 with good prognostic factors. Treatment planning\nand seed implanting are most often based on the intensive use of transrectal\nultrasound (TRUS) imaging. This is not easy because prostate visualization is\ndifficult in this imaging modality particularly as regards the apex of the\ngland and from an intra- and interobserver variability standpoint. Radioactive\nseeds are implanted inside open interventional MR machines in some centers.\nSince MRI was shown to be sensitive and specific for prostate imaging whilst\nopen MR is prohibitive for most centers and makes surgical procedures very\ncomplex, this work suggests bringing the MR virtually in the operating room\nwith MRI/TRUS data fusion. This involves providing the physician with\nbi-modality images (TRUS plus MRI) intended to improve treatment planning from\nthe data registration stage. The paper describes the method developed and\nimplemented in the PROCUR system. Results are reported for a phantom and first\nseries of patients. Phantom experiments helped characterize the accuracy of the\nprocess. Patient experiments have shown that using MRI data linked with TRUS\ndata improves TRUS image segmentation especially regarding the apex and base of\nthe prostate. This may significantly modify prostate volume definition and have\nan impact on treatment planning.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.2666v1"
    },
    {
        "title": "3D-Ultrasound probe calibration for computer-guided diagnosis and\n  therapy",
        "authors": [
            "Michael Baumann",
            "Vincent Daanen",
            "Antoine Leroy",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  With the emergence of swept-volume ultrasound (US) probes, precise and almost\nreal-time US volume imaging has become available. This offers many new\nopportunities for computer guided diagnosis and therapy, 3-D images containing\nsignificantly more information than 2-D slices. However, computer guidance\noften requires knowledge about the exact position of US voxels relative to a\ntracking reference, which can only be achieved through probe calibration. In\nthis paper we present a 3-D US probe calibration system based on a membrane\nphantom. The calibration matrix is retrieved by detection of a membrane plane\nin a dozen of US acquisitions of the phantom. Plane detection is robustly\nperformed with the 2-D Hough transformation. The feature extraction process is\nfully automated, calibration requires about 20 minutes and the calibration\nsystem can be used in a clinical context. The precision of the system was\nevaluated to a root mean square (RMS) distance error of 1.15mm and to an RMS\nangular error of 0.61 degrees. The point reconstruction accuracy was evaluated\nto 0.9mm and the angular reconstruction accuracy to 1.79 degrees.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.3711v1"
    },
    {
        "title": "Framework for 3D TransRectal Ultrasound",
        "authors": [
            "Pierre Mozer",
            "Michael Baumann",
            "G. Chevreau",
            "Vincent Daanen",
            "Alexandre Moreau-Gaudry",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Prostate biopsies are mainly performed under 2D TransRectal UltraSound (TRUS)\ncontrol by sampling the prostate according to a predefined pattern. In case of\nfirst biopsies, this pattern follows a random systematic plan. Sometimes,\nrepeat biopsies can be needed to target regions unsampled by previous biopsies\nor resample critical regions (for example in case of cancer expectant\nmanagement or previous prostatic intraepithelial neoplasia findings). From a\nclinical point of view, it could be useful to control the 3D spatial\ndistribution of theses biopsies inside the prostate. Modern 3D-TRUS probes\nallow acquiring high-quality volumes of the prostate in few seconds. We\ndeveloped a framework to track the prostate in 3D TRUS images. It means that if\none acquires a reference volume at the beginning of the session and another\nduring each biopsy, it is possible to determine the relationship between the\nprostate in the reference and the others volumes by aligning images. We used\nthis tool to evaluate the ability of a single operator (a young urologist\nassistant professor) to perform a pattern of 12 biopsies under 2D TRUS\nguidance.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.3965v1"
    },
    {
        "title": "Abstractions for biomolecular computations",
        "authors": [
            "Babatunde O. Okunoye"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  Deoxyribonucleic acid is increasingly being understood to be an informational\nmolecule, capable of information processing.It has found application in the\ndetermination of non-deterministic algorithms and in the design of molecular\ncomputing devices. This is a theoretical analysis of the mathematical\nproperties and relations of the molecules which constituting DNA, which\nexplains in part why DNA is a successful computing molecule.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.4480v1"
    },
    {
        "title": "Biopsies prostatiques sous guidage chographique 3D et temps rel\n  (4D) sur fantme. Etude comparative versus guidage 2D",
        "authors": [
            "Jean-Alexandre Long",
            "Vincent Daanen",
            "Alexandre Moreau-Gaudry",
            "Jocelyne Troccaz",
            "Jean-Jacques Rambeaud",
            "Jean-Luc Descotes"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper analyzes the impact of using 2D or 3D ultrasound on the efficiency\nof prostate biopsies. The evaluation is performed on home-made phantoms. The\nstudy shows that the accuracy is significantly improved.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.4483v1"
    },
    {
        "title": "Graceful Degradation of Air Traffic Operations",
        "authors": [
            "Maxime Gariel",
            "Eric Feron"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  The introduction of new technologies and concepts of operation in the air\ntransportation system is not possible, unless they can be proven not to\nadversely affect the system operation under not only nominal, but also degraded\nconditions. In extreme scenarios, degraded operations due to partial or\ncomplete technological failures should never endanger system safety. Many past\nsystem evolutions, whether ground-based or airborne, have been based on\ntrial-and-error, and system safety was addressed only after a specific event\nyielded dramatic or near- dramatic consequences. Future system evolutions,\nhowever, must leverage available computation, prior knowledge and abstract\nreasoning to anticipate all possible system degradations and prove that such\ndegradations are graceful and safe. This paper is concerned with the graceful\ndegradation of high-density, structured arrival traffic against partial or\ncomplete surveillance failures. It is shown that for equal performance\nrequirements, some traffic configurations might be easier to handle than\nothers, thereby offering a quantitative perspective on these traffic\nconfigurations. ability to \"gracefully degrade\". To support our work, we also\nintroduce a new conflict resolution algorithm, aimed at solving conflicts\ninvolving many aircraft when aircraft position information is in the process of\ndegrading.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.4750v1"
    },
    {
        "title": "Dipole-Loaded Monopole Optimized Using VSO, v.3",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A dipole-loaded monopole antenna is optimized for uniform hemispherical\ncoverage using VSO, a new global search design and optimization algorithm. The\nantenna's performance is compared to genetic algorithm and hill-climber\noptimized loaded monopoles, and VSO is tested against two suites of benchmark\nfunctions and several other algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.0220v3"
    },
    {
        "title": "How to Build an RSS Feed using ASP",
        "authors": [
            "Umakant Mishra"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  RSS is a XML based format. The Current popular version of RSS is RSS version\n2.0. The purpose of adding an RSS feed to your site is to show if anything new\nis added to the site. For example, if a new article or blog or news item is\nadded to your site that should automatically appear in the RSS feed so that the\nvisitors/ RSS readers will automatically get updated about this new addition.\nThe RSS feed is also called RSS channel.\n  There are two main elements of the RSS XML file, one is the header or channel\nelement that describes the details about the site/feeder and other is the body\nor item element that describes the consists of individual articles/entries\nupdated in the site. As the format of the RSS feed file is pretty simple, it\ncan be coded in any language, ASP, PHP or anything of that sort. We will build\nan RSS feeder using classical ASP (Active Server Pages) code in this article.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.0772v1"
    },
    {
        "title": "Wireless sensor network technology for moisture monitoring of wood",
        "authors": [
            "Ivan Arakistain",
            "Jose Miguel Abascal",
            "Oriol Munne"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Leaks represent a very important hazard for the buildings and they can affect\nall sorts of building materials and specially wood due to its hygroscopic\nproperties. Excessive moisture content can affect in a negative way building\nprocesses such as the installation of wooden floors or the use of wood as a\nstructural material. Moisture meters can provide prompt and non-destructive\ndetermination of wood moisture, and as such are among the most useful tools\navailable to wood products manufacturers and scientists. However, a continuous\nmonitoring system is needed in order to avoid excessive moisture content which\ncan damage wooden floors as well as structural wood. Data and procedures are\npresented in order to develop a suitable monitoring tool based on wireless\nsensor networks to provide an electronic tool of active security both for the\ninstallation of wooden floors and for the proper maintenance of existent\nbuildings which have a timber structure.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.0952v1"
    },
    {
        "title": "Machining of complex-shaped parts with guidance curves",
        "authors": [
            "Laurent Tapie",
            "Bernardin Mawussi",
            "Walter Rubio",
            "Benot Furet"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Nowadays, high-speed machining is usually used for production of hardened\nmaterial parts with complex shapes such as dies and molds. In such parts, tool\npaths generated for bottom machining feature with the conventional parallel\nplane strategy induced many feed rate reductions, especially when boundaries of\nthe feature have a lot of curvatures and are not parallel. Several machining\nexperiments on hardened material lead to the conclusion that a tool path\nimplying stable cutting conditions might guarantee a better part surface\nintegrity. To ensure this stability, the shape machined must be decomposed when\nconventional strategies are not suitable. In this paper, an experimental\napproach based on high-speed performance simulation is conducted on a master\nbottom machining feature in order to highlight the influence of the curvatures\ntowards a suitable decomposition of machining area. The decomposition is\nachieved through the construction of intermediate curves between the closed\nboundaries of the feature. These intermediate curves are used as guidance curve\nfor the tool paths generation with an alternative machining strategy called\n\"guidance curve strategy\". For the construction of intermediate curves, key\nparameters reflecting the influence of their proximity with each closed\nboundary and the influence of the curvatures of this latter are introduced.\nBased on the results, a method for defining guidance curves in four steps is\nproposed.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.1215v1"
    },
    {
        "title": "Design of One-Dimensional Linear Phase Digital IIR Filters Using\n  Orthogonal Polynomials",
        "authors": [
            "Vinay Kumar",
            "Sunil Bhooshan"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In the present paper, we discuss a method to design a linear phase\n1-dimensional Infinite Impulse Response (IIR) filter using orthogonal\npolynomials. The filter is designed using a set of object functions. These\nobject functions are realized using a set of orthogonal polynomials. The method\nincludes placement of zeros and poles in such a way that the amplitude\ncharacteristics are not changed while we change the phase characteristics of\nthe resulting IIR filter.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.2817v1"
    },
    {
        "title": "CMOS Low Power Cell Library For Digital Design",
        "authors": [
            "Kanika Kaur",
            "Arti Noor"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Historically, VLSI designers have focused on increasing the speed and\nreducing the area of digital systems. However, the evolution of portable\nsystems and advanced Deep Sub-Micron fabrication technologies have brought\npower dissipation as another critical design factor. Low power design reduces\ncooling cost and increases reliability especially for high density systems.\nMoreover, it reduces the weight and size of portable devices. The power\ndissipation in CMOS circuits consists of static and dynamic components. Since\ndynamic power is proportional to V2 dd and static power is proportional to Vdd,\nlowering the supply voltage and device dimensions, the transistor threshold\nvoltage also has to be scaled down to achieve the required performance. In case\nof static power, the power is consumed during the steady state condition i.e\nwhen there are no input/output transitions. Static power has two sources: DC\npower and Leakage power. Consecutively to facilitate voltage scaling without\ndisturbing the performance, threshold voltage has to be minimized. Furthermore\nit leads to better noise margins and helps to avoid the hot carrier effects in\nshort channel devices. In this paper we have been proposed the new CMOS library\nfor the complex digital design using scaling the supply voltage and device\ndimensions and also suggest the methods to control the leakage current to\nobtain the minimum power dissipation at optimum value of supply voltage and\ntransistor threshold. In this paper CMOS Cell library has been implemented\nusing TSMC (0.18um) and TSMC (90nm) technology using HEP2 tool of IC designing\nfrom Mentor Graphics for various analysis and simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.3017v1"
    },
    {
        "title": "Design and Implementation of Car Parking System on FPGA",
        "authors": [
            "Ramneet Kaur",
            "Balwinder Singh"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  As, the number of vehicles are increased day by day in rapid manner. It\ncauses the problem of traffic congestion, pollution (noise and air). To\novercome this problem A FPGA based parking system has been proposed. In this\npaper, parking system is implemented using Finite State Machine modelling. The\nsystem has two main modules i.e. identification module and slot checking\nmodule. Identification module identifies the visitor. Slot checking module\nchecks the slot status. These modules are modeled in HDL and implemented on\nFPGA. A prototype of parking system is designed with various interfaces like\nsensor interfacing, stepper motor and LCD.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.3051v1"
    },
    {
        "title": "Low Power Dual Edge-Triggered Static D Flip-Flop",
        "authors": [
            " Anurag",
            "Gurmohan Singh",
            "V. Sulochana"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This paper enumerates new architecture of low power dual-edge triggered\nFlip-Flop (DETFF) designed at 180nm CMOS technology. In DETFF same data\nthroughput can be achieved with half of the clock frequency as compared to\nsingle edge triggered Flip-Flop (SETFF). In this paper conventional and\nproposed DETFF are presented and compared at same simulation conditions. The\npost layout experimental results comparison shows that the average power\ndissipation is improved by 48.17%, 41.29% and 36.84% when compared with SCDFF,\nDEPFF and SEDNIFF respectively and improvement in PDP is 42.44%, 33.88% and\n24.69% as compared to SCDFF, DEPFF and SEDNIFF respectively. Therefore the\nproposed DETFF design is suitable for low power and small area applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.3075v2"
    },
    {
        "title": "Forecasting Intermittent Demand by Hyperbolic-Exponential Smoothing",
        "authors": [
            "S. D. Prestwich",
            "S. A. Tarim",
            "R. Rossi",
            "B. Hnich"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Croston's method is generally viewed as superior to exponential smoothing\nwhen demand is intermittent, but it has the drawbacks of bias and an inability\nto deal with obsolescence, in which an item's demand ceases altogether. Several\nvariants have been reported, some of which are unbiased on certain types of\ndemand, but only one recent variant addresses the problem of obsolescence. We\ndescribe a new hybrid of Croston's method and Bayesian inference called\nHyperbolic-Exponential Smoothing, which is unbiased on non-intermittent and\nstochastic intermittent demand, decays hyperbolically when obsolescence occurs\nand performs well in experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.6102v2"
    },
    {
        "title": "Abstract Geometrical Computation 8: Small Machines, Accumulations and\n  Rationality",
        "authors": [
            "Florent Becker",
            "Mathieu Chapelle",
            "Jrme Durand-Lose",
            "Vincent Levorato",
            "Maxime Senot"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In the context of abstract geometrical computation, computing with colored\nline segments, we study the possibility of having an accumulation with small\nsignal machines, ie, signal machines having only a very limited number of\ndistinct speeds. The cases of 2 and 4 speeds are trivial: we provide a proof\nthat no machine can produce an accumulation in the case of 2 speeds and exhibit\nan accumulation with 4 speeds. The main result is the twofold case of 3 speeds.\nOn the one hand, we prove that accumulations cannot happen when all ratios\nbetween speeds and all ratios between initial distances are rational. On the\nother hand, we provide examples of an accumulation in the case of an irrational\nratio between 2 speeds and in the case of an irrational ratio between two\ndistances in the initial configuration. This dichotomy is explained by the\npresence of a phenomenon computing Euclid's algorithm (gcd): it stops if and\nonly if its input is commensurate (ie, of rational ratio).\n",
        "pdf_link": "http://arxiv.org/pdf/1307.6468v1"
    },
    {
        "title": "An Integrated Geographic Information System and Marketing Information\n  System Model",
        "authors": [
            "Quist-Aphetsi Kester",
            " Koumadi",
            "Koudjo M",
            "Nii Narku Quaynor"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Maintaining competitive advantage is significant in this present day of\nglobalization, knowledge management and enormous economic activities. An\norganization's future developments are influenced by its managements'\ndecisions. Businesses today are facing a lot of challenges in terms of\ncompetition and they have to be in the lead by strengthening their research and\ndevelopment strategies with the aid of cutting edge technologies. Hence\nmarketing intelligence is now a key to the success of any business in today's\nrapidly changing business environment. With all the technologies available in\nmarketing research, businesses still struggle with how to gather information\nand make decisions in a short time and real-time about their customers' needs\nand purchasing patterns in various geographical areas.\n  This paper is set out to contribute to the body of knowledge in the area of\nthe application of Geographic Information Systems technology solutions to\nbusinesses by developing a model for integrating Geographic Information Systems\ninto existing Marketing Information Systems for effective marketing research.\nThis model will interconnect organizations at the highest levels, providing\nreassurance to enable broad scope of checks and balances as well as benefiting\nmany business activities including operational, tactical and strategic decision\nmaking due to its analytical and solution driven functions.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.7787v1"
    },
    {
        "title": "Complexity Analysis in Cyclic Tag System Emulated by Rule 110",
        "authors": [
            "Shigeru Ninagawa",
            "Genaro J. Martnez"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  It is known that elementary cellular automaton rule 110 is capable of\nsupporting universal computation by emulating cyclic tag system. Since the\nwhole information necessary to perform computation is stored in the\nconfiguration, it is reasonable to investigate the complexity of configuration\nfor the analysis of computing process. In this research we employed Lempel-Ziv\ncomplexity as a measure of complexity and calculated it during the evolution of\nemulating cyclic tag system by rule 110. As a result, we observed the stepwise\ndecline of complexity during the evolution. That is caused by the\ntransformation from table data to moving data and the elimination of table data\nby a rejector.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.7951v1"
    },
    {
        "title": "Improved Median Polish Kriging for Simulation Metamodeling",
        "authors": [
            "Firas Al Rekabi",
            "Asim El Sheikh"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In simulation, Median Polish Kriging is a technique used to predict\nunobserved data points in two-dimensional space. The linear behavior of the\ntraditional Median Polish Kriging in the estimation of the mean function in a\nhigh grid makes the interpolation of O(1) which has a low order in the\nprediction and that leads to a high prediction error. Therefore, an improvement\nin the estimation of the mean function has been introduced using Biharmonic\nspline interpolation and the new technique has been called Improved Median\nPolish Kriging (IMPK). The IMPK has been applied to the standard coal-ash data\nin two-dimension. The novel method gave much better results according to the\ncross validation results that were obtained when compared with the traditional\nMedian Polish Kriging.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.8172v1"
    },
    {
        "title": "Sistem Informasi Penjualan Dan Perbaikan Komputer (Studi Kasus: CV\n  Computer Plus Palembang)",
        "authors": [
            " Syaprina",
            "Leon Andretti Abdillah",
            "Nyimas Sopiah"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The purpose of this research is to develop an Information System of Selling\nand Services using Microsoft Visual Basic and Microsoft Access for it database.\nThe benefits of this research is to help CV Computer Plus in selling and\nservices data processing everyday. To develop this IS is used 5 (five) steps:\n1) Planning, 2) Analysis, 3) Design, 4) Implementation, and 5) Evaluation. The\nInformation System can record the selling and services data, it also prepared\nusefull reports. By using this IS, CV Computer Plus can operate their selling\nand services efficiency and effectively. In the future it can be upgraded for\nnetwork application.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.8191v1"
    },
    {
        "title": "Development of Wearable Systems for Ubiquitous Healthcare Service\n  Provisioning",
        "authors": [
            "O. O. Ogunduyile",
            "O. O. Olugbara",
            "M. Lall"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper reports on the development of a wearable system using wireless\nbiomedical sensors for ubiquitous healthcare service provisioning. The\nprototype system is developed to address current healthcare challenges such as\nincreasing cost of services, inability to access diverse services, low quality\nservices and increasing population of elderly as experienced globally. The\nbiomedical sensors proactively collect physiological data of remote patients to\nrecommend diagnostic services. The prototype system is designed to monitor\noxygen saturation level (SpO2), Heart Rate (HR), activity and location of the\nelderly. Physiological data collected are uploaded to a Health Server (HS) via\nGPRS/Internet for analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.0158v1"
    },
    {
        "title": "The UK-DALE dataset, domestic appliance-level electricity demand and\n  whole-house demand from five UK homes",
        "authors": [
            "Jack Kelly",
            "William Knottenbelt"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Many countries are rolling out smart electricity meters. These measure a\nhome's total power demand. However, research into consumer behaviour suggests\nthat consumers are best able to improve their energy efficiency when provided\nwith itemised, appliance-by-appliance consumption information. Energy\ndisaggregation is a computational technique for estimating\nappliance-by-appliance energy consumption from a whole-house meter signal.\n  To conduct research on disaggregation algorithms, researchers require data\ndescribing not just the aggregate demand per building but also the `ground\ntruth' demand of individual appliances. In this context, we present UK-DALE: an\nopen-access dataset from the UK recording Domestic Appliance-Level Electricity\nat a sample rate of 16 kHz for the whole-house and at 1/6 Hz for individual\nappliances. This is the first open access UK dataset at this temporal\nresolution. We recorded from five houses, one of which was recorded for 655\ndays, the longest duration we are aware of for any energy dataset at this\nsample rate. We also describe the low-cost, open-source, wireless system we\nbuilt for collecting our dataset.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.0284v3"
    },
    {
        "title": "Design of Reversible Counter",
        "authors": [
            "Md. Selim Al Mamun",
            "B. K. Karmaker"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This article presents a research work on the design and synthesis of\nsequential circuits and flip-flops that are available in digital arena; and\ndescribes a new synthesis design of reversible counter that is optimized in\nterms of quantum cost, delay and garbage outputs compared to the existing\ndesigns. We proposed a new model of reversible T flip-flop in designing\nreversible counter\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1271v1"
    },
    {
        "title": "Steerable Antennas for Automotive Communication Systems",
        "authors": [
            "Ardavan Rahimian"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This research project undertakes a comprehensive analysis of RF beamforming\ntechniques for design, simulation, fabrication, and measurement of Butler\nMatrix and Rotman Lens beamforming networks. It is aimed to develop novel and\nwell-established designs for steerable antenna systems that can be used in\nvehicular telematics and automotive communication systems based on microwave\nand millimeter-wave techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1286v1"
    },
    {
        "title": "Visual and Predictive Analytics on Singapore News: Experiments on GDELT,\n  Wikipedia, and ^STI",
        "authors": [
            "Clifton Phua",
            "Yuzhang Feng",
            "Junyao Ji",
            "Timothy Soh"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The open-source Global Database of Events, Language, and Tone (GDELT) is the\nmost comprehensive and updated Big Data source of important terms extracted\nfrom international news articles . We focus only on GDELT's Singapore events to\nbetter understand the data quality of its news articles, accuracy of its term\nextraction, and potential for prediction. To test news completeness and\nvalidity, we visually compared GDELT (Singapore news articles' terms from 1979\nto 2013) to Wikipedia's timeline of Singaporean history. To test term\nextraction accuracy, we visually compared GDELT (CAMEO codes and TABARI system\nof extraction from Singapore news articles' text from April to December 2013)\nto SAS Text Miner's term and topic extraction. To perform predictive analytics,\nwe propose a novel feature engineering method to transform row-level GDELT from\narticles to a user-specified temporal resolution. For example, we apply a\ndecision tree using daily counts of feature values from GDELT to predict\nSingapore stock market's Straits Times Index (^STI). Of practical interest from\nthe above results is SAS Visual Analytics' ability to highlight the various\nimpacts of June 2013 Southeast Asian haze and December 2013 Little India riot\non Singapore. Although Singapore is unique as a sovereign city-state, a leading\nfinancial centre, has strong international influence, and consists of a highly\nmulti-cultural population, the visual and predictive analytics reported here\nare highly applicable to another country's GDELT data.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.1996v1"
    },
    {
        "title": "Apple IOS Devices for Network Administrators",
        "authors": [
            "Timur Mirzoev",
            "Gerard Gingo",
            "Mike Stawchansky",
            "Tracy White"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  As tablet devices continue to gain market share at the expense of the\ntraditional PC, they become a more integral part of the corporate landscape.\nTablets are no longer being utilized only by sales executives for presentation\npurposes, or as addition to the traditional laptop. Users are attempting to\nperform significant amounts of their daily work on tablet devices, some even\nabandoning the ubiquitous laptop or desktop entirely. Operating exclusively\nfrom a tablet device, specifically Apple IOS tablet devices creates unique\nchallenges in a corporate environment traditionally dominated by Microsoft\nWindows operating systems. Interactions with file shares, presentation media,\nVPN, and remote access present barriers that users and helpdesk support are\nunfamiliar with in a relation to an iPad or iPhone. Many solutions are being\noffered to these challenges some of which are analyzed by this manuscript.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.2153v1"
    },
    {
        "title": "Teaching Network Storage Technology Assessment Outcomes and Directions",
        "authors": [
            "Dr. V. Jovanovic",
            "Dr. Timur Mirzoev"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The paper presents academic content, delivery and assessment mechanisms used,\navailable resources including initial lessons from teaching Networked Storage\nTechnology as a special topics course to students enrolled in two specific\nprograms - IT and CS. The course is based on the EMC s vendor-neutral Storage\nTechnology Fundamentals course. Furthermore, this manuscript provides a\ndetailed review of how the course fits into our curriculum, particularly, how\nit helps achieving the 2008 ABET assessment requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.2346v1"
    },
    {
        "title": "Automation Security",
        "authors": [
            "Dr. Timur Mirzoev"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Web-based Automated Process Control systems are a new type of applications\nthat use the Internet to control industrial processes with the access to the\nreal-time data. Supervisory control and data acquisition (SCADA) networks\ncontain computers and applications that perform key functions in providing\nessential services and commodities (e.g., electricity, natural gas, gasoline,\nwater, waste treatment, transportation) to all Americans. As such, they are\npart of the nation s critical infrastructure and require protection from a\nvariety of threats that exist in cyber space today.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.2347v1"
    },
    {
        "title": "Energy and Latency Aware Application Mapping Algorithm & Optimization\n  for Homogeneous 3D Network on Chip",
        "authors": [
            "Vaibhav Jha",
            "Sunny Deol",
            "Mohit Jha",
            "GK Sharma"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Energy efficiency is one of the most critical issue in design of System on\nChip. In Network On Chip (NoC) based system, energy consumption is influenced\ndramatically by mapping of Intellectual Property (IP) which affect the\nperformance of the system. In this paper we test the antecedently extant\nproposed algorithms and introduced a new energy proficient algorithm stand for\n3D NoC architecture. In addition a hybrid method has also been implemented\nusing bioinspired optimization (particle swarm optimization) technique. The\nproposed algorithm has been implemented and evaluated on randomly generated\nbenchmark and real life application such as MMS, Telecom and VOPD. The\nalgorithm has also been tested with the E3S benchmark and has been compared\nwith the existing algorithm (spiral and crinkle) and has shown better reduction\nin the communication energy consumption and shows improvement in the\nperformance of the system. Comparing our work with spiral and crinkle,\nexperimental result shows that the average reduction in communication energy\nconsumption is 19% with spiral and 17% with crinkle mapping algorithms, while\nreduction in communication cost is 24% and 21% whereas reduction in latency is\nof 24% and 22% with spiral and crinkle. Optimizing our work and the existing\nmethods using bio-inspired technique and having the comparison among them an\naverage energy reduction is found to be of 18% and 24%.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.2512v1"
    },
    {
        "title": "Substrate integrated waveguide power divider, circulator and coupler in\n  [10-15] GHz band",
        "authors": [
            "Bouchra Rahali Mohammed Feham"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The Substrate Integrated Waveguide (SIW) technology is an attractive approach\nfor the design of high performance microwave and millimeter wave components, as\nit combines the advantages of planar technology, such as low fabrication costs,\nwith the low loss inherent to the waveguide solution. In this study, a\nsubstrate integrated waveguide power divider, circulator and coupler are\nconceived and optimized in [10-15] GHz band by Ansoft HFSS code. Thus, results\nof this modeling are presented, discussed and allow to integrate these devices\nin planar circuits.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.2888v1"
    },
    {
        "title": "Elevation Contour Analysis and Water body Extraction for Finding Water\n  Scarcity Locations using DEM",
        "authors": [
            "B. G. Kodge",
            "P. S. Hiremath"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The present study was aimed to create new methods for extraction and analysis\nof land elevation contour lines, automatic extraction of water bodies (river\nbasins and lakes), from the digital elevation models (DEM) of a test area. And\nextraction of villages which are fell under critical water scarcity regions for\nagriculture and drinking water with respect to their elevation data and\navailable natural water resources.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3002v2"
    },
    {
        "title": "Computer Simulation Codes for the Quine-McCluskey Method of Logic\n  Minimization",
        "authors": [
            "Sourangsu Banerji"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The Quine-McCluskey method is useful in minimizing logic expressions for\nlarger number of variables when compared with minimization by Karnaugh Map or\nBoolean algebra. In this paper, we have tried to put together all of the\ncomputer codes which are available on the internet, edited and modified them as\nwell as rewritten some parts of those collected codes our self, which are used\nin the implementation of the Quine- McCluskey method. A brief introduction and\nthe logic of this method are discussed following which the codes have been\nprovided. The Quine-McCluskey Method has been implemented using computer\nlanguages like C and C++ using some amount of variations. Our effort is to list\nthem all, so that the readers well versed in any of the particular computer\nlanguage will find it easy to follow the code written in that particular\nlanguage.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.3349v2"
    },
    {
        "title": "Invisibility System Using Image Processing and Optical Camouflage\n  Technology",
        "authors": [
            "Vasireddy Srikanth",
            "Pillem Ramesh"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Invisible persons are seen in fiction stories only, but in the real world it\nis proved that invisibility is possible. This paper describes the creation of\ninvisibility with the help of technologies like Optical camouflage; Image based\nrendering and Retro reflective projection. The object that needs to be made\ntransparent or invisible is painted or covered with retro reflective material.\nThen a projector projects the background image on it making the masking object\nvirtually transparent. Capturing the background image requires a video camera,\nwhich sits behind the person wearing the cloak. The video from the camera must\nbe in a digital format so it can be sent to a computer for image processing\nusing image based rendering technical. There are some useful applications for\nthis simple but astonishing technology.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4107v1"
    },
    {
        "title": "Big Data: Overview",
        "authors": [
            "Richa Gupta",
            "Sunny Gupta",
            "Anuradha Singhal"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Big data is data that exceeds the processing capacity of traditional\ndatabases. The data is too big to be processed by a single machine. New and\ninnovative methods are required to process and store such large volumes of\ndata. This paper provides an overview on big data, its importance in our live\nand some technologies to handle big data.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4136v1"
    },
    {
        "title": "Web Mining using Artificial Ant Colonies: A Survey",
        "authors": [
            "Richa Gupta"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Web mining has been very crucial to any organization as it provides useful\ninsights to business patterns. It helps the company to understand its customers\nbetter. As the web is growing in pace, so is its importance and hence it\nbecomes all the more necessary to find useful patterns. Here in this paper, web\nmining using ant colony optimization has been reviewed with some of its\nexperimental results.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4139v1"
    },
    {
        "title": "Journey from Data Mining to Web Mining to Big Data",
        "authors": [
            "Richa Gupta"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper describes the journey of big data starting from data mining to web\nmining to big data. It discusses each of this method in brief and also provides\ntheir applications. It states the importance of mining big data today using\nfast and novel approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4140v1"
    },
    {
        "title": "Trust Evaluation using an Improved Context Similarity Measurement",
        "authors": [
            "Mohsen Raeesi",
            "Mohammad Amin Morid",
            "Mehdi Shajari"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In context-aware trust evaluation, using ontology tree is a popular approach\nto represent the relation between contexts. Usually, similarity between two\ncontexts is computed using these trees. Therefore, the performance of trust\nevaluation highly depends on the quality of ontology trees. Fairness or\ngranularity consistency is one of the major limitations affecting the quality\nof ontology tree. This limitation refers to inequality of semantic similarity\nin the most ontology trees. In other words, semantic similarity of every two\nadjacent nodes is unequal in these trees. It deteriorates the performance of\ncontexts similarity computation. We overcome this limitation by weighting tree\nedges based on their semantic similarity. Weight of each edge is computed using\nNormalized Similarity Score (NSS) method. This method is based on frequencies\nof concepts (words) co-occurrences in the pages indexed by search engines. Our\nexperiments represent the better performance of the proposed approach in\ncomparison with established trust evaluation approaches. The suggested approach\ncan enhance efficiency of any solution which models semantic relations by\nontology tree.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.4592v1"
    },
    {
        "title": "Training-Free Non-Intrusive Load Monitoring of Electric Vehicle Charging\n  with Low Sampling Rate",
        "authors": [
            "Zhilin Zhang",
            "Jae Hyun Son",
            "Ying Li",
            "Mark Trayer",
            "Zhouyue Pi",
            "Dong Yoon Hwang",
            "Joong Ki Moon"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Non-intrusive load monitoring (NILM) is an important topic in smart-grid and\nsmart-home. Many energy disaggregation algorithms have been proposed to detect\nvarious individual appliances from one aggregated signal observation. However,\nfew works studied the energy disaggregation of plug-in electric vehicle (EV)\ncharging in the residential environment since EVs charging at home has emerged\nonly recently. Recent studies showed that EV charging has a large impact on\nsmart-grid especially in summer. Therefore, EV charging monitoring has become a\nmore important and urgent missing piece in energy disaggregation. In this\npaper, we present a novel method to disaggregate EV charging signals from\naggregated real power signals. The proposed method can effectively mitigate\ninterference coming from air-conditioner (AC), enabling accurate EV charging\ndetection and energy estimation under the presence of AC power signals.\nBesides, the proposed algorithm requires no training, demands a light\ncomputational load, delivers high estimation accuracy, and works well for data\nrecorded at the low sampling rate 1/60 Hz. When the algorithm is tested on\nreal-world data recorded from 11 houses over about a whole year (total 125\nmonths worth of data), the averaged error in estimating energy consumption of\nEV charging is 15.7 kwh/month (while the true averaged energy consumption of EV\ncharging is 208.5 kwh/month), and the averaged normalized mean square error in\ndisaggregating EV charging load signals is 0.19.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.5020v2"
    },
    {
        "title": "Design of a Low Voltage Class-AB CMOS Super Buffer Amplifier with Sub\n  Threshold and Leakage Control",
        "authors": [
            "Rakesh Gupta"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper describes a CMOS analogy voltage supper buffer designed to have\nextremely low static current Consumption as well as high current drive\ncapability. A new technique is used to reduce the leakage power of class-AB\nCMOS buffer circuits without affecting dynamic power dissipation. The name of\napplied technique is TRANSISTOR GATING TECHNIQUE, which gives the high speed\nbuffer with the reduced low power dissipation (1.105%), low leakage and reduced\narea (3.08%) also. The proposed buffer is simulated at 45nm CMOS technology and\nthe circuit is operated at 3.3V supply[11]. Consumption is comparable to the\nswitching component. Reports indicate that 40% or even higher percentage of the\ntotal power consumption is due to the leakage of transistors. This percentage\nwill increase with technology scaling unless effective techniques are\nintroduced to bring leakage under control. This article focuses on circuit\noptimization and Design automation techniques to accomplish this goal [9].\n",
        "pdf_link": "http://arxiv.org/pdf/1404.6034v1"
    },
    {
        "title": "Design and considerations of ADC0808 as interleaved ADCs",
        "authors": [
            "Rajiv Kumar",
            "Rakesh Gupta"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Here in this paper we are presenting a digital system background technique\nfor correcting the time offset error rate and gain mismatches in a time\ninterleaved analog to digital converter system for N channel communication\nusing 8 bit ADC0808 ICs. A time interleaved A to D converter system is an\neffective way to implement a high sampling rate ADC with relatively slow\ncircuits. This paper analyses the benefits and derives an upper band on the\nperformance by considering kT/C noise and slewing requirement of the circuit\ndriving the system. In the system, several channel ADCs operate at interleaved\nsampling times as if they were effectively a single ADC operating at a much\nhigher sampling rate. A timing mismatch calibration technique is proposed that\ncovers linear and non linear channel mismatches, unifies, and extends the\nchannel models. A novel foreground channel mismatch identification method has\nbeen developed, which can be used to fully characterize dynamic linear\nmismatches. A background identification method provides accurate timing\nmismatch estimates.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.6040v1"
    },
    {
        "title": "Big Spectrum Data: The New Resource for Cognitive Wireless Networking",
        "authors": [
            "Guoru Ding",
            "Qihui Wu",
            "Jinlong Wang",
            "Yu-Dong Yao"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The era of Big Data is here now, which has brought both unprecedented\nopportunities and critical challenges. In this article, from a perspective of\ncognitive wireless networking, we start with a definition of Big Spectrum Data\nby analyzing its characteristics in terms of six Vs, i.e., volume, variety,\nvelocity, veracity, viability, and value. We then present a high-level tutorial\non research frontiers in Big Spectrum Data analytics to guide the development\nof practical algorithms. We also highlight Big Spectrum Data as the new\nresource for cognitive wireless networking by presenting the emerging use\ncases.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.6508v1"
    },
    {
        "title": "Data Driven Energy Efficiency in Buildings",
        "authors": [
            "Nipun Batra",
            "Amarjeet Singh",
            "Pushpendra Singh",
            "Haimonti Dutta",
            "Venkatesh Sarangan",
            "Mani Srivastava"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Buildings across the world contribute significantly to the overall energy\nconsumption and are thus stakeholders in grid operations. Towards the\ndevelopment of a smart grid, utilities and governments across the world are\nencouraging smart meter deployments. High resolution (often at every 15\nminutes) data from these smart meters can be used to understand and optimize\nenergy consumptions in buildings. In addition to smart meters, buildings are\nalso increasingly managed with Building Management Systems (BMS) which control\ndifferent sub-systems such as lighting and heating, ventilation, and air\nconditioning (HVAC). With the advent of these smart meters, increased usage of\nBMS and easy availability and widespread installation of ambient sensors, there\nis a deluge of building energy data. This data has been leveraged for a variety\nof applications such as demand response, appliance fault detection and\noptimizing HVAC schedules. Beyond the traditional use of such data sets, they\ncan be put to effective use towards making buildings smarter and hence driving\nevery possible bit of energy efficiency. Effective use of this data entails\nseveral critical areas from sensing to decision making and participatory\ninvolvement of occupants. Picking from wide literature in building energy\nefficiency, we identify five crust areas (also referred to as 5 Is) for\nrealizing data driven energy efficiency in buildings : i) instrument optimally;\nii) interconnect sub-systems; iii) inferred decision making; iv) involve\noccupants and v) intelligent operations. We classify prior work as per these 5\nIs and dis-cuss challenges, opportunities and applications across them.\nBuilding upon these 5 Is we discuss a well studied problem in building energy\nefficiency -non-intrusive load monitoring (NILM) and how research in this area\nspans across the 5 Is.\n",
        "pdf_link": "http://arxiv.org/pdf/1404.7227v3"
    },
    {
        "title": "Manufacturing Pathway and Experimental Demonstration for Nanoscale\n  Fine-Grained 3-D Integrated Circuit Fabric",
        "authors": [
            "Mostafizur Rahman",
            "Jiajun Shi",
            "Mingyu Li",
            "Santosh Khasanvis",
            "Csaba Andras Moritz"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  At sub-20nm technologies CMOS scaling faces severe challenges primarily due\nto fundamental device scaling limitations, interconnection overhead and complex\nmanufacturing. Migration to 3D has been long sought as a possible pathway to\ncontinue scaling, however, intrinsic requirements of CMOS are not compatible\nfor fine-grained 3D integration. We proposed a truly fine-grained 3D integrated\ncircuit fabric called Skybridge that solves nanoscale challenges and achieves\norders of magnitude benefits over CMOS. In Skybridge, device, circuit,\nconnectivity, thermal management and manufacturing issues are addressed in an\nintegrated 3D compatible manner. At the core of Skybridge assembly are uniform\nvertical nanowires, which are functionalized with architected features for\nfabric integration. All active components are created primarily using\nsequential material deposition steps on these nanowires. Lithography and doping\nare performed prior to any functionalization and their precision requirements\nare significantly reduced. This paper introduces Skybridge manufacturing\npathway that is developed based on extensive process, device simulations and\nexperimental metrology, and uses established processes. Experimental\ndemonstrations of key process steps are also shown.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.00286v1"
    },
    {
        "title": "Sensitivity Analysis of Resonant Circuits",
        "authors": [
            "Olivier Buu"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  We use first-order perturbation theory to provide a local linear relation\nbetween the circuit parameters and the poles of an RLC network. The sensitivity\nmatrix, which defines this relationship, is obtained from the systems\neigenvectors and the derivative of its eigenvalues. In general, the sensitivity\nmatrix is related to the equilibrium fluctuations of the system. In particular,\nit may be used as the basis for a statistical model to efficiently predict the\nsensitivity of the circuit response to small component variations. The method\nis illustrated with a calculation of conditional probabilities by Monte Carlo\nSimulation.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.00632v1"
    },
    {
        "title": "Low Power Wideband Sensing for One-Bit Quantized Cognitive Radio Systems",
        "authors": [
            "Abdelmohsen Ali",
            "Walaa Hamouda"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  We proposes an ultra low power wideband spectrum sensing architecture by\nutilizing a one-bit quantization at the cognitive radio (CR) receiver. The\nimpact of this aggressive quantization is quantified and it is shown that the\nproposed method is robust to low signal-to-noise ratios (SNR). We derive\nclosed-form expressions for both false alarm and detection probabilities. The\nsensing performance and the analytical results are assessed through comparisons\nwith respective results from computer simulations. The results indicate that\nthe proposed method provides significant saving in power, complexity, and\nsensing period on the account of an acceptable range of performance\ndegradation.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.01753v1"
    },
    {
        "title": "A few reflections on the quality of emergence in complex collective\n  systems",
        "authors": [
            "Vincenzo De Florio"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  A number of elements towards a classification of the quality of emergence in\nemergent collective systems are provided. By using those elements, several\nclasses of emergent systems are exemplified, ranging from simple aggregations\nof simple parts up to complex organizations of complex collective systems. In\nso doing, the factors likely to play a a significant role in the persistence of\nemergence and its opposite are highlighted. From this, new elements for\ndiscussion are identified also considering elements from the System of Leibniz.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.01821v2"
    },
    {
        "title": "Review on the Design of Web Based SCADA Systems Based on OPC DA Protocol",
        "authors": [
            "Hosny A. Abbas",
            "Ahmed M. Mohamed"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  One of the most familiar SCADA (supervisory control and data acquisition)\napplication protocols now is OPC protocol. This interface is supported by\nalmost all SCADA, visualization, and process control systems. There are many\nresearch efforts tried to design and implement an approach to access an OPC DA\nserver through the Internet. To achieve this goal they used diverse of modern\nIT technologies like XML, Web services, Java and AJAX. In this paper, we\npresent a complete classification of the different approaches introduced in the\nliterature. A comparative study is also introduced. Finally we study the\nfeasibility of the realization of these approaches based on the real time\nconstraints imposed by the nature of the problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.05069v1"
    },
    {
        "title": "The Quasi cellular nets-based models of transport and logistic systems",
        "authors": [
            "Anton Aristov"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  There are many systems in different subjects such as industry, medicine,\ntransport, social and others, can be discribed on their dynamic of flows.\nNowadays models of flows consist of micro- and macro-models. In practice there\nis a problem of convertation from different levels of simulation. In the\ndifferent articles author descriptes quasi cellular nets. Quasi cellular nets\nare new type of discrete structures without signature. It may be used for\nsimulation instruments. This structures can simulate flows on micro- and macro\nlevels on the single model structure. In this article described using quasi\ncellular nets in transport and logistics of open-cast mining.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.00312v1"
    },
    {
        "title": "Computation of Transition Adjacency Relations Based on Complete Prefix\n  Unfolding (Technical Report)",
        "authors": [
            "Jisheng Pei",
            "Lijie Wen",
            "Akhil Kumar",
            "Xiaojun Ye"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  An increasing number of works have devoted to the application of Transition\nAdjacency Relation (TAR) as a means to capture behavioral features of business\nprocess models. In this paper, we systematically study the efficient TAR\nderivation from process models using unfolding technique which previously has\nbeen used to address the state space explosion when dealing with concurrent\nbehaviors of a Petri net. We reveal and formally describe the equivalence\nbetween TAR and Event Adjacency Relation (EAR), the manifestation of TAR in the\nComplete Prefix Unfolding (CPU) of a Petri net. By computing TARs from CPU\nusing this equivalence, we can alleviate the concurrency caused state-explosion\nissues. Furthermore, structural boosting rules are categorized, proved and\nadded to the TAR computing algorithm. Formal proofs of correctness and\ngenerality of CPU-based TAR computation are provided for the first time by this\nwork, and they significantly expand the range of Petri nets from which TARs can\nbe efficiently derived. Experiments on both industrial and synthesized process\nmodels show the effectiveness of proposed CPU-based algorithms as well as the\nobservation that they scale well with the increase in size and concurrency of\nbusiness process models.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.00428v6"
    },
    {
        "title": "Introduction of the Residue Number Arithmetic Logic Unit With Brief\n  Computational Complexity Analysis",
        "authors": [
            "Eric B. Olsen"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Digital System Research has pioneered the mathematics and design for a new\nclass of computing machine using residue numbers. Unlike prior art, the new\nbreakthrough provides methods and apparatus for general purpose computation\nusing several new residue based fractional representations. The result is that\nfractional arithmetic may be performed without carry. Additionally, fractional\noperations such as addition, subtraction and multiplication of a fraction by an\ninteger occur in a single clock period, regardless of word size. Fractional\nmultiplication is of the order O(p), where p equals the number of residues.\nMore significantly, complex operations, such as sum of products, may be\nperformed in an extended format, where fractional products are performed and\nsummed using single clock instructions, regardless of word width, and where a\nnormalization operation with an execution time of the order O(p) is performed\nas a final step.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.00911v1"
    },
    {
        "title": "Emerging Cloud Computing Security Threats",
        "authors": [
            "Kamal Ahmat"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Cloud computing is one of the latest emerging innovations of the modern\ninternet and technological landscape. With everyone from the White house to\nmajor online technological leaders like Amazon and Google using or offering\ncloud computing services it is truly presents itself as an exciting and\ninnovative method to store and use data on the internet.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.01701v1"
    },
    {
        "title": "Motion model transitions in GPS-IMU sensor fusion for user tracking in\n  augmented reality",
        "authors": [
            "Erkan Bostanci"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Finding the position of the user is an important processing step for\naugmented reality (AR) applications. This paper investigates the use of\ndifferent motion models in order to choose the most suitable one, and\neventually reduce the Kalman filter errors in sensor fusion for such\napplications where the accuracy of user tracking is crucial. A Deterministic\nFinite Automaton (DFA) was employed using the innovation parameters of the\nfilter. Results show that the approach presented here reduces the filter error\ncompared to a static model and prevents filter divergence. The approach was\ntested on a simple AR game in order to justify the accuracy and performance of\nthe algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.02758v1"
    },
    {
        "title": "Web application for size and topology optimization of trusses and gusset\n  plates",
        "authors": [
            "Shankarjee Krishnamoorthi",
            "Gaurav Srivastava",
            "Amar Mandhyan"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  With its ever growing popularity, providing Internet based applications tuned\ntowards practical applications is on the rise. Advantages such as no external\nplugins and additional software, ease of use, updating and maintenance have\nincreased the popularity of web applications. In this work, a web-based\napplication has been developed which can perform size optimization of truss\nstructure as a whole as well as topology optimization of individual gusset\nplate of each joint based on specified joint displacements and load conditions.\nThis application is developed using cutting-edge web technologies such as\nThree.js and HTML5. The client side boasts of an intuitive interface which in\naddition to its modeling capabilities also recommends configurations based on\nuser input, provides analysis options and finally displays the results. The\nserver side, using a combination of Scilab and DAKOTA, computes solution and\nalso provides the user with comparisons of the optimal design with that\nconforming to Indian Standard (IS 800-2007). It is a freely available one-stop\nweb-based application to perform optimal and/or code based design of trusses.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.02881v1"
    },
    {
        "title": "Simulation and Analysis of Container Freight Train Operations at Port\n  Botany",
        "authors": [
            "Daniel Guimarans",
            "Daniel Harabor",
            "Pascal van Hentenryck"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Over two million containers crossed the docks at Sydney's Port Botany in\n2011/12; a figure that is forecast increase more than threefold by the end of\nthe next decade. To cope with such large growth in volumes the NSW Government\nplans to double rail mode share at the port by the year 2020. Conventional\nwisdom from industry and the media says that existing infrastructure cannot\nhandle such volumes. In this paper we use a combination of data analytics and\nsimulation to examine operations at the port and evaluate the efficacy of\ncurrent infrastructure to handle projected growth in volumes. Contrary to\nconventional wisdom we find that current rail resources appear distinctly\nunder-utilised. Moreover: (i) the peak rail capacity of Port Botany is 1.78\nmillion TEU per annum; over six times higher than 2011/12 rail volumes; (ii)\nthere are no infrastructural impediments to the achievement of peak rail\ncapacity; (iii) operational changes, not infrastructural investment, are the\nkey to unlocking the potential of the port; (iv) Port Botany is well positioned\nto handle projected increases in container volumes over the next decade and\nbeyond, including the 28% rail mode share target established by the New South\nWales State Government.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.03476v2"
    },
    {
        "title": "Finding Needles in a Haystack: Missing Tag Detection in Large RFID\n  Systems",
        "authors": [
            "Jihong Yu",
            "Lin Chen",
            "Kehao Wang"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Radio frequency identification (RFID) technology has been widely used in\nmissing tag detection to reduce and avoid inventory shrinkage. In this\napplication, promptly finding out the missing event is of paramount importance.\nHowever, existing missing tag detection protocols cannot efficiently handle the\npresence of a large number of unexpected tags whose IDs are not known to the\nreader, which shackles the time efficiency. To deal with the problem of\ndetecting missing tags in the presence of unexpected tags, this paper\nintroduces a two-phase Bloom filter-based missing tag detection protocol\n(BMTD). The proposed BMTD exploits Bloom filter in sequence to first deactivate\nthe unexpected tags and then test the membership of the expected tags, thus\ndampening the interference from the unexpected tags and considerably reducing\nthe detection time. Moreover, the theoretical analysis of the protocol\nparameters is performed to minimize the detection time of the proposed BMTD and\nachieve the required reliability simultaneously. Extensive experiments are then\nconducted to evaluate the performance of the proposed BMTD. The results\ndemonstrate that the proposed BMTD significantly outperforms the\nstate-of-the-art solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.05228v1"
    },
    {
        "title": "Two improved normalized subband adaptive filter algorithms with good\n  robustness against impulsive interferences",
        "authors": [
            "Yi Yu",
            "Haiquan Zhao",
            "Badong Chen",
            "Zhengyou He"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  To improve the robustness of subband adaptive filter (SAF) against impulsive\ninterferences, we propose two modified SAF algorithms with an individual scale\nfunction for each subband, which are derived by maximizing correntropy-based\ncost function and minimizing logarithm-based cost function, respectively,\ncalled MCC-SAF and LC-SAF. Whenever the impulsive interference happens, the\nsubband scale functions can sharply drop the step size, which eliminate the\ninfluence of outliers on the tap-weight vector update. Therefore, the proposed\nalgorithms are robust against impulsive interferences, and exhibit the faster\nconvergence rate and better tracking capability than the sign SAF (SSAF)\nalgorithm. Besides, in impulse-free interference environments, the proposed\nalgorithms achieve similar convergence performance as the normalized SAF (NSAF)\nalgorithm. Simulation results have demonstrated the performance of our proposed\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.05338v2"
    },
    {
        "title": "On A Testing and Implementation of Quantum Gate and Measurement Emulator\n  (QGAME)",
        "authors": [
            "A. B. Mutiara",
            "R. Refianti",
            "J. S. K. Karamoy"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Today, people are looking forward to get an awesome computational power. This\nkind of desire can be answered by quantum computing. By adopting quantum\nmechanics theory, it can generate a very fast computation result. As known,\nquantum mechanics can establish that particle can also become wave; it shows\nthat electron can be in duality. Through this theory, even a human\nteleportation is issued can be really happened in the future. However, it needs\na high requirement of hardware support to implement the real quantum computing.\nThat is why it is difficult to bring quantum computing into reality. This\nresearch presents a study about quantum computing. Here it is studied, a\nspecialty of quantum computing, like superposition, as if the classical\ncomputer can do it. Since there was a marvellous research about quantum\ncomputer simulation that runs on classical computer, this research provides an\nanalysis about our testing and implementation of Quantum Gate and Measurement\nEmulator (QGAME). Our analysis, testing and implementation are based on a\nmethod that always use in the software engineering field.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.05499v1"
    },
    {
        "title": "Energy Consumption Forecasting for Smart Meters",
        "authors": [
            "Anshul Bansal",
            "Susheel Kaushik Rompikuntla",
            "Jaganadh Gopinadhan",
            "Amanpreet Kaur",
            "Zahoor Ahamed Kazi"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Earth, water, air, food, shelter and energy are essential factors required\nfor human being to survive on the planet. Among this energy plays a key role in\nour day to day living including giving lighting, cooling and heating of\nshelter, preparation of food. Due to this interdependency, energy, specifically\nelectricity, production and distribution became a high tech industry. Unlike\nother industries, the key differentiator of electricity industry is the product\nitself. It can be produced but cannot be stored for future; production and\nconsumption happen almost in near real-time. This particular peculiarity of the\nindustry is the key driver for Machine Learning and Data Science based\ninnovations in this industry. There is always a gap between the demand and\nsupply in the electricity market across the globe. To fill the gap and improve\nthe service efficiency through providing necessary supply to the market,\ncommercial as well as federal electricity companies employ forecasting\ntechniques to predict the future demand and try to meet the demand and provide\ncurtailment guidelines to optimise the electricity consumption/demand. In this\npaper the authors examine the application of Machine Learning algorithms,\nspecifically Boosted Decision Tree Regression, to the modelling and forecasting\nof energy consumption for smart meters. The data used for this exercise is\nobtained from DECC data website. Along with this data, the methodology has been\ntested in Smart Meter data obtained from EMA Singapore. This paper focuses on\nfeature engineering for time series forecasting using regression algorithms and\nderiving a methodology to create personalised electricity plans offers for\nhousehold users based on usage history.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.05979v1"
    },
    {
        "title": "Cloud Computation and Google Earth Visualization of Heat/Cold Waves: A\n  Nonanticipative Long-Range Forecasting Case Study",
        "authors": [
            "Dmytro Zubov"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Long-range forecasting of heat/cold waves is a topical issue nowadays. High\ncomputational complexity of the design of numerical and statistical models is a\nbottleneck for the forecast process. In this work, Windows Server 2012 R2\nvirtual machines are used as a high-performance tool for the speed-up of the\ncomputational process. Six D-series and one standard tier A-series virtual\nmachines were hosted in Microsoft Azure public cloud for this purpose.\nVisualization of the forecasted data is based on the Google Earth Pro virtual\nglobe in ASP.NET web-site against http://gearth.azurewebsites.net (prototype),\nwhere KMZ file represents geographic placemarks. The long-range predictions of\nthe heat/cold waves are computed for several specifically located places based\non nonanticipative analog algorithm. The arguments of forecast models are\ndatasets from around the world, which reflects the concept of teleconnections.\nThis methodology does not require the probability distribution to design the\nforecast models and/or calculate the predictions. Heat weaves at Annaba\n(Algeria) are discussed in detail. Up to 36.4% of heat waves are specifically\npredicted. Up to 33.3% of cold waves are specifically predicted for other four\nlocations around the world. The proposed approach is 100% accurate if the signs\nof predicted and actual values are compared according to climatological\nbaseline. These high-accuracy predictions were achieved due to the\ninterdisciplinary approach, but advanced computer science techniques, public\ncloud computing and Google Earth Pro virtual globe mainly, form the major part\nof the work.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.06017v1"
    },
    {
        "title": "A Novel Approach to Compress Centralized Text Data using Indexed\n  Dictionary",
        "authors": [
            "Vivek Dimri",
            "Prof. Ranjit Biswas"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Data compression is very important feature in terms of saving the memory\nspace. In this proposal, an indexed dictionary based compression is used for\ntext data, where the word's reference in dictionary is used for compression.\nThis approach is not file based, a common dictionary is used for compression.\nWhich contains the words, the position of the word in dictionary is one of the\nkey parts of encoded frame which is compressed form of the text word. This is\nloss-less compression. This compression approach is also take cares of small\nwords like one or two characters words which usually decrease the efficiency of\ncompression algorithms. This approach is also deals with file having special\ncharacters as a word. Special character words, alpha numeric words, normal\ntexted words and small words all deals differently which makes this approach\nmore efficient. Since a centralized dictionary is used for data compression,\ntherefore, this approach is not preferred for transfer compressed file, while\nit is suitable to store text data in compressed form in hard disk drive and\ncentralized storage or cloud drive for memory utilization.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.07153v1"
    },
    {
        "title": "Design of portable power consumption measuring system for green\n  computing needs",
        "authors": [
            "Kamil Rzepka",
            "Przemysaw Skurowski",
            "Baej Adamczyk",
            "Adam Pilniak"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The article presents the design of a digital power measurement device\nintended for the green IT. Article comprises: use case analysis, accuracy and\nprecision measurements and real life test of apache web server as exemplary\napplication.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.08201v1"
    },
    {
        "title": "ePlace-3D: Electrostatics based Placement for 3D-ICs",
        "authors": [
            "Jingwei Lu",
            "Hao Zhuang",
            "Ilgweon Kang",
            "Pengwen Chen",
            "Chung-Kuan Cheng"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  We propose a flat, analytic, mixed-size placement algorithm ePlace-3D for\nthree-dimension integrated circuits (3D-ICs) using nonlinear optimization. Our\ncontributions are (1) electrostatics based 3D density function with globally\nuniform smoothness (2) 3D numerical solution with improved spectral formulation\n(3) 3D nonlinear pre-conditioner for convergence acceleration (4) interleaved\n2D-3D placement for efficiency enhancement. Our placer outperforms the leading\nwork mPL6-3D and NTUplace3-3D with 6.44% and 37.15% shorter wirelength, 9.11%\nand 10.27% fewer 3D vertical interconnects (VI) on average of IBM-PLACE\ncircuits. Validation on the large-scale modern mixed-size (MMS) 3D circuits\nshows high performance and scalability.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.08291v5"
    },
    {
        "title": "Picturing Indefinite Causal Structure",
        "authors": [
            "Aleks Kissinger",
            "Sander Uijlen"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Following on from the notion of (first-order) causality, which generalises\nthe notion of being tracepreserving from CP-maps to abstract processes, we give\na characterization for the most general kind of map which sends causal\nprocesses to causal processes. These new, second-order causal processes enable\nus to treat the input processes as 'local laboratories' whose causal ordering\nneeds not be fixed in advance. Using this characterization, we give a\nfully-diagrammatic proof of a non-trivial theorem: namely that being\ncausality-preserving on separable processes implies being 'completely'\ncausality preserving. That is, causality is preserved even when the 'local\nlaboratories' are allowed to have ancilla systems. An immediate consequence is\nthat preserving causality is separable processes is equivalence to preserving\ncausality for strongly non-signalling (a.k.a. localizable) processes.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.00659v1"
    },
    {
        "title": "SOI RF Switch for Wireless Sensor Network",
        "authors": [
            "Wei Cai",
            "Cheng Li",
            "ShiWei Luan"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The objective of this research was to design a 0-5 GHz RF SOI switch, with\n0.18um power Jazz SOI technology by using Cadence software, for health care\napplications. This paper introduces the design of a RF switch implemented in\nshunt-series topology. An insertion loss of 0.906 dB and an isolation of 30.95\ndB were obtained at 5 GHz. The switch also achieved a third order distortion of\n53.05 dBm and 1 dB compression point reached 50.06dBm. The RF switch\nperformance meets the desired specification requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.01763v1"
    },
    {
        "title": "Low Power SI Class E Power Amplifier and RF Switch For Health Care",
        "authors": [
            "Wei Cai",
            "Jian Xu",
            "Liang Huang"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This research was to design a 2.4 GHz class E Power Amplifier (PA) for health\ncare, with 0.18um Semiconductor Manufacturing International Corporation CMOS\ntechnology by using Cadence software. And also RF switch was designed at\ncadence software with power Jazz 180nm SOI process. The ultimate goal for such\napplication is to reach high performance and low cost, and between high\nperformance and low power consumption design. This paper introduces the design\nof a 2.4GHz class E power amplifier and RF switch design. PA consists of\ncascade stage with negative capacitance. This power amplifier can transmit\n16dBm output power to a 50{\\Omega} load. The performance of the power amplifier\nand switch meet the specification requirements of the desired.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.01771v1"
    },
    {
        "title": "Taxi-based Emergency Medical System",
        "authors": [
            "Li-Yi Lin"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In case of a severe accident, the key to saving lives is the time between the\nincident and when the victim receives treatment from the first-responders. In\nareas with well designed emergency medical systems, the time for an ambulance\nto arrive at the accident location is often not too long. However, in many low\nand middle income countries, it usually takes much longer for an ambulance to\narrive at the accident location due to lack of proper services. On the other\nhand, with ubiquitous wireless connectivity, and emergence of radio based\ntaxis, it seems feasible to build a low-cost emergency response system based on\ntaxi service. In this report, we explore one such solution for deployment of a\ntaxi-based emergency response systems using reinforcement learning.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.04126v1"
    },
    {
        "title": "Stay-point Identification as Curve Extrema",
        "authors": [
            "Georgios Stylianou"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In a nutshell, stay-points are locations that a person has stopped for some\namount of time. Previous work depends mainly on stay-point identification\nmethods using experimentally fine tuned threshold values. These behave well on\ntheir experimental datasets but may exhibit reduced performance on other\ndatasets.\n  In this work, we demonstrate the potential of a geometry-based method for\nstay-point extraction. This is accomplished by transforming the user's\ntrajectory path to a two-dimensional discrete time series curve that in turn\ntransforms the stay-points to the local minima of the first derivative of this\ncurve.\n  To demonstrate the soundness of the proposed method, we evaluated it on raw,\nnoisy trajectory data acquired over the period of 28 different days using four\ndifferent techniques. The results demonstrate, among others, that given a good\ntrajectory tracking technique, we can identify correctly 86% to 98% of the\nstay-points.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.06276v1"
    },
    {
        "title": "Validation of Internal Meters of Mobile Android Devices",
        "authors": [
            "Mahmoud A. Bokhari",
            "Yuanzhong Xia",
            "Bo Zhou",
            "Brad Alexander",
            "Markus Wagner"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In this paper we outline our results for validating the precision of the\ninternal power meters of smart-phones under different workloads. We compare its\nresults with an external power meter. This is the first step towards creating\ncustomized energy models on the fly and towards optimizing battery efficiency\nusing genetic program improvements. Our experimental results indicate that the\ninternal meters are sufficiently precise when large enough time windows are\nconsidered.\n  This is part of our work on the \"dreaming smart-phone\". For a technical\ndemonstration please watch our videos\nhttps://www.youtube.com/watch?v=xeeFz2GLFdU and\nhttps://www.youtube.com/watch?v=C7WHoLW1KYw.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.07095v1"
    },
    {
        "title": "An Introduction to Classic DEVS",
        "authors": [
            "Yentl Van Tendeloo",
            "Hans Vangheluwe"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  DEVS is a popular formalism for modelling complex dynamic systems using a\ndiscrete-event abstraction. At this abstraction level, a timed sequence\nofpertinent \"events\" input to a system (or internal, in the case of timeouts)\ncause instantaneous changes to the state of the system. Between events, the\nstate does not change, resulting in a a piecewise constant state trajectory.\nMain advantages of DEVS are its rigorous formal definition, and its support for\nmodular composition.\n  This chapter introduces the Classic DEVS formalism in a bottom-up fashion,\nusing a simple traffic light example. The syntax and operational semantics of\nAtomic (i.e., non-hierarchical) models are intruced first. The semantics of\nCoupled (hierarchical) models is then given by translation into Atomic DEVS\nmodels. As this formal \"flattening\" is not efficient, a modular abstract\nsimulator which operates directly on the coupled model is also presented. This\nis the common basis for subsequent efficient implementations. We continue to\nactual applications of DEVS modelling and simulation, as seen in performance\nanalysis for queueing systems. Finally, we present some of the shortcomings in\nthe Classic DEVS formalism, and show solutions to them in the form of variants\nof the original formalism.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.07697v5"
    },
    {
        "title": "Persistent Entropy for Separating Topological Features from Noise in\n  Vietoris-Rips Complexes",
        "authors": [
            "Nieves Atienza",
            "Rocio Gonzalez-Diaz",
            "Matteo Rucco"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Persistent homology studies the evolution of k-dimensional holes along a\nnested sequence of simplicial complexes (called a filtration). The set of bars\n(i.e. intervals) representing birth and death times of k-dimensional holes\nalong such sequence is called the persistence barcode. k-Dimensional holes with\nshort lifetimes are informally considered to be \"topological noise\", and those\nwith long lifetimes are considered to be \"topological features\" associated to\nthe filtration. Persistent entropy is defined as the Shannon entropy of the\npersistence barcode of a given filtration. In this paper we present new\nimportant properties of persistent entropy of Cech and Vietoris-Rips\nfiltrations. Among the properties, we put a focus on the stability theorem that\nallows to use persistent entropy for comparing persistence barcodes. Later, we\nderive a simple method for separating topological noise from features in\nVietoris-Rips filtrations.\n",
        "pdf_link": "http://arxiv.org/pdf/1701.07857v1"
    },
    {
        "title": "Quantitative Characterization of Components of Computer Assisted\n  Interventions",
        "authors": [
            "Asli Okur",
            "Ralf Stauder",
            "Hubertus Feussner",
            "Nassir Navab"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Purpose: We propose a mathematical framework for quantitative analysis\nweighting the impact of heterogeneous components of a surgery. While\nmulti-level approaches, surgical process modeling and other workflow analysis\nmethods exist, this is to our knowledge the first quantitative approach.\nMethods: Inspired by the group decision making problem from the field of\noperational research, we define event impact factors, which combine independent\nand very diverse low-level functions. This allows us to rate surgical events by\ntheir importance. Results: We conducted surveys with 4 surgeons to determine\nthe importance of roles, phases and their combinations within a laparoscopic\ncholecystectomy. Applying this data on a recorded surgery, we showed that it is\npossible to define a quantitative measure for deciding on acception or\nrejection of calls to different roles and at different phases of surgery.\nConclusions: This methodology allows us to use components such as expertise and\nrole of the surgical staff and other aspects of a given surgery in order to\nquantitatively analyze and evaluate events, actions, user interfaces or\nprocedures.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.00582v1"
    },
    {
        "title": "Sensitivity Analysis of Expensive Black-Box Systems Using Metamodeling",
        "authors": [
            "Tom Van Steenkiste",
            "Joachim van der Herten",
            "Ivo Couckuyt",
            "Tom Dhaene"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Simulations are becoming ever more common as a tool for designing complex\nproducts. Sensitivity analysis techniques can be applied to these simulations\nto gain insight, or to reduce the complexity of the problem at hand. However,\nthese simulators are often expensive to evaluate and sensitivity analysis\ntypically requires a large amount of evaluations. Metamodeling has been\nsuccessfully applied in the past to reduce the amount of required evaluations\nfor design tasks such as optimization and design space exploration. In this\npaper, we propose a novel sensitivity analysis algorithm for variance and\nderivative based indices using sequential sampling and metamodeling. Several\nstopping criteria are proposed and investigated to keep the total number of\nevaluations minimal. The results show that both variance and derivative based\ntechniques can be accurately computed with a minimal amount of evaluations\nusing fast metamodels and FLOLA-Voronoi or density sequential sampling\nalgorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.00650v1"
    },
    {
        "title": "Evaluation of Trace Alignment Quality and its Application in Medical\n  Process Mining",
        "authors": [
            "Moliang Zhou",
            "Sen Yang",
            "Shuyu Lv",
            "Xinyu Li",
            "Shuhong Chen",
            "Ivan Marsic",
            "Richard Farneth",
            "Randall Burd"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Trace alignment algorithms have been used in process mining for discovering\nthe consensus treatment procedures and process deviations. Different alignment\nalgorithms, however, may produce very different results. No widely-adopted\nmethod exists for evaluating the results of trace alignment. Existing\nreference-free evaluation methods cannot adequately and comprehensively assess\nthe alignment quality. We analyzed and compared the existing evaluation\nmethods, identifying their limitations, and introduced improvements in two\nreference-free evaluation methods. Our approach assesses the alignment result\nglobally instead of locally, and therefore helps the algorithm to optimize\noverall alignment quality. We also introduced a novel metric to measure the\nalignment complexity, which can be used as a constraint on alignment algorithm\noptimization. We tested our evaluation methods on a trauma resuscitation\ndataset and provided the medical explanation of the activities and patterns\nidentified as deviations using our proposed evaluation methods.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.04719v4"
    },
    {
        "title": "Kharita: Robust Map Inference using Graph Spanners",
        "authors": [
            "Rade Stanojevic",
            "Sofiane Abbar",
            "Saravanan Thirumuruganathan",
            "Sanjay Chawla",
            "Fethi Filali",
            "Ahid Aleimat"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The widespread availability of GPS information in everyday devices such as\ncars, smartphones and smart watches make it possible to collect large amount of\ngeospatial trajectory information. A particularly important, yet technically\nchallenging, application of this data is to identify the underlying road\nnetwork and keep it updated under various changes. In this paper, we propose\nefficient algorithms that can generate accurate maps in both batch and online\nsettings. Our algorithms utilize techniques from graph spanners so that they\nproduce maps can effectively handle a wide variety of road and intersection\nshapes. We conduct a rigorous evaluation of our algorithms over two real-world\ndatasets and under a wide variety of performance metrics. Our experiments show\na significant improvement over prior work. In particular, we observe an\nincrease in Biagioni f-score of up to 20% when compared to the state of the art\nwhile reducing the execution time by an order of magnitude. We also make our\nsource code open source for reproducibility and enable other researchers to\nbuild on our work.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.06025v1"
    },
    {
        "title": "Correct Convergence of Min-Sum Loopy Belief Propagation in a Block\n  Interpolation Problem",
        "authors": [
            "Yutong Wang",
            "Matthew G. Reyes",
            "David L. Neuhoff"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This work proves a new result on the correct convergence of Min-Sum Loopy\nBelief Propagation (LBP) in an interpolation problem on a square grid graph.\nThe focus is on the notion of local solutions, a numerical quantity attached to\neach site of the graph that can be used for obtaining MAP estimates. The main\nresult is that over an $N\\times N$ grid graph with a one-run boundary\nconfiguration, the local solutions at each $i \\in B$ can be calculated using\nMin-Sum LBP by passing difference messages in $2N$ iterations, which parallels\nthe well-known convergence time in trees.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.06391v1"
    },
    {
        "title": "Characterizing Classes of Potential Outliers through Traffic Data Set\n  Data Signature 2D nMDS Projection",
        "authors": [
            "Erlo Robert F. Oquendo",
            "Jhoirene B. Clemente",
            "Jasmine A. Malinao",
            "Henry N. Adorna"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This paper presents a formal method for characterizing the potential outliers\nfrom the data signature projection of traffic data set using Non-Metric\nMultidimensional Scaling (nMDS) visualization. Previous work had only relied on\nvisual inspection and the subjective nature of this technique may derive false\nand invalid potential outliers. The identification of correct potential\noutliers had already been an open problem proposed in literature. This is due\nto the fact that they pinpoint areas and time frames where traffic\nincidents/accidents occur along the North Luzon Expressway (NLEX) in Luzon. In\nthis paper, potential outliers are classified into (1) absolute potential\noutliers; (2) valid potential outliers; and (3) ambiguous potential outliers\nthrough the use of confidence bands and confidence ellipse. A method is also\ndescribed to validate cluster membership of identified ambiguous potential\noutliers. Using the 2006 NLEX Balintawak Northbound (BLK-NB) data set, we were\nable to identify two absolute potential outliers, nine valid potential\noutliers, and five ambiguous potential outliers. In a literature where Vector\nFusion was used, 10 potential outliers were identified. Given the results for\nthe nMDS visualization using the confidence bands and confidence ellipses, all\nof these 10 potential outliers were also found and 8 new potential outliers\nwere also found.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07501v1"
    },
    {
        "title": "Insense: Incoherent Sensor Selection for Sparse Signals",
        "authors": [
            "Amirali Aghazadeh",
            "Mohammad Golbabaee",
            "Andrew S. Lan",
            "Richard G. Baraniuk"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Sensor selection refers to the problem of intelligently selecting a small\nsubset of a collection of available sensors to reduce the sensing cost while\npreserving signal acquisition performance. The majority of sensor selection\nalgorithms find the subset of sensors that best recovers an arbitrary signal\nfrom a number of linear measurements that is larger than the dimension of the\nsignal. In this paper, we develop a new sensor selection algorithm for sparse\n(or near sparse) signals that finds a subset of sensors that best recovers such\nsignals from a number of measurements that is much smaller than the dimension\nof the signal. Existing sensor selection algorithms cannot be applied in such\nsituations. Our proposed Incoherent Sensor Selection (Insense) algorithm\nminimizes a coherence-based cost function that is adapted from recent results\nin sparse recovery theory. Using six datasets, including two real-world\ndatasets on microbial diagnostics and structural health monitoring, we\ndemonstrate the superior performance of Insense for sparse-signal sensor\nselection.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07670v1"
    },
    {
        "title": "Modulation and Multiple Access for 5G Networks",
        "authors": [
            "Yunlong Cai",
            "Zhijin Qin",
            "Fangyu Cui",
            "Geoffrey Ye Li",
            "Julie A. McCann"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Fifth generation (5G) wireless networks face various challenges in order to\nsupport large-scale heterogeneous traffic and users, therefore new modulation\nand multiple access (MA) schemes are being developed to meet the changing\ndemands. As this research space is ever increasing, it becomes more important\nto analyze the various approaches, therefore in this article we present a\ncomprehensive overview of the most promising modulation and MA schemes for 5G\nnetworks. We first introduce the different types of modulation that indicate\ntheir potential for orthogonal multiple access (OMA) schemes and compare their\nperformance in terms of spectral efficiency, out-of-band leakage, and bit-error\nrate. We then pay close attention to various types of non-orthogonal multiple\naccess (NOMA) candidates, including power-domain NOMA, code-domain NOMA, and\nNOMA multiplexing in multiple domains. From this exploration we can identify\nthe opportunities and challenges that will have significant impact on the\ndesign of modulation and MA for 5G networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07673v1"
    },
    {
        "title": "Building up user confidence for the spaceborne derived global and\n  continental land cover products for the Mediterranean region: the case of\n  Thessaly",
        "authors": [
            "Ioannis Manakos",
            "Christina Karakizi",
            "Giannis Gkinis",
            "Konstantinos Karantzalos"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Across globe and space agencies nations recognize the importance of\nhomogenized land cover information, prone to regular updates, both in the\ncontext of thematic and spatial resolutions. Recent sensor advances and the\nfree distribution policy promote the utilization of spaceborne products in an\nunprecedented pace into an increasingly wider range of applications. Ensuring\ncredibility to the users is a major enabler in this process. To this end this\nstudy contributes with a systematic accuracy performance measurement and\ncontinental/global land cover layers' inter-comparison moving towards\nconfidence built up. Confidence levels during validation and a weighted overall\naccuracy assessment were applied. Google Earth imagery was employed to assess\nthe accuracy of three land cover products, i.e., Globeland30, HRLs and CLC\n2012, for the years 2010 and 2012. Reported rates indicate a minimum weighted\noverall accuracy of 84%. Specific classes' performance deviations from the\ngeneral trend were noted and discussed on the basis of an unbiased sampling\napproach. By integrating confidence levels during the ground truth annotation,\nstratified sampling on the several Corine Level 3 subclasses and the weighted\noverall accuracy assessment, the different aspects of the considered land cover\nproducts can be highlighted more objectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.07890v1"
    },
    {
        "title": "Preventing Hospital Acquired Infections Through a Workflow-Based\n  Cyber-Physical System",
        "authors": [
            "Maria Iuliana Bocicor",
            "Arthur-Jozsef Molnar",
            "Cristian Taslitchi"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Hospital acquired infections (HAI) are infections acquired within the\nhospital from healthcare workers, patients or from the environment, but which\nhave no connection to the initial reason for the patient's hospital admission.\nHAI are a serious world-wide problem, leading to an increase in mortality\nrates, duration of hospitalisation as well as significant economic burden on\nhospitals. Although clear preventive guidelines exist, studies show that\ncompliance to them is frequently poor. This paper details the software\nperspective for an innovative, business process software based cyber-physical\nsystem that will be implemented as part of a European Union-funded research\nproject. The system is composed of a network of sensors mounted in different\nsites around the hospital, a series of wearables used by the healthcare workers\nand a server side workflow engine. For better understanding, we describe the\nsystem through the lens of a single, simple clinical workflow that is\nresponsible for a significant portion of all hospital infections. The goal is\nthat when completed, the system will be configurable in the sense of\nfacilitating the creation and automated monitoring of those clinical workflows\nthat when combined, account for over 90\\% of hospital infections.\n",
        "pdf_link": "http://arxiv.org/pdf/1702.08010v1"
    },
    {
        "title": "Hotspot-aware DSA Grouping and Mask Assignment",
        "authors": [
            "Yasmine Badr",
            "Puneet Gupta"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In Directed Self Assembly (DSA), poor printing of guiding templates can cause\nmisassembly resulting in high defect probability. Therefore, hotspots should be\navoided in the choice of the DSA groups. Accordingly, Directed Self-Assembly\n(DSA) technologies which use Multiple Patterning (MP) to print the guiding\ntemplates need to be aware of hotspots during the DSA grouping and MP\nDecomposition. In this paper, we present a hotspot-aware heuristic for DSA\ngrouping and MP decomposition. Results show that that the proposed heuristic\neliminates 78% of the hotspots and conflicts that result from using a\nhotspot-unaware grouping and decomposition algorithm. In comparison to the\noptimal solution using Integer Linear Programming, the proposed heuristic\nresults in ~24% more violations.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.02921v1"
    },
    {
        "title": "Adapting Engineering Education to Industrie 4.0 Vision",
        "authors": [
            "Selim Coskun",
            "Yasanur Kayikci",
            "Eray Gencay"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Industrie 4.0 is originally a future vision described in the high-tech\nstrategy of the German government that is conceived upon the information and\ncommunication technologies like Cyber-Physical Systems, Internet of Things,\nPhysical Internet and Internet of Services to achieve a high degree of\nflexibility in production, higher productivity rates through real-time\nmonitoring and diagnosis, and a lower wastage rate of material in production.\nAn important part of the tasks in the preparation for Industrie 4.0 is the\nadaption of the higher education to the requirements of this vision, in\nparticular the engineering education. In this work, we introduce a road map\nconsisting of three pillars describing the changes/enhancements to be conducted\nin the areas of curriculum development, lab concept, and student club\nactivities. We also report our current application of this road map at the\nTurkish-German University, Istanbul.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.08806v1"
    },
    {
        "title": "Do two parties represent the US? Clustering analysis of US public\n  ideology survey",
        "authors": [
            "Louisa Lee",
            "Siyu Zhang",
            "Vicky Chuqiao Yang"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Recent surveys have shown that an increasing portion of the US public\nbelieves the two major US parties adequately represent the US public opinion\nand think additional parties are needed. However, there are high barriers for\nthird parties in political elections. In this paper, we aim to address two\nquestions: \"How well do the two major US parties represent the public's\nideology?\" and \"Does a more-than-two-party system better represent the ideology\nof the public?\". To address these questions, we utilize the American National\nElection Studies Time series dataset. We perform unsupervised clustering with\nGaussian Mixture Model method on this dataset. When clustered into two\nclusters, we find a large centrist cluster and a small right-wing cluster. The\nDemocratic Party's position (estimated using the mean position of the\nindividuals self-identified with the parties) is similar to that of the\ncentrist cluster, and the Republican Party's position is between the two\nclusters. We investigate if more than two parties represent the population\nbetter by comparing the Akaike Information Criteria for clustering results of\nthe various number of clusters. We find that additional clusters give a better\nrepresentation of the data, even after penalizing for the additional\nparameters. This suggests a multiparty system represents of the ideology of the\npublic better.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.09347v2"
    },
    {
        "title": "Assessment of Urban Ecological Service value used in Urban Rail Transit\n  Project",
        "authors": [
            "Yijie Li",
            "Jing Chen"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Ecosystem services refer to the ones human beings often obtain from the\nnatural environment ecosystem. In order to solve the problem of environmental\ndegradation, based on the Integrated Valuation of Ecosystem Services and\nTrade-offs (InVEST model), this paper makes innovation by adding the urban\nmodule that was not in the previous models, which can better deal with the\nevaluation of ecosystem services in urban scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.06572v1"
    },
    {
        "title": "Inverse reinforcement learning conditioned on brain scan",
        "authors": [
            "Tofara Moyo"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  We outline a way for an agent to learn the dispositions of a particular\nindividual through inverse reinforcement learning where the state space at time\nt includes an fMRI scan of the individual, to represent his brain state at that\ntime. The fundamental assumption being that the information shown on an fMRI\nscan of an individual is conditioned on his thoughts and thought processes. The\nsystem models both long and short term memory as well any internal dynamics we\nmay not be aware of that are in the human brain. The human expert will put on a\nsuit for a set duration with sensors whose information will be used to train a\npolicy network, while a generative model will be trained to produce the next\nfMRI scan image conditioned on the present one and the state of the\nenvironment. During operation the humanoid robots actions will be conditioned\non this evolving fMRI and the environment it is in.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.09770v1"
    },
    {
        "title": "Characterizing IoT Data and its Quality for Use",
        "authors": [
            "Nashez Zubair",
            "Niranjan A",
            "Kiran Hebbar",
            "Yogesh Simmhan"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The Internet of Things (IoT) is a cyber physical social system that\nencompasses science, enterprise and societal domains. Data is the most\nimportant commodity in IoT, enabling the \"smarts\" through analytics and\ndecision making. IoT environments can generate and consume vast amounts of\ndata. But managing this data effectively and gaining meaningful insights from\nit requires us to understand its characteristics. Traditional scientific,\nenterprise and big data management approaches may not be adequate, and have to\nevolve. Further, these characteristics and the physical deployment environments\nalso impact the quality of the data for use. In this paper, we offer a taxonomy\nof IoT data characteristics, along with data quality considerations, that are\nconstructed from the ground-up based on the diverse IoT domains and\napplications we review. We emphasize on the essential features, rather than a\nvast array of attributes. We also indicate factors that influence the data\nquality. Such a review is of value to IoT managers, data handlers and\napplication composers in managing and making meaningful use of data, and for\nbig data platform developers to offer meaningful solutions to address these\nconsiderations.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.10497v1"
    },
    {
        "title": "Wise Data: A Novel Approach in Data Science from a Network Science\n  Perspective",
        "authors": [
            "Mike Raeini"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Human beings have been generating data since very long times ago. We ask the\nfollowing common-sense and wise questions (WizQuestions):\n  1. Why do we refer to some pieces of data more often than referring to other\npieces? 2. What does make those commonly-referred pieces of data so unique and\ndifferent? 3. What are the characteristics of data that sometimes make the data\nso unique and different?\n  In this article, we introduce a novel approach (model) that helps us answer\nthese questions from data science and network science perspectives. WizWordily\nspeaking, our proposed approach enables us to model the data (as a network),\nmeasure the quality of data, and study the network of data deeply and\nthoroughly.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.10686v2"
    },
    {
        "title": "Algorithmic measurement procedures",
        "authors": [
            "Aldo F. G. Solis-Labastida",
            "Jorge G. Hirsch"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Measurements are shown to be processes designed to return figures: they are\neffective. This effectivity allows for a formalization as Turing machines,\nwhich can be described employing computation theory. Inspired in the halting\nproblem we draw some limitations for measurement procedures: procedures that\nverify if a quantity is measured cannot work in every case.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.11028v1"
    },
    {
        "title": "JXES: JSON Support for the XES Event Log Standard",
        "authors": [
            "Madhavi Bangalore Shankara Narayana",
            "Hossameldin Khalifa",
            "Wil van der Aalst"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Process mining assumes the existence of an event log where each event refers\nto a case, an activity, and a point in time. XES is an XML based IEEE approved\nstandard format for event logs supported by most of the process mining tools.\nJSON (JavaScript Object Notation) is a lightweight data interchange format. In\nthis paper, we present JXES, the JSON standard for the event logs and also\nprovide implementation in ProM for importing and exporting event logs in JSON\nformat using 4 different parsers. The evaluation results show notable\nperformance differences between the different parsers (Simple JSON, Jackson,\nGSON, Jsoninter).\n",
        "pdf_link": "http://arxiv.org/pdf/2009.06363v1"
    },
    {
        "title": "GUI Based Automatic Remote Control of Gas Reduction System using PIC\n  Microcontroller",
        "authors": [
            "Ayad Ghany Ismaeel",
            "Raghad Zuhair Yousif",
            "Essa F. Abdallh"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The GRS is a one of the important units in Erbil Power Station EPS, which is\nresponsible on controlling gas pressure and gas temperature this unit\npreviously works manually. The local control panel for GRS system contains two\ntypes of digital signals the first one indicated by Light Emitting Diodes LED\nto point normal operations, fault and alarm, and event of operations while the\nsecond indicated by ON-OFF switches, which consists of two types the push\nbuttons switch and mode selector switch. To overcome human in manual control\nfaults in controlling GRS systems, automation system becomes the best solution.\nThe purpose of this research is to design and implement embedded automation\nsystem that can be used to control a GRS automatically through a GUI and from\nremote location by using programmable interface controller (PIC16F877A). In\nthis research the (PIC) software which is based on (C language), developed by\nMicrochip (MPLAB) is used in programming a PIC microcontroller, then Visual\nBasic is used in the construction of GUI, the RS-232 serial cable is used as a\nconnector between PIC and PC. Implement the proposed design and test it as a\nfirst system shows all operations of GRS successful were converted into full\ncomputerize controlling (with the ability of full automatic control) from\nremote location through proposed GUI. Keywords-Peripheral Interface Controller\n(PIC); Microcontroller; Graphical User Interface (GUI); Remote; Control.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.0668v1"
    },
    {
        "title": "BiEntropy - The Approximate Entropy of a Finite Binary String",
        "authors": [
            "Grenville J. Croll"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We design, implement and test a simple algorithm which computes the\napproximate entropy of a finite binary string of arbitrary length. The\nalgorithm uses a weighted average of the Shannon Entropies of the string and\nall but the last binary derivative of the string. We successfully test the\nalgorithm in the fields of Prime Number Theory (where we prove explicitly that\nthe sequence of prime numbers is not periodic), Human Vision, Cryptography,\nRandom Number Generation and Quantitative Finance.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.0954v2"
    },
    {
        "title": "Augmented Reality in ICT for Minimum Knowledge Loss",
        "authors": [
            "RamKumar Lakshminarayanan",
            "RD. Balaji",
            "Binod kumar",
            "Malathi Balaji"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Informatics world digitizes the human beings, with the contribution made by\nall the industrial people. In the recent survey it is proved that people are\nnot accustomed or they are not able to access the electronic devices to its\nextreme usage. Also people are more dependent to the technologies and their\nday-to-day activities are ruled by the same. In this paper we discuss on one of\nthe advanced technology which will soon rule the world and make the people are\nmore creative and at the same time hassle-free. This concept is introduced as\n6th sense technology by an IIT, Mumbai student who is presently Ph.D., scholar\nin MIT, USA. Similar to this research there is one more research going on under\nthe title Augmented Reality. This research makes a new association with the\nreal world to digital world and allows us to share and manipulate the\ninformation directly with our mental thoughts. A college which implements state\nof the art technology for teaching and learning, Higher College of Technology,\nMuscat, (HCT) tries to identify the opportunities and limitations of\nimplementing this augmented reality for teaching and learning. The research\nteam of HCT, here, tries to give two scenarios in which augmented reality can\nfit in. Since this research is in the conceptual level we are trying to\nillustrate the history of this technology and how it can be adopted in the\nteaching environment\n",
        "pdf_link": "http://arxiv.org/pdf/1305.2500v1"
    },
    {
        "title": "Field Programmable DSP Arrays - A Novel Reconfigurable Architecture for\n  Efficient Realization of Digital Signal Processing Functions",
        "authors": [
            "Amitabha Sinha",
            "Soumojit Acharyya",
            "Suranjan Chakraborty",
            "Mitrava Sarkar"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Digital Signal Processing functions are widely used in real time high speed\napplications. Those functions are generally implemented either on ASICs with\ninflexibility, or on FPGAs with bottlenecks of relatively smaller utilization\nfactor or lower speed compared to ASIC. The proposed reconfigurable DSP\nprocessor is redolent to FPGA, but with basic fixed Common Modules (CMs) (like\nadders, subtractors, multipliers, scaling units, shifters) instead of CLBs.\nThis paper introduces the development of a reconfigurable DSP processor that\nintegrates different filter and transform functions. The switching between DSP\nfunctions is occurred by reconfiguring the interconnection between CMs.\nValidation of the proposed reconfigurable architecture has been achieved on\nVirtex5 FPGA. The architecture provides sufficient amount of flexibility,\nparallelism and scalability.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.3251v1"
    },
    {
        "title": "An UHF RFID Energy-Harvesting System Enhanced by a DC-DC Charge Pump in\n  Silicon-on-Insulator Technology",
        "authors": [
            "D. De Donno",
            "L. Catarinucci",
            "L. Tarricone"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  An RF-DC converter enhanced by a DC-DC voltage booster in\nsilicon-on-insulator technology for UHF radio frequency identification (RFID)\nenergy harvesting is presented in this letter. When the received RF power level\nis -14 dBm or higher, the system, fabricated on an FR4 substrate using\noff-the-shelf low-cost discrete components and connected to a flexible dipole\nantenna, is able to produce 2.4-V DC voltage to power general-purpose\nelectronic devices. As a simple proof of concept,a device comprising\nmicrocontroller, temperature sensor, and EEPROM is considered in this work. The\nexperimental results demonstrate the capability of the system to autonomously\nperform temperature data logging up to a distance of 5 m from a conventional\nUHF RFID reader used as an RF energy source.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.4731v2"
    },
    {
        "title": "Enabling Self-Powered Autonomous Wireless Sensors with New-Generation\n  I2C-RFID Chips",
        "authors": [
            "D. De Donno",
            "L. Catarinucci",
            "L. Tarricone"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  A self-powered autonomous RFID device with sensing and computing capabilities\nis presented in this paper. Powered by an RF energy-harvesting circuit enhanced\nby a DC-DC voltage booster in silicon-on-insulator (SOI) technology, the device\nrelies on a microcontroller and a new generation I2C-RFID chip to wirelessly\ndeliver sensor data to standard RFID EPC Class-1 Generation-2 (Gen2) readers.\nWhen the RF power received from the interrogating reader is -14 dBm or higher,\nthe device, fabricated on an FR4 substrate using low-cost discrete components,\nis able to produce 2.4-V DC voltage to power its circuitry. The experimental\nresults demonstrate the effectiveness of the device to perform reliable sensor\ndata transmissions up to 5 meters in fully-passive mode. To the best of our\nknowledge, this represents the longest read range ever reported for passive UHF\nRFID sensors compliant with the EPC Gen2 standard.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.4732v1"
    },
    {
        "title": "Comparative Study of ERP Implementation Methodology Case Study:\n  Accelerated SAP VS Dantes & Hasibuan Methodology",
        "authors": [
            "M. Hilman",
            "F. Setiadi",
            "I. Sarika",
            "J. Budiasto",
            "R. Alfian"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Enterprise Resource Planning (ERP) system is a concept of enterprise system\nthat describe the integration of the whole process in the organization. Study\nin this field mostly about external development paradigm on information system\ndevelopment. So, issue in ERP is all about how to adopt it in the organization,\nnot about the application development. This paper reviews two methodologies on\nERP system implementation, one is vendor perspective methodology and new\ngeneric perspective methodology. Comparation of both methodology is done in\nthis study using certain metric measurements. Result is the vendor perspective\nslightly superior than new generic perspective methodology.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.6010v2"
    },
    {
        "title": "Information System as a Service: Issues and Challenges",
        "authors": [
            "Muhammad Hilman"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Information system evolved as the evolution of information technology. The\ncurrent state of information technology, placed the internet as a main\nresources of computing. Cloud technology as the backbone of internet has been\nutilized as a powerful computing resources. Therefore, cloud introduced new\nterm of service oriented technology, popular with \"as a service\" kind of name.\nIn this paper, the service oriented paradigm will be used to address future\ntrend of information system. Thus, this paper try to introduce the term\n\"information system as a service\", holistic view of infrastructure as a\nservice, platform as a service, software as a service, and data as a service.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.6011v2"
    },
    {
        "title": "Calculation of geometric characteristics of land cover and urban canyon\n  for multi-scale parameterization of megalopolis meteorological models",
        "authors": [
            "Timofey E. Samsonov",
            "Vladimir N. Semin",
            "Pavel I. Konstantinov",
            "Mikhail I. Varentzov"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The results of studies on the development of computational techniques for\ngeometric and thematic characteristics of the underlying surface and urban\ncanyon are presented. These characteristics are intended for parameterization\nof the local model of energy-mass exchange between the surface layer of the\natmosphere and the surface of the active layer of the underlying urban areas\n(cities). Multiscale database of parameters of the underlying surface with a\nresolution of 200, 500 and 1000 meters is obtained. The use of\nmicro-meteorology models that take into account the specificity of the urban\nenvironment, coupled with mesoscale prognostic models will significantly\nimprove the sound quality of the meteorological fields and local operational\nweather forecasting in the metropolitan areas where considering the\nhydrometeorological situation is particularly important.\n",
        "pdf_link": "http://arxiv.org/pdf/1305.6067v1"
    },
    {
        "title": "Overview of Spintronic Sensors, Internet of Things, and Smart Living",
        "authors": [
            "X. Liu",
            "K. H. Lam",
            "K. Zhu",
            "C. Zheng",
            "X. Li",
            "Y. Du",
            "Chunhua Liu",
            "P. W. T. Pong"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Smart living is a trending lifestyle that envisions lower energy consumption,\nsound public services, and better quality of life for human being. The Internet\nof Things (IoT) is a compelling platform connecting various sensors around us\nto the Internet, providing great opportunities for the realization of smart\nliving. Spintronic sensors with superb measuring ability and multiple unique\nadvantages can be an important piece of cornerstone for IoT. In this review, we\ndiscuss successful applications of spintronic sensors in electrical current\nsensing, transmission and distribution lines monitoring, vehicle detection, and\nbiodetection. Traditional monitoring systems with limited sensors and wired\ncommunication can merely collect fragmented data in the application domains. In\nthis paper, the wireless spintronic sensor networks (WSSNs) will be proposed\nand illustrated to provide pervasive monitoring systems, which facilitate the\nintelligent surveillance and management over building, power grid, transport,\nand healthcare. The database of collected information will be of great use to\nthe policy making in public services and city planning. This work provides\ninsights for realizing smart living through the integration of IoT with\nspintronic sensor technology.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.00317v1"
    },
    {
        "title": "Enerji zleme Yazlmlar iin Merkezi ve Genel bir\n  Mimari (A Centralized and Generic Architecture for Energy Monitoring\n  Software)",
        "authors": [
            "Dilek Kk",
            "Turan Demirci"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  There is need for several software systems within the energy domain and\ncorresponding systems are being developed to satisfy these needs. These systems\ninclude energy monitoring, information, wide area monitoring and control\nsystems, and SCADA systems. Energy monitoring systems are one of the most\nimportant and common systems among them. In this study, after briefly reviewing\nseveral of the software systems within the energy domain, a centralized and\ngeneric software architecture for energy monitoring systems is presented. Next,\nsample projects are described in which energy monitoring systems based on this\narchitecture have been implemented. We envisage that this study will be an\nimportant resource for software projects in the energy domain.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.00739v1"
    },
    {
        "title": "Activity Recognition Based on Micro-Doppler Signature with In-Home Wi-Fi",
        "authors": [
            "Qingchao Chen",
            "Bo Tan",
            "Kevin Chetty",
            "Karl Woodbridge"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Device free activity recognition and monitoring has become a promising\nresearch area with increasing public interest in pattern of life monitoring and\nchronic health conditions. This paper proposes a novel framework for in-home\nWi-Fi signal-based activity recognition in e-healthcare applications using\npassive micro-Doppler (m-D) signature classification. The framework includes\nsignal modeling, Doppler extraction and m-D classification. A data collection\ncampaign was designed to verify the framework where six m-D signatures\ncorresponding to typical daily activities are sucessfully detected and\nclassified using our software defined radio (SDR) demo system. Analysis of the\ndata focussed on potential discriminative characteristics, such as maximum\nDoppler frequency and time duration of activity. Finally, a sparsity induced\nclassifier is applied for adaptting the method in healthcare application\nscenarios and the results are compared with those from the well-known Support\nVector Machine (SVM) method.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.01801v1"
    },
    {
        "title": "GSM based CommSense system to measure and estimate environmental changes",
        "authors": [
            "Abhishek Bhatta",
            "Amit Kumar Mishra"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Facilitating the coexistence of radar systems with communication systems has\nbeen a major area of research in radar engineering. The current work presents a\nnew way to sense the environment using the channel equalization block of\nexisting communication systems. We have named this system CommSense. In the\ncurrent paper we demonstrate the feasibility of the system using Global System\nfor Mobile Communications (GSM) signals. The implementation has been done using\nopen-source Software Defined Radio (SDR) environment. In the preliminary\nresults obtained in our work we show that it is possible to distinguish\nenvironmental changes using the proposed system. The major advantage of the\nsystem is that it is inexpensive as channel estimation is an inherent block in\nany communication system and hence the added cost to make it work as an\nenvironment sensor is minimal. The major challenge, on which we are continuing\nour work, is how to characterize the features in the environmental changes.\nThis is an acute challenge given the fact that the bandwidth available is\nnarrow and the system is inherently a forward looking radar. However the\ninitial results, as shown in this paper, are encouraging and we intend to use\nan application specific instrumentation (ASIN) scheme to distinguish the\nenvironmental changes.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.02659v2"
    },
    {
        "title": "Length Matters: Clustering System Log Messages using Length of Words",
        "authors": [
            "Keiichi Shima"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The analysis techniques of system log messages (syslog messages) have a long\nhistory from when the syslog mechanism was invented. Typically, the analysis\nconsists of two parts, one is a message template generation, and the other is\nfinding something interesting using the messages classified by the inferred\ntemplates. It is important to generate better templates to achieve better,\nprecise, or convincible analysis results. In this paper, we propose a\nclassification methodology using the length of words of each message. Our\nmethod is suitable for online template generation because it does not require\ntwo-pass analysis to generate template messages, that is an important factor\nconsidering increasing amount of log messages produced by a large number of\nsystem components such as cloud infrastructure.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.03213v1"
    },
    {
        "title": "On the optimality of ternary arithmetic for compactness and hardware\n  design",
        "authors": [
            "Harris V. Georgiou"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In this paper, the optimality of ternary arithmetic is investigated under\nstrict mathematical formulation. The arithmetic systems are presented in\ngeneric form, as the means to encode numeric values, and the choice of radix is\nasserted as the main parameter to assess the efficiency of the representation,\nin terms of information compactness and estimated implementation cost in\nhardware. Using proper formulations for the optimization task, the universal\nconstant 'e' (base of natural logarithms) is proven as the most efficient radix\nand ternary is asserted as the closest integer choice.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.03715v1"
    },
    {
        "title": "A Novel Approach for Learning How to Automatically Match Job Offers and\n  Candidate Profiles",
        "authors": [
            "Jorge Martinez-Gil",
            "Alejandra Lorena Paoletti",
            "Mario Pichler"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Automatic matching of job offers and job candidates is a major problem for a\nnumber of organizations and job applicants that if it were successfully\naddressed could have a positive impact in many countries around the world. In\nthis context, it is widely accepted that semi-automatic matching algorithms\nbetween job and candidate profiles would provide a vital technology for making\nthe recruitment processes faster, more accurate and transparent. In this work,\nwe present our research towards achieving a realistic matching approach for\nsatisfactorily addressing this challenge. This novel approach relies on a\nmatching learning solution aiming to learn from past solved cases in order to\naccurately predict the results in new situations. An empirical study shows us\nthat our approach is able to beat solutions with no learning capabilities by a\nwide margin.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.04931v2"
    },
    {
        "title": "COOLL: Controlled On/Off Loads Library, a Public Dataset of High-Sampled\n  Electrical Signals for Appliance Identification",
        "authors": [
            "Thomas Picon",
            "Mohamed Nait Meziane",
            "Philippe Ravier",
            "Guy Lamarque",
            "Clarisse Novello",
            "Jean-Charles Le Bunetel",
            "Yves Raingeaud"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper gives a brief description of the Controlled On/Off Loads Library\n(COOLL) dataset. This latter is a dataset of high-sampled electrical current\nand voltage measurements representing individual appliances consumption. The\nmeasurements were taken in June 2016 in the PRISME laboratory of the University\nof Orl\\'eans, France. The appliances are mainly controllable appliances (i.e.\nwe can precisely control their turn-on/off time instants). 42 appliances of 12\ntypes were measured at a 100 kHz sampling frequency.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.05803v1"
    },
    {
        "title": "Detection of Dangerous Magnetic Field Ranges from Tablets by Clustering\n  Analysis",
        "authors": [
            "Darko Brodi",
            "Alessia Amelio"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The paper considers the problem of the extremely low frequency magnetic field\nradiation generated by the tablet computers. Accordingly, the measurement of\nthe magnetic field radiation from a set of tablets is carried out. Furthermore,\nthe measurement results are analyzed and clustered according to the K-Medians\nalgorithm to obtain different magnetic field ranges. The obtained cluster\nranges are evaluated according to the reference level proposed by the TCO\nstandard in order to define dangerous areas in the neighborhood of tablet,\nwhich are established during the typical work with tablet computers. Analysis\nshows that dangerous areas correspond to specific inner components of tablet,\nand gives suggestions to users for a safe usage of tablet and to companies\nproducing tablet components for limiting the risk of magnetic field exposure.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.00443v1"
    },
    {
        "title": "DEMoS Manifesto",
        "authors": [
            "Rasmus Ulslev Pedersen"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This is a manifesto for DEMoS, which is a Distributed Embedded Modular\nSystem, but also a manifesto addressing the need for more\ninter-/cross-disciplinary mastery of working knowledge related to installing\nthis class of systems in the real world. There is somehow room for yet another\nclass of systems - complementary to existing embedded systems - complementing\ndistributed operating systems - which takes on an interdisciplinary\ncyber-physical-materiality approach, a dedicated holistic perspective that\nrecognizes the true value of interdisciplinary mastery vs. the implicit and\noverlooked expense of narrow intra-disciplinary focus dominating much of\nsystems development (e.g. EE, CE, CS, SE, and IS). Interdisciplinary mastery\nyields its accumulated value across the development, deployment, use, re-use,\nand decommission phases for this class of systems: DEMoS is a system\narchitected to be locally distributed, embedded, and modular as outlined herein\nand with the additional goals of human interdisciplinary mastery in this\ncontext: A potential set of goals for developing and applying DEMoS can be\nfound in UN Resolution 70/1.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.04191v1"
    },
    {
        "title": "Computational Intelligence: are you crazy? Since when has intelligence\n  become computational?",
        "authors": [
            "Emanuel Diamant"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Computational Intelligence is a dead-end attempt to recreate human-like\nintelligence in a computing machine. The goal is unattainable because the means\nchosen for its accomplishment are mutually inconsistent and contradictory:\n\"Computational\" implies data processing ability while \"Intelligence\" implies\nthe ability to process information. In the research community, there is a lack\nof interest in data versus information divergence. The cause of this\nindifference is the Shannon's Information theory, which has dominated the\nscientific community since the early 1950s. However, today it is clear that\nShannon's theory is applicable only to a specific case of data communication\nand is inapplicable to the majority of other occasions, where information about\nsemantic properties of a message must be taken into account. The paper will try\nto explain the devastating results of overlooking some of these very important\nissues - what is intelligence, what is semantic information, how they are\ninterrelated and what happens when the relationship is disregarded.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.05087v1"
    },
    {
        "title": "Improving the Quality of Random Number Generators by Applying a Simple\n  Ratio Transformation",
        "authors": [
            "Michael Kolonko",
            "Zijun Wu",
            "Feng Gu"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  It is well-known that the quality of random number generators can often be\nimproved by combining several generators, e.g. by summing or subtracting their\nresults. In this paper we investigate the ratio of two random number generators\nas an alternative approach: the smaller of two input random numbers is divided\nby the larger, resulting in a rational number from $[0,1]$.\n  We investigate theoretical properties of this approach and show that it\nyields a good approximation to the ideal uniform distribution. To evaluate the\nempirical properties we use the well-known test suite \\textsc{TestU01}. We\napply the ratio transformation to moderately bad generators, i.e. those that\nfailed up to 40\\% of the tests from the test battery \\textsc{Crush} of\n\\textsc{TestU01}. We show that more than half of them turn into very good\ngenerators that pass all tests of \\textsc{Crush} and \\textsc{BigCrush} from\n\\textsc{TestU01} when the ratio transformation is applied. In particular,\ngenerators based on linear operations seem to benefit from the ratio, as this\nbreaks up some of the unwanted regularities in the input sequences. Thus the\nadditional effort to produce a second random number and to calculate the ratio\nallows to increase the quality of available random number generators.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.07318v1"
    },
    {
        "title": "Neural Network-based exploration of construct validity for Russian\n  version of the 10-item Big Five Inventory",
        "authors": [
            "Anastasia Sergeeva",
            "Bogdan Kirillov",
            "Alyona Dzhumagulova"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This study aims to present a new method of exploring construct validity of\nquestionnaires based on neural network. Using this test we further explore\nconvergent validity for Russian adaptation of TIPI (Ten-Item Personality\nInventory by Gosling, Rentfrow, and Swann). Due to small number of questions\nTIPI-RU can be used as an express-method for surveying large number of people,\nespecially in the Internet-studies. It can be also used with other translations\nof the same questionnaire in the intercultural studies. The neural network test\nfor construct validity can be used as more convenient substitute for path\nmodel.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.00905v1"
    },
    {
        "title": "Gamorithm",
        "authors": [
            "Moshe Sipper",
            "Jason H. Moore"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Examining games from a fresh perspective we present the idea of game-inspired\nand game-based algorithms, dubbed \"gamorithms\".\n",
        "pdf_link": "http://arxiv.org/pdf/1806.02717v2"
    },
    {
        "title": "Design and Application of Data Aquistion Interface Circuit",
        "authors": [
            "Hayder O. Alwan",
            "Noor M. Farhan",
            "Qais S- Al-Sabbagh"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  A commitment to condition monitoring involves the operators of plant in the\nconduct of a range of activities. These activities may be compli-cated in\nnature and indeed may often be performed automatically under computer control.\nThey can, however, always be down into a rela-tively small number of easily\nidentifiable functional tasks. This makes it much easier to identify the common\nelements of machine condition monitoring schemes. A proposed interface circuit\ndesign and application will be further explain in this paper, the implemented\nmonitoring unit circuit also illustrated, see appendix A. Two scenarios\npresented in this paper, first ten turns assume to be shorted, and in the\nsecond thirty turns shorted to show the difference in the amplitude of\nfrequencies at each case. This paper present. An improvement in three-phase\nsquirrel-cage induction motor stator inter-turn fault detection and diagnosis\nbased on a neural network approach is presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.08721v1"
    },
    {
        "title": "Automatic streetlights that glow on detecting night and object using\n  Arduino",
        "authors": [
            "Zain Mumtaz",
            "Saleem Ullah",
            "Zeeshan Ilyas",
            "Shuo Liu",
            "Naila Aslam",
            "Jehangir Arshad Meo",
            "Hamza Ahmad Madni"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Our manuscript aims to develop a system which will lead to energy\nconservation and by doing so, we would be able to lighten few more homes. The\nproposed work is accomplished by using Arduino microcontroller and sensors that\nwill control the electricity based on night and object's detection. Meanwhile,\na counter is set that will count the number of objects passed through the road.\nThe beauty of the proposed work is that the wastage of unused electricity can\nbe reduced, lifetime of the streetlights gets enhance because the lights do not\nstay ON during the whole night, and helps to increase safety measurements. We\nare confident that the proposed idea will be beneficial in the future\napplications of microcontrollers and sensors etc.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.10968v1"
    },
    {
        "title": "On Double-Sided QR-Codes",
        "authors": [
            "Alexey Tikhonov"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Due to the widespread adoption of the smart mobile devices, QR codes have\nbecome one of the most-known types of 2D codes around the world. However, the\ndata capacity properties of modern QR codes are still not perfect. To address\nthis issue, in this paper, we propose a novel approach to make double-sided QR\ncodes, which could carry two different messages in a straight and mirrored\nposition. To facilitate the process of creation of such codes we propose two\nmethods of their construction: the brute-force method and the analytic\nsolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.05722v1"
    },
    {
        "title": "Monitorology the art of observing the world",
        "authors": [
            "Miroslaw Malek"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In the age of ever increasing demand for big data and data analytics, a\nquestion of collecting the data becomes fundamental. What and how to collect\nthe data is essential as it has direct impact on decision making, system\noperation and control. Specifically, we focus on the art of observing the world\nby electronic devices such as sensors and meters that, in general, we call\nmonitors. We define five challenges to ensure effective and efficient\nmonitoring that still need a lot of research. Additionally, we illustrate each\nchallenge by example. Since reliance on big data and data analytics is\ncontinuously increasing, these challenges will become ever more relevant to\nsave the world from flood of meaningless, dumb data, leading frequently to\nfalse conclusions and wrong decisions whose impact may range from a minor\ninconvenience to major disasters and even loss of lives.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.09459v1"
    },
    {
        "title": "Charging control of electric vehicles using contextual bandits\n  considering the electrical distribution grid",
        "authors": [
            "Christian Rmer",
            "Johannes Hiry",
            "Chris Kittl",
            "Thomas Liebig",
            "Christian Rehtanz"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  With the proliferation of electric vehicles, the electrical distribution\ngrids are more prone to overloads. In this paper, we study an intelligent\npricing and power control mechanism based on contextual bandits to provide\nincentives for distributing charging load and preventing network failure. The\npresented work combines the microscopic mobility simulator SUMO with electric\nnetwork simulator SIMONA and thus produces reliable electrical distribution\nload values. Our experiments are carefully conducted under realistic conditions\nand reveal that conditional bandit learning outperforms context-free\nreinforcement learning algorithms and our approach is suitable for the given\nproblem. As reinforcement learning algorithms can be adapted rapidly to include\nnew information we assume these to be suitable as part of a holistic traffic\ncontrol scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.01163v1"
    },
    {
        "title": "Programmable Logic Arrays",
        "authors": [
            "Issam Damaj"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Programmable logic arrays (PLAs) are traditional digital electronic devices.\nA PLA is a simple programmable logic device (SPLD) used to implement\ncombinational logic circuits. A PLA has a set of programmable AND gates, which\nlink to a set of programmable OR gates to produce an output. The AND-OR layout\nof a PLA allows for implementing logic functions that are in a sum-of-products\nform. PLAs are available in the market in different types. PLAs could be stand\nalone chips, or parts of bigger processing systems. Stand alone PLAs are\navailable as mask programmable (MPLAs) and field programmable (FPLAs) devices.\nThe attractions of PLAs that brought them to mainstream engineers include their\nsimplicity, relatively small circuit area, predictable propagation delay, and\nease of development. The powerful-but-simple property brought PLAs to rapid\nprototyping, synthesis, design optimization techniques, embedded systems,\ntraditional computer systems, hybrid high-performance computing systems, etc.\nIndeed, there has been renewable interests in working with the simple AND-to-OR\nPLAs.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02074v1"
    },
    {
        "title": "Logic Design",
        "authors": [
            "Issam Damaj"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Electronic circuits can be separated into two groups, digital and analog\ncircuits. Analog circuits operate on analog quantities that are continuous in\nvalue, whereas digital circuits operate on digital quantities that are discrete\nin value and limited in precision. In practice, most digital systems contain\ncombinational circuits along with memory; these systems are known as sequential\ncircuits. Sequential circuits are of two types: synchronous and asynchronous.\nIn a synchronous sequential circuit, a clock signal is used at discrete\ninstants of time to synchronize desired operations. Asynchronous sequential\ncircuits do not require synchronizing clock pulses; however, the completion of\nan operation signals the start of the next operation in sequence. The basic\nlogic design steps are generally identical for sequential and combinational\ncircuits; these are specification, formulation, optimization, and the\nimplementation of the optimized equations using a suitable hardware technology.\nThe differences between sequential and combinational design steps appear in the\ndetails of each step. The minimization (optimization) techniques used in logic\ndesign range from simple (manual) to complex (automated). An example of manual\noptimization methods is the Karnough map (K-map). Indeed, hardware\nimplementation technology has been growing faster than the ability of designers\nto produce hardware designs. Hence, there has been a growing interest in\ndeveloping techniques and tools that facilitate the process of logic design.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02075v1"
    },
    {
        "title": "High-level Synthesis",
        "authors": [
            "Issam Damaj"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Hardware synthesis is a general term used to refer to the processes involved\nin automatically generating a hardware design from its specification.\nHigh-level synthesis (HLS) could be defined as the translation from a\nbehavioral description of the intended hardware circuit into a structural\ndescription similar to the compilation of programming languages (such as C and\nPascal into assembly language. The chained synthesis tasks at each level of the\ndesign process include system synthesis, register-transfer synthesis, logic\nsynthesis, and circuit synthesis. The development of hardware solutions for\ncomplex applications is no more a complicated task with the emergence of\nvarious HLS tools. Many areas of application have benefited from the modern\nadvances in hardware design, such as automotive and aerospace industries,\ncomputer graphics, signal and image processing, security, complex simulations\nlike molecular modeling, and DND matching. The field of HLS is continuing its\nrapid growth to facilitate the creation of hardware and to blur more and more\nthe border separating the processes of designing hardware and software.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.02076v1"
    },
    {
        "title": "Analytical review of medical mobile diagnostic systems",
        "authors": [
            "Darii Kordiyak",
            "Nataliya Shakhovska"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  This article analyzes the mobile medical diagnostic systems and compare them\nwith the proposed HealthTracker system based on smartwatch Apple Watch. Before\nthe development of the system HealthTracker, there was conducted a review and\nanalysis of existing similar systems to identify common and distinctive\nfeatures of the future system. This analysis will improve HealthTracker system,\nbased on the strengths and weaknesses of existing systems and help identify and\njustify the key benefits and unique system HealthTracker. The main goal is to\nprovide a system HealthTracker convenient way to interact with the patient the\ndoctor based on the vital signs of the patient. Apple Watch is an excellent\nwatch presented in 2014 that has the capacity to collect and compile data on\nthe health of the user and can be used for medical purposes.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03212v1"
    },
    {
        "title": "Simulation Typology and Termination Risks",
        "authors": [
            "Alexey Turchin",
            "Michael Batin",
            "David Denkenberger",
            "Roman Yampolskiy"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The goal of the article is to explore what is the most probable type of\nsimulation in which humanity lives (if any) and how this affects simulation\ntermination risks. We firstly explore the question of what kind of simulation\nin which humanity is most likely located based on pure theoretical reasoning.\nWe suggest a new patch to the classical simulation argument, showing that we\nare likely simulated not by our own descendants, but by alien civilizations.\nBased on this, we provide classification of different possible simulations and\nwe find that simpler, less expensive and one-person-centered simulations,\nresurrectional simulations, or simulations of the first artificial general\nintelligence's (AGI's) origin (singularity simulations) should dominate. Also,\nsimulations which simulate the 21st century and global catastrophic risks are\nprobable. We then explore whether the simulation could collapse or be\nterminated. Most simulations must be terminated after they model the\nsingularity or after they model a global catastrophe before the singularity.\nUndeniably observed glitches, but not philosophical speculations could result\nin simulation termination. The simulation could collapse if it is overwhelmed\nby glitches. The Doomsday Argument in simulations implies termination soon. We\nconclude that all types of the most probable simulations except resurrectional\nsimulations are prone to termination risks in a relatively short time frame of\nhundreds of years or less from now.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.05792v1"
    },
    {
        "title": "Inquiry of P-reduction in Cook's 1971 Paper -- from Oracle machine to\n  Turing machine",
        "authors": [
            "JianMing Zhou",
            "Yu Li"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In this paper, we inquire the key concept P-reduction in Cook's theorem and\nreveal that there exists the fallacy of definition in P-reduction caused by the\ndisguised displacement of NDTM from Oracle machine to Turing machine. The\ndefinition or derivation of P-reduction is essentially equivalent to Turing's\ncomputability. Whether NP problems might been reduced to logical forms\n(tautology or SAT) or NP problems might been reduced each other, they have not\nbeen really proven in Cook's 1971 paper.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.06311v1"
    },
    {
        "title": "Quartierstrom -- Implementation of a real world prosumer centric local\n  energy market in Walenstadt, Switzerland",
        "authors": [
            "Liliane Ableitner",
            "Arne Meeuw",
            "Sandro Schopfer",
            "Verena Tiefenbeck",
            "Felix Wortmann",
            "Anselma Wrner"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Prosumers in many regions are facing reduced feed-in tariffs and currently\nhave no possibility to influence the level of remuneration for the locally\nproduced solar energy. Peer-to-peer communities may offer an alternative to the\nfeed-in tariff model by enabling prosumers to directly sell their solar energy\nto local consumers (possibly at a rate that is beneficial for both consumer and\nprosumer). The Quartierstrom project investigates a transactional energy system\nthat manages the exchange and remuneration of electricity between consumers,\nprosumers and the local electric grid provider in the absence of\nintermediaries. This whitepaper describes the prototypical real-world system\nbeing implemented in the town of Walenstadt, Switzerland, with 37 participating\nhouseholds. The community members of this pilot project pay a reduced tariff\nfor grid usage if the electricity produced by a prosumer is sold to another\ncommunity member, which is located on the same voltage or grid level downstream\na substation1. Such a tariff structure incentivizes local balancing, i.e.\nlocally produced energy can be consumed locally whenever possible to avoid\ncosts from higher grid levels. The blockchain is a novel technology suitable to\nlog the produced and consumed units of energy within a community, making it\npossible to implement market places. In those marketplaces, both prosumers and\nconsumers can indicate a price at which they are willing to sell / buy locally\nproduced solar energy without the intermediation of a utility. The key goals of\nthis project are the assessment of A) the technical, economical and ecological\nfeasibility of a blockchain-based community energy system regarding local\nutilization of solar energy, grid quality and energy efficiency and B)\nresulting dynamics regarding local market prices and user acceptance.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.07242v2"
    },
    {
        "title": "Cost-Based Approach to Complexity: A Common Denominator?",
        "authors": [
            "Luciano da F. Costa",
            "Guilherme S. Domingues"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Complexity remains one of the central challenges in science and technology.\nAlthough several approaches at defining and/or quantifying complexity have been\nproposed, at some point each of them seems to run into intrinsic limitations or\nmutual disagreement. Two are the main objectives of the present work: (i) to\nreview some of the main approaches to complexity; and (ii) to suggest a\ncost-based approach that, to a great extent, can be understood as an\nintegration of the several facets of complexity while keeping its meaning for\nhumans in mind. More specifically, it is poised that complexity, an inherently\nrelative and subjective concept, can be summarized as the cost of developing a\nmodel, plus the cost of its respective operation. As a consequence, complexity\ncan vary along time and space. The proposal is illustrated respectively to\nseveral applications examples, including a real-data base situation.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.11925v3"
    },
    {
        "title": "Digital Availability of Product Information for Collaborative\n  Engineering of Spacecraft",
        "authors": [
            "Diana Peters",
            "Philipp M. Fischer",
            "Philipp M. Schfer",
            "Kobkaew Opasjumruskit",
            "Andreas Gerndt"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In this paper, we introduce a system to collect product information from\nmanufacturers and make it available in tools that are used for concurrent\ndesign of spacecraft. The planning of a spacecraft needs experts from different\ndisciplines, like propulsion, power, and thermal. Since these different\ndisciplines rely on each other there is a high need for communication between\nthem, which is often realized by a Model-Based Systems Engineering (MBSE)\nprocess and corresponding tools. We show by comparison that the product\ninformation provided by manufacturers often does not match the information\nneeded by MBSE tools on a syntactic or semantic level. The information from\nmanufacturers is also currently not available in machine-readable formats.\nAfterwards, we present a prototype of a system that makes product information\nfrom manufacturers directly available in MBSE tools, in a machine-readable way.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.12548v1"
    },
    {
        "title": "Context Adaptivity as Enabler for Meaningful Pervasive Advertising",
        "authors": [
            "Christine Bauer"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Socio-demographic user profiles are currently regarded as the most convenient\nbase for successful personalized advertising. However, signs point to the\ndormant power of context recognition. While technologies that can sense the\nenvironment are increasingly advanced, questions such as what to sense and how\nto adapt to a consumer's context are largely unanswered. Research in the field\nis scattered and frequently prototype-driven. What the community lacks is a\nthorough methodology to provide the basis for any context-adaptive system:\nconceptualizing context. This position paper describes our current research of\nconceptualizing context for pervasive advertising. It summarizes findings from\nliterature analysis and proposes a methodology for context conceptualization,\nwhich is currently work-in-progress.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01490v1"
    },
    {
        "title": "CAD Tool Design Space Exploration via Bayesian Optimization",
        "authors": [
            "Yuzhe Ma",
            "Ziyang Yu",
            "Bei Yu"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The design complexity is increasing as the technology node keeps scaling\ndown. As a result, the electronic design automation (EDA) tools also become\nmore and more complex. There are lots of parameters involved in EDA tools,\nwhich results in a huge design space. What's worse, the runtime cost of the EDA\nflow also goes up as the complexity increases, thus exhaustive exploration is\nprohibitive for modern designs. Therefore, an efficient design space\nexploration methodology is of great importance in advanced designs. In this\npaper we target at an automatic flow for reducing manual tuning efforts to\nachieve high quality circuits synthesis outcomes. It is based on Bayesian\noptimization which is a promising technique for optimizing black-box functions\nthat are expensive to evaluate. Gaussian process regression is leveraged as the\nsurrogate model in Bayesian optimization framework. In this work, we use 64-bit\nprefix adder design as a case study. We demonstrate that the Bayesian\noptimization is efficient and effective for performing design space exploration\non EDA tool parameters, which has great potential for accelerating the design\nflow in advanced technology nodes.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.06460v1"
    },
    {
        "title": "BiEntropy, TriEntropy and Primality",
        "authors": [
            "Grenville J. Croll"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The order and disorder of binary representations of the natural numbers < 2^8\nis measured using the BiEntropy function. Significant differences are detected\nbetween the primes and the non primes. The BiEntropic prime density is shown to\nbe quadratic with a very small Gaussian distributed error. The work is repeated\nin binary using a monte carlo simulation for a sample of the natural numbers <\n2^32 and in trinary for all natural numbers < 3^9 with similar but cubic\nresults. We find a significant relationship between BiEntropy and TriEntropy\nsuch that we can discriminate between the primes and numbers divisible by six.\nWe discuss the theoretical underpinnings of these results and show how they\ngeneralise to give a tight bound on the variance of Pi(x) - Li(x) for all x.\nThis bound is much tighter than the bound given by Von Koch in 1901 as an\nequivalence for proof of the Riemann Hypothesis. Since the primes are Gaussian\ndue to a simple induction on the binary derivative, this implies that the twin\nprimes conjecture is true. We also provide absolutely convergent asymptotes for\nthe numbers of Fermat and Mersenne primes in the appendices.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.08051v2"
    },
    {
        "title": "A Noxious Market for Personal Data",
        "authors": [
            "Abdul Abdulrahim",
            "Michael Famoroti"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Many policymakers, academics and governments have advocated for exchangeable\nproperty rights over information as it presents a market solution to what could\nbe considered a market failure. Particularly in jurisdictions such as Africa,\nAsia or South America, where weaker legal protections and fleeting regulatory\nenforcement leaves data subjects vulnerable or exploited regardless of the\noutcome. We argue that whether we could achieve this personal data economy in\nwhich individuals have ownership rights akin to property rights over their data\nshould be approached with caution as a solution to ensuring individuals have\nagency over their data across different legal landscapes. We present an\nobjection to the use of property rights, a market solution, due to the\n\\textit{noxious} nature of personal data - which is founded on Satz and\nSandel's objection to markets.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.00457v1"
    },
    {
        "title": "A Promise Theoretic Account of the Boeing 737 Max MCAS Algorithm Affair",
        "authors": [
            "J. A. Bergstra",
            "M. Burgess"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Many public controversies involve the assessment of statements about which we\nhave imperfect information. Without a structured approach, it is quite\ndifficult to develop an approach to reasoning which is not based on ad hoc\nchoices. Forms of logic have been used in the past to try to bring such\nclarity, but these fail for a variety of reasons. We demonstrate a simple\napproach to bringing a standardized approach to semantics, in certain\ndiscourse, using Promise Theory. As a case, we use Promise Theory (PT) to\ncollect and structure publicly available information about the case of the MCAS\nsoftware component for the Boeing 737 Max flight control system.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.01543v1"
    },
    {
        "title": "Roof Age Determination for the Automated Site-Selection of Rooftop Solar",
        "authors": [
            "Chris Heinrich",
            "Michael Laskin",
            "Simas Glinskis",
            "Evert van Nieuwenburg"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Rooftop solar is one of the most promising tools for drawing down greenhouse\ngas (GHG) emissions and is cost-competitive with fossil fuels in many areas of\nthe world today. One of the most important criteria for determining the\nsuitability of a building for rooftop solar is the current age of its roof. The\nreason for this is simple -- because rooftop solar installations are\nlong-lived, the roof needs to be new enough to last for the lifetime of the\nsolar array or old enough to justify being replaced. In this paper we present a\ndata-driven method for determining the age of a roof from historical satellite\nimagery, which removes one of the last obstacles to a fully automated pipeline\nfor rooftop solar site selection. We estimate that a full solution to this\nproblem would reduce customer acquisition costs for rooftop solar by\n$\\sim$20\\%, leading to an additional $\\sim$750 megatons of CO$_2$ displaced\nbetween 2020 and 2050.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.04227v1"
    },
    {
        "title": "The Epistemic Landscape: a Computability Perspective",
        "authors": [
            "Frdric Prost"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  By nature, transmissible human knowledge is enumerable: every sentence,\nmovie, audio record can be encoded in a sufficiently long string of 0's and\n1's. The works of G\\\"odel, Turing and others showed that there are inherent\nlimits and properties associated with the fact that language technology is\nenumerable. G\\\"odel's numbering technique is universal for enumerable\nstructures and shows strong limits of the language technology. Computability\ntheory is a particular example: programs can be numbered and all sorts of\nlimits can be studied from there. Computability is also at the heart of science\nsince any experimental validation of a theory supposes that theoretical results\nhave been computed, then checked against concrete experiments. It implies that\nlimitations on what is computable ultimately are also limits of what we\nunderstand as \"scientific theory\", and more generally to all the transmissible\nknowledge. We argue that it is fruitful to look a epistemology from a\ncomputability perspective. We show that it allows to precisely define different\nkinds of knowledge acquisition techniques, and helps the study of how they are\nrelated to one another.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.10800v1"
    },
    {
        "title": "Proposal of a standard of Knowledge Management and Technological\n  Innovation for Mexico",
        "authors": [
            "Jorge Romero-Hidalgo"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The purpose of this work is to offer a methodology that allows to construct a\nstandard in Knowledge Management and Technological Innovation which may be used\nin various organizations in M\\'exico to improve the operation of their\nresources and productivity. Based on the review of the existing literature, a\nmodel is offered including several elements to enable organizations to\nestablish their position in relation to both concepts. The following proposal\nis based on a systematic effort to understand and integrate models of Knowledge\nManagement and Innovation published in recent years as well as the results of\nthe experiences to propose standards of Knowledge Management and Technological\nInnovation. In order to elaborate the proposal, factors and their associated\ncomponents have been analyzed through a review of the literature in order to\nbuild and validate a standard proposal. To test the research study, a six-stage\nresearch model has been constructed. For this purpose, an in-depth exploratory\nresearch study has been carried out in a public sector organization, in an area\nthat allows the replicability of the model. The results have been analyzed to\nconstruct and empirically validate the Mexican Standard of Knowledge Management\nan Technological Innovation. Finally, after the statistical analysis, results\nobtained from the application of the validated instrument are shown , which\nsupports the definition of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.11379v1"
    },
    {
        "title": "On the loss of learning capability inside an arrangement of neural\n  networks",
        "authors": [
            "Ivan Arraut",
            "Diana Diaz"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  We analyze the loss of information and the loss of learning capability inside\nan arrangement of neural networks. Our method is new and based on the\nformulation of non-unitary Bogoliubov transformations in order to connect the\ninformation between different points of the arrangement. This can be done after\nexpanding the activation function in a Fourier series and then assuming that\nits information is stored inside a Quantum scalar field.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.11880v1"
    },
    {
        "title": "White Paper on Business of 6G",
        "authors": [
            "Seppo Yrjola",
            "Petri Ahokangas",
            "Marja Matinmikko-Blue",
            "Risto Jurva",
            "Vivek Kant",
            "Pasi Karppinen",
            "Marianne Kinnula",
            "Harilaos Koumaras",
            "Mika Rantakokko",
            "Volker Ziegler",
            "Abhishek Thakur",
            "Hans-Jurgen Zepernick"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Developing products, services and vertical applications for the future\ndigitized society in the 6G era requires a multidisciplinary approach and a\nre-definition of how we create, deliver and consume network resources, data and\nservices for both communications and sensing purposes. This development will\nchange and disrupt the traditional business models and ecosystem roles of\ndigital service providers, as well as open the market for key stakeholders in\nthe 6G era like digital service operators, cloud operators and resource\nbrokers. White paper discusses unprecedented opportunities of enabling and\nempowering multiple stakeholders to have a more active participation in the\nfuture 6G ecosystem via novel sustainable open ecosystemic business models with\nflexible integration of long tail services with tailored performance\nattributes. This research adopts a qualitative scenario planning method and\nportrays three scenario themes resulting in a total of 12 scenarios for the\nfutures of the 6G business. By focusing on key trends, their interactions, and\nirreducible uncertainties, scenario building generates perspectives for the\nfutures within which alternative 6G business strategies were developed and\nassessed for a traditional incumbent mobile network operator and a novel 6G\ndigital service provider stemming from redefined sustainable economics.\nValue-capture in the 6G era requires understanding the dynamics of platforms\nand ecosystems. Results indicate that, to reach some of the preferred futures,\nwe should pay attention to the privacy and security issues related to business\nand regulation needs; public/governmental, corporate, community and user(s)\nperspectives to and aims of governance; ecosystem configuration related to\nusers, decentralized business models and platforms; user empowerment; and the\nrole of location-specificity of services.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06400v2"
    },
    {
        "title": "AGI and the Knight-Darwin Law: why idealized AGI reproduction requires\n  collaboration",
        "authors": [
            "Samuel Allen Alexander"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Can an AGI create a more intelligent AGI? Under idealized assumptions, for a\ncertain theoretical type of intelligence, our answer is: \"Not without outside\nhelp\". This is a paper on the mathematical structure of AGI populations when\nparent AGIs create child AGIs. We argue that such populations satisfy a certain\nbiological law. Motivated by observations of sexual reproduction in\nseemingly-asexual species, the Knight-Darwin Law states that it is impossible\nfor one organism to asexually produce another, which asexually produces\nanother, and so on forever: that any sequence of organisms (each one a child of\nthe previous) must contain occasional multi-parent organisms, or must\nterminate. By proving that a certain measure (arguably an intelligence measure)\ndecreases when an idealized parent AGI single-handedly creates a child AGI, we\nargue that a similar Law holds for AGIs.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.08801v1"
    },
    {
        "title": "Acceptance of e-procurement in organisations",
        "authors": [
            "Muhammed S. Maddi",
            "Paul Davis",
            "John Geraghty"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  This research is concerned with the development of a realistic model for\ne-procurement adoption by organisations and groups observing the Rules of\nIslamic Sharia (RIS). This model is intended to be based on the behavioural\ncontrol, subjective norms, and the recognition of the benefits and risks of e\nprocurement adoption. The developed model,(E-PAM), combined and extended two\nexisting models previously used for information technology adoption. Central to\nthe design of the E-PAM is the principle that a realistic model should consider\nall relevant psychological, social, cultural, demography, and religious\nfactors. .\n",
        "pdf_link": "http://arxiv.org/pdf/2005.10094v1"
    },
    {
        "title": "Performance of Linear Field Reconstruction Techniques with Noise and\n  Uncertain Sensor Locations",
        "authors": [
            "A. Nordio",
            "C. -F. Chiasserini",
            "E. Viterbo"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  We consider a wireless sensor network, sampling a bandlimited field,\ndescribed by a limited number of harmonics. Sensor nodes are irregularly\ndeployed over the area of interest or subject to random motion; in addition\nsensors measurements are affected by noise. Our goal is to obtain a high\nquality reconstruction of the field, with the mean square error (MSE) of the\nestimate as performance metric. In particular, we analytically derive the\nperformance of several reconstruction/estimation techniques based on linear\nfiltering. For each technique, we obtain the MSE, as well as its asymptotic\nexpression in the case where the field number of harmonics and the number of\nsensors grow to infinity, while their ratio is kept constant. Through numerical\nsimulations, we show the validity of the asymptotic analysis, even for a small\nnumber of sensors. We provide some novel guidelines for the design of sensor\nnetworks when many parameters, such as field bandwidth, number of sensors,\nreconstruction quality, sensor motion characteristics, and noise level of the\nmeasures, have to be traded off.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.0796v1"
    },
    {
        "title": "Bandlimited Field Reconstruction for Wireless Sensor Networks",
        "authors": [
            "A. Nordio",
            "C. -F. Chiasserini",
            "E. Viterbo"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Wireless sensor networks are often used for environmental monitoring\napplications. In this context sampling and reconstruction of a physical field\nis one of the most important problems to solve. We focus on a bandlimited field\nand find under which conditions on the network topology the reconstruction of\nthe field is successful, with a given probability. We review irregular sampling\ntheory, and analyze the problem using random matrix theory. We show that even a\nvery irregular spatial distribution of sensors may lead to a successful signal\nreconstruction, provided that the number of collected samples is large enough\nwith respect to the field bandwidth. Furthermore, we give the basis to\nanalytically determine the probability of successful field reconstruction.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.1954v1"
    },
    {
        "title": "Design of Multistage Decimation Filters Using Cyclotomic Polynomials:\n  Optimization and Design Issues",
        "authors": [
            "Massimiliano Laddomada"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This paper focuses on the design of multiplier-less decimation filters\nsuitable for oversampled digital signals. The aim is twofold. On one hand, it\nproposes an optimization framework for the design of constituent decimation\nfilters in a general multistage decimation architecture. The basic building\nblocks embedded in the proposed filters belong, for a simple reason, to the\nclass of cyclotomic polynomials (CPs): the first 104 CPs have a z-transfer\nfunction whose coefficients are simply {-1,0,+1}. On the other hand, the paper\nprovides a bunch of useful techniques, most of which stemming from some key\nproperties of CPs, for designing the proposed filters in a variety of\narchitectures. Both recursive and non-recursive architectures are discussed by\nfocusing on a specific decimation filter obtained as a result of the\noptimization algorithm.\n  Design guidelines are provided with the aim to simplify the design of the\nconstituent decimation filters in the multistage chain.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.2182v1"
    },
    {
        "title": "On the Polyphase Decomposition for Design of Generalized Comb Decimation\n  Filters",
        "authors": [
            "Massimiliano Laddomada"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Generalized comb filters (GCFs) are efficient anti-aliasing decimation\nfilters with improved selectivity and quantization noise (QN) rejection\nperformance around the so called folding bands with respect to classical comb\nfilters.\n  In this paper, we address the design of GCF filters by proposing an efficient\npartial polyphase architecture with the aim to reduce the data rate as much as\npossible after the Sigma-Delta A/D conversion. We propose a mathematical\nframework in order to completely characterize the dependence of the frequency\nresponse of GCFs on the quantization of the multipliers embedded in the\nproposed filter architecture. This analysis paves the way to the design of\nmultiplier-less decimation architectures.\n  We also derive the impulse response of a sample 3rd order GCF filter used as\na reference scheme throughout the paper.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.2436v1"
    },
    {
        "title": "RS-232 Led Board",
        "authors": [
            "Vladimir Tskhvaradze"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  This article demonstrates how to develop a Microchip PIC16F84 based device\nthat supports RS-232 interface with PC. Circuit (LED Board) design and software\ndevelopment will be discussed. PicBasic Pro Compiler from microEngineering\nLabs, Inc. is used for PIC programming. Development of LED Board Control\nConsole using C/C++ is also briefly discussed. The project requires basic work\nexperience with Microchip PICs, serial communication and programming.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.3236v1"
    },
    {
        "title": "Products of irreducible random matrices in the (Max,+) Algebra",
        "authors": [
            "Jean Mairesse"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  We consider the recursive equation ``x(n+1)=A(n)x(n)'' where x(n+1) and x(n)\nare column vectors of size k and where A(n) is an irreducible random matrix of\nsize k x k. The matrix-vector multiplication in the (max,+) algebra is defined\nby (A(n)x(n))_i= max_j [ A(n)_{ij} +x(n)_j ]. This type of equation can be used\nto represent the evolution of Stochastic Event Graphs which include cyclic\nJackson Networks, some manufacturing models and models with general blocking\n(such as Kanban). Let us assume that the sequence (A(n))_n is i.i.d or more\ngenerally stationary and ergodic. The main result of the paper states that the\nsystem couples in finite time with a unique stationary regime if and only if\nthere exists a set of matrices C such that P {A(0) in C} > 0, and the matrices\nin C have a unique periodic regime.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.3672v1"
    },
    {
        "title": "Further Comments on \"Residue-to-Binary Converters Based on New Chinese\n  Remainder Theorems\"",
        "authors": [
            "Jean-Luc Beuchat"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Ananda Mohan suggested that the first New Chinese Remainder Theorem\nintroduced by Wang can be derived from the constructive proof of the well-known\nChinese Remainder Theorem (CRT) and claimed that Wang's approach is the same as\nthe one proposed earlier by Huang. Ananda Mohan's proof is however erroneous\nand we show here that Wang's New CRT I is a rewriting of an algorithm\npreviously sketched by Hitz and Kaltofen.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.3732v2"
    },
    {
        "title": "Reductionism, emergence, and levels of abstractions",
        "authors": [
            "Russ Abbott"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Can there be independent higher level laws of nature if everything is\nreducible to the fundamental laws of physics? The computer science notion of\nlevel of abstraction explains why there can -- illustrating how computational\nthinking can solve one of philosophy's most vexing problems.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.4198v1"
    },
    {
        "title": "Blocking a transition in a Free Choice net and what it tells about its\n  throughput",
        "authors": [
            "Bruno Gaujal",
            "Stefan Haar",
            "Jean Mairesse"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In a live and bounded Free Choice Petri net, pick a non-conflicting\ntransition. Then there exists a unique reachable marking in which no transition\nis enabled except the selected one. For a routed live and bounded Free Choice\nnet, this property is true for any transition of the net. Consider now a live\nand bounded stochastic routed Free Choice net, and assume that the routings and\nthe firing times are independent and identically distributed. Using the above\nresults, we prove the existence of asymptotic firing throughputs for all\ntransitions in the net. Furthermore the vector of the throughputs at the\ndifferent transitions is explicitly computable up to a multiplicative constant.\n",
        "pdf_link": "http://arxiv.org/pdf/0707.4372v1"
    },
    {
        "title": "A Novel VSWR-Protected and Controllable CMOS Class E Power Amplifier for\n  Bluetooth Applications",
        "authors": [
            "Wei Chen",
            "Wei Lin",
            "Shizhen Huang"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  This paper describes the design of a differential class-E PA for Bluetooth\napplications in 0.18um CMOS technology with load mismatch protection and power\ncontrol features. The breakdown induced by load mismatch can be avoided by\nattenuating the RF power to the final stage during over voltage conditions.\nPower control is realized by means of \"open loop\" techniques to regulate the\npower supply voltage, and a novel controllable bias network with temperature\ncompensated is proposed, which allows a moderate power control slope (dB/V) to\nbe achieved. Post-layout Simulation results show that the level of output power\ncan be controlled in 2dBm steps; especially the output power in every step is\nquite insensitive to temperature variations.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0213v1"
    },
    {
        "title": "Complexity",
        "authors": [
            "Carlos Gershenson"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The term complexity derives etymologically from the Latin plexus, which means\ninterwoven. Intuitively, this implies that something complex is composed by\nelements that are difficult to separate. This difficulty arises from the\nrelevant interactions that take place between components. This lack of\nseparability is at odds with the classical scientific method - which has been\nused since the times of Galileo, Newton, Descartes, and Laplace - and has also\ninfluenced philosophy and engineering. In recent decades, the scientific study\nof complexity and complex systems has proposed a paradigm shift in science and\nphilosophy, proposing novel methods that take into account relevant\ninteractions.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0214v1"
    },
    {
        "title": "Framework to Integrate Business Intelligence and Knowledge Management in\n  Banking Industry",
        "authors": [
            "G. Koteswara Rao",
            "Roshan Kumar"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  In this digital age organizations depend upon the technologies to provide\ncustomer-centric solutions by understanding well about their customers'\nbehaviour and continuously improving business process of the organization.\nBusiness intelligence (BI) applications will play a vital role at this stage by\ndiscovering the knowledge hidden in internal as well as external sources. On\nthe other hand, Knowledge Management (KM) will enhance the organisations\nperformance by providing collaborative tools to learn, create and share the\nknowledge among the employees. The main intention of the BI is to enhance the\nemployees' knowledge with information that allows them to make decisions to\nachieve its organisational strategies. However only twenty percent of data\nexist in structured form, majority of banks knowledge is in unstructured or\nminds of its employees. Organizations are needed to integrate KM with Knowledge\nwhich is discovered from data and information. The purpose of this paper is to\ndiscuss the need of business insiders in the process of knowledge discovery and\ndistribution, to make BI more relevant to business of the bank. We have also\ndiscussed about the BI/KM applications in banking industry and provided a\nframework to integrate BI and KM in banking industry.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.0614v3"
    },
    {
        "title": "The Aware Cricket Ground",
        "authors": [
            "Wazir Zada Khan",
            "Mohammed Y. Aalsalem",
            "Quratul Ain Arshad"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The most profound technologies are those that disappear. They weave\nthemselves into fabrics of everyday life until they are indistinguishable from\nit [1]. This research work is a mere effort for automated decision making\nduring sports of most common interest leveraging ubiquitous computing.\nPrimarily cricket has been selected for the first implementation of the idea. A\npositioning system is used for locating the objects moving in the field. Main\nobjectives of the research are to help achieve the following goals. 1) Make\nDecisions where human eye can make error due to human limitations. 2) Simulate\nthe Match activity during and after the game in a 3D computerized Graphics\nsystem. 3) Make various types of game and performance analysis of a certain\nteam or a player.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.6199v1"
    },
    {
        "title": "Outsourcing Competence",
        "authors": [
            "J. A. Bergstra",
            "G. P. A. J. Delen",
            "S. F. M. van Vlijmen"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The topic of this paper, competences needed for outsourcing, is organized by\nfirst providing a generic competence scheme, which is subsequently instantiated\nto the area of sourcing and outsourcing. Sourcing and outsourcing are\npositioned as different areas of activity, neither one of which is subsumed\nunder the other one. It is argued that competences relevant for outsourcing are\nmainly community based rather than evidence based. Subjective ability and\nobjective ability are distinguished as categories, together making up ability,\nwhich are distinct but not necessarily disjoint from competence. Conjectural\nability is introduced as a form of subjective ability. A person's competence\nprofile includes competences as well as abilities, including subjective ones.\nCompetence assessment and acquisition as well as the impact of assessed\ncompetence on practical work is described. The analysis of competence and\nability thus developed is used as standpoint from which to extract a\nspecification of an audience for a theory of outsourcing, yet to be written.\nMoreover, it allows to formulate requirements for and in preparation of the\ndevelopment of an outsourcing theory. Formulating these requirements is done\nunder the assumption that a person's awareness of a theory of outsourcing is\nexpected to strengthen that person's outsourcing competence profile.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.6536v1"
    },
    {
        "title": "Towards an interoperable information infrastructure providing decision\n  support for genomic medicine",
        "authors": [
            "Matthias Samwald",
            "Holger Stenzhorn",
            "Michel Dumontier",
            "M. Scott Marshall",
            "Joanne Luciano",
            "Klaus-Peter Adlassnig"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Genetic dispositions play a major role in individual disease risk and\ntreatment response. Genomic medicine, in which medical decisions are refined by\ngenetic information of particular patients, is becoming increasingly important.\nHere we describe our work and future visions around the creation of a\ndistributed infrastructure for pharmacogenetic data and medical decision\nsupport, based on industry standards such as the Web Ontology Language (OWL)\nand the Arden Syntax.\n",
        "pdf_link": "http://arxiv.org/pdf/1109.6626v1"
    },
    {
        "title": "Sociotechnical Management Model for Governance of an Ecosystem",
        "authors": [
            "Antonio J. Balloni",
            "Adalberto Mantovani Martiniano de Azevedo",
            "Marco Antonio Silveira"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This is an opinion paper regarding a proposal of a model for a Ecosystemm\nGovernance. In the globalized world the importance of Information Systems (IS)\nand Information Technology (IT) become increasingly relevant regarding the\nrequirements imposed by competition. Both the knowledge of the business as the\nrapid flow of information are fundamental for a enterprise decision making.\nWhereas the basic definition of IT = hardware + software, i.e., tools that has\nbeen used to create, store and disseminate data and information in the creation\nof knowledge, and IS = IT + People + procedures that collect, process and\ndisseminate the information to support decision making, coordination, control,\nanalysis and visualization in the organization [01], it makes implicit the\nunderstanding of IS is essential to create competitive companies, to manage\nglobal corporations and provide customers with products and services of value.\nIn this work we are correlating IS with the governance of management of an\necosystem. Yet, as IT is redefining the foundations of business, then the\ncustomer service, operations, strategies of product marketing and its\ndistribution and even the knowledge management (KM) depends very much, or\nsometimes even completely, on the IS. The IT and its costs have become a part\nof day-to-day business [02]. In order to meet this complexity of business\nneeds, today is not possible to disregard the IT and its available resources,\nwhich makes very dificult to draw up IS. Therefore, the perspective view of the\nSociotehcnical Aspects of an IS are directly concerned with governance and the\nmodel proposed regarding an ecosystem. Finally, whereas the summary above, the\nmain objective of this opinion paper is to propose the guidelines for a\nSociotechnical Management Model of Governance for an Ecosystem.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.2650v1"
    },
    {
        "title": "CrowdInside: Automatic Construction of Indoor Floorplans",
        "authors": [
            "Moustafa Alzantot",
            "Moustafa Youssef"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The existence of a worldwide indoor floorplans database can lead to\nsignificant growth in location-based applications, especially for indoor\nenvironments. In this paper, we present CrowdInside: a crowdsourcing-based\nsystem for the automatic construction of buildings floorplans. CrowdInside\nleverages the smart phones sensors that are ubiquitously available with humans\nwho use a building to automatically and transparently construct accurate motion\ntraces. These accurate traces are generated based on a novel technique for\nreducing the errors in the inertial motion traces by using the points of\ninterest in the indoor environment, such as elevators and stairs, for error\nresetting. The collected traces are then processed to detect the overall\nfloorplan shape as well as higher level semantics such as detecting rooms and\ncorridors shapes along with a variety of points of interest in the environment.\nImplementation of the system in two testbeds, using different Android phones,\nshows that CrowdInside can detect the points of interest accurately with 0.2%\nfalse positive rate and 1.3% false negative rate. In addition, the proposed\nerror resetting technique leads to more than 12 times enhancement in the median\ndistance error compared to the state-of-the-art. Moreover, the detailed\nfloorplan can be accurately estimated with a a relatively small number of\ntraces. This number is amortized over the number of users of the building. We\nalso discuss possible extensions to CrowdInside for inferring even higher level\nsemantics about the discovered floorplans.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.3794v1"
    },
    {
        "title": "Performance Analysis of MIMO Radar Waveform using Accelerated Particle\n  Swarm Optimization Algorithm",
        "authors": [
            "B. Roja Reddy",
            "Uttara Kumari . M"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The Accelerated Particle Swarm Optimization Algorithm is promoted to\nnumerically design orthogonal Discrete Frequency Waveforms and Modified\nDiscrete Frequency Waveforms (DFCWs) with good correlation properties for MIMO\nradar. We employ Accelerated Particle Swarm Optimization algorithm (ACC_PSO),\nParticles of a swarm communicate good positions, velocity and accelerations to\neach other as well as dynamically adjust their own position, velocity and\nacceleration derived from the best of all particles. The simulation results\nshow that the proposed algorithm is effective for the design of DFCWs signal\nused in MIMO radar.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.4015v1"
    },
    {
        "title": "AutoAmp : An Open-Source Analog Amplifier Design Tool - For Classroom\n  and Lab Purposes",
        "authors": [
            "Om Prasad Patri",
            "K. Sanmukh Rao"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This correspondence presents an open-source tool AutoAmp developed at the\nIndian Institute of Technology, Guwahati. It is available at\nhttp://sourceforge.net/projects/autoamp-iitg/ This tool helps the user to\ndesign different types of electronic amplifiers, using solid state devices, for\na given specification. It can handle several types of designs namely\ncommon-emitter BJT amplifier (single and two-stage), operational amplifiers\n(inverting and non-inverting) and power amplifier. Not only does it design the\namplifier, it also simulates the designed amplifier using SPICE simulator and\ndisplays the performance curves. This tool is deemed to prove invaluable in\nundergraduate teaching and labs. Especially in electronics-design related\nlaboratories, the student need not design the amplifiers which are mostly the\nheart of many electronic designs.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.4157v1"
    },
    {
        "title": "A Connected Enterprise - Transformation through Mobility and Social\n  Networks",
        "authors": [
            "Jitendra Maan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Due to rapid changes in business dynamics, there is a growing demand to\nencourage social conversations/exchanges and the ability to connect and\ncommunicate with peers, partners, customers and other stakeholders anytime,\nanywhere which drives the need of mobile-enable, the existing enterprise\napplications. This paper highlights a distinct set of needs and key customer\nchallenges that must be considered and addressed for deployment of Social\nCollaboration applications and Mobility services in enterprises. It not only\naddresses the Critical Success Factors for enterprise mobility enablement but\nalso outlines the unique business requirements to rapidly create social\ncollaboration culture and the discipline of turning social data into meaningful\ninsights to drive business decisions in real-time. Moreover, the paper\nemphasizes on developing composite offerings on social enterprise and Mobile\nnetworks that not only offer the value proposition in terms of financially\noriented results, but also help customer to maximize return on investment\n(ROI).\n",
        "pdf_link": "http://arxiv.org/pdf/1209.4894v1"
    },
    {
        "title": "Controlling and securing a Digital Home using Multiple Sensor Based\n  Perception system Integrated with Mobile and Voice technology",
        "authors": [
            "Avishek Ahmed",
            "Tanvir Ahmed",
            "Md. Samawat Ullah",
            "Md. Manirul Islam"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Fully controlled digital home had always been considered as a luxury of rich\npeople because of excessive cost to install the system. It is now within the\nreach of mass people with lots of inexpensive cool features. In this paper we\nhave designed and developed a very low cost, efficient and reliable Digital\nhome system. Fully Controlled Digital Home is no more a Luxury. Our proposed\nsystem made it affordable. We built a low-cost feature-rich Digital Home System\n(DHS). Digital Home System is combination of automated services i.e. Electronic\nDevice Controller, IR Security System, Web Desktop, Remote Video Surveillance\nSystem and Virtual Mobile by which we can control our home by avoiding old\nmanual processes e.g. our physical presence at home is optional. The System\nprovides some of the modern luxury & security features to us. Now we can\ncontrol Light, fan, AC or any electronic devices by voice command, Blue-tooth,\nGPRS or Website. To control the system remotely, GPRS connectivity is added. We\ncan also monitor our home from remote area by using Remote Video Surveillance\nSystem. This enables live video into mobile device of the digital home.\nMoreover, we can also access our PC and do the necessary tasks from any\ninternet enabled computer in the world by using Web Desktop which is specially\nbuilt for this purpose. Furthermore, access of unauthorized person in the home\nwill be notified by SMS & store the image of the person and also generate a\nvoice alarm. So that ensures the security of our valuable things. Also we can\nidentify and monitor the location of our valuable assets e.g. precious metals\nremotely. Finally, Virtual mobile application is a Universal mobile Driver by\nwhich we can exactly perform some same task e.g. Remote call, Phone book\naccess, SMS read-write of our mobile device from our new invented computer's\nvirtual mobile.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5420v1"
    },
    {
        "title": "Automatic Electric Meter Reading System: A Cost-Feasible Alternative\n  Approach In Meter Reading For Bangladesh Perspective Using Low-Cost Digital\n  Wattmeter And Wimax Technology",
        "authors": [
            "Tanvir Ahmed",
            "Md. Suzan Miah",
            "Md. Manirul Islam",
            "Md. Rakib Uddin"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Energy meter reading is a monotonous and an expensive task. Now the meter\nreader people goes to each meter and take the meter reading manually to issue\nthe bill which will later be entered in the billing software for billing and\npayment automation. If the manual meter reading and bill data entry process can\nbe automated then it would reduced the laborious task and financial wastage.\n\"Automatic Electric Meter Reading (AMR) System\" is a metering system that is to\nbe used for data collecting from the meter and processing the collected data\nfor billing and other decision purposes. In this paper we have proposed an\nautomatic meter reading system which is low cost, high performance, highest\ndata rate, highest coverage area and most appropriate for Bangladesh\nperspective. In this AMR system there are four basic units. They are reading\nunit, communication unit, data receiving and processing unit and billing\nsystem. For reading unit we identified the disk rotation of the energy meter\nand stored the data in microcontroller. So it is not required to change the\ncurrent analog energy meter. An external module will be added with the current\nenergy meter. In the communication unit Wimax transceiver was used for wireless\ncommunication between meter end and the server end because of its wide coverage\narea. In the data receiving and processing unit meter reading will be collected\nfrom the transceiver which is controlled by another microcontroller. There will\nbe a computer application that will take the data from the microcontroller.\nThis will also help to avoid any tampering or break down of energy meter. There\nare various AMR system exists all over the world. Those systems were analyzed\nand we found they are not feasible for Bangladesh.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5431v1"
    },
    {
        "title": "Secure electronic lock using pic 16f628a microcontroller",
        "authors": [
            "Muhanad Hayder Mohammed"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The proposed system implements the electronic embedded lock, its provides a\ngreat benefit over traditional lock, which use the manual key, so if the key\nlost or theft then anybody could open the lock, while thieving or losing the\nlong and complex password is harder compare to traditional key, furthermore\ncombining both manual key with computerized password make the system more\nsecure. Long password will reduce the possibilities of breaking the code and\nopening the lock. The system comprised keypad, and HD44780 20x2 LCD Along with\nPIC16f628a microcontroller. The firmware control these components such that\ninteraction with keypad is very is ver easy and smoothly, the LCD provide user\nwith messages and notification to be informed about what is the system state.\nUser can performing opening and closing the lock, changing the current password\nin the microcontroller EEPROM and clearing single digit while entering the\npassword when wrong digit entered (back space). The proposed system firmware\ndeveloped using assembly language with MPLAB development environment. It tested\nand implemented in real hardware with proper functioning and bug free.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5435v1"
    },
    {
        "title": "A Tutorial for Creating and Publishing Open Source Lisp Software",
        "authors": [
            "Robert Smith"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The proliferation and accessability of the Internet have made it simple to\nview, download, and publish source code. This paper gives a short tutorial on\nhow to create a new Common Lisp project and publish it.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5626v1"
    },
    {
        "title": "Smart Charging Technologies for Portable Electronic Devices",
        "authors": [
            "Stefan Hild",
            "Sean Leavey",
            "Christian Grf",
            "Borja Sorazu"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this article we describe our efforts of extending demand-side control\nconcepts to the application in portable electronic devices, such as laptop\ncomputers, mobile phones and tablet computers. As these devices feature\nbuilt-in energy storage (in the form of batteries) and the ability to run\ncomplex control routines, they are ideal for the implementation of smart\ncharging concepts. We developed a prototype of a smart laptop charger that\ncontrols the charging process depending on the locally measured frequency of\nthe electricity grid. If this technique is incorporated into millions of\ndevices in UK households, this will contribute significantly to the stability\nof the electricity grid, help to mitigate the power production fluctuations\nfrom renewable energy sources and avoid the high cost of building and\nmaintaining conventional power plants as standby reserve.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.5931v2"
    },
    {
        "title": "Vulnerability Management for an Enterprise Resource Planning System",
        "authors": [
            "Shivani Goel",
            "Ravi Kiran",
            "Deepak Garg"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Enterprise resource planning (ERP) systems are commonly used in technical\neducational institutions(TEIs). ERP systems should continue providing services\nto its users irrespective of the level of failure. There could be many types of\nfailures in the ERP systems. There are different types of measures or\ncharacteristics that can be defined for ERP systems to handle the levels of\nfailure. Here in this paper, various types of failure levels are identified\nalong with various characteristics which are concerned with those failures. The\nrelation between all these is summarized. The disruptions causing\nvulnerabilities in TEIs are identified .A vulnerability management cycle has\nbeen suggested along with many commercial and open source vulnerability\nmanagement tools. The paper also highlights the importance of resiliency in ERP\nsystems in TEIs.\n",
        "pdf_link": "http://arxiv.org/pdf/1209.6484v1"
    },
    {
        "title": "Using Raspberry Pi for scientific video observation of pedestrians\n  during a music festival",
        "authors": [
            "Daniel H. Biedermann",
            "Felix Dietrich",
            "Oliver Handel",
            "Peter M. Kielar",
            "Michael Seitz"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The document serves as a reference for researchers trying to capture a large\nportion of a mass event on video for several hours, while using a very limited\nbudget.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.00217v1"
    },
    {
        "title": "Building a Decision Tree Model for Academic Advising Affairs Based on\n  the Algorithm C 4-5",
        "authors": [
            "Mohammed Al-Sarem"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The ability to recognize students weakness and solve any problem that may\nconfront them in timely fashion is always a target for all educational\ninstitutions. Thus, colleges and universities implement the so-called academic\nadvising affairs. On the academic advisor relies the responsibility of solving\nany problem that may confront students learning progress. This paper shows how\nthe adviser can benefit from data mining techniques, namely decision trees\ntechniques. The C 4.5 algorithm is used as a method for building such trees.\nThe output is evaluated based on the accuracy measure, Kappa measure, and ROC\narea. The difference between the registered and gained credit hours is\nconsidered as the main attribute on which advisor can rely\n",
        "pdf_link": "http://arxiv.org/pdf/1511.04026v1"
    },
    {
        "title": "Preprint WebVRGIS Based Traffic Analysis and Visualization System",
        "authors": [
            "Xiaoming Li",
            "Zhihan Lv",
            "Weixi Wang",
            "Baoyun Zhang",
            "Jinxing Hu",
            "Ling Yin",
            "Shengzhong Feng"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This is the preprint version of our paper on Advances in Engineering\nSoftware. With several characteristics, such as large scale, diverse\npredictability and timeliness, the city traffic data falls in the range of\ndefinition of Big Data. A Virtual Reality GIS based traffic analysis and\nvisualization system is proposed as a promising and inspiring approach to\nmanage and develop traffic big data. In addition to the basic GIS interaction\nfunctions, the proposed system also includes some intelligent visual analysis\nand forecasting functions. The passenger flow forecasting algorithm is\nintroduced in detail.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.06313v1"
    },
    {
        "title": "Analysis of SVN Repositories for Remote Access",
        "authors": [
            " Sadaf",
            "Safeeullah Soomro",
            "Suhni Abbasi"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Software Evolution is considered to be essential and challenging\ncharacteristic in the field of software engineering. Version control system is\nan incremental versions tracking system, introduced to avoid unnecessary\noverwriting of files such as programming code, web pages and records. It also\nhelps to decrease the confusion affected by duplicate or outdated data. In this\nproposed research SVN repository is maintained and analyzed for\nmsitone.wikispaces.com to minimize the efforts as well as resources for the\nfuture users. We have used two semester data for the analysis purpose that is\nobserved SVN repository. The result shows that, implementing the SVN\nrepositories are helpful for maintenance of the Wikispaces as it also reduce\nthe cost, time and efforts for their evolution. Whereas without implementing\nthe SVN repositories Wikispaces were just supposed to be building the house by\nputting each brick from start.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.06722v1"
    },
    {
        "title": "WLAN Specific IoT Enable Power Efficient RAM Design on 40nm FPGA",
        "authors": [
            "Tanesh Kumar",
            "Faizan Khan",
            "Safeeullah Soomro",
            "Areez Khalil Memon"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Increasing the speed of computer is one of the important aspects of the\nRandom Access Memory (RAM) and for better and fast processing it should be\nefficient. In this work, the main focus is to design energy efficient RAM and\nit also can be accessed through internet. A 128-bit IPv6 address is added to\nthe RAM in order to control it via internet. Four different types of Low\nVoltage CMOS (LCVMOS) IO standards are used to make it low power under five\ndifferent WLAN frequencies is taken. At WLAN frequency 2.4GHz, there is maximum\npower reduction of 85% is achieved when LVCMOS12 is taken in place of LVCMOS25.\nThis design is implemented using Virtex-6 FPGA, Device xc6vlx75t and Package\nFF484\n",
        "pdf_link": "http://arxiv.org/pdf/1511.06759v1"
    },
    {
        "title": "Pairwise Comparisons Rating Scale Paradox",
        "authors": [
            "W. W. Koczkodaj"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This study demonstrates that incorrect data are entered into a pairwise\ncomparisons matrix for processing into weights for the data collected by a\nrating scale. Unprocessed rating scale data lead to a paradox. A solution to\nit, based on normalization, is proposed. This is an essential correction for\nvirtually all pairwise comparisons methods using rating scales. The\nillustration of the relative error currently, taking place, is discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.07540v2"
    },
    {
        "title": "moGrams: a network-based methodology for visualizing the set of\n  non-dominated solutions in multiobjective optimization",
        "authors": [
            "Krzysztof Trawiski",
            "Manuel Chica",
            "David P. Pancho",
            "Sergio Damas",
            "Oscar Cordn"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  An appropriate visualization of multiobjective non-dominated solutions is a\nvaluable asset for decision making. Although there are methods for visualizing\nthe solutions in the design space, they do not provide any information about\ntheir relationship. In this work, we propose a novel methodology that allows\nthe visualization of the non-dominated solutions in the design space and their\nrelationships by means of a network. The nodes represent the solutions in the\nobjective space, while the edges show the relationships between the solutions\nin the design space. Our proposal (called moGrams) thus provides a joint\nvisualization of both objective and design spaces. It aims at helping the\ndecision maker to get more understanding of the problem so that (s)he can\nchoose the more appropriate final solution. moGrams can be applied to any\nmulticriteria problem in which the solutions are related by a similarity\nmetric. Besides, the decision maker interaction is facilitated by modifying the\nnetwork based on the current preferences to obtain a clearer view. An\nexhaustive experimental study is performed using three multiobjective problems\nin order to show both the usefulness and versatility of moGrams. The results\nexhibit interesting characteristics of our methodology for visualizing and\nanalyzing solutions of multiobjective problems.\n",
        "pdf_link": "http://arxiv.org/pdf/1511.08178v1"
    },
    {
        "title": "A Generative Model for Non-Intrusive Load Monitoring in Commercial\n  Buildings",
        "authors": [
            "Simon Henriet",
            "Umut Simsekli",
            "Benoit Fuentes",
            "Gal Richard"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In the recent years, there has been an increasing academic and industrial\ninterest for analyzing the electrical consumption of commercial buildings.\nWhilst having similarities with the Non Intrusive Load Monitoring (NILM) tasks\nfor residential buildings, the nature of the signals that are collected from\nlarge commercial buildings introduces additional difficulties to the NILM\nresearch causing existing NILM approaches to fail. On the other hand, the\namount of publicly available datasets collected from commercial buildings is\nvery limited, which makes the NILM research even more challenging for this type\nof large buildings. In this study, we aim at addressing these issues. We first\npresent an extensive statistical analysis of both commercial and residential\nmeasurements from public and private datasets and show important differences.\nSecondly, we develop an algorithm for generating synthetic current waveforms.\nWe then demonstrate using real measurement and quantitative metrics that both\nour device model and our simulations are realistic and can be used to evaluate\nNILM algorithms. Finally, to encourage research on commercial buildings we\nrelease a synthesized dataset.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.00515v1"
    },
    {
        "title": "Analysing the Potential of BLE to Support Dynamic Broadcasting Scenarios",
        "authors": [
            "Miran Bori",
            "Ana Fernndez Vilas",
            "Rebeca P. Daz Redondo"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  In this paper, we present a novel approach for broadcasting information based\non a Bluetooth Low Energy (BLE) ibeacon technology. We propose a dynamic method\nthat uses a combination of Wi-Fi and BLE technology where every technology\nplays a part in a user discovery and broadcasting process. In such system, a\nspecific ibeacon device broadcasts the information when a user is in proximity.\nUsing experiments, we conduct a scenario where the system discovers users,\ndisseminates information, and later we use collected data to examine the system\nperformance and capability. The results show that our proposed approach has a\npromising potential to become a powerful tool in the discovery and broadcasting\nconcept that can be easily implemented and used in business environments.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.02309v1"
    },
    {
        "title": "Automation of Processor Verification Using Recurrent Neural Networks",
        "authors": [
            "Martin Fajcik",
            "Marcela Zachariasova",
            "Pavel Smrz"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  When considering simulation-based verification of processors, the current\ntrend is to generate stimuli using pseudorandom generators (PRGs), apply them\nto the processor inputs and monitor the achieved coverage of its functionality\nin order to determine verification completeness. Stimuli can have different\nforms, for example, they can be represented by bit vectors applied to the input\nports of the processor or by programs that are loaded directly into the program\nmemory. In this paper, we propose a new technique dynamically altering\nconstraints for PRG via recurrent neural network, which receives a coverage\nfeedback from the simulation of design under verification. For the\ndemonstration purposes we used processors provided by Codasip as their coverage\nstate space is reasonably big and differs for various kinds of processors.\nNevertheless, techniques presented in this paper are widely applicable. The\nresults of experiments show that not only the coverage closure is achieved much\nsooner, but we are able to isolate a small set of stimuli with high coverage\nthat can be used for running regression tests.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.09810v1"
    },
    {
        "title": "A Framework for Detecting and Translating User Behavior from Smart Meter\n  Data",
        "authors": [
            "Egon Kidmose",
            "Emad Ebeid",
            "Rune Hylsberg Jacobsen"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The European adoption of smart electricity meters triggers the developments\nof new value-added service for smart energy and optimal consumption. Recently,\nseveral algorithms and tools have been built to analyze smart meter's data.\nThis paper introduces an open framework and prototypes for detecting and\npresenting user behavior from its smart meter power consumption data. The\nframework aims at presenting the detected user behavior in natural language\nreports. In order to validate the proposed framework, an experiment has been\nperformed and the results have been presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.03111v1"
    },
    {
        "title": "Towards a Circular Economy via Intelligent Metamaterials",
        "authors": [
            "Christos Liaskos",
            "Ageliki Tsioliaridou",
            "Sotiris Ioannidis"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The present study proposes the use of intelligent metasurfaces in the design\nof products, as enforcers of circular economy principles. Intelligent\nmetasurfaces can tune their physical properties (electromagnetic, acoustic,\nmechanical) by receiving software commands. When incorporated within products\nand spaces they can mitigate the resource waste caused by inefficient,\npartially optimized designs and security concerns. Thus, circular economy and\nfast-paced product design become compatible. The study begins by considering\nelectromagnetic metamaterials, and proposes a complete methodology for their\ndeployment. Finally, it is shown that the same principles can be extended to\nthe control of mechanical properties of objects, exemplary enabling the\nmicro-management of vibrations and heat, with unprecedented circular economy\npotential.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.06006v1"
    },
    {
        "title": "FluidDyn: a Python open-source framework for research and teaching in\n  fluid dynamics",
        "authors": [
            "Pierre Augier",
            "Ashwin Vishnu Mohanan",
            "Cyrille Bonamy"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  FluidDyn is a project to foster open-science and open-source in the fluid\ndynamics community. It is thought of as a research project to channel\nopen-source dynamics, methods and tools to do science. We propose a set of\nPython packages forming a framework to study fluid dynamics with different\nmethods, in particular laboratory experiments (package fluidlab), simulations\n(packages fluidfft, fluidsim and fluidfoam) and data processing (package\nfluidimage). In the present article, we give an overview of the specialized\npackages of the project and then focus on the base package called fluiddyn,\nwhich contains common code used in the specialized packages. Packages fluidfft\nand fluidsim are described with greater detail in two companion papers, Mohanan\net al. (2018a,b). With the project FluidDyn, we demonstrate that specialized\nscientific code can be written with methods and good practices of the\nopen-source community. The Mercurial repositories are available in Bitbucket\n(https://bitbucket.org/fluiddyn/). All codes are documented using Sphinx and\nRead the Docs, and tested with continuous integration run on Bitbucket,\nPipelines and Travis. To improve the reuse potential, the codes are as modular\nas possible, leveraging the simple object-oriented programming model of Python.\nAll codes are also written to be highly efficient, using C++, Cython and\nPythran to speedup the performance of critical functions.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.09224v1"
    },
    {
        "title": "Graph Compact Orthogonal Layout Algorithm",
        "authors": [
            "Karlis Freivalds",
            "Jans Glagolevs"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  There exist many orthogonal graph drawing algorithms that minimize edge\ncrossings or edge bends, however they produce unsatisfactory drawings in many\npractical cases. In this paper we present a grid-based algorithm for drawing\northogonal graphs with nodes of prescribed size. It distinguishes by creating\npleasant and compact drawings in relatively small running time. The main idea\nis to minimize the total edge length that implicitly minimizes crossings and\nmakes the drawing easy to comprehend. The algorithm is based on combining local\nand global improvements. Local improvements are moving each node to a new place\nand swapping of nodes. Global improvement is based on constrained quadratic\nprogramming approach that minimizes the total edge length while keeping node\nrelative positions.\n",
        "pdf_link": "http://arxiv.org/pdf/1807.09368v1"
    },
    {
        "title": "A Blockchain-based Educational Record Repository",
        "authors": [
            "Emanuel E. Bessa",
            "Joberto S. B. Martins"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The Blockchain technology was initially adopted to implement various\ncryptocurrencies. Currently, Blockchain is foreseen as a general purpose\ntechnology with a huge potential in many areas. Blockchain-based applications\nhave inherent characteristics like authenticity, immutability and consensus.\nBeyond that, records stored on Blockchain ledger can be accessed any time and\nfrom any location. Blockchain has a great potential for managing and\nmaintaining educational records. This paper presents a Blockchain-based\nEducational Record Repository (BcER2) that manages and distributes educational\nassets for academic and industry professionals. The BcER2 system allows\neducational records like e-diplomas and e-certificates to be securely and\nseamless transferred, shared and distributed by parties.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.00315v1"
    },
    {
        "title": "Grounds for trust: Essential Epistemic Opacity and Computational\n  Reliabilism",
        "authors": [
            "Juan M. Durn",
            "Nico Formanek"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Several philosophical issues in connection with computer simulations rely on\nthe assumption that results of simulations are trustworthy. Examples of these\ninclude the debate on the experimental role of computer simulations\n\\cite{Parker2009, Morrison2009}, the nature of computer data\n\\cite{Barberousse2013, Humphreys2013}, and the explanatory power of computer\nsimulations \\cite{Krohs2008, Duran2017}. The aim of this article is to show\nthat these authors are right in assuming that the results of computer\nsimulations are to be trusted when computer simulations are reliable processes.\nAfter a short reconstruction of the problem of \\textit{epistemic opacity}, the\narticle elaborates extensively on \\textit{computational reliabilism}, a\nspecified form of process reliabilism with computer simulations located at the\ncenter. The article ends with a discussion of four sources for computational\nreliabilism, namely, verification and validation, robustness analysis for\ncomputer simulations, a history of (un)successful implementations, and the role\nof expert knowledge in simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.01052v1"
    },
    {
        "title": "Computer simulations in science and engineering - Concepts - Practices -\n  Perspectives",
        "authors": [
            "Juan M. Durn"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The ubiquitous presence of computer simulations in all kinds of research\nareas evidence their role as the new driving force for the advancement of\nscience and engineering research. Nothing seems to escape the image of success\nthat computer simulations project onto the research community and the general\npublic. One simple way to illustrate this consists of asking ourselves how\nwould contemporary science and engineering look like without the use of\ncomputer simulations. The answer would certainly diverge from the current image\nwe have of scientific and engineering research.\n  As much as computer simulations are successful, they are also methods that\nfail in their purpose of inquiring about the world; and as much as researchers\nmake use of them, computer simulations raise important questions that are at\nthe heart of contemporary science and engineering practice. In this respect,\ncomputer simulations make a fantastic subject of research for the natural\nsciences, the social sciences, engineering and, as in our case, also for\nphilosophy. Studies on computer simulations touch upon many different facets of\nscientific and engineering research and evoke philosophically inclined\nquestions of interpretation with close ties to problems in experimental\nsettings and engineering applications (...)\n",
        "pdf_link": "http://arxiv.org/pdf/1904.01053v1"
    },
    {
        "title": "Varying the explanatory span: scientific explanation for computer\n  simulations",
        "authors": [
            "Juan M. Durn"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  This article aims to develop a new account of scientific explanation for\ncomputer simulations. To this end, two questions are answered: what is the\nexplanatory relation for computer simulations? and what kind of epistemic gain\nshould be expected? For several reasons tailored to the benefits and needs of\ncomputer simulations, these questions are better answered within the\nunificationist model of scientific explanation. Unlike previous efforts in the\nliterature, I submit that the explanatory relation is between the simulation\nmodel and the results of the simulation. I also argue that our epistemic gain\ngoes beyond the unificationist account, encompassing a practical dimension as\nwell.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.01054v1"
    },
    {
        "title": "Teleporting digital images",
        "authors": [
            "Mario Mastriani"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  During the last 25 years the scientific community has coexisted with the most\nfascinating protocol due to Quantum Physics: quantum teleportation (QTele),\nwhich would have been impossible if quantum entanglement, so questioned by\nEinstein, did not exist. In this work, a complete architecture for the\nteleportation of Computational Basis States (CBS) is presented. Such CBS will\nrepresent each of the possible 24 classical bits commonly used to encode every\npixel of a 3-color-channel-image (red-green-blue, or cyan-yellow-magenta). For\nthis purpose, a couple of interfaces: classical-to-quantum (Cl2Qu) and\nquantum-to-classical (Qu2Cl) are presented with two versions of the\nteleportation protocol: standard and simplified.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.02066v7"
    },
    {
        "title": "Combining Conformance Checking and Classification of XES Log Data for\n  the Manufacturing Domain",
        "authors": [
            "Matthias Ehrendorfer",
            "Juergen-Albrecht Fassmann",
            "Juergen Mangler",
            "Stefanie Rinderle-Ma"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Currently, data collection on the shop floor is based on individual resources\nsuch as machines, robots, and Autonomous Guided Vehicles (AGVs). There is a gap\nbetween this approach and manufacturing orchestration software that supervises\nthe process of creating single products and controls the ressources'\ninteractions. This creates the need to save resource-based data streams in\ndatabases, clean it, and then re-contextualize it, i.e., by connecting it to\norders, batches, and single products. Looking at this data from a\nprocess-oriented analysis point of view enables new analysis prospects. This\npaper utilises these prospects in an experimental way by creating BPMN models\nfor the manufacturing of two real-world products: (1) a low volume, high\ncomplexity lower-housing for a gas-turbine and (2) a high volume, low\ncomplexity, small tolerance valve lifter for a gas turbine. In contrast to the\nresource-based data collection, 30+ values are modeled into the BPMN models and\nenacted by a workflow engine, creating execution logs in the XES standard\nformat. Conformance checks are carried out and interpreted for both scenarios\nand it is shown how existing classification and clustering techniques can be\napplied on the collected data in order to predict good and bad parts, ex-post\nand potentially at run-time.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.05883v1"
    },
    {
        "title": "Evaluation of IoT-Based Computational Intelligence Tools for DNA\n  Sequence Analysis in Bioinformatics",
        "authors": [
            "Zainab Alansari",
            "Nor Badrul Anuar",
            "Amirrudin Kamsin",
            "Safeeullah Soomro",
            "Mohammad Riyaz Belgaum"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In contemporary age, Computational Intelligence (CI) performs an essential\nrole in the interpretation of big biological data considering that it could\nprovide all of the molecular biology and DNA sequencing computations. For this\npurpose, many researchers have attempted to implement different tools in this\nfield and have competed aggressively. Hence, determining the best of them among\nthe enormous number of available tools is not an easy task, selecting the one\nwhich accomplishes big data in the concise time and with no error can\nsignificantly improve the scientist's contribution in the bioinformatics field.\nThis study uses different analysis and methods such as Fuzzy, Dempster-Shafer,\nMurphy and Entropy Shannon to provide the most significant and reliable\nevaluation of IoT-based computational intelligence tools for DNA sequence\nanalysis. The outcomes of this study can be advantageous to the bioinformatics\ncommunity, researchers and experts in big biological data.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.09268v1"
    },
    {
        "title": "The Rise of Internet of Things (IoT) in Big Healthcare Data: Review and\n  Open research Issues",
        "authors": [
            "Zainab Alansari",
            "Safeeullah Soomro",
            "Mohammad Riyaz Belgaum",
            "Shahaboddin Shamshirband"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Health is one of the sustainable development areas in all of the countries.\nInternet of Things has a variety of use in this sector which was not studied\nyet. The aim of this research is to prioritize IoT usage in the healthcare\nsector to achieve sustainable development. The study is an applied descriptive\nresearch according to data collection. As per the research methodology which is\nFAHP, it is a single cross sectional survey research. After data collection,\nthe agreed paired comparison matrices, allocated to weighted criteria and the\npriority of IoT usage were determined. Based on the research findings, the two\ncriteria of Economic Prosperity and Quality of Life achieved the highest\npriority for IoT sustainable development in the healthcare sector. Moreover,\nthe top priorities for IoT in the area of health, according to the usage, were\nidentified as Ultraviolet Radiation, Dental Health and Fall Detection.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.09270v1"
    },
    {
        "title": "A Review on Energy Consumption Optimization Techniques in IoT Based\n  Smart Building Environments",
        "authors": [
            "Abdul Salam Shah",
            "Haidawati Nasir",
            "Muhammad Fayaz",
            "Adidah Lajis",
            "Asadullah Shah"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In recent years, due to the unnecessary wastage of electrical energy in\nresidential buildings, the requirement of energy optimization and user comfort\nhas gained vital importance. In the literature, various techniques have been\nproposed addressing the energy optimization problem. The goal of each technique\nwas to maintain a balance between user comfort and energy requirements such\nthat the user can achieve the desired comfort level with the minimum amount of\nenergy consumption. Researchers have addressed the issue with the help of\ndifferent optimization algorithms and variations in the parameters to reduce\nenergy consumption. To the best of our knowledge, this problem is not solved\nyet due to its challenging nature. The gap in the literature is due to the\nadvancements in the technology and drawbacks of the optimization algorithms and\nthe introduction of different new optimization algorithms. Further, many newly\nproposed optimization algorithms which have produced better accuracy on the\nbenchmark instances but have not been applied yet for the optimization of\nenergy consumption in smart homes. In this paper, we have carried out a\ndetailed literature review of the techniques used for the optimization of\nenergy consumption and scheduling in smart homes. The detailed discussion has\nbeen carried out on different factors contributing towards thermal comfort,\nvisual comfort, and air quality comfort. We have also reviewed the fog and edge\ncomputing techniques used in smart homes.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.09821v1"
    },
    {
        "title": "New-Generation Design-Technology Co-Optimization (DTCO):\n  Machine-Learning Assisted Modeling Framework",
        "authors": [
            "Zhe Zhang",
            "Runsheng Wang",
            "Cheng Chen",
            "Qianqian Huang",
            "Yangyuan Wang",
            "Cheng Hu",
            "Dehuang Wu",
            "Joddy Wang",
            "Ru Huang"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In this paper, we propose a machine-learning assisted modeling framework in\ndesign-technology co-optimization (DTCO) flow. Neural network (NN) based\nsurrogate model is used as an alternative of compact model of new devices\nwithout prior knowledge of device physics to predict device and circuit\nelectrical characteristics. This modeling framework is demonstrated and\nverified in FinFET with high predicted accuracy in device and circuit level.\nDetails about the data handling and prediction results are discussed. Moreover,\nsame framework is applied to new mechanism device tunnel FET (TFET) to predict\ndevice and circuit characteristics. This work provides new modeling method for\nDTCO flow.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.10269v1"
    },
    {
        "title": "An adaptive architecture for portability of greenhouse models",
        "authors": [
            "Luis Miranda",
            "Guido Schillaci"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  This work deals with the portability of greenhouse models, as we believe that\nthis is a challenge to their practical usage in control strategies under\nproduction conditions. We address this task by means of adaptive neural\nnetworks, which re-adjust their weights when transferred to new conditions.\nSuch an adaptive account for computational models is typical of the field of\ndevelopmental robotics, which investigates learning of motor control in\nartificial systems inspired on infants development. Similarly to robots,\ngreenhouses are complex systems comprising technical and biological elements,\nwhose state can be measured and modified through control actions. We present an\nadaptive model architecture to perform online learning on greenhouse models.\nThis learning process makes use of an episodic memory and of online\nre-training. This allows for adaptation without the need for a complete new\ntraining, which might be prohibitive if the data under the new conditions is\nscarce. Current experiments focus on how a model of tomato photosynthesis,\ndeveloped in a research facility, can adapt itself to a new environment in a\nproduction greenhouse. Further research will focus on model plasticity by means\nof adaptive learning rates and management of the episodic memory described in\nthis paper. The models presented as a proof-of-concept estimate the\ntranspiration and photosynthesis of a hydroponic tomato crop by using\nmeasurements of the climate as inputs. The models are trained and tested using\ndata from a greenhouse in Berlin, Germany. Thereafter, the adaptive\narchitecture is fed with data from a production greenhouse in southern Germany,\nwhere other tomato varieties were grown under different irrigation and climate\nstrategies. The proposed adaptive architecture represents a promising tool for\nspreading the use of models produced by high-tech research centers to the\ngreenhouse production sector.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.01643v2"
    },
    {
        "title": "Modelagem de um Problema de Dimensionamento de Lotes com Demanda\n  Variavel e Deterministica e Efeitos de Learning e Forgetting",
        "authors": [
            "Pedro Cesar Lopes Gerum"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The main goal of this paper was to analyze the importance that the effects of\nlearning and forgetting might have in a lot-sizing problem. It assumes that the\nlearning curve and the economies of scale are present in several industries yet\nare, in most cases, not considered when dealing with a lot-sizing problem. The\nimportance of the effects was demonstrated and quantified, showing that there\nis still space for developments in this field. However, as the problem becomes\nquadratic, there is a possibility that the current algorithms are not able to\nsolve the problem to optimality. Thus, future improvements in the algorithms\nmay further improve the results. However, the overall results found with\ncurrent algorithms show that the contribution of a discount from a learning\ncurve can be very considerable, even if it is a minimal amount.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.10293v1"
    },
    {
        "title": "Real-time stock analysis for blending recipes in industrial plants",
        "authors": [
            "Florin Zamfir",
            "Nicolae Paraschiv",
            "Emil Pricop"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Many companies use Excel spreadsheets to keep stock records and to calculate\nprocess-specific data. These spreadsheets are often hard to understand and\ntrack. And if the user does not protect them, there is a risk that the user\nrandomly changes or erase formulas. The paper focuses on the stocks of products\nused in a blending process with a known recipe. Developing an application that\ncan bring this data in a centralized form and that can assist the operator in\ndecide is a necessity. When a programmer implements an application that uses\ndata from plants he needs to consider one fundamental aspect as reading\nreal-time data from the process. The real-time stock analysis application takes\ninto account all the above elements. The application is easy to use by an\noperator in the command room of installation because of the planning algorithms\nintegrated into it. The algorithms proposed and implemented in this paper have\nwell-defined goals: identifying the ingredients needed to achieve the blending\nprocess for required quantities, determine the quantities of the finished\nproduct that can be made with the existing ingredients and determine the\noptimum quantities of the finished product. The application implemented in C#\nintensively uses these algorithms and gives the user the ability to build the\nresult step by step.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.02960v1"
    },
    {
        "title": "Stochastic model of business process decomposition",
        "authors": [
            "Grigory Tsiperman"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Decomposition is the basis of works dedicated to business process modelling\nat the stage of information and management systems analysis and design. The\narticle shows that the business process decomposition can be represented as a\nGalton Watson branching stochastic process. This representation allows\nestimating the decomposition tree depth and the total amount of its elements,\nas well as explaining the empirical requirement for the business function\ndecomposition (not more than 7 elements). The problem is deemed relevant as the\nobtained results allow objectively estimating the labor input in business\nprocess modelling.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.09954v1"
    },
    {
        "title": "BinarySDG: binary sensor data generation with R",
        "authors": [
            "Marco Piangerelli",
            "Giacomo Rocchetti",
            "Alessandro Liscio",
            "Renato De Leone"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The scarcity of Smart Home data is still a pretty big problem, and in a world\nwhere the size of a dataset can often make the difference between a poor\nperformance and a good performance for problems related to machine learning\nprojects, this needs to be resolved. But whereas the problem of retrieving real\ndata can't really be resolved, as most of the time the process of installing\nsensors and retrieving data can be found to be really expensive and\ntime-consuming, we need to find a faster and easier solution, which is where\nsynthetic data comes in. Here we propose BinarySDG (Binary Synthetic Data\nGenerator) as a flexible and easy way to generate synthetic data for binary\nsensors.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.10308v1"
    },
    {
        "title": "Exact Calculation of Expected Values for Splitting Pairs in Blackjack",
        "authors": [
            "John A. Nairn"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Computer calculations for most exact expected values in blackjack have been\navailable since the 1960's, but exact results for pair splitting and\nresplitting have previously been too computer intensive. This paper describes a\nnew algorithm for exact pair-splitting. By using dealer probability caching\nmethods and revising the method for recursively generating possible player\nhands, the estimated calculation time compared to standard methods was reduced\nby five orders of magnitude. The resulting algorithm was used to calculate the\nfirst exact and complete pair splitting results for a single deck game. The\nexact results were compared to prior approximate theories for resplitting. The\nprior theories are accurate for many calculations, but inaccurate for\nresplitting tens. A new approximation method was developed that is accurate for\nall resplitting calculations.\n",
        "pdf_link": "http://arxiv.org/pdf/1909.13710v1"
    },
    {
        "title": "Fast Safety Assessment and Correction Framework for Maintenance Work\n  Zones",
        "authors": [
            "Zhepu Xu",
            "Qun Yang"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  A framework is proposed to assess the safety of maintenance work zones in a\ntimely manner, show whether there are safety hazards, whether adjustments need\nto be made and how to adjust it. By means of advanced data acquisition\ntechnologies such as multi video detection and portable device based\nnaturalistic driving, the microscopic vehicle behaviour data can be collected.\nBased on this data, a method for expressing and displaying the distribution of\nunsafe vehicle behaviour is used to show whether safety hazards exist. Using\nVissim, the impacts of the length and speed limit of the warning area, the\nlength and type of the upstream transition area and the length of the work area\nof the maintenance work zone on the distribution of unsafe vehicle behaviour\nare simulated to establish the safety correction matrix, which can tell\nmaintenance departments the direction of adjustment when safety hazards exist\nin maintenance work zones.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.01179v1"
    },
    {
        "title": "Priority Quality Attributes for Engineering AI-enabled Systems",
        "authors": [
            "Lena Pons",
            "Ipek Ozkaya"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Deploying successful software-reliant systems that address their mission\ngoals and user needs within cost, resource, and expected quality constraints\nrequire design trade-offs. These trade-offs dictate how systems are structured\nand how they behave and consequently can effectively be evolved and sustained.\nSoftware engineering practices address this challenge by centering system\ndesign and evolution around delivering key quality attributes, such as\nsecurity, privacy, data centricity, sustainability, and explainability. These\nconcerns are more urgent requirements for software-reliant systems that also\ninclude AI components due to the uncertainty introduced by data elements.\nMoreover, systems employed by the public sector exhibit unique design time and\nruntime challenges due to the regulatory nature of the domains. We assert that\nthe quality attributes of security, privacy, data centricity, sustainability,\nand explainability pose new challenges to AI engineering and will drive the\nsuccess of AI-enabled systems in the public sector. In this position paper, we\nenumerate with examples from healthcare domain concerns related to these\nrequirements to mitigate barriers to architecting and fielding AI-enabled\nsystems in the public sector.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.02912v1"
    },
    {
        "title": "Business Process Variant Analysis: Survey and Classification",
        "authors": [
            "Farbod Taymouri",
            "Marcello La Rosa",
            "Marlon Dumas",
            "Fabrizio Maria Maggi"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Process variant analysis aims at identifying and addressing the differences\nexisting in a set of process executions enacted by the same process model. A\nprocess model can be executed differently in different situations for various\nreasons, e.g., the process could run in different locations or seasons, which\ngives rise to different behaviors. Having intuitions about the discrepancies in\nprocess behaviors, though challenging, is beneficial for managers and process\nanalysts since they can improve their process models efficiently, e.g., via\ninteractive learning or adapting mechanisms. Several methods have been proposed\nto tackle the problem of uncovering discrepancies in process executions.\nHowever, because of the interdisciplinary nature of the challenge, the methods\nand sorts of analysis in the literature are very heterogeneous. This article\nnot only presents a systematic literature review and taxonomy of methods for\nvariant analysis of business processes but also provides a methodology\nincluding the required steps to apply this type of analysis for the\nidentification of variants in business process executions.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.07582v2"
    },
    {
        "title": "Inflationary Constant Factors and Why Python is Faster Than C++",
        "authors": [
            "Mehrdad Niknami"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Constant-factor differences are frequently ignored when analyzing the\ncomplexity of algorithms and implementations, as they appear to be\ninsignificant in practice. In this paper, we demonstrate that this assumption\ncan in fact have far more profound implications on time complexity than is\nobvious at first glance, and that a poor consideration of trade-offs can result\nin polynomially slower algorithms whose roots can be deeply and fundamentally\ningrained into a programming language itself. While the general observation may\nnot be novel from a theoretical standpoint, it is rarely (if ever) presented in\ntraditional computer science curricula or other settings, and appears to be far\nfrom common knowledge in practical software engineering. We thus hope bring\nawareness to this issue and urge careful consideration of significant\ntrade-offs that can result from trivial decisions made while programming.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.12338v2"
    },
    {
        "title": "Generation of Complex Road Networks Using a Simplified Logical\n  Description for the Validation of Automated Vehicles",
        "authors": [
            "Daniel Becker",
            "Fabian Ru",
            "Christian Geller",
            "Lutz Eckstein"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Simulation is a valuable building block for the verification and validation\nof automated driving functions (ADF). When simulating urban driving scenarios,\nsimulation maps are one important component. Often, the generation of those\nroad networks is a time consuming and manual effort. Furthermore, typically\nmany variations of a distinct junction or road section are demanded to ensure\nthat an ADF can be validated in the process of releasing those functions to the\npublic. Therefore, in this paper, we present a prototypical solution for a\nlogical road network description which is easy to maintain and modify. The\nconcept aims to be non-redundant so that changes of distinct quantities do not\naffect other places in the code and thus the variation of maps is\nstraightforward. In addition, the simple definition of junctions is a focus of\nthe work. Intersecting roads are defined separately, are then set in relation\nand the junction is finally generated automatically. The idea is to derive the\ndescription from a commonly used, standardized format for simulation maps in\norder to generate this format from the introduced logical description.\nConsequently, we developed a command-line tool that generates the standardized\nsimulation map format OpenDRIVE.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.03403v1"
    },
    {
        "title": "Smart Motion Detection System using Raspberry Pi",
        "authors": [
            "Venkat Margapuri"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  This paper throws light on the security issues that modern day homes and\nbusinesses face and describes the implementation of a motion detection system\nusing Raspberry Pi which could be an effective solution to address the security\nconcerns. The goal of the solution is to provide an implementation that uses\nPIR motion sensors for motion detection and sends notifications to users via\nemails. Furthermore, the system is verified using a verification tool named\nUPPAAL.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.06442v1"
    },
    {
        "title": "The Metastable Behavior of a Schmitt-Trigger",
        "authors": [
            "Andreas Steininger",
            "Jrgen Maier",
            "Robert Najvirt"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Schmitt-Trigger circuits are the method of choice for converting general\nsignal shapes into clean, well-behaved digital ones. In this context these\ncircuits are often used for metastability handling, as well. However, like any\nother positive feedback circuit, a Schmitt-Trigger can become metastable\nitself. Therefore, its own metastable behavior must be well understood; in\nparticular the conditions that may cause its metastability. In this paper we\nwill build on existing results from Marino to show that (a) a monotonic input\nsignal can cause late transitions but never leads to a non-digital voltage at\nthe Schmitt-Trigger output, and (b) a non-monotonic input can pin the\nSchmitt-Trigger output to a constant voltage at any desired (also non-digital)\nlevel for an arbitrary duration. In fact, the output can even be driven to any\nwaveform within the dynamic limits of the system. We will base our analysis on\na mathematical model of a Schmitt-Trigger's dynamic behavior and perform SPICE\nsimulations to support our theory and confirm its validity for modern CMOS\nimplementations. Furthermore, we will discuss several use cases of a\nSchmitt-Trigger in the light of our results.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.08319v1"
    },
    {
        "title": "A Faithful Binary Circuit Model with Adversarial Noise",
        "authors": [
            "Matthias Fgger",
            "Jrgen Maier",
            "Robert Najvirt",
            "Thomas Nowak",
            "Ulrich Schmid"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Accurate delay models are important for static and dynamic timing analysis of\ndigital circuits, and mandatory for formal verification. However, F\\\"ugger et\nal. [IEEE TC 2016] proved that pure and inertial delays, which are employed for\ndynamic timing analysis in state-of-the-art tools like ModelSim, NC-Sim and\nVCS, do not yield faithful digital circuit models. Involution delays, which are\nbased on delay functions that are mathematical involutions depending on the\nprevious-output-to-input time offset, were introduced by F\\\"ugger et al.\n[DATE'15] as a faithful alternative (that can easily be used with existing\ntools). Although involution delays were shown to predict real signal traces\nreasonably accurately, any model with a deterministic delay function is\nnaturally limited in its modeling power. In this paper, we thus extend the\ninvolution model, by adding non-deterministic delay variations (random or even\nadversarial), and prove analytically that faithfulness is not impaired by this\ngeneralization. Albeit the amount of non-determinism must be considerably\nrestricted to ensure this property, the result is surprising: the involution\nmodel differs from non-faithful models mainly in handling fast glitch trains,\nwhere small delay shifts have large effects. This originally suggested that\nadding even small variations should break the faithfulness of the model, which\nturned out not to be the case. Moreover, the results of our simulations also\nconfirm that this generalized involution model has larger modeling power and,\nhence, applicability.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.08485v2"
    },
    {
        "title": "Artificial Buildings: Safety, Complexity and a Quantifiable Measure of\n  Beauty",
        "authors": [
            "Arash Mehrjou"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  A place to live is one of the most crucial necessities for all living\norganisms since the advent of life on planet Earth. The nature of homes has\nchanged considerably over time. At the very early stages, human begins lived in\nnatural places such as caves. Later on, they started to use their intelligence\nto build places with special purposes. Nowadays, modern technologies such as\nrobotics and artificial intelligence have made their ways into the construction\nprocess and opened up a whole new area of opportunities and concerns that may\nbe of interest to both technologists and philosophers. In this article, I\nreview the evolution of buildings from fully natural to fully artificial and\ndiscuss philosophical thoughts that a fully automated construction technology\nmay raise. I elaborate on the safety concerns of a fully automated\narchitectural process. Then, I'll borrow Kolmogorov complexity from algorithmic\ninformation theory to define a complexity measure for buildings. The proposed\nmeasure is then used to provide a quantifiable measure of beauty.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.11113v1"
    },
    {
        "title": "Run-Time Power Modelling in Embedded GPUs with Dynamic Voltage and\n  Frequency Scaling",
        "authors": [
            "Jose Nunez-Yanez",
            "Kris Nikov",
            "Kerstin Eder",
            "Mohammad Hosseinabady"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  This paper investigates the application of a robust CPU-based power modelling\nmethodology that performs an automatic search of explanatory events derived\nfrom performance counters to embedded GPUs. A 64-bit Tegra TX1 SoC is\nconfigured with DVFS enabled and multiple CUDA benchmarks are used to train and\ntest models optimized for each frequency and voltage point. These optimized\nmodels are then compared with a simpler unified model that uses a single set of\nmodel coefficients for all frequency and voltage points of interest. To obtain\nthis unified model, a number of experiments are conducted to extract\ninformation on idle, clock and static power to derive power usage from a single\nreference equation. The results show that the unified model offers competitive\naccuracy with an average 5\\% error with four explanatory variables on the test\ndata set and it is capable to correctly predict the impact of voltage,\nfrequency and temperature on power consumption. This model could be used to\nreplace direct power measurements when these are not available due to hardware\nlimitations or worst-case analysis in emulation platforms.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.12176v1"
    },
    {
        "title": "Environmental Impact of Bundling Transport Deliveries Using SUMO:\n  Analysis of a cooperative approach in Austria",
        "authors": [
            "Aso Validi",
            "Nicole Polasek",
            "Leonie Alabi",
            "Michael Leitner",
            "Cristina Olaverri-Monreal"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Urban Traffic is recognized as one of the major CO2 contributors that puts a\nhigh burden on the environment. Different attempts have been made for reducing\nthe impacts ranging from traffic management actions to shared-vehicle concepts\nto simply reducing the number of vehicles on the streets. By relying on\ncooperative approaches between different logistics companies, such as sharing\nand pooling resources for bundling deliveries in the same zone, an increased\nenvironmental benefit can be attained. To quantify this benefit we compare the\nCO2 emissions, fuel consumption and total delivery time resulting from\ndeliveries performed by one cargo truck with two trailers versus by two\nsingle-trailer cargo trucks under real conditions in a simulation scenario in\nthe city of Linz in Austria. Results showed a fuel consumption and CO2\nemissions reduction of 28% and 34% respectively in the scenario in which\nresources were bundled in one single truck.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.12965v2"
    },
    {
        "title": "Technical Report: Selective Imaging of File System Data on Live Systems",
        "authors": [
            "Fabian Faust",
            "Aurlien Thierry",
            "Tilo Mller",
            "Felix Freiling"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  In contrast to the common habit of taking full bitwise copies of storage\ndevices before analysis, selective imaging promises to alleviate the problems\ncreated by the increasing capacity of storage devices. Imaging is selective if\nonly selected data objects from an image that were explicitly chosen are\nincluded in the copied data. While selective imaging has been defined for\npost-mortem data acquisition, performing this process live, i.e., by using the\nsystem that contains the evidence also to execute the imaging software, is less\nwell defined and understood. We present the design and implementation of a new\nlive Selective Imaging Tool for Windows, called SIT, which is based on the DFIR\nORC framework and uses AFF4 as a container format. We discuss the rationale\nbehind the design of SIT and evaluate its effectiveness.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.02573v1"
    },
    {
        "title": "Analogy, Mind, and Life",
        "authors": [
            "Vitor Manuel Dinis Pereira"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  I'll show that the kind of analogy between life and information [argue for by\nauthors such as Davies (2000), Walker and Davies (2013), Dyson (1979), Gleick\n(2011), Kurzweil (2012), Ward (2009)], that seems to be central to the effect\nthat artificial mind may represents an expected advance in the life evolution\nin Universe, is like the design argument and that if the design argument is\nunfounded and invalid, the argument to the effect that artificial mind may\nrepresents an expected advance in the life evolution in Universe is also\nunfounded and invalid. However, if we are prepared to admit (though we should\nnot do) this method of reasoning as valid, I'll show that the analogy between\nlife and information to the effect that artificial mind may represents an\nexpected advance in the life evolution in Universe seems suggest some type of\nreductionism of life to information, but biology respectively chemistry or\nphysics are not reductionist, contrary to what seems to be suggested by the\nanalogy between life and information.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.13803v1"
    },
    {
        "title": "Designing a Binary Clock using logic gates",
        "authors": [
            "Jacob John"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Wristwatches have been a common fashion accessory addition for several\npeople. However, the concept of using a seven-segment digital display or\nsometimes, even an analog indicator hasn't changed for a number of years. This\nproject aims to test and design a binary clock, also referred to as 32, 16, 8,\n4, 2, 1 clock or even 8, 4, 2, 1 clock (due to their display configuration),\nthat could change this everlasting display for watches. Specifically, digital\nlogic and design engineers would find interest in this topic due to the\nsophistication involved in reading-out the time. This project will do so using\nby showing each decimal digit of sexagesimal time as a binary value. This\ndesign will be primarily functioning on logic gates and would involve the use\nof several basic components that include, but are not limited to, integrated\ncircuits (or ICs), Light-emitting diodes (LEDs), and resistors.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.02845v1"
    },
    {
        "title": "Practical application of the multi-model approach in the study of\n  complex systems",
        "authors": [
            "Anna V. Korolkova",
            "Dmitry S. Kulyabov",
            "Michal Hnati"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Different kinds of models are used to study various natural and technical\nphenomena. Usually, the researcher is limited to using a certain kind of model\napproach, not using others (or even not realizing the existence of other model\napproaches). The authors believe that a complete study of a certain phenomenon\nshould cover several model approaches. The paper describes several model\napproaches which we used in the study of the random early detection algorithm\nfor active queue management. Both the model approaches themselves and their\nimplementation and the results obtained are described.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.08153v1"
    },
    {
        "title": "Using Fault Injection on the Nanosatellite Subsystems Integration\n  Testing",
        "authors": [
            "Carlos Leandro Gomes Batista",
            "Andr Corsetti",
            "Ftima Mattiello-Francisco"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Since the 2000's, an increased number of nanosatellites have accessed space.\nHowever, studies show that the number of unsuccessful nanosatellite missions is\nvery expressive. Moreover, these statistics are correlated to poor verification\nand validation processes used by hobbyists satellite developers because major\nspace agencies keep high successful ratings even with small/nano satellites\nmissions due to its rigorous V\\&V processes. Aiming to improve payloads\nintegration testing of NanosatC-BR-2, a 2-U Cubesat based nanosatellite under\ndevelopment by INPE, the fault injection technique has been used. It is very\nuseful technique to test systems prototypes. We present the design and\nimplementation of a Failure Emulator Mechanism (FEM) on I2C communication bus\nfor testing the interaction among the NCBR2 subsystems, supporting\ninteroperability and robustness requirements verification. The FEM is modelled\nto work at the communication bus emulating eventual faults of the communicating\nsubsystems in the messages exchanged. Using an Arduino board for the FEM and NI\nLabView environment it is possible to program the mechanism to inject different\nfaults at the I2C bus during different operation modes. Based on a serial\narchitecture, the FEM will be able to intercept all messages and implement\ndifferent faults as service and timing faults. The FEM interface with the\ntester is designed in LabView environment. Control and observation facilities\nare available to generate and upload the faultload script to FEM Arduino board.\nThe proposed FEM architecture and its implementation are validated using two\nsubsystems under testing prototypes: the OnBoard Data Handling Computer and the\nLangmuir Probe NCBR2 payload. For this analysis purpose, the prototypes\nsimulate in two different Arduinos boards the expected behavior of each\nsubsystem in the communication.\n",
        "pdf_link": "http://arxiv.org/pdf/2102.11776v1"
    },
    {
        "title": "One-Time Pads from the Digits of Pi",
        "authors": [
            "Devlin Gualtieri"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  I present a method for generating one-time pads from the digits of pi.\nComputer code is given to generate such pads from passphrases in a method\nhaving an extremely low probability (<10^-53) of a successful discovery of the\none-time pads by a brute-force attack. The advantages and disadvantages of this\nmethod are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.08783v1"
    },
    {
        "title": "Predicting the Students Involvements and its Impacts on Learning\n  Outcomes Through Online Education During Covid-19",
        "authors": [
            "Muhammad Nadeem",
            "Faisal Bukhari",
            "Ali Hussain"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Everybody knows very well about the COVID-19 pandemic, lockdown, and its\nimpacts and effects on every field of life, from childhood to senior citizens,\nfrom local to global. The underlying research study focuses on students'\ninvolvement in online classes. This paper assesses the effect of the COVID-19\npandemic on the students' participation and involvement during online classes\ncompared to the physical classes, cheating behavior, health effects, and study\nstyles of the students of diverse degrees and age groups. This research study\ncontributes to the real problems and challenges that students faced during\nonline classes during the COVID-19 pandemic. The percentages of the students'\nresponses with different color schemes shown in Fig. 1, Fig. 2, Fig.3(a),\nFig.3(b) and Fig.4 are conveying powerful and meaningful insight. These figures\nand the results given in Table I and Table II indicate that most students are\nnot fully involved during online classes due to technical issues, remote\ndistance, etc. We applied the Test here because we do not have exact population\nmeans. We used ttest_1samp with default value 0 to compute the variables'\nstatistics and p-value. These values are minimal in favor of rejecting the null\nor H0 (hypothesis) and accepting the alternate or H1 (hypothesis). It further\nmeans that students' involvement during online classes is severely affected.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.00031v1"
    },
    {
        "title": "A Digital Delay Model Supporting Large Adversarial Delay Variations",
        "authors": [
            "Daniel hlinger",
            "Ulrich Schmid"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Dynamic digital timing analysis is a promising alternative to analog\nsimulations for verifying particularly timing-critical parts of a circuit. A\nnecessary prerequisite is a digital delay model, which allows to accurately\npredict the input-to-output delay of a given transition in the input signal(s)\nof a gate. Since all existing digital delay models for dynamic digital timing\nanalysis are deterministic, however, they cannot cover delay fluctuations\ncaused by PVT variations, aging and analog signal noise. The only exception\nknown to us is the $\\eta$-IDM introduced by F\\\"ugger et al. at DATE'18, which\nallows to add (very) small adversarially chosen delay variations to the\ndeterministic involution delay model, without endangering its faithfulness. In\nthis paper, we show that it is possible to extend the range of allowed delay\nvariations so significantly that realistic PVT variations and aging are covered\nby the resulting extended $\\eta$-IDM.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.09588v2"
    },
    {
        "title": "A Survey of Process-Oriented Data Science and Analytics for supporting\n  Business Process Management",
        "authors": [
            "Asjad Khan",
            "Aditya Ghose",
            "Hoa Dam",
            "Arsal Syed"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Process analytics approaches allow organizations to support the practice of\nBusiness Process Management and continuous improvement by leveraging all\nprocess-related data to extract knowledge, improve process performance and\nsupport decision-making across the organization. Process execution data once\ncollected will contain hidden insights and actionable knowledge that are of\nconsiderable business value enabling firms to take a data-driven approach for\nidentifying performance bottlenecks, reducing costs, extracting insights and\noptimizing the utilization of available resources. Understanding the properties\nof 'current deployed process' (whose execution trace is often available in\nthese logs), is critical to understanding the variation across the process\ninstances, root-causes of inefficiencies and determining the areas for\ninvesting improvement efforts. In this survey, we discuss various methods that\nallow organizations to understand the behaviour of their processes, monitor\ncurrently running process instances, predict the future behavior of those\ninstances and provide better support for operational decision-making across the\norganization.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10398v1"
    },
    {
        "title": "A Novel IoT-Based System for Ten Pin Bowling",
        "authors": [
            "Ilias Zosimadis",
            "Ioannis Stamelos"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Bowling is a target sport that is popular among all age groups with\nprofessionals and amateur players. Delivering an accurate and consistent\nbowling throw into the lane requires the incorporation of motion techniques.\nConsequently, this research presents a novel IoT-Cloud based system for\nproviding real-time monitoring and coaching services to bowling athletes. The\nsystem includes two inertial measurement units (IMUs) sensors for capturing\nmotion data, a mobile application and a cloud server for processing the data.\nFirst, the quality of each phase of a throw is assessed using a Dynamic Time\nWrapping (DTW) based algorithm. Second, an on device-level technique is\nproposed to identify common bowling errors. Finally, an SVM classification\nmodel is employed for assessing the skill level of bowler athletes. We\nrecruited nine right-handed bowlers to perform 50 throws wearing the two\nsensors and using the proposed system. The results of our experiments suggest\nthat the proposed system can effectively and efficiently assess the quality of\nthe throw, detect common bowling errors and classify the skill level of the\nbowler.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10523v1"
    },
    {
        "title": "Foundations and Scoping of Data Science",
        "authors": [
            "M. Tamer zsu"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  There has been an increasing recognition of the value of data and of\ndata-based decision making. As a consequence, the development of data science\nas a field of study has intensified in recent years. However, there is no\nsystematic and comprehensive treatment and understanding of data science. This\narticle describes a systematic and end-to-end framing of the field based on an\ninclusive definition. It identifies the core components making up the data\nscience ecosystem, presents its lifecycle modeling the development process, and\nargues its interdisciplinarity.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.13761v3"
    },
    {
        "title": "Methods and Techniques of Quality Management for ICT Audit Processes",
        "authors": [
            "Marius Popa"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In modern organizations, Information and Communication Technologies are used\nto support the organizations' activities. To manage the quality of the\norganization processes, audit processes are implemented. Also, the audit\nprocesses can aim the quality of ICT systems themselves because their\ninvolvement in organization processes. The paper investigates the ways in which\na quality management can be applied for audit processes in order to obtain a\nhigh level of quality for the audit recommendations.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.0395v1"
    },
    {
        "title": "Compressed Beamforming Applied to B-Mode Ultrasound Imaging",
        "authors": [
            "Noam Wagner",
            "Yonina C. Eldar",
            "Arie Feuer",
            "Zvi Friedman"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Emerging sonography techniques often imply increasing in the number of\ntransducer elements involved in the imaging process. Consequently, larger\namounts of data must be acquired and processed by the beamformer. The\nsignificant growth in the amounts of data effects both machinery size and power\nconsumption. Within the classical sampling framework, state of the art systems\nreduce processing rates by exploiting the bandpass bandwidth of the detected\nsignals. It has been recently shown, that a much more significant sample-rate\nreduction may be obtained, by treating ultrasound signals within the Finite\nRate of Innovation framework. These ideas follow the spirit of Xampling, which\ncombines classic methods from sampling theory with recent developments in\nCompressed Sensing. Applying such low-rate sampling schemes to individual\ntransducer elements, which detect energy reflected from biological tissues, is\nlimited by the noisy nature of the signals. This often results in erroneous\nparameter extraction, bringing forward the need to enhance the SNR of the\nlow-rate samples. In our work, we manage to achieve such SNR enhancement, by\nbeamforming the sub-Nyquist samples obtained from multiple elements. We refer\nto this process as \"compressed beamforming\". Applying it to cardiac ultrasound\ndata, we successfully image macroscopic perturbations, while achieving a nearly\neight-fold reduction in sample-rate, compared to standard techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1200v1"
    },
    {
        "title": "Transparent caching of virtual stubs for improved performance in\n  ubiquitous environments",
        "authors": [
            "Lachhman Das Dhomeja",
            "Yasir Arfat Malkani",
            "Asad Ali Shaikh",
            "Ayaz Keerio"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Context-awareness is an essential requirement for pervasive computing\napplications, which enables them to adapt and perform tasks based on context.\nOne of the adaptive features of context-awareness is contextual\nreconfiguration. Contextual reconfiguration involves discovering remote\nservice(s) based on context and binding them to the application components to\nrealize new behaviors, which may be needed to satisfy user needs or to enrich\nuser experience. One of the steps in the reconfiguration process involves a\nremote lookup to discover the service(s) based on context. This remote lookup\nprocess provides the largest contribution to reconfiguration time and this is\ndue to fact that the remote calls are much slower than local calls.\nConsequently, it affects system performance. In pervasive computing\napplications, this may turn out to be undesirable in terms of user experience.\nMoreover, other distributed applications using the network may be affected as\nevery remote method call decreases the amount of bandwidth available on the\nnetwork. Various systems provide reconfiguration support and offer high-level\nreconfiguration directives to develop adaptive context-aware applications, but\ndo not address this performance bottleneck. We address this issue and implement\nseamless caching of virtual stubs within our PCRA1 for improved performance. In\nthis paper we present and describe our transparent caching support and also\nprovide its performance evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1204v1"
    },
    {
        "title": "Single bit full adder design using 8 transistors with novel 3\n  transistors XNOR gate",
        "authors": [
            "Manoj Kumar",
            "Sandeep K. Arya",
            "Sujata Pandey"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In present work a new XNOR gate using three transistors has been presented,\nwhich shows power dissipation of 550.7272$\\mu$W in 0.35$\\mu$m technology with\nsupply voltage of 3.3V. Minimum level for high output of 2.05V and maximum\nlevel for low output of 0.084V have been obtained. A single bit full adder\nusing eight transistors has been designed using proposed XNOR cell, which shows\npower dissipation of 581.542$\\mu$W. Minimum level for high output of 1.97V and\nmaximum level for low output of 0.24V is obtained for sum output signal. For\ncarry signal maximum level for low output of 0.32V and minimum level for high\noutput of 3.2V have been achieved. Simulations have been performed by using\nSPICE based on TSMC 0.35$\\mu$m CMOS technology. Power consumption of proposed\nXNOR gate and full adder has been compared with earlier reported circuits and\nproposed circuit's shows better performance in terms of power consumption and\ntransistor count.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1966v1"
    },
    {
        "title": "Low Power Low Voltage Bulk Driven Balanced OTA",
        "authors": [
            "Neha Gupta",
            "Sapna Singh",
            "Meenakshi Suthar",
            "Priyanka Soni"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The last few decades, a great deal of attention has been paid to low-voltage\n(LV) low-power (LP) integrated circuits design since the power consumption has\nbecome a critical issue. Among many techniques used for the design of LV LP\nanalog circuits, the Bulk-driven principle offers a promising route towards\nthis design for many aspects mainly the simplicity and using the conventional\nMOS technology to implement these designs. This paper is devoted to the\nBulk-driven (BD) principle and utilizing this principle to design LV LP\nbuilding block of Operational Transconductance Amplifier (OTA) in standard CMOS\nprocesses and supply voltage 0.9V. The simulation results have been carried out\nby the Spice simulator using the 130nm CMOS technology from TSMC.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1970v1"
    },
    {
        "title": "Improvement of Anomoly Detection Algorithms in Hyperspectral Images\n  using Discrete Wavelet Transform",
        "authors": [
            "Mohsen Zare Baghbidi",
            "Kamal Jamshidi",
            "Ahmad Reza Naghsh Nilchi",
            "Saeid Homayouni"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Recently anomaly detection (AD) has become an important application for\ntarget detection in hyperspectral remotely sensed images. In many applications,\nin addition to high accuracy of detection we need a fast and reliable algorithm\nas well. This paper presents a novel method to improve the performance of\ncurrent AD algorithms. The proposed method first calculates Discrete Wavelet\nTransform (DWT) of every pixel vector of image using Daubechies4 wavelet. Then,\nAD algorithm performs on four bands of \"Wavelet transform\" matrix which are the\napproximation of main image. In this research some benchmark AD algorithms\nincluding Local RX, DWRX and DWEST have been implemented on Airborne\nVisible/Infrared Imaging Spectrometer (AVIRIS) hyperspectral datasets.\nExperimental results demonstrate significant improvement of runtime in proposed\nmethod. In addition, this method improves the accuracy of AD algorithms because\nof DWT's power in extracting approximation coefficients of signal, which\ncontain the main behaviour of signal, and abandon the redundant information in\nhyperspectral image data.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.2025v1"
    },
    {
        "title": "Fostering continuous innovation in design with an integrated knowledge\n  management approach",
        "authors": [
            "J. Xu",
            "Rmy Houssin",
            "Emmanuel Caillaud",
            "Mickal Gardoni"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In the global competition, companies are propelled by an immense pressure to\ninnovate. The trend to produce more new knowledge-intensive products or\nservices and the rapid progress of information technologies arouse huge\ninterest on knowledge management for innovation. However the strategy of\nknowledge management is not widely adopted for innovation in industries due to\na lack of an effective approach of their integration. This study aims to help\nthe designers to innovate more efficiently based on an integrated approach of\nknowledge management. Based on this integrated approach, a prototype of\ndistributed knowledge management system for innovation is developed. An\nindustrial application is presented and its initial results indicate the\napplicability of the approach and the prototype in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.2083v1"
    },
    {
        "title": "A New Design Technique of Reversible BCD Adder Based on NMOS With Pass\n  Transistor Gates",
        "authors": [
            "Md. Sazzad Hossain",
            "Md. Rashedul Hasan Rakib",
            "Md. Motiur Rahman",
            "A. S. M. Delowar Hossain",
            "Md. Minul Hasan"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper, we have proposed a new design technique of BCD Adder using\nnewly constructed reversible gates are based on NMOS with pass transistor\ngates, where the conventional reversible gates are based on CMOS with\ntransmission gates. We also compare the proposed reversible gates with the\nconventional CMOS reversible gates which show that the required number of\nTransistors is significantly reduced.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.2473v1"
    },
    {
        "title": "Improved Strategies for Enhanced Business Performance in Cloud based IT\n  Industries",
        "authors": [
            "T. R. Gopalakrishnan Nair",
            "M. Vaidehi",
            "V. Suma"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Emergence of sophisticated technologies in IT industries has posed several\nchallenges such as production of products using advanced technical process for\ninstance Result Orientation Approach, Deployment, Assessment and Refinement\n(RADAR) in a dynamic and competitive environment. The key challenge for any\nengineer is therefore to develop process and products which ultimately lead\ntowards total customer satisfaction. Recent development in technology has\ndriven most of the IT industries to operate in the cloud environment due to\nreduced infrastructure investment and maintenance overheads. However, existing\nprocess in cloud lacks efficient multiple service paradigms that can provide\nimproved business gain. Thus, it is the responsibility of every engineer to\ncontribute towards effective and efficient techniques and models that can\nenhance the business performance. The position of this paper is to present\nseveral major issues prevailing in the IT industries such as delay time,\nresponse time, performance etc., which call for immediate attention in order to\nposition themselves in the market. Further, this paper provides improved\nstrategies through efficient job scheduling and modified resource allocation\ntechniques for aforementioned issues in order to enhance the business\nperformance in cloud-based IT sectors. The simulated results provided in this\npaper indicate the impact of enhanced solutions incorporated in the job\nprocessing strategies. They further enable better performance of the cloud with\nreduced delay and response time resulting towards improved throughput.\nSubsequently, it increases the job acceptance ratio with respect to time and\nthereby leading the industry to accomplish total customer satisfaction in\naddition to the continued sustainability in the competitive business market.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.2508v2"
    },
    {
        "title": "A Genetic Algorithm for the Calibration of a Micro-Simulation Model",
        "authors": [
            "Omar Baqueiro Espinosa"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper describes the process followed to calibrate a micro-simulation\nmodel for the Altmark region in Germany and a Derbyshire region in the UK. The\ncalibration process is performed in three main steps: first, a subset of input\nand output variables to use for the calibration process is selected from the\ncomplete parameter space in the model; second, the calibration process is\nperformed using a genetic algorithm calibration approach; finally, a comparison\nbetween the real data and the data obtained from the best fit model is done to\nverify the accuracy of the model.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.3456v1"
    },
    {
        "title": "Construction of Learning Path Using Ant Colony Optimization from a\n  Frequent Pattern Graph",
        "authors": [
            "Souvik Sengupta",
            "Sandipan Sahu",
            "Ranjan Dasgupta"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In an e-Learning system a learner may come across multiple unknown terms,\nwhich are generally hyperlinked, while reading a text definition or theory on\nany topic. It becomes even harder when one tries to understand those unknown\nterms through further such links and they again find some new terms that have\nnew links. As a consequence they get confused where to initiate from and what\nare the prerequisites. So it is very obvious for the learner to make a choice\nof what should be learnt before what. In this paper we have taken the data\nmining based frequent pattern graph model to define the association and\nsequencing between the words and then adopted the Ant Colony Optimization, an\nartificial intelligence approach, to derive a searching technique to obtain an\nefficient and optimized learning path to reach to a unknown term.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.3976v1"
    },
    {
        "title": "Learners' Quanta based Design of a Learning Management System",
        "authors": [
            "Souvik Sengupta",
            "Nabendu Chaki",
            "Ranjan Dasgupta"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  In this paper IEEE Learning Technology System Architecture (LTSA) for LMS\nsoftware has been analyzed. It has been observed that LTSA is too abstract to\nbe adapted in a uniform way by LMS developers. A Learners' Quanta based high\nlevel design that satisfies the IEEE LTSA standard has been proposed for future\ndevelopment of efficient LMS software. A hybrid model of learning fitting into\nLTSA model has also been proposed while designing.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.3978v1"
    },
    {
        "title": "A comparison algorithm to check LTSA Layer 1 and SCORM compliance in\n  e-Learning sites",
        "authors": [
            "Souvik Sengupta",
            "Saurabh Pal",
            "Nilanjan Banerjee"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The success of e-Learning is largely dependent on the impact of its\nmultimedia aided learning content on the learner over the hyper media. The\ne-Learning portals with different proportion of multimedia elements have\ndifferent impact on the learner, as there is lack of standardization. The\nLearning Technology System Architecture (LTSA) Layer 1 deals with the effect of\nenvironment on the learner. From an information technology perspective it\nspecifies learner interaction from the environment to the learner via\nmultimedia content. Sharable Content Object Reference Model (SCROM) is a\ncollection of standards and specifications for content of web-based e-learning\nand specifies how JavaScript API can be used to integrate content development.\nIn this paper an examination is made on the design features of interactive\nmultimedia components of the learning packages by creating an algorithm which\nwill give a comparative study of multimedia component used by different\nlearning packages. The resultant graph as output helps us to analysis to what\nextent any LMS compliance LTSA layer 1 and SCORM specification.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.3981v1"
    },
    {
        "title": "The milling process monitoring using 3D envelope method",
        "authors": [
            "Claudiu-Florinel Bisu",
            "Alain Grard",
            "Miron Zapciu",
            "Olivier Cahuc"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper proposes a method to vibration analysis in order to on-line\nmonitoring of milling process quality. Adapting envelope analysis to\ncharacterize the milling tool materials is an important contribution to the\nqualitative and quantitative characterization of milling capacity and a step by\nmodeling the three-dimensional cutting process. An experimental protocol was\ndesigned and developed for the acquisition, processing and analyzing\nthree-dimensional signal. The vibration envelope analysis is proposed to detect\nthe cutting capacity of the tool with the optimization application of cutting\nparameters. The research is focused on Hilbert transform optimization to\nevaluate the dynamic behavior of the machine/ tool/workpiece.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.4442v1"
    },
    {
        "title": "New Approach of Envelope Dynamic Analysis for Milling Process",
        "authors": [
            "Claudiu-Florinel Bisu",
            "Miron Zapciu",
            "Alain Grard",
            "V. Vijelea",
            "Marin Anica"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This paper proposes a method to vibration analysis in order to on-line\nmonitoring of milling process quality. Adapting envelope analysis to\ncharacterize the milling tool materials is an important contribution to the\nqualitative and quantitative characterization of milling capacity and a step by\nmodeling the three-dimensional cutting process. An experimental protocol was\ndesigned and developed for the acquisition, processing and analyzing\nthree-dimensional signal. The vibration envelope analysis is proposed to detect\nthe cutting capacity of the tool with the optimization application of cutting\nparameters. The research is focused on FFT Fourier transform optimization of\nvibration analysis and vibration envelope to evaluate the dynamic behavior of\nthe machine/ tool/workpiece\n",
        "pdf_link": "http://arxiv.org/pdf/1201.4446v1"
    },
    {
        "title": "A Knowledge Engineering Method for New Product Development",
        "authors": [
            "Nicolas Perry",
            "Samar Ammar-Khodja"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Engineering activities involve large groups of people from different domains\nand disciplines. They often generate important information flows that are\ndifficult to manage. To face these difficulties, a knowledge engineering\nprocess is necessary to structure the information and its use. This paper\npresents a deployment of a knowledge capitalization process based on the\nenrichment of MOKA methodology to support the integration of Process Planning\nknowledge in a CAD System. Our goal is to help different actors to work\ncollaboratively by proposing one referential view of the domain, the context\nand the objectives assuming that it will help them in better decision-making.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.5009v1"
    },
    {
        "title": "Design and implementation of the Customer Experience Data Mart in the\n  Telecommunication Industry: Application Order-To-Payment end to end process",
        "authors": [
            "Mounire Benhima",
            "John P. Reilly",
            "Zaineb Naamane",
            "Meriam Kharbat",
            "Mohammed Issam Kabbaj",
            "Oussama Esqalli"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Facing the new market challenges, service providers are looking for solutions\nto improve three major business areas namely the Customer Experience, The\nOperational Efficiency and Revenue and Margin. To meet the business requiements\nrelated to these areas, service providers are going through three major\ntransformation programs namely the Business Support Systems transformation\nprogram for Customer related aspects, the Operations Support System\ntransformation program for mainly service Fulfillment and Assurance and\nResource, Fulfillment and Assurance, and Time To Market Transformation program\nfor Products ans Services development and management. These transformations are\nabout making a transition from a current situation with all its views to a\ndesired one. The information view transformation is about reorganizing and\nreengineering the existing information to be used for the day to day activities\nand reporting to support decision making. For reporting purpose, service\nproviders have to invest in Business Intelligence solutions. For which the main\npurpose is to provide the right information in a timely manner to efficiently\nsupport the decision making. One of the key BI challenges is to model an\ninformation structure where to host all the information coming from multiple\nsources. The purpose of this paper is to suggest a step by step methodology to\ndesign a Telco Data Mart, one of the fundamental BI components.\nOrder-To-Payment, an end to end customer process, will be used as an\napplication for this methodology. Our methodology consists on bringing together\nthe concepts of business intelligence and the telecom business frameworks\ndeveloped by the TM Forum: the Business Process Framework, the Information\nFramework, and the Business Metrics. The advantage of this solution is its\nability to adapt to any telecom enterprise architecture since it's built around\nthe business standards.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.0534v1"
    },
    {
        "title": "Smart Grid Demand Monitoring Model",
        "authors": [
            "Kalpana Kandpal",
            "Anjali Singhal"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper is in related to the demand genrated by the consumer for a time\nfor the power which is being viewed by taking some measures to solve the demand\nneed.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.1451v1"
    },
    {
        "title": "Pi Fractions for Generating Uniformly Distributed Sampling Points in\n  Global Search and Optimization Algorithms",
        "authors": [
            "Richard A. Formato"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Pi Fractions are used to create deterministic uniformly distributed\npseudorandom decision space sample points for a global search and optimization\nalgorithm. These fractions appear to be uniformly distributed on [0,1] and can\nbe used in any stochastic algorithm rendering it effectively deterministic\nwithout compromising its ability to explore the decision space. Pi Fractions\nare generated using the BBP Pi digit extraction algorithm. The Pi Fraction\napproach is tested using genetic algorithm Pi-GASR with very good results. A Pi\nFraction data file is available upon request.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3038v2"
    },
    {
        "title": "Comprehensive Analysis and Measurement of Frequency-Tuned and\n  Impedance-Tuned Wireless Non-Radiative Power Transfer Systems",
        "authors": [
            "Jason D. Heebl",
            "Erin M. Thomas",
            "Robert P. Penno",
            "Anthony Grbic"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper theoretically and experimentally investigates frequency-tuned and\nimpedance-tuned wireless non-radiative power transfer (WNPT) systems.\nClosed-form expressions for the efficiencies of both systems, as a function of\nfrequency and system (circuit) parameters, are presented. In the\nfrequency-tuned system, the operating frequency is adjusted to compensate for\nchanges in mutual inductance that occur for variations of transmitter and\nreceiver loop positions. Frequency-tuning is employed for a range of distances\nover which the loops are strongly coupled. In contrast, the impedance-tuned\nsystem employs varactor-based matching networks to compensate for changes in\nmutual inductance and achieve a simultaneous conjugate impedance match over a\nrange of distances. The frequency-tuned system is simpler to implement, while\nthe impedance-tuned system is more complex but can achieve higher efficiencies.\nBoth of the experimental WNPT systems studied employ resonant shielded loops as\ntransmitting and receiving devices.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3324v1"
    },
    {
        "title": "Advanced Self-interference Cancellation and Multiantenna Techniques for\n  Full-Duplex Radios",
        "authors": [
            "Dani Korpi",
            "Sathya Venkatasubramanian",
            "Taneli Riihonen",
            "Lauri Anttila",
            "Strasdosky Otewa",
            "Clemens Icheln",
            "Katsuyuki Haneda",
            "Sergei Tretyakov",
            "Mikko Valkama",
            "Risto Wichman"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In an in-band full-duplex system, radios transmit and receive simultaneously\nin the same frequency band at the same time, providing a radical improvement in\nspectral efficiency over a half-duplex system. However, in order to design such\na system, it is necessary to mitigate the self-interference due to simultaneous\ntransmission and reception, which seriously limits the maximum transmit power\nof the full-duplex device. Especially, large differences in power levels in the\nreceiver front-end sets stringent requirements for the linearity of the\ntransceiver electronics. We present an advanced architecture for a compact\nfull-duplex multiantenna transceiver combining antenna design with analog and\ndigital cancellation, including both linear and nonlinear signal processing.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3331v1"
    },
    {
        "title": "Accelerating SystemVerilog UVM Based VIP to Improve Methodology for\n  Verification of Image Signal Processing Designs Using HW Emulator",
        "authors": [
            "Abhishek Jain",
            "Piyush Kumar Gupta",
            "Dr. Hima Gupta",
            "Sachish Dhar"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper we present the development of Acceleratable UVCs from standard\nUVCs in SystemVerilog and their usage in UVM based Verification Environment of\nImage Signal Processing designs to increase run time performance. This paper\ncovers development of Acceleratable UVCs from standard UVCs for internal\ncontrol and data buses of ST imaging group by partitioning of transaction-level\ncomponents and cycle-accurate signal-level components between the software\nsimulator and hardware accelerator respectively. Standard Co-Emulation API:\nModeling Interface (SCE-MI) compliant, transaction-level communications link\nbetween test benches running on a host system and Emulation machine is\nestablished. Accelerated Verification IPs are used at UVM based Verification\nEnvironment of Image Signal Processing designs both with simulator and emulator\nas UVM acceleration is an extension of the standard simulation-only UVM and is\nfully backward compatible with it. Acceleratable UVCs significantly reduces\ndevelopment schedule risks while leveraging transaction models used during\nsimulation.\n  In this paper, we discuss our experiences on UVM based methodology adoption\non TestBench-Xpress(TBX) based technology step by step. We are also doing\ncomparison between the run time performance results from earlier simulator-only\nenvironment and the new, hardware-accelerated environment. Although this paper\nfocuses on Acceleratable UVCs development and their usage for image signal\nprocessing designs, Same concept can be extended for non-image signal\nprocessing designs.\n  KEYWORDS- SystemVerilog, Universal Verification Methodology (UVM),\nTestBench-Xpress (TBX), Universal Verification Component (UVC), Standard\nCo-Emulation API: Modelling Interface (SCE-MI), Acceleratable UVC, Emulator,\nXRTL Tasks/Functions (xtf), Transactor interface (tif), Verification IP (VIP).\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3554v1"
    },
    {
        "title": "Transport Information System using Query Centric Cyber Physical Systems\n  (QCPS)",
        "authors": [
            "Ankit Mundra",
            "Geetanjali Rathee",
            "Meenu Chawla",
            "Nitin Rakesh",
            "Ashsutosh Soni"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  To incorporate the computation and communication with the physical world,\nnext generation architecture i.e. CPS is viewed as a new technology. To improve\nthe better interaction with the physical world or to perk up the electricity\ndelivery usage, various CPS based approaches have been introduced. Recently\nseveral GPS equipped smart phones and sensor based frameworks have been\nproposed which provide various services i.e. environment estimation, road\nsafety improvement but encounter certain limitations like elevated energy\nconsumption and high computation cost. To meet the high reliability and safety\nrequirements, this paper introduces a novel approach based on QCPS model which\nprovides several users services (discussed in this paper). Further, this paper\nproposed a Transport Information System (TIS), which provide the communication\nwith lower cost overhead by arranging the similar sensors in the form of grids.\nEach grid has a coordinator which interacts with cloud to process the user\nquery. In order to evaluate the performance of proposed approach we have\nimplemented a test bed of 16 wireless sensor nodes and have shown the\nperformance in terms of computation and communication cost.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.3623v1"
    },
    {
        "title": "The Energy/Frequency Convexity Rule: Modeling and Experimental\n  Validation on Mobile Devices",
        "authors": [
            "Karel De Vogeleer",
            "Gerard Memmi",
            "Pierre Jouvelot",
            "Fabien Coelho"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper provides both theoretical and experimental evidence for the\nexistence of an Energy/Frequency Convexity Rule, which relates energy\nconsumption and CPU frequency on mobile devices. We monitored a typical\nsmartphone running a specific computing-intensive kernel of multiple nested\nloops written in C using a high-resolution power gauge. Data gathered during a\nweek-long acquisition campaign suggest that energy consumed per input element\nis strongly correlated with CPU frequency, and, more interestingly, the curve\nexhibits a clear minimum over a 0.2 GHz to 1.6 GHz window. We provide and\nmotivate an analytical model for this behavior, which fits well with the data.\nOur work should be of clear interest to researchers focusing on energy usage\nand minimization for mobile devices, and provide new insights for optimization\nopportunities.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4655v1"
    },
    {
        "title": "Antifragility = Elasticity + Resilience + Machine Learning: Models and\n  Algorithms for Open System Fidelity",
        "authors": [
            "Vincenzo De Florio"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  We introduce a model of the fidelity of open systems - fidelity being\ninterpreted here as the compliance between corresponding figures of interest in\ntwo separate but communicating domains. A special case of fidelity is given by\nreal-timeliness and synchrony, in which the figure of interest is the physical\nand the system's notion of time. Our model covers two orthogonal aspects of\nfidelity, the first one focusing on a system's steady state and the second one\ncapturing that system's dynamic and behavioural characteristics. We discuss how\nthe two aspects correspond respectively to elasticity and resilience and we\nhighlight each aspect's qualities and limitations. Finally we sketch the\nelements of a new model coupling both of the first model's aspects and\ncomplementing them with machine learning. Finally, a conjecture is put forward\nthat the new model may represent a first step towards compositional criteria\nfor antifragile systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.4862v1"
    },
    {
        "title": "Beyond Reuse Distance Analysis: Dynamic Analysis for Characterization of\n  Data Locality Potential",
        "authors": [
            "Naznin Fauzia",
            "Venmugil Elango",
            "Mahesh Ravishankar",
            "J. Ramanujam",
            "Fabrice Rastello",
            "Atanas Rountev",
            "Louis-Nol Pouchet",
            "P. Sadayappan"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Emerging computer architectures will feature drastically decreased flops/byte\n(ratio of peak processing rate to memory bandwidth) as highlighted by recent\nstudies on Exascale architectural trends. Further, flops are getting cheaper\nwhile the energy cost of data movement is increasingly dominant. The\nunderstanding and characterization of data locality properties of computations\nis critical in order to guide efforts to enhance data locality. Reuse distance\nanalysis of memory address traces is a valuable tool to perform data locality\ncharacterization of programs. A single reuse distance analysis can be used to\nestimate the number of cache misses in a fully associative LRU cache of any\nsize, thereby providing estimates on the minimum bandwidth requirements at\ndifferent levels of the memory hierarchy to avoid being bandwidth bound.\nHowever, such an analysis only holds for the particular execution order that\nproduced the trace. It cannot estimate potential improvement in data locality\nthrough dependence preserving transformations that change the execution\nschedule of the operations in the computation. In this article, we develop a\nnovel dynamic analysis approach to characterize the inherent locality\nproperties of a computation and thereby assess the potential for data locality\nenhancement via dependence preserving transformations. The execution trace of a\ncode is analyzed to extract a computational directed acyclic graph (CDAG) of\nthe data dependences. The CDAG is then partitioned into convex subsets, and the\nconvex partitioning is used to reorder the operations in the execution trace to\nenhance data locality. The approach enables us to go beyond reuse distance\nanalysis of a single specific order of execution of the operations of a\ncomputation in characterization of its data locality properties. It can serve a\nvaluable role in identifying promising code regions for manual transformation,\nas well as assessing the effectiveness of compiler transformations for data\nlocality enhancement. We demonstrate the effectiveness of the approach using a\nnumber of benchmarks, including case studies where the potential shown by the\nanalysis is exploited to achieve lower data movement costs and better\nperformance.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5024v1"
    },
    {
        "title": "Simulating Behaviours to face up an Emergency Evacuation",
        "authors": [
            "Pablo Cristian Tissera",
            "Alicia Castro",
            "A. Marcela Printista",
            "Emilio Luque"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Computer based models describing pedestrian behavior in an emergency\nevacuation play a vital role in the development of active strategies that\nminimize the evacuation time when a closed area must be evacuated. The\nreference model has a hybrid structure where the dynamics of fire and smoke\npropagation are modeled by means of Cellular Automata and for simulating\npeople's behavior we are using Intelligent Agents. The model consists of two\nsub-models, called environmental and pedestrian ones. As part of the pedestrian\nmodel, this paper concentrates in a methodology that is able to model some of\nthe frequently observed human's behaviors in evacuation exercises. Each agent\nwill perceive what is happening around, select the options that exist in that\ncontext and then it makes a decision that will reflect its ability to cope with\nan emergency evacuation, called in this work, behavior. We also developed\nsimple exercises where the model is applied to the simulation of an evacuation\ndue to a potential hazard, such as fire, smoke or some kind of collapse.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5209v1"
    },
    {
        "title": "Intelligent Product: Mobile Agent Architecture Integrating the End of\n  Life Cycle (EOL) For minimizing the lunch phase PLM",
        "authors": [
            "Abdelhak Boulaalam",
            "El Habib Nfaoui",
            "Omar El Beqqali"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  To improve the increasingly demands products that are customized, all\nbusiness activities performed along the product life cycle must be coordinated\nand efficiently managed along the extended enterprise. For this, enterprise had\nwanted to retain control over the whole product lifecycle especially when the\nproduct is in use/recycling (End Of Life phase). Although there have been many\nprevious research works about product lifecycle management in the beginning of\nlife (BOL) and middle of life (MOL) phases, few addressed the end of life (EOL)\nphase, in particular, when the product is at the customers. In this paper,\nbased on product embedded device identification (PEID) and mobile agent\ntechnologies, and with the advent of the development of the \"intelligent\nproducts\", we will try to improve innovation: (a) by minimize the lunch phase,\n(b) and the involvement of the customer in product lifecycle.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5509v1"
    },
    {
        "title": "GreenMail: Reducing Email Service's Carbon Emission with Minimum Cost",
        "authors": [
            "Chen Li"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Internet services contribute a large fraction of worldwide carbon emission\nnowadays, in a context of increasing number of companies tending to provide and\nmore and more developers use Internet services. Noticeably, a trend is those\nservice providers are trying to reduce their carbon emissions by utilizing\non-site or off-site renewable energy in their datacenters in order to attract\nmore customers. With such efforts have been paid, there are still some users\nwho are aggressively calling for even cleaner Internet services. For example,\nover 500,000 Facebook users petitioned the social networking site to use\nrenewable energy to power its datacenter. However, it seems impossible for such\ndemand to be satisfied merely from the inside of those production datacenters,\nconsidering the transition cost and stability. Outside the existing Internet\nservices, on the other hand, may easily set up a proxy service to attract those\nrenewable-energy-sensitive users, by 1) using carbon neutral or even\nover-offsetting cloud instances to bridge the end user and traditional Internet\nservices; and 2) estimating and offsetting the carbon emissions from the\ntraditional Internet services. In our paper, we proposed GreenMail, which is a\ngeneral IMAP proxy caching system that connects email users and traditional\nemail services. GreenMail runs on green web hosts to cache users' emails on\ngreen cloud instances. Besides, it offsets the carbon emitted by traditional\nbackend email services. With GreenMail, users could set a carbon emission\nconstraint and use traditional email service without breaking any code\nmodification of user side and email server side.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5546v1"
    },
    {
        "title": "Specification of the State Lifetime in the DEVS Formalism by Fuzzy\n  Controller",
        "authors": [
            "Dahmani Youcef",
            "Hamri Maamar"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper aims to develop a new approach to assess the duration of state in\nthe DEVS formalism by fuzzy controller. The idea is to define a set of fuzzy\nrules obtained from observers or expert knowledge and to specify a fuzzy model\nwhich computes this duration, this latter is fed into the simulator to specify\nthe new value in the model. In conventional model, each state is defined by a\nmean lifetime value whereas our method, calculates for each state the new\nlifetime according to inputs values. A wildfire case study is presented at the\nend of the paper. It is a challenging task due to its complex behavior,\ndynamical weather condition, and various variables involved. A global\nspecification of the fuzzy controller and the forest fire model are presented\nin the DEVS formalism and comparison between conventional and fuzzy method is\nillustrated.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.5638v1"
    },
    {
        "title": "Software Architecture and Subclassing Technique for Semiconductor\n  Manufacturing Machines",
        "authors": [
            "HyungTae Kim",
            "HaeJeong Yang"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper proposed software architecture for operating an automatic\nsemiconductor manufacturing machine. Recent machines for semiconductor process\nare required for high level of automation which are composed of motion control,\nmachine vision, data acquisition and networking. These functions are executed\nthrough industrial equipments that are generally installed in a computer. The\nequipments occupy a great part of system resource and generate a lot of\ncomputation, so the software structure should be designed for efficiency. The\nproposed architecture is consisted of four layers and virtual equipments(VEs).\nThe VEs are made by subclassing the physical equipments(PEs) and the layers are\ncoded into thread which updates the status of VEs. Subroutines in a program\nrefer to the pointer of VEs, and direct access to physical equipment are\nprohibited. The number of access (NOA) to PEs in typical industrial application\nwas simulated for the unlimited access structure and the presented structure.\nThe result showed that the proposed structure was more efficient than typical\nones and irrespective of subroutines. This architecture was also applied to\ndesign a machine operating software and performed automatic wafer dicing.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.6125v1"
    },
    {
        "title": "A Software Design through Electrical System for a Building",
        "authors": [
            "Anghel Drugarin",
            "Cornelia Victoria"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Computer aided design of lighting systems made new installations of lighting\ndimensioning and verification of existing lighting systems for both indoor and\noutdoor lighting systems.The design of the building light system was in a\ndedicated software, named DiaLux, version 4.11.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.7148v1"
    },
    {
        "title": "Modeling Life as Cognitive Info-Computation",
        "authors": [
            "Gordana Dodig-Crnkovic"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This article presents a naturalist approach to cognition understood as a\nnetwork of info-computational, autopoietic processes in living systems. It\nprovides a conceptual framework for the unified view of cognition as evolved\nfrom the simplest to the most complex organisms, based on new empirical and\ntheoretical results. It addresses three fundamental questions: what cognition\nis, how cognition works and what cognition does at different levels of\ncomplexity of living organisms. By explicating the info-computational character\nof cognition, its evolution, agent-dependency and generative mechanisms we can\nbetter understand its life-sustaining and life-propagating role. The\ninfo-computational approach contributes to rethinking cognition as a process of\nnatural computation in living beings that can be applied for cognitive\ncomputation in artificial systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.7191v1"
    },
    {
        "title": "ICT technologies for the refurbishment of wooden structure buildings",
        "authors": [
            "Ivan Arakistain",
            "Jose Miguel Abascal",
            "Oriol Munne"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Nowadays, one would think that after years of massive concrete and steel\nconstruction in Spain, there are not many wood structure buildings left to be\nrefurbished except for some palaces or cathedrals. However, if we go for a walk\nand have a look at the old part of any city, we will realize that still most of\nthe buildings have a wood structure. In spite of the fact that the majority of\nurban regulations forbid their demolition, other bad practices such as casting\nand overloading the wood structure are very common. Considering that we want to\nreach a standard of sustainable construction, the economical and environmental\ncosts, which are implied by the deficient refurbishment makes it well worth a\nprevious study of the structure, which in most cases represents less than a 1%\nof the total budget. The main goal of this paper is to present most relevant\nparts of the whole process of diagnosis of a wood structure building by means\nof Non-Destructive Testing Techniques. Among the ones to be considered, we\ncould mention the analysis of the building and its surroundings, on-site\ninspection of the building, structural diagnosis, definition of the corrective\nactions to be taken, definition of treatments, quality control and a\nmaintenance plan. For the on-site inspection of the building, in the paper we\nwill highlight the use of Non-Destructive methods such as resistograph\ndrilling, X-ray imaging, ultrasound-based testing or moisture measurement. We\nwill provide practical examples of all this. The aim of this paper is to give\nthe audience an overall idea on how a pre-assessment work can enhance the\nrefurbishment of a wood structure building while reducing costs and\nenvironmental impact.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.8136v1"
    },
    {
        "title": "Introducing E-maintenance 2.0",
        "authors": [
            "Abdessamad Mouzoune",
            "Saoudi Taibi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  While research literature is still debating e-maintenance definition, a new\nreality is emerging in business world confirming the enterprise 2.0 model.\nExecutives are more and more forced to stop running against current trend\ntowards social media and instead envisage harnessing its power within the\nenterprise. Maintenance can't be an exception for long and has to take\nadvantage of new opportunities created by social technological innovations. In\nthis paper, a combination of pure E perspective and 2.0 perspective is proposed\nto avoid a lock-in and allow continous evolution of e-maintenance within the\nnew context of business: A combination of data centric models and people\noriented applications to form a collaborative environment in order to conceive\nand achieve global goals of maintenance.New challenges are also to be expected\nas to the effecient integration of enterprise 2.0 tools within current\ne-maintenance platforms and futher research work is still to be done in this\narea.\n",
        "pdf_link": "http://arxiv.org/pdf/1401.8252v1"
    },
    {
        "title": "Estimation of Optimized Energy and Latency Constraints for Task\n  Allocation in 3d Network on Chip",
        "authors": [
            "Vaibhav Jha",
            "Mohit Jha",
            "GK Sharma"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In Network on Chip (NoC) rooted system, energy consumption is affected by\ntask scheduling and allocation schemes which affect the performance of the\nsystem. In this paper we test the pre-existing proposed algorithms and\nintroduced a new energy skilled algorithm for 3D NoC architecture. An efficient\ndynamic and cluster approaches are proposed along with the optimization using\nbio-inspired algorithm. The proposed algorithm has been implemented and\nevaluated on randomly generated benchmark and real life application such as\nMMS, Telecom and VOPD. The algorithm has also been tested with the E3S\nbenchmark and has been compared with the existing mapping algorithm spiral and\ncrinkle and has shown better reduction in the communication energy consumption\nand shows improvement in the performance of the system. On performing\nexperimental analysis of proposed algorithm results shows that average\nreduction in energy consumption is 49%, reduction in communication cost is 48%\nand average latency is 34%. Cluster based approach is mapped onto NoC using\nDynamic Diagonal Mapping (DDMap), Crinkle and Spiral algorithms and found DDmap\nprovides improved result. On analysis and comparison of mapping of cluster\nusing DDmap approach the average energy reduction is 14% and 9% with crinkle\nand spiral.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.0109v1"
    },
    {
        "title": "Coal Blending: Business Value, Analysis, and Optimization",
        "authors": [
            "James Whitacre",
            "Sven Schellenberg",
            "Antony Iorio"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Coal blending is a critically important process in the coal mining industry\nas it directly influences the number of product tonnes and the total revenue\ngenerated by a mine site. Coal blending represents a challenging and complex\nproblem with numerous blending possibilities, multiple constraints and\ncompeting objectives. At many mine sites, blending decisions are made using\nheuristics that have been developed through experience or made by using\ncomputer assisted control algorithms or linear programming. While current\nblending procedures have achieved profitable outcomes in the past, they often\nresult in a sub-optimal utilization of high quality coal. This sub-optimality\nhas a considerable negative impact on mine site productivity as it can reduce\nthe amount of lower quality ROM that is blended and sold. This article reviews\nthe coal blending problem and discusses some of the difficult trade-offs and\nchallenges that arise in trying to address this problem. We highlight some of\nthe risks from making simplifying assumptions and the limitations of current\nsoftware optimization systems. We conclude by explaining how the mining\nindustry would significantly benefit from research and development into\noptimization algorithms and technologies that are better able to combine\ncomputer optimization algorithm capabilities with the important insights of\nengineers and quality control specialists.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.0276v2"
    },
    {
        "title": "Rapture in the Cartesian Wall between Real World Entities and their\n  Abstract Models",
        "authors": [
            "Narada Wickramage"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This short paper envisages that the advancements made with respect to Big\nData (BD), High Performance Computing, etc. would give rise to a new paradigm\nof concrete information models, which would closely replicate the real world\nand the consequences such as self-verifying information models, BD warehouses\nas intermediaries between data sources and information systems, etc.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.1085v1"
    },
    {
        "title": "Use of ARAS 360 to Facilitate Rapid Development of Articulated Total\n  Body Biomechanical Physics Simulations",
        "authors": [
            "Bob J. Scurlock"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The development of 3-dimensional environments to be used within a\nbiomechanical physics simulation framework, such as Articulated Total Body, can\nbe laborious and time intensive. This brief article demonstrates how the ARAS\n360 software package can aid the user by speeding up development time.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.2063v1"
    },
    {
        "title": "A New Multi-Tiered Solid State Disk Using Slc/Mlc Combined Flash Memory",
        "authors": [
            "Arash Batni",
            "Farshad Safaei"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Storing digital information, ensuring the accuracy, steady and uninterrupted\naccess to the data are considered as fundamental challenges in enterprise-class\norganizations and companies. In recent years, new types of storage systems such\nas solid state disks (SSD) have been introduced. Unlike hard disks that have\nmechanical structure, SSDs are based on flash memory and thus have electronic\nstructure. Generally a SSD consists of a number of flash memory chips, some\nbuffers of the volatile memory type, and an embedded microprocessor, which have\nbeen interconnected by a port. This microprocessor run a small file system\nwhich called flash translation layer (FTL). This software controls and\nschedules buffers, data transfers and all flash memory tasks. SSDs have some\nadvantages over hard disks such as high speed, low energy consumption, lower\nheat and noise, resistance against damage, and smaller size. Besides, some\ndisadvantages such as limited endurance and high price are still challenging.\nIn this study, the effort is to combine two common technologies - SLC and MLC\nchips - used in the manufacture of SSDs in a single SSD to decrease the side\neffects of current SSDs. The idea of using multi-layer SSD is regarded as an\nefficient solution in this field.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.2157v1"
    },
    {
        "title": "The Eve of 3D Printing in Telemedicine: State of the Art and Future\n  Challenges",
        "authors": [
            "Piero Giacomelli",
            "Asa Smedberg"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  3D printing has raised a lot of attention from fields outside the\nmanufacturing one in the last years. In this paper, we will illustrate some\nrecent advances of 3D printing technology, applied to the field of telemedicine\nand remote patient care. The potentiality of this technology will be detailed\nwithout lab examples. Some crucial aspect such as the regulation of these\ndevices and the need of some standards will also be discussed. The purpose of\nthis paper is to present some of the most promising applications of such\ntechnology.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.2305v1"
    },
    {
        "title": "Mending the Big-Data Missing Information",
        "authors": [
            "Hadassa Daltrophe",
            "Shlomi Dolev",
            "Zvi Lotker"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Consider a high-dimensional data set, in which for every data-point there is\nincomplete information. Each object in the data set represents a real entity,\nwhich is described by a point in high-dimensional space. We model the lack of\ninformation for a given object as an affine subspace in $\\mathbb{R}^d$ whose\ndimension $k$ is the number of missing features.\n  Our goal in this study is to find clusters of objects where the main problem\nis to cope with partial information and high dimension. Assuming the data set\nis separable, namely, its emergence from clusters that can be modeled as a set\nof disjoint ball in $\\mathbb{R}^d$, we suggest a simple data clustering\nalgorithm. Our suggested algorithm use the affine subspaces minimum distance\nand calculates pair-wise projection of the data achieving poly-logarithmic time\ncomplexity.\n  We use probabilistic considerations to prove the algorithm's correctness.\nThese probabilistic results are of independent interest, and can serve to\nbetter understand the geometry of high dimensional objects.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.2512v5"
    },
    {
        "title": "A Layered Modeling and Simulation Approach to investigate Resource-aware\n  Computing in MPSoCs",
        "authors": [
            "Aurang Zaib",
            "Prashanth Raju",
            "Thomas Wild",
            "Andreas Herkersdorf"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Increasing complexity of modern multi-processor system on chip (MPSoC) and\nthe decreasing feature size have introduced new challenges. System designers\nhave to consider now aspects which were not part of the design process in past\ntimes. Resource-aware Computing is one of such emerging design concerns which\ncan help to improve performance, dependability and resource utilization of\noverall system. Resource-aware execution takes into account the resource status\nwhen executing tasks on MPSoCs. Exploration of resource-aware computing at\nearly design stages of complex systems is mandatory and appropriate\nmethodologies to do this in an efficient manner are thus required. In this\npaper, we present a modular approach which provides modeling and simulation\nsupport for investigation of resource-aware execution in MPSoCs. The proposed\nmethodology enables rapid exploration of the design space by modeling and\nsimulating the resource-awareness in a separate layer while widely reusing the\nlegacy system model in the other layer. Our experiments illustrate the benefits\nof our approach for the exploration of resource-aware execution on MPSoCs.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.2917v1"
    },
    {
        "title": "GREEND: An Energy Consumption Dataset of Households in Italy and Austria",
        "authors": [
            "Andrea Monacchi",
            "Dominik Egarter",
            "Wilfried Elmenreich",
            "Salvatore D'Alessandro",
            "Andrea M. Tonello"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Home energy management systems can be used to monitor and optimize\nconsumption and local production from renewable energy. To assess solutions\nbefore their deployment, researchers and designers of those systems demand for\nenergy consumption datasets. In this paper, we present the GREEND dataset,\ncontaining detailed power usage information obtained through a measurement\ncampaign in households in Austria and Italy. We provide a description of\nconsumption scenarios and discuss design choices for the sensing\ninfrastructure. Finally, we benchmark the dataset with state-of-the-art\ntechniques in load disaggregation, occupancy detection and appliance usage\nmining.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.3100v2"
    },
    {
        "title": "Recognition and Ranking Critical Success Factors of Business\n  Intelligence in Hospitals -- Case Study: Hasheminejad Hospital",
        "authors": [
            "Marjan Naderinejad",
            "Mohammad Jafar Tarokh",
            "Alireza Poorebrahimi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Business Intelligence, not as a tool of a product but as a new approach is\npropounded in organizations to make tough decisions in business as shortly as\npossible. Hospital managers often need business intelligence in their fiscal,\noperational, and clinical reports and indices. The main goal of recognition and\nranking CSF is implementation of a business intelligent system in hospitals to\nincrease success factor of application of business intelligence in health and\ntreatment sector. This paper is an application and descriptive-analytical one,\nin which we use questionnaires to gather data and we used SPSS and LISREL to\nanalyze them. Its statistical society is managers and personnel of Hasheminejad\nhospital and case studies are selected by Cochran formula. The findings show\nthat all three organizational, process, and technological factors equally\naffect implementation of business intelligence based on Yeoh & Koronis\napproach, where the assumptions are based upon it. The proposed model for CSFs\nof business intelligence in hospitals include: declaring perspective, goals and\nstrategies, development of human and financial resources, clarification of\norganizational culture, documentation and process mature, management support,\netc. Business intelligence implementation is affected by different components.\nCenter of Hasheminejad hospital BI system as a leader in providing quality\nhealth care, partially succeeded to take advantage of the benefits the\norganization in passing the information revolution but the development of this\nsystem to achieve intelligent hospital and its certainty is a high priority,\nthus it can`t be said that the hospital-wide BI system is quite favorable. In\nthis regard, it can be concluded that Hasheminejad hospital requires practical\nmodel for business intelligence systems development.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.4597v1"
    },
    {
        "title": "Using the Expectation Maximization Algorithm with Heterogeneous Mixture\n  Components for the Analysis of Spectrometry Data",
        "authors": [
            "Dominik Kopczynski",
            "Sven Rahmann"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Coupling a multi-capillary column (MCC) with an ion mobility (IM)\nspectrometer (IMS) opened a multitude of new application areas for gas\nanalysis, especially in a medical context, as volatile organic compounds (VOCs)\nin exhaled breath can hint at a person's state of health. To obtain a potential\ndiagnosis from a raw MCC/IMS measurement, several computational steps are\nnecessary, which so far have required manual interaction, e.g., human\nevaluation of discovered peaks. We have recently proposed an automated pipeline\nfor this task that does not require human intervention during the analysis.\nNevertheless, there is a need for improved methods for each computational step.\nIn comparison to gas chromatography / mass spectrometry (GC/MS) data, MCC/IMS\ndata is easier and less expensive to obtain, but peaks are more diffuse and\nthere is a higher noise level. MCC/IMS measurements can be described as samples\nof mixture models (i.e., of convex combinations) of two-dimensional probability\ndistributions. So we use the expectation-maximization (EM) algorithm to\ndeconvolute mixtures in order to develop methods that improve data processing\nin three computational steps: denoising, baseline correction and peak\nclustering. A common theme of these methods is that mixture components within\none model are not homogeneous (e.g., all Gaussian), but of different types.\nEvaluation shows that the novel methods outperform the existing ones. We\nprovide Python software implementing all three methods and make our evaluation\ndata available at http://www.rahmannlab.de/research/ims.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.5501v1"
    },
    {
        "title": "Extended AIGER Format for Synthesis",
        "authors": [
            "Swen Jacobs"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  We extend the AIGER format, as used in HWMCC, to a format that is suitable to\ndefine synthesis problems with safety specifications. We recap the original\nformat and define one format for posing synthesis problems and one for\nsolutions of synthesis problems in this setting.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.5793v2"
    },
    {
        "title": "Revised Version of a JCIT Paper-Comparison of Feature Point Extraction\n  Algorithms for Vision Based Autonomous Aerial Refueling",
        "authors": [
            "Borui Li",
            "Chundi Mu",
            "Tao Wang",
            "Qian Peng"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This is a revised version of our paper published in Journal of Convergence\nInformation Technology(JCIT): \"Comparison of Feature Point Extraction\nAlgorithms for Vision Based Autonomous Aerial Refueling\". We corrected some\nerrors including measurement unit errors, spelling errors and so on. Since the\npublished papers in JCIT are not allowed to be modified, we submit the revised\nversion to arXiv.org to make the paper more rigorous and not to confuse other\nresearchers.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6163v2"
    },
    {
        "title": "Adaptive Minimum-Maximum Exclusive Mean Filter for Impulse Noise Removal",
        "authors": [
            "Shuliang Wang",
            "Zhe Zhou",
            "Wenzhong Shi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Many filters are proposed for impulse noise removal. However, they are hard\nto keep excellent denoising performance with high computational efficiency. In\nresponse to this difficulty, this paper presents a novel fast filter, adaptive\nminimum-maximum exclusive mean (AMMEM) filter to remove impulse noise. Although\nthe AMMEM filter is a variety of the maximum-minimum exclusive mean (MMEM)\nfilter, however, the AMMEM filter inherits the advantages, and overcomes the\ndrawbacks, compared with the MMEM filter. To increase the various performances\nof noise removal, the AMMEM filter uses an adaptive size window, introduces two\nflexible factors, projection factor P and detection factor T, and limits the\ncalculation scope of the AVG. The experimental results show the AMMEM filter\nmakes a significant improvement in terms of noise detection, image restoration,\nand computational efficiency. Even at noise level as high as 95%, the AMMEM\nfilter still can restore the images with good visual effect.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6174v2"
    },
    {
        "title": "Mobile Application for GBAS Air Traffic Status Unit",
        "authors": [
            "Hiba Zaidi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  At present, the Air Traffic Status Unit is a windows PC based application,\nwhich receives the status of ground based augmentation system station over\nEthernet and displays on the screen. The objective of this project is to\nconvert the PC based Application into Mobile application using Android OS.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6822v1"
    },
    {
        "title": "Odravanje raunarskih sistema",
        "authors": [
            "Samir Leme"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Computer hardware and software are resources without which the modern\nbusiness of any organization, from manufacturing to services, is impossible.\nNot enough attention is being payed to maintenance of computer systems as an\naspect of business. This paper gives some recommendations for the selection of\nthe computer systems maintenance approach, based on many years of experience\nmaintaining these systems at the University of Zenica.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.7135v1"
    },
    {
        "title": "How to Track Online SLA",
        "authors": [
            "Anuradha Rana",
            "Pratima Sharma"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  SLA (Service level agreement) is defined by an organization to fulfil its\nclient requirements, the time within which the deliverables should be turned\nover to the clients. Tracking of SLA can be done manually by checking the\nstatus, priority of any particular task. Manual SLA tracking takes time as one\nhas to go over each and every task that needs to be completed. For instance,\nyou ordered a product from a website and you are not happy with the quality of\nthe product and want to replace the same on urgent basis, You send mail to the\ncustomer support department, the query/complaint will be submitted in a queue\nand will be processed basis of its priority and urgency (The SLA for responding\nback to customers concern are listed in the policy). This online SLA tracking\nsystem will ensure that no queries/complaints are missed and are processed in\nan organized manner as per their priority and the date by when it should be\nhandled. The portal will provide the status of the complaints for that\nparticular day and the ones which have been pending since last week. The\ninformation can be refreshed as per the client need (within what time frame the\ncomplaint should be addressed).\n",
        "pdf_link": "http://arxiv.org/pdf/1407.0697v1"
    },
    {
        "title": "Business types classification via e-commerce stage model in oil industry\n  in Iran",
        "authors": [
            "Mohammad Nassiry",
            "Muriati Mukhtar"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Since the strategies and plans for e-commerce development are different for\ndifferent industries and since the oil industry is one of the most important\nindustries in Iran, the scope of this research is thus confined to that of the\noil industry in Iran. The main aim of this study is to identify and classify\nthe different features of e-commerce development stages and features based on\nthe different business types present in companies in the oil industry in Iran.\nIn order to achieve both of these objectives a questionnaire was developed and\nadministered online. The questionnaire was distributed to forty representatives\nworking in different companies. The collected data was classified and sorted\nand the priority e-commerce features was classified and displayed as triangles\nfor each business type. Furthermore, the experts were asked to indicate the\nfeatures which they implemented in their companies in order to know the most\nused features in each stage. The results of this study give an insight to the\npractice of e-commerce for Iranian oil companies and can be used to strategize\nfuture directions for the industry in terms of e- commerce.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.1429v1"
    },
    {
        "title": "Sequential Data Mining using Correlation Matrix Memory",
        "authors": [
            "Sanil Shanker KP",
            "Aaron Turner",
            "Elizabeth Sherly",
            "Jim Austin"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper proposes a method for sequential data mining using correlation\nmatrix memory. Here, we use the concept of the Logical Match to mine the\nindices of the sequential pattern. We demonstrate the uniqueness of the method\nwith both the artificial and the real datum taken from NCBI databank.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2206v1"
    },
    {
        "title": "Intelligent Fatigue Detection and Automatic Vehicle Control System",
        "authors": [
            "Monali Gulhane",
            "P. S. Mohod"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper describes method for detecting the early signs of fatigue in train\ndrivers. As soon as the train driver is falling in symptoms of fatigue\nimmediate message will be transfer to the control room indicating the status of\nthe drivers. In addition of the advance technology of heart rate sensors is\nalso added in the system for correct detection of status of driver if in either\ncase driver is falling to fatigue due to any sever medical problems .The\nfatigue is detected in the system by the image processing method of comparing\nthe image(frames) in the video and by using the human features we are able to\nestimate the indirect way of detecting fatigue. The technique also focuses on\nmodes of person when driving the train i.e. awake, drowsy state or sleepy and\nsleep state. The system is very efficient to detect the fatigue and control the\ntrain also train can be controlled if it cross any such signal by which the\ntrain may collide on another train.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2412v1"
    },
    {
        "title": "A New Fuzzy DEMATEL-TODIM Hybrid Method for evaluation criteria of\n  Knowledge management in supply chain",
        "authors": [
            "Mahdi Mahmoodi",
            "Gelayol Safavi Jahromi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Knowledge management (KM) adoption in the supply chain network needs a good\ninvestment as well as few changes in the culture of the entire SC. Knowledge\nmanagement is the process of creating, distributing and transferring\ninformation. The goal of this study is to Rank KM criteria in supply chain\nnetwork in Iran which is important for firms these days. Criterion used in this\npaper were extracted from the literature review and were confirmed by supply\nchain experts. The proposed approach for ranking and finding out about these\ncriterion is hybrid fuzzy DEMATEL-TODIM, with using fuzzy number as data for\nour studies we could avoid uncertainty. The data was gathered from PhD. And Ms.\nStudents in industrial engineering of Kharrazmi university of Tehran and PhD.\nAnd Ms. Students of the management department of Semnan university. A new\nhybrid approach was used for achieving the results of this study. This new\nhybrid approach ranks data criteria respect to each other, then by using TODIM\nfor ranking respect to the best situation (gains), the rates of criterion were\ndetermined which is a very important advantage\n",
        "pdf_link": "http://arxiv.org/pdf/1407.3657v1"
    },
    {
        "title": "Data Transfer between Two USB Flash SCSI Disks using a Touch Screen",
        "authors": [
            "Anurag A. Chakravorty",
            "Raghwendra J. Suryawanshi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Under normal circumstances, as an intermediate device, if we want to move or\ncopy data from one mass storage device to another, we use a computer in the\nform of desktops, laptops, etc. We need a device which can be used as an\nintermediate device, also which is a complete blend of hardware & software.\nThis device is a gadget that can be used to transfer data between two flash\nSCSI devices via a touch screen. This is a user friendly device which uses the\nmost popular bus USB (Universal Serial Bus) with Type-A connector. It is\ngoverned by the USB 2.0 Protocol. One of the major advantage of this device is\nits portability.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.5008v1"
    },
    {
        "title": "M$^2$I: Channel Modeling for Metamaterial-Enhanced Magnetic Induction\n  Communications",
        "authors": [
            "Hongzhi Guo",
            "Zhi Sun",
            "Jingbo Sun",
            "Natalia M. Litchinitser"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Magnetic Induction (MI) communication technique has shown great potentials in\ncomplex and RF-challenging environments, such as underground and underwater,\ndue to its advantage over EM wave-based techniques in penetrating lossy medium.\nHowever, the transmission distance of MI techniques is limited since magnetic\nfield attenuates very fast in the near field. To this end, this paper proposes\nMetamaterial-enhanced Magnetic Induction (M$^2$I) communication mechanism,\nwhere a MI coil antenna is enclosed by a metamaterial shell that can enhance\nthe magnetic fields around the MI transceivers. As a result, the M$^2$I\ncommunication system can achieve tens of meters communication range by using\npocket-sized antennas. In this paper, an analytical channel model is developed\nto explore the fundamentals of the M$^2$I mechanism, in the aspects of\ncommunication range and channel capacity, and the susceptibility to various\nhostile and complex environments. The theoretical model is validated through\nthe finite element simulation software, Comsol Multiphysics. Proof-of-concept\nexperiments are also conducted to validate the feasibility of M$^2$I.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.5040v2"
    },
    {
        "title": "Supporting Read/Write Applications in Embedded Real-time Systems via\n  Suspension-aware Analysis",
        "authors": [
            "Guangmo Tong",
            "Cong Liu"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In many embedded real-time systems, applications often interact with I/O\ndevices via read/write operations, which may incur considerable suspension\ndelays. Unfortunately, prior analysis methods for validating timing correctness\nin embedded systems become quite pessimistic when suspension delays are\npresent. In this paper, we consider the problem of supporting two common types\nof I/O applications in a multiprocessor system, that is, write-only\napplications and read-write applications. For the write-only application model,\nwe present a much improved analysis technique that results in only O(m)\nsuspension-related utilization loss, where m is the number of processors. For\nthe second application model, we present a flexible I/O placement strategy and\na corresponding new scheduling algorithm, which can completely circumvent the\nnegative impact due to read- and write-induced suspension delays. We illustrate\nthe feasibility of the proposed I/O-placement-based schedule via a case study\nimplementation. Furthermore, experiments presented herein show that the\nimprovement with respect to system utilization over prior methods is often\nsignificant.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.5126v1"
    },
    {
        "title": "A Novel Hybrid Algorithm for Permutation Flow Shop Scheduling",
        "authors": [
            "Sandeep Kumar",
            "Pooja Jadon"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In the present scenario the recent engineering and industrial built-up units\nare facing hodgepodge of problems in a lot of aspects such as machining time,\nelectricity, man power, raw material and customers constraints. The job-shop\nscheduling is one of the most significant industrial behaviours, particularly\nin manufacturing planning. This paper proposes the permutation flow shop\nsequencing problem with the objective of makespan minimization using the new\nmodified proposed method of johnsons algorithm as well as the guptas heuristic\nalgorithm. This paper involves the determination of the order of processing of\nn jobs in m machines. Although since the problem is known to be np-hard for\nthree or more machines, that produces near optimal solution of the given\nproblem. The proposed method is very simple and easy to understand followed by\na numerical illustration is given.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.5931v1"
    },
    {
        "title": "Adaptive Fault Diagnosis using Self-Referential Reasoning",
        "authors": [
            "Robert Cowen"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The problem is to determine which processors are reliable in a remote\nlocation by asking \"Yes or No\" questions. The processors are of three types:\nthose that always tell the truth, those that always lie, and those the\nsometimes tell the truth and sometimes lie. Using self-referential reasoning,\nalong with earlier techniques, we can regard both the truth-tellers and liars\nas reliable and thus the tackle situations when fewer than half the processors\nare truth-tellers.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6255v1"
    },
    {
        "title": "Simulation and optimization of container terminal operations: a case\n  study",
        "authors": [
            "Gamal Abd El-Nasser A. Said",
            "Abeer M. Mahmoud",
            "El-Sayed M. El-Horbaty"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Container terminals are facing a set of interrelated problems. Container\nhandling problems at container terminals are NP-hard problems. The docking time\nof container ships at the port must be optimized. In this paper we have built a\nsimulation model that integrates all the activities of a container terminal.\nThe proposed approach is applied on a real case study data of container\nterminal at El-Dekheilla port. The results show that the proposed approach\nreduced the ship turnaround time in port where 51% reduction in ship service\ntime (loading/unloading) in port is achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6257v1"
    },
    {
        "title": "Solving container terminals problems using computer-based modeling",
        "authors": [
            "Gamal Abd El-Nasser A. Said",
            "Abeer M. Mahmoud",
            "El-Sayed M. El-Horbaty"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper addresses the applications of different techniques for solving\ncontainer terminals problems. We have built a simulation model that can be used\nto analyze the performance of container terminal operations. The proposed\napproach is intended to be applied for a real case study in Alexandria\nContainer Terminal (ACT) at Alexandria port. The implementation of our approach\nshows that a proposed model increases the efficiency of Alexandria container\nterminal at Alexandria port.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.6384v1"
    },
    {
        "title": "Study on FLOWSIM and its Application for Isolated Signal-ized\n  Intersection Assessment",
        "authors": [
            "Yuhan Jia",
            "Jianping Wu",
            "Yiman Du",
            "Geqi Qi"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Recently the traffic related problems have become strategically important,\ndue to the continuously increasing vehicle number. As a result, microscopic\nsimulation software has become an efficient method in traffic engineering for\nits cost-effectiveness and safety characteristics. In this paper, a new fuzzy\nlogic based simulation software (FLOWSIM) is introduced, which can reflect the\nmixed traffic flow phenomenon in China better. The fuzzy logic based\ncar-following model and lane-changing model are explained in detail.\nFurthermore, its applications for mixed traffic flow management in mid-size\ncities and for signalized intersection management assessment in large cities\nare illustrated by examples in China. Finally, further study objectives are\ndiscussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.8244v1"
    },
    {
        "title": "Theoretical Analysis of Radiative Cooling for Mobile and Embedded\n  Systems",
        "authors": [
            "Karel De Vogeleer",
            "Gerard Memmi",
            "Pierre Jouvelot",
            "Fabien Coelho"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  A new global analytical model of the heat dissipation process that occurs in\npassively-cooled embedded systems is introduced, and we explicit under what\ncircumstances the traditional assumption that exponential cooling laws apply in\nsuch context is valid. Since the power consumption and reliability of\nmicroprocessors are highly dependent on temperature, management units need\naccurate thermal models. Exponential cooling models are justified for\nactively-cooled systems. Here, we analyze the tractability of the cooling law\nfor a passively cooled body, subject to radiative and convective cooling,\nincluding internal heat generation. Focusing then on embedded system-like\nobjects, we compare the performance difference between our new passive cooling\nlaw and the conventionally-used exponential one. We show that, for quasi\nisothermal cooling surfaces of the order of 1\\,dm$^2$ or greater, the radiative\ncooling effect may become comparable to the convective cooling one. In other\nwords, radiation becomes non-negligible for systems with a cooling surface\nlarger than about 1\\,dm$^2$. Otherwise for surfaces below 1\\,dm$^2$, we show\nthat the differences between the exact solution and the exponential cooling law\nbecomes negligible. In the absence of accurate temperature measurements, an\nexponential cooling model is shown to be accurate enough for systems, such as\nsmall-sized SoCs, that require low processing overhead.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.0628v2"
    },
    {
        "title": "Adaptive two-dimensional wavelet transformation based on the Haar system",
        "authors": [
            "Mikhail Prisheltsev"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The purpose is to study qualitative and quantitative rates of image\ncompression by using different Haar wavelet banks. The experimental results of\nadaptive compression are provided. The paper deals with specific examples of\northogonal Haar bases generated by multiresolution analysis. Bases consist of\nthree piecewise constant wavelet functions with a support $[0,1] \\times [0,1]\n$.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.0705v1"
    },
    {
        "title": "Programing implementation of the Quine-McCluskey method for minimization\n  of Boolean expression",
        "authors": [
            "Jiangbo Huang"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  A Boolean function is a function that produces a Boolean value output by\nlogical calculation of Boolean inputs. It plays key roles in programing\nalgorithms and design of circuits. Minimization of Boolean function is able to\noptimize the algorithms and circuits. Quine-McCluskey (QM) method is one of the\nmost powerful techniques to simplify Boolean expressions. Compared to other\ntechniques, QM method is more executable and can handle more variables. In\naddition, QM method is easier to be implemented in computer programs, which\nmakes it an efficient technique. There are several versions of QM simulation\ncodes online, whereas some of them appear to have limitations of variables\nnumbers or lack the consideration of Dont-Care conditions. Here a QM simulation\ncode based on C programing is introduced. Theoretically it is able to handle\nany number of variables and has taken the Dont-Care conditions into account.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.1059v1"
    },
    {
        "title": "A Novel Design of IEEE 802.15.4 and Solar Based Autonomous Water Quality\n  Monitoring Prototype using ECHERP",
        "authors": [
            "Fredrick Romanus Ishengoma"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The recently advancement in Wireless Sensor Network (WSN) technology has\nbrought new distributed sensing applications such as water quality monitoring.\nWith sensing capabilities and using parameters like pH, conductivity and\ntemperature, the quality of water can be known. This paper proposes a novel\ndesign based on IEEE 802.15.4 (Zig-Bee protocol) and solar energy called\nAutonomous Water Quality Monitoring Prototype (AWQMP). The prototype is\ndesigned to use ECHERP routing protocol and Adruino Mega 2560, an open-source\nelectronic prototyping platform for data acquisition. AWQMP is expected to give\nreal time data acquirement and to reduce the cost of manual water quality\nmonitoring due to its autonomous characteristic. Moreover, the proposed\nprototype will help to study the behavior of aquatic animals in deployed water\nbodies.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.1773v1"
    },
    {
        "title": "Area Versus Speed Trade-off Analysis of a WiMAX Deinterleaver Circuit\n  Design",
        "authors": [
            "Omar Rafique"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Trade-off is one of the main design parameters in the field of electronic\ncircuit design. Whereas smaller electronics devices which use less hardware due\nto techniques like hardware multiplexing or due to smaller devices created due\nto techniques developed by nanotechnology and MEMS, are more appealing, a\ntrade-off between area, power and speed is inevitable. This paper analyses the\ntrade-off in the design of WiMAX deinterleaver. The main aim is to reduce the\nhardware utilization in a deinterleaver but speed and power consumption are\nimportant parameters which cannot be overlooked.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.2889v1"
    },
    {
        "title": "3D simulation of complex shading affecting PV systems taking benefit\n  from the power of graphics cards developed for the video game industry",
        "authors": [
            "Jesus Robledo",
            "Jonathan Leloux",
            "Eduardo Lorenzo"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Shading reduces the power output of a photovoltaic (PV) system. The design\nengineering of PV systems requires modeling and evaluating shading losses. Some\nPV systems are affected by complex shading scenes whose resulting PV energy\nlosses are very difficult to evaluate with current modeling tools. Several\nspecialized PV design and simulation software include the possibility to\nevaluate shading losses. They generally possess a Graphical User Interface\n(GUI) through which the user can draw a 3D shading scene, and then evaluate its\ncorresponding PV energy losses. The complexity of the objects that these tools\ncan handle is relatively limited. We have created a software solution, 3DPV,\nwhich allows evaluating the energy losses induced by complex 3D scenes on PV\ngenerators. The 3D objects can be imported from specialized 3D modeling\nsoftware or from a 3D object library. The shadows cast by this 3D scene on the\nPV generator are then directly evaluated from the Graphics Processing Unit\n(GPU). Thanks to the recent development of GPUs for the video game industry,\nthe shadows can be evaluated with a very high spatial resolution that reaches\nwell beyond the PV cell level, in very short calculation times. A PV simulation\nmodel then translates the geometrical shading into PV energy output losses.\n3DPV has been implemented using WebGL, which allows it to run directly from a\nWeb browser, without requiring any local installation from the user. This also\nallows taken full benefits from the information already available from\nInternet, such as the 3D object libraries. This contribution describes, step by\nstep, the method that allows 3DPV to evaluate the PV energy losses caused by\ncomplex shading. We then illustrate the results of this methodology to several\napplication cases that are encountered in the world of PV systems design.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.5780v1"
    },
    {
        "title": "On The Dynamical Nature Of Computation",
        "authors": [
            "Nabarun Mondal",
            "Partha P. Ghosh"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Dynamical Systems theory generally deals with fixed point iterations of\ncontinuous functions. Computation by Turing machine although is a fixed point\niteration but is not continuous. This specific category of fixed point\niterations can only be studied using their orbits. Therefore the standard\nnotion of chaos is not immediately applicable. However, when a suitable\ndefinition is used, it is found that the notion of chaos and fractal sets\nexists even in computation. It is found that a non terminating Computation will\nbe almost surely chaotic, and autonomous learning will almost surely identify\nfractal only sets.\n",
        "pdf_link": "http://arxiv.org/pdf/1410.8402v1"
    },
    {
        "title": "Photomapping Using Aerial Vehicle",
        "authors": [
            "Su Kim"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Creating a photomap plays a critical role in navigation. Therefore, flying\nvehicles are usually used to create topdown maps of the environment. In this\nreport we used two different aerial vehicles to create a map in a simulated\nenvironment\n",
        "pdf_link": "http://arxiv.org/pdf/1410.8509v2"
    },
    {
        "title": "Mapping and Matching Algorithms: Data Mining by Adaptive Graphs",
        "authors": [
            "Paolo D'Alberto",
            "Veronica Milenkly"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Assume we have two bijective functions $U(x)$ and $M(x)$ with $M(x)\\neq U(x)$\nfor all $x$ and $M,N: \\N \\rightarrow \\N$ . Every day and in different\nlocations, we see the different results of $U$ and $M$ without seeing $x$. We\nare not assured about the time stamp nor the order within the day but at least\nthe location is fully defined. We want to find the matching between $U(x)$ and\n$M(x)$ (i.e., we will not know $x$). We formulate this problem as an adaptive\ngraph mining: we develop the theory, the solution, and the implementation. This\nwork stems from a practical problem thus our definitions. The solution is\nsimple, clear, and the implementation parallel and efficient. In our\nexperience, the problem and the solution are novel and we want to share our\nfinding.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.00491v1"
    },
    {
        "title": "PC Guided Automatic Vehicle System",
        "authors": [
            "M. A. A. Mashud",
            "M. R. Hossain",
            "Mustari Zaman",
            "M. A. Razzaque"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The main objective of this paper is to design and develop an automatic\nvehicle, fully controlled by a computer system. The vehicle designed in the\npresent work can move in a pre-determined path and work automatically without\nthe need of any human operator and it also controlled by human operator. Such a\nvehicle is capable of performing wide variety of difficult tasks in space\nresearch, domestic, scientific and industrial fields. For this purpose, an IBM\ncompatible PC with Pentium microprocessor has been used which performed the\nfunction of the system controller. Its parallel printer port has been used as\ndata communication port to interface the vehicle. A suitable software program\nhas been developed for the system controller to send commands to the vehicle.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.01109v1"
    },
    {
        "title": "Micro-location for Internet of Things equipped Smart Buildings",
        "authors": [
            "Faheem Zafari",
            "Ioannis Papapanagiotou",
            "Konstantinos Christidis"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Micro-location is the process of locating any entity with high accuracy\n(possibly in centimeters), while geofencing is the process of creating a\nvirtual fence around a so-called Point of Interest (PoI). In this paper, we\npresent an insight into various micro-location enabling technologies and\nservices. We also discuss how these can accelerate the incorporation of\nInternet of Things (IoT) in smart buildings. We argue that micro-location based\nlocation-aware solutions can play a significant role in facilitating the\ntenants of an IoT equipped smart building. Also, such advanced technologies\nwill enable the smart building control system through minimal actions performed\nby the tenants. We also highlight the existing and envisioned services to be\nprovided by using micro-location enabling technologies. We describe the\nchallenges and propose some potential solutions such that micro-location\nenabling technologies and services are thoroughly integrated with IoT equipped\nsmart building.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.01539v2"
    },
    {
        "title": "Design, Analysis, and Simulation of a Pipe-Welding Robot with Fixed\n  Plinth",
        "authors": [
            "Anahita Emami",
            "Seyedmeysam Khaleghian",
            "Mohammad Mahjoob Jahromi"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Industrial requirements concerning the increased efficiency and high rate of\nmanufacturing result in the development of manufacturer robots, and a vast\ngroup of these types of robots is used for welding. This study presented the\ndesign, analysis, and simulation of a pipe-welding robot with fixed plinth for\na constant circular welding around the pipes. Design of a welding robot capable\nof keeping the electrode orientation, welding speed, and distance between\nelectrode and pipe surface constant can improve the quality of welding; thus, a\nfive-linked articulated robot was designed for this purpose. Solving of direct\nand diverse kinematics and dynamics equations of the robot was done by means of\nMatlab software. The robot was also simulated using a program written in Matlab\nand the diagrams of angles, velocities, and accelerations of all the arms, and\nthe applied force and torque of each arm required for drive the mechanism were\nobtained.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.01930v1"
    },
    {
        "title": "Complexity of Power Draws for Load Disaggregation",
        "authors": [
            "Dominik Egarter",
            "Manfred Pchacker",
            "Wilfried Elmenreich"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Non-Intrusive Load Monitoring (NILM) is a technology offering methods to\nidentify appliances in homes based on their consumption characteristics and the\ntotal household demand. Recently, many different novel NILM approaches were\nintroduced, tested on real-world data and evaluated with a common evaluation\nmetric. However, the fair comparison between different NILM approaches even\nwith the usage of the same evaluation metric is nearly impossible due to\nincomplete or missing problem definitions. Each NILM approach typically is\nevaluated under different test scenarios. Test results are thus influenced by\nthe considered appliances, the number of used appliances, the device type\nrepresenting the appliance and the pre-processing stages denoising the\nconsumption data. This paper introduces a novel complexity measure of\naggregated consumption data providing an assessment of the problem complexity\naffected by the used appliances, the appliance characteristics and the\nappliance usage over time. We test our load disaggregation complexity on\ndifferent real-world datasets and with a state-of-the-art NILM approach. The\nintroduced disaggregation complexity measure is able to classify the\ndisaggregation problem based on the used appliance set and the considered\nmeasurement noise.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.02954v1"
    },
    {
        "title": "Extended Report: Fine-grained Recognition of Abnormal Behaviors for\n  Early Detection of Mild Cognitive Impairment",
        "authors": [
            "Daniele Riboni",
            "Claudio Bettini",
            "Gabriele Civitarese",
            "Zaffar Haider Janjua",
            "Rim Helaoui"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  According to the World Health Organization, the rate of people aged 60 or\nmore is growing faster than any other age group in almost every country, and\nthis trend is not going to change in a near future. Since senior citizens are\nat high risk of non communicable diseases requiring long-term care, this trend\nwill challenge the sustainability of the entire health system. Pervasive\ncomputing can provide innovative methods and tools for early detecting the\nonset of health issues. In this paper we propose a novel method to detect\nabnormal behaviors of elderly people living at home. The method relies on\nmedical models, provided by cognitive neuroscience researchers, describing\nabnormal activity routines that may indicate the onset of early symptoms of\nmild cognitive impairment. A non-intrusive sensor-based infrastructure acquires\nlow-level data about the interaction of the individual with home appliances and\nfurniture, as well as data from environmental sensors. Based on those data, a\nnovel hybrid statistical-symbolical technique is used to detect the abnormal\nbehaviors of the patient, which are communicated to the medical center.\nDifferently from related works, our method can detect abnormal behaviors at a\nfine-grained level, thus providing an important tool to support the medical\ndiagnosis. In order to evaluate our method we have developed a prototype of the\nsystem and acquired a large dataset of abnormal behaviors carried out in an\ninstrumented smart home. Experimental results show that our technique is able\nto detect most anomalies while generating a small number of false positives.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.05581v1"
    },
    {
        "title": "Sparsity based Efficient Cross-Correlation Techniques in Sensor Networks",
        "authors": [
            "Prasant Misra",
            "Wen Hu",
            "Mingrui Yang",
            "Marco Duarte",
            "Sanjay Jha"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Cross-correlation is a popular signal processing technique used in numerous\nlocation tracking systems for obtaining reliable range information. However,\nits efficient design and practical implementation has not yet been achieved on\nmote platforms that are typical in wireless sensor network due to resource\nconstrains. In this paper, we propose SparseS-XCorr: cross-correlation via\nstructured sparse representation, a new computing framework for ranging based\non L1-minimization and structured sparsity. The key idea is to compress the\nranging signal samples on the mote by efficient random projections and transfer\nthem to a central device; where a convex optimization process estimates the\nrange by exploiting the sparse signal structure in the proposed correlation\ndictionary. Through theoretical validation, extensive empirical studies and\nexperiments on an end-to-end acoustic ranging system implemented on resource\nlimited off-the-shelf sensor nodes, we show that the proposed framework can\nachieve up to two orders of magnitude better performance compared to other\napproaches such as working on DCT domain and downsampling. Compared to the\nstandard cross-correlation, it is able to obtain range estimates with a bias of\n2-6cm with 30% and approximately 100cm with 5% compressed measurements. Its\nstructured sparsity model is able to improve the ranging accuracy by 40% under\nchallenging recovery conditions (such as high compression factor and low\nsignal-to-noise ratio) by overcoming limitations due to dictionary coherence.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.06473v3"
    },
    {
        "title": "A Simulation Modeling Approach for Optimization of Storage Space\n  Allocation in Container Terminal",
        "authors": [
            "Gamal Abd El-Nasser A. Said",
            "El-Sayed M. El-Horbaty"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Container handling problems at container terminals are NP-hard problems. This\npaper presents an approach using discrete-event simulation modeling to optimize\nsolution for storage space allocation problem, taking into account all various\ninterrelated container terminal handling activities. The proposed approach is\napplied on a real case study data of container terminal at Alexandria port. The\ncomputational results show the effectiveness of the proposed model for\noptimization of storage space allocation in container terminal where 54%\nreduction in containers handling time in port is achieved.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.06802v1"
    },
    {
        "title": "Contemporary Internet of Things platforms",
        "authors": [
            "Julien Mineraud",
            "Oleksiy Mazhelis",
            "Xiang Su",
            "Sasu Tarkoma"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  This document regroups a representative, but non-exhaustive, list of\ncontemporary IoT platforms. The platforms are ordered alphabetically. The aim\nof this document is to provide the a quick review of current IoT platforms, as\nwell as relevant information.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.07438v1"
    },
    {
        "title": "Crowds for Clouds: Recent Trends in Humanities Research Infrastructures",
        "authors": [
            "Tobias Blanke",
            "Conny Kristel",
            "Laurent Romary"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Humanities have convincingly argued that they need transnational research\nopportunities and through the digital transformation of their disciplines also\nhave the means to proceed with it on an up to now unknown scale. The digital\ntransformation of research and its resources means that many of the artifacts,\ndocuments, materials, etc. that interest humanities research can now be\ncombined in new and innovative ways. Due to the digital transformations, (big)\ndata and information have become central to the study of culture and society.\nHumanities research infrastructures manage, organise and distribute this kind\nof information and many more data objects as they becomes relevant for social\nand cultural research.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.00533v1"
    },
    {
        "title": "Novel velocity model to improve indoor localization using inertial\n  navigation with sensors on a smartphone",
        "authors": [
            "Rasika Lakmal Hettiarachchige Don",
            "Jagath Samarabandu"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  We present a generalized velocity model to improve localization when using an\nInertial Navigation System (INS). This algorithm was applied to correct the\nvelocity of a smart phone based indoor INS system to increase the accuracy by\ncounteracting the accumulation of large drift caused by sensor reading errors.\nWe investigated the accuracy of the algorithm with three different velocity\nmodels which were derived from the actual velocity measured at the hip of\nwalking person. Our results show that the proposed method with Gaussian\nvelocity model achieves competitive accuracy with a 50\\% less variance over\nStep and Heading approach proving the accuracy and robustness of proposed\nmethod. We also investigated the frequency of applying corrections and found\nthat a minimum of 5\\% corrections per step is sufficient for improved accuracy.\nThe proposed method is applicable in indoor localization and tracking\napplications based on smart phone where traditional approaches such as GNSS\nsuffers from many issues.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.03004v1"
    },
    {
        "title": "Transit directions at global scale",
        "authors": [
            "Joris van der Geer"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  A novel approach to integrated ground and air public transport journey\nplanning, operating at continent scale. Flexible date search, prerequisite for\nlong distance trips given their typical low and irregular service frequencies,\nis core functionality. The algorithm is especially suited for irregular and\npoorly structured networks. Almost all of the described functionality is\nimplemented in a working prototype. Using ground transport only, the system is\non par with Google Transit on random country-wide trips in the US.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.03633v1"
    },
    {
        "title": "Predictive and statistical analyses for academic advisory support",
        "authors": [
            "Mohammed Al-Sarem"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The ability to recognize weakness of students and solving any problem may\nconfront them in timely fashion is always a target of all educational\ninstitutions. This study was designed to explore how can predictive and\nstatistical analysis support the academic work of adviser mainly in analysis\nprogress of students . The sample consisted of a total of 249 undergraduate\nstudents: 46 % of them were Female and 54% Male. A one-way analysis of variance\nand t-test were conducted to analysis if there was different behavior in\nregistering courses. Predictive data mining is used for support adviser in\ndecision making. Several classification techniques with 10-fold Cross\nvalidation were applied. Among of them, C 4.5 constitutes the best agreement\namong the finding results.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.04244v1"
    },
    {
        "title": "Multi-Number CVT-XOR Arithmetic Operations in any Base System and its\n  Significant Properties",
        "authors": [
            "Jayanta Kumar Das",
            "Pabitra Pal Choudhury",
            "Sudhakar Sahoo"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Carry Value Transformation (CVT) is a model of discrete dynamical system\nwhich is one special case of Integral Value Transformations (IVTs). Earlier in\n[5] it has been proved that sum of two non-negative integers is equal to the\nsum of their CVT and XOR values in any base system. In the present study, this\nphenomenon is extended to perform CVT and XOR operations for many non-negative\nintegers in any base system. To achieve that both the definition of CVT and XOR\nare modified over the set of multiple integers instead of two. Also some\nimportant properties of these operations have been studied. With the help of\ncellular automata the adder circuit designed in [14] on using CVT-XOR\nrecurrence formula is used to design a parallel adder circuit for multiple\nnumbers in binary number system.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.04249v1"
    },
    {
        "title": "Superposition principle in linear networks with controlled sources",
        "authors": [
            "Ciro Visone"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The manuscript discusses a well-known issue that, despite its fundamental\nrole in basic electric circuit theory, seems to be tackled without the needful\nattention. The question if the Principle of Superposition (POS) can be applied\nto linear networks containing linear dependent sources still appears as an\naddressed point unworthy to be further discussed. Conversely, the analysis of\nthis point has been recently re-proposed [5,6] and an alternative conclusion\nhas been drawn. From this result, the manuscript provides an alternative\napproach to such issue from a more general point of view. It is oriented to\nclarify the issue from the didactic viewpoint, rather than provide a more\nefficient general technique for circuit analysis. By starting from a linear\nsystem of equations, representing a general linear circuit containing\ncontrolled sources, the correct interpretation of turning off the controlled\nelements in terms of circuit equivalent is provided, so allowing a statement of\nthe POS for linear circuits in a wider context. Further, this approach is\nsufficiently intuitive and straightforward to fit the needs of a Basic Electric\nCircuit Theory class.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.04563v1"
    },
    {
        "title": "50+ Metrics for Calendar Mining",
        "authors": [
            "Zdor Dniel Kelemen",
            "Dniel Miglsz"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In this report we propose 50+ metrics which can be measured by organizations\nin order to identify improvements in various areas such as meeting efficiency,\ncapacity planning or leadership skills, just to new a few. The notion of\ncalendar mining is introduced and support is provided for performing the\nmeasurement by a reference data model and queries for all metrics defined.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.06740v1"
    },
    {
        "title": "NexMon: A Cookbook for Firmware Modifications on Smartphones to Enable\n  Monitor Mode",
        "authors": [
            "Matthias Schulz",
            "Daniel Wegemer",
            "Matthias Hollick"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Full control over a Wi-Fi chip for research purposes is often limited by its\nfirmware, which makes it hard to evolve communication protocols and test\nschemes in practical environments. Monitor mode, which allows eavesdropping on\nall frames on a wireless communication channel, is a first step to lower this\nbarrier. Use cases include, but are not limited to, network packet analyses,\nsecurity research and testing of new medium access control layer protocols.\nMonitor mode is generally offered by SoftMAC drivers that implement the media\naccess control sublayer management entity (MLME) in the driver rather than in\nthe Wi-Fi chip. On smartphones, however, mostly FullMAC chips are used to\nreduce power consumption, as MLME tasks do not need to wake up the main\nprocessor. Even though, monitor mode is also possible in FullMAC scenarios, it\nis generally not implemented in today's Wi-Fi firmwares used in smartphones.\nThis work focuses on bringing monitor mode to Nexus 5 smartphones to enhance\nthe interoperability between applications that require monitor mode and BCM4339\nWi-Fi chips. The implementation is based on our new C-based programming\nframework to extend existing Wi-Fi firmwares.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.07077v1"
    },
    {
        "title": "A Method for RFO Estimation Using Phase Analysis of Pilot Symbols in\n  OFDM Systems",
        "authors": [
            "Yong Chan Lee",
            "Won Chol Jang",
            "Yong Hak Sin"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In this paper, a method for CFO/RFO estimation based on proportional\ncoefficients extraction in OFDM system is proposed, which may be applied to any\npilot symbol pattern.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.07625v1"
    },
    {
        "title": "The Pilot Alignment Pattern Design in OFDM Systems",
        "authors": [
            "Yong Chan Lee",
            "Won Chol Jang",
            "Un Kyong Choe",
            "Gyong Chol Leem"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In this paper, we propose optimal pilot pattern of downlink OFDM (Orthogonal\nFrequency Division Multiplexing) communication system.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.07811v1"
    },
    {
        "title": "A Formal Approach to Power Optimization in CPSs with Delay-Workload\n  Dependence Awareness",
        "authors": [
            "Hyung-Chan An",
            "Hoeseok Yang",
            "Soonhoi Ha"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The design of cyber-physical systems (CPSs) faces various new challenges that\nare unheard of in the design of classical real-time systems. Power optimization\nis one of the major design goals that is witnessing such new challenges. The\npresence of interaction between the cyber and physical components of a CPS\nleads to dependence between the time delay of a computational task and the\namount of workload in the next iteration. We demonstrate that it is essential\nto take this delay-workload dependence into consideration in order to achieve\nlow power consumption.\n  In this paper, we identify this new challenge, and present the first formal\nand comprehensive model to enable rigorous investigations on this topic. We\npropose a simple power management policy, and show that this policy achieves a\nbest possible notion of optimality. In fact, we show that the optimal power\nconsumption is attained in a \"steady-state\" operation and a simple policy of\nfinding and entering this steady state suffices, which can be quite surprising\nconsidering the added complexity of this problem. Finally, we validated the\nefficiency of our policy with experiments.\n",
        "pdf_link": "http://arxiv.org/pdf/1601.08046v1"
    },
    {
        "title": "Using Newton's method to model a spatial light distribution of a LED\n  with attached secondary optics",
        "authors": [
            "David Kaljun",
            "Joze Petrii",
            "Janez erovnik"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In design of optical systems based on LED (Light emitting diode) technology,\na crucial task is to handle the unstructured data describing properties of\noptical elements in standard formats. This leads to the problem of data fitting\nwithin an appropriate model. Newton's method is used as an upgrade of\npreviously developed most promising discrete optimization heuristics showing\nimprovement of both performance and quality of solutions. Experiment also\nindicates that a combination of an algorithm that finds promising initial\nsolutions as a preprocessor to Newton's method may be a winning idea, at least\non some datasets of instances.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.01090v1"
    },
    {
        "title": "In-Vehicle PLC: In-Car and In-Ship Channel Characterization",
        "authors": [
            "Alberto Pittolo",
            "Marco De Piante",
            "Fabio Versolatto",
            "Andrea M. Tonello"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper deals with power line communication (PLC) in the context of\nin-vehicle data networks. This technology can provide high-speed data\nconnectivity via the exploitation of the existing power network, with clear\npotential benefits in terms of cost and weight reduction. The focus is on two\nscenarios: an electric car and a cruise ship. An overview of the wiring\ninfrastructure and the network topology in these two scenarios is provided. The\nmain findings reported in the literature related to the channel characteristics\nare reported. Noise is also assessed with emphasis to the electric car context.\nThen, new results from the statistical analysis of measurements made in a\ncompact electric car and in a large cruise ship are shown. The channel\ncharacteristics are analysed in terms of average channel gain, delay spread,\ncoherence bandwidth and achievable transmission rate. Finally, an overall\ncomparison is made, highlighting similarities and differences taking into\naccount also the conventional (combustion engine) car and the largely\ninvestigated in-home scenario.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.02260v1"
    },
    {
        "title": "Microprocessor Optimizations for the Internet of Things: A Survey",
        "authors": [
            "Tosiron Adegbija",
            "Anita Rogacs",
            "Chandrakant Patel",
            "Ann Gordon-Ross"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The Internet of Things (IoT) refers to a pervasive presence of interconnected\nand uniquely identifiable physical devices. These devices' goal is to gather\ndata and drive actions in order to improve productivity, and ultimately reduce\nor eliminate reliance on human intervention for data acquisition,\ninterpretation, and use. The proliferation of these connected low-power devices\nwill result in a data explosion that will significantly increase data\ntransmission costs with respect to energy consumption and latency. Edge\ncomputing reduces these costs by performing computations at the edge nodes,\nprior to data transmission, to interpret and/or utilize the data. While much\nresearch has focused on the IoT's connected nature and communication\nchallenges, the challenges of IoT embedded computing with respect to device\nmicroprocessors has received much less attention. This paper explores IoT\napplications' execution characteristics from a microarchitectural perspective\nand the microarchitectural characteristics that will enable efficient and\neffective edge computing. To tractably represent a wide variety of\nnext-generation IoT applications, we present a broad IoT application\nclassification methodology based on application functions, to enable quicker\nworkload characterizations for IoT microprocessors. We then survey and discuss\npotential microarchitectural optimizations and computing paradigms that will\nenable the design of right-provisioned microprocessors that are efficient,\nconfigurable, extensible, and scalable. This paper provides a foundation for\nthe analysis and design of a diverse set of microprocessor architectures for\nnext-generation IoT devices.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.02393v2"
    },
    {
        "title": "The Design Principles of Konrad Zuse's Mechanical Computers",
        "authors": [
            "Raul Rojas"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Konrad Zuse built the Z1, a mechanical programmable computing machine,\nbetween 1935/36 and 1937/38. The Z1 was a binary floating-point computing\ndevice. The individual logical gates were constructed using metallic plates and\ninterconnection rods. This paper describes the design principles Zuse followed\nin order to complete a complex calculating machine, as the Z1 was. Zuse called\nhis basic switching elements \"mechanical relays\" in analogy to the electrical\nrelays used in telephony.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.02396v1"
    },
    {
        "title": "Mapping EU fishing activities using ship tracking data",
        "authors": [
            "Michele Vespe",
            "Maurizio Gibin",
            "Alfredo Alessandrini",
            "Fabrizio Natale",
            "Fabio Mazzarella",
            "Giacomo C. Osio"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Information and understanding of fishing activities at sea are fundamental\ncomponents of marine knowledge and maritime situational awareness. Such\ninformation is important to fisheries science, public authorities and policy\nmakers. In this paper we introduce a first map at European scale of EU fishing\nactivities extracted using Automatic Identification System (AIS) ship tracking\ndata. The resulting map is a density of points that identify fishing\nactivities. A measure of the reliability of such information is also presented\nas a map of coverage reception capabilities.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.03826v3"
    },
    {
        "title": "A (Basis for a) Philosophy of a Theory of Fuzzy Computation",
        "authors": [
            "Apostolos Syropoulos"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Vagueness is a linguistic phenomenon as well as a property of physical\nobjects. Fuzzy set theory is a mathematical model of vagueness that has been\nused to define vague models of computation. The prominent model of vague\ncomputation is the fuzzy Turing machine. This conceptual computing device gives\nan idea of what computing under vagueness means, nevertheless, it is not the\nmost natural model. Based on the properties of this and other models of vague\ncomputing, it is aimed to formulate a basis for a philosophy of a theory of\nfuzzy computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.05162v1"
    },
    {
        "title": "Norm-1 Regularized Consensus-based ADMM for Imaging with a Compressive\n  Antenna",
        "authors": [
            "Juan Heredia Juesas",
            "Ali Molaei",
            "Luis Tirado",
            "William Blackwell",
            "Jose A Martinez Lorenzo"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper presents a novel norm-one-regularized, consensus-based imaging\nalgorithm, based on the Alternating Direction Method of Multipliers (ADMM).\nThis algorithm is capable of imaging composite dielectric and metallic targets\nby using limited amount of data. The distributed capabilities of the ADMM\naccelerates the convergence of the imaging. Recently, a Compressive Reflector\nAntenna (CRA) has been proposed as a way to provide high-sensing-capacity with\na minimum cost and complexity in the hardware architecture. The ADMM algorithm\napplied to the imaging capabilities of the Compressive Antenna (CA) outperforms\ncurrent state of the art iterative reconstruction algorithms, such as\nNesterov-based methods, in terms of computational cost; and it ultimately\nenables the use of a CA in quasi-real-time, compressive sensing imaging\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.05581v1"
    },
    {
        "title": "Multiprocessor Scheduling of a Multi-mode Dataflow Graph Considering\n  Mode Transition Delay",
        "authors": [
            "Hanwoong Jung",
            "Hyunok Oh",
            "Soonhoi Ha"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Synchronous Data Flow (SDF) model is widely used for specifying signal\nprocessing or streaming applications. Since modern embedded applications become\nmore complex with dynamic behavior changes at run-time, several extensions of\nthe SDF model have been proposed to specify the dynamic behavior changes while\npreserving static analyzability of the SDF model. They assume that an\napplication has a finite number of behaviors (or modes) and each behavior\n(mode) is represented by an SDF graph. They are classified as multi-mode\ndataflow models in this paper. While there exist several scheduling techniques\nfor multi-mode dataflow models, no one allows task migration between modes. By\nobserving that the resource requirement can be additionally reduced if task\nmigration is allowed, we propose a multiprocessor scheduling technique of a\nmulti-mode dataflow graph considering task migration between modes. Based on a\ngenetic algorithm, the proposed technique schedules all SDF graphs in all modes\nsimultaneously to minimize the resource requirement. To satisfy the throughput\nconstraint, the proposed technique calculates the actual throughput requirement\nof each mode and the output buffer size for tolerating throughput jitter. We\ncompare the proposed technique with a method which analyzes SDF graphs in each\nexecution mode separately and a method that does not allow task migration for\nsynthetic examples and three real applications: H.264 decoder, vocoder, and LTE\nreceiver algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.05775v1"
    },
    {
        "title": "Beyond Binary Computers: How To Implement Multi-Switch Computer Hardware\n  and Software and; The Advantage of a Multi-Switched Computer",
        "authors": [
            "Givon Zirkind"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper explores the possibilities of using a computing methodology\n--hardware and software-- that employs technology other than binary. I refer to\nthis as \"supra - binary\" computing. Software constructs that use more than\nbinary techniques are discussed. The gains in supra - binary software are\ndemonstrated, which includes supra - binary code being RISC. Possible hardware\nimplementations of a computer with other than binary based architecture are\ndemonstrated and considered. The advantages and possible disadvantages of these\nhardware implementations are discussed. The gain in computing speed is\nevaluated and demonstrated. Supra - binary processing would streamline parallel\nprocessing and make its implementation a built - in feature of the software and\nhardware. Also, supra - binary would bring an advancement to neural networking.\nThis is discussed and demonstrated. In addition, possible applications of supra\n- binary computing to database and neural networking are discussed. Also, the\npossible implementations could be applied to telecommunications with dramatic\nresults.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.06223v1"
    },
    {
        "title": "Continuous-Flow Graph Transportation Distances",
        "authors": [
            "Justin Solomon",
            "Raif Rustamov",
            "Leonidas Guibas",
            "Adrian Butscher"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Optimal transportation distances are valuable for comparing and analyzing\nprobability distributions, but larger-scale computational techniques for the\ntheoretically favorable quadratic case are limited to smooth domains or\nregularized approximations. Motivated by fluid flow-based transportation on\n$\\mathbb{R}^n$, however, this paper introduces an alternative definition of\noptimal transportation between distributions over graph vertices. This new\ndistance still satisfies the triangle inequality but has better scaling and a\nconnection to continuous theories of transportation. It is constructed by\nadapting a Riemannian structure over probability distributions to the graph\ncase, providing transportation distances as shortest-paths in probability\nspace. After defining and analyzing theoretical properties of our new distance,\nwe provide a time discretization as well as experiments verifying its\neffectiveness.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.06927v1"
    },
    {
        "title": "Nipce-Bell or Turing: How to Test Odor Reproduction?",
        "authors": [
            "David Harel"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In a 1950 article in Mind, decades before the existence of anything\nresembling an artificial intelligence system, Alan Turing addressed the\nquestion of how to test whether machines can think, or in modern terminology,\nwhether a computer claimed to exhibit intelligence indeed does so. The current\npaper raises the analogous issue for olfaction: how to test the validity of a\nsystem claimed to reproduce arbitrary odors artificially, in a way recognizable\nto humans, in face of the unavailability of a general naming method for odors.\nAlthough odor reproduction systems are still far from being viable, the\nquestion of how to test candidates thereof is claimed to be interesting and\nnontrivial, and a novel method is proposed. To some extent, the method is\ninspired by Turing`s test for AI, in that it involves a human challenger and\nthe real and artificial entities, yet it is very different: our test is\nconditional, requiring from the artificial no more than is required from the\noriginal, and it employs a novel method of immersion that takes advantage of\nthe availability of near-perfect reproduction methods for sight and sound.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.08666v5"
    },
    {
        "title": "EDF-VD Scheduling of Mixed-Criticality Systems with Degraded Quality\n  Guarantees",
        "authors": [
            "Di Liu",
            "Jelena Spasic",
            "Gang Chen",
            "Nan Guan",
            "Songran Liu",
            "Todor Stefanov",
            "Wang Yi"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper studies real-time scheduling of mixed-criticality systems where\nlow-criticality tasks are still guaranteed some service in the high-criticality\nmode, with reduced execution budgets. First, we present a utilization-based\nschedulability test for such systems under EDF-VD scheduling. Second, we\nquantify the suboptimality of EDF-VD (with our test condition) in terms of\nspeedup factors. In general, the speedup factor is a function with respect to\nthe ratio between the amount of resource required by different types of tasks\nin different criticality modes, and reaches 4/3 in the worst case. Furthermore,\nwe show that the proposed utilization-based schedulability test and speedup\nfactor results apply to the elastic mixed-criticality model as well.\nExperiments show effectiveness of our proposed method and confirm the\ntheoretical suboptimality results.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.01302v1"
    },
    {
        "title": "2.4GHZ Class AB power Amplifier For Healthcare Application",
        "authors": [
            "Wei Cai",
            "Liang Huang",
            "WuJie Wen"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The objective of this research was to design a 2.4 GHz class AB Power\nAmplifier, with 0.18 um SMIC CMOS technology by using Cadence software, for\nhealth care applications. The ultimate goal for such application is to minimize\nthe trade-offs between performance and cost, and between performance and low\npower consumption design. The performance of the power amplifier meets the\nspecification requirements of the desired.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.02455v1"
    },
    {
        "title": "Process Information Model for Sheet Metal Operations",
        "authors": [
            "Ravi Kumar Gupta",
            "Pothala Sreenu",
            "Alain Bernard",
            "Florent Laroche"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The paper extracts the process parameters from a sheet metal part model\n(B-Rep). These process parameters can be used in sheet metal manufacturing to\ncontrol the manufacturing operations. By extracting these process parameters\nrequired for manufacturing, CAM program can be generated automatically using\nthe part model and resource information. A Product model is generated in\nmodeling software and converted into STEP file which is used for extracting\nB-Rep which interned is used to classify and extract feature by using sheet\nmetal feature recognition module. The feature edges are classified as CEEs,\nIEEs, CIEs and IIEs based on topological properties. Database is created for\nmaterial properties of the sheet metal and machine tools required to\nmanufacture features in a part model. The extracted feature, feature's edge\ninformation and resource information are then used to compute process\nparameters and values required to control manufacturing operations. The\nextracted feature, feature's edge information, resource information and process\nparameters are the integral components of the proposed process information\nmodel for sheet metal operations.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.02514v1"
    },
    {
        "title": "An Alternative Framework for Time Series Decomposition and Forecasting\n  and its Relevance for Portfolio Choice: A Comparative Study of the Indian\n  Consumer Durable and Small Cap Sectors",
        "authors": [
            "Jaydip Sen",
            "Tamal Datta Chaudhuri"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  One of the challenging research problems in the domain of time series\nanalysis and forecasting is making efficient and robust prediction of stock\nmarket prices. With rapid development and evolution of sophisticated algorithms\nand with the availability of extremely fast computing platforms, it has now\nbecome possible to effectively extract, store, process and analyze high volume\nstock market time series data. Complex algorithms for forecasting are now\navailable for speedy execution over parallel architecture leading to fairly\naccurate results. In this paper, we have used time series data of the two\nsectors of the Indian economy: Consumer Durables sector and the Small Cap\nsector for the period January 2010 to December 2015 and proposed a\ndecomposition approach for better understanding of the behavior of each of the\ntime series. Our contention is that various sectors reveal different time\nseries patterns and understanding them is essential for portfolio formation.\nFurther, based on this structural analysis, we have also proposed several\nrobust forecasting techniques and analyzed their accuracy in prediction using\nsuitably chosen training and test data sets. Extensive results are presented to\ndemonstrate the effectiveness of our propositions.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.03930v1"
    },
    {
        "title": "Improvement of algorithms to identify transportation modes for\n  MobilitApp, an Android Application to anonymously track citizens in Barcelona",
        "authors": [
            "Gerard Marrugat Torregrosa",
            "Monica Aguilar Igartua",
            "Silvia Puglisi"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  MobilitApp is an Android application whose objective is to obtain mobility\ndata from the citizens of the metropolitan area of Barcelona. The current\nproject is based on the research of more trustful and stronger transport\ndecision algorithms using advantages of accelerometry techniques. The developed\nalgorithm reads data from the mobile's accelerometer and gyroscope and writes\nit in a file that is afterwards sent to the server. This process is executed in\nbackground without interfering in the main application activity. Collected data\nhas been processed and used to analyze the behaviour of the mobility pattern of\nthe distinct transport modalities. The obtained result has been parameters\nwhich allow us to configure a model for each mean activity and designing a\ntransport mode detection algorithm which would use information obtained from\nthe mobile's own sensors. MobilitApp is still executing its main functionality,\nmonitoring mobility data from the citizens. In future versions the solution\nproposed to detect the transport systems will be integrated into the\napplication, in this way the app will work with information obtained from the\ndevice and will not depend on any other services.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.05342v1"
    },
    {
        "title": "The bitwise operations in relation to obtaining Latin squares",
        "authors": [
            "Krasimir Yordzhev"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The main thrust of the article is to provide interesting example, useful for\nstudents of using bitwise operations in the programming languages C ++ and\nJava. As an example, we describe an algorithm for obtaining a Latin square of\narbitrary order. We will outline some techniques for the use of bitwise\noperations.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.07171v2"
    },
    {
        "title": "Requirements for storing electrophysiology data",
        "authors": [
            "Jeff Teeters",
            "Jan Benda",
            "Andrew Davison",
            "Stephen Eglen",
            "Richard C. Gerkin",
            "Jeffrey Grethe",
            "Jan Grewe",
            "Kenneth Harris",
            "Christian Kellner",
            "Yann Le Franc",
            "Roman Mouek",
            "Dimiter Prodanov",
            "Robert Prpper",
            "Hyrum L. Sessions",
            "Leslie Smith",
            "Andrey Sobolev",
            "Friedrich Sommer",
            "Adrian Stoewer",
            "Thomas Wachtler",
            "Barry Wark"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The purpose of this document is to specify the basic data types required for\nstoring electrophysiology and optical imaging data to facilitate computer-based\nneuroscience studies and data sharing. These requirements are being developed\nwithin a working group of the Electrophysiology Task Force in the International\nNeuroinformatics Coordinating Facility (INCF) Program on Standards for Data\nSharing. While this document describes the requirements of the standard\nindependent of the actual storage technology, the Task Force has recommended\nbasing a standard on HDF5. This is in line with a number of groups who are\nalready using HDF5 to store electrophysiology data, although currently without\nbeing based on a standard.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.07673v2"
    },
    {
        "title": "Reservoir Computing for Detection of Steady State in Performance Tests\n  of Compressors",
        "authors": [
            "Eric Aislan Antonelo",
            "Carlos Alberto Flesch",
            "Filipe Schmitz"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Fabrication of devices in industrial plants often includes undergoing quality\nassurance tests or tests that seek to determine some attributes or capacities\nof the device. For instance, in testing refrigeration compressors, we want to\nfind the true refrigeration capacity of the compressor being tested. Such test\n(also called an episode) may take up to four hours, being an actual hindrance\nto applying it to the total number of compressors produced. This work seeks to\nreduce the time spent on such industrial trials by employing Recurrent Neural\nNetworks (RNNs) as dynamical models for detecting when a test is entering the\nso-called steady-state region. Specifically, we use Reservoir Computing (RC)\nnetworks which simplify the learning of RNNs by speeding up training time and\nshowing convergence to a global optimum. Also, this work proposes a\nself-organized subspace projection method for RC networks which uses\ninformation from the beginning of the episode to define a cluster to which the\nepisode belongs to. This assigned cluster defines a particular binary input\nthat shifts the operating point of the reservoir to a subspace of trajectories\nfor the duration of the episode. This new method is shown to turn the RC model\nrobust in performance with respect to varying combination of reservoir\nparameters, such as spectral radius and leak rate, when compared to a standard\nRC network.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.00782v1"
    },
    {
        "title": "JetsonLEAP: a Framework to Measure Power on a Heterogeneous\n  System-on-a-Chip Device",
        "authors": [
            "Tarsila Bessa",
            "Christopher Gull",
            "Pedro Quinto",
            "Michael Frank",
            "Jos Nacif",
            "Fernando Magno Quinto Pereira"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Computer science marches towards energy-aware practices. This trend impacts\nnot only the design of computer architectures, but also the design of programs.\nHowever, developers still lack affordable and accurate technology to measure\nenergy consumption in computing systems. The goal of this paper is to mitigate\nsuch problem. To this end, we introduce JetsonLEAP, a framework that supports\nthe implementation of energy-aware programs. JetsonLEAP consists of an embedded\nhardware, in our case, the Nvidia Tegra TK1 System-on-a-chip device, a circuit\nto control the flow of energy, of our own design, plus a library to instrument\nprogram parts. We discuss two different circuit setups. The most precise setup\nlets us reliably measure the energy spent by 225,000 instructions, the least\nprecise, although more affordable setup, gives us a window of 975,000\ninstructions. To probe the precision of our system, we use it in tandem with a\nhigh-precision, high-cost acquisition system, and show that results do not\ndiffer in any significant way from those that we get using our simpler\napparatus. Our entire infrastructure - board, power meter and both circuits -\ncan be reproduced with about $500.00. To demonstrate the efficacy of our\nframework, we have used it to measure the energy consumed by programs running\non ARM cores, on the GPU, and on a remote server. Furthermore, we have studied\nthe impact of OpenACC directives on the energy efficiency of high-performance\napplications.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.03042v1"
    },
    {
        "title": "Computational Anatomy in Theano",
        "authors": [
            "Line Khnel",
            "Stefan Sommer"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  To model deformation of anatomical shapes, non-linear statistics are required\nto take into account the non-linear structure of the data space. Computer\nimplementations of non-linear statistics and differential geometry algorithms\noften lead to long and complex code sequences. The aim of the paper is to show\nhow the Theano framework can be used for simple and concise implementation of\ncomplex differential geometry algorithms while being able to handle complex and\nhigh-dimensional data structures. We show how the Theano framework meets both\nof these requirements. The framework provides a symbolic language that allows\nmathematical equations to be directly translated into Theano code, and it is\nable to perform both fast CPU and GPU computations on high-dimensional data. We\nshow how different concepts from non-linear statistics and differential\ngeometry can be implemented in Theano, and give examples of the implemented\ntheory visualized on landmark representations of Corpus Callosum shapes.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.07690v1"
    },
    {
        "title": "Smart Grids Data Analysis: A Systematic Mapping Study",
        "authors": [
            "Bruno Rossi",
            "Stanislav Chren"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Data analytics and data science play a significant role in nowadays society.\nIn the context of Smart Grids (SG), the collection of vast amounts of data has\nseen the emergence of a plethora of data analysis approaches. In this paper, we\nconduct a Systematic Mapping Study (SMS) aimed at getting insights about\ndifferent facets of SG data analysis: application sub-domains (e.g., power load\ncontrol), aspects covered (e.g., forecasting), used techniques (e.g.,\nclustering), tool-support, research methods (e.g., experiments/simulations),\nreplicability/reproducibility of research. The final goal is to provide a view\nof the current status of research. Overall, we found that each sub-domain has\nits peculiarities in terms of techniques, approaches and research methodologies\napplied. Simulations and experiments play a crucial role in many areas. The\nreplicability of studies is limited concerning the provided implemented\nalgorithms, and to a lower extent due to the usage of private datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.00156v2"
    },
    {
        "title": "Sunlight Enabled Vehicle Detection by LED Street Lights",
        "authors": [
            "Weicheng Xue",
            "Shangbin Li",
            "Zhengyuan Xu"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  We propose and demonstrate a preliminary traffic sensing system based on the\nwidely distributed LED street lights. The system utilizes and discriminates the\nphotoelectric responses of the LEDs to sunlight when a vehicle moves through\nthe LEDs' field of view aiming at the road. A data vector is constructed from\nthe consecutively collected time samples of a moving observation window, and a\nsupport vector machine (SVM) based learning algorithm is subsequently developed\nto classify the presence of a vehicle. Finally, we build a simulated platform\nto experimentally evaluate the performance of the vehicle detection algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.01980v1"
    },
    {
        "title": "The alternative bases of Boolean functions as a means of improving the\n  structure of digital blocks",
        "authors": [
            "Sergii Kushch"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This paper analyzes three forms of representation of Boolean functions, such\nas Classical, Algebraic and Reed-Muller. The concept of intersection and\nsubsets of representation forms have been introduced, moreover suitable\ncriteria for creating these subsets have been established. Later, these subsets\nhave been quantitatively compared by the number of parameters, in order to\nassess the effectiveness of using each of the forms of representations proposed\nin the work. Definitions of the specific weight of subsets of priority forms of\nthe representation of Boolean functions showed that the classical form is the\nleast optimal, in comparison with the parameters of other forms Also, it has\nbeen shown that the use of alternative forms of representation of Boolean\nfunctions, in some cases, allows to reduce twice the number of incoming PLA\nbuses. Estimating the average loss from the exclusive use of the Classical Form\nRepresentation also shows that the use of alternatives yields significant\nbenefits in some parameters, this can be used to optimize devices in the logic\ndesign process and reduce the chip area, what also contributes to reductions in\nthe cost of such devices.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.03325v1"
    },
    {
        "title": "Creation and Fixing of Lithography Hotspots with Synopsys Tools",
        "authors": [
            "I-Lun Tseng",
            "Valerio Perez",
            "Yongfu Li",
            "Zhao Chuan Lee",
            "Vikas Tripathi",
            "Jonathan Yoong Seang Ong"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  At advanced process nodes, pattern matching techniques have been used in the\ndetection of lithography hotspots, which can affect yields of manufactured\nintegrated circuits. Although commercial pattern matching and in-design hotspot\nfixing tools have been developed, engineers still need to verify that specific\nhotspot patterns in routed designs can indeed be detected or even repaired by\nsoftware tools. Therefore, there is the need to create test cases with which\ntargeted hotspot patterns can be generated in routed layouts by using an APR\n(automatic placement and routing) tool. In this paper, we propose a methodology\nof creating hotspot patterns in the routing space by using Synopsys tools.\nAlso, methods for repairing hotspots during the physical design phase are\npresented. With the use of the proposed hotspot creation methodology, we can\ngenerate routed designs containing targeted hotspot patterns. As a result, the\neffectiveness of hotspot detection rules, hotspot fixing guidance rules, and\nrelevant software tool functions can be verified.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.05998v1"
    },
    {
        "title": "Context-Aware DFM Rule Analysis and Scoring Using Machine Learning",
        "authors": [
            "Vikas Tripathi",
            "Valerio Perez",
            "Yongfu Li",
            "Zhao Chuan Lee",
            "I-Lun Tseng",
            "Jonathan Ong"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  To evaluate the quality of physical layout designs in terms of\nmanufacturability, DFM rule scoring techniques have been widely used in\nphysical design and physical verification phases. However, one major drawback\nof conventional DFM rule scoring methodologies is that resultant DFM rule\nscores may not accurate since the scores may not highly correspond to\nlithography simulation results. For instance, conventional DFM rule scoring\nmethodologies usually use rule-based techniques to compute scores without\nconsidering neighboring geometric scenarios of targeted layout shapes. That can\nlead to inaccurate scoring results since computed DFM rule scores can be either\ntoo optimistic or too pessimistic. Therefore, in this paper, we propose a novel\napproach with the use of machine learning technology to analyze the context of\ntargeted layouts and predict their lithography impacts on manufacturability.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.05999v1"
    },
    {
        "title": "PhaseMAC: A 14 TOPS/W 8bit GRO based Phase Domain MAC Circuit for\n  In-Sensor-Computed Deep Learning Accelerators",
        "authors": [
            "Kentaro Yoshioka",
            "Yosuke Toyama",
            "Koichiro Ban",
            "Daisuke Yashima",
            "Shigeru Maya",
            "Akihide Sai",
            "Kohei Onizuka"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  PhaseMAC (PMAC), a phase domain Gated-Ring-Oscillator (GRO) based 8bit MAC\ncircuit, is proposed to minimize both area and power consumption of deep\nlearning accelerators. PMAC composes of only digital cells and consumes\nsignificantly smaller power than standard digital designs, owing to its\nefficient analog accumulation nature. It occupies 26.6 times smaller area than\nconventional analog designs, which is competitive to digital MAC circuits. PMAC\nachieves a peak efficiency of 14 TOPS/W, which is best reported and 48% higher\nthan conventional arts. Results in anomaly detection tasks are demonstrated,\nwhich is the hottest application in the industrial IoT scene.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.09335v1"
    },
    {
        "title": "MMDF2018 Workshop Report",
        "authors": [
            "Chun-An Chou",
            "Xiaoning Jin",
            "Amy Mueller",
            "Sarah Ostadabbas"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Driven by the recent advances in smart, miniaturized, and mass produced\nsensors, networked systems, and high-speed data communication and computing,\nthe ability to collect and process larger volumes of higher veracity real-time\ndata from a variety of modalities is expanding. However, despite research\nthrusts explored since the late 1990's, to date no standard, generalizable\nsolutions have emerged for effectively integrating and processing multimodal\ndata, and consequently practitioners across a wide variety of disciplines must\nstill follow a trial-and-error process to identify the optimum procedure for\neach individual application and data sources. A deeper understanding of the\nutility and capabilities (as well as the shortcomings and challenges) of\nexisting multimodal data fusion methods as a function of data and challenge\ncharacteristics has the potential to deliver better data analysis tools across\nall sectors, therein enabling more efficient and effective automated\nmanufacturing, patient care, infrastructure maintenance, environmental\nunderstanding, transportation networks, energy systems, etc. There is therefore\nan urgent need to identify the underlying patterns that can be used to\ndetermine a priori which techniques will be most useful for any specific\ndataset or application. This next stage of understanding and discovery (i.e.,\nthe development of generalized solutions) can only be achieved via a high level\ncross-disciplinary aggregation of learnings, and this workshop was proposed at\nan opportune time as many domains have already started exploring use of\nmultimodal data fusion techniques in a wide range of application-specific\ncontexts.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.10721v1"
    },
    {
        "title": "PlayNPort: A Portable Wireless Music Player and Text Reader System",
        "authors": [
            "Lakhan Shiva Kamireddy",
            "Dharmik Thakkar",
            "Lakhan Saiteja K"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Portable Consumer Electronics has made a mark in the industry. With the ease\nof use at an accessible price range, they have experienced significant growth\nin the market. Our idea is to develop a portable wireless music player and text\nreader using a Cortex-M series microcontroller and bare-metal programming\ntechniques. We chose to use an SD card as the storage device. The resulting\nelectronic device is similar to a consumer grade music player available in a\ncar. The system comprises an MCU, an MP3 encoder/decoder, an LCD, an audio\noutput jack, an SD card and a remote control. We also present various\nchallenges involved in developing the system and solutions we used to overcome\nthe challenges. The intricacy of the work lies in the fact that the system was\ndeveloped to be consumer-centric by providing a rich User Experience. It can be\nused as a personal entertainment system in a car.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.00406v1"
    },
    {
        "title": "Theoretical analysis and propositions for \"ontology citation\"",
        "authors": [
            "Biswanath Dutta"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Ontology citation, the practice of referring the ontology in a similar\nfashion the scientific community routinely follows in providing the\nbibliographic references to other scholarly works, has not received enough\nattention it supposed to. Interestingly, so far none of the existing standard\ncitation styles (e.g., APA, CMOS, and IEEE) have included ontology as a citable\ninformation source in the list of citable information sources such as journal\narticle, book, website, etc. Also, not much work can be found in the literature\non this topic though there are various issues and aspects of it that demand a\nthorough study. For instance, what to cite? Is it the publication that\ndescribes the ontology, or the ontology itself? The citation format, style,\nillustration of motivations of ontology citation, the citation principles,\nontology impact factor, citation analysis, and so forth. In this work, we\nprimarily analyse the current ontology citation practices and the related\nissues. We illustrate the various motivations and the basic principles of\nontology citation. We also propose a template for referring the source of\nontologies.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.01462v1"
    },
    {
        "title": "Web Based Information System for Heat Supply Monitoring",
        "authors": [
            "Borislav Stoyanov",
            "Strahil Strahilov"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The paper presents web based information system for heat supply monitoring.\nThe proposed model and information system for gathering data from heating\nstation heat-flow meters and regulators is software realized. The novel system\nwith proved functionality can be commercialized at the cost of minimal\ninvestments, finding wildly use on Bulgarian market as cheap and quality\nalternative of the western systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.01640v1"
    },
    {
        "title": "Current potentials and challenges using Sentinel-1 for broadacre field\n  remote sensing",
        "authors": [
            "Martin Peter Christiansen",
            "Morten Stigaard Laursen",
            "Birgitte Feld Mikkelsen",
            "Nima Teimouri",
            "Rasmus Nyholm Jrgensen",
            "Claus Aage Grn Srensen"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  ESA operates the Sentinel-1 satellites, which provides Synthetic Aperture\nRadar (SAR) data of Earth. Recorded Sentinel-1 data have shown a potential for\nremotely observing and monitoring local conditions on broad acre fields. Remote\nsensing using Sentinel-1 have the potential to provide daily updates on the\ncurrent conditions in the individual fields and at the same time give an\noverview of the agricultural areas in the region. Research depends on the\nability of independent validation of the presented results. In the case of the\nSentinel-1 satellites, every researcher has access to the same base dataset,\nand therefore independent validation is possible. Well documented research\nperformed with Sentinel-1 allow other research the ability to redo the\nexperiments and either validate or falsify presented findings. Based on current\nstate-of-art research we have chosen to provide a service for researchers in\nthe agricultural domain. The service allows researchers the ability to monitor\nlocal conditions by using the Sentinel-1 information combined with a priori\nknowledge from broad acre fields. Correlating processed Sentinel-1 to the\nactual conditions is still a task the individual researchers must perform to\nbenefit from the service. In this paper, we presented our methodology in\ntranslating sentinel-1 data to a level that is more accessible to researchers\nin the agricultural field. The goal here was to make the data more easily\navailable, so the primary focus can be on correlating and comparing to\nmeasurements collected in the broadacre fields. We illustrate the value of the\nservice with three examples of the possible application areas. The presented\napplication examples are all based on Denmark, where we have processed all\nsentinel-1 scan from since 2016.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.01652v1"
    },
    {
        "title": "CrowdExpress: A Probabilistic Framework for On-Time Crowdsourced Package\n  Deliveries",
        "authors": [
            "Chao Chen",
            "Sen Yang",
            "Weichen Liu",
            "Yasha Wang",
            "Bin Guo",
            "Daqing Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Speed and cost of logistics are two major concerns to on-line shoppers, but\nthey generally conflict with each other in nature. To alleviate the\ncontradiction, we propose to exploit existing taxis that are transporting\npassengers on the street to relay packages collaboratively, which can\nsimultaneously lower the cost and accelerate the speed. Specifically, we\npropose a probabilistic framework containing two phases called CrowdExpress for\nthe on-time package express deliveries. In the first phase, we mine the\nhistorical taxi GPS trajectory data offline to build the package transport\nnetwork. In the second phase, we develop an online adaptive taxi scheduling\nalgorithm to find the path with the maximum arriving-on-time probability\n\"on-the-fly\" upon real- time requests, and direct the package routing\naccordingly. Finally, we evaluate the system using the real-world taxi data\ngenerated by over 19,000 taxis in a month in the city of New York, US. Results\nshow that around 9,500 packages can be delivered successfully on time per day\nwith the success rate over 94%, moreover, the average computation time is\nwithin 25 milliseconds.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.02897v1"
    },
    {
        "title": "UAV Aided Aerial-Ground IoT for Air Quality Sensing in Smart City:\n  Architecture, Technologies and Implementation",
        "authors": [
            "Zhiwen Hu",
            "Zixuan Bai",
            "Yuzhe Yang",
            "Zijie Zheng",
            "Kaigui Bian",
            "Lingyang Song"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  As air pollution is becoming the largest environmental health risk, the\nmonitoring of air quality has drawn much attention in both theoretical studies\nand practical implementations. In this article, we present a real-time,\nfine-grained and power-efficient air quality monitoring system based on aerial\nand ground sensing. The architecture of this system consists of four layers:\nthe sensing layer to collect data, the transmission layer to enable\nbidirectional communications, the processing layer to analyze and process the\ndata, and the presentation layer to provide graphic interface for users. Three\nmajor techniques are investigated in our implementation, given by the data\nprocessing, the deployment strategy and the power control. For data processing,\nspacial fitting and short-term prediction are performed to eliminate the\ninfluences of the incomplete measurement and the latency of data uploading. The\ndeployment strategies of ground sensing and aerial sensing are investigated to\nimprove the quality of the collected data. The power control is further\nconsidered to balance between power consumption and data accuracy. Our\nimplementation has been deployed in Peking University and Xidian University\nsince February 2018, and has collected about 100 thousand effective data\nsamples by June 2018.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.03746v1"
    },
    {
        "title": "A Conceptual Approach to Complex Model Management with Generalized\n  Modelling Patterns and Evolutionary Identification",
        "authors": [
            "Sergey V. Kovalchuk",
            "Oleg G. Metsker",
            "Anastasia A. Funkner",
            "Ilia O. Kisliakovskii",
            "Nikolay O. Nikitin",
            "Anna V. Kalyuzhnaya",
            "Danila A. Vaganov",
            "Klavdiya O. Bochenina"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Complex systems' modeling and simulation are powerful ways to investigate a\nmultitude of natural phenomena providing extended knowledge on their structure\nand behavior. However, enhanced modeling and simulation require integration of\nvarious data and knowledge sources, models of various kinds (data-driven\nmodels, numerical models, simulation models, etc.), intelligent components in\none composite solution. Growing complexity of such composite model leads to the\nneed of specific approaches for management of such model. This need extends\nwhere the model itself becomes a complex system. One of the important aspects\nof complex model management is dealing with the uncertainty of various kinds\n(context, parametric, structural, input/output) to control the model. In the\nsituation where a system being modeled, or modeling requirements change over\ntime, specific methods and tools are needed to make modeling and application\nprocedures (meta-modeling operations) in an automatic manner. To support\nautomatic building and management of complex models we propose a general\nevolutionary computation approach which enables managing of complexity and\nuncertainty of various kinds. The approach is based on an evolutionary\ninvestigation of model phase space to identify the best model's structure and\nparameters. Examples of different areas (healthcare, hydrometeorology, social\nnetwork analysis) were elaborated with the proposed approach and solutions.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.04656v1"
    },
    {
        "title": "OpenMPL: An Open Source Layout Decomposer",
        "authors": [
            "Wei Li",
            "Yuzhe Ma",
            "Qi Sun",
            "Yibo Lin",
            "Iris Hui-Ru Jiang",
            "Bei Yu",
            "David Z. Pan"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Multiple patterning lithography has been widely adopted in advanced\ntechnology nodes of VLSI manufacturing. As a key step in the design flow,\nmultiple patterning layout decomposition (MPLD) is critical to design closure.\nDue to the NP-hardness of the general decomposition problem, various efficient\nalgorithms have been proposed with high quality solutions. However, with\nincreasingly complicated design flow and peripheral processing steps,\ndeveloping a high-quality layout decomposer becomes more and more difficult,\nslowing down the further advancement in this field. This paper presents OpenMPL\n[1], an open-source layout decomposition framework, with well-separated\nperipheral processing and the core solving steps. We demonstrate the\nflexibility of the framework with efficient implementations of various\nstate-of-the-art algorithms, which enable us to reproduce most of the recent\nresults on widely-recognized benchmarks. We believe OpenMPL can pave the road\nfor developing layout decomposition engines and stimulate further researches on\nthis problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.07554v3"
    },
    {
        "title": "UVM Based Reusable Verification IP for Wishbone Compliant SPI Master\n  Core",
        "authors": [
            "Lakhan Shiva Kamireddy",
            "Lakhan Saiteja Kamireddy"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The System on Chip design industry relies heavily on functional verification\nto ensure that the designs are bug-free. As design engineers are coming up with\nincreasingly dense chips with much functionality, the functional verification\nfield has advanced to provide modern verification techniques. In this paper, we\npresent verification of a wishbone compliant Serial Peripheral Interface (SPI)\nMaster core using a System Verilog based standard verification methodology, the\nUniversal Verification Methodology (UVM). The reason for using UVM factory\npattern with parameterized classes is to develop a robust and reusable\nverification IP. SPI is a full duplex communication protocol used to interface\ncomponents most likely in embedded systems. We have verified an SPI Master IP\ncore design that is wishbone compliant and compatible with SPI protocol and bus\nand furnished the results of our verification. We have used QuestaSim for\nsimulation and analysis of waveforms, Integrated Metrics Center, Cadence for\ncoverage analysis. We also propose interesting future directions for this work\nin developing reliable systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1809.10845v1"
    },
    {
        "title": "Exploring the Scope of Unconstrained Via Minimization by Recursive\n  Floorplan Bipartitioning",
        "authors": [
            "Bapi Kar",
            "Susmita Sur-Kolay",
            "Chittaranjan Mandal"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Random via failure is a major concern for post-fabrication reliability and\npoor manufacturing yield. A demanding solution to this problem is redundant via\ninsertion during post-routing optimization. It becomes very critical when a\nmulti-layer routing solution already incurs a large number of vias. Very few\nglobal routers addressed unconstrained via minimization (UVM) problem, while\nusing minimal pattern routing and layer assignment of nets. It also includes a\nrecent floorplan based early global routability assessment tool STAIRoute\n\\cite{karb2}.\n  This work addresses an early version of unconstrained via minimization\nproblem during early global routing by identifying a set of minimal bend\nrouting regions in any floorplan, by a new recursive bipartitioning framework.\nThese regions facilitate monotone pattern routing of a set of nets in the\nfloorplan by STAIRoute. The area/number balanced floorplan bipartitionining is\na multi-objective optimization problem and known to be NP-hard \\cite{majum2}.\nNo existing approaches considered bend minimization as an objective and some of\nthem incurred higher runtime overhead. In this paper, we present a Greedy as\nwell as randomized neighbor search based staircase wave-front propagation\nmethods for obtaining optimal bipartitioning results for minimal bend routing\nthrough multiple routing layers, for a balanced trade-off between routability,\nwirelength and congestion.\n  Experiments were conducted on MCNC/GSRC floorplanning benchmarks for studying\nthe variation of early via count obtained by STAIRoute for different values of\nthe trade-off parameters ($\\gamma, \\beta$) in this multi-objective optimization\nproblem, using $8$ metal layers. We studied the impact of ($\\gamma, \\beta$)\nvalues on each of the objectives as well as their linear combination function\n$Gain$ of these objectives.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.05161v1"
    },
    {
        "title": "Future Perspectives of Co-Simulation in the Smart Grid Domain",
        "authors": [
            "Cornelius Steinbrink",
            "Florian Schlgl",
            "Davood Babazadeh",
            "Sebastian Lehnhoff",
            "Sebastian Rohjans",
            "Anand Narajan"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The recent attention towards research and development in cyber-physical\nenergy systems has introduced the necessity of emerging multi-domain\nco-simulation tools. Different educational, research and industrial efforts\nhave been set to tackle the co-simulation topic from several perspectives. The\nmajority of previous works has addressed the standardization of models and\ninterfaces for data exchange, automation of simulation, as well as improving\nperformance and accuracy of co-simulation setups. Furthermore, the domains of\ninterest so far have involved communication, control, markets and the\nenvironment in addition to physical energy systems. However, the current\ncharacteristics and state of co-simulation testbeds need to be re-evaluated for\nfuture research demands. These demands vary from new domains of interest, such\nas human and social behavior models, to new applications of co-simulation, such\nas holistic prognosis and system planning. This paper aims to formulate these\nresearch demands that can then be used as a road map and guideline for future\ndevelopment of co-simulation in cyber-physical energy systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06862v1"
    },
    {
        "title": "Smart Grid Co-Simulation with MOSAIK and HLA: A Comparison Study",
        "authors": [
            "Cornelius Steinbrink",
            "Arjen A. van der Meer",
            "Milos Cvetkovic",
            "Davood Babazadeh",
            "Sebastian Rohjans",
            "Peter Palensky",
            "Sebastian Lehnhoff"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Evaluating new technological developments for energy systems is becoming more\nand more complex. The overall application environment is a continuously growing\nand interconnected cyber-physical system so that analytical assessment is\npractically impossible to realize. Consequently, new solutions must be\nevaluated in simulation studies. Due to the interdisciplinarity of the\nsimulation scenarios, various heterogeneous tools must be connected. This\napproach is known as co-simulation. During the last years, different approaches\nhave been developed or adapted for applications in energy systems. In this\npaper, two co-simulation approaches are compared that follow generic, versatile\nconcepts. The tool mosaik, which has been explicitly developed for the purpose\nof co-simulation in complex energy systems, is compared to the High Level\nArchitecture (HLA), which possesses a domain-independent scope but is often\nemployed in the energy domain. The comparison is twofold, considering the\ntools' conceptual architectures as well as results from the simulation of\nrepresentative test cases. It suggests that mosaik may be the better choice for\nentry-level, prototypical co-simulation while HLA is more suited for complex\nand extensive studies.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.06877v1"
    },
    {
        "title": "Real-time Structural Health Monitoring System Using Internet of Things\n  and Cloud Computing",
        "authors": [
            "Hung-Fu Chang",
            "Tzu-Kang Lin"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Real-time monitoring of various structural behaviors, particularly\ndisplacement and acceleration, serves important and valuable information for\npeople; for example, they can be used for active control or damage warning.\nWith recent advancement of the Internet of Things and client-side web\ntechnologies, wireless integrated sensor devices nowadays can process real-time\nraw sensor signal data into target measurements, such as displacement, and then\nsend the results through a standard protocol to the servers on the Internet.\nThe monitoring results are further processed for visualization purpose in the\nservers and the computed results are pushed to connected clients like browsers\nor mobile applications in real-time. We build a real-time cloud-based system\nthat can receive heterogeneous IoT data, allow users to create a\nthree-dimensional model online according to the real world structure, and the\nmonitoring results can be visualized in that model. In this paper, we\nillustrate the software architecture of the proposed system and focus on the\ntechnologies that are used, like client-side scripting, NoSql database, and\nsocket communication. We also present the challenges of displaying the overall\nmovement and shape transformation of the 3D structural model. Thus, each\ninternal-connected element's rotations and translations are obtained by\nconverting the monitoring results of each sensor device measured in the global\ncoordinate system. To overcome this, we create an inverted movement calculation\nmethod. A simple 3D two-level structural model and simulated sensor\ndisplacements are used to demonstrate system function and validate the inverted\nmovement calculation method.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.00670v1"
    },
    {
        "title": "Detecting Multiple Communities Using Quantum Annealing on the D-Wave\n  System",
        "authors": [
            "Christian F. A. Negre",
            "Hayato Ushijima-Mwesigwa",
            "Susan M. Mniszewski"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  A very important problem in combinatorial optimization is partitioning a\nnetwork into communities of densely connected nodes; where the connectivity\nbetween nodes inside a particular community is large compared to the\nconnectivity between nodes belonging to different ones. This problem is known\nas community detection, and has become very important in various fields of\nscience including chemistry, biology and social sciences. The problem of\ncommunity detection is a twofold problem that consists of determining the\nnumber of communities and, at the same time, finding those communities. This\ndrastically increases the solution space for heuristics to work on, compared to\ntraditional graph partitioning problems. In many of the scientific domains in\nwhich graphs are used, there is the need to have the ability to partition a\ngraph into communities with the ``highest quality'' possible since the presence\nof even small isolated communities can become crucial to explain a particular\nphenomenon. We have explored community detection using the power of quantum\nannealers, and in particular the D-Wave 2X and 2000Q machines. It turns out\nthat the problem of detecting at most two communities naturally fits into the\narchitecture of a quantum annealer with almost no need of reformulation. This\npaper addresses a systematic study of detecting two or more communities in a\nnetwork using a quantum annealer.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.09756v1"
    },
    {
        "title": "Information Operations Recognition: from Nonlinear Analysis to\n  Decision-making",
        "authors": [
            "Aleksandr G. Dodonov",
            "Dmitry V. Lande",
            "Vitaliy V. Tsyganok",
            "Oleh V. Andriichuk",
            "Sergii V. Kadenko",
            "Anastasia N. Graivoronskaya"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The book is dedicated to the issues of information operations recognition\nbased on analysis of information space, particularly, web-resources, social\nnetworks, and blogs. In this context, open source intelligence technology\n(OSINT) solves the problem of initial analysis of modern-time information\nflows. The book provides a detailed description of mathematical principles of\ninformation operations recognition, based on mathematical statistics, nonlinear\ndynamics, complex networks theory, information and mathematical modeling,\nsociology. A separate chapter covers the applications of approaches from expert\nestimation theory and decision-making support to information operation\nrecognition. The book is addressed to a broad circle of specialists from\ninformation technology and security domains.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.10876v2"
    },
    {
        "title": "Autonomous CPS mobility securely designed",
        "authors": [
            "David Hofbauer",
            "Christoph Schmittner",
            "Manuela Brandstetter",
            "Markus Tauber"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In the last years the interconnection and ongoing development of physical\nsystems combined with cyber resources has led to increasing automation. Through\nthis progress in technology, autonomous vehicles, especially autonomous trains\nare getting more attention from industry and are already under test. The use of\nautonomous trains is known for increasing operation efficiency and reduction of\npersonnel and infrastructure costs, which is mostly considered for main tracks.\nHowever, for less-used secondary lines, autonomous trains and their underlying\nsensor infrastructure are not yet considered. Thus, a system needs to be\ndeveloped, which is less expensive for installation and operation of these\ntrains and underlying infrastructure for secondary lines. Therefore, this\nposition paper describes the process of how to derive an approach to help\ndevelop a digital interlocking system at design time for the use with secondary\nrailway lines. In this work, we motivate the necessary research by\ninvestigating gaps in existing work as well as presenting a possible solution\nfor this problem, a meta-model. The model considers safety, security as well as\ninteroperability like 5G and socio-technical aspects to provide a holistic\nmodeling approach for the development of the interlocking system for industrial\nsecondary line use cases.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.00967v1"
    },
    {
        "title": "Fashion Retail: Forecasting Demand for New Items",
        "authors": [
            "Pawan Kumar Singh",
            "Yadunath Gupta",
            "Nilpa Jha",
            "Aruna Rajan"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Fashion merchandising is one of the most complicated problems in forecasting,\ngiven the transient nature of trends in colours, prints, cuts, patterns, and\nmaterials in fashion, the economies of scale achievable only in bulk\nproduction, as well as geographical variations in consumption. Retailers that\nserve a large customer base spend a lot of money and resources to stay prepared\nfor meeting changing fashion demands, and incur huge losses in unsold inventory\nand liquidation costs [2]. This problem has been addressed by analysts and\nstatisticians as well as ML researchers in a conventional fashion - of building\nmodels that forecast for future demand given a particular item of fashion with\nhistorical data on its sales. To our knowledge, none of these models have\ngeneralized well to predict future demand at an abstracted level for a new\ndesign/style of fashion article. To address this problem, we present a study of\nlarge scale fashion sales data and directly infer which clothing/footwear\nattributes and merchandising factors drove demand for those items. We then\nbuild generalised models to forecast demand given new item attributes, and\ndemonstrate robust performance by experimenting with different neural\narchitectures, ML methods, and loss functions.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.01960v1"
    },
    {
        "title": "TPM: A GPS-based Trajectory Pattern Mining System",
        "authors": [
            "Yang Cao",
            "Jingling Yuan",
            "Song Xiao",
            "Qing Xie"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  With the development of big data and artificial intelligence, the technology\nof urban computing becomes more mature and widely used. In urban computing,\nusing GPS-based trajectory data to discover urban dense areas, extract similar\nurban trajectories, predict urban traffic, and solve traffic congestion\nproblems are all important issues. This paper presents a GPS-based trajectory\npattern mining system called TPM. Firstly, the TPM can mine urban dense areas\nvia clustering the spatial-temporal data, and automatically generate\ntrajectories after the timing trajectory identification. Mainly, we propose a\nmethod for trajectory similarity matching, and similar trajectories can be\nextracted via the trajectory similarity matching in this system. The TPM can be\napplied to the trajectory system equipped with the GPS device, such as the\nvehicle trajectory, the bicycle trajectory, the electronic bracelet trajectory,\netc., to provide services for traffic navigation and journey recommendation.\nMeantime, the system can provide support in the decision for urban resource\nallocation, urban functional region identification, traffic congestion and so\non.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.02678v1"
    },
    {
        "title": "A Theoretical Model For Artificial Learning, Memory Management And\n  Decision Making System",
        "authors": [
            "Ravin Kumar"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Human beings are considered as the most intelligent species on Earth. The\nability to think, to create, to innovate, are the key elements which make\nhumans superior over other existing species on Earth. Machines lack all those\nelements, although machines are faster than human in aspects like computing,\nequating etc. But humans are still more valuable than machines, due to all\nthose previously discussed elements. Various models have been developed in last\nfew years to create models that can think like human beings, but are not\ncompletely successful. This paper presents a new theoretical system for\nlearning, memory management and decision making that can be used to develop\nhighly complex systems, and shows the potential to be used for development of\nsystems that can be used to provide the essential features to the machines to\nact like human beings.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04698v1"
    },
    {
        "title": "Inferring Accurate Bus Trajectories from Noisy Estimated Arrival Time\n  Records",
        "authors": [
            "Lakmal Meegahapola",
            "Noel Athaide",
            "Kasthuri Jayarajah",
            "Shili Xiang",
            "Archan Misra"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Urban commuting data has long been a vital source of understanding population\nmobility behaviour and has been widely adopted for various applications such as\ntransport infrastructure planning and urban anomaly detection. While\nindividual-specific transaction records (such as smart card (tap-in, tap-out)\ndata or taxi trip records) hold a wealth of information, these are often\nprivate data available only to the service provider (e.g., taxicab operator).\nIn this work, we explore the utility in harnessing publicly available, albeit\nnoisy, transportation datasets, such as noisy \"Estimated Time of Arrival\" (ETA)\nrecords (commonly available to commuters through transit Apps or electronic\nsignages). We first propose a framework to extract accurate individual bus\ntrajectories from such ETA records, and present results from both a primary\ncity (Singapore) and a secondary city (London) to validate the techniques.\nFinally, we quantify the upper bound on the spatiotemporal resolution, of the\nreconstructed trajectory outputs, achieved by our proposed technique.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.08483v1"
    },
    {
        "title": "Modeling and analysis of alternative distribution and Physical Internet\n  schemes in urban area",
        "authors": [
            "Hao Jiang",
            "Eric Ballot",
            "Shenle Pan"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Urban logistics is becoming more complicated and costlier due to new\nchallenges in recent years. Since the main problem lies on congestion, the\nclean vehicle is not necessarily the most effective solution. There is thus a\nneed to redesign the logistics networks in the city. This paper proposes a\nmethodology to evaluate different distribution schemes in the city among which\nwe find the most efficient and sustainable one. External impacts are added to\nthe analysis of schemes, including accident, air pollution, climate change,\nnoise, and congestion. An optimization model based on an analytical model is\ndeveloped to optimize transportation means and distribution schemes. Results\nbased on Bordeaux city show that PI scheme improves the performances of\ndistribution.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.10593v1"
    },
    {
        "title": "Prototype Software Monitoring Sarana dan Prasarana Perguruan Tinggi",
        "authors": [
            "Leon Andretti Abdillah",
            "Linda Atika",
            " Kurniawan",
            "Fitri Purwaningtias"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  This study aims to facilitate the management system of monitoring\ninfrastructure program of university facilities and infrastructure, through\nsoftware engineering technology approach as an effort to improve productivity\nand quality of monitoring process become more efficient and effective. The\nsoftware in this research is built in a systematic and organized approach to\nmonitoring infrastructure of facilities and infrastructure using appropriate\ntools and techniques. Through this research, universities are expected to be\nable to develop the necessary quality measures to support the process of\nplanning and controlling infrastructure infrastructure monitoring. The research\nwas conducted using survey method, development of monitoring management and\nsoftware. Up to the design stage of this program prototype, research has\nproduced a special picture of the software requirements to be built in the next\nyear. Software development process starting from the analysis phase of system\nand software requirements, designing data structures up to the architecture\nstage of the program has produced a list of needs/requirements, the design of\nprogram prototype contained in the design of input/output for the monitoring\nprocess facilities and infrastructure.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.13527v1"
    },
    {
        "title": "Conjure Documentation, Release 2.3.0",
        "authors": [
            "zgr Akgn",
            "Andrs Salamon"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Conjure is an automated modelling tool for Constraint Programming. In this\ndocumentation, you will find the following: A brief introduction to Conjure,\ninstallation instructions, a description of how to use Conjure through its\ncommand line user interface, a list of Conjure's features, a description of\nConjure's input language Essence, and a collection of simple demonstrations of\nConjure's use.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.00475v3"
    },
    {
        "title": "A Survey of Benchmarks to Evaluate Data Analytics for Smart-*\n  Applications",
        "authors": [
            "Athanasios Kiatipis",
            "Alvaro Brandon",
            "Rizkallah Touma",
            "Pierre Matri",
            "Michal Zasadzinski",
            "Linh Thuy Nhuyen",
            "Adrien Lebre",
            "Alexandru Costan"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The growth of ubiquitous sensor networks at an accelerating pace cuts across\nmany areas of modern day life. They enable measuring, inferring, understanding\nand acting upon a wide variety of indicators, in fields ranging from\nagriculture to healthcare or to complex urban environments. The applications\ndevoted to this task are designated as Smart-* Applications. They hide a\nstaggering complexity, relying on multiple layers of data collection,\ntransmission, aggregation, analysis and also storage, both at the network edge\nand on the cloud. Furthermore, Smart-* Applications raise additional specific\nchallenges, such as the need to process and extract knowledge from diverse\ndata, which is flowing at high velocity in near real-time or in the heavily\ndistributed environment they rely on. How to assess the performance of such a\ncomplex stack, when faced with the specifics of \\mbox{Smart-*} Applications,\nremains an open research question. In this article, the key specific\ncharacteristics and requirements of Smart-* Applications are initially\ndetailed. Afterwards, for each of these requirements, there is a description of\nthe benchmarks one can use to precisely evaluate the performance of the\nunderlying systems and technologies. Finally, an identification of future\nresearch directions related to identified open issues for benchmarking Smart-*\nApplications is performed.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.02004v1"
    },
    {
        "title": "Information collection for fraud detection in P2P financial market",
        "authors": [
            "Hao Wang",
            "Zonghu Wang",
            "Bin Zhang",
            "Jun Zhou"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Fintech companies have been facing challenges from fraudulent behavior for a\nlong time. Fraud rate in Chinese P2P financial market could go as high as 10%.\nIt is crucial to collect sufficient information of the user as input to the\nanti-fraud process. Data collection framework for Fintech companies are\ndifferent fro m conventional internet firms. With individual-based crawling\nrequest , we need to deal with new challenges negligible elsewhere . In this\npaper , we give an outline of how we collect data from the web to facilitate\nour anti-fraud process. We also overview the challenges and solutions to our\nproblems. Our team at HC Financial Service Group is one of the few companies\nthat are capable of developing full-fledged crawlers on our own.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.02009v1"
    },
    {
        "title": "Simulation Reproducibility of a Chaotic Circuit",
        "authors": [
            "T. E. Nazare",
            "E. G. Nepomuceno"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  An evergreen scientific feature is the ability for scientific works to be\nreproduced. This feature allows researchers to understand, enhance, or even\nquestion works that have been developed by other scientists. In control theory\nthe importance of modeling and simulation of systems is widely recognized.\nDespite this recognition, less attention is paid to the effects of finite\nprecision of computers on the simulation reproducibility of nonlinear dynamic\nsystems. In this work, a case study of reproducibility is presented in the\nsimulation of a chaotic Jerk circuit, using the software LtSpice. In order to\ndo so, we performed simulations of the circuit in the same version of the\nsoftware on different computers, in order to collect the data and compare them\nwith experimental results. The comparison was made with the NRMSE (Normalized\nRoot Mean Square Error), in order to identify the computer with the highest\nprediction horizon. Tests performed in 4 different configurations showed the\ndifficulties of simulation reproducibility in LtSpice. The methodology\ndeveloped was efficient in identifying the computer with better performance,\nwhich allows applying it to other cases in the literature.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.04551v1"
    },
    {
        "title": "What's My Process Model Composed of? A Systematic Literature Review of\n  Meta-Models in BPM",
        "authors": [
            "Greta Adamo",
            "Chiara Ghidini",
            "Chiara Di Francescomarino"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Business process modelling languages typically enable the representation of\nbusiness process models by employing (graphical) symbols. These symbols can\nvary depending upon the verbosity of the language, the modeling paradigm, the\nfocus of the language, and so on. To make explicit the different constructs and\nrules employed by a specific language as well as bridge the gap across\ndifferent languages, meta-models have been proposed in literature. These\nmeta-models are a crucial source of knowledge on what state-of-the-art\nliterature considers relevant to describe business processes. Moreover, the\nrapid growth of techniques and tools that aim at supporting all dimensions of\nbusiness processes and not only its control flow perspective, as for instance\ndata and organisational aspects, makes even more important to have a clear\nidea, already at the conceptual level, of the key process constructs. The goal\nof this work is to provide the first extensive systematic literature review\n(SLR) of business process meta-models. This SLR aims at answering research\nquestions concerning: (i) the kind of meta-models proposed in literature; (ii)\nthe recurring constructs they contain; (iii) their purposes; and (iv) their\nevaluations. Thirty-six papers were selected and evaluated against four\nresearch questions. The results indicate the existence of a reasonable body of\nwork conducted in this specific area, but not a full maturity. In particular,\nwhile traditional paradigms towards business process modelling, and aspects\nrelated to the business process control flow seem to be well present, novel\nparadigms and aspects related to the organisational, data and goal-oriented\naspects of business processes seem to be still under-investigated.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.05564v2"
    },
    {
        "title": "Scalability of TTool's AMS extensions: a case study",
        "authors": [
            "Daniela Genius"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Embedded cyber-physical systems (CPS) are commonly built upon heterogeneous\ndigital and analog integrated circuits, including sensors and actuators. Less\ncommon is their deployment on parallel, NoC based designs based on general\npurpose processor cores of a Multi-processor System-on-chip (MPSoC).\nApplication code has to be run on the MPSoC for the digital part, and interact\nwith the analog sensors. We recently proposed a major extension to the design\nand exploration tool named TTool, now allowing the design of CPS on a high\nlevel of abstraction and the generation of cycle-bit accurate simulations. We\nexplore the scalability of our approach with an automotive case study.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.06091v1"
    },
    {
        "title": "Smart Monitoring: remote-monitoring technology of power, gas, and water\n  consumption in Smart Cities",
        "authors": [
            "Sergey Surnov",
            "Igor Bychkovskiy",
            "Grigory Surnov",
            "Sergey Krasnov"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  This paper describes the remote-collection technology of detailed data (Smart\nMonitoring) on the consumption and quality of energy resources in public\nservices. In this article, under \"energy resources\" (hereinafter referred to as\nresources) we outline electrical power, water (hot and cold), heat, and gas.\nData on resource quality refer to the parameters characterizing the consumed\nresource. We also present an option of the data-acquisition system structure\nbased on Smart Monitoring technology. Particular attention is paid to security\nin the system and the centralized management of its elements. The data flow in\nsuch system carries information about the behavior of energy consumers and the\nhousehold equipment they use. Data on energy consumption for billing purposes\nin such a system is just one of many kinds, and not the most important feature.\nThe development of Smart Monitoring technology is aimed at developing the\nmarket of IT services and mass services based on analysis of collected detailed\ndata on energy-resource consumption.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.08759v1"
    },
    {
        "title": "NDE 4.0 From Design Thinking to Strategy",
        "authors": [
            "Johannes Vrana",
            "Ripudaman Singh"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Cyber technologies are offering new horizons for quality control in\nmanufacturing and safety assurance in-service of physical assets. The line\nbetween non-destructive evaluation (NDE) and Industry 4.0 is getting blurred\nsince both are sensory data-driven domains. This multidisciplinary approach has\nled to the emergence of a new capability: NDE 4.0. The NDT community is coming\ntogether once again to define the purpose, chart the process, and address the\nadoption of emerging technologies. In this paper, the authors have taken a\ndesign thinking approach to spotlight proper objectives for research on this\nsubject. It begins with qualitative research on twenty different perceptions of\nstakeholders and misconceptions around the current state of NDE. The\ninterpretation is used to define ten value propositions or use cases under \"NDE\nfor Industry 4.0\" and \"Industry 4.0 for NDE\" leading up to the clarity of\npurpose for NDE 4.0, enhanced safety and economic value for stakeholders. To\npursue this worthy cause, the paper delves into some of the top adoption\nchallenges, and proposes a journey of managed innovation, conscious skills\ndevelopment, and a new form of leadership required to succeed in the\ncyber-physical world.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07773v2"
    },
    {
        "title": "Current Practices in the Information Collection for Enterprise\n  Architecture Management",
        "authors": [
            "Robert Ehrensperger",
            "Clemens Sauerwein",
            "Ruth Breu"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The digital transformation influences business models, processes, and\nenterprise IT landscape as a whole. Therefore, business-IT alignment is\nbecoming more important than ever before. Enterprise architecture management\n(EAM) is designed to support and improve this business-IT alignment. The\nsuccess of EAM crucially depends on the information available about a company's\nenterprise architecture, such as infrastructure components, applications, and\nbusiness processes. This paper discusses the results of a qualitative expert\nsurvey with 26 experts in the field of EAM. The goal of this survey was to\nhighlight current practices in the information collection for EAM and identify\nrelevant information from enterprise-external data sources. The results provide\na comprehensive overview of collected and utilized information in the industry,\nincluding an assessment of the relevance of such information. Furthermore, the\nresults highlight challenges in practice and point out investments that\norganizations plan in the field of EAM.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.05087v1"
    },
    {
        "title": "NDE 4.0: Digital Twin, Semantics, Interfaces, Networking, Feedback, New\n  Markets and Integration into the Industrial Internet of Things",
        "authors": [
            "Johannes Vrana"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The industrial revolution is divided into three phases by historians: The\ninvention of the steam engine (mechanization), electricity (mass production)\nand the microelectric revolution (automation). There was a similar development\nin non-destructive evaluation: tools such as lenses or stethoscopes allowed the\nhuman senses to be sharpened, the conversion of waves makes the invisible\nvisible and thus offers a \"look\" into the components and finally automation,\ndigitization and reconstruction. During the entire industrial development NDE\nwas decisively responsible for the quality and thus for the success of the\nmanufactured goods. Industry is now talking about a fourth revolution: The\ninformatization, digitization and networking of industrial production. As\nalways, NDE will be critical to the success of this fourth revolution by\nproviding the database needed for feedback in a networked production\nenvironment. For NDE, this will lead to change. The test results must be made\navailable to a networked production environment in such a way that they can be\nevaluated for feedback loops, the testability must be considered in the design\nand the reliability of the test statements will become increasingly important.\nThis publication presents first an orientation to NDE 4.0, including the\ndevelopment of Industry and NDE, a definition of its revolutions, a collection\nof several current-day challenges of NDE, and a discussion whether and how\nthose can be solved with NDE 4.0. Second this publication presents concepts on\nhow NDE can be integrated into Industry 4.0 landscapes: The Reference\nArchitecture Model Industry 4.0 (RAMI 4.0) shows the complete Industry 4.0\nspace and allows every Industry 4.0 standard and interface to be located. The\nIndustry 4.0 Asset Administration Shell (AAS) implements the digital twin and\nis the interface between Industry 4.0 communication and the physical device.\nThe ...\n",
        "pdf_link": "http://arxiv.org/pdf/2004.05193v1"
    },
    {
        "title": "Software-Based Monitoring and Analysis of a USB Host Controller Subject\n  to Electrostatic Discharge",
        "authors": [
            "Natasha Jarus",
            "Antonio Sabatini",
            "Pratik Maheshwari",
            "Sahra Sedigh Sarvestani"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Observing, understanding, and mitigating the effects of failure in embedded\nsystems is essential for building dependable control systems. We develop a\nsoftware-based monitoring methodology to further this goal. This methodology\ncan be applied to any embedded system peripheral and allows the system to\noperate normally while the monitoring software is running. We use software to\ninstrument the operating system kernel and record indicators of system\nbehavior. By comparing those indicators against baseline indicators of normal\nsystem operation, faults can be detected and appropriate action can be taken.\n  We implement this methodology to detect faults caused by electrostatic\ndischarge in a USB host controller. As indicators, we select specific control\nregisters that provide a manifestation of the internal execution of the host\ncontroller. Analysis of the recorded register values reveals differences in\nsystem execution when the system is subject to interference. %We also develop a\nclassifier capable of predicting whether or not the system's behavior is being\naffected by such shocks. This improved understanding of system behavior may\nlead to better hardware and software mitigation of electrostatic discharge and\nassist in root-cause analysis and repair of failures.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.06647v1"
    },
    {
        "title": "Dataset for anomalies detection in 3D printing",
        "authors": [
            "Joanna Sendorek",
            "Tomasz Szydlo",
            "Mateusz Windak",
            "Robert Brzoza-Woch"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Nowadays, Internet of Things plays a significant role in many domains.\nEspecially, Industry 4.0 is making a great usage of concepts like smart sensors\nand big data analysis. IoT devices are commonly used to monitor industry\nmachines and detect anomalies in their work. In this paper we present and\ndescribe a set of data streams coming from working 3D printer. Among others, it\ncontains accelerometer data of printer head, intrusion power and temperatures\nof the printer elements. In order to gain data we lead to several printing\nmalfunctions applied to the 3D model. Resulting dataset can therefore be used\nfor anomalies detection research.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.08817v1"
    },
    {
        "title": "Knowledge Management Systems Requirements Specifications",
        "authors": [
            "Omar S. Al-Kadi"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  In recent years, Knowledge Management Systems (KMS) have drawn remarkable\nattention. However, there is no common understanding of how a knowledge\nmanagement system should look like or where the corresponding research should\nbe directed at. Based on a number of essential requirements that a KMS should\nsatisfy, this report introduces some possible requirements for the\ncommonwealth's KMS components forming the KMS architecture. Also, these\nrequirements will be analysed through evaluating and measuring there\nfunctionality to produce a tangible outcome.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.08961v1"
    },
    {
        "title": "Distributed Resources for the Earth System Grid Advanced Management\n  (DREAM)",
        "authors": [
            "Luca Cinquini",
            "Steve Petruzza",
            "Jason Jerome Boutte",
            "Sasha Ames",
            "Ghaleb Abdulla",
            "Venkatramani Balaji",
            "Robert Ferraro",
            "Aparna Radhakrishnan",
            "Laura Carriere",
            "Thomas Maxwell",
            "Giorgio Scorzelli",
            "Valerio Pascucci"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The DREAM project was funded more than 3 years ago to design and implement a\nnext-generation ESGF (Earth System Grid Federation [1]) architecture which\nwould be suitable for managing and accessing data and services resources on a\ndistributed and scalable environment. In particular, the project intended to\nfocus on the computing and visualization capabilities of the stack, which at\nthe time were rather primitive. At the beginning, the team had the general\nnotion that a better ESGF architecture could be built by modularizing each\ncomponent, and redefining its interaction with other components by defining and\nexposing a well defined API. Although this was still the high level principle\nthat guided the work, the DREAM project was able to accomplish its goals by\nleveraging new practices in IT that started just about 3 or 4 years ago: the\nadvent of containerization technologies (specifically, Docker), the development\nof frameworks to manage containers at scale (Docker Swarm and Kubernetes), and\ntheir application to the commercial Cloud. Thanks to these new technologies,\nDREAM was able to improve the ESGF architecture (including its computing and\nvisualization services) to a level of deployability and scalability beyond the\noriginal expectations.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09599v1"
    },
    {
        "title": "Business Process Re-engineering in Supply Chains Examining the case of\n  the expanding Halal industry",
        "authors": [
            "Mohammed Belkhatir",
            "Shalini Bala",
            "Noureddine Belkhatir"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Due to several issues arising in the rapidly-expanding Halal industry, among\nthem the production of non-genuine or contaminated products and meats, there is\na need to develop effective solutions for ensuring authenticity and quality.\nThis paper proposes the specification of a formalized supply chain framework\nfor the production and monitoring of food and products. The latter enforces\nhigh-level quality of automated monitoring as well as shorter production cycles\nthrough enhanced coordination between the actors and organizations involved.\nOur proposal is guided by business process support to ensure quality and\nefficiency of product development and delivery. It moreover meets the\nrequirements of industrial standards by adopting the Capability Maturity Model\nIntegration highest process maturity level through establishing quantitative\nprocess-improvement objectives, proposing the integrated support of engineering\nprocesses, enforcing synchronization and coordination, drastic monitoring and\nexception handling. We then delve into some of the important technologies from\nthe implementation point-of-view and align it with the formalized Halal\nframework. An Information Technology support instantiation is proposed leading\nto a use case scenario with technology identification.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09796v1"
    },
    {
        "title": "Correlating Unlabeled Events at Runtime",
        "authors": [
            "Iman M. A. Helal",
            "Ahmed Awad"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Process mining is of great importance for both data-centric and\nprocess-centric systems. Process mining receives so-called process logs which\nare collections of partially-ordered events. An event has to possess at least\nthree attributes, case ID, task ID and a timestamp for mining approaches to\nwork. When a case ID is unknown, the event is called unlabeled. Traditionally,\nprocess mining is an offline task, where events are collected from different\nsources are usually manually correlated. That is, events belonging to the same\ninstance are assigned the same case ID. With today's high-volume/high-speed\nnature of, e.g., IoT applications, process mining shifts to be an online task.\nFor this, event correlation has to be automated and has to occur as the data is\ngenerated. In this paper, we introduce an approach that correlates unlabeled\nevents at runtime. Given a process model, a stream of unlabeled events and\nother information about task duration, our approach can induce a case\nidentifier to a set of unlabeled events with a trust percentage. It can also\ncheck the conformance of the identified cases with the process model. A\nprototype of the proposed approach was implemented and evaluated against\nreal-life and synthetic logs.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.09971v1"
    },
    {
        "title": "ROOT I/O compression improvements for HEP analysis",
        "authors": [
            "Oksana Shadura",
            "Brian Paul Bockelman",
            "Philippe Canal",
            "Danilo Piparo",
            "Zhe Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  We overview recent changes in the ROOT I/O system, increasing performance and\nenhancing it and improving its interaction with other data analysis ecosystems.\nBoth the newly introduced compression algorithms, the much faster bulk I/O data\npath, and a few additional techniques have the potential to significantly to\nimprove experiment's software performance. The need for efficient lossless data\ncompression has grown significantly as the amount of HEP data collected,\ntransmitted, and stored has dramatically increased during the LHC era. While\ncompression reduces storage space and, potentially, I/O bandwidth usage, it\nshould not be applied blindly: there are significant trade-offs between the\nincreased CPU cost for reading and writing files and the reduce storage space.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.10531v1"
    },
    {
        "title": "Business Email Compromise (BEC) and Cyberpsychology",
        "authors": [
            "Alessandro Ecclesie Agazzi"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The paper gives a brief introduction about what BEC (Business Email\nCompromise) is and why we should be concerned about. In addition, it presents 2\nexamples, Ubiquity and Peebles Media Group, which have been chosen to analyse\nthe phenomena of BEC and underpin how universal BEC threat is for all\ncompanies. The psychology behind this scam has been, then, studied. In\nparticular, the Big Five Framework has been analysed to understand how\npersonality traits play an important role in Social Engineering-based attacks.\nFurthermore, the 6 basic principles of influence, by Cialdini, have been\npresented to show which strategies are adopted in such scam. The paper follows\nwith the analysis of the BEC impacts, the incidents evaluation and, finally,\nwith the description of some precautions, that companies should undertake in\norder to mitigate the likelihood of a Business Email Compromise.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.02415v1"
    },
    {
        "title": "A Research Agenda on Pediatric Chest X-Ray: Is Deep Learning Still in\n  Childhood?",
        "authors": [
            "Afonso U. Fonseca",
            "Gabriel S. Vieira",
            "Fabrzzio A. A. M. N. Soares",
            "Renato F. Bulco-Neto"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Several reasons explain the significant role that chest X-rays play on\nsupporting clinical analysis and early disease detection in pediatric patients,\nsuch as low cost, high resolution, low radiation levels, and high availability.\nIn the last decade, Deep Learning (DL) has been given special attention from\nthe computer-aided diagnosis research community, outperforming the state of the\nart of many techniques, including those applied to pediatric chest X-rays\n(PCXR). Due to this increasing interest, much high-quality secondary research\nhas also arisen, overviewing machine learning and DL algorithms on medical\nimaging and PCXR, in particular. However, these secondary studies follow\ndifferent guidelines, hampering their reproduction or improvement by\nthird-parties regarding the identified trends and gaps. This paper proposes a\n\"deep radiography\" of primary research on DL techniques applied in PCXR images.\nWe elaborated on a Systematic Literature Mapping (SLM) protocol, including\nautomatic search on six sources for studies published from January 1, 2010, to\nMay 20, 2020, and selection criteria utilized on a hundred research papers. As\na result, this paper categorizes twenty-six relevant studies and provides a\nresearch agenda highlighting limitations, gaps, and trends for further\ninvestigations on DL usage in PCXR images. Besides the fact that there is no\nsystematic mapping study on this research topic, to the best of authors'\nknowledge, this work organizes the process of finding and selecting relevant\nstudies and data gathering and synthesis in a reproducible way.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11369v2"
    },
    {
        "title": "Observing the Invisible: Live Cache Inspection for High-Performance\n  Embedded Systems",
        "authors": [
            "Dharmesh Tarapore",
            "Shahin Roozkhosh",
            "Steven Brzozowski",
            "Renato Mancuso"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The vast majority of high-performance embedded systems implement multi-level\nCPU cache hierarchies. But the exact behavior of these CPU caches has\nhistorically been opaque to system designers. Absent expensive hardware\ndebuggers, an understanding of cache makeup remains tenuous at best. This\nenduring opacity further obscures the complex interplay among applications and\nOS-level components, particularly as they compete for the allocation of cache\nresources. Notwithstanding the relegation of cache comprehension to proxies\nsuch as static cache analysis, performance counter-based profiling, and cache\nhierarchy simulations, the underpinnings of cache structure and evolution\ncontinue to elude software-centric solutions. In this paper, we explore a novel\nmethod of studying cache contents and their evolution via snapshotting. Our\nmethod complements extant approaches for cache profiling to better formulate,\nvalidate, and refine hypotheses on the behavior of modern caches. We leverage\ncache introspection interfaces provided by vendors to perform live cache\ninspections without the need for external hardware. We present CacheFlow, a\nproof-of-concept Linux kernel module which snapshots cache contents on an\nNVIDIA Tegra TX1 SoC (system on chip).\n",
        "pdf_link": "http://arxiv.org/pdf/2007.12271v1"
    },
    {
        "title": "Genetic Algorithm: Reviews, Implementations, and Applications",
        "authors": [
            "Tanweer Alam",
            "Shamimul Qamar",
            "Amit Dixit",
            "Mohamed Benaida"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Nowadays genetic algorithm (GA) is greatly used in engineering pedagogy as an\nadaptive technique to learn and solve complex problems and issues. It is a\nmeta-heuristic approach that is used to solve hybrid computation challenges. GA\nutilizes selection, crossover, and mutation operators to effectively manage the\nsearching system strategy. This algorithm is derived from natural selection and\ngenetics concepts. GA is an intelligent use of random search supported with\nhistorical data to contribute the search in an area of the improved outcome\nwithin a coverage framework. Such algorithms are widely used for maintaining\nhigh-quality reactions to optimize issues and problems investigation. These\ntechniques are recognized to be somewhat of a statistical investigation process\nto search for a suitable solution or prevent an accurate strategy for\nchallenges in optimization or searches. These techniques have been produced\nfrom natural selection or genetics principles. For random testing, historical\ninformation is provided with intelligent enslavement to continue moving the\nsearch out from the area of improved features for processing of the outcomes.\nIt is a category of heuristics of evolutionary history using behavioral\nscience-influenced methods like an annuity, gene, preference, or combination\n(sometimes refers to as hybridization). This method seemed to be a valuable\ntool to find solutions for problems optimization. In this paper, the author has\nexplored the GAs, its role in engineering pedagogies, and the emerging areas\nwhere it is using, and its implementation.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.12673v1"
    },
    {
        "title": "3D city models for urban farming site identification in buildings",
        "authors": [
            "Ankit Palliwal",
            "Shuang Song",
            "Hugh Tiang Wah Tan",
            "Filip Biljecki"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Studies have suggested that there is farming potential in residential\nbuildings. However, these studies are limited in scope, require field visits\nand time-consuming measurements. Furthermore, they have not suggested ways to\nidentify suitable sites on a larger scale let alone means of surveying numerous\nmicro-locations across the same building. Using a case study area focused on\nhigh-rise buildings in Singapore, this paper examines a novel application of 3D\ncity models to identify suitable farming micro-locations in buildings. We\nspecifically investigate whether the vertical spaces of these buildings\ncomprising outdoor corridors, fa\\c{c}ades and windows receive sufficient\nphotosynthetically active radiation (PAR) for growing food crops and do so at a\nhigh resolution. We also analyze the spatio-temporal characteristics of PAR,\nand the impact of shadows and different weather conditions on PAR in the\nbuilding. Environmental simulations on the 3D model of the study area indicated\nthat the cumulative daily PAR or Daily Light Integral (DLI) at a location in\nthe building was dependent on its orientation and shape, sun's diurnal and\nannual motion, weather conditions, and shadowing effects of the building's\nfa\\c{c}ades and surrounding buildings. The DLI in the study area generally\nincreased with building's levels and, depending on the particular\nmicro-location, was found suitable for growing moderately light-demanding crops\nsuch as lettuce and sweet pepper. These variations in DLI at different\nlocations of the same building affirmed the need for such simulations. The\nsimulations were validated with field measurements of PAR, and correlation\ncoefficients between them exceeded 0.5 in most cases thus, making a case that\n3D city models offer a promising practical solution to identifying suitable\nfarming locations in residential buildings, and have the potential for\nurban-scale applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.14203v2"
    },
    {
        "title": "To Lane or Not to Lane? Comparing On-Road Experiences in Developing and\n  Developed Countries using a New Simulator \"RoadBird\"",
        "authors": [
            "Md. Masum Mushfiq",
            "Tarik Reza Toha",
            "Saiful Islam Salim",
            "Aaiyeesha Mostak",
            "Masfiqur Rahaman",
            "Najla Abdulrahman Al-Nabhan",
            "Arif Mohamin Sadri",
            "A. B. M. Alim Al Islam"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Even though the traffic systems in developed countries have been analyzed\nwith rigor and operated efficiently, the same does not generally hold for\ndeveloping countries due to inadequate planning, design, and operations of\ntheir transportation systems. Because of inherent differences between internal\ninfrastructures, the systems deployed in developed countries may not be\namenable to developing ones. Besides, the traffic systems of developing\ncountries are not well-studied in the literature to the best of our knowledge.\nFor example, it is yet to explore how a developed country's lane-based traffic\nflow would perform in the context of a developing country, which generally\nexperiences non-lane-based traffic. As such, by using our newly developed\ntraffic simulator 'RoadBird', we investigate outcomes of both lane-based and\nnon-lane-based traffic from the contexts of both developing and developed\ncountries. To do so, we run simulations over real road topologies (extracted\nfrom the GIS maps of major cities such as Dhaka, Miami, and Riyadh) considering\ndifferent scenarios such as lane-based or non-lane-based flows, homogeneous or\nheterogeneous traffic, with or without pedestrians, etc. We also incorporate\ndifferent car-following and lane-changing models to mimic traffic behaviors and\ninvestigate their performances. While the lane changing dilemma remains an open\nresearch question, our experimental evidences indicate: (i) lane-based\napproaches will not necessarily perform better in the case of currently-adopted\nnon-lane-based scenarios; and (ii) non-lane-based strategies may benefit system\nperformance in lane-based scenarios while having heavy mixed traffic.\nNonetheless, we reveal several new insights for on-road experiences both in\ndeveloping and developed countries.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.08590v1"
    },
    {
        "title": "On licenses for [Open] Hardware",
        "authors": [
            "Mrius Montn",
            "Xavier Salazar"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  This document explains the basic concepts related to software and hardware\nlicenses, and it summarizes the most popular licenses that are currently used\nfor hardware projects. Two case studies of hardware projects at different\nlevels of abstraction are also presented, together with a discussion of license\napplicability, commercial issues, code protection, and related concerns. This\npaper intends to help the reader understand how to release open hardware with\nthe most appropriate license, and to answer questions that are of current\ninterest. We have been mainly motivated by the growing influence of the open\nRISC-V ISA, but trying to address a wider hardware point of view.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.09039v1"
    },
    {
        "title": "A microsimulation approach for the impact assessment of a\n  Vehicle-to-Infrastructure based Road Hazard Warning system",
        "authors": [
            "Kallirroi N. Porfyri",
            "Areti Kotsi",
            "Evangelos Mitsakis"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Cooperative Intelligent Transportation Systems (C-ITS) constitute\ntechnologies which enable vehicles to communicate with each other and with road\ninfrastructure. Verification or testing is required for C-ITS applications, in\norder to assess their impact on traffic operation. In this work, a microscopic\ntraffic simulation approach is used, to evaluate the impact of\nVehicle-to-Infrastructure (V2I) technologies in the context of a road traffic\naccident. Specifically, the methodology is implemented to explicitly models\nvehicles collisions, Road Hazard Warning (RHW), Emergency Electronic Brake\nLight (EEBL) warnings and the resulting driver behavior. Moreover, a new gap\ncontrol mechanism is adopted, to improve safety by advising vehicles in hazard\nlane to increase their headways with respect to their preceding vehicle, so\nthat they can avoid a collision. Perfect communication links to all vehicles\nare assumed. The study findings indicate that the proposed V2I hazard warning\nstrategy has a positive impact on traffic flow safety and efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.10262v1"
    },
    {
        "title": "C-ITS bundling for integrated traffic management",
        "authors": [
            "Evangelos Mitsakis",
            "Areti Kotsi",
            "Vasileios Psonis"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Cooperative Intelligent Transportation Systems (C-ITS) enable vehicles\ncommunication with each other (Vehicle-to-Vehicle, V2V) and with roadside\ninfrastructure (Vehicle-to-Infrastructure, V2I). In the context of traffic\nefficiency, C-ITS technologies could assist in road network status\nvisualization and monitoring, through data exchange, improving this way traffic\ncontrol organization and traffic management implementation. Bundling is the\nprovision of several C-ITS services as one combined service. The purpose of\nbundling is to harvest the usability of C-ITS services by developing a strategy\nfor the operation and exploitation of services in real-time and within varying\ngeographical areas. Two different dimensions of bundling have been recognized\ncovering: 1) end-users, and 2) operators-managers. The objective of the\noperators-managers dimension is the integration of C-ITS services in\noperational traffic management. This work spotlights the operators-managers\nbundling dimension, presenting a framework based on a step-by-step approach for\nintegrating C-ITS services in traditional traffic management.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.03425v1"
    },
    {
        "title": "Foresight AND Hindsight",
        "authors": [
            "Mihai Nadin"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  To model is to represent. The threshold of decidability defines two\nepistemological choices: one model (or a finite number of models) suffices for\nrepresenting the dynamics below the undecidable; above this threshold (defined\nas G-complexity), every model is partial, no complete modeling is possible.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.03111v1"
    },
    {
        "title": "The Future of Artificial Intelligence and its Social, Economic and\n  Ethical Consequences",
        "authors": [
            "Burhan Rashid Hussein",
            "Chongomweru Halimu",
            "Muhammad Tariq Siddique"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Recent development in AI has enabled the expansion of its application to\nmultiple domains. From medical treatment, gaming, manufacturing to daily\nbusiness processes. A huge amount of money has been poured into AI research due\nto its exciting discoveries. Technology giants like Google, Facebook, Amazon,\nand Baidu are the driving forces in the field today. But the rapid growth and\nexcitement that the technology offers obscure us from looking at the impact it\nbrings on our society. This short paper gives a brief history of AI and\nsummarizes various social, economic and ethical issues that are impacting our\nsociety today. We hope that this work will provide a useful starting point and\nperhaps reference for newcomers and stakeholders of the field.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.03366v1"
    },
    {
        "title": "Analyzing and comparing door-to-door travel times for air transportation\n  using aggregated Uber data",
        "authors": [
            "Philippe Monmousseau",
            "Aude Marzuoli",
            "Eric Feron",
            "Daniel Delahaye"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Improving the passenger air travel experience is one of the explicit goals\nset by the Next Generation Air Transportation System in the United States and\nby the Advisory Council for Aeronautics Research in Europe FlightPath 2050.\nBoth suggest door-to-door travel times as a potential metric for these\nobjectives. In this paper, we propose a data-driven model to estimate\ndoor-to-door travel times and compare the reach and performance of different\naccess modes to a city, as well as conduct segment analysis of full\ndoor-to-door trips. This model can also be used to compare cities with respect\nto the integration of their airport within their road structure. We showcase\nmultiple applications of this full door-to-door travel time model to\ndemonstrate how the model can be used to locate where progress can be made.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.08852v1"
    },
    {
        "title": "Designing an Android Application for Bills Segregation",
        "authors": [
            "Ruifeng Guo"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  In recent years, several people have been hanging out or sharing rental house\nwith others. For utilities bills and other items, most people have been using\nthe tedious way where a person pay the bill and others transfer the money to\ntheir bank account. We research and develop android app as there has been a few\ncompanies trying to solve this. Our android application for bills segregation\ncan resolve this problem. In our novel system, the user can create event which\nrepresent all events that required to split the payment to everyone. In this\napplication, the user can invite the people and set the rules such as the\npercentage of each person. More importantly, the users will have the dashboard\nto display all the event and be able to chat with each other seamlessly.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.06823v1"
    },
    {
        "title": "Introduction to Big data Technology",
        "authors": [
            "Bilal Abu-Salih",
            "Pornpit Wongthongtham",
            "Dengya Zhu",
            "Kit Yan Chan",
            "Amit Rudra"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Big data is no more \"all just hype\" but widely applied in nearly all aspects\nof our business, governments, and organizations with the technology stack of\nAI. Its influences are far beyond a simple technique innovation but involves\nall rears in the world. This chapter will first have historical review of big\ndata; followed by discussion of characteristics of big data, i.e. from the 3V's\nto up 10V's of big data. The chapter then introduces technology stacks for an\nor-ganization to build a big data application, from\ninfrastruc-ture/platform/ecosystem to constructional units and components.\nFinally, we provide some big data online resources for reference.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.08062v1"
    },
    {
        "title": "Total Novel and Complexity. Literature and Complexity Science",
        "authors": [
            "Carlos Eduardo Maldonado"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  A strong link between complexity theory and literature is possible, i.e.\nfeasible, under one proviso, namely that total novels be considered. However,\nneither in literature at large nor in complexity science has been literature\nseriously taken into consideration. This paper argues that a total novel is\nmost conspicuous example of a complex system. The argument is supported by a\nclear characterization of what a total novel is and entails. Science and\nliterature can be thus complemented and developed, hand in hand.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.02774v1"
    },
    {
        "title": "Multi-objective Digital Design Optimisation via Improved Drive\n  Granularity Standard Cells",
        "authors": [
            "Linan Cao",
            "Simon J. Bale",
            "Martin A. Trefzer"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  To tackle the complexity of state-of-the-art electronic systems, silicon\nfoundries continuously shrink the technology nodes and electronic design\nautomation (EDA) vendors offer hierarchical design flows to decompose systems\ninto smaller blocks. However, such a staged design methodology consists of\nvarious levels of abstraction, where margins will be accumulated and result in\ndegradation of the overall design quality. This limits the full use of\ncapabilities of both the process technology and EDA tools. In this work, a\nstudy of drive granularity of standard cells is performed and an interpolation\nmethod is proposed for drive option expansion within original cell libraries.\nThese aim to investigate how industrial synthesis tools deal with the drive\nstrength selection using different granularity sets. In addition, a\nfully-automated, multi-objective (MO) EDA digital flow is introduced for power,\nperformance, area (PPA) optimisation based on drive strength refinement. This\npopulation-based search method better handles the increased difficulty of cell\nselection when using larger logic libraries, producing better optimised\nsolutions than standard tool flow in this case. The achieved experimental\nresults demonstrate how the improved drive granularity cells overall enhance\nthe quality of designs and how a significant improvement in trading off PPA is\nachieved by the MOEDA flow.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.11248v2"
    },
    {
        "title": "SQUADfps: Integrated Model-Based Machine Safety and Product Quality for\n  Flexible Production Systems",
        "authors": [
            "Chee Hung Koo",
            "Stefan Rothbauer",
            "Marian Vorderer",
            "Kai Hoefig",
            "Marc Zeller"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Growing individualization of products up to lot-size-1 and high volatility of\nproduct mixes lead to new challenges in the manufacturing domain, including the\nneed for frequent reconfiguration of the system and reacting to changing\norders. Thus, apart from functional aspects, safety aspects of the production\nsystem as well as product quality assurance aspects must be addressed for\nflexible and reconfigurable manufacturing systems at runtime. To cope with the\nmentioned challenges, we present an integrated model-based approach SQUADfps\n(machine Safety and product QUAlity for flexible proDuction systems) to support\nthe automatic conduct of the risk assessment of flexible production scenarios\nin terms of safety as well as the process-FMEA to ensure that the requirements\nw.r.t. the quality of the production process and the resulting product are met.\nOur approach is based on a meta-model which captures all information needed to\nconduct both risk assessment and process-FMEA dynamically during the runtime,\nand thus enables flexible manufacturing scenarios with frequent changes of the\nproduction system and orders up to a lot-size of one while guaranteeing safety\nand product quality requirements. The automatically generated results will\nassist human in making further decisions. To demonstrate the feasibility of our\napproach, we apply it to a case study.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.14817v2"
    },
    {
        "title": "WAP: Digital Dependability Identities",
        "authors": [
            "Daniel Schneider",
            "Mario Trapp",
            "Yiannis Papadopoulos",
            "Eric Armengaud",
            "Marc Zeller",
            "Kai Hoefig"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Cyber-Physical Systems (CPS) provide enormous potential for innovation but a\nprecondition for this is that the issue of dependability has been addressed.\nThis paper presents the concept of a Digital Dependability Identity (DDI) of a\ncomponent or system as foundation for assuring the dependability of CPS. A DDI\nis an analyzable and potentially executable model of information about the\ndependability of a component or system. We argue that DDIs must fulfill a\nnumber of properties including being universally useful across supply chains,\nenabling off-line certification of systems where possible, and providing\ncapabilities for in-field certification of safety of CPS. In this paper, we\nfocus on system safety as one integral part of dependability and as a practical\ndemonstration of the concept, we present an initial implementation of DDIs in\nthe form of Conditional Safety Certificates (also known as ConSerts). We\nexplain ConSerts and their practical operationalization based on an\nillustrative example.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.14984v1"
    },
    {
        "title": "INSiDER: Incorporation of system and safety analysis models using a\n  dedicated reference model",
        "authors": [
            "Marc Zeller",
            "Kai Hoefig"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  In order to enable model-based, iterative design of safety-relevant systems,\nan efficient incorporation of safety and system engineering is a pressing need.\nOur approach interconnects system design and safety analysis models efficiently\nusing a dedicated reference model. Since all information are available in a\nstructured way, traceability between the model elements and consistency checks\nenable automated synchronization to guarantee that information within both kind\nof models are consistent during the development life-cycle.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.14992v1"
    },
    {
        "title": "IoT Solution for Winter Survival of Indoor Plants",
        "authors": [
            "Md Saroar Jahan",
            "Jhuma kabir Mim",
            "Sampo Niittyviita",
            "Santeri Moberg",
            "Murad Ahmad",
            "Nijar Hossain"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Not only does cold climate pose a problem for outdoor plants during winter in\nthe northern hemisphere, but for indoor plants as well: low sunlight, low\nhumidity, and simultaneous cold breezes from windows and heat from radiators\nall cause problems for indoor plants. People often treat their indoor plants\nlike mere decoration, which can often lead to health issues for the plant or\neven death of the plant, especially during winter. A plant monitoring system\nwas developed to solve this problem, collecting information on plants' indoor\nenvironmental conditions (light, humidity, and temperature) and providing this\ninformation in an accessible format for the user. Preliminary functional tests\nwere conducted in similar settings where the system would be used. In addition,\nthe concept was evaluated by interviewing an expert in the field of\nhorticulture.\n  The evaluation results indicate that this kind of system could prove useful;\nhowever, the tests indicated that the system requires further development to\nachieve more practical value and wider usage.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.05130v1"
    },
    {
        "title": "Identifying intracity freight trip ends from heavy truck GPS\n  trajectories",
        "authors": [
            "Yitao Yang",
            "Bin Jia",
            "Xiao-Yong Yan",
            "Rui Jiang",
            "Hao Ji",
            "Ziyou Gao"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Intracity heavy truck freight trips are basic data in city freight system\nplanning and management. In the big data era, massive heavy truck GPS\ntrajectories can be acquired cost effectively in real-time. Identifying freight\ntrip ends (origins and destinations) from heavy truck GPS trajectories is an\noutstanding problem. Although previous studies proposed a variety of trip end\nidentification methods from different perspectives, these studies subjectively\ndefined key threshold parameters and ignored the complex intracity heavy truck\ntravel characteristics. Here, we propose a data-driven trip end identification\nmethod in which the speed threshold for identifying truck stops and the\nmultilevel time thresholds for distinguishing temporary stops and freight trip\nends are objectively defined. Moreover, an appropriate time threshold level is\ndynamically selected by considering the intracity activity patterns of heavy\ntrucks. Furthermore, we use urban road networks and point-of-interest (POI)\ndata to eliminate misidentified trip ends to improve method accuracy. The\nvalidation results show that the accuracy of the method we propose is 87.45%.\nOur method incorporates the impact of the city freight context on truck\ntrajectory characteristics, and its results can reflect the spatial\ndistribution and chain patterns of intracity heavy truck freight trips, which\nhave a wide range of practical applications.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.09881v2"
    },
    {
        "title": "To Block or Not to Block: Accelerating Mobile Web Pages On-The-Fly\n  Through JavaScript Classification",
        "authors": [
            "Moumena Chaqfeh",
            "Muhammad Haseeb",
            "Waleed Hashmi",
            "Patrick Inshuti",
            "Manesha Ramesh",
            "Matteo Varvello",
            "Fareed Zaffar",
            "Lakshmi Subramanian",
            "Yasir Zaki"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  The increasing complexity of JavaScript in modern mobile web pages has become\na critical performance bottleneck for low-end mobile phone users, especially in\ndeveloping regions. In this paper, we propose SlimWeb, a novel approach that\nautomatically derives lightweight versions of mobile web pages on-the-fly by\neliminating the use of unnecessary JavaScript. SlimWeb consists of a JavaScript\nclassification service powered by a supervised Machine Learning (ML) model that\nprovides insights into each JavaScript element embedded in a web page. SlimWeb\naims to improve the web browsing experience by predicting the class of each\nelement, such that essential elements are preserved and non-essential elements\nare blocked by the browsers using the service. We motivate the core design of\nSlimWeb using a user preference survey of 306 users and perform a detailed\nevaluation of SlimWeb across 500 popular web pages in a developing region on\nreal 3G and 4G cellular networks, along with a user experience study with 20\nreal-world users and a usage willingness survey of 588 users. Evaluation\nresults show that SlimWeb achieves a 50% reduction in the page load time\ncompared to the original pages, and more than 30% reduction compared to\ncompeting solutions, while achieving high similarity scores to the original\npages measured via a qualitative evaluation study of 62 users. SlimWeb improves\nthe overall user experience by more than 60% compared to the original pages,\nwhile maintaining 90%-100% of the visual and functional components of most\npages. Finally, the SlimWeb classifier achieves a median accuracy of 90% in\npredicting the JavaScript category.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.13764v1"
    },
    {
        "title": "A Fuzzy Post-project Evaluation Approach for Security Video Surveillance\n  System",
        "authors": [
            "Ming Liu",
            "Zhi Xue"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Video surveillance is an essential component of the public security system.\nThe security video surveillance system is a powerful means to prevent violence\nand crimes, and it is closely coupled with the construction of smart cities. A\npost-project evaluation is an evaluation of a project's actions and outcomes\nafter its completion. Post-project evaluation can scientifically and\nobjectively evaluate the construction effectiveness of video surveillance\nsystem at a certain stage. Utilizing post-project evaluation can find out the\ncauses of success or failure to make recommendations for the construction of a\nsecurity video surveillance system in the next stage. Therefore, we propose a\nfuzzy post-project evaluation approach for the security video surveillance\nsystem in a real-world community. The fuzzy theory and fuzzy multi-level\nevaluation method are applied. The evaluation result demonstrates that the\nproposed approach is practically applicable to real-world security video\nsurveillance systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.15316v1"
    },
    {
        "title": "Data-Enhanced Process Models in Process Mining",
        "authors": [
            "Jonas Cremerius",
            "Mathias Weske"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Understanding and improving business processes have become important success\nfactors for organizations. Process mining has proven very successful with a\nvariety of methods and techniques, including discovering process models based\non event logs. Process mining has traditionally focussed on control flow and\ntiming aspects. However, getting insights about a process is not only based on\nactivities and their orderings, but also on the data generated and manipulated\nduring process executions. Today, almost every process activity generates data;\nthese data do not play the role in process mining that it deserves. This paper\nintroduces a visualization technique for enhancing discovered process models\nwith domain data, thereby allowing data-based exploration of processes.\nData-enhanced process models aim at supporting domain experts to explore the\nprocess, where they can select attributes of interest and observe their\ninfluence on the process. The visualization technique is illustrated by the\nMIMIC-IV real-world data set on hospitalizations in the US.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.00565v1"
    },
    {
        "title": "Design an IT Policy Implementation Plan",
        "authors": [
            "Saman Sarraf",
            "Milton Kabia"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Information technology (IT) companies implement multi-dimensional policy\nplans that include procedures, sub-plans, and instructions to outline their\nbusiness scopes, targets, and communications. This work outlined the IT policy\nimplementation plan designed by an imaginary company with a random name called\nNorthcentral Cloud Consulting Firm (NCCF), containing proposed IT policies,\nmilestones and roadmaps, control framework, stakeholder responsibilities,\nknowledge transfer plan, and leadership roles. As NCCF's major customers seek\ndata-driven solutions in cloud computing, the NCCF IT policy plan provides\nvarious data policies, including security and proper usage of machine learning\nservices. The plan offers a detailed roadmap of its financial, geographical,\nand reputational expansion within three years. The IT policy plan also\ncompromises an IT risk management, contingency, and emergency communication\nplan, mainly for protecting data and business continuity. Stakeholder\nresponsibilities are incorporated into the IT policy plan, as NCCF considers\nany engagement with its customers as a collaborative effort in which both\nparties have and share several responsibilities.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.03327v1"
    },
    {
        "title": "Analysing Design Approaches for the Power Consumption in Cyber-Physical\n  Systems",
        "authors": [
            "Patrizia Sailer",
            "Igor Ivkic",
            "Markus Tauber",
            "Andreas Mauthe",
            "Antonios Gouglidis"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  The importance of Cyber Physical Systems (CPS) and Internet of Things (IoT)\napplications is constantly increasing, especially in the context of Industry\n4.0. Architectural decisions are crucial not just for performance, security and\nresilience reasons but also regarding costs and resource usage. In this paper\nwe analyse two of the fundamental approaches to design control loops (i.e.\ntime-driven and event-driven), show how they can be realised and evaluate their\npower requirements. Through this the design criteria can be extended also\nconsidering the optimization of energy related aspects.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.07745v1"
    },
    {
        "title": "Video or Image Transmission Security for ESP-EYE IoT device used in\n  Business Processes",
        "authors": [
            "Omer Aydin",
            "Ibrahim Ismail Erhan"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Internet of Things is the name of a communication network that is formed by\nphysical objects such as RFID tags, sensors and some lightweight development\nplatforms that have the ability to connect to the internet. While the devices\ncan communicate among themselves in this network, they can also be part of a\nlarge network. The data produced by those physical objects which are the member\nof IoT network are processed by different methods and the outputs obtained are\nused in processes such as decision making and learning. With this aspect of the\nInternet of Things, it affects all areas of human life and its number is\nincreasing day by day. These devices appear to have security gaps due to their\nlimited resources, their wide range of usage area and incomplete security\nstandards. These devices, which are located in people's living areas,\nmanufacturing and business processes also cause difficulties in protecting\nprivacy. In this study, a solution has been developed for the communication\nsecurity of the internet of things called ESP-Eye which includes a camera,\nwireless communication module and face recognition software. The proposed\nsolution was implemented on the ESP-Eye.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.08321v1"
    },
    {
        "title": "UNITI Mobile -- EMI-Apps for a Large-Scale European Study on Tinnitus",
        "authors": [
            "Carsten Vogel",
            "Johannes Schobel",
            "Winfried Schlee",
            "Milena Engelke",
            "Rdiger Pryss"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  More and more observational studies exploit the achievements of mobile\ntechnology to ease the overall implementation procedure. Many strategies like\ndigital phenotyping, ecological momentary assessments or mobile crowdsensing\nare used in this context. Recently, an increasing number of intervention\nstudies makes use of mobile technology as well. For the chronic disorder\ntinnitus, only few long-running intervention studies exist, which use mobile\ntechnology in a larger setting. Tinnitus is characterized by its heterogeneous\npatient's symptom profiles, which complicates the development of general\ntreatments. In the UNITI project, researchers from different European countries\ntry to unify existing treatments and interventions to cope with this\nheterogeneity. One study arm (UNITI Mobile) exploits mobile technology to\ninvestigate newly implemented interventions types, especially within the\npan-European setting. The goals are to learn more about the validity and\nusefulness of mobile technology in this context. Furthermore, differences among\nthe countries shall be investigated. Practically, two native intervention apps\nhave been developed for UNITI and the mobile study arm, which pose features not\npresented so far in other apps of the authors. Along the implementation\nprocedure, it is discussed whether these features might leverage similar types\nof studies in future. Since instruments like the mHealth evidence reporting and\nassessment checklist (mERA), developed by the WHO mHealth technical evidence\nreview group, indicate that aspects shown for UNITI Mobile are important in the\ncontext of health interventions using mobile phones, our findings may be of a\nmore general interest and are therefore being discussed in the work at hand.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.14029v1"
    },
    {
        "title": "Adoption Factors of Enabling I4.0 Technologies and Benefits in the\n  Supply Chain",
        "authors": [
            "Jos Carlos Franceli",
            "Silvia Novaes Zilber Turri"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Industry 4.0 technologies is a new paradigm of integration of cyber-physical\nsystems and information and communication solutions. This topic has been\nvaguely explored in social sciences; hence this study attempts to bridge this\ngap by investigating adoption process, based on I4.0 technologies. This paper\naims to identify the barriers and benefits generated in the Supply Chain\nthrough a systematic literature review. The results present a framework that\nconnects adoption factors, enabling technologies of I4.0, and benefits to the\nSupply Chain. innovations to be adopted.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.01207v1"
    },
    {
        "title": "SIMPT: Process Improvement Using Interactive Simulation of Time-aware\n  Process Trees",
        "authors": [
            "Mahsa Pourbafrani",
            "Shuai Jiao",
            "Wil M. P. van der Aalst"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Process mining techniques including process discovery, conformance checking,\nand process enhancement provide extensive knowledge about processes.\nDiscovering running processes and deviations as well as detecting performance\nproblems and bottlenecks are well-supported by process mining tools. However,\nall the provided techniques represent the past/current state of the process.\nThe improvement in a process requires insights into the future states of the\nprocess w.r.t. the possible actions/changes. In this paper, we present a new\ntool that enables process owners to extract all the process aspects from their\nhistorical event data automatically, change these aspects, and re-run the\nprocess automatically using an interface. The combination of process mining and\nsimulation techniques provides new evidence-driven ways to explore \"what-if\"\nquestions. Therefore, assessing the effects of changes in process improvement\nis also possible. Our Python-based web-application provides a complete\ninteractive platform to improve the flow of activities, i.e., process tree,\nalong with possible changes in all the derived activity, resource, and process\nparameters. These parameters are derived directly from an event log without\nuser-background knowledge.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.02052v1"
    },
    {
        "title": "JOET: Sustainable Vehicle-assisted Edge Computing for Internet of\n  Vehicles",
        "authors": [
            "Wei Huang",
            "Neal N. Xiong",
            "Shahid Mumtaz"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Task offloading in Internet of Vehicles (IoV) involves numerous steps and\noptimization variables such as: where to offload tasks, how to allocate\ncomputation resources, how to adjust offloading ratio and transmit power for\noffloading, and such optimization variables and hybrid combination features are\nhighly coupled with each other. Thus, this is a fully challenge issue to\noptimize these variables for task offloading to sustainably reduce energy\nconsumption with load balancing while ensuring that a task is completed before\nits deadline. In this paper, we first provide a Mixed Integer Nonlinear\nProgramming Problem (MINLP) formulation for such task offloading under energy\nand deadline constraints in IoV. Furthermore, in order to efficiently solve the\nformulated MINLP, we decompose it into two subproblems, and design a\nlow-complexity Joint Optimization for Energy Consumption and Task Processing\nDelay (JOET) algorithm to optimize selection decisions, resource allocation,\noffloading ratio and transmit power adjustment. We carry out extensive\nsimulation experiments to validate JOET. Simulation results demonstrate that\nJOET outperforms many representative existing approaches in quickly converge\nand effectively reduce energy consumption and delay. Specifically, average\nenergy consumption and task processing delay have been reduced by 15.93% and\n15.78%, respectively, and load balancing efficiency has increased by 10.20%.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.02443v1"
    },
    {
        "title": "Impressions of the GDMC AI Settlement Generation Challenge in Minecraft",
        "authors": [
            "Christoph Salge",
            "Claus Aranha",
            "Adrian Brightmoore",
            "Sean Butler",
            "Rodrigo Canaan",
            "Michael Cook",
            "Michael Cerny Green",
            "Hagen Fischer",
            "Christian Guckelsberger",
            "Jupiter Hadley",
            "Jean-Baptiste Herv",
            "Mark R Johnson",
            "Quinn Kybartas",
            "David Mason",
            "Mike Preuss",
            "Tristan Smith",
            "Ruck Thawonmas",
            "Julian Togelius"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  The GDMC AI settlement generation challenge is a PCG competition about\nproducing an algorithm that can create an \"interesting\" Minecraft settlement\nfor a given map. This paper contains a collection of written experiences with\nthis competition, by participants, judges, organizers and advisors. We asked\npeople to reflect both on the artifacts themselves, and on the competition in\ngeneral. The aim of this paper is to offer a shareable and edited collection of\nexperiences and qualitative feedback - which seem to contain a lot of insights\non PCG and computational creativity, but would otherwise be lost once the\noutput of the competition is reduced to scalar performance values. We reflect\nupon some organizational issues for AI competitions, and discuss the future of\nthe GDMC competition.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.02955v1"
    },
    {
        "title": "A hydraulic model outperforms work-balance models for predicting\n  recovery kinetics from intermittent exercise",
        "authors": [
            "Fabian C. Weigend",
            "David C. Clarke",
            "Oliver Obst",
            "Jason Siegler"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Data Science advances in sports commonly involve \"big data\", i.e., large\nsport-related data sets. However, such big data sets are not always available,\nnecessitating specialized models that apply to relatively few observations. One\nimportant area of sport-science research that features small data sets is the\nstudy of recovery from exercise. In this area, models are typically fitted to\ndata collected from exhaustive exercise test protocols, which athletes can\nperform only a few times. Recent findings highlight that established recovery\nsuch as the so-called work-balance models are too simple to adequately fit\nobserved trends in the data. Therefore, we investigated a hydraulic model that\nrequires the same few data points as work-balance models to be applied, but\npromises to predict recovery dynamics more accurately.\n  To compare the hydraulic model to established work-balance models, we\nretrospectively applied them to data compiled from published studies. In total,\none hydraulic model and three work-balance models were compared on data\nextracted from five studies. The hydraulic model outperformed established\nwork-balance models on all defined metrics, even those that penalize models\nfeaturing higher numbers of parameters. These results incentivize further\ninvestigation of the hydraulic model as a new alternative to established\nperformance models of energy recovery.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.04510v2"
    },
    {
        "title": "Hierarchical Structural Analysis Method for Complex Equation-oriented\n  Models",
        "authors": [
            "Chao Wang",
            "Li Wan",
            "Tifan Xiong",
            "Yuanlong Xie",
            "Shuting Wang",
            "Jianwan Ding",
            "Liping Chen"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Structural analysis is a method for verifying equation-oriented models in the\ndesign of industrial systems. Existing structural analysis methods need\nflattening of the hierarchical models into an equation system for analysis.\nHowever, the large-scale equations in complex models make structural analysis\ndifficult. Aimed to address the issue, this study proposes a hierarchical\nstructural analysis method by exploring the relationship between the\nsingularities of the hierarchical equation-oriented model and its components.\nThis method obtains the singularity of a hierarchical equation-oriented model\nby analyzing a dummy model constructed with the parts from the decomposing\nresults of its components. Based on this, the structural singularity of a\ncomplex model can be obtained by layer-by-layer analysis according to their\nnatural hierarchy. The hierarchical structural analysis method can reduce the\nequation scale in each analysis and achieve efficient structural analysis of\nvery complex models. This method can be adaptively applied to\nnonlinear-algebraic and differential-algebraic equation models. The main\nalgorithms, application cases and comparison with the existing methods are\npresent in this paper. The complexity analysis results show the enhanced\nefficiency of the proposed method in the structural analysis of complex\nequation-oriented models. Compared with the existing methods, the time\ncomplexity of the proposed method is improved significantly.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.04525v2"
    },
    {
        "title": "Research on Brick Schema Representation for Building Operation with\n  Variable Refrigerant Flow Systems",
        "authors": [
            "Jingming Li",
            "Nianping Li",
            "Rui Yan",
            "Kushnazarov Farruh",
            "Anbang Li",
            "Kehua Li"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Building metadata is regarded as the signpost in organizing massive building\ndata. The application of building metadata simplifies the creation of digital\nrepresentations and provides portable data analytics. Typical metadata\nstandards such as Brick and Haystack are used to describe the data of the\nbuilding system. Brick uses standard ontologies to create building metadata.\nHowever, neither Haystack nor Brick has provided definitions about the Variable\nRefrigerant Flow (VRF) system so far. For years, both Brick and Haystack\nworking groups have been discussing how to describe VRF in their schema, mainly\nabout the classification of VRF and the definitions of VRF units. There were no\nsettled solutions for these problems. Meanwhile, the global VRF market is\ngrowing increasingly fast because of the energy efficiency and installation\nsimplicity of the VRF system. It is needed to have the metadata to describe VRF\nunits in buildings for data analysis and management. Addressing this challenge,\nthis paper extended Brick Schema with the VRF module and verified the Brick VRF\nmodule. Then, the model and the service framework were developed and applied\nfor a building in China. The framework can serve portable energy analysis for\ndifferent areas. The VRF module of this paper provides a possible solution for\nthe expression of the VRF system in the building semantic web. The works in\nthis paper will support semantic web in automation strategies for building\nmanagement and scalable building operation.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.07037v2"
    },
    {
        "title": "Quantifying Intrinsic Value of Information of Trajectories",
        "authors": [
            "Kien Nguyen",
            "John Krumm",
            "Cyrus Shahabi"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  A trajectory, defined as a sequence of location measurements, contains\nvaluable information about movements of an individual. Its value of information\n(VOI) may change depending on the specific application. However, in a variety\nof applications, knowing the intrinsic VOI of a trajectory is important to\nguide other subsequent tasks or decisions. This work aims to find a principled\nframework to quantify the intrinsic VOI of trajectories from the owner's\nperspective. This is a challenging problem because an appropriate framework\nneeds to take into account various characteristics of the trajectory, prior\nknowledge, and different types of trajectory degradation. We propose a\nframework based on information gain (IG) as a principled approach to solve this\nproblem. Our IG framework transforms a trajectory with discrete-time\nmeasurements to a canonical representation, i.e., continuous in time with\ncontinuous mean and variance estimates, and then quantifies the reduction of\nuncertainty about the locations of the owner over a period of time as the VOI\nof the trajectory. Qualitative and extensive quantitative evaluation show that\nthe IG framework is capable of effectively capturing important characteristics\ncontributing to the VOI of trajectories.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.12450v2"
    },
    {
        "title": "A New Rational Approach to the Square Root of 5",
        "authors": [
            "Shenghui Su",
            "Jianhua Zheng",
            "Shuwang Lv"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  In this paper, authors construct a new type of sequence which is named an\nextra-super increasing sequence, and give the definitions of the minimal super\nincreasing sequence {a[0], a[1], ..., a[n]} and minimal extra-super increasing\nsequence {z[0], z[1], ..., z[n]}. Find that there always exists a fit n which\nmakes (z[n] / z[n-1] - a[n] / a[n-1])= PHI, where PHI is the golden ratio\nconjugate with a finite precision in the range of computer expression. Further,\nderive the formula radic(5) = 2(z[n] / z[n-1] - a[n] / a[n-1]) + 1, where n\ncorresponds to the demanded precision. Experiments demonstrate that the\napproach to radic(5) through a term ratio difference is more smooth and\nexpeditious than through a Taylor power series, and convince the authors that\nlim(n to infinity) (z[n] / z[n-1] - a[n] / a[n-1]) = PHI holds.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.13110v3"
    },
    {
        "title": "An Indoor Crowd Movement Trajectory Benchmark Dataset",
        "authors": [
            "Ying Zhao",
            "Xin Zhao",
            "Siming Chen",
            "Zhuo Zhang",
            "Xin Huang"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  In recent years, technologies of indoor crowd positioning and movement data\nanalysis have received widespread attention in the fields of reliability\nmanagement, indoor navigation, and crowd behavior monitoring. However, only a\nfew indoor crowd movement trajectory datasets are available to the public, thus\nrestricting the development of related research and application. This paper\ncontributes a new benchmark dataset of indoor crowd movement trajectories. This\ndataset records the movements of over 5000 participants at a three day large\nacademic conference in a two story indoor venue. The conference comprises\nvaried activities, such as academic seminars, business exhibitions, a hacking\ncontest, interviews, tea breaks, and a banquet. The participants are divided\ninto seven types according to participation permission to the activities. Some\nof them are involved in anomalous events, such as loss of items, unauthorized\naccesses, and equipment failures, forming a variety of spatial temporal\nmovement patterns. In this paper, we first introduce the scenario design,\nentity and behavior modeling, and data generator of the dataset. Then, a\ndetailed ground truth of the dataset is presented. Finally, we describe the\nprocess and experience of applying the dataset to the contest of ChinaVis Data\nChallenge 2019. Evaluation results of the 75 contest entries and the feedback\nfrom 359 contestants demonstrate that the dataset has satisfactory\ncompleteness, and usability, and can effectively identify the performance of\nmethods, technologies, and systems for indoor trajectory analysis.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.01091v1"
    },
    {
        "title": "Smart Grids Co-Simulations: Survey & Research Directions",
        "authors": [
            "Peter Mihal",
            "Martin Schvarcbacher",
            "Bruno Rossi",
            "Tom Pitner"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  The integration of renewable sources, communication and power networks with\ninformation and communication technologies is one of the main challenges in\nSmart Grids (SG) large-scale testing. For this reason, the coupling of\nsimulators is commonly used to dynamically simulate several aspects of the SG\ninfrastructure, in the so-called co-simulations. In this paper, we provide a\nscoping review of research of co-simulations in the context of Smart Grids: i)\nresearch areas and research problems addressed by co-simulations, ii) specific\nco-simulation aspects focus of research, iii) typical coupling of simulators in\nco-simulation studies. Based on the results, we discuss research directions of\nfuture SG co-simulation research in each of the identified areas.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.02349v1"
    },
    {
        "title": "NetSD: Remote Access to Integrated SD Cards of Embedded Devices",
        "authors": [
            "Valentin Schrter",
            "Arne Boockmeyer",
            "Lukas Pirl"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Digitalization continuously pervades all areas and the Internet of Things\n(IoT) is still on the rise. This leads to an increased need for efficiency in\nthe development of embedded devices and systems composed thereof. Hybrid\ntestbeds are common environments to representatively assess, e.g.,\nhardware-software interaction, interoperability, and scalability. Although\nautomation is inevitable to achieve efficiency, not all devices offer\ninterfaces to be fully software-controlled. Most notably, block devices tend to\nbe inaccessible for software outside a Device under Test (DuT), especially when\nthe latter is in a dysfunctional state.\n  This paper introduces the Networked SD card (NetSD) which enables remote\naccess to removable block devices. The proposed system consists of a hardware\npart, which enables multiplexed access to a block device (e.g., an SD card) and\na software part which enables remote access to the block device (e.g., via HTTP\nor network block device). NetSD thus adds testing and automation possibilities\nto DuTs without the need to modify their hard- or software. During the hardware\ndesign, we fund that different SD transfer modes and access profiles (read or\nwrite focus) benefit from different pull-up resistor configurations for the\ndata lines.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.15322v1"
    },
    {
        "title": "Brilliant Challenges Optimization Problem Submission Contest Final\n  Report",
        "authors": [
            "Jan Badura",
            "Artur Laskowski",
            "Maciej Antczak",
            "Jacek Blazewicz",
            "Grzegorz Pawlak",
            "Erwin Pesch",
            "Thomas Villmann",
            "Szymon Wasik"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  This paper concludes the Brilliant Challenges contest. Participants had to\ndesign interesting optimization problems and publish them using the Optil.io\nplatform. It was the first widely-advertised contest in the area of operational\nresearch where the objective was to submit the problem definition instead of\nthe algorithmic solutions. Thus, it is a crucial contribution to Open Science\nand the application of crowdsourcing methodology to solve discrete optimization\nproblems. The paper briefly describes submitted problems, presents the winners,\nand discusses the contest's achievements and shortcomings. Finally, we define\nguidelines supporting the organization of contests of similar type in the\nfuture.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.04916v1"
    },
    {
        "title": "Presentation and Publication: Loss and Slippage in Networks of Automated\n  Market Makers",
        "authors": [
            "Daniel Engel",
            "Maurice Herlihy"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Automated market makers (AMMs) are smart contracts that automatically trade\nelectronic assets according to a mathematical formula. This paper investigates\nhow an AMM's formula affects the interests of liquidity providers, who endow\nthe AMM with assets, and traders, who exchange one asset for another at the\nAMM's rates. *Linear slippage* measures how a trade's size affects the trader's\nreturn, *angular slippage* measures how a trade's size affects the subsequent\nmarket price, *divergence loss* measures the opportunity cost of providers'\ninvestments, and *load* balances the costs to traders and providers. We give\nformal definitions for these costs, show that they obey certain conservation\nlaws: these costs can be shifted around but never fully eliminated. We analyze\nhow these costs behave under *composition*, when simple individual AMMs are\nlinked to form more complex networks of AMMs.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.09872v1"
    },
    {
        "title": "Easy and structured approach for software and firmware co-simulation for\n  bus centric designs",
        "authors": [
            "Micha Kruszewski"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Although software and firmware co-simulation is gaining popularity, it is\nstill not widely used in the FPGA designs. This work presents easy and\nstructured approach for software and firmware co-simulation for bus centric\ndesigns. The proposed approach is very modular and software language agnostic.\nThe only requirement is that the firmware design is accessible via some kind of\nsystem bus. The concept has been used for testing DAQ system being developed\nfor high energy physics experiment.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.10447v1"
    },
    {
        "title": "Piano Fingering with Reinforcement Learning",
        "authors": [
            "Pedro Ramoneda",
            "Marius Miron",
            "Xavier Serra"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Hand and finger movements are a mainstay of piano technique. Automatic\nFingering from symbolic music data allows us to simulate finger and hand\nmovements. Previous proposals achieve automatic piano fingering based on\nknowledge-driven or data-driven techniques. We combine both approaches with\ndeep reinforcement learning techniques to derive piano fingering. Finally, we\nexplore how to incorporate past experience into reinforcement learning-based\npiano fingering in further work.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.08009v1"
    },
    {
        "title": "Towards Grassroots Peering at the Edge",
        "authors": [
            "David Bermbach",
            "Sergio Lucia",
            "Vlado Handziski",
            "Adam Wolisz"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Fog Computing allows applications to address their latency and privacy\nrequirements while coping with bandwidth limitations of Internet service\nproviders (ISPs). Existing research on fog systems has so far mostly taken a\nvery high-level view on the actual fog infrastructure. In this position paper,\nwe identify and discuss the problem of having multiple ISPs in edge-to-edge\ncommunication. As a possible solution we propose that edge operators create\ndirect edge-to-edge links in a grassroots fashion and discuss different\nimplementation options. Based on this, we highlight some important open\nresearch challenges that result from this.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.03462v1"
    },
    {
        "title": "Proxy System with JPEG Bitstream-Based File-Size Preserving Encryption\n  for Cloud Photo Streams",
        "authors": [
            "Hiroyuki Kobayashi",
            "Hitoshi Kiya"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  In this paper, we propose a proxy system with JPEG bitstream-based file-size\npreserving encryption to securely store compressed images in cloud\nenvironments. The proposed system, which is settled between client's device and\nthe Internet, allows us not only to have exact the same file size as that of\noriginal JPEG streams but also to maintain a predetermined image format. In an\nexperiment, the proposed system is verified to be effective in two cloud photo\nsteams: Google Photo and iCloud Photo.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.03469v1"
    },
    {
        "title": "Interactive Process Improvement using Simulation of Enriched Process\n  Trees",
        "authors": [
            "Mahsa Pourbafrani",
            "Wil M. P. van der Aalst"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Event data provide the main source of information for analyzing and improving\nprocesses in organizations. Process mining techniques capture the state of\nrunning processes w.r.t. various aspects, such as activity-flow and performance\nmetrics. The next step for process owners is to take the provided insights and\nturn them into actions in order to improve their processes. These actions may\nbe taken in different aspects of a process. However, simply being aware of the\nprocess aspects that need to be improved as well as potential actions is\ninsufficient. The key step in between is to assess the outcomes of the\ndecisions and improvements. In this paper, we propose a framework to\nsystematically compare event data and the simulated event data of\norganizations, as well as comparing the results of modified processes in\ndifferent settings. The proposed framework could be provided as an analytic\nservice to enable organizations in easily accessing event data analytics. The\nframework is supported with a simulation tool that enables applying changes to\nthe processes and re-running the process in various scenarios. The simulation\nstep includes different perspectives of a process that can be captured\nautomatically and modified by the user. Then, we apply a state-of-the-art\ncomparison approach for processes using their event data which visually\nreflects the effects of these changes in the process, i.e., evaluating the\nprocess improvement. Our framework also includes the implementation of the\nchange measurement module as a tool.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.07755v1"
    },
    {
        "title": "Proceedings of the XI International Workshop on Locational Analysis and\n  Related Problems",
        "authors": [
            "Maria Albareda-Sambola",
            "Marta Baldomero-Naranjo",
            "Juan Manuel Muoz-Ocaa",
            "Jessica Rodrguez-Pereira"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  The International Workshop on Locational Analysis and Related Problems will\ntake place during January 31-February 1, 2022 in Elche (Spain). It is organized\nby the Spanish Location Network and the Location Group GELOCA from the Spanish\nSociety of Statistics and Operations Research (SEIO). The Spanish Location\nNetwork is a group of more than 140 researchers from several Spanish\nuniversities organized into 7 thematic groups. The Network has been funded by\nthe Spanish Government since 2003. This edition of the conference is organized\nin collaboration with project PROMETEO/2021/063 funded by the Valencian\ngovernment.\n  One of the main activities of the Network is a yearly meeting aimed at\npromoting the communication among its members and between them and other\nresearchers, and to contribute to the development of the location field and\nrelated problems. The last meetings have taken place in Sevilla (January 23-24,\n2020), C\\'adiz (January 20-February 1, 2019), Segovia (September 27-29, 2017),\nM\\'alaga (September 14-16, 2016), Barcelona (November 25-28, 2015), Sevilla\n(October 1-3, 2014), Torremolinos (M\\'alaga, June 19-21, 2013), Granada (May\n10-12, 2012), Las Palmas de Gran Canaria (February 2-5, 2011) and Sevilla\n(February 1-3, 2010).\n  The topics of interest are location analysis and related problems. This\nincludes location models, networks, transportation, logistics, exact and\nheuristic solution methods, and computational geometry, among others.\n",
        "pdf_link": "http://arxiv.org/pdf/2202.13878v1"
    },
    {
        "title": "Accuracy of Garmin GPS Running Watches over Repetitive Trials on the\n  Same Route",
        "authors": [
            "Joe Dumas"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Many runners use watches incorporating Global Positioning System technology\nto track their workouts. These devices can be valuable training aids, but they\nhave limitations. For several reasons including variations in satellite\nposition, environmental factors, and design decisions made by the manufacturer,\nGPS-enabled watches can produce position measurement errors. These can result\nin incorrect estimations of total distance covered as well as running pace.\nThis study examined the accuracy of three Garmin running watches of different\ntechnological generations using repetitive trials, over several years, by the\nsame runner over the same route. The older watches, a Forerunner 205 and a\nForerunner 220, showed similar accuracy when traversing the route. The newer\ngeneration watch, a Forerunner 45S, was found to be significantly less accurate\nin terms of both the trueness and precision of its distance measurements. This\nmay indicate that Garmin, in competition with other manufacturers of similar\ndevices, has chosen in recent years to prioritize device miniaturization and\nbattery life over accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.00491v1"
    },
    {
        "title": "Computational Language $ $ based on Orthomodular Lattices with the\n  Non-distributivity of Quantum Logic",
        "authors": [
            "Kazuki Otsuka"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  It is argued that transformation processes (generation rules) showing\nevidence of a long evolutionary history in universal computing systems can be\ngeneralized. The explicit function class $ \\Omega $ is defined as follows:\n\"Operators whose eigenvectors (or eigenvalues) have an irrational number in\ntheir components constitute a class of functions with quasi-periodic structure,\n$ \\Omega $, and the class $ \\Omega $ shows evidence of a long evolutionary\nhistory.\" In order to empirically prove this theorem by examining physical\nsystems carrying out life activities or intellectual outputs of developed\nintelligence, the basic framework of the universal machine model C and the\ncomputational language $ \\beta $ is presented as a model for general\ncomputational methods, which allow transformation processes (generation rules)\nwith deep algorithmic complexity to be derived from generation results. C and $\n\\beta $ perform massively parallel computations on event-state systems\nconsisting of exponential combinations of propositional elements expressed in\nterms of correlations between subsystems. The logical structure of the\ncomputational language relies on a non-distributivity in Hilbert spaces or\northogonal modular lattices, allowing for the manipulation and deduction of\nsimultaneous propositions. In this logical local structure, the propositions\nimplying certain consequences are not uniquely determined.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.12385v3"
    },
    {
        "title": "Arithmetic logical Irreversibility and the Turing's Halt Problem",
        "authors": [
            "Yair Lapin"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  The Turing machine halting problem can be explained by several factors,\nincluding arithmetic logic irreversibility and memory erasure, which contribute\nto computational uncertainty due to information loss during computation.\nEssentially, this means that an algorithm can only preserve information about\nan input, rather than generate new information. This uncertainty arises from\ncharacteristics such as arithmetic logical irreversibility, Landauer's\nprinciple, and memory erasure, which ultimately lead to a loss of information\nand an increase in entropy. To measure this uncertainty and loss of\ninformation, the concept of arithmetic logical entropy can be used. The Turing\nmachine and its equivalent, general recursive functions can be understood\nthrough the {\\lambda} calculus and the Turing/Church thesis. However, there are\ncertain recursive functions that cannot be fully understood or predicted by\nother algorithms due to the loss of information during logical-arithmetic\noperations. In other words, the behaviour of these functions cannot be\ncompletely determined at every stage of the computation due to a lack of\ninformation in their definition. While there are some cases where the behaviour\nof recursive functions is highly predictable, the lack of information in most\ncases makes it impossible for algorithms to determine if a program will halt or\nnot. This inability to predict the outcome of the computation is the essence of\nthe halting problem of the Turing machine. Even in cases where more information\nis available about the program, it is still difficult to determine with\ncertainty if the program will halt or not. This also highlights the importance\nof the Turing oracle machine, which introduces information from outside the\ncomputation to compensate for the lack of information and ultimately decide the\nresult of the computation.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.00563v4"
    },
    {
        "title": "Application of Stochastic Optimization Techniques to the Unit Commitment\n  Problem -- A Review",
        "authors": [
            "Vincent Meilinger"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Due to the established energy production methods contribution to the climate\ncrisis, renewable energy is to replace a substantial part of coal or nuclear\nplants to prevent greenhouse gases or toxic waste entering the atmosphere. This\nrelatively quick shift in energy production, primarily pushed by increasing\npolitical and economical pressure, requires enormous effort on the part of the\nenergy providers to balance out production fluctuations. Consequently, a lot of\nresearch is conducted in the key area of stochastic unit commitment (UC) on\nelectrical grids and microgrids. The term unit commitment includes a large\nvariety of optimization techniques, and in this paper we will review recent\ndevelopments in this area. We start by giving an overview over different\nproblem definitions and stochastic optimization procedures, to then assess\nrecent contributions to this topic. We therefore compare the proposals and case\nstudies of several papers.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.00922v1"
    },
    {
        "title": "Innovating at Speed and at Scale: A Next Generation Infrastructure for\n  Accelerating Semiconductor Technologies",
        "authors": [
            "Richard A. Gottscho",
            "Edlyn V. Levine",
            "Tsu-Jae King Liu",
            "Paul C. McIntyre",
            "Subhasish Mitra",
            "Boris Murmann",
            "Jan M. Rabaey",
            "Sayeef Salahuddin",
            "Willy C. Shih",
            "H. -S. Philip Wong"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Semiconductor innovation drives improvements to technologies that are\ncritical to modern society. The country that successfully accelerates\nsemiconductor innovation is positioned to lead future semiconductor-driven\nindustries and benefit from the resulting economic growth. It is our view that\na next generation infrastructure is necessary to accelerate and enhance\nsemiconductor innovation in the U.S. In this paper, we propose such an advanced\ninfrastructure composed of a national network of facilities with enhancements\nin technology and business models. These enhancements enable application-driven\nand challenge-based research and development, and ensure that facilities are\naccessible and sustainable. The main tenets are: a challenge-driven operational\nmodel, a next-generation infrastructure to serve that operational model,\ntechnology innovations needed for advanced facilities to speed up learning\ncycles, and innovative cost-effective business models for sustainability.\nUltimately, the expected outcomes of such a participatory, scalable, and\nsustainable nation-level advanced infrastructure will have tremendous impact on\ngovernment, industry, and academia alike.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.02216v1"
    },
    {
        "title": "A Validation Procedure for the Estimation of Reachable Regions in\n  Football",
        "authors": [
            "M. Renkin",
            "J. Bischofberger",
            "E. Schikuta",
            "A. Baca"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Modelling the trajectorial motion of humans along the ground is a\nfoundational task in the quantitative analysis of sports like association\nfootball. Most existing models of football player motion have not been\nvalidated yet with respect to actual data. One of the reasons for this lack is\nthat performing such a validation is not straightforward, because models of\nplayer motion are usually phrased in a way that emphasises possibly reachable\npositions rather than expected positions. Since positional data of football\nplayers typically contains outliers, this data may misrepresent the range of\nactually reachable positions.\n  This paper proposes a validation routine for trajectorial motion models that\nmeasures and optimises the ability of a motion model to accurately predict all\npossibly reachable positions by favoring the smallest predicted area of\nreachable positions that encompasses all observed reached positions up to a\nmanually defined threshold. We demonstrate validation and optimisation on four\ndifferent motion models, assuming (a) motion with constant speed, (b) motion\nwith constant acceleration, (c) motion with constant acceleration with a speed\nlimit, and (d) motion along two segments with constant speed. Our results show\nthat assuming motion with constant speed or constant acceleration without a\nlimit on the achievable speed is particularly inappropriate for an accurate\ndistinction between reachable and unreachable locations. Motion along two\nsegments of constant speed provides by far the highest accuracy among the\ntested models and serves as an efficient and accurate approximation of\nreal-world player motion.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.13992v1"
    },
    {
        "title": "Utilizing Low-Cost Linux Micro-Computer & Android Phone Solutions on\n  Cube-Satellites",
        "authors": [
            "Ahmed Farid",
            "Ahmed Samy",
            "Ahmed Shalaby",
            "Ahmed Tarek",
            "Mahmoud Ayyad",
            "Muhammad Assem",
            "Samy Amin"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Realizing functional space systems using flight-tested components is\nproblematic in developing economies, as such components are costly for most\ninstitutions to sponsor. The B.Sc. project, Subsystems for 2nd Iteration Cairo\nUniversity Cube-Satellite, addresses technology demonstration using\ncommercially available electronics and low cost computing platforms, such as\nAndroid phones and Raspberry Pi Linux micro-computer as computing hardware. As\nfor software, the project makes use of open-source modules and locally\ndeveloped code to implement needed functionalities, in addition to a mechanism\nto operate a virtual desktop Linux OS in parallel to an Android application.\nThe paper aims to demonstrate the significance, operation design, and problem\nsolving of such approaches. The paper concludes with future prospects for\nimproving upon the proposed computing systems\n",
        "pdf_link": "http://arxiv.org/pdf/2205.08255v1"
    },
    {
        "title": "A Non-Habituating Configurable Audio Visual Animal Deterrent System to\n  Mitigate Roadkill",
        "authors": [
            "Vedant Malolan Srinivas"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Growth economies continue to be more reliant on roadways than ever before.\nOver 30,000 miles of road are added yearly to the already enormous road system\nthat exists in the United States. As roads segment habitats, animals have no\noption but to walk across them for food, water and companionship. In this\nprocess they end up becoming roadkill. Wherever wildlife habitat and roadways\noverlap, death and destruction seem impossible to control. These animal deaths\nhave a direct impact on the biodiversity and dynamics of an ecosystem and\nroadkill poses a threat to many species that are fighting extinction. Vehicles\ncolliding with animals results in human fatalities, life changing injuries and\nextensive property damage. Current methods of handling roadkill are primarily\npassive and do not utilize the animal's natural instincts. This paper presents\nan alternative approach by actively involving the animal, warning them of an\noncoming vehicle and triggering their survival instincts. Making the animal an\nintegral part of the solution, augmenting their sensory perception with science\nand technology and utilizing their heightened reflexes and survival instincts\nprovides a better chance at mitigating the problem of roadkill. The results\nshow that this solution is able to provide animals a warning of an oncoming\nvehicle, consistently, reliably and in a wide range of testing conditions.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.11514v1"
    },
    {
        "title": "The openESEA Modelling Language for Ethical, Social and Environmental\n  Accounting: Technical Report",
        "authors": [
            "Sergio Espaa",
            "Vijanti Ramautar"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Over the years ethical, social and environmental accounting (ESEA) has become\na common practice among responsible organisations. ESEA entails assessing and\nreporting organisations\" performance on environmental, social and governance\ntopics. In this report, we present a textual grammar for specifying ESEA\nmethods. With the grammar ESEA models can be created. Such models can be\ninterpreted by our open-source, model-driven tool, called openESEA. The report\npresents the metamodel of the grammar, the grammar itself, and explanations of\neach grammar primitive.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.15279v3"
    },
    {
        "title": "Measuring Discrimination Abilities of Monk Parakeets Between Discreet\n  and Continuous Quantities Through a Digital Life Enrichment Application",
        "authors": [
            "Jrmy Barbay",
            "Fabin Jaa",
            "Cristbal Sepulveda lvarez"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Ain et al. measured three African Grey (Psittacus erithacus) parrot's\ndiscrimination abilities between discreet and continuous quantities. Some\nfeatures of their experimental protocol make it difficult to apply to other\nsubjects and/or species without introducing a risk for some bias, as subjects\ncould read cues from the experimenter (even though the study's subjects\nprobably did not). Can digital life enrichment techniques permit us to\nreplicate their results with other species with less risk for experimental\nbias, with a better precision, and at lower cost? Inspired by previous informal\ndigital life enrichment experiments with parrots, we designed and tested a web\napplication to digitally replicate and extend Ain et al.'s experimental setup.\nWe were able to obtain similar results to theirs for two individuals from a\ndistinct species, Monk Parakeets (Myiopsitta Monachus), with increased\nguarantees against potential experimental biases, in a way which should allow\nto replicate such experiments at larger scale and at a much lower cost.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.00734v1"
    },
    {
        "title": "Business Process Simulation with Differentiated Resources: Does it Make\n  a Difference?",
        "authors": [
            "Orlenys Lopez-Pintado",
            "Marlon Dumas"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Business process simulation is a versatile technique to predict the impact of\none or more changes on the performance of a process. Mainstream approaches in\nthis space suffer from various limitations, some stemming from the fact that\nthey treat resources as undifferentiated entities grouped into resource pools.\nThese approaches assume that all resources in a pool have the same performance\nand share the same availability calendars. Previous studies have acknowledged\nthese assumptions, without quantifying their impact on simulation model\naccuracy. This paper addresses this gap in the context of simulation models\nautomatically discovered from event logs. The paper proposes a simulation\napproach and a method for discovering simulation models, wherein each resource\nis treated as an individual entity, with its own performance and availability\ncalendar. An evaluation shows that simulation models with differentiated\nresources more closely replicate the distributions of cycle times and the work\nrhythm in a process than models with undifferentiated resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.07928v1"
    },
    {
        "title": "Cloud Process Execution Engine: Architecture and Interfaces",
        "authors": [
            "Juergen Mangler",
            "Stefanie Rinderle-Ma"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Process Execution Engines are a vital part of Business Process Management\n(BPM) and Manufacturing Orchestration Management (MOM), as they allow the\nbusiness or manufacturing logic (expressed in a graphical notation such as\nBPMN) to be executed. This execution drives and supervises all interactions\nbetween humans, machines, software, and the environment. If done right, this\nwill lead to a highly flexible, low-code, and easy to maintain solution, that\nallows for ad-hoc changes and functional evolution, as well as delivering a\nwealth of data for data-science applications. The Cloud Process Execution\nEngine CPEE.org implements a radically distributed scale-out architecture,\ntogether with a minimal set of interfaces, to allow for the simplest possible\nintegration with existing services, machines, and existing data-analysis tools.\nIts open-source components can serve as a blueprint for future development of\ncommercial solutions, and serves as a proven testbed for academic research,\nteaching, and industrial application since 2008. In this paper we present the\narchitecture, interfaces that make CPEE.org possible, as well as discuss\ndifferent lifecycle models utilized during execution to provide overarching\nsupport for a wide range of data-analysis tasks.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12214v2"
    },
    {
        "title": "Repairing Activity Start Times to Improve Business Process Simulation",
        "authors": [
            "David Chapela-Campa",
            "Marlon Dumas"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Business Process Simulation (BPS) is a common technique to estimate the\nimpact of business process changes, e.g. what would be the cycle time of a\nprocess if the number of traces increases? The starting point of BPS is a\nbusiness process model annotated with simulation parameters (a BPS model).\nSeveral studies have proposed methods to automatically discover BPS models from\nevent logs -- extracted from enterprise information systems -- via process\nmining techniques. These approaches model the processing time of each activity\nbased on the start and end timestamps recorded in the event log. In practice,\nhowever, it is common that the recorded start times do not precisely reflect\nthe actual start of the activities. For example, a resource starts working on\nan activity, but its start time is not recorded until she/he interacts with the\nsystem. If not corrected, these situations induce waiting times in which the\nresource is considered to be free, while she/he is actually working. To address\nthis limitation, this article proposes a technique to identify the waiting time\nprevious to each activity instance in which the resource is actually working on\nthem, and repair their start time so that they reflect the actual processing\ntime. The idea of the proposed technique is that, as far as simulation is\nconcerned, an activity instance may start once it is enabled and the\ncorresponding resource is available. Accordingly, for each activity instance,\nthe proposed technique estimates the activity enablement and the resource\navailability time based on the information available in the event log, and\nrepairs the start time to include the non-recorded processing time. An\nempirical evaluation involving eight real-life event logs shows that the\nproposed approach leads to BPS models that closely reflect the temporal\ndynamics of the process.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12224v1"
    },
    {
        "title": "Trading Strategies: Earning More in Investment",
        "authors": [
            "Yueying Ma",
            "Yan Mi",
            "Yujing Bian"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Gold and bitcoin are not new to us, but with limited cash and time, given\nonly the past stream of the daily price of gold and bitcoin, it is a kind of\nnew problem for us to develop a certain model and determine the best strategy\nto get the most return. Here, our team members analyzed the data provided and\nfinally made a unified system of models to predict the price and evaluate the\nrisk and return in our act of investment, and we name this series of models and\nmeasurements as CTP Model. This is a model which can determine and describe\nwhat transaction should the trader make each day and what is the certain\nmaximum return he will get under different risk levels.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.03294v1"
    },
    {
        "title": "Development of an IoT-Based Sleep Apnea Monitoring System for Healthcare\n  Applications",
        "authors": [
            "Abdur Rab Dhruba",
            "Kazi Nabiul Alam",
            "Md Shakib Khan",
            "Sami Bourouis",
            "Mohammad Monirujjaman Khan"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Sleep is an essential and vital element of a person life and health that\nhelps to refresh and recharge the mind and body of a person. The quality of\nsleep is very important in every person lifestyle, removing various diseases.\nBad sleep is a big problem for a lot of people for a very long time. People\nsuffering from various diseases are dealing with various sleeping disorders,\ncommonly known as sleep apnea. Real-time monitoring of sleep is the key to\ndetecting sleep apnea. To solve this problem, an IoT based real-time sleep\napnea monitoring system has been developed. It will allow the user to measure\ndifferent indexes of sleep and will notify them through a mobile application\nwhen anything odd occurs. The system contains various sensors to measure the\nECG, Heart Rate, Pulse rate, Skin response, and SpO2 of any person during the\nentire sleeping period. To analyze and detect sleep apnea in real time, the\nsystem monitors several people during the sleeping period. The results are\ndisplayed on the monitor of the Arduino boards and in the mobile application.\nThe analysis of the achieved data can detect sleep apnea in some of the people\nthat the system monitored, and it can also display the reason why sleep apnea\nhappens. This paper will help everyone learn about sleep apnea and will help\npeople detect it and take the necessary steps to prevent it.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.05449v1"
    },
    {
        "title": "A Digital Twin Description Framework and its Mapping to Asset\n  Administration Shell",
        "authors": [
            "Bentley James Oakes",
            "Ali Parsai",
            "Bart Meyers",
            "Istvan David",
            "Simon Van Mierlo",
            "Serge Demeyer",
            "Joachim Denil",
            "Paul De Meulenaere",
            "Hans Vangheluwe"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  The pace of reporting on Digital Twin (DT) projects continues to accelerate\nboth in industry and academia. However, these experience reports often leave\nout essential characteristics of the DT, such as the scope of the\nsystem-under-study, the insights and actions enabled, and the time-scale of\nprocessing. A lack of these details could therefore hamper both understanding\nof these DTs and development of DT tools and techniques. Our previous work\ndeveloped a DT description framework with fourteen characteristics as a\nchecklist for experience report authors to better describe the capabilities of\ntheir DT projects. This report provides an extended example of reporting to\nhighlight the utility of this description framework, focusing on the DT of an\nindustrial drilling machine. Furthermore, we provide a mapping from our\ndescription framework to the Asset Administration Shell (AAS) which is an\nemerging standard for Industry 4.0 system integration. This mapping aids\npractitioners in understanding how our description framework relates to AAS,\npotentially aiding in description or implementation activities.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12661v2"
    },
    {
        "title": "Language and Intelligence, Artificial vs. Natural or What Can and What\n  Cannot AI Do with NL?",
        "authors": [
            "Gyula Klima"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  In this talk, I argue that there are certain pragmatic features of natural\nlanguage (that I will call 'productivity' and 'malleability', on top of\nsyntactical generativity and semantical compositionality), which are not only\nhard, but even impossible to capture in an artificial language used by an AI\nsystem, and the reason for this is to be found in certain deep, metaphysical\ndifferences between artificial and natural intelligence, accounting for the\ndifferences in their respective processes of concept-formation.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.12829v1"
    },
    {
        "title": "Star Anagram Detection and Classification",
        "authors": [
            "Jason Parker",
            "Dan Barker"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  A star anagram is a rearrangement of the letters of one word to produce\nanother word where no letter retains its original neighbors. These maximally\nshuffled anagrams are rare, comprising only about 5.7% of anagrams in English.\nThey can also be depicted as unicursal polygons with varying forms, including\nthe eponymous stars. We develop automated methods for detecting stars among\nother anagrams and for classifying them based on their polygon's degree of both\nrotational and reflective symmetry. Next, we explore several properties of star\nanagrams including proofs for two results about the edge lengths of perfect,\ni.e., maximally symmetric, stars leveraging perhaps surprising connections to\nmodular arithmetic and the celebrated Chinese Remainder Theorem. Finally, we\nconduct an exhaustive search of English for star anagrams and provide numerical\nresults about their clustering into common shapes along with examples of\ngeometrically noteworthy stars.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.06397v1"
    },
    {
        "title": "PoolLines: Modeling Carpooling as Ephemeral Lines in GTFS for effective\n  integration with Public Transit",
        "authors": [
            "Youssef Chaabouni",
            "Andrea Araldo",
            "Andr de Palma",
            "Souhila Arib"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  In carpooling systems, a set of drivers owning a private car can accept a\nsmall detour to pick-up and drop-off other riders. However, carpooling is\nwidely used for long-distance trips, where rider-driver matching can be done\ndays ahead. Making carpooling a viable option for daily commute is more\nchallenging, as trips are shorter and, proportionally, the detours tolerated by\ndrivers are more tight. As a consequence, finding riders and drivers sharing\nclose-enough origins, destinations and departure time is less likely, which\nlimits potential matching. In this paper we propose an Integrated System, where\ncarpooling matching is synchronized with Public Transit (PT) schedules, so as\nto serve as a feeder service to PT in the first mile. Driver detours are\nproposed towards PT selected stations, which are used as consolidation points,\nthus increasing matching probability. We present a computationally efficient\nmethod to represent PT schedules and drivers trajectory in a single General\nTransit Feed Specification database, which allows to compute multimodal rider\njourneys using any off the shelf planners. We showcase our approach in the\nmetropolitan area of Portland, Oregon, considering 8k randomly generated trips.\nWe show the benefits of our Integrated System. We find that 10% more riders\nfind a feasible matching with respect to the status quo, where carpooling and\nPT are operated separately. We release our code as open source.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.07578v1"
    },
    {
        "title": "O Problema do Roteamento de Interligaes Eltricas em Circuitos\n  Integrados",
        "authors": [
            "Tiago Matos Santos"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Integrated circuit design automation tools are essential for the feasibility\nof complex designs with millions of transistors. One of the steps performed\nwithin the process is the routing of interconnections between components of a\ncircuit. This problem, which also aims to optimize the utilization of\nconnection resources, has been shown to be NP-Complete and requires heuristic\nalgorithms to look for the best achievable solutions. In this work, we present\na definition of this problem in context with a brief review of existing\nsolutions in the literature. Then, we propose a methodology for the development\nof an original algorithm, which aims to differentiate itself, in certain\ndomains, from the solutions already proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.10483v1"
    },
    {
        "title": "Knowledge Retrieval With Functional Object-Oriented Networks",
        "authors": [
            "Shawn Diaz"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  In this experiment, three different search algorithms are implemented for the\npurpose of extracting a task tree from a large knowledge graph, known as the\nFunctional Object-Oriented Network (FOON). Using a universal FOON, which\ncontains knowledge extracted by annotating online cooking videos, and a desired\ngoal, a task tree can be retrieved. The process of searching the universal FOON\nfor task tree retrieval is tested using iterative deepening search and greedy\nbest-first search with two different heuristic functions. The performance of\nthese three algorithms is analyzed and compared. The results of the experiment\nshow that iterative deepening performs strongly overall. However, different\nheuristics in an informed search proved to be beneficial for certain\nsituations.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.02608v1"
    },
    {
        "title": "Extracting task trees using knowledge retrieval search algorithms in\n  functional object-oriented network",
        "authors": [
            "Tyree Lewis"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  The functional object-oriented network (FOON) has been developed as a\nknowledge representation method that can be used by robots in order to perform\ntask planning. A FOON can be observed as a graph that can provide an ordered\nplan for robots to retrieve a task tree, through the knowledge retrieval\nprocess. We compare two search algorithms to evaluate their performance in\nextracting task trees: iterative deepening search (IDS) and greedy best-first\nsearch (GBFS) with two different heuristic functions. Then, we determine which\nalgorithm is capable of obtaining a task tree for various cooking recipes using\nthe least number of functional units. Preliminary results show that each\nalgorithm can perform better than the other, depending on the recipe provided\nto the search algorithm.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.08314v1"
    },
    {
        "title": "An Accurate Hybrid Delay Model for Multi-Input Gates",
        "authors": [
            "Arman Ferdowsi",
            "Ulrich Schmid",
            "Josef Salzmann"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  In order to facilitate the analysis of timing relations between individual\ntransitions in a signal trace, dynamic digital timing analysis offers a less\naccurate but much faster alternative to analog simulations of digital circuits.\nThis primarily requires gate delay models that also account for the fact that\nthe input-to-output delay of a particular input transition also depends on the\ntemporal distance to the previous output transitions. In the case of\nmulti-input gates, the delay also experiences variations caused by multi-input\nswitching (MIS) effects, i.e., transitions at different inputs that occur in\nclose temporal proximity. In this paper, we advocate the development of hybrid\ndelay models for CMOS gates obtained by replacing transistors with time-variant\nresistors. We exemplify our approach by applying it to a NOR gate (and, hence,\nto the dual NAND gate) and a Muller C gate. We analytically solve the resulting\nfirst-order differential equations with non-constant-coefficients, and derive\nanalytic expressions for the resulting MIS gate delays. The resulting formulas\nnot only pave the way to a sound model parametrization procedure, but are also\ninstrumental for implementing fast and efficient digital timing simulation. By\ncomparison with analog simulation data, we show that our models faithfully\nrepresent all relevant MIS effects. Using an implementation in the Involution\nTool, we demonstrate that our model surpasses the alternative digital delay\nmodels for NOR gates known to us in terms of accuracy, with comparably short\nrunning times.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.10628v2"
    },
    {
        "title": "$\\texttt{Davos}$: a Python \"smuggler\" for constructing lightweight\n  reproducible notebooks",
        "authors": [
            "Paxton C. Fitzpatrick",
            "Jeremy R. Manning"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Reproducibility is a core requirement of modern scientific research. For\ncomputational research, reproducibility means that code should produce the same\nresults, even when run on different systems. A standard approach to ensuring\nreproducibility entails packaging a project's dependencies along with its\nprimary code base. Existing solutions vary in how deeply these dependencies are\nspecified, ranging from virtual environments, to containers, to virtual\nmachines. Each of these existing solutions requires installing or setting up a\nsystem for running the desired code, increasing the complexity and time cost of\nsharing or engaging with reproducible science. Here, we propose a\nlighter-weight solution: the $\\texttt{Davos}$ package. When used in combination\nwith a notebook-based Python project, $\\texttt{Davos}$ provides a mechanism for\nspecifying the correct versions of the project's dependencies directly within\nthe code that requires them, and automatically installing them in an isolated\nenvironment when the code is run. The $\\texttt{Davos}$ package further ensures\nthat those packages and specific versions are used every time the notebook's\ncode is executed. This enables researchers to share a complete reproducible\ncopy of their code within a single Jupyter notebook file.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.15445v2"
    },
    {
        "title": "Brief on tool path generation/optimization methods for multi-axis CNC\n  machining",
        "authors": [
            "Qiang Zou"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  The quality of tool paths is a dominant factor in CNC machining, determining\nits efficiency and accuracy. This paper provides a brief review (in Chinese) on\ntool path planning methods reported in the literature, focusing on their\ncategorization, motivating problems/issues, and historical development. Some\npromising research trends have also been stressed, especially for the paradigm\nshift from tool path generation towards tool path optimization.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.07941v1"
    },
    {
        "title": "Automating Crochet Patterns for Surfaces of Revolution",
        "authors": [
            "Megan Martinez",
            "Amanda Taylor Lipnicki"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  A surface of revolution is created by taking a curve in the $xy$-plane and\nrotating it about some axis. We develop a program which automatically generates\ncrochet patterns for surfaces by revolution when they are obtained by rotating\nabout the $x$-axis. In order to accomplish this, we invoke the arclength\nintegral to determine where to take measurements for each row. In addition, a\ndistance measure is created to optimally space increases and decreases. The\nresult is a program that will take a function, $x$-bounds, crochet gauge, and a\nscale in order to produce a polished crochet pattern.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.02205v1"
    },
    {
        "title": "A Systematic Review on Human Modeling: Digging into Human Digital Twin\n  Implementations",
        "authors": [
            "Heribert Pascual",
            "Xavi Masip Bruin",
            "Albert Alonso",
            "Judit Cerd"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Human Digital Twins (HDTs) are digital replicas of humans that either mirror\na complete human body, some parts of it as can be organs, flows, cells, or even\nhuman behaviors. An HDT is a human specific replica application inferred from\nthe digital twin (DT) manufacturing concept, defined as a technique that\ncreates digital replicas of physical systems or processes aimed at optimizing\ntheir performance and supporting more accurate decision-making processes. The\nmain goal of this paper is to provide readers with a comprehensive overview of\ncurrent efforts in the HDT field, by browsing its basic concepts, differences\nwith DTs, existing developments, and the distinct areas of application. The\nreview methodology includes an exhaustive review of scientific literature,\npatents, and industrial initiatives, as well as a discussion about ongoing and\nforeseen HDT research activity, emphasizing its potential benefits and\nlimitations.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.03593v1"
    },
    {
        "title": "EuroCrops: All you need to know about the Largest Harmonised Open Crop\n  Dataset Across the European Union",
        "authors": [
            "Maja Schneider",
            "Tobias Schelte",
            "Felix Schmitz",
            "Marco Krner"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  EuroCrops contains geo-referenced polygons of agricultural croplands from 16\ncountries of the European Union (EU) as well as information on the respective\ncrop species grown there. These semantic annotations are derived from\nself-declarations by farmers receiving subsidies under the Common Agriculture\nPolicy (CAP) of the European Commission (EC). Over the last 1.5 years, the\nindividual national crop datasets have been manually collected, the crop\nclasses have been translated into the English language and transferred into the\nnewly developed Hierarchical Crop and Agriculture Taxonomy (HCAT). EuroCrops is\npublicly available under continuous improvement through an active user\ncommunity.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.10202v1"
    },
    {
        "title": "CoCoMo: Computational Consciousness Modeling for Generative and Ethical\n  AI",
        "authors": [
            "Edward Y. Chang"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  The CoCoMo model proposes a computational solution to the challenge of\nincorporating ethical and emotional intelligence considerations into AI\nsystems, with the aim of creating AI agents that combine knowledge with\ncompassion. To achieve this goal, CoCoMo prioritizes fairness, beneficence,\nnon-maleficence, empathy, adaptability, transparency, and critical and\nexploratory thinking abilities. The model employs consciousness modeling,\nreinforcement learning, and prompt template formulation to support these\ndesired traits. By incorporating ethical and emotional intelligence\nconsiderations, a generative AI model can potentially lead to improved\nfairness, reduced toxicity, and increased reliability.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.02438v2"
    },
    {
        "title": "Manuscript of a method for improving wear in intermittently computing\n  file systems",
        "authors": [
            "Yeteng Liao",
            "Han wang"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  For the first time, the repeated wear phenomenon of high-frequency power\nfailure on the data block area in intermittent computing file system is found.\nA method to improve NVM wear in ICFS under high-frequency power failure\nscenarios is proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.05399v1"
    },
    {
        "title": "The Standard Problem",
        "authors": [
            "Enrico Coiera"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Objective: This paper proposes a framework to support the scientific research\nof standards so that they can be better measured, evaluated, and designed.\nMethods: Beginning with the notion of common models, the framework describes\nthe general standard problem - the seeming impossibility of creating a\nsingular, persistent and definitive standard which is not subject to change\nover time in an open system. Results: The standard problem arises from\nuncertainty driven by variations in operating context, standard quality,\ndifferences in implementation, and drift over time. As a result, fitting work\nusing conformance services is needed to repair these gaps between a standard\nand what is required for real-world use. To guide standards design and repair,\na framework for measuring performance in context is suggested, based on signal\ndetection theory and technomarkers. Based on the type of common model in\noperation, different conformance strategies are identified: (a) Universal\nconformance (all agents access the same standard); (b) Mediated conformance (an\ninteroperability layer supports heterogeneous agents) and (c) Localized\nconformance (autonomous adaptive agents manage their own needs). Conformance\nmethods include incremental design, modular design, adaptors, and creating\ninteractive and adaptive agents. Discussion: Machine learning should have a\nmajor role in adaptive fitting. Research to guide the choice and design of\nconformance services may focus on the stability and homogeneity of shared\ntasks, and whether common models are shared ahead of time or adjusted at task\ntime. Conclusion: This analysis conceptually decouples interoperability and\nstandardization. While standards facilitate interoperability, interoperability\nis achievable without standardization.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.09114v2"
    },
    {
        "title": "From Electronic Design Automation to Building Design Automation:\n  Challenges and Opportunities",
        "authors": [
            "Yu-Wen Lin",
            "Tsz Ling Elaine Tang",
            "Alberto L. Sangiovanni-Vincentelli",
            "Stefano Schiavon",
            "Costas J. Spanos"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Design automation, which involves the use of software tools and technologies\nto streamline the design process, has been widely adopted in the electronics\nindustry, resulting in significant advancements in product development and\nmanufacturing. However, building design, which involves the creation of complex\nstructures and systems, has traditionally lagged behind in leveraging design\nautomation technologies. Despite extensive research on design automation in the\nbuilding industry, its application in the current design of buildings is\nlimited. This paper aims to (1) compare the design processes between\nelectronics and building design, (2) highlight similarities and differences in\ntheir approaches, and (3) examine challenges and opportunities associated with\nbringing the concept of design automation from electronics to building design.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.06380v1"
    },
    {
        "title": "Assessing Exoplanet Habitability through Data-driven Approaches: A\n  Comprehensive Literature Review",
        "authors": [
            "Mithil Sai Jakka"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  The exploration and study of exoplanets remain at the frontier of\nastronomical research, challenging scientists to continuously innovate and\nrefine methodologies to navigate the vast, complex data these celestial bodies\nproduce. This literature the review aims to illuminate the emerging trends and\nadvancements within this sphere, specifically focusing on the interplay between\nexoplanet detection, classification, and visualization, and the the\nincreasingly pivotal role of machine learning and computational models. Our\njourney through this realm of exploration commences with a comprehensive\nanalysis of fifteen meticulously selected, seminal papers in the field. These\npapers, each representing a distinct facet of exoplanet research, collectively\noffer a multi-dimensional perspective on the current state of the field. They\nprovide valuable insights into the innovative application of machine learning\ntechniques to overcome the challenges posed by the analysis and interpretation\nof astronomical data. From the application of Support Vector Machines (SVM) to\nDeep Learning models, the review encapsulates the broad spectrum of machine\nlearning approaches employed in exoplanet research. The review also seeks to\nunravel the story woven by the data within these papers, detailing the triumphs\nand tribulations of the field. It highlights the increasing reliance on diverse\ndatasets, such as Kepler and TESS, and the push for improved accuracy in\nexoplanet detection and classification models. The narrative concludes with key\ntakeaways and insights, drawing together the threads of research to present a\ncohesive picture of the direction in which the field is moving. This literature\nreview, therefore, serves not just as an academic exploration, but also as a\nnarrative of scientific discovery and innovation in the quest to understand our\ncosmic neighborhood.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11204v1"
    },
    {
        "title": "Exploring the use of Eye Tracking Technology to improve Website\n  Usability",
        "authors": [
            "Niharika Veeravalli"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  This study investigates the capability blessings of the use of eye-monitoring\ntechnology to beautify the usability of web sites. With the upward thrust of\non-line interactions, website usability has turn out to be increasingly\nimportant for making sure person pleasure and engagement. Eye-tracking\ntechnology offers a non-invasive way to measure how users interact with web\nsites with the aid of monitoring their eye actions and gaze styles. By studying\nthose statistics, internet site designers and builders can advantage insights\ninto how customers navigate, examine, and method data on their web sites. This\npaper affords an overview of applicable literature on eye-monitoring and\nwebsite usability, as well as a precis of research which have explored the\nusage of eye-tracking era to improve website design and overall performance.\nThe outcomes propose that eye-tracking era can offer valuable records for\nenhancing internet site usability, inclusive of insights into consumer\nattention, visible hierarchy, and consumer engagement. Further studies are\nwanted to explore the full potential of eye-tracking generation and to develop\ngreat practices for incorporating this technology into website design and\ndevelopment techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.11345v1"
    },
    {
        "title": "Software Development Vehicles to enable extended and early co-design: a\n  RISC-V and HPC case of study",
        "authors": [
            "Filippo Mantovani",
            "Pablo Vizcaino",
            "Fabio Banchelli",
            "Marta Garcia-Gasulla",
            "Roger Ferrer",
            "Giorgos Ieronymakis",
            "Nikos Dimou",
            "Vassilis Papaefstathiou",
            "Jesus Labarta"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Prototyping HPC systems with low-to-mid technology readiness level (TRL)\nsystems is critical for providing feedback to hardware designers, the system\nsoftware team (e.g., compiler developers), and early adopters from the\nscientific community. The typical approach to hardware design and HPC system\nprototyping often limits feedback or only allows it at a late stage. In this\npaper, we present a set of tools for co-designing HPC systems, called software\ndevelopment vehicles (SDV). We use an innovative RISC-V design as a\ndemonstrator, which includes a scalar CPU and a vector processing unit capable\nof operating large vectors up to 16 kbits. We provide an incremental\nmethodology and early tangible evidence of the co-design process that provide\nfeedback to improve both architecture and system software at a very early stage\nof system development.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.01797v1"
    },
    {
        "title": "From Full-fledged ERP Systems Towards Process-centric Business Process\n  Platforms",
        "authors": [
            "Lukas Bhme",
            "Tobias Wuttke",
            "Ralf Teusner",
            "Michael Perscheid",
            "Sebastian Baltes",
            "Christoph Matthies",
            "Benedict Bender"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Enterprise Resource Planning (ERP) systems are critical to the success of\nenterprises, facilitating business operations through standardized digital\nprocesses. However, existing ERP systems are unsuitable for startups and small\nand medium-sized enterprises that grow quickly and require adaptable solutions\nwith low barriers to entry. Drawing upon 15 explorative interviews with\nindustry experts, we examine the challenges of current ERP systems using the\ntask technology fit theory across companies of varying sizes. We describe high\nentry barriers, high costs of implementing implicit processes, and insufficient\ninteroperability of already employed tools. We present a vision of a future\nbusiness process platform based on three enablers: Business processes as\nfirst-class entities, semantic data and processes, and cloud-native elasticity\nand high availability. We discuss how these enablers address current ERP\nsystems' challenges and how they may be used for research on the next\ngeneration of business software for tomorrow's enterprises.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.02995v1"
    },
    {
        "title": "Enjeux de communication dans la multirepr{}sentation cartographique\n  reproductible",
        "authors": [
            "Nicolas Lambert",
            "Timothe Giraud",
            "Ronan Ysebaert"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  This chapter deepens cartographic communication through a cartographic\nmultirepresentation exercise. Using a single dataset on World population data,\nthe chapter presents a series of 13 different maps to illustrate how mapping is\nprimarily a matter of choices and methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.10862v1"
    },
    {
        "title": "Towards Mobility Data Science (Vision Paper)",
        "authors": [
            "Mohamed Mokbel",
            "Mahmoud Sakr",
            "Li Xiong",
            "Andreas Zfle",
            "Jussara Almeida",
            "Taylor Anderson",
            "Walid Aref",
            "Gennady Andrienko",
            "Natalia Andrienko",
            "Yang Cao",
            "Sanjay Chawla",
            "Reynold Cheng",
            "Panos Chrysanthis",
            "Xiqi Fei",
            "Gabriel Ghinita",
            "Anita Graser",
            "Dimitrios Gunopulos",
            "Christian Jensen",
            "Joon-Seok Kim",
            "Kyoung-Sook Kim",
            "Peer Krger",
            "John Krumm",
            "Johannes Lauer",
            "Amr Magdy",
            "Mario Nascimento",
            "Siva Ravada",
            "Matthias Renz",
            "Dimitris Sacharidis",
            "Cyrus Shahabi",
            "Flora Salim",
            "Mohamed Sarwat",
            "Maxime Schoemans",
            "Bettina Speckmann",
            "Egemen Tanin",
            "Xu Teng",
            "Yannis Theodoridis",
            "Kristian Torp",
            "Goce Trajcevski",
            "Marc van Kreveld",
            "Carola Wenk",
            "Martin Werner",
            "Raymond Wong",
            "Song Wu",
            "Jianqiu Xu",
            "Moustafa Youssef",
            "Demetris Zeinalipour",
            "Mengxuan Zhang",
            "Esteban Zimnyi"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Mobility data captures the locations of moving objects such as humans,\nanimals, and cars. With the availability of GPS-equipped mobile devices and\nother inexpensive location-tracking technologies, mobility data is collected\nubiquitously. In recent years, the use of mobility data has demonstrated\nsignificant impact in various domains including traffic management, urban\nplanning, and health sciences. In this paper, we present the emerging domain of\nmobility data science. Towards a unified approach to mobility data science, we\nenvision a pipeline having the following components: mobility data collection,\ncleaning, analysis, management, and privacy. For each of these components, we\nexplain how mobility data science differs from general data science, we survey\nthe current state of the art and describe open challenges for the research\ncommunity in the coming years.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.05717v4"
    },
    {
        "title": "The Impact of Process Complexity on Process Performance: A Study using\n  Event Log Data",
        "authors": [
            "Maxim Vidgof",
            "Bastian Wurm",
            "Jan Mendling"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Complexity is an important characteristic of any business process. The key\nassumption of much research in Business Process Management is that process\ncomplexity has a negative impact on process performance. So far, behavioral\nstudies have measured complexity based on the perception of process\nstakeholders. The aim of this study is to investigate if such a connection can\nbe supported based on the analysis of event log data. To do so, we employ a set\nof 38 metrics that capture different dimensions of process complexity. We use\nthese metrics to build various regression models that explain process\nperformance in terms of throughput time. We find that process complexity as\ncaptured in event logs explains the throughput time of process executions to a\nconsiderable extent, with the respective R-squared reaching up to 0.96. Our\nstudy offers implications for empirical research on process performance and can\nserve as a toolbox for practitioners.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06106v1"
    },
    {
        "title": "Impacts of Business Architecture in the Context of Digital\n  Transformation: An Empirical Study Using PLS-SEM Approach",
        "authors": [
            "Dennis O'Higgins"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Despite the critical importance of Digital Transformation, up to 95% of\ninitiatives fail to deliver expected business benefits. This paper explores the\nrole of Business Architecture practices in enhancing digital transformation\nsuccess. Using an adapted Balanced Scorecard approach and a Structural Equation\nModel (SEM), we analysed survey responses from 129 industry practitioners using\na Partial Least Squares (PLS) approach. Our findings indicate that effective\nbusiness architecture practices significantly improve business alignment,\nefficiency, service delivery, and strategic outcomes, leading to successful\ndigital transformation. The study also validates factors proposed by AL-Malaise\nAL-Ghamdi (2017) in the context of digital transformation. The paper presents\nan adapted conceptual model addressing discriminant validity issues in previous\nmodels and benefiting from the robustness of the Balanced Scorecard approach.\nThe study concludes by highlighting the essential role of business architecture\nin driving digital transformation success.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.11895v1"
    },
    {
        "title": "Analytical Solution of Poisson's Equation with Application to VLSI\n  Global Placement",
        "authors": [
            "Wenxing Zhu",
            "Zhipeng Huang",
            "Jianli Chen",
            "Yao-Wen Chang"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Poisson's equation has been used in VLSI global placement for describing the\npotential field caused by a given charge density distribution. Unlike previous\nglobal placement methods that solve Poisson's equation numerically, in this\npaper, we provide an analytical solution of the equation to calculate the\npotential energy of an electrostatic system. The analytical solution is derived\nbased on the separation of variables method and an exact density function to\nmodel the block distribution in the placement region, which is an infinite\nseries and converges absolutely. Using the analytical solution, we give a fast\ncomputation scheme of Poisson's equation and develop an effective and efficient\nglobal placement algorithm called Pplace. Experimental results show that our\nPplace achieves smaller placement wirelength than ePlace and NTUplace3. With\nthe pervasive applications of Poisson's equation in scientific fields, in\nparticular, our effective, efficient, and robust computation scheme for its\nanalytical solution can provide substantial impacts on these fields.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.12041v1"
    },
    {
        "title": "IoT Based Smart Attendance System Using Rfid: A Systematic Literature\n  Review",
        "authors": [
            "Kashif Ishaq",
            "Samra Bibi"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  The use of Radio Frequency Identification (RFID) technology is ubiquitous in\na number of businesses and sectors, including retail sales, smart cities,\nagriculture, and transportation. Additionally, educational institutions have\nstarted using RFID to track student attendance, combining this technology with\nGoogle Sheets and the Internet of Things (IoT) to build a real-time attendance\ntracking system. For a thorough examination of the creation of a student\nattendance system, this paper includes a systematic literature evaluation of 21\nmajor research published on IoT based attendance systems employing RFID. This\nRFID-based attendance system enables automation, eliminating several problems\nconnected with the manual process, such as time wasting, proxies, and the\npossibility of losing the attendance sheet, in contrast to the traditional\nattendance system, which depends on manual signatures. By creating a system\nthat automatically registers students' attendance by merely flashing their\nstudent cards at the RFID reader, all the aforementioned difficulties may be\nsuccessfully addressed. This automated method guarantees attendance monitoring\naccuracy and dependability while also saving time. This paper's conclusion\nhighlights the significant advantages of implementing an IoT-based attendance\nsystem based on RFID technology. The suggested solution provides a trustworthy,\nefficient, and secure alternative to manual attendance techniques, successfully\naddressing their shortcomings. This paper offers helpful insights for\ninstitutions looking to create a cutting-edge attendance system that increases\nstudent involvement and academic achievement by looking at guiding principles,\nbest practices, and the successful resolution of difficulties.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.02591v1"
    },
    {
        "title": "ChatGPT: ascertaining the self-evident. The use of AI in generating\n  human knowledge",
        "authors": [
            "Ioannis D. Apostolopoulos",
            "Mpesi Tzani",
            "Sokratis I. Aznaouridis"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  The fundamental principles, potential applications, and ethical concerns of\nChatGPT are analyzed and discussed in this study. Since ChatGPT emerged, it has\ngained a rapidly growing popularity, with more than 600 million users today.\nThe development of ChatGPT was a significant mile-stone, as it demonstrated the\npotential of large-scale language models to generate natural language responses\nthat are almost indistinguishable from those of a human. ChatGPT's operational\nprinciples, prospective applications, and ability to advance a range of human\nendeavours are discussed in the paper. However, much of the work discusses and\nposes moral and other problems that rely on the subject. To document the\nlatter, we submitted 14 queries and captured the ChatGPT responses. ChatGPT\nappeared to be honest, self-knowledgeable, and careful with its answers. The\nauthors come to the realization that since AI is already a part of society, the\npervasiveness of the ChatGPT tool to the general public has once again brought\nto light concerns regarding AI in general. Still, they have moved from the\ndomain of scientific community collective reflection at a conceptual level to\neveryday practice this time.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.06373v1"
    },
    {
        "title": "An Efficient Early-breaking Estimation and Tree-splitting Missing RFID\n  Tag Identification Protocol",
        "authors": [
            "Lijuan Zhang",
            "Mingqiu Fan",
            "Chunni Yu",
            "Lei Lei"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Recent statistics have demonstrated that missing items have become the main\ncause of loss for retailers in inventory management. To quickly identify\nmissing tags, traditional protocols adopt Aloha-based strategies which take a\nlong time, especially when the number of tags is large. Among them, few works\nconsidered the effect of unexpected unknown tags on the missing tag\nidentification process. With the presence of unknown tags, some missing tags\nmay be falsely identified as present. Thus, the system's reliability is hardly\nguaranteed. In this work, we propose an efficient early-breaking estimation and\ntree-splitting-based missing tag identification (ETMTI) protocol for\nlarge-scale RFID systems. In ETMTI, a new early-breaking estimation and\ndeactivation method is developed to effectively estimate the number of unknown\ntags and deactivate them within a short time. Next, a new tree-splitting-based\nmissing tag identification method is proposed to quickly identify missing tags\nwith a B-ary splitting tree. Besides, a bit-tracking response strategy is\ndesigned to further reduce the time cost. The optimal parameters, time cost,\nand false negative rate of ETMTI are analyzed theoretically. Simulation results\nare presented to demonstrate that the proposed ETMTI protocol takes a smaller\ntime and has a lower false negative rate than the best-performing benchmarks.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.09484v1"
    },
    {
        "title": "Towards The Ultimate Brain: Exploring Scientific Discovery with ChatGPT\n  AI",
        "authors": [
            "Gerardo Adesso"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  This paper presents a novel approach to scientific discovery using an\nartificial intelligence (AI) environment known as ChatGPT, developed by OpenAI.\nThis is the first paper entirely generated with outputs from ChatGPT. We\ndemonstrate how ChatGPT can be instructed through a gamification environment to\ndefine and benchmark hypothetical physical theories. Through this environment,\nChatGPT successfully simulates the creation of a new improved model, called\nGPT$^4$, which combines the concepts of GPT in AI (generative pretrained\ntransformer) and GPT in physics (generalized probabilistic theory). We show\nthat GPT$^4$ can use its built-in mathematical and statistical capabilities to\nsimulate and analyze physical laws and phenomena. As a demonstration of its\nlanguage capabilities, GPT$^4$ also generates a limerick about itself. Overall,\nour results demonstrate the promising potential for human-AI collaboration in\nscientific discovery, as well as the importance of designing systems that\neffectively integrate AI's capabilities with human intelligence.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.12400v1"
    },
    {
        "title": "Towards an Interoperability Roadmap for the Energy Transition",
        "authors": [
            "Valerie Reif",
            "Thomas I. Strasser",
            "Joseba Jimeno",
            "Marjolaine Farre",
            "Oliver Genest",
            "Amlie Gyrard",
            "Mark McGranaghan",
            "Gianluca Lipari",
            "Johann Schtz",
            "Mathias Uslar",
            "Sebastian Vogel",
            "Arsim Bytyqi",
            "Rita Dornmair",
            "Andreas Corusa",
            "Gaurav Roy",
            "Ferdinanda Ponci",
            "Alberto Dognini",
            "Antonello Monti"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Smart grid interoperability is the means to achieve the twin green and\ndigital transition but re-mains heterogeneous and fragmented to date. This work\npresents the first ideas and corner-stones of an Interoperability Roadmap for\nthe Energy Transition that is being developed by the Horizon Europe int:net\nproject. This roadmap builds on four cornerstones that address open\ninteroperability issues. These are a knowledge base to address the lack of\nconvergence among existing initiatives, a maturity model and a network of\ntesting and certification facilities to ad-dress the lack of practical tools\nfor the industry, and a governance process to address the gap between\nstandards-related approaches of Standards Development Organisations and\nResearch and Innovation projects. A community of practice will be set up to\nensure the continuity of the ongoing activities related to smart grid\ninteroperability. To outlive the duration of the int:net project, the aim is to\nformalise the community of practice as a legal entity.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.08284v1"
    },
    {
        "title": "Proceedings of the XII International Workshop on Locational Analysis and\n  Related Problems",
        "authors": [
            "Marta Baldomero-Naranjo",
            "Vctor Blanco",
            "Sergio Garca",
            "Ricardo Gzquez",
            "Jrg Kalcsics",
            "Luisa I. Martnez-Merino",
            "Juan M. Muoz-Ocaa",
            "Francisco Temprano",
            "Alberto Torrejn"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  The International Workshop on Locational Analysis and Related Problems will\ntake place during September 7-8, 2023 in Edinburgh (United Kingdom). It is\norganized by the Spanish Location Network and the Location Group GELOCA from\nthe Spanish Society of Statistics and Operations Research (SEIO). The Spanish\nLocation Network is a group of more than 140 researchers from several Spanish\nuniversities organized into 7 thematic groups. The Network has been funded by\nthe Spanish Government since 2003. The current project is RED2022-134149-T. One\nof the main activities of the Network is a yearly meeting aimed at promoting\nthe communication among its members and between them and other researchers, and\nto contribute to the development of the location field and related problems. As\na proof of the internationalization of this research group, this will be the\nfirst time that the meeting is held out of Spain. The topics of interest are\nlocation analysis and related problems. This includes location models,\nnetworks, transportation, logistics, exact and heuristic solution methods, and\ncomputational geometry, among others.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.08337v2"
    },
    {
        "title": "How do users design scientific workflows? The Case of Snakemake",
        "authors": [
            "Sebastian Pohl",
            "Nourhan Elfaramawy",
            "Kedi Cao",
            "Birte Kehr",
            "Matthias Weidlich"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Scientific workflows automate the analysis of large-scale scientific data,\nfostering the reuse of data processing operators as well as the reproducibility\nand traceability of analysis results. In exploratory research, however,\nworkflows are continuously adapted, utilizing a wide range of tools and\nsoftware libraries, to test scientific hypotheses. Script-based workflow\nengines cater to the required flexibility through direct integration of\nprogramming primitives but lack abstractions for interactive exploration of the\nworkflow design by a user during workflow execution. To derive requirements for\nsuch interactive workflows, we conduct an empirical study on the use of\nSnakemake, a popular Python-based workflow engine. Based on workflows collected\nfrom 1602 GitHub repositories, we present insights on common structures of\nSnakemake workflows, as well as the language features typically adopted in\ntheir specification.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.14097v1"
    },
    {
        "title": "Robo Sapiens",
        "authors": [
            "Chaim Ash",
            "Amelia Hans"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  This paper proposes a new method of natural language acquisition for robots\nthat does not require the conversion of speech to text. Folks'Talks employs\nvoice2voice technology that enables a robot to understand the meaning of what\nit is told and to have the ability to learn and understand new languages -\ninclusive of accent, dialect, and physiological differences. To do this, sound\nprocessing and computer vision are incorporated to give the robot a sense of\nspatiotemporal causality. The \"language model\" we are proposing equips a robot\nto imitate a natural speaker's conversational behavior by thinking contextually\nand articulating its surroundings.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.08323v1"
    },
    {
        "title": "CTMaaS: An innovative platform for C-ITS-enabled dynamic Traffic and\n  Fleet Management as a Service",
        "authors": [
            "Areti Kotsi",
            "Vasileia Klimi",
            "Evangelos Mitsakis"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Fleet management systems have been one of the most important research fields\nin transportation science. Nowadays the enhancement of fleet management systems\nwith technologies such as the Cooperative Intelligent Transport System (CITS)\nthat allows fleets to communicate with their environment, with other vehicles\nor with the road infrastructure, resulting in safer and more efficient road\ntravel. This paper aims to present the CTMaaS platform, a tool which integrates\nCITS services and traffic management processes to manage vehicle fleets.\nStarting with a literature review, the paper presents various fleet management\nsystems, that have been developed in the last years, and the most typical CITS\nservices. The next chapters present the CTMaaS platform, use cases, and\nmethodology.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.14052v1"
    },
    {
        "title": "All you need is data: the added value of National Access Points as\n  backbone European ITS data exchange infrastructures",
        "authors": [
            "Chrysostomos Mylonas",
            "Maria Stavara",
            "Evangelos Mitsakis"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Intelligent Transport Systems are crucial in the digital transformation of\ntransportation. The EC mandates the establishment of National Access Points\n(NAPs) in each Member State, serving as common national interfaces for ITS data\nexchange. While progress has been made in standardizing NAP data, integration\nwith operational ITS practices remain limited. This paper presents five NAP use\ncases from the NAPCORE (National Access Point Coordination Organization for\nEurope) CEF funded project. The first one outlines a National Virtual Traffic\nManagement Center offering real time visualized KPIs supporting motorway\ntraffic operations. The second focuses on NAP enabled Cooperative ITS and\ndynamic traffic management services. Next use case involves a Pan European\ninterface, providing visualizations of data availability. The fourth use case\nenhances the digitization of traffic management plans, among different TMC.\nFinally, the fifth use case demonstrates a technical interface combining NAP\ntraffic data with meteorological information for KPIs on extreme weather\nimpacts on traffic.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.14054v1"
    },
    {
        "title": "Large scale deployment of C-ITS: Impact assessment results of the\n  C-Roads Greece pilots",
        "authors": [
            "Areti Kotsi",
            "Evangelos Mitsakis"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  This paper aims to provide insights related to the impact assessment and\nevaluation results from the use of CITS services in the Greek pilot of the\nCRoads Greece project, i.e., Attica Tollway and Egnatia Odos Tollway. The\nimpact assessment and evaluation of the CITS services includes aspects related\nto user acceptance, real world pilot logs collected from the two pilots, and\nsimulation experiments that were conducted for the impact assessment of the\nCITS services. The paper concludes with a roadmap and guidelines for the\nextended deployment of CITS services in the Greek highway and urban road\nnetworks.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.10734v1"
    },
    {
        "title": "Using Terrestrial Laser Scanning, Unmanned Aerial Vehicles and Mixed\n  Reality Methodologies for Digital Survey, 3D Modelling and Historical\n  Recreation of Religious Heritage Monuments",
        "authors": [
            "Aristeidis Zachos",
            "Christos-Nikolaos Anagnostopoulos"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Preserving and safeguarding the Cultural Heritage (CH) of our world from\nunforeseen hazards should be viewed as a collective responsibility for\nhumanity. Consequently, there is a growing imperative for targeted measures\naimed at conserving, rejuvenating, and safeguarding historical assets that\ncarry cultural significance. In recent times, Terrestrial Laser Scanning (TLS),\nUnmanned Aerial Vehicle (UAV) Photogrammetry, and applications in Mixed Reality\n(MR) have assumed a pivotal role in the mapping, recording, preservation, and\npromotion of Cultural Heritage. This ar-ticle endeavors to present a\ncomprehensive approach spanning from 3D surveying to the 3D representation and\npromotion of Religious Cultural Heritage, offering an overview of the applied\nmethodologies. Through the integration of TLS and UAV photogrammetry\ntechniques, a comprehensive digital record of Panagia Ekatontapyliani, the\nadjoining Church of Agios Nikolaos, and the Baptistery, along with their wall\npaintings (hagiographies) and natural surroundings, has been obtained. This\nrecord serves as the foundation for historical documentation and recreation\nusing the HBIM concept, paving the way for the development of diverse Mixed\nReality applications. These applications aim to enhance the visibility,\naccessibility, and visitability of the Monument.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.01380v1"
    },
    {
        "title": "On the relevance of the Godot Engine in the indie game development\n  industry",
        "authors": [
            "Julian Holfeld"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  This paper examines the relevance of the Godot Engine in the indie game\nindustry. The Godot Engine is a relatively new game engine from 2014 and\ncompetes with leading market players. To get to the bottom of its relevance,\ntwo major online sales platforms and the game engines that are commonly used,\nSteam and itch[dot]io, are examined. Mainly, these findings are compared with\nreference data from 2018. It turns out that the Godot engine has gained massive\nrelevance in 2020 and now seems to be one of the leading players in the indie\ngame industry. The exact causes are difficult to determine. However, this paper\nprovides many clues for further research in this area.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.01909v2"
    },
    {
        "title": "Petri Nets for Smart Grids: The Story So Far",
        "authors": [
            "Mouzhi Ge",
            "Bruno Rossi",
            "Stanislav Chren",
            "Jos Miguel Blanco"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Since the energy domain is in a transformative shift towards sustainability,\nthe integration of new technologies and smart systems into traditional power\ngrids has emerged. As an effective approach, Petri Nets (PN) have been applied\nto model and analyze the complex dynamics in Smart Grid (SG) environments.\nHowever, we are currently missing an overview of types of PNs applied to\ndifferent areas and problems related to SGs. Therefore, this paper proposes\nfour fundamental research questions related to the application areas of PNs in\nSGs, PNs types, aspects modelled by PNs in the identified areas, and the\nvalidation methods in the evaluation. The answers to the research questions are\nderived from a comprehensive and interdisciplinary literature analysis. The\nresults capture a valuable overview of PNs applications in the global energy\nlandscape and can offer indications for future research directions.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.05462v1"
    },
    {
        "title": "Analog Circuit Sizing Using Machine Learning Based Transistor Circuit\n  Model",
        "authors": [
            "Alireza Bagheri Rajeoni"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  In this work, a new method for designing an analog circuit for deep\nsub-micron CMOS fabrication processes is proposed. The proposed method\nleverages the regression algorithms with the transistor circuit model to size a\ntransistor in 0.18 um technology fast and without using simulation software.\nThreshold voltage, output resistance, and the product of mobility and oxide\ncapacitance are key parameters in the transistor circuit model to size a\ntransistor. For nano-scale transistors, however, these parameters are nonlinear\nwith respect to electrical and physical characteristics of transistors and\ncircuit simulator is needed to find the value of these parameters and therefore\nthe design time increases. Regression analysis is utilized to predict values of\nthese parameters. We demonstrate the performance of the proposed method by\ndesigning a Current Feedback Instrumentational Amplifier (CFIA). We show that\nthe presented method accomplishes higher than 90% accuracy in predicting the\ndesired value of W. It reduces the design time over 97% compared to\nconventional methods. The designed circuit using the proposed method consumes\n5.76 uW power and has a Common Mode Rejection Ratio (CMRR) of 35.83 dB and it\nresults in achieving 8.17 V/V gain.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16425v1"
    },
    {
        "title": "Selenium-Jupiter: A JUnit 5 extension for Selenium WebDriver",
        "authors": [
            "Boni Garca",
            "Carlos Delgado Kloos",
            "Carlos Alario-Hoyos",
            "Mario Munoz-Organero"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Selenium WebDriver is a library that allows controlling web browsers (e.g.,\nChrome, Firefox, etc.) programmatically. It provides a cross-browser\nprogramming interface in several languages used primarily to implement\nend-to-end tests for web applications. JUnit is a popular unit testing\nframework for Java. Its latest version (i.e., JUnit 5) provides a programming\nand extension model called Jupiter. This paper presents Selenium-Jupiter, an\nopen-source JUnit 5 extension for Selenium WebDriver. Selenium-Jupiter aims to\nease the development of Selenium WebDriver tests thanks to an automated driver\nmanagement process implemented in conjunction with the Jupiter parameter\nresolution mechanism. Moreover, Selenium-Jupiter provides seamless integration\nwith Docker, allowing the use of different web browsers in Docker containers\nout of the box. This feature enables cross-browser testing, load testing, and\ntroubleshooting (e.g., configurable session recordings). This paper presents an\nexample case in which Selenium-Jupiter is used to evaluate the performance of\nvideo conferencing systems based on WebRTC. This example case shows that\nSelenium-Jupiter can build and maintain the required infrastructure for complex\ntests effortlessly.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.01480v1"
    },
    {
        "title": "Portable medical devices creation technology by using the Bluetooth\n  module",
        "authors": [
            "A. O. Dadukin",
            "N. I. Pchelintseva"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The article is devoted Bluetooth wireless personal area networks\nspecification, which provides standard for exchanging data over short\ndistances. It is shown how the technology has evolved and its application in\nthe design of devices. Health Device Profile considered in details, which the\nmain feature is the work of a medical orientation devices.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.03323v1"
    },
    {
        "title": "Research on the evolution of domestic multi-functional meter technology",
        "authors": [
            "Zhen Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The technical evolution of domestic multi-functional electricity meter is\ndeeply discussed. With the rapid development of the domestic power market and\nthe continuous innovation of technology, the domestic multi-functional\nelectricity meters have experienced the transformation from simple billing to\ncomplex multi-functional, from a single application to a wide range of fields.\nThis transformation has not only driven the rapid development of electricity\nmeter technology, but also met the increasing power demand and management\nrequirements. This paper expounds the concept of multi-function meter, the\nworking principle and algorithm of digital multiplier, the initiation and\nevolution of multi-function electricity meter standard, and the initiation and\nevolution of domestic multi-function electricity meter products. Although the\ndomestic independent production of multi-functional meter has made great\nachievements in performance, but in the reliability and key process technology\nstill need to be improved. In addition, the development of communication\ntechnology also provides a new opportunity for the progress of electricity\nmeter technology. The application of the new technology provides a more\nconvenient and efficient way for the data transmission and remote management of\nelectricity meters. Domestic multi-functional electricity meters have made\nremarkable achievements in technology evolution and application and expansion,\nbut they still face some challenges and opportunities. In the future, with the\ncontinuous development of the power market and the promotion of smart grid\nconstruction, domestic multi-functional electricity meters need to continue to\nstrengthen technological innovation and product research and development,\nimprove the reliability and competitiveness of products, in order to meet\nhigher application needs and market requirements.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.05573v1"
    },
    {
        "title": "Design of an Analog Memory Cell in 0.25 micron CMOS process",
        "authors": [
            "Paramita Barai"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  CMOS VLSI technology is the most dominant integration methodology prevailing\nin the world today. Various signal-processing blocks are made using analog or\ndigital design techniques in MOS VLSI. An important component is the Memory\nunit used to store data. In the project a memory cell has been built up using\nanalog design method. A capacitor is used as the basic storage device. The main\nidea behind analog memory is that the analog value of the charge or voltage\nstored in the capacitor is the data stored. So the dielectric quality of the\ncapacitor becomes important here to determine how effectively it can store some\ncharge. Analog memory is a trade off between hardware cost, chip area and\naccuracy or quality of storage. The circuit of analog memory cell was developed\nstarting from the idea that required voltage will be stored in a capacitor and\nMOS transistors were used as switches. A given technology of integration was\nused and hence the dielectric property of the capacitor was fixed. By suitable\ncircuit configuration the analog voltage value was written to the capacitor,\nread out when required and the charge loss was also refreshed. The results\nobtained are as given in the thesis.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.14822v1"
    },
    {
        "title": "Urban Green Index estimation based on data collected by remote sensing\n  for Romanian cities",
        "authors": [
            "Marian Necula",
            "Tudorel Andrei",
            "Bogdan Oancea",
            "Mihaela Pun"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The modernization of offi cial statistics involves the use of new data\nsources, such as data collected through remote sensing. The document contains a\ndescription of how an urban green index, derived from the SDG 11.7 objective,\nwas obtained for Romania's 41 county seat cities based on free data sets\ncollected by remote sensing from the European and North American space\nagencies. The main result is represented by an estimate of the areas of\nsurfaces covered with vegetation for the 40 county seat towns and the\nmunicipality of Bucharest, relative to the total surface. To estimate the area\ncovered with vegetation, we used two data sets obtained by remote sensing,\nnamely data provided by the MODIS mission, the TERRA satellite, and data\nprovided by the Sentinel 2 mission from the Copernicus space program. Based on\nthe results obtained, namely the surface area covered with vegetation,\nestimated in square kilometers, and the percentage of the total surface area or\nurban green index, we have created a national top of the county seat cities\n",
        "pdf_link": "http://arxiv.org/pdf/2402.18618v1"
    },
    {
        "title": "New algorithms for the simplification of multiple trajectories under\n  bandwidth constraints",
        "authors": [
            "Gilles Dejaegere",
            "Mahmoud Sakr"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  This study introduces time-windowed variations of three established\ntrajectory simplification algorithms. These new algorithms are specifically\ndesigned to be used in contexts with bandwidth limitations. We present the\ndetails of these algorithms and highlight the differences compared to their\nclassical counterparts.\n  To evaluate their performance, we conduct accuracy assessments for varying\nsizes of time windows, utilizing two different datasets and exploring different\ncompression ratios. The accuracies of the proposed algorithms are compared with\nthose of existing methods. Our findings demonstrate that, for larger time\nwindows, the enhanced version of the bandwidth-constrained STTrace outperforms\nother algorithms, with the bandwidth-constrained improved version of \\squish\nalso yielding satisfactory results at a lower computational cost. Conversely,\nfor short time windows, only the bandwidth-constrained version of Dead\nReckoning remains satisfactory.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.04821v1"
    },
    {
        "title": "Research on the evolution of smart meter technology",
        "authors": [
            "Zhen Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Smart meter is not only a device used to measure the amount of electricity,\nbut also a core component of the smart grid, realizing the efficient\nmonitoring, prediction and management of power use. With an insight into the\nevolution of smart meter technology, I realized that this change didn't happen\novernight. It has undergone a long journey from the initial mechanical\nelectricity meters to the electronic electricity meters, and now to the highly\nintelligent electricity meters. Technological breakthroughs at each stage have\nlaid the foundation for the final form of smart meters. In the era of\nmechanical watt-hour meters, the measurement of electric energy mainly depends\non the rotation and counting of mechanical structures. The accuracy and\nstability of this method are affected by mechanical wear, environmental\ninterference and other factors, and it is difficult to meet the increasing\ndemand for power management. With the rapid development of electronic\ntechnology, the electronic electricity meter came into being. It uses\nelectronic technology to sample and process the current and voltage, which\ngreatly improves the accuracy and stability of the measurement. At the same\ntime, the electronic electricity meter also has the function of remote meter\nreading and data processing, which has brought great convenience to the power\nmanagement. However, there still have some limitations, such as the complexity\nof data processing and the limitation of communication capacity. It is these\nchallenges that drive the creation of smart power meters. smart meters combine\nadvanced technologies such as the Internet of Things, big data and cloud\ncomputing to realize the real-time monitoring, analysis and prediction of the\nuse of power.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.15406v1"
    },
    {
        "title": "Towards a Cost-Benefit Analysis of Additive Manufacturing as a Service",
        "authors": [
            "Igor Ivki",
            "Tobias Buhmann",
            "Burkhard List",
            "Clemens Gnauer"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The landscape of traditional industrial manufacturing is undergoing a pivotal\nshift from resource-intensive production and long supply chains to more\nsustainable and regionally focused economies. In this evolving scenario, the\nmove towards local, on-demand manufacturing is emerging as a remedy to the\nenvironmentally damaging practice of mass-producing products in distant\ncountries and then transporting them over long distances to customers. This\nparadigm shift significantly empowers customers, giving them greater control\nover the manufacturing process by enabling on-demand production and favouring\nlocal production sites over traditional mass production and extensive shipping\npractices. In this position paper we propose a cloud-native Manufacturing as a\nService (MaaS) platform that integrates advances in three-dimensional (3D)\nprinting technology into a responsive and eco-conscious manufacturing\necosystem. In this context, we propose a high-level architectural design for a\ncloud-based MaaS platform that connects web shops of local stores with small\nand medium-sized enterprises (SMEs) operating 3D printers. Furthermore, we\noutline an experimental design, including a cost-benefit analysis, to\nempirically evaluate the operational effectiveness and economic feasibility in\na cloud-based additive manufacturing ecosystem. The proposed cloud-based MaaS\nplatform enables on-demand additive manufacturing and opens up a profit sharing\nopportunity between different stakeholders.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.18882v1"
    },
    {
        "title": "Towards a Cloud-based Smart Office Solution for Shared Workplace\n  Individualization",
        "authors": [
            "Dominik Hasiwar",
            "Andreas Gruber",
            "Christian Dragschitz",
            "Igor Ivki"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  In the evolving landscape of workplace dynamics, the shift towards hybrid\nworking models has highlighted inefficiencies in the use of traditional office\nspace and the need for an improved employee experience. In this position paper\nwe propose a Smart Office solution that addresses these challenges by\nintegrating a microservice architecture with Internet of Things (IoT)\ntechnologies to provide a flexible, personalized workspace environment. The\nposition paper focuses on the technical implementation of this solution,\nincluding the design of a Workplace Environment Index (WEI) to monitor and\nimprove office conditions. By using cloud technology, IoT devices with sensors,\nand following a user-centred design, the proposed solution shows how Shared\nOpen Workspaces can be transformed into adaptive, efficient environments that\nsupport the diverse needs of the modern workforce. This position paper paves\nthe way for future experimentation in real-world office environments to\nvalidate the effectiveness of the Smart Office solution and provide insights\ninto its potential to redefine the workplace for improved productivity and\nemployee satisfaction.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.18883v2"
    },
    {
        "title": "An IoT Based Water-Logging Detection System: A Case Study of Dhaka",
        "authors": [
            "Md Manirul Islam",
            "Md. Sadad Mahamud",
            "Umme Salsabil",
            "A. A. M. Mazharul Amin",
            "Samiul Haque Suman"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  With a large number of populations, many problems are rising rapidly in\nDhaka, the capital city of Bangladesh. Water-logging is one of the major issues\namong them. Heavy rainfall, lack of awareness and poor maintenance causes bad\nsewerage system in the city. As a result, water is overflowed on the roads and\nsometimes it gets mixed with the drinking water. To overcome this problem, this\npaper realizes the potential of using Internet of Things to combat\nwater-logging in drainage pipes which are used to move wastes as well as\nrainwater away from the city. The proposed system will continuously monitor\nreal time water level, water flow and gas level inside the drainage pipe.\nMoreover, all the monitoring data will be stored in the central database for\ngraphical representation and further analysis. In addition to that if any\nemergency arises in the drainage system, an alert will be sent directly to the\nnearest maintenance office.\n",
        "pdf_link": "http://arxiv.org/pdf/2403.18949v1"
    },
    {
        "title": "VeGAn-Tool: A Fuzzy-logic Approach for Value-based Goal Model Analysis",
        "authors": [
            "Carlos Cano-Genoves",
            "Emilio Insfrn",
            "Silvia Abraho"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Goal-oriented analysis tools are used to assess goal models and assist\nanalysts in decision-making. We introduce the VeGAn-Tool, which prioritizes\ngoals according to their qualitative importance for the stakeholders and\npropagates this information in the goal model according to the different types\nof relationships. The FTOPSIS technique is used to calculate the value of each\nintentional element by employing the fuzzified importance (importance level\nfuzzified and refined by a confidence level) and the impact among the related\nintentional elements. The result is a prioritized goal model according to the\nvalue of each intentional element from the stakeholders' point of view.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.16070v1"
    },
    {
        "title": "Applying the Iterative Development Process: The Creation of Fractal\n  Emergence",
        "authors": [
            "Christopher R. H. Hanusa",
            "Eric Vergo"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The iterative development process is a framework used to design products and\napplications across a wide range of domains. It centers around building\nprototypes, testing them, and updating based on the test results. We discuss\nhow we applied this technique to create Fractal Emergence, an interactive piece\nof mathematical art.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.04544v1"
    },
    {
        "title": "PARSAC: Fast, Human-quality Floorplanning for Modern SoCs with Complex\n  Design Constraints",
        "authors": [
            "Hesham Mostafa",
            "Uday Mallappa",
            "Mikhail Galkin",
            "Mariano Phielipp",
            "Somdeb Majumdar"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The floorplanning of Systems-on-a-Chip (SoCs) and of chip sub-systems is a\ncrucial step in the physical design flow as it determines the optimal shapes\nand locations of the blocks that make up the system. Simulated Annealing (SA)\nhas been the method of choice for tackling classical floorplanning problems\nwhere the objective is to minimize wire-length and the total placement area.\nThe goal in industry-relevant floorplanning problems, however, is not only to\nminimize area and wire-length, but to do that while respecting hard placement\nconstraints that specify the general area and/or the specific locations for the\nplacement of some blocks. We show that simply incorporating these constraints\ninto the SA objective function leads to sub-optimal, and often illegal,\nsolutions. We propose the Constraints-Aware Simulated Annealing (CA-SA) method\nand show that it strongly outperforms vanilla SA in floorplanning problems with\nhard placement constraints. We developed a new floorplanning tool on top of\nCA-SA: PARSAC (Parallel Simulated Annealing with Constraints). PARSAC is an\nefficient, easy-to-use, and massively parallel floorplanner. Unlike current\nSA-based or learning-based floorplanning tools that cannot effectively\nincorporate hard placement-constraints, PARSAC can quickly construct the\nPareto-optimal legal solutions front for constrained floorplanning problems.\nPARSAC also outperforms traditional SA on legacy floorplanning benchmarks.\nPARSAC is available as an open-source repository for researchers to replicate\nand build on our result.\n",
        "pdf_link": "http://arxiv.org/pdf/2405.05495v3"
    },
    {
        "title": "A Match Made in Semantics: Physics-infused Digital Twins for Smart\n  Building Automation",
        "authors": [
            "Ganesh Ramanathan",
            "Simon Mayer"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Buildings contain electro-mechanical systems that ensure the occupants'\ncomfort, health, and safety. The functioning of these systems is automated\nthrough control programs, which are often available as reusable artifacts in a\nsoftware library. However, matching these reusable control programs to the\ninstalled technical systems requires manual effort and adds engineering cost.\nIn this article, we show that such matching can be accomplished fully\nautomatically through logical rules and based on the creation of semantic\nrelationships between descriptions of \\emph{physical processes} and\ndescriptions of technical systems and control programs. For this purpose, we\npropose a high-level bridging ontology that enables the desired rule-based\nmatching and equips digital twins of the technical systems with the required\nknowledge about the underlying physical processes in a self-contained manner.\nWe evaluated our approach in a real-life building automation project with a\ntotal of 34 deployed air handling units. Our data show that rules based on our\nbridging ontology enabled the system to infer the suitable choice of control\nprograms automatically in more than 90\\% of the cases while avoiding almost an\nhour of manual work for each such match.\n",
        "pdf_link": "http://arxiv.org/pdf/2406.13247v1"
    },
    {
        "title": "Genetic Bottleneck and the Emergence of High Intelligence by Scaling-out\n  and High Throughput",
        "authors": [
            "Arifa Khan",
            "Saravanan P",
            "Venkatesan S. K."
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  We study the biological evolution of low-latency natural neural networks for\nshort-term survival, and its parallels in the development of low latency\nhigh-performance Central Processing Unit in computer design and architecture.\nThe necessity of accurate high-quality display of motion picture led to the\nspecial processing units known as the GPU, just as how special visual cortex\nregions of animals produced such low-latency computational capacity. The human\nbrain, especially considered as nothing but a scaled-up version of a primate\nbrain evolved in response to genomic bottleneck, producing a brain that is\ntrainable and prunable by society, and as a further extension, invents\nlanguage, writing and storage of narratives displaced in time and space. We\nconclude that this modern digital invention of social media and the archived\ncollective common corpus has further evolved from just simple CPU-based\nlow-latency fast retrieval to high-throughput parallel processing of data using\nGPUs to train Attention based Deep Learning Neural Networks producing\nGenerative AI with aspects like toxicity, bias, memorization, hallucination,\nwith intriguing close parallels in humans and their society. We show how this\npaves the way for constructive approaches to eliminating such drawbacks from\nhuman society and its proxy and collective large-scale mirror, the Generative\nAI of the LLMs.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.08743v1"
    },
    {
        "title": "A Brief Discussion on the Philosophical Principles and Development\n  Directions of Data Circulation",
        "authors": [
            "Zhi Li",
            "Lei Zhang",
            "Junyi Xin",
            "Jianfei He",
            "Yan Li",
            "Zhenjun Ma",
            "Qi Sun"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The data circulation is a complex scenario involving a large number of\nparticipants and different types of requirements, which not only has to comply\nwith the laws and regulations, but also faces multiple challenges in technical\nand business areas. In order to systematically and comprehensively address\nthese issues, it is essential to have a comprehensive and profound\nunderstanding of 'data circulation'.\n  The traditional analysis method tends to proceed based on the traditional\ncirculation model of commodities, that is, tangible objects, which has some\ndefects and shortcomings, and tends to be a formalized approach, which is faced\nnumerous challenges in practice. This paper analyzes the circulation of data\nwith a philosophical approach, obtains the new explication of data and\nexecuting entity, and provides a new definition of the concepts of data\nutilization and data key stakeholders (objects). At the same time, it puts\nforward the idea of ``data alienation'', and constructs a new interpretive\nframework of ``data circulation''.\n  Based on the framework of this interpretation, it is clearly proposed that\n``data alienation'' is the core of ``data circulation'', benefit distribution\nis the driving force, and legal compliance is the foundation, and further\ndiscussed the three modes of ``data circulation''. It further discusses the\nthree modes of ``data circulation''. It is pointed out that ``data\ncirculation'' is different from traditional ``commodity circulation''. To\nachieve ``data circulation'',a comprehensive information infrastructure needs\nto be established. from a theoretical point of view, it lays a solid foundation\nfor the development of ``data circulation''.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.16719v1"
    },
    {
        "title": "Evaluating the Usability of Qualified Electronic Signatures:\n  Systematized Use Cases and Design Paradigms",
        "authors": [
            "Mustafa Cagal",
            "Kemal Bicakci"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Despite being legally equivalent to handwritten signatures, Qualified\nElectronic Signatures (QES) have not yet achieved significant market success.\nQES offer substantial potential for reducing reliance on paper-based contracts,\nenabling secure digital applications, and standardizing public services.\nHowever, there is limited information on their usability despite the extensive\nrange of use cases. To address this gap, we systematize QES use cases and\ncategorize the system designs implemented to support these use cases,\nemphasizing the necessity to evaluate their respective strengths and weaknesses\nthrough usability studies. Additionally, we present findings from cognitive\nwalkthroughs conducted on use cases across four different QES systems. We\nanticipate that this work will serve as a foundation for a significant\nexpansion of research into the usability of Qualified Electronic Signatures.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.14349v1"
    },
    {
        "title": "Artificial Intelligence-based Smart Port Logistics Metaverse for\n  Enhancing Productivity, Environment, and Safety in Port Logistics: A Case\n  Study of Busan Port",
        "authors": [
            "Sunghyun Sim",
            "Dohee Kim",
            "Kikun Park",
            "Hyerim Bae"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The increase in global trade, the impact of COVID-19, and the tightening of\nenvironmental and safety regulations have brought significant changes to the\nmaritime transportation market. To address these challenges, the port logistics\nsector is rapidly adopting advanced technologies such as big data, Internet of\nThings, and AI. However, despite these efforts, solving several issues related\nto productivity, environment, and safety in the port logistics sector requires\ncollaboration among various stakeholders. In this study, we introduce an\nAI-based port logistics metaverse framework (PLMF) that facilitates\ncommunication, data sharing, and decision-making among diverse stakeholders in\nport logistics. The developed PLMF includes 11 AI-based metaverse content\nmodules related to productivity, environment, and safety, enabling the\nmonitoring, simulation, and decision making of real port logistics processes.\nExamples of these modules include the prediction of expected time of arrival,\ndynamic port operation planning, monitoring and prediction of ship fuel\nconsumption and port equipment emissions, and detection and monitoring of\nhazardous ship routes and accidents between workers and port equipment. We\nconducted a case study using historical data from Busan Port to analyze the\neffectiveness of the PLMF. By predicting the expected arrival time of ships\nwithin the PLMF and optimizing port operations accordingly, we observed that\nthe framework could generate additional direct revenue of approximately 7.3\nmillion dollars annually, along with a 79% improvement in ship punctuality,\nresulting in certain environmental benefits for the port. These findings\nindicate that PLMF not only provides a platform for various stakeholders in\nport logistics to participate and collaborate but also significantly enhances\nthe accuracy and sustainability of decision-making in port logistics through\nAI-based simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2409.10519v1"
    },
    {
        "title": "Constrain Path Optimization on Time-Dependent Road Networks",
        "authors": [
            "Kousik Kumar Dutta",
            "Venkata M. V. Gunturi"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Time-Dependent Constrained Path Optimization (TD-CPO) takes the following\ninput: (i) time-dependent (TD) road network, (ii) source ($s$), (iii)\ndestination ($d$), (iv) departure time ($t$) and, (v) budget ($\\mathcal{B}$).\nIn TD graph, each edge is characterized by a time-dependent arrival time and a\nscore function. TD-CPO aims to determine a loopless path $s$--$d$ departing\nfrom $s$ at time $t$ and arriving at $d$ on or before $t+\\mathcal{B}$ while\nmaximizing the score. TD-CPO has applications in urban navigation. TD-CPO is a\nvariant of the Arc Orienteering Problem (AOP) known to be NP-hard in nature.\nThe key computational challenge of TD-CPO is that we need to find the \"longest\npath\" in terms of score within the given budget constraint in a TD graph.\nCurrent works prune down the search space very aggressively. Thus, despite\nhaving low execution time, these algorithms often produce low-quality\nsolutions. In contrast, our proposed approach $\\mathcal{SCOPE}$ efficiently\nsolves TD-CPO by exploiting road networks' spatial and temporal properties. The\ninherent computational structure of $\\mathcal{SCOPE}$ enables trivial\nparallelization for improved performance. Our experiments indicate that\n$\\mathcal{SCOPE}$ produces superior quality solutions (nearly $2x$) compared to\nthe state-of-the-art algorithm while having comparable running times.\nFurthermore, $\\mathcal{SCOPE}$ exhibits almost linear speedup as the number of\nCPUs (cores) increases (up to 24 CPUs).\n",
        "pdf_link": "http://arxiv.org/pdf/2409.17192v1"
    },
    {
        "title": "Mov-Avg: Codeless time series analysis using moving averages",
        "authors": [
            "Pawe Weichbroth",
            "Jakub Buczkowski"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  This paper introduces Mov-Avg, the Python software package for time series\nanalysis that requires little computer programming experience from the user.\nThe package allows the identification of trends, patterns, and the prediction\nof future events based on data collected over time. In this regard, the Mov-Avg\nimplementation provides three indicators to apply, namely: Simple Moving\nAverage, Weighted Moving Average and Exponential Moving Average. Due to its\ngeneric design, the Mov-Avg software package can be used in any field where the\napplication of moving averages is valid. In general, the Mov-Avg library for\ntime series analysis contributes to a better understanding of data-driven\nprocesses over time by taking advantage of moving averages in any way adapted\nto the research context.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.04149v1"
    },
    {
        "title": "Matheuristic Local Search for the Placement of Analog Integrated\n  Circuits",
        "authors": [
            "Josef Grus",
            "Zdenk Hanzlek"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The suboptimal physical design of the integrated circuits may not only\nincrease the manufacturing costs due to the larger size of the chip but can\nalso impact its performance by placing interconnected rectangular devices too\nfar from each other. In the domain of Analog and Mixed-Signal Integrated\nCircuits (AMS ICs), placement automation is lacking behind its digital\ncounterpart, mainly due to the variety of components and complex constraints\nthe placement needs to satisfy. Integer Linear Programming (ILP) is a suitable\napproach to modeling the placement problem for AMS ICs. However, not even\nstate-of-the-art solvers can create high-quality placements for large problem\ninstances. In this paper, we study how to improve the results of our previous\nILP model, first by introducing additional constraints and second by using\nmatheuristics. Given the initial solution we obtain using our original ILP\nmodel, we use the solver to perform a local search. We try to improve the\ncriterion by considering only a few spatially close rectangles while keeping\nthe rest of the placement fixed. This local search approach enables us to\nsignificantly improve the quality of instances whose solution space we could\nnot sufficiently explore before, even when the computation time reserved for\nthe matheuristic is limited. Finally, we evaluate our revised approach on\nsynthetically generated instances containing more than 200 independent\nrectangles and on real-life problems.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.16323v1"
    },
    {
        "title": "Even the \"Devil\" has Rights!",
        "authors": [
            "Mennatullah Siam"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  There have been works discussing the adoption of a human rights framework for\nresponsible AI, emphasizing various rights such as the right to contribute to\nscientific advancements. Yet, to the best of our knowledge, this is the first\nattempt to take this framework with special focus on computer vision and\ndocumenting human rights violations in its community. This work summarizes such\nincidents accompanied with evidence from the lens of a female African Muslim\nHijabi researcher. While previous works resorted to qualitative surveys that\ngather opinions from various researchers in the field, this work argues that a\nsingle documented violation is sufficient to warrant attention regardless of\nthe stature of this researcher. Incidents documented in this work include\nsilence on Genocides that are occurring while promoting the governments\ncontributing to it, a broken reviewing system and corruption in the faculty\nsupport systems. This work discusses that demonizing individuals for\ndiscrimination based on gender, ethnicity, creed or reprisal has been a\nsuccessful tool for exclusion with documented evidence from a single case. We\nargue that human rights are guaranteed for every single individual even the\nones that might be labelled as devils in the community for whichever reasons to\ndismantle such a tool from its roots.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.22963v2"
    },
    {
        "title": "Distribution Hub Optimization: Application of Conditional P-Median Using\n  Road Network Distances",
        "authors": [
            "Faizan Faisal",
            "Zubair Khalid"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  This paper explores a GIS-based application of the conditional p-median\nproblem (where p = 1) in last-mile delivery logistics. The rapid growth of\ne-commerce in Pakistan has primarily benefited logistics companies, which face\nthe challenge of resolving inefficiencies in the existing infrastructure and\nscaling effectively to meet increasing demand. Addressing these challenges\nwould not only reduce operational costs but also lower carbon footprints. We\npresent an algorithm that utilizes road-network-based distances to determine\nthe optimal location for a new hub facility, a problem known in operations\nresearch as the conditional p-median problem. The algorithm optimizes the\nplacement of a new facility, given q existing facilities. The past delivery\ndata for this research was provided by Muller and Phipps Logistics Pakistan.\nOur method involves constructing a distance matrix between candidate hub\nlocations and past delivery points, followed by a grid search to identify the\noptimal hub location. To simulate the absence of past delivery data, we\nrepeated the process using the population distribution of Lahore. Our results\ndemonstrate a 16% reduction in average delivery distance with the addition of a\nnew hub.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.05851v1"
    },
    {
        "title": "IUMENTA: A generic framework for animal digital twins within the Open\n  Digital Twin Platform",
        "authors": [
            "Ali Youssef",
            "Kristina Vodorezova",
            "Yannick Aarts",
            "Wisdom E. K. Agbeti",
            "Arjan P. Palstra",
            "Edwin Foekema",
            "Leonel Aguilar",
            "Ricardo da Silva Torres",
            "Jascha Grbel"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  IUMENTA (Latin for livestock) is an innovative software framework designed to\nconstruct and simulate digital twins of animals. By leveraging the powerful\ncapability of the Open Digital Twin Platform (ODTP) alongside advanced software\nsensors, IUMENTA offers researchers a user-friendly tool to seamlessly develop\nadaptive digital replicas of animal-based processes. This framework establishes\na dynamic ecosystem that integrates insights from diverse experiments,\nconsequently enhancing our understanding of animal behavioural and\nphysiological responses. Through real-time tracking of an animal's energy\nbalance. IUMENTA provides valuable insights into metabolic rates, nutritional\nneeds, emotional states, and overall well-being of animals. In this article, we\nexplore the application of the IUMENTA framework in developing a digital twin\nfocused on the animal's energy balance. IUMENTA includes the EnergyTag system,\na state-of-the-art wearable software sensor, which facilitates real-time\nmonitoring of energy expenditure, allowing for continuous updates and\npersonalisation of the energy balance digital twin.\n",
        "pdf_link": "http://arxiv.org/pdf/2411.10466v1"
    },
    {
        "title": "Mr.TPL: A Method for Multi-Pin Net Router in Triple Patterning\n  Lithography",
        "authors": [
            "Chengkai Wang",
            "Weiqing Ji",
            "Mingyang Kou",
            "Zhiyang Chen",
            "Fei Li",
            "Hailong Yao"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Triple patterning lithography (TPL) has been recognized as one of the most\npromising solutions to print critical features in advanced technology nodes. A\ncritical challenge within TPL is the effective assignment of the layout to\nmasks. Recently, various layout decomposition methods and TPL-aware routing\nmethods have been proposed to consider TPL. However, these methods typically\nresult in numerous conflicts and stitches, and are mainly designed for 2-pin\nnets. This paper proposes a multi-pin net routing method in triple patterning\nlithography, called Mr.TPL. Experimental results demonstrate that Mr.TPL\nreduces color conflicts by 81.17%, decreases stitches by 76.89%, and achieves\nup to 5.4X speed improvement compared to the state-of-the-art TPL-aware routing\nmethod.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.02703v1"
    },
    {
        "title": "Optimal Traffic Flow in Quantum Annealing-Supported Virtual Traffic\n  Lights",
        "authors": [
            "Abyad Enan",
            "M Sabbir Salek",
            "Mashrur Chowdhury",
            "Gurcan Comert",
            "Sakib M. Khan",
            "Reek Majumder"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The Virtual Traffic Light (VTL) eliminates the need for physical traffic\nsignal infrastructure at intersections, leveraging Connected Vehicles (CVs) to\noptimize traffic flow. VTL assigns right-of-way dynamically based on factors\nsuch as estimated times of arrival (ETAs), the number of CVs in various lanes,\nand emission rates. These factors are considered in line with the objectives of\nthe VTL application. Aiming to optimize traffic flow and reduce delays, the VTL\nsystem generates Signal Phase and Timing (SPaT) data for CVs approaching an\nintersection, while considering the impact of each CV movement on others.\nHowever, the stochastic nature of vehicle arrivals at intersections complicates\nreal-time optimization, challenging classical computing methods. To address\nthis limitation, we develop a VTL method that leverages quantum computing to\nminimize stopped delays for CVs. The method formulates the VTL problem as a\nQuadratic Unconstrained Binary Optimization (QUBO) problem, a mathematical\nframework well-suited for quantum computing. Using D-Wave cloud-based quantum\ncomputer, our approach determines optimal solutions for right-of-way\nassignments under the standard National Electrical Manufacturers Association\n(NEMA) phasing system. The system was evaluated using the microscopic traffic\nsimulator SUMO under varying traffic volumes. Our results demonstrate that the\nquantum-enabled VTL system reduces stopped delays and travel times compared to\nclassical optimization-based systems. This approach not only enhances traffic\nmanagement efficiency but also reduces the infrastructure costs associated with\ntraditional traffic signals. The quantum computing-supported VTL system offers\na transformative solution for large-scale traffic control, providing superior\nperformance across diverse traffic scenarios and paving the way for advanced,\ncost-effective traffic management.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.18776v1"
    },
    {
        "title": "Von Neumann Quantum Logic vs. Classical von Neumann Architecture?",
        "authors": [
            "Alexander Yu. Vlasov"
        ],
        "category": "cs.OH",
        "published_year": "2000",
        "summary": "  The name of John von Neumann is common both in quantum mechanics and computer\nscience. Are they really two absolutely unconnected areas? Many works devoted\nto quantum computations and communications are serious argument to suggest\nabout existence of such a relation, but it is impossible to touch the new and\nactive theme in a short review. In the paper are described the structures and\nmodels of linear algebra and just due to their generality it is possible to use\nuniversal description of very different areas as quantum mechanics and theory\nof Bayesian image analysis, associative memory, neural networks, fuzzy logic.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0001001v1"
    },
    {
        "title": "Automated Real-Time Testing (ARTT) for Embedded Control Systems (ECS)",
        "authors": [
            "Jon Hawkins",
            "Haung V. Nguyen",
            "Reginald B. Howard"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  Developing real-time automated test systems for embedded control systems has\nbeen a real problem. Some engineers and scientists have used customized\nsoftware and hardware as a solution, which can be very expensive and time\nconsuming to develop. We have discovered how to integrate a suite of\ncommercially available off-the-shelf software tools and hardware to develop a\nscalable test platform that is capable of performing complete black-box testing\nfor a dual-channel real-time Embedded-PLC-based control system\n(www.aps.anl.gov). We will discuss how the Vali/Test Pro testing methodology\nwas implemented to structure testing for a personnel safety system with large\nquantities of requirements and test cases.\n  This work was supported by the U.S. Department of Energy, Basic Energy\nSciences, under Contract No. W-31-109-Eng-38.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0111005v3"
    },
    {
        "title": "Symmetric and anti-symmetric quantum functions",
        "authors": [
            "J. R. Burger"
        ],
        "category": "cs.OH",
        "published_year": "2003",
        "summary": "  This paper introduces and analyzes symmetric and anti-symmetric quantum\nbinary functions. Generally, such functions uniquely convert a given\ncomputational basis state into a different basis state, but with either a plus\nor a minus sign. Such functions may serve along with a constant function (in a\nDeutsch-Jozsa type of algorithm) to provide 2**n deterministic qubit\ncombinations (for n qubits) instead of just one.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0304016v2"
    },
    {
        "title": "Supporting Dynamic Ad hoc Collaboration Capabilities",
        "authors": [
            "D. Agarwal",
            "K. Berket"
        ],
        "category": "cs.OH",
        "published_year": "2003",
        "summary": "  Modern HENP experiments such as CMS and Atlas involve as many as 2000\ncollaborators around the world. Collaborations this large will be unable to\nmeet often enough to support working closely together. Many of the tools\ncurrently available for collaboration focus on heavy-weight applications such\nas videoconferencing tools. While these are important, there is a more basic\nneed for tools that support connecting physicists to work together on an ad hoc\nor continuous basis. Tools that support the day-to-day connectivity and\nunderlying needs of a group of collaborators are important for providing\nlight-weight, non-intrusive, and flexible ways to work collaboratively. Some\nexample tools include messaging, file-sharing, and shared plot viewers. An\nimportant component of the environment is a scalable underlying communication\nframework. In this paper we will describe our current progress on building a\ndynamic and ad hoc collaboration environment and our vision for its evolution\ninto a HENP collaboration environment.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0307037v1"
    },
    {
        "title": "Using biased coins as oracles",
        "authors": [
            "Toby Ord",
            "Tien D. Kieu"
        ],
        "category": "cs.OH",
        "published_year": "2004",
        "summary": "  While it is well known that a Turing machine equipped with the ability to\nflip a fair coin cannot compute more that a standard Turing machine, we show\nthat this is not true for a biased coin. Indeed, any oracle set $X$ may be\ncoded as a probability $p_{X}$ such that if a Turing machine is given a coin\nwhich lands heads with probability $p_{X}$ it can compute any function\nrecursive in $X$ with arbitrarily high probability. We also show how the\nassumption of a non-recursive bias can be weakened by using a sequence of\nincreasingly accurate recursive biases or by choosing the bias at random from a\ndistribution with a non-recursive mean. We conclude by briefly mentioning some\nimplications regarding the physical realisability of such methods.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0401019v1"
    },
    {
        "title": "Hard Disk Drive as a Magnetomechanical Logic Device",
        "authors": [
            "Vladimir L. Safonov"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  We consider the conditions how two binary numbers can be superimposed on the\nsame track with the use of different recording magnetic fields. As a result the\naverage magnetization of longitudinal medium along the track can have three\nstates: -M, 0 and +M. Possibility to perform logic operations with these states\nis considered. We demonstrate OR, AND, XOR and NOT operations and discuss a\nmodification of a recording device.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0611134v1"
    },
    {
        "title": "Probability Bracket Notation, Markov Chains, Stochastic Processes, and\n  Microscopic Probabilistic Processes",
        "authors": [
            "Xing M. Wang"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Inspired by the Dirac vector probability notation (VPN), we propose the\nProbability Bracket Notation (PBN), a new set of symbols defined similarly (but\nnot identically) as in the VPN. Applying the PBN to fundamental definitions and\ntheorems for discrete and continuous random variables, we show that the PBN\ncould play a similar role in the probability space as the VBN in the Hilbert\nvector. Our system P-kets are identified with the probability vectors in Markov\nchains (MC). The master equation of homogeneous MC in the Schrodinger pictures\ncan be basis-independent. Our system P-bra is linked to the Doi state function\nand the Peliti standard bra. Transformed from the Schrodinger picture to the\nHeisenberg picture, the time dependence of the system P-ket of a homogeneous MC\n(HMC) is shifted to the observable as a stochastic process. Using the\ncorrelations established by the special Wick rotation (SWR), the microscopic\nprobabilistic processes (MPPs) are investigated for single and many-particle\nsystems. The expected occupation number of particles in quantum statistics is\nreproduced by associating time with temperature (the Wick-Matsubara relation).\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0702021v8"
    },
    {
        "title": "Induced Hilbert Space, Markov Chain, Diffusion Map and Fock Space in\n  Thermophysics",
        "authors": [
            "Xing M. Wang"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  In this article, we continue to explore Probability Bracket Notation (PBN),\nproposed in our previous article. Using both Dirac vector bracket notation\n(VBN) and PBN, we define induced Hilbert space and induced sample space, and\npropose that there exists an equivalence relation between a Hilbert space and a\nsample space constructed from the same base observable(s). Then we investigate\nMarkov transition matrices and their eigenvectors to make diffusion maps with\ntwo examples: a simple graph theory example, to serve as a prototype of\nbidirectional transition operator; a famous text document example in IR\nliterature, to serve as a tutorial of diffusion map in text document space. We\nshow that the sample space of the Markov chain and the Hilbert space spanned by\nthe eigenvectors of the transition matrix are not equivalent. At the end, we\napply our PBN and equivalence proposal to Thermophysics by associating sample\n(phase) space with the Hilbert space of a single particle and the Fock space of\nmany-particle systems.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0702121v5"
    },
    {
        "title": "Hilbert++ Manual",
        "authors": [
            "Alessandro Mirone"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  We present here an installation guide, a hand-on mini-tutorial through\nexamples, and the theoretical foundations of the Hilbert++ code.\n",
        "pdf_link": "http://arxiv.org/pdf/0706.4170v2"
    },
    {
        "title": "Towards 3D ultrasound image based soft tissue tracking: a transrectal\n  ultrasound prostate image alignment system",
        "authors": [
            "Michael Baumann",
            "Pierre Mozer",
            "Vincent Daanen",
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The emergence of real-time 3D ultrasound (US) makes it possible to consider\nimage-based tracking of subcutaneous soft tissue targets for computer guided\ndiagnosis and therapy. We propose a 3D transrectal US based tracking system for\nprecise prostate biopsy sample localisation. The aim is to improve sample\ndistribution, to enable targeting of unsampled regions for repeated biopsies,\nand to make post-interventional quality controls possible. Since the patient is\nnot immobilized, since the prostate is mobile and due to the fact that probe\nmovements are only constrained by the rectum during biopsy acquisition, the\ntracking system must be able to estimate rigid transformations that are beyond\nthe capture range of common image similarity measures. We propose a fast and\nrobust multi-resolution attribute-vector registration approach that combines\nglobal and local optimization methods to solve this problem. Global\noptimization is performed on a probe movement model that reduces the\ndimensionality of the search space and thus renders optimization efficient. The\nmethod was tested on 237 prostate volumes acquired from 14 different patients\nfor 3D to 3D and 3D to orthogonal 2D slices registration. The 3D-3D version of\nthe algorithm converged correctly in 96.7% of all cases in 6.5s with an\naccuracy of 1.41mm (r.m.s.) and 3.84mm (max). The 3D to slices method yielded a\nsuccess rate of 88.9% in 2.3s with an accuracy of 1.37mm (r.m.s.) and 4.3mm\n(max).\n",
        "pdf_link": "http://arxiv.org/pdf/0712.0769v1"
    },
    {
        "title": "Medical image computing and computer-aided medical interventions applied\n  to soft tissues. Work in progress in urology",
        "authors": [
            "Jocelyne Troccaz",
            "Michael Baumann",
            "Peter Berkelman",
            "Philippe Cinquin",
            "Vincent Daanen",
            "Antoine Leroy",
            "Maud Marchal",
            "Yohan Payan",
            "Emmanuel Promayon",
            "Sandrine Voros",
            "Stphane Bart",
            "Michel Bolla",
            "Emmanuel Chartier-Kastler",
            "Jean-Luc Descotes",
            "Andre Dusserre",
            "Jean-Yves Giraud",
            "Jean-Alexandre Long",
            "Ronan Moalic",
            "Pierre Mozer"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  Until recently, Computer-Aided Medical Interventions (CAMI) and Medical\nRobotics have focused on rigid and non deformable anatomical structures.\nNowadays, special attention is paid to soft tissues, raising complex issues due\nto their mobility and deformation. Mini-invasive digestive surgery was probably\none of the first fields where soft tissues were handled through the development\nof simulators, tracking of anatomical structures and specific assistance\nrobots. However, other clinical domains, for instance urology, are concerned.\nIndeed, laparoscopic surgery, new tumour destruction techniques (e.g. HIFU,\nradiofrequency, or cryoablation), increasingly early detection of cancer, and\nuse of interventional and diagnostic imaging modalities, recently opened new\nchallenges to the urologist and scientists involved in CAMI. This resulted in\nthe last five years in a very significant increase of research and developments\nof computer-aided urology systems. In this paper, we propose a description of\nthe main problems related to computer-aided diagnostic and therapy of soft\ntissues and give a survey of the different types of assistance offered to the\nurologist: robotization, image fusion, surgical navigation. Both research\nprojects and operational industrial systems are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.2100v1"
    },
    {
        "title": "Computer- and robot-assisted urological surgery",
        "authors": [
            "Jocelyne Troccaz"
        ],
        "category": "cs.OH",
        "published_year": "2007",
        "summary": "  The author reviews the computer and robotic tools available to urologists to\nhelp in diagnosis and technical procedures. The first part concerns the\ncontribution of robotics and presents several systems at various stages of\ndevelopment (laboratory prototypes, systems under validation or marketed\nsystems). The second part describes image fusion tools and navigation systems\ncurrently under development or evaluation. Several studies on computerized\nsimulation of urological procedures are also presented.\n",
        "pdf_link": "http://arxiv.org/pdf/0712.3299v1"
    },
    {
        "title": "Measures for classification and detection in steganalysis",
        "authors": [
            "Sujit Gujar",
            "C E Veni Madhavan"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  Still and multi-media images are subject to transformations for compression,\nsteganographic embedding and digital watermarking. In a major program of\nactivities we are engaged in the modeling, design and analysis of digital\ncontent. Statistical and pattern classification techniques should be combined\nwith understanding of run length, transform coding techniques, and also\nencryption techniques.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.0529v1"
    },
    {
        "title": "Finite-size effects in the dependency networks of free and open-source\n  software",
        "authors": [
            "Rajiv Nair",
            "G. Nagarjuna",
            "Arnab K. Ray"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  We propose a continuum model for the degree distribution of directed networks\nin free and open-source software. The degree distributions of links in both the\nin-directed and out-directed dependency networks follow Zipf's law for the\nintermediate nodes, but the heavily linked nodes and the poorly linked nodes\ndeviate from this trend and exhibit finite-size effects. The finite-size\nparameters make a quantitative distinction between the in-directed and\nout-directed networks. For the out-degree distribution, the initial condition\nfor a dynamic evolution corresponds to the limiting count of the most heavily\nliked nodes that the out-directed network can finally have. The number of nodes\ncontributing out-directed links grows with every generation of software\nrelease, but this growth ultimately saturates towards a terminal value due to\nthe finiteness of semantic possibilities in the network.\n",
        "pdf_link": "http://arxiv.org/pdf/0901.4904v4"
    },
    {
        "title": "Towards a General Definition of Biometric Systems",
        "authors": [
            "Markus Schatten",
            "Miroslav Baca",
            "Mirko Cubrilo"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  A foundation for closing the gap between biometrics in the narrower and the\nbroader perspective is presented trough a conceptualization of biometric\nsystems in both perspectives. A clear distinction between verification,\nidentification and classification systems is made as well as shown that there\nare additional classes of biometric systems. In the end a Unified Modeling\nLanguage model is developed showing the connections between the two\nperspectives.\n",
        "pdf_link": "http://arxiv.org/pdf/0909.2365v1"
    },
    {
        "title": "Discussion on Supervisory Control by Solving Automata Equation",
        "authors": [
            "Victor Bushkov",
            "Nina Yevtushenko",
            "Tiziano Villa"
        ],
        "category": "cs.OH",
        "published_year": "2009",
        "summary": "  In this paper we consider the supervisory control problem through language\nequation solving. The equation solving approach allows to deal with more\ngeneral topologies and to find a largest supervisor which can be used as a\nreservoir for deriving an optimal controller. We introduce the notions of\nsolutions under partial controllability and partial observability, and we show\nhow supervisory control problems with partial controllability and partial\nobservability can be solved by employing equation solving methods.\n",
        "pdf_link": "http://arxiv.org/pdf/0912.0970v1"
    },
    {
        "title": "Measurement of Nuchal Translucency Thickness for Detection of\n  Chromosomal Abnormalities using First Trimester Ultrasound Fetal Images",
        "authors": [
            "S. Nirmala",
            "V. Palanisamy"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The Nuchal Translucency thickness measurement is made to identify the Down\nSyndrome in screening first trimester fetus and presented in this paper. The\nmean shift analysis and canny operators are utilized for segmenting the nuchal\ntranslucency region and the exact thickness has been estimated using Blob\nanalysis. It is observed from the results that the fetus in the 14th week of\nGestation is expected to have a nuchal translucency thickness of 1.87 plus or\nminus 0.25mm.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.1986v1"
    },
    {
        "title": "Hybrid Workflow Policy Management for Heart Disease Identification",
        "authors": [
            "Dong-Hyun Kim",
            "Woo-Ram Jung",
            "Chan-Hyun Youn"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  As science technology grows, medical application is becoming more complex to\nsolve the physiological problems within expected time. Workflow management\nsystems (WMS) in Grid computing are promising solution to solve the\nsophisticated problem such as genomic analysis, drug discovery, disease\nidentification, etc. Although existing WMS can provide basic management\nfunctionality in Grid environment, consideration of user requirements such as\nperformance, reliability and interaction with user is missing. In this paper,\nwe propose hybrid workflow management system for heart disease identification\nand discuss how to guarantee different user requirements according to user SLA.\nThe proposed system is applied to Physio-Grid e-health platform to identify\nhuman heart disease with ECG analysis and Virtual Heart Simulation (VHS)\nworkflow applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1001.4199v1"
    },
    {
        "title": "New Insights from an Analysis of Social Influence Networks under the\n  Linear Threshold Model",
        "authors": [
            "Srinivasan Venkatramanan",
            "Anurag Kumar"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  We study the spread of influence in a social network based on the Linear\nThreshold model. We derive an analytical expression for evaluating the expected\nsize of the eventual influenced set for a given initial set, using the\nprobability of activation for each node in the social network. We then provide\nan equivalent interpretation for the influence spread, in terms of acyclic path\nprobabilities in the Markov chain obtained by reversing the edges in the social\nnetwork influence graph. We use some properties of such acyclic path\nprobabilities to provide an alternate proof for the submodularity of the\ninfluence function. We illustrate the usefulness of the analytical expression\nin estimating the most influential set, in special cases such as the\nUILT(Uniform Influence Linear Threshold), USLT(Uniform Susceptance Linear\nThreshold) and node-degree based influence models. We show that the PageRank\nheuristic is either provably optimal or performs very well in the above models,\nand explore its limitations in more general cases. Finally, based on the\ninsights obtained from the analytical expressions, we provide an efficient\nalgorithm which approximates the greedy algorithm for the influence\nmaximization problem.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.1335v1"
    },
    {
        "title": "SVM Model for Identification of human GPCRs",
        "authors": [
            "Sonal Shrivastava",
            "K. R. Pardasani",
            "M. M. Malik"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  G-protein coupled receptors (GPCRs) constitute a broad class of cell-surface\nreceptors in eukaryotes and they possess seven transmembrane a-helical domains.\nGPCRs are usually classified into several functionally distinct families that\nplay a key role in cellular signalling and regulation of basic physiological\nprocesses. We can develop statistical models based on these common features\nthat can be used to classify proteins, to predict new members, and to study the\nsequence-function relationship of this protein function group. In this study,\nSVM based classification model has been developed for the identification of\nhuman gpcr sequences. Sequences of Level 1 subfamilies of Class A rhodopsin is\nconsidered as case study. In the present study, an attempt has been made to\nclassify GPCRs on the basis of species. The present study classifies human gpcr\nsequences with rest of the species available in GPCRDB. Classification is based\non specific information derived from the n-terminal and extracellular loops of\nthe sequences, some physicochemical properties and amino acid composition of\ncorresponding gpcr sequences. Our method classifies Level 1 subfamilies of\nGPCRs with 94% accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1002.3983v1"
    },
    {
        "title": "A New Variable Threshold and Dynamic Step Size Based Active Noise\n  Control System for Improving Performance",
        "authors": [
            "P. Babu",
            "A. Krishnan"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Several approaches have been introduced in literature for active noise\ncontrol (ANC) systems. Since FxLMS algorithm appears to be the best choice as a\ncontroller filter, researchers tend to improve performance of ANC systems by\nenhancing and modifying this algorithm. In this paper, modification is done in\nthe existing FxLMS algorithm that provides a new structure for improving the\ntracking performance and convergence rate. The secondary signal y(n) is dynamic\nthresholded by Wavelet transform to improve tracking. The convergence rate is\nimproved by dynamically varying the step size of the error signal.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.1509v1"
    },
    {
        "title": "Plagiarism Detection using ROUGE and WordNet",
        "authors": [
            "Chien-Ying Chen",
            "Jen-Yuan Yeh",
            "Hao-Ren Ke"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  With the arrival of digital era and Internet, the lack of information control\nprovides an incentive for people to freely use any content available to them.\nPlagiarism occurs when users fail to credit the original owner for the content\nreferred to, and such behavior leads to violation of intellectual property. Two\nmain approaches to plagiarism detection are fingerprinting and term occurrence;\nhowever, one common weakness shared by both approaches, especially\nfingerprinting, is the incapability to detect modified text plagiarism. This\nstudy proposes adoption of ROUGE and WordNet to plagiarism detection. The\nformer includes ngram co-occurrence statistics, skip-bigram, and longest common\nsubsequence (LCS), while the latter acts as a thesaurus and provides semantic\ninformation. N-gram co-occurrence statistics can detect verbatim copy and\ncertain sentence modification, skip-bigram and LCS are immune from text\nmodification such as simple addition or deletion of words, and WordNet may\nhandle the problem of word substitution.\n",
        "pdf_link": "http://arxiv.org/pdf/1003.4065v1"
    },
    {
        "title": "Instantaneous noise-based logic",
        "authors": [
            "Laszlo B. Kish",
            "Sunil Khatri",
            "Ferdinand Peper"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  We show two universal, Boolean, deterministic logic schemes based on binary\nnoise timefunctions that can be realized without time-averaging units. The\nfirst scheme is based on a new bipolar random telegraph wave scheme and the\nsecond one makes use of the recent noise-based logic which is conjectured to be\nthe brain's method of logic operations [Physics Letters A 373 (2009)\n2338-2342]. Error propagation and error removal issues are also addressed.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.2652v2"
    },
    {
        "title": "Linked Environment Data for the Life Sciences",
        "authors": [
            "Maria Rther",
            "Thomas Bandholtz",
            "Antoine Logean"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Environment Agencies from Europe and the US are setting up a network of\nLinked Environment Data and are looking to crosslink it with Linked Data\ncontributions from the life sciences.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.1620v1"
    },
    {
        "title": "Online traffic state estimation based on floating car data",
        "authors": [
            "Arne Kesting",
            "Martin Treiber"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Besides the traditional data collection by stationary detectors, recent\nadvances in wireless and sensor technologies have promoted new potentials for a\nvehicle-based data collection and local dissemination of information. By means\nof microscopic traffic simulations we study the problem of online estimation of\nthe current traffic situation based on floating car data. Our focus is on the\nestimation on the up- and downstream jam fronts determining the extension of\ntraffic congestion. We study the impact of delayed information transmission by\nshort-range communication via wireless LAN in contrast to instantaneous\ninformation transmission to the roadside units by means of mobile radio. The\ndelayed information transmission leads to systematic estimation errors which\ncannot be compensated for by a higher percentage of probe vehicles. Additional\nflow measurements from stationary detectors allow for a model-based prediction\nwhich is effective for much lower floating car percentages than 1%.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.4567v1"
    },
    {
        "title": "The dependence on the initial states and the transitivity of the regular\n  autonomous asynchronous systems",
        "authors": [
            "Serban E. Vlad"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The asynchronous systems are non-deterministic real time, binary valued\nmodels of the asynchronous circuits from electronics. Autonomy means that there\nis no input and regularity means analogies with the (real) dynamical systems.\nWe introduce the concepts of dependence on the initial states and of\ntransitivity for these systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1012.5841v1"
    },
    {
        "title": "Support of Interactive 3D/4D Presentations by the Very First Ever Made\n  Virtual Laboratories of Antennas",
        "authors": [
            "Nikolitsa Yannopoulou",
            "Petros Zimourtopoulos"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Based on the experience we have gained so far, as independent reviewers of\nRadioengineering journal, we thought that may be proved useful to publicly\nshare with the interested author, especially the young one, some practical\nimplementations of our ideas for the interactive representation of data using\n3D/4D movement and animation, in an attempt to motivate and support her/him in\nthe development of similar dynamic presentations, when s/he is looking for a\nway to locate the stronger aspects of her/his research results in order to\nprepare a clear, most appropriate for publication, static presentation figure.\nFor this purpose, we selected to demonstrate a number of presentations, from\nthe simplest to the most complicated, concerning well-known antenna issues with\nrather hard to imagine details, as it happens perhaps in cases involving\nSpherical Coordinates and Polarization, which we created to enrich the very\nfirst ever made Virtual Laboratories of Antennas, that we distribute over the\nOpen Internet through our website Virtual Antennas. These presentations were\ndeveloped in a general way, without using antenna simulators, to handle output\ntext and image data from third-party CAS Computer Algebra Systems, such as the\nMathematica commercial software we use or the Maxima FLOSS we track its\nevolution.\n",
        "pdf_link": "http://arxiv.org/pdf/1102.4241v3"
    },
    {
        "title": "Simplicity Effects in the Experience of Near-Miss",
        "authors": [
            "Jean-Louis Dessalles"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Near-miss experiences are one of the main sources of intense emotions.\nDespite people's consistency when judging near-miss situations and when\ncommunicating about them, there is no integrated theoretical account of the\nphenomenon. In particular, individuals' reaction to near-miss situations is not\ncorrectly predicted by rationality-based or probability-based optimization. The\npresent study suggests that emotional intensity in the case of near-miss is in\npart predicted by Simplicity Theory.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.4843v1"
    },
    {
        "title": "Emotion in good luck and bad luck: predictions from simplicity theory",
        "authors": [
            "Jean-Louis Dessalles"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  The feeling of good or bad luck occurs whenever there is an emotion contrast\nbetween an event and an easily accessible counterfactual alternative. This\nstudy suggests that cognitive simplicity plays a key role in the human ability\nto experience good and bad luck after the occurrence of an event.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.4882v1"
    },
    {
        "title": "A structural model of intuitive probability",
        "authors": [
            "Jean-Louis Dessalles"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Though the ability of human beings to deal with probabilities has been put\ninto question, the assessment of rarity is a crucial competence underlying much\nof human decision-making and is pervasive in spontaneous narrative behaviour.\nThis paper proposes a new model of rarity and randomness assessment, designed\nto be cognitively plausible. Intuitive randomness is defined as a function of\nstructural complexity. It is thus possible to assign probability to events\nwithout being obliged to consider the set of alternatives. The model is tested\non Lottery sequences and compared with subjects' preferences.\n",
        "pdf_link": "http://arxiv.org/pdf/1108.4884v1"
    },
    {
        "title": "New noise-based logic representations to avoid some problems with time\n  complexity",
        "authors": [
            "H. Wen",
            "L. B. Kish",
            "A. Klappenecker",
            "F. Peper"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  Instantaneous noise-based logic can avoid time-averaging, which implies\nsignificant potential for low-power parallel operations in\nbeyond-Moore-law-chips. However, the universe (uniform superposition) will be\nzero with high probability (non-zero with exponentially low probability) in the\nrandom-telegraph-wave representation thus the operations with the universe\nwould require exponential time-complexity. To fix this deficiency, we modify\nthe amplitudes of the signals of the L and H states and achieve an exponential\nspeedup compared to the old situation. Another improvement concerns the\nidentification of a single product (hyperspace) state. We introduce a time\nshifted noise-based logic, which is constructed by shifting each reference\nsignal with a small time delay. This modification implies an exponential\nspeedup of single hyperspace vector identification compared to the former case\nand it requires the same, O(N) complexity as in quantum computing.\n",
        "pdf_link": "http://arxiv.org/pdf/1111.3859v3"
    },
    {
        "title": "Performance Evaluation of Biometric Template Update",
        "authors": [
            "Romain Giot",
            "Christophe Rosenberger",
            "Bernadette Dorizzi"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Template update allows to modify the biometric reference of a user while he\nuses the biometric system. With such kind of mechanism we expect the biometric\nsystem uses always an up to date representation of the user, by capturing his\nintra-class (temporary or permanent) variability. Although several studies\nexist in the literature, there is no commonly adopted evaluation scheme. This\ndoes not ease the comparison of the different systems of the literature. In\nthis paper, we show that using different evaluation procedures can lead in\ndifferent, and contradictory, interpretations of the results. We use a\nkeystroke dynamics (which is a modality suffering of template ageing quickly)\ntemplate update system on a dataset consisting of height different sessions to\nillustrate this point. Even if we do not answer to this problematic, it shows\nthat it is necessary to normalize the template update evaluation procedures.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.1502v1"
    },
    {
        "title": "Designing the Mode solving of the photonic crystal fiber via BPM and\n  Exploring the Single-Mode Properties",
        "authors": [
            "Mohammed Debbal",
            "Mohamed Chikh-Bled"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Microstructured optical fibers (MOFs) are one of the most exciting recent\ndevelopments in fiber optics. A MOF usually consists of a hexagonal arrangement\nof air holes running down the length of a silica fiber surrounding a central\ncore of solid silica or, in some cases air. MOFs can exhibit a number of unique\nproperties, including zero dispersion at visible wavelengths and low or high\neffective nonlinearity [3]-[17], By varying the size of the holes and their\nnumber and position, one can also design MOFs with carefully controlled\ndispersive and modal properties. In this paper, we analyze and modeling the\nbehavior of the photonic crystal fiber (PCF) by using in the first step a\npropagator method based on the BPM method. With our BPM software, the electric\nfield contour of the fundamental mode of PCF was demonstrated. We also used it\nto see the variation of the effective index; an effective index model confirms\nthat such a fiber can be single mode for any wavelength. It would make a study\nof photonic crystal fibers, and a study of the numerical simulation methods\nallow the simulation of optical properties and has modeled the propagation of\nlight in this fiber type. After that we use the V-parameter because it offers a\nsimple way to design a photonic crystal fiber (PCF), by basing in a recent\nformulation of this parameter of a PCF, we provide numerically based empirical\nexpression for this quantity only dependent on the two structural parameters,\nthe air hole diameter and the hole-to-hole center spacing.\n",
        "pdf_link": "http://arxiv.org/pdf/1205.6515v1"
    },
    {
        "title": "A Novel Low Power UWB Cascode SiGe BiCMOS LNA with Current Reuse and\n  Zero-Pole Cancellation",
        "authors": [
            "Chunbao Ding",
            "Wanrong Zhang",
            "Dongyue Jin",
            "Hongyun Xie",
            "Pei Shen",
            "Liang Chen"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  A low power cascode SiGe BiCMOS low noise amplifier (LNA) with current reuse\nand zero-pole cancellation is presented for ultra-wideband (UWB) application.\nThe LNA is composed of cascode input stage and common emitter (CE) output stage\nwith dual loop feedbacks. The novel cascode-CE current reuse topology replaces\nthe traditional two stages topology so as to obtain low power consumption. The\nemitter degenerative inductor in input stage is adopted to achieve good input\nimpedance matching and noise performance. The two poles are introduced by the\nemitter inductor, which will degrade the gain performance, are cancelled by the\ndual loop feedbacks of the resistance-inductor (RL) shunt-shunt feedback and\nresistance-capacitor (RC) series-series feedback in the output stage.\nMeanwhile, output impedance matching is also achieved. Based on TSMC 0.35{\\mu}m\nSiGe BiCMOS process, the topology and chip layout of the proposed LNA are\ndesigned and post-simulated. The LNA achieves the noise figure of 2.3~4.1dB,\ngain of 18.9~20.2dB, gain flatness of \\pm0.65dB, input third order intercept\npoint (IIP3) of -7dBm at 6GHz, exhibits less than 16ps of group delay\nvariation, good input and output impedances matching, and unconditionally\nstable over the whole band. The power consuming is only 18mW.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.3562v1"
    },
    {
        "title": "Survey of Multiscale and Multiphysics Applications and Communities",
        "authors": [
            "Derek Groen",
            "Stefan J. Zasada",
            "Peter V. Coveney"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Multiscale and multiphysics applications are now commonplace, and many\nresearchers focus on combining existing models to construct combined multiscale\nmodels. Here we present a concise review of multiscale applications and their\nsource communities. We investigate the prevalence of multiscale projects in the\nEU and the US, review a range of coupling toolkits they use to construct\nmultiscale models and identify areas where collaboration between disciplines\ncould be particularly beneficial. We conclude that multiscale computing has\nbecome increasingly popular in recent years, that different communities adopt\nvery different approaches to constructing multiscale simulations, and that\nsimulations on a length scale of a few metres and a time scale of a few hours\ncan be found in many of the multiscale research domains. Communities may\nreceive additional benefit from sharing methods that are geared towards these\nscales.\n",
        "pdf_link": "http://arxiv.org/pdf/1208.6444v3"
    },
    {
        "title": "A Synthesis Method for Quaternary Quantum Logic Circuits",
        "authors": [
            "Sudhindu Bikash Mandal",
            "Amlan Chakrabarti",
            "Susmita Sur-Kolay"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Synthesis of quaternary quantum circuits involves basic quaternary gates and\nlogic operations in the quaternary quantum domain. In this paper, we propose\nnew projection operations and quaternary logic gates for synthesizing\nquaternary logic functions. We also demonstrate the realization of the proposed\ngates using basic quantum quaternary operations. We then employ our synthesis\nmethod to design of quaternary adder and some benchmark circuits. Our results\nin terms of circuit cost, are better than the existing works.\n",
        "pdf_link": "http://arxiv.org/pdf/1210.8055v1"
    },
    {
        "title": "Design and Development of an Ultrasonic Motion Detector",
        "authors": [
            "A. M. Zungeru"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  The ultrasonic motion detector devices emit ultrasonic sound energy into an\narea of interest (monitored area), and this further reacts to a change in the\nreflected energy pattern. The system uses a technique that is based on a\nfrequency shift in reflected energy to detect a movement or change in position\n(motion). In this system, ultrasonic sound is transmitted from the transmitting\ndevice which is normally in the form of energy. The transmitted sound utilizes\nair as its medium and this travel in a wave type motion. The wave is reflected\nback from the surroundings in the room/hallway and the device hears a pitch\ncharacteristic of the protected environment. In this system, the wave pattern\nis disturbed and reflected back more quickly, thus increasing the pitch and\nsignaling an alarm whenever motion is detected. The main contribution of this\nwork is the design of a circuit that can sense motion through movement of\nanything, a low cost and portable motion detector, and the design of a circuit\nthat can be used to trigger another circuit whether to ON or OFF depending on\nthe circuit attached to it. Generally, the design is made to detect movement or\nmoving object in a an enclosed area. In this work, a transmitter transducer\ngenerates a signal at a frequency of 40khz, and when the signal is blocked by\nany moving object, and this in turn, triggers a buzzer via a timing circuit.\nThis system works on the principle of the signal interference by a moving body,\nand the system is dependent on the presence of an intruder or moving object\nwithin a monitored area. The system after design and construction was tested\nand found to work in accordance with specifications.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.1732v1"
    },
    {
        "title": "Independent Component Analysis for Filtering Airwaves in Seabed Logging\n  Application",
        "authors": [
            "Adeel Ansari",
            "Afza Bt Shafie",
            "Abas B Md Said",
            "Seema Ansari"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Marine controlled source electromagnetic (CSEM) sensing method used for the\ndetection of hydrocarbons based reservoirs in seabed logging application does\nnot perform well due to the presence of the airwaves (or sea-surface). These\nairwaves interfere with the signal that comes from the subsurface seafloor and\nalso tend to dominate in the receiver response at larger offsets. The task is\nto identify these air waves and the way they interact, and to filter them out.\nIn this paper, a popular method for counteracting with the above stated problem\nscenario is Independent Component Analysis (ICA). Independent component\nanalysis (ICA) is a statistical method for transforming an observed\nmultidimensional or multivariate dataset into its constituent components\n(sources) that are statistically as independent from each other as possible.\nICA-type de-convolution algorithm that is FASTICA is considered for mixed\nsignals de-convolution and considered convenient depending upon the nature of\nthe source and noise model. The results from the FASTICA algorithm are shown\nand evaluated. In this paper, we present the FASTICA algorithm for the seabed\nlogging application.\n",
        "pdf_link": "http://arxiv.org/pdf/1303.2593v1"
    },
    {
        "title": "Condition-Based Maintenance using Sensor Arrays and Telematics",
        "authors": [
            "Gopalakrishna Palem"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Emergence of uniquely addressable embeddable devices has raised the bar on\nTelematics capabilities. Though the technology itself is not new, its\napplication has been quite limited until now. Sensor based telematics\ntechnologies generate volumes of data that are orders of magnitude larger than\nwhat operators have dealt with previously. Real-time big data computation\ncapabilities have opened the flood gates for creating new predictive analytics\ncapabilities into an otherwise simple data log systems, enabling real-time\ncontrol and monitoring to take preventive action in case of any anomalies.\nCondition-based-maintenance, usage-based-insurance, smart metering and\ndemand-based load generation etc. are some of the predictive analytics use\ncases for Telematics. This paper presents the approach of condition-based\nmaintenance using real-time sensor monitoring, Telematics and predictive data\nanalytics.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.1921v1"
    },
    {
        "title": "Unconventional research in USSR and Russia: short overview",
        "authors": [
            "Serge Kernbach"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  This work briefly surveys unconventional research in Russia from the end of\nthe 19th until the beginning of the 21th centuries in areas related to\ngeneration and detection of a 'high-penetrating' emission of non-biological\norigin. The overview is based on open scientific and journalistic materials.\nThe unique character of this research and its history, originating from\ngovernmental programs of the USSR, is shown. Relations to modern studies on\nbiological effects of weak electromagnetic emission, several areas of\nbioinformatics and theories of physical vacuum are discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.1148v2"
    },
    {
        "title": "Solve of problems of mathematical theory of learning with using computer\n  modeling methods",
        "authors": [
            "R. V. Mayer"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Analyzed models of learning, which take into account that: 1) the rate of\nincrease of student's knowledge is proportional to the difference between\nlevels of teacher's requirements and prior knowledge; 2) if the requirements\nare too high, then student motivation decreases and he stops learning. Was\nproposed: 1) a one component model, coming from the fact that the training\ninformation consists of equal elements; 2) a two component model that takes\ninto account that knowledge is assimilated with varying strength, 'trustworthy'\nknowledge forgotten much slower then 'weak'; 3) two component model, which\ntakes into account the transition of 'weak' knowledge in 'trustworthy'\nknowledge. The solution of the five predictors and optimization problems of\nlearning theory are represented.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.2182v1"
    },
    {
        "title": "Exact Reconstruction of Spatially Undersampled Signals in Evolutionary\n  Systems",
        "authors": [
            "Akram Aldroubi",
            "Jacqueline Davis",
            "Ilya Krishtal"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  We consider the problem of spatiotemporal sampling in which an initial state\n$f$ of an evolution process $f_t=A_tf$ is to be recovered from a combined set\nof coarse samples from varying time levels $\\{t_1,\\dots,t_N\\}$. This new way of\nsampling, which we call dynamical sampling, differs from standard sampling\nsince at any fixed time $t_i$ there are not enough samples to recover the\nfunction $f$ or the state $f_{t_i}$. Although dynamical sampling is an inverse\nproblem, it differs from the typical inverse problems in which $f$ is to be\nrecovered from $A_Tf$ for a single time $T$. In this paper, we consider signals\nthat are modeled by $\\ell^2(\\mathbb Z)$ or a shift invariant space $V\\subset\nL^2(\\mathbb R)$.\n",
        "pdf_link": "http://arxiv.org/pdf/1312.3203v1"
    },
    {
        "title": "A New Approach to Customization of Collision Warning Systems to\n  Individual Drivers",
        "authors": [
            "Ali Rakhshan",
            "Evan Ray",
            "Hossein Pishro-Nik"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  This paper discusses the need for individualizing safety systems and proposes\nan approach including the Real-Time estimation of the distribution of brake\nresponse times for an individual driver. While maintaining high level of\nsafety, the collision warning system should send \"tailored\" responses to the\ndriver. This method could be the first step to show that safety applications\nwould potentially benefit from customizing to individual drivers'\ncharacteristics using VANET. Our simulation results show that, as one of the\nimminent and preliminary outcomes of the new improved system, the number of\nfalse alarms will be reduced by more than 40%. We think this tactic can reach\nto even beyond the safety applications for designing the future innovative\nsystems.\n",
        "pdf_link": "http://arxiv.org/pdf/1408.4111v2"
    },
    {
        "title": "The Solving of the Problems with Random Division of an Interval with Use\n  of Computer Analytic Programs",
        "authors": [
            "Aleksander Reznik",
            "Vitaly Efimov",
            "Aleksander Soloview",
            "Andrey Torgov"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  An original approach to solving rather difficult probabilistic problems\narising in studying the readout of random discrete fields and having no exact\nanalytical solutions at the moment is proposed. Several algorithms for direct,\niterative, and combinatorial-recursive calculations of multidimensional\nintegral expressions, which can describe partial solutions of these problems,\nare presented (these solutions are further used to search for the common closed\nanalytical regularities). The huge volume of necessary calculations forced us\nto formalize completely the algorithms and to transfer all the burden of\nroutine analytical transforms to a computer. The calculations performed helped\nus to establish (and to prove later) a number of new earlier unknown\nprobabilistic formulas responsible for random division of an interval. One more\nimportant feature of this study is the fact that we introduced a new concept of\n'three-dimensional generalized Catalan numbers' and found their explicit form\nin solving problems associated with random division of an interval.\n",
        "pdf_link": "http://arxiv.org/pdf/1411.6580v2"
    },
    {
        "title": "Towards an intelligent VNS heuristic for the k-labelled spanning forest\n  problem",
        "authors": [
            "Sergio Consoli",
            "Jos Andrs Moreno Prez",
            "Nenad Mladenovic"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  In a currently ongoing project, we investigate a new possibility for solving\nthe k-labelled spanning forest (kLSF) problem by an intelligent Variable\nNeighbourhood Search (Int-VNS) metaheuristic. In the kLSF problem we are given\nan undirected input graph G and an integer positive value k, and the aim is to\nfind a spanning forest of G having the minimum number of connected components\nand the upper bound k on the number of labels to use. The problem is related to\nthe minimum labelling spanning tree (MLST) problem, whose goal is to get the\nspanning tree of the input graph with the minimum number of labels, and has\nseveral applications in the real world, where one aims to ensure connectivity\nby means of homogeneous connections. The Int-VNS metaheuristic that we propose\nfor the kLSF problem is derived from the promising intelligent VNS strategy\nrecently proposed for the MLST problem, and integrates the basic VNS for the\nkLSF problem with other complementary approaches from machine learning,\nstatistics and experimental algorithmics, in order to produce high-quality\nperformance and to completely automate the resulting strategy.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.02009v1"
    },
    {
        "title": "Understanding Soft Errors in Uncore Components",
        "authors": [
            "Hyungmin Cho",
            "Chen-Yong Cher",
            "Thomas Shepherd",
            "Subhasish Mitra"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  The effects of soft errors in processor cores have been widely studied.\nHowever, little has been published about soft errors in uncore components, such\nas memory subsystem and I/O controllers, of a System-on-a-Chip (SoC). In this\nwork, we study how soft errors in uncore components affect system-level\nbehaviors. We have created a new mixed-mode simulation platform that combines\nsimulators at two different levels of abstraction, and achieves 20,000x speedup\nover RTL-only simulation. Using this platform, we present the first study of\nthe system-level impact of soft errors inside various uncore components of a\nlarge-scale, multi-core SoC using the industrial-grade, open-source OpenSPARC\nT2 SoC design. Our results show that soft errors in uncore components can\nsignificantly impact system-level reliability. We also demonstrate that uncore\nsoft errors can create major challenges for traditional system-level checkpoint\nrecovery techniques. To overcome such recovery challenges, we present a new\nreplay recovery technique for uncore components belonging to the memory\nsubsystem. For the L2 cache controller and the DRAM controller components of\nOpenSPARC T2, our new technique reduces the probability that an application run\nfails to produce correct results due to soft errors by more than 100x with\n3.32% and 6.09% chip-level area and power impact, respectively.\n",
        "pdf_link": "http://arxiv.org/pdf/1504.01381v3"
    },
    {
        "title": "Real-Time Contingency Analysis with Corrective Transmission Switching -\n  Part I: Methodology",
        "authors": [
            "Xingpeng Li",
            "Pranavamoorthy Balasubramanian",
            "Mostafa Sahraei-Ardakani",
            "Mojdeh Abdi-Khorsand",
            "Kory W. Hedman",
            "Robin Podmore"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Transmission switching (TS) has gained significant attention recently.\nHowever, barriers still remain and must be overcome before the technology can\nbe adopted by the industry. The state of the art challenges include AC\nfeasibility and performance, computational complexity, the ability to handle\nlarge-scale real power systems, and dynamic stability. This two-part paper\ninvestigates these challenges by developing an AC TS-based real-time\ncontingency analysis (RTCA) tool that can handle large-scale systems within a\nreasonable time. The tool proposes multiple corrective switching actions, after\ndetection of a contingency with potential violations. To reduce the\ncomputational complexity, three heuristic algorithms are proposed to generate a\nsmall set of candidates for switching. Parallel computing is implemented to\nfurther speed up the solution time. Furthermore, stability analysis is\nperformed to check for dynamic stability of proposed TS solutions. Part I of\nthe paper presents a comprehensive literature review and the methodology. The\npromising results, tested on the Tennessee Valley Authority (TVA) system and\nactual energy management system (EMS) snapshots from Pennsylvania New Jersey\nMaryland (PJM) and the Electric Reliability Council of Texas (ERCOT), are\npresented in Part II. It is concluded that RTCA with corrective TS\nsignificantly reduces potential post-contingency violations and is ripe for\nindustry adoption.\n",
        "pdf_link": "http://arxiv.org/pdf/1604.05570v1"
    },
    {
        "title": "Online Charging Scheduling Algorithms of Electric Vehicles in Smart\n  Grid: An Overview",
        "authors": [
            "Wanrong Tang",
            "Suzhi Bi",
            "Ying Jun",
            " Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  As an environment-friendly substitute for conventional fuel-powered vehicles,\nelectric vehicles (EVs) and their components have been widely developed and\ndeployed worldwide. The large-scale integration of EVs into power grid brings\nboth challenges and opportunities to the system performance. On one hand, the\nload demand from EV charging imposes large impact on the stability and\nefficiency of power grid. On the other hand, EVs could potentially act as\nmobile energy storage systems to improve the power network performance, such as\nload flattening, fast frequency control, and facilitating renewable energy\nintegration. Evidently, uncontrolled EV charging could lead to inefficient\npower network operation or even security issues. This spurs enormous research\ninterests in designing charging coordination mechanisms. A key design challenge\nhere lies in the lack of complete knowledge of events that occur in the future.\nIndeed, the amount of knowledge of future events significantly impacts the\ndesign of efficient charging control algorithms. This article focuses on\nintroducing online EV charging scheduling techniques that deal with different\ndegrees of uncertainty and randomness of future knowledge. Besides, we\nhighlight the promising future research directions for EV charging control.\n",
        "pdf_link": "http://arxiv.org/pdf/1609.02791v1"
    },
    {
        "title": "Finite Computational Structures and Implementations",
        "authors": [
            "Attila Egri-Nagy"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  What is computable with limited resources? How can we verify the correctness\nof computations? How to measure computational power with precision? Despite the\nimmense scientific and engineering progress in computing, we still have only\npartial answers to these questions. In order to make these problems more\nprecise, we describe an abstract algebraic definition of classical computation,\ngeneralizing traditional models to semigroups. The mathematical abstraction\nalso allows the investigation of different computing paradigms (e.g. cellular\nautomata, reversible computing) in the same framework. Here we summarize the\nmain questions and recent results of the research of finite computation.\n",
        "pdf_link": "http://arxiv.org/pdf/1610.05849v1"
    },
    {
        "title": "Bayesian Gates for Reliable Logical Operations under Noisy Condition",
        "authors": [
            "Tetsuya J. Kobayashi"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  The reliability of logical operations is indispensable for the reliable\noperation of computational systems. Since the down-sizing of micro-fabrication\ngenerates non-negligible noise in these systems, a new approach for designing\nnoise-immune gates is required. In this paper, we demonstrate that noise-immune\ngates can be designed by combining Bayesian inference theory with the idea of\ncomputation over a noisy signal. To reveal their practical advantages, the\nperformance of these gates is evaluated in comparison with a stochastic\nresonance-based gate proposed previously. This approach for computation is also\ndemonstrated to be better than a conventional one that conducts information\ntransmission and computation separately.\n",
        "pdf_link": "http://arxiv.org/pdf/1703.00444v3"
    },
    {
        "title": "From Logic to Biology via Physics: a survey",
        "authors": [
            "Giuseppe Longo",
            "Mal Montvil"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This short text summarizes the work in biology proposed in our book,\nPerspectives on Organisms, where we analyse the unity proper to organisms by\nlooking at it from different viewpoints. We discuss the theoretical roles of\nbiological time, complexity, theoretical symmetries, singularities and critical\ntransitions. We explicitly borrow from the conclusions in some key chapters and\nintroduce them by a reflection on \"incompleteness\", also proposed in the book.\nWe consider that incompleteness is a fundamental notion to understand the way\nin which we construct knowledge. Then we will introduce an approach to\nbiological dynamics where randomness is central to the theoretical\ndetermination: randomness does not oppose biological stability but contributes\nto it by variability, adaptation, and diversity. Then, evolutionary and\nontogenetic trajectories are continual changes of coherence structures\ninvolving symmetry changes within an ever-changing global stability.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.06001v2"
    },
    {
        "title": "TikZ-network manual",
        "authors": [
            "Jrgen Hackl"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  TikZ-network is an open source software project for visualizing graphs and\nnetworks in LaTeX. It aims to provide a simple and easy tool to create,\nvisualize and modify complex networks. The packaged is based on the PGF/TikZ\nlanguages for producing vector graphics from a geometric/algebraic description.\nParticular focus is made on the software usability and interoperability with\nother tools. Simple networks can be directly created within LaTeX, while more\ncomplex networks can be imported from external sources (e.g. igraph, networkx,\nQGIS, ...). Additionally, tikz-network supports visualization of multilayer\nnetworks in two and three dimensions. The software is available at:\nhttps://github.com/hackl/tikz-network.\n",
        "pdf_link": "http://arxiv.org/pdf/1709.06005v2"
    },
    {
        "title": "Machine Learning Based Fast Power Integrity Classifier",
        "authors": [
            "HuaChun Zhang",
            "Lynden Kagan",
            "Chen Zheng"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In this paper, we proposed a new machine learning based fast power integrity\nclassifier that quickly flags the EM/IR hotspots. We discussed the features to\nextract to describe the power grid, cell power density, routing impact and\ncontrolled collapse chip connection (C4) bumps, etc. The continuous and\ndiscontinuous cases are identified and treated using different machine learning\nmodels. Nearest neighbors, random forest and neural network models are compared\nto select the best performance candidates. Experiments are run on open source\nbenchmark, and result is showing promising prediction accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1711.03406v1"
    },
    {
        "title": "automan: a simple, Python-based, automation framework for numerical\n  computing",
        "authors": [
            "Prabhu Ramachandran"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  We present an easy-to-use, Python-based framework that allows a researcher to\nautomate their computational simulations. In particular the framework\nfacilitates assembling several long-running computations and producing various\nplots from the data produced by these computations. The framework makes it\npossible to reproduce every figure made for a publication with a single\ncommand. It also allows one to distribute the computations across a network of\ncomputers. The framework has been used to write research papers in numerical\ncomputing. This paper discusses the design of the framework, and the benefits\nof using it. The ideas presented are general and should help researchers\norganize their computations for better reproducibility.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.04786v2"
    },
    {
        "title": "Analytical Inverter Delay Modeling Using Matlab's Curve Fitting Toolbox",
        "authors": [
            "Walter Schneider"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This paper presents a new analytical propagation delay model for deep\nsubmicron CMOS inverters. The model is inspired by the key observation that the\ninverter delay is a complicated function of several process parameters as well\nas load capacitance. These relationships are considered by fitting functions\nfor each parameter derived from the Curve Fitting Toolbox in Matlab. Compared\nto SPICE simulations based on the BSIM4 transistor model, the analytical delay\nmodel shows very good accuracy with an average error less than 2% over a wide\nrange of process parameters and output loads. Hence, the proposed model can be\nefficiently used for different technology nodes as well as statistical gate\ndelay characterisation.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.00005v1"
    },
    {
        "title": "Hardware implementation of auto-mutual information function for\n  condition monitoring",
        "authors": [
            "Harun Siljak",
            "Abdulhamit Subasi",
            "Belle R. Upadhyaya"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This study is aimed at showing applicability of mutual information, namely\nauto-mutual information function for condition monitoring in electrical motors,\nthrough age detection in accelerated motor aging. Vibration data collected in\nartificial induction motor experiment is used for verification of both the\noriginal auto-mutual information function algorithm and its hardware\nimplementation in Verilog, produced from an initial version made with Matlab\nHDL (Hardware Description Language) Coder. A conceptual model for industry and\neducation based on a field programmable logic array development board is\ndeveloped and demonstrated on the auto-mutual information function example,\nwhile suggesting other applications as well. It has also been shown that\nattractor reconstruction for the vibration data cannot be straightforward.\n",
        "pdf_link": "http://arxiv.org/pdf/1801.08444v1"
    },
    {
        "title": "A Review of Augmented Reality Applications for Building Evacuation",
        "authors": [
            "Lovreglio Ruggiero"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Evacuation is one of the main disaster management solutions to reduce the\nimpact of man-made and natural threats on building occupants. To date, several\nmodern technologies and gamification concepts, e.g. immersive virtual reality\nand serious games, have been used to enhance building evacuation preparedness\nand effectiveness. Those tools have been used both to investigate human\nbehavior during building emergencies and to train building occupants on how to\ncope with building evacuations.\n  Augmented Reality (AR) is novel technology that can enhance this process\nproviding building occupants with virtual contents to improve their evacuation\nperformance. This work aims at reviewing existing AR applications developed for\nbuilding evacuation. This review identifies the disasters and types of building\nthose tools have been applied for. Moreover, the application goals, hardware\nand evacuation stages affected by AR are also investigated in the review.\nFinally, this review aims at identifying the challenges to face for further\ndevelopment of AR evacuation tools.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.04186v1"
    },
    {
        "title": "Random Tilings with the GPU",
        "authors": [
            "David Keating",
            "Ananth Sridhar"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  We present GPU accelerated implementations of Markov chain algorithms to\nsample random tilings, dimers, and the six-vertex model.\n",
        "pdf_link": "http://arxiv.org/pdf/1804.07250v1"
    },
    {
        "title": "Ten Simple Rules for Reproducible Research in Jupyter Notebooks",
        "authors": [
            "Adam Rule",
            "Amanda Birmingham",
            "Cristal Zuniga",
            "Ilkay Altintas",
            "Shih-Cheng Huang",
            "Rob Knight",
            "Niema Moshiri",
            "Mai H. Nguyen",
            "Sara Brin Rosenthal",
            "Fernando Prez",
            "Peter W. Rose"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Reproducibility of computational studies is a hallmark of scientific\nmethodology. It enables researchers to build with confidence on the methods and\nfindings of others, reuse and extend computational pipelines, and thereby drive\nscientific progress. Since many experimental studies rely on computational\nanalyses, biologists need guidance on how to set up and document reproducible\ndata analyses or simulations.\n  In this paper, we address several questions about reproducibility. For\nexample, what are the technical and non-technical barriers to reproducible\ncomputational studies? What opportunities and challenges do computational\nnotebooks offer to overcome some of these barriers? What tools are available\nand how can they be used effectively?\n  We have developed a set of rules to serve as a guide to scientists with a\nspecific focus on computational notebook systems, such as Jupyter Notebooks,\nwhich have become a tool of choice for many applications. Notebooks combine\ndetailed workflows with narrative text and visualization of results. Combined\nwith software repositories and open source licensing, notebooks are powerful\ntools for transparent, collaborative, reproducible, and reusable data analyses.\n",
        "pdf_link": "http://arxiv.org/pdf/1810.08055v1"
    },
    {
        "title": "Towards Modernising Data Collection and Archive for the Tor Network",
        "authors": [
            "Iain R. Learmonth",
            "Karsten Loesing"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  CollecTor is developed by Tor Project's Metrics Team for the purpose of\narchiving data relating to the public Tor network and applications developed by\nTor Project. This report distills the requirements for a prototype modernized\nreplacement of the CollecTor service, and evaluates frameworks and libraries\nthat are available to reduce code maintenance costs for the CollecTor service.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.08429v1"
    },
    {
        "title": "Markov chain aggregation and its application to rule-based modelling",
        "authors": [
            "Tatjana Petrov"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Rule-based modelling allows to represent molecular interactions in a compact\nand natural way. The underlying molecular dynamics, by the laws of stochastic\nchemical kinetics, behaves as a continuous-time Markov chain. However, this\nMarkov chain enumerates all possible reaction mixtures, rendering the analysis\nof the chain computationally demanding and often prohibitive in practice. We\nhere describe how it is possible to efficiently find a smaller, aggregate\nchain, which preserves certain properties of the original one. Formal methods\nand lumpability notions are used to define algorithms for automated and\nefficient construction of such smaller chains (without ever constructing the\noriginal ones). We here illustrate the method on an example and we discuss the\napplicability of the method in the context of modelling large signalling\npathways.\n",
        "pdf_link": "http://arxiv.org/pdf/1812.09774v1"
    },
    {
        "title": "Pragmatic inference and visual abstraction enable contextual flexibility\n  during visual communication",
        "authors": [
            "Judith Fan",
            "Robert Hawkins",
            "Mike Wu",
            "Noah Goodman"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Visual modes of communication are ubiquitous in modern life --- from maps to\ndata plots to political cartoons. Here we investigate drawing, the most basic\nform of visual communication. Participants were paired in an online environment\nto play a drawing-based reference game. On each trial, both participants were\nshown the same four objects, but in different locations. The sketcher's goal\nwas to draw one of these objects so that the viewer could select it from the\narray. On `close' trials, objects belonged to the same basic-level category,\nwhereas on `far' trials objects belonged to different categories. We found that\npeople exploited shared information to efficiently communicate about the target\nobject: on far trials, sketchers achieved high recognition accuracy while\napplying fewer strokes, using less ink, and spending less time on their\ndrawings than on close trials. We hypothesized that humans succeed in this task\nby recruiting two core faculties: visual abstraction, the ability to perceive\nthe correspondence between an object and a drawing of it; and pragmatic\ninference, the ability to judge what information would help a viewer\ndistinguish the target from distractors. To evaluate this hypothesis, we\ndeveloped a computational model of the sketcher that embodied both faculties,\ninstantiated as a deep convolutional neural network nested within a\nprobabilistic program. We found that this model fit human data well and\noutperformed lesioned variants. Together, this work provides the first\nalgorithmically explicit theory of how visual perception and social cognition\njointly support contextual flexibility in visual communication.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.04448v2"
    },
    {
        "title": "Substation One-Line Diagram Automatic Generation and Visualization",
        "authors": [
            "Jing Hong",
            "Yue Li",
            "Yiran Xu",
            "Chen Yuan",
            "Hong Fan",
            "Guangyi Liu",
            "Renchang Dai"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In Energy Management System (EMS) applications and many other off-line\nplanning and study tools, one-line diagram (OLND) of the whole system and\nstations is a straightforward view for planners and operators to design,\nmonitor, analyze, and control the power system. Large-scale power system OLND\nis usually manually developed and maintained. The work is tedious,\ntime-consuming and ease to make mistake. Meanwhile, the manually created\ndiagrams are hard to be shared among the on-line and off-line systems. To save\nthe time and efforts to draw and maintain OLNDs, and provide the capability to\nshare the OLNDs, a tool to automatically develop substation based upon Common\nInformation Model (CIM) standard is needed. Currently, there is no standard\nrule to draw the substation OLND. Besides, the substation layouts can be\naltered from the typical formats in textbooks based on factors of economy,\nefficiency, engineering practice, etc. This paper presents a tool on substation\nOLND automatic generation and visualization. This tool takes the substation\nCIM/E model as input, then automatically computes the coordinates of all\ncomponents and generates the substation OLND based on its components attributes\nand connectivity relations. Evaluation of the proposed approach is presented\nusing a real provincial power system. Over 95\\% of substation OLNDs are\ndecently presented and the rest are corner cases, needing extra effort to do\nspecific reconfiguration.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09495v1"
    },
    {
        "title": "Was ist eine Professur fuer Kuenstliche Intelligenz?",
        "authors": [
            "Kristian Kersting",
            "Jan Peters",
            "Constantin Rothkopf"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The Federal Government of Germany aims to boost the research in the field of\nArtificial Intelligence (AI). For instance, 100 new professorships are said to\nbe established. However, the white paper of the government does not answer what\nan AI professorship is at all. In order to give colleagues, politicians, and\ncitizens an idea, we present a view that is often followed when appointing\nprofessors for AI at German and international universities. We hope that it\nwill help to establish a guideline with internationally accepted measures and\nthus make the public debate more informed.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09516v1"
    },
    {
        "title": "Simulation-Based Analytics for Fabrication Quality-Associated Decision\n  Support",
        "authors": [
            "Wenying Ji"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Automated, data-driven quality management systems, which facilitate the\ntransformation of data into useable information, are desired to enhance\ndecision-making processes. Integration of accurate, reliable, and\nstraightforward approaches that measure uncertainty of inspection processes are\ninstrumental for the successful implementation of automated, data-driven\nquality management systems. This research has addressed these needs by\nexploring and adapting Bayesian statistics-based approaches for fraction\nnonconforming posterior distribution derivation purposes. Using these accurate\nand reliable inputs, this research further develops novel, analytically-based\napproaches to improve the practical function of traditional construction\nfabrication quality management systems. Multiple descriptive and predictive\nanalytical functionalities are developed to support and augment\nquality-associated decision-making processes. Multi-relational databases (e.g.,\nquality management system, engineering design system, and cost management\nsystem) from an industrial company in Edmonton, Canada, are investigated and\nmapped to implement the novel system proposed. This research has contributed to\nacademic literature and practice by: (1) advancing decision-support systems for\nconstruction management by developing a dynamic simulation environment that\nuses real-time data to enhance simulation predictability; (2) developing\nintegrated analytical methods for improved modeling in fabrication\nquality-associated decision making; and (3) creating reliable and interpretable\ndecision-support metrics for quality performance measurement, complexity\nanalysis, and rework cost management to reduce the data interpretation load of\npractitioners and to uncover valuable knowledge and information from available\ndata sources.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.10565v1"
    },
    {
        "title": "How to Design While Loops",
        "authors": [
            "Marco T. Morazn"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Beginning students find the syntactic construct known as a while loop\ndifficult to master. The difficulties revolve around guaranteeing loop\ntermination and around learning how to properly sequence mutations to solve a\nproblem. In fact, both of these are intertwined and students need to be taught\na model that helps them reason about how to design while loops. For students\nthat have been introduced to how to design programs using structural recursion,\ngenerative recursion, accumulative recursion, and mutation, the task of\nteaching them how to design while loops is made easier. These students are\nfamiliar, for example, with state variables, termination arguments, and\naccumulator invariants. All of these are fundamental in the design of while\nloops. This articles presents a novel technique used at Seton Hall University\nto introduce beginners to the design of while loops. It presents a design\nrecipe that students can follow step-by-step to establish such things as the\ndriver of the loop, the loop invariant, and the proper sequencing of mutations.\nThe article also presents an example of designing a while-loop based function\nusing the new design recipe.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.12375v1"
    },
    {
        "title": "An Efficient Topology-Based Algorithm for Transient Analysis of Power\n  Grid",
        "authors": [
            "Jim Jing-Yan Wang",
            "Lan Yang",
            "Jingbin Wang",
            "Lorenzo Azevedo"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In the design flow of integrated circuits, chip-level verification is an\nimportant step that sanity checks the performance is as expected. Power grid\nverification is one of the most expensive and time-consuming steps of\nchip-level verification, due to its extremely large size. Efficient power grid\nanalysis technology is highly demanded as it saves computing resources and\nenables faster iteration. In this paper, a topology-base power grid transient\nanalysis algorithm is proposed. Nodal analysis is adopted to analyze the\ntopology which is mathematically equivalent to iteratively solving a positive\nsemi-definite linear equation. The convergence of the method is proved.\n",
        "pdf_link": "http://arxiv.org/pdf/1409.7166v2"
    },
    {
        "title": "3D/4D ultrasound registration of bone",
        "authors": [
            "Jonathan Schers",
            "Jocelyne Troccaz",
            "Vincent Daanen",
            "Cline Fouard",
            "Christopher Plaskos",
            "Pascal Kilian"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This paper presents a method to reduce the invasiveness of Computer Assisted\nOrthopaedic Surgery (CAOS) using ultrasound. In this goal, we need to develop a\nmethod for 3D/4D ultrasound registration. The premilinary results of this study\nsuggest that the development of a robust and ``realtime'' 3D/4D ultrasound\nregistration is feasible.\n",
        "pdf_link": "http://arxiv.org/pdf/0801.2823v1"
    },
    {
        "title": "TER: A Robot for Remote Ultrasonic Examination: Experimental Evaluations",
        "authors": [
            "Jean-Jacques Banihachemi",
            "Eric Boidard",
            "Jean-Luc Bosson",
            "Luc Bressollette",
            "Ivan Bricault",
            "Philippe Cinquin",
            "Gilbert Ferretti",
            "Maud Marchal",
            "Thomas Martinelli",
            "Alexandre Moreau-Gaudry",
            "Franck Pelissier",
            "Christian Roux",
            "Dominique Saragaglia",
            "Pierre Thorel",
            "Jocelyne Troccaz",
            "Adriana Vilchis"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  This chapter:\n  o Motivates the clinical use of robotic tele-echography\n  o Introduces the TER system\n  o Describes technical and clinical evaluations performed with TER\n",
        "pdf_link": "http://arxiv.org/pdf/0801.4355v1"
    },
    {
        "title": "Solving the Parity Problem with Rule 60 in Array Size of the Power of\n  Two",
        "authors": [
            "Shigeru Ninagawa"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  In the parity problem, a given cellular automaton has to classify any initial\nconfiguration into two classes according to its parity. Elementary cellular\nautomaton rule 60 can solve the parity problem in periodic boundary conditions\nwith array size of the power of two. The spectral analysis of the\nconfigurations of rule 60 at each time step in the evolution reveals that\nspatial periodicity emerges as the evolution proceeds and the patterns with\nlonger period split into the ones with shorter period. This phenomenon is\nanalogous to the cascade process in which large scale eddies split into smaller\nones in turbulence. By measuring the Lempel-Ziv complexity of configuration, we\nfound the stepping decrease of the complexity during the evolution. This result\nmight imply that a decision problem solving process is accompanied with the\ndecline of complexity of configuration.\n",
        "pdf_link": "http://arxiv.org/pdf/1307.3888v1"
    },
    {
        "title": "DGD Gallery: Storage, sharing, and publication of digital research data",
        "authors": [
            "Michael Joswig",
            "Milan Mehner",
            "Stefan Sechelmann",
            "Jan Techter",
            "Alexander I. Bobenko"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  We describe a project, called the \"Discretization in Geometry and Dynamics\nGallery\", or DGD Gallery for short, whose goal is to store geometric data and\nto make it publicly available. The DGD Gallery offers an online web service for\nthe storage, sharing, and publication of digital research data.\n",
        "pdf_link": "http://arxiv.org/pdf/1512.04364v1"
    },
    {
        "title": "Sensor Fusion for Public Space Utilization Monitoring in a Smart City",
        "authors": [
            "Billy Pik Lik Lau",
            "Nipun Wijerathne",
            "Benny Kai Kiat Ng",
            "and Chau Yuen"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Public space utilization is crucial for urban developers to understand how\nefficient a place is being occupied in order to improve existing or future\ninfrastructures. In a smart cities approach, implementing public space\nmonitoring with Internet-of-Things (IoT) sensors appear to be a viable\nsolution. However, choice of sensors often is a challenging problem and often\nlinked with scalability, coverage, energy consumption, accuracy, and privacy.\nTo get the most from low cost sensor with aforementioned design in mind, we\nproposed data processing modules for capturing public space utilization with\nRenewable Wireless Sensor Network (RWSN) platform using pyroelectric infrared\n(PIR) and analog sound sensor. We first proposed a calibration process to\nremove false alarm of PIR sensor due to the impact of weather and environment.\nWe then demonstrate how the sounds sensor can be processed to provide various\ninsight of a public space. Lastly, we fused both sensors and study a particular\npublic space utilization based on one month data to unveil its usage.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.01581v2"
    },
    {
        "title": "Modeling and Real-Time Scheduling of DC Platform Supply Vessel for Fuel\n  Efficient Operation",
        "authors": [
            "Kuntal Satpathi",
            "VSK Murthy Balijepalli",
            "Abhisek Ukil"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  DC marine architecture integrated with variable speed diesel generators (DGs)\nhas garnered the attention of the researchers primarily because of its ability\nto deliver fuel efficient operation. This paper aims in modeling and to\nautonomously perform real-time load scheduling of dc platform supply vessel\n(PSV) with an objective to minimize specific fuel oil consumption (SFOC) for\nbetter fuel efficiency. Focus has been on the modeling of various components\nand control routines, which are envisaged to be an integral part of dc PSVs.\nIntegration with photovoltaic-based energy storage system (ESS) has been\nconsidered as an option to cater for the short time load transients. In this\ncontext, this paper proposes a real-time transient simulation scheme, which\ncomprises of optimized generation scheduling of generators and ESS using dc\noptimal power flow algorithm. This framework considers real dynamics of dc PSV\nduring various marine operations with possible contingency scenarios, such as\noutage of generation systems, abrupt load changes, and unavailability of ESS.\nThe proposed modeling and control routines with real-time transient simulation\nscheme have been validated utilizing the real-time marine simulation platform.\nThe results indicate that the coordinated treatment of renewable based ESS with\nDGs operating with optimized speed yields better fuel savings. This has been\nobserved in improved SFOC operating trajectory for critical marine missions.\nFurthermore, SFOC minimization at multiple suboptimal points with its treatment\nin the real-time marine system is also highlighted.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.10336v1"
    },
    {
        "title": "Customized Routing Optimization Based on Gradient Boost Regressor Model",
        "authors": [
            "Chen Zheng",
            "Clara Grzegorz Kasprowicz",
            "Carol Saunders"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  In this paper, we discussed limitation of current\nelectronic-design-automoation (EDA) tool and proposed a machine learning\nframework to overcome the limitations and achieve better design quality. We\nexplored how to efficiently extract relevant features and leverage gradient\nboost regressor (GBR) model to predict underestimated risky net (URN).\nCustomized routing optimizations are applied to the URNs and results show clear\ntiming improvement and trend to converge toward timing closure.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.11118v1"
    },
    {
        "title": "Customizing Pareto Simulated Annealing for Multi-objective Optimization\n  of Control Cabinet Layout",
        "authors": [
            "Sabri Pllana",
            "Suejb Memeti",
            "Joanna Kolodziej"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Determining the optimal location of control cabinet components requires the\nexploration of a large configuration space. For real-world control cabinets it\nis impractical to evaluate all possible cabinet configurations. Therefore, we\nneed to apply methods for intelligent exploration of cabinet configuration\nspace that enable to find a near-optimal configuration without evaluation of\nall possible configurations. In this paper, we describe an approach for\nmulti-objective optimization of control cabinet layout that is based on Pareto\nSimulated Annealing. Optimization aims at minimizing the total wire length used\nfor interconnection of components and the heat convection within the cabinet.\nWe simulate heat convection to study the warm air flow within the control\ncabinet and determine the optimal position of components that generate heat\nduring the operation. We evaluate and demonstrate the effectiveness of our\napproach empirically for various control cabinet sizes and usage scenarios.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.04825v1"
    },
    {
        "title": "Deep Fuzzy Systems",
        "authors": [
            "Khaled Ahmed Nagaty"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  An investigation of deep fuzzy systems is presented in this paper. A deep\nfuzzy system is represented by recursive fuzzy systems from an input terminal\nto output terminal. Recursive fuzzy systems are sequences of fuzzy grade\nmemberships obtained using fuzzy transmition functions and recursive calls to\nfuzzy systems. A recursive fuzzy system which calls a fuzzy system n times\nincludes fuzzy chains to evaluate the final grade membership of this recursive\nsystem. A connection matrix which includes recursive calls are used to\nrepresent recursive fuzzy systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1906.08222v1"
    },
    {
        "title": "Application Specific Instrumentation (ASIN): A Bio-inspired Paradigm to\n  Instrumentation using recognition before detection",
        "authors": [
            "Amit Kumar Mishra"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In this paper we present a new scheme for instrumentation, which has been\ninspired by the way small mammals sense their environment. We call this scheme\nApplication Specific Instrumentation (ASIN). A conventional instrumentation\nsystem focuses on gathering as much information about the scene as possible.\nThis, usually, is a generic system whose data can be used by another system to\ntake a specific action. ASIN fuses these two steps into one. The major merit of\nthe proposed scheme is that it uses low resolution sensors and much less\ncomputational overhead to give good performance for a highly specialised\napplication\n",
        "pdf_link": "http://arxiv.org/pdf/1611.00228v1"
    },
    {
        "title": "A Brief Survey of Non-Residue Based Computational Error Correction",
        "authors": [
            "Sriseshan Srikanth",
            "Bobin Deng",
            "Thomas M. Conte"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  The idea of computational error correction has been around for over half a\ncentury. The motivation has largely been to mitigate unreliable devices,\nmanufacturing defects or harsh environments, primarily as a mandatory measure\nto preserve reliability, or more recently, as a means to lower energy by\nallowing soft errors to occasionally creep. While residue codes have shown\ngreat promise for this purpose, there have been several orthogonal non-residue\nbased techniques. In this article, we provide a high level outline of some of\nthese non-residual approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.03099v1"
    },
    {
        "title": "An Efficient Framework for Floor-plan Prediction of Dynamic Runtime\n  Reconfigurable Systems",
        "authors": [
            "A. Al-Wattar",
            "S. Areibi",
            "G. Grewal"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Several embedded application domains for reconfigurable systems tend to\ncombine frequent changes with high performance demands of their workloads such\nas image processing, wearable computing and network processors. Time\nmultiplexing of reconfigurable hardware resources raises a number of new\nissues, ranging from run-time systems to complex programming models that\nusually form a Reconfigurable hardware Operating System (ROS). The Operating\nSystem performs online task scheduling and handles resource management. There\nare many challenges in adaptive computing and dynamic reconfigurable systems.\nOne of the major understudied challenges is estimating the required resources\nin terms of soft cores, Programmable Reconfigurable Regions (PRRs), the\nappropriate communication infrastructure, and to predict a near optimal layout\nand floorplan of the reconfigurable logic fabric. Some of these issues are\nspecific to the application being designed, while others are more general and\nrelate to the underlying run-time environment. Static resource allocation for\nRun- Time Reconfiguration (RTR) often leads to inferior and unacceptable\nresults. In this paper, we present a novel adaptive and dynamic methodology,\nbased on a Machine Learning approach, for predicting and estimating the\nnecessary resources for an application based on past historical information. An\nimportant feature of the proposed methodology is that the system is able to\nlearn and generalize and, therefore, is expected to improve its accuracy over\ntime. The goal of the entire process is to extract useful hidden knowledge from\nthe data. This knowledge is the prediction and estimation of the necessary\nresources for an unknown or not previously seen application.\n",
        "pdf_link": "http://arxiv.org/pdf/1611.05438v1"
    },
    {
        "title": "City traffic forecasting using taxi GPS data: A coarse-grained cellular\n  automata model",
        "authors": [
            "Yucheng Hu",
            "Minwei Li",
            "Hao Liu",
            "Xiaolu Guo",
            "Xiaowei Wang",
            "Tiejun Li"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  City traffic is a dynamic system of enormous complexity. Modeling and\npredicting city traffic flow remains to be a challenge task and the main\ndifficulties are how to specify the supply and demands and how to parameterize\nthe model. In this paper we attempt to solve these problems with the help of\nlarge amount of floating car data. We propose a coarse-grained cellular\nautomata model that simulates vehicles moving on uniform grids whose size are\nmuch larger compared with the microscopic cellular automata model. The car-car\ninteraction in the microscopic model is replaced by the coupling between\nvehicles and coarse-grained state variables in our model. To parameterize the\nmodel, flux-occupancy relations are fitted from the historical data at every\ngrids, which serve as the coarse-grained fundamental diagrams coupling the\noccupancy and speed. To evaluate the model, we feed it with the historical\ntravel demands and trajectories obtained from the floating car data and use the\nmodel to predict road speed one hour into the future. Numerical results show\nthat our model can capture the traffic flow pattern of the entire city and make\nreasonable predictions. The current work can be considered a prototype for a\nmodel-based forecasting system for city traffic.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.02540v1"
    },
    {
        "title": "Detecting Plagiarism based on the Creation Process",
        "authors": [
            "Johannes Schneider",
            "Avi Bernstein",
            "Jan Vom Brocke",
            "Kostadin Damevski",
            "David C. Shepherd"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  All methodologies for detecting plagiarism to date have focused on the final\ndigital \"outcome\", such as a document or source code. Our novel approach takes\nthe creation process into account using logged events collected by special\nsoftware or by the macro recorders found in most office applications. We look\nat an author's interaction logs with the software used to create the work.\nDetection relies on comparing the histograms of multiple logs' command use. A\nwork is classified as plagiarism if its log deviates too much from logs of\n\"honestly created\" works or if its log is too similar to another log. The\ntechnique supports the detection of plagiarism for digital outcomes that stem\nfrom \\emph{unique} tasks, such as theses and \\emph{equal} tasks such as\nassignments for which the same problem sets are solved by multiple students.\nFocusing on the latter case, we evaluate this approach using logs collected by\nan interactive development environment (IDE) from more than sixty students who\ncompleted three programming assignments.\n",
        "pdf_link": "http://arxiv.org/pdf/1612.09183v2"
    },
    {
        "title": "Realize special instructions on clustering VLIW DSP:\n  multiplication-accumulation instruction",
        "authors": [
            "Binbin Liu",
            "Qilong Zheng"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  BWDSP is a 32bit static scalar digital signal processor with VLIW and SIMD\nfeatures, which is designed for high-performance computing. Associated special\ninstructions are designed for its special architecture and application\nscenarios. However, the existing compilation framework doesn't meet these\nspecial instructions. Therefore, in the context of traditional Open64 compiler,\nproposed a special instruction algorithm. Through this algorithm implements the\nmultiplication-accumulation operation with BWDSP structure, to improve the\nperformance of algorithms with multiply-accumulate requirements. Experimental\nresults show that the algorithm, which can make an maximum of 8.85 speedup on\nBWDSP.\n",
        "pdf_link": "http://arxiv.org/pdf/1902.05982v1"
    },
    {
        "title": "Transfer and Online Reinforcement Learning in STT-MRAM Based Embedded\n  Systems for Autonomous Drones",
        "authors": [
            "Insik Yoon",
            "Aqeel Anwar",
            "Titash Rakshit",
            "Arijit Raychowdhury"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In this paper we present an algorithm-hardware codesign for camera-based\nautonomous flight in small drones. We show that the large write-latency and\nwrite-energy for nonvolatile memory (NVM) based embedded systems makes them\nunsuitable for real-time reinforcement learning (RL). We address this by\nperforming transfer learning (TL) on metaenvironments and RL on the last few\nlayers of a deep convolutional network. While the NVM stores the meta-model\nfrom TL, an on-die SRAM stores the weights of the last few layers. Thus all the\nreal-time updates via RL are carried out on the SRAM arrays. This provides us\nwith a practical platform with comparable performance as end-to-end RL and\n83.4% lower energy per image frame\n",
        "pdf_link": "http://arxiv.org/pdf/1905.06314v1"
    },
    {
        "title": "Definitively Identifying an Inherent Limitation to Actual Cognition",
        "authors": [
            "Arthur Charlesworth"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  A century ago, discoveries of a serious kind of logical error made separately\nby several leading mathematicians led to acceptance of a sharply enhanced\nstandard for rigor within what ultimately became the foundation for Computer\nScience. By 1931, Godel had obtained a definitive and remarkable result: an\ninherent limitation to that foundation. The resulting limitation is not\napplicable to actual human cognition, to even the smallest extent, unless both\nof these extremely brittle assumptions hold: humans are infallible reasoners\nand reason solely via formal inference rules. Both assumptions are contradicted\nby empirical data from well-known Cognitive Science experiments. This article\ninvestigates how a novel multi-part methodology recasts computability theory\nwithin Computer Science to obtain a definitive limitation whose application to\nhuman cognition avoids assumptions contradicting empirical data. The limitation\napplies to individual humans, to finite sets of humans, and more generally to\nany real-world entity.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.13010v2"
    },
    {
        "title": "Nonintrusive Load Monitoring for Machines used in Manufacturing",
        "authors": [
            "Christian Gebbe"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In order to increase the electric energy efficiency of production machines,\nit is necessary to determine the energy demand of the constituent electric\nloads. Therefore, a new measurement system based on nonintrusive load\nmonitoring is proposed in this paper. It only measures the voltage and current\nof the aggregate load and then uses automatic disaggregation methods to\nestimate the energy demand of the constituent loads. In two case studies, the\nenergy demand of most loads could be determined with an accuracy of 85~\\% or\nmore in this way.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.01500v1"
    },
    {
        "title": "High-Freedom Inverse Design with Deep Neural Network for Metasurface\n  Filter in the Visible",
        "authors": [
            "Xiao Han",
            "Ziyang Fan",
            "Chao Li",
            "Zeyang Liu",
            "L. Jay Guo"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In order to obtain a metasurface structure capable of filtering the light of\na specific wavelength in the visible band, traditional method usually traverses\nthe space consisting of possible designs, searching for a potentially\nsatisfying device by performing iterative calculations to solve Maxwell's\nequations. In this paper, we propose a neural network that can complete an\ninverse design process to solve the problem. Compared with the traditional\nmethod, our method is much faster while competent of generating better devices\nwith the desired spectrum. One of the most significant advantages is that it\ncan handle a real spectrum as well as an artificial one. Besides, our method\nencompasses a high degree of freedom to generate devices, ensuring their\ngenerated spectra resemble desired ones and meeting the accuracy requirements\nwithout losing practicability in the manufacturing process.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.03696v1"
    },
    {
        "title": "Estudo comparativo de meta-heursticas para problemas de\n  coloraes de grafos",
        "authors": [
            "Flvio Jos Mendes Coelho"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  A classic graph coloring problem is to assign colors to vertices of any graph\nso that distinct colors are assigned to adjacent vertices. Optimal graph\ncoloring colors a graph with a minimum number of colors, which is its chromatic\nnumber. Finding out the chromatic number is a combinatorial optimization\nproblem proven to be computationally intractable, which implies that no\nalgorithm that computes large instances of the problem in a reasonable time is\nknown. For this reason, approximate methods and metaheuristics form a set of\ntechniques that do not guarantee optimality but obtain good solutions in a\nreasonable time. This paper reports a comparative study of the Hill-Climbing,\nSimulated Annealing, Tabu Search, and Iterated Local Search metaheuristics for\nthe classic graph coloring problem considering its time efficiency for\nprocessing the DSJC125 and DSJC250 instances of the DIMACS benchmark.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.11533v1"
    },
    {
        "title": "Interactive distributed cloud-based web-server systems for the smart\n  healthcare industry",
        "authors": [
            "Almagul Baurzhanovna Kondybayeva"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The work aims to investigate the possible contemporary interactive cloud\nbased solutions in the fields of the applied medicine for the smart Healthcare\nas the data visualization open-source free system distributed under the MIT\nlicense. A comparative study of a number of the well-known implementations of\nthe Ray Casting algorithms was studied. A new method of numerical calculus is\nproposed for calculating the volume -- the method of spheres, as well as a\nproposal for paralleling the algorithm on graphic accelerators in a linearly\nhomogeneous computing environment using the block decomposition methods. For\nthe artifacts control -- algorithm of the cubic interpolation was used. The\ncloud server architecture was proposed.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.01442v1"
    },
    {
        "title": "AI in society and culture: decision making and values",
        "authors": [
            "Katalin Feher",
            "Asta Zelenkauskaite"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  With the increased expectation of artificial intelligence, academic research\nface complex questions of human-centred, responsible and trustworthy technology\nembedded into society and culture. Several academic debates, social\nconsultations and impact studies are available to reveal the key aspects of the\nchanging human-machine ecosystem. To contribute to these studies, hundreds of\nrelated academic sources are summarized below regarding AI-driven decisions and\nvaluable AI. In details, sociocultural filters, taxonomy of human-machine\ndecisions and perspectives of value-based AI are in the focus of this\nliterature review. For better understanding, it is proposed to invite\nstakeholders in the prepared large-scale survey about the next generation AI\nthat investigates issues that go beyond the technology.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.02777v1"
    },
    {
        "title": "Neighbourhood Evaluation Criteria for Vertex Cover Problem",
        "authors": [
            "Kaustubh K Joshi"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Neighbourhood Evaluation Criteria is a heuristical approximate algorithm that\nattempts to solve the Minimum Vertex Cover. degree count is kept in check for\neach vertex and the highest count based vertex is included in our cover set. In\nthe case of multiple equivalent vertices, the one with the lowest neighbourhood\ninfluence is selected. In the case of still existing multiple equivalent\nvertices, the one with the lowest remaining active vertex count (the highest\nIndependent Set enabling count) is selected as a tie-breaker.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.05065v1"
    },
    {
        "title": "System of Computer Modeling and Features of their use in the Educational\n  Process of General Secondary Eeducation",
        "authors": [
            "Svitlana H. Lytvynova"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The article analyzes the historical aspect of the formation of computer\nmodeling as one of the perspective directions of educational process\ndevelopment. The notion of \"system of computer modeling\", conceptual model of\nsystem of computer modeling (SCMod), its components (mathematical, animation,\ngraphic, strategic), functions, principles and purposes of use are grounded.\nThe features of the organization of students work using SCMod, individual and\ngroup work, the formation of subject competencies are described; the aspect of\nstudents' motivation to learning is considered. It is established that\neducational institutions can use SCMod at different levels and stages of\ntraining and in different contexts, which consist of interrelated physical,\nsocial, cultural and technological aspects. It is determined that the use of\nSCMod in general secondary school would increase the capacity of teachers to\nimprove the training of students in natural and mathematical subjects and\ncontribute to the individualization of the learning process, in order to meet\nthe pace, educational interests and capabilities of each particular student. It\nis substantiated that the use of SCMod in the study of natural-mathematical\nsubjects contributes to the formation of subject competencies, develops the\nskills of analysis and decision-making, increases the level of digital\ncommunication, develops vigilance, raises the level of knowledge, increases the\nduration of attention of students. Further research requires the justification\nof the process of forming students' competencies in natural-mathematical\nsubjects and designing cognitive tasks using SCMod.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.07552v1"
    },
    {
        "title": "A state of the art of urban reconstruction: street, street network,\n  vegetation, urban feature",
        "authors": [
            "Remi Cura",
            "Julien Perret",
            "Nicolas Paparoditis"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  World population is raising, especially the part of people living in cities.\nWith increased population and complex roles regarding their inhabitants and\ntheir surroundings, cities concentrate difficulties for design, planning and\nanalysis. These tasks require a way to reconstruct/model a city. Traditionally,\nmuch attention has been given to buildings reconstruction, yet an essential\npart of city were neglected: streets. Streets reconstruction has been seldom\nresearched. Streets are also complex compositions of urban features, and have a\nunique role for transportation (as they comprise roads). We aim at completing\nthe recent state of the art for building reconstruction (Musialski2012) by\nconsidering all other aspect of urban reconstruction. We introduce the need for\ncity models. Because reconstruction always necessitates data, we first analyse\nwhich data are available. We then expose a state of the art of street\nreconstruction, street network reconstruction, urban features\nreconstruction/modelling, vegetation , and urban objects\nreconstruction/modelling.\n  Although reconstruction strategies vary widely, we can order them by the role\nthe model plays, from data driven approach, to model-based approach, to inverse\nprocedural modelling and model catalogue matching. The main challenges seems to\ncome from the complex nature of urban environment and from the limitations of\nthe available data. Urban features have strong relationships, between them, and\nto their surrounding, as well as in hierarchical relations. Procedural\nmodelling has the power to express these relations, and could be applied to the\nreconstruction of urban features via the Inverse Procedural Modelling paradigm.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.04332v1"
    },
    {
        "title": "Algorithms Clearly Beat Gamers at Quantum Moves. A Verification",
        "authors": [
            "Allan Grnlund"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The paper [S{\\o}rensen et al., Nature 532] considers how human players\ncompare to algorithms for solving the Quantum Moves game BringHomeWater and\ndesign new algorithms based on the intuition extracted from players. The claim\nby [S{\\o}rensen et al., Nature 532] is that players outperform widely used\nalgorithms, in particular the KASS algorithm, based on the Krotov algorithm,\nand that player intuition is crucial to develop improved methods. However, as\ninitially discussed by D. Sels [D. Sels, Phys. Rev. A 97], a standard\nCoordinate Ascent algorithm outperforms all players by a large margin. Albeit\nD. Sels only compare to player solutions, the simple algorithm outperforms all\nalgorithms based on player solutions and Krotov, and it does so using much less\ntime and iterations. In this paper we elaborate on the methods discussed by D.\nSels and verify that the presented algorithm, solves the problem better than\nall players and algorithms derived from player solutions in [S{\\o}rensen et\nal., Nature 532]. We also verify the theoretical analysis presented by D. Sels,\nthat gives a theoretically derived protocol that outperforms all players. We\nadd a comparison with gradient ascent or GRAPE. Starting from uniform random\nvalues, GRAPE outperforms all players by a large margin. GRAPE works at least\nas well as the methods from [S{\\o}rensen et al., Nature 532] initialized with\nplayer solutions. A standard analysis of the results from GRAPE provides a\nstarting point for GRAPE, that outperform all algorithms from [S{\\o}rensen et\nal., Nature 532]. We compare with a basic Krotov algorithm, and get results\nsimilar to GRAPE, clearly outperforming players and the KASS algorithm. These\nexperiments verify and underline the result in [D. Sels, Phys. Rev. A 97] that\nthe conclusions from [S{\\o}rensen et al., Nature 532] regarding algorithms are\nuntenable. In fact the opposite conclusions are true.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.01008v4"
    },
    {
        "title": "MoA Interpretation of the Iterative Conjugate Gradient Method with Psi\n  Reduction - A Tutorial to teach the Mathematically literate in Linear and\n  Tensor Algebra: Part I",
        "authors": [
            "Lenore Mullin",
            "Paul Sebexen"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  It is often difficult to learn new mathematics semantically and\nsyntactically, even when there are similarities in the words and meaning when\ndiscussed aloud. The goal of this document is to facilitate learning through\nexplanations and definitions relating our common mathematical knowledge and\nhighlighting what is new. It is meant to be a working document that will evolve\nbased on feedback from target audiences, those mathematically literate in\nlinear and tensor algebra, those that want to learn MoA, Psi Calculus, and its\nuses, those that want and need the ability to prove a design, either in\nhardware or software through the ONF, Operational Normal Form, and those\nwanting to exploit all resources optimally, especially when Tensor Algebra,\ni.e. algorithms foundational to their application,are needed: Knowledge\nRepresentation, Machine Learning, Signal Processing, AI, HPC, etc.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.02612v1"
    },
    {
        "title": "Power and Thermal Analysis of Commercial Mobile Platforms: Experiments\n  and Case Studies",
        "authors": [
            "Ganapati Bhat",
            "Suat Gumussoy",
            "Umit Y. Ogras"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  State-of-the-art mobile processors can deliver fast response time and high\nthroughput to maximize the user experience. However, high performance comes at\nthe expense of larger power density, which leads to higher skin temperatures.\nSince this can degrade the user experience, there is a strong need for power\nconsumption and thermal analysis in mobile processors. In this paper, we first\nperform experiments on the Nexus 6P phone to study the power, performance and\nthermal behavior of modern smartphones. Using the insight from these\nexperiments, we propose a control algorithm that throttles select applications\nwithout affecting other apps. We demonstrate our governor on the Exynos 5422\nprocessor employed in the Odroid-XU3 board.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.09814v1"
    },
    {
        "title": "A Method for Expressing and Displaying the Vehicle Behavior Distribution\n  in Maintenance Work Zones",
        "authors": [
            "Qun Yang",
            "Zhepu Xu",
            "Saravanan Gurupackiam",
            "Ping Wang"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Maintenance work zones on the road network have impacts on the normal\ntravelling of vehicles, which increase the risk of traffic accidents. The\ntraffic characteristic analysis in maintenance work zones is a basis for\nmaintenance work zone related research such as layout design, traffic control\nand safety assessment. Due to the difficulty in vehicle microscopic behaviour\ndata acquisition, traditional traffic characteristic analysis mainly focuses on\nmacroscopic characteristics. With the development of data acquisition\ntechnology, it becomes much easier to obtain a large amount of microscopic\nbehaviour data nowadays, which lays a good foundation for analysing the traffic\ncharacteristics from a new point of view. This paper puts forward a method for\nexpressing and displaying the vehicle behaviour distribution in maintenance\nwork zones. Using portable vehicle microscopic behaviour data acquisition\ndevices, lots of data can be obtained. Based on this data, an endpoint\ndetection technology is used to automatically extract the segments in behaviour\ndata with violent fluctuations, which are segments where vehicles take\nbehaviours such as acceleration or turning. Using the support vector machine\nclassification method, the specific types of behaviours of the segments\nextracted can be identified, and together with a data combination method, a\ntotal of ten types of behaviours can be identified. Then the kernel density\nanalysis is used to cluster different types of behaviours of all passing\nvehicles to show the distribution on maps. By this method, how vehicles travel\nthrough maintenance work zones, and how different vehicle behaviours distribute\nin maintenance work zones can be displayed intuitively on maps, which is a\nnovel traffic characteristic and can shed light to maintenance work zone\nrelated researches such as safety assessment and design method.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.11786v1"
    },
    {
        "title": "PowerNet: Neural Power Demand Forecasting in Smart Grid",
        "authors": [
            "Yao Cheng",
            "Chang Xu",
            "Daisuke Mashima",
            "Vrizlynn L. L. Thing",
            "Yongdong Wu"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Power demand forecasting is a critical task for achieving efficiency and\nreliability in power grid operation. Accurate forecasting allows grid operators\nto better maintain the balance of supply and demand as well as to optimize\noperational cost for generation and transmission. This article proposes a novel\nneural network architecture PowerNet, which can incorporate multiple\nheterogeneous features, such as historical energy consumption data, weather\ndata, and calendar information, for the power demand forecasting task. Compared\nto two recent works based on Gradient Boosting Tree (GBT) and Support Vector\nRegression (SVR), PowerNet demonstrates a decrease of 33.3% and 14.3% in\nforecasting error, respectively. We further provide empirical results the two\noperational considerations that are crucial when using PowerNet in practice,\ni.e., how far in the future the model can forecast with a decent accuracy and\nhow often we should re-train the forecasting model to retain its modeling\ncapability. Finally, we briefly discuss a multilayer anomaly detection approach\nbased on PowerNet.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.11979v1"
    },
    {
        "title": "Simulation and Learning for Urban Mobility: City-scale Traffic\n  Reconstruction and Autonomous Driving",
        "authors": [
            "Weizi Li"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Traffic congestion has become one of the most critical issues worldwide. The\ncosts due to traffic gridlock and jams are approximately $160 billion in the\nUnited States, more than {\\pounds}13 billion in the United Kingdom, and over\none trillion dollars across the globe annually. As more metropolitan areas will\nexperience increasingly severe traffic conditions, the ability to analyze,\nunderstand, and improve traffic dynamics becomes critical. This dissertation is\nan effort towards achieving such an ability. I propose various techniques\ncombining simulation and machine learning to tackle the problem of traffic from\ntwo perspectives: city-scale traffic reconstruction and autonomous driving.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.06131v1"
    },
    {
        "title": "DNA based Network Model and Blockchain",
        "authors": [
            "A. M. El-Edkawy",
            "M. A. El-Dosuky",
            "Taher Hamza"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Biological cells can transmit, process and receive chemically encoded data in\nthe same way as network devices transmit, process, and receive digitally\nencoded data. Communication protocols have led to the rapid development of\ncomputer networks. Therefore, we need to develop communication protocols for\nbiological cell networks, which will lead to significant development,\nespecially in medical applications where surgery or delivery of drugs can be\nperformed using nanoscale devices. Blockchain is a peer-to-peer network that\ncontains a series of clusters to make a valid and secure transaction. Blockhain\ntechnology is used in many areas such as e-commerce, public services, security,\nfinance, Internet stuff, etc. Although blockchain has a major impact on\nInternet technology, it suffers from time problems and scalability. DNA\ncomputing is the execution of computations using natural molecules, especially\nDNA. DNA gaps above silicon because of massive parallelism, size and storage\ndensity. In this paper, biological cells and DNA are used to create the\nnecessary protocols for the networks to be used in the performance of the\ncell-based communication system. The proposed hybrid solution involves DNA as\nwell as calculated on an enzymatic basis, where each contributes to the\nfunction of a given protocol. Also a correspondence between blockchain and DNA\nis proposed that can be utilized to create DNA based blockchain.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.07829v1"
    },
    {
        "title": "How Downwards Causation Occurs in Digital Computers",
        "authors": [
            "George Ellis",
            "Barbara Drossel"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Digital computers carry out algorithms coded in high level programs. These\nabstract entities determine what happens at the physical level: they control\nwhether electrons flow through specific transistors at specific times or not,\nentailing downward causation in both the logical and implementation\nhierarchies. This paper explores how this is possible in the light of the\nalleged causal completeness of physics at the bottom level, and highlights the\nmechanism that enables strong emergence (the manifest causal effectiveness of\napplication programs) to occur. Although synchronic emergence of higher levels\nfrom lower levels is manifestly true, diachronic emergence is generically not\nthe case; indeed we give specific examples where it cannot occur because of the\ncausal effectiveness of higher level variables.\n",
        "pdf_link": "http://arxiv.org/pdf/1908.10186v2"
    },
    {
        "title": "CAN-D: A Modular Four-Step Pipeline for Comprehensively Decoding\n  Controller Area Network Data",
        "authors": [
            "Miki E. Verma",
            "Robert A. Bridges",
            "Jordan J. Sosnowski",
            "Samuel C. Hollifield",
            "Michael D. Iannacone"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  CANs are a broadcast protocol for real-time communication of critical vehicle\nsubsystems. Original equipment manufacturers of passenger vehicles hold secret\ntheir mappings of CAN data to vehicle signals, and these definitions vary\naccording to make, model, and year. Without these mappings, the wealth of\nreal-time vehicle information hidden in the CAN packets is uninterpretable,\nimpeding vehicle-related research. Guided by the 4-part CAN signal definition,\nwe present CAN-D (CAN-Decoder), a modular, 4-step pipeline for identifying each\nsignal's boundaries (start bit, length), endianness (byte order), signedness\n(bit-to-integer encoding), and by leveraging diagnostic standards, augmenting a\nsubset of the extracted signals with physical interpretation. We provide a\ncomprehensive review of the CAN signal reverse engineering research. Previous\nmethods ignore endianness and signedness, rendering them incapable of decoding\nmany standard CAN signal definitions. Incorporating endianness grows the search\nspace from 128 to 4.72E21 signal tokenizations and introduces a web of changing\ndependencies. We formulate, formally analyze, and provide an efficient solution\nto an optimization problem, allowing identification of the optimal set of\nsignal boundaries and byte orderings. We provide two novel, state-of-the-art\nsignal boundary classifiers-both superior to previous approaches in precision\nand recall in three different test scenarios-and the first signedness\nclassification algorithm which exhibits a $>$97\\% F-score. CAN-D is the only\nsolution with the potential to extract any CAN signal. In evaluation on 10\nvehicles, CAN-D's average $\\ell^1$ error is 5x better than all previous methods\nand exhibits lower ave. error, even when considering only signals that meet\nprior methods' assumptions. CAN-D is implemented in lightweight hardware,\nallowing for an OBD-II plugin for real-time in-vehicle CAN decoding.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.05993v2"
    },
    {
        "title": "Does Cascading Schmitt-Trigger Stages Improve the Metastable Behavior?",
        "authors": [
            "Andreas Steininger",
            "Robert Najvirt",
            "Jrgen Maier"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Schmitt-Trigger stages are the method of choice for robust discretization of\ninput voltages with excessive transition times or significant noise. However,\nthey may suffer from metastability. Based on the experience that the cascading\nof flip-flop stages yields a dramatic improvement of their overall\nmetastability hardness, in this paper we elaborate on the question whether the\ncascading of Schmitt-Trigger stages can obtain a similar gain. We perform a\ntheoretic analysis that is backed up by an existing metastability model for a\nsingle Schmitt-Trigger stage and elaborate some claims about the behavior of a\nSchmitt-Trigger cascade. These claims suggest that the occurrence of\nmetastability is indeed reduced from the first stage to the second which\nsuggests an improvement. On the downside, however, it becomes clear that\nmetastability can still not be completely ruled out, and in some cases the\nbehavior of the cascade may be less beneficial for a given application, e.g. by\nintroducing seemingly acausal transitions. We validate our findings by\nextensive HSPICE simulations in which we directly cover our most important\nclaims.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.08415v1"
    },
    {
        "title": "No Substitute for Functionalism -- A Reply to 'Falsification &\n  Consciousness'",
        "authors": [
            "Natesh Ganesh"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  In their paper 'Falsification and Consciousness' [1], Kleiner and Hoel\nintroduced a formal mathematical model of the process of generating observable\ndata from experiments and using that data to generate inferences and\npredictions onto an experience space. The resulting substitution argument built\non this framework was used to show that any theory of consciousness with\nindependent inference and prediction data are pre-falsified, if the inference\nreports are considered valid. If this argument does indeed pre-falsify many of\nthe leading theories of consciousness, it would indicate a fundamental problem\naffecting the field of consciousness as a whole that would require radical\nchanges to how consciousness science is performed. In this reply, the author\nwill identify avenues of expansion for the model proposed in [1], allowing us\nto distinguish between different types of variation. Motivated by examples from\nneural networks, state machines and Turing machines, we will prove that\nsubstitutions do not exist for a very broad class of Level-1 functionalist\ntheories, rendering them immune to the aforementioned substitution argument.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.13664v3"
    },
    {
        "title": "Efficient Metastability Characterization for Schmitt-Triggers",
        "authors": [
            "Jrgen Maier",
            "Andreas Steininger"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Despite their attractiveness as metastability filters, Schmitt-Triggers can\nsuffer from metastability themselves. Therefore, in the selection or\nconstruction of a suitable Schmitt-Trigger implementation, it is a necessity to\naccurately determine the metastable behavior. Only then one is able to compare\ndifferent designs and thus guide proper optimizations, and only then one can\nassess the potential for residual metastable upsets. However, while the state\nof the art provides a lot of research and practical characterization approaches\nfor flip-flops, comparatively little is known about Schmitt-Trigger\ncharacterization. Unlike the flip-flop with its single metastable point, the\nSchmitt-Trigger exhibits a whole range of metastable points depending on the\ninput voltage. Thus the task of characterization gets much more challenging.\n  In this paper we present different approaches to determine the metastable\nbehavior of Schmitt-Triggers using novel methods and mechanisms. We compare\ntheir accuracy and runtime by applying them to three common circuit\nimplementations. The achieved results are then used to reason about the\nmetastable behavior of the chosen designs which turns out to be problematic in\nsome cases. Overall the approaches proposed in this paper are generic and can\nbe extended beyond the Schmitt-Trigger, i.e., to efficiently characterize\nmetastable states in other circuits as well.\n",
        "pdf_link": "http://arxiv.org/pdf/2006.14001v1"
    },
    {
        "title": "An Event-Driven Framework for Business Awareness Management",
        "authors": [
            "Babis Magoutas",
            "Dimitris Apostolou",
            "Gregoris Mentzas"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Modern organizations need real-time awareness about the current business\nconditions and the various events that occur from multiple and heterogeneous\nenvironments and influence their business operations. Moreover, based on\nreal-time awareness they need a mechanism that allows them to respond quickly\nto the changing business conditions, in order to either avoid problematic\nsituations or exploit opportunities that may arise in their business\nenvironment. In this paper we present BEAM, an event-driven framework that\nenables awareness about the situations happening in business environments and\nincreases organizations responsiveness to them. We illustrate how BEAM\nincreases the awareness of managers about the running business processes, as\nwell as their flexibility by presenting a practical application of the\nframework in the transportation and logistics domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.02615v1"
    },
    {
        "title": "Looking for non-compliant documents using error messages from multiple\n  parsers",
        "authors": [
            "Michael Robinson"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Whether a file is accepted by a single parser is not a reliable indication of\nwhether a file complies with its stated format. Bugs within both the parser and\nthe format specification mean that a compliant file may fail to parse, or that\na non-compliant file might be read without any apparent trouble. The latter\nsituation presents a significant security risk, and should be avoided. This\narticle suggests that a better way to assess format specification compliance is\nto examine the set of error messages produced by a set of parsers rather than a\nsingle parser. If both a sample of compliant files and a sample of\nnon-compliant files are available, then we show how a statistical test based on\na pseudo-likelihood ratio can be very effective at determining a file's\ncompliance. Our method is format agnostic, and does not directly rely upon a\nformal specification of the format. Although this article focuses upon the case\nof the PDF format (ISO 32000-2), we make no attempt to use any specific details\nof the format. Furthermore, we show how principal components analysis can be\nuseful for a format specification designer to assess the quality and structure\nof these samples of files and parsers. While these tests are absolutely\nrudimentary, it appears that their use to measure file format variability and\nto identify non-compliant files is both novel and surprisingly effective.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.10211v1"
    },
    {
        "title": "GIS-Based Estimation of Seasonal Solar Energy Potential for Parking Lots\n  and Roads",
        "authors": [
            "Vishnu Mahesh Vivek Nanda",
            "Laura Tateosian",
            "Perver Baran"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The amount of sun cast on roads and parking lots determines the charging\nopportunities for solar vehicles and impacts the efficiency of conventional\nvehicles. Estimates of solar energy potential on urban surfaces to assess\nparking and driving conditions need to account for the shadows cast by\nsurrounding trees and buildings. However, though existing GIS tools can\ncalculate solar potential on surfaces that have buildings and trees, these\ntools do not estimate the conditions beneath trees and do not consider the\nseasonal changes in deciduous trees. We introduce a new approach to address\nthese factors using pixel substitution and a light penetration factor. In this\npaper, we describe how to integrate these techniques into a workflow for\ncomputing solar potential estimates for parking and driving conditions. We\ndemonstrate the methodology in an urban setting in North Carolina that includes\na mixture of urban structures and trees. We provide code samples so that this\nworkflow is easily repeatable. The solar maps produced with our method are a\nuseful resource for planning solar vehicle parking and routing, and identifying\nshaded conditions for conventional vehicles.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.13470v1"
    },
    {
        "title": "Exact and heuristic approaches for multi-objective garbage accumulation\n  points location in real scenarios",
        "authors": [
            "Diego Gabriel Rossit",
            "Jamal Toutouh",
            "Sergio Nesmachnow"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Municipal solid waste management is a major challenge for nowadays urban\nsocieties, because it accounts for a large proportion of public budget and,\nwhen mishandled, it can lead to environmental and social problems. This work\nfocuses on the problem of locating waste bins in an urban area, which is\nconsidered to have a strong influence in the overall efficiency of the reverse\nlogistic chain. This article contributes with an exact multiobjective approach\nto solve the waste bin location in which the optimization criteria that are\nconsidered are: the accessibility to the system (as quality of service\nmeasure), the investment cost, and the required frequency of waste removal from\nthe bins (as a proxy of the posterior routing costs). In this approach,\ndifferent methods to obtain the objectives ideal and nadir values over the\nPareto front are proposed and compared. Then, a family of heuristic methods\nbased on the PageRank algorithm is proposed which aims to optimize the\naccessibility to the system, the amount of collected waste and the installation\ncost. The experimental evaluation was performed on real-world scenarios of the\ncities of Montevideo, Uruguay, and Bah\\'ia Blanca, Argentina. The obtained\nresults show the competitiveness of the proposed approaches for constructing a\nset of candidate solutions that considers the different trade-offs between the\noptimization criteria.\n",
        "pdf_link": "http://arxiv.org/pdf/2103.04826v2"
    },
    {
        "title": "The Evolution of Real-time Remote Intraoperative Neurophysiological\n  Monitoring (IONM)",
        "authors": [
            "Jeffrey Balzer",
            "Julia Caviness",
            "Don Krieger"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Real-time monitoring of nervous system function with immediate communication\nof relevant information to the surgeon enables prevention and/or mitigation of\niatrogenic injury in many surgical procedures. The hardware and software\ninfrastructure and demonstrated usefulness of telemedicine in support of IONM\noriginated in a busy university health center environment and then spread\nwidely as comparable functional capabilities were added by commercial equipment\nmanufacturers. The earliest implementations included primitive data archival\nand case documentation capabilities and relied primarily on deidentification\nfor security. They emphasized full-featured control of the real-time data\ndisplay by remote observers. Today, remote IONM is routinely utilized in more\nthan 200,000 high-risk surgical procedures/year in the United States. For many\ncases, remote observers rely on screen capture to view the data as it is\ndisplayed in the remote operating room while providing sophisticated security\ncapabilities and data archival and standardized metadata and case\ndocumentation.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10225v1"
    },
    {
        "title": "Simulating City-level Airborne Infectious Diseases",
        "authors": [
            "Mei Shan",
            "Zhou Xuan",
            "Zhu Yifan",
            "Zu Zhenghu",
            "Zheng Tao",
            "A. V. Boukhanovsky",
            "P. M. A Sloot"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  With the exponential growth in the world population and the constant increase\nin human mobility, the danger of outbreaks of epidemics is rising. Especially\nin high density urban areas such as public transport and transfer points, where\npeople come in close proximity of each other, we observe a dramatic increase in\nthe transmission of airborne viruses and related pathogens. It is essential to\nhave a good understanding of the `transmission highways' in such areas, in\norder to prevent or to predict the spreading of infectious diseases. The\napproach we take is to combine as much information as is possible, from all\nrelevant sources and integrate this in a simulation environment that allows for\nscenario testing and decision support. In this paper we lay out a novel\napproach to study Urban Airborne Disease spreading by combining traffic\ninformation, with geo-spatial data, infection dynamics and spreading\ncharacteristics.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.0160v1"
    },
    {
        "title": "An Example for the Use of Bitwise Operations in Programming",
        "authors": [
            "Krasimir Yankov Yordzhev"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  This piece of work presents a meaningful example for the advantages of using\nbitwise operations for creating effective algorithms in programming. A task\nconnected with mathematical modeling in weaving industry is examined and\ncomputed.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.1468v1"
    },
    {
        "title": "On Some Entertaining Applications of the Concept of Set in Computer\n  Science Course",
        "authors": [
            "Krasimir Yordzhev",
            "Hristina Kostadinova"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Some aspects of programming education are examined in this work. It is\nemphasised, based on the entertainment value, the most appropriate examples are\nchosen to demonstrate the different language constructions and data structures.\nSuch an example is the demonstrated algorithm for solving the widespread\nnowadays \"Sudoku\" puzzle. This is made, because of the connection with the term\nset and putting it into practice in the programming. Using the so built program\nthere are solved some combinatorial problems, connected to the Sudoku matrices.\n  Key words: Education in programming, programming languages, data structures,\nset, Sudoku matrix, Sudoku puzzle.\n",
        "pdf_link": "http://arxiv.org/pdf/1201.3457v1"
    },
    {
        "title": "The Knowledge-Based Economy and the Triple Helix Model",
        "authors": [
            "Loet Leydesdorff"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  1. Introduction - the metaphor of a \"knowledge-based economy\"; 2. The Triple\nHelix as a model of the knowledge-based economy; 3. Knowledge as a social\ncoordination mechanism; 4. Neo-evolutionary dynamics in a Triple Helix of\ncoordination mechanism; 5. The operation of the knowledge base; 6. The\nrestructuring of knowledge production in a KBE; 7. The KBE and the\nsystems-of-innovation approach; 8. The KBE and neo-evolutionary theories of\ninnovation; 8.1 The construction of the evolving unit; 8.2 User-producer\nrelations in systems of innovation; 8.3 'Mode-2' and the production of\nscientific knowledge; 8.4 A Triple Helix model of innovations; 9. Empirical\nstudies and simulations using the TH model; 10. The KBE and the measurement;\n10.1 The communication of meaning and information; 10.2 The expectation of\nsocial structure; 10.3 Configurations in a knowledge-based economy\n",
        "pdf_link": "http://arxiv.org/pdf/1201.4553v1"
    },
    {
        "title": "Real-Time Estimation of the Distribution of Brake Response Times for an\n  Individual Driver Using Vehicular Ad Hoc Network",
        "authors": [
            "Ali Rakhshan",
            "Evan Ray",
            "Hossein Pishro-Nik"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Adapting the functioning of the collision warning systems to the specific\ndrivers' characteristics is of great benefit to drivers. For example, by\ncustomizing collision warning algorithms we can minimize false alarms, thereby\nreducing injuries and deaths in highway traffic accidents. In order to take the\nbehaviors of individual drivers into account, the system needs to have a\nReal-Time estimation of the distribution of brake response times for an\nindividual driver. In this paper, we propose a method for doing this estimation\nwhich is not computationally intensive and can take advantage of the\ninformation contained in all data points.\n",
        "pdf_link": "http://arxiv.org/pdf/1405.6161v1"
    },
    {
        "title": "A Wavelet Based Algorithm for the Identification of Oscillatory\n  Event-Related Potential Components",
        "authors": [
            "Arun Kumar A",
            "Ninan Sajeeth Philip",
            "Vincent J Samar",
            "James A Desjardins",
            "Sidney J Segalowitz"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  Event Related Potentials (ERPs) are very feeble alterations in the ongoing\nElectroencephalogram (EEG) and their detection is a challenging problem. Based\non the unique time-based parameters derived from wavelet coefficients and the\nasymmetry property of wavelets a novel algorithm to separate ERP components in\nsingle-trial EEG data is described. Though illustrated as a specific\napplication to N170 ERP detection, the algorithm is a generalized approach that\ncan be easily adapted to isolate different kinds of ERP components. The\nalgorithm detected the N170 ERP component with a high level of accuracy. We\ndemonstrate that the asymmetry method is more accurate than the matching\nwavelet algorithm and t-CWT method by 48.67 and 8.03 percent respectively. This\npaper provides an off-line demonstration of the algorithm and considers issues\nrelated to the extension of the algorithm to real-time applications.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.2227v1"
    },
    {
        "title": "Compressive Periodogram Reconstruction Using Uniform Binning",
        "authors": [
            "Dyonisius Dony Ariananda",
            "Daniel Romero",
            "Geert Leus"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  In this paper, two problems that show great similarities are examined. The\nfirst problem is the reconstruction of the angular-domain periodogram from\nspatial-domain signals received at different time indices. The second one is\nthe reconstruction of the frequency-domain periodogram from time-domain signals\nreceived at different wireless sensors. We split the entire angular or\nfrequency band into uniform bins. The bin size is set such that the received\nspectra at two frequencies or angles, whose distance is equal to or larger than\nthe size of a bin, are uncorrelated. These problems in the two different\ndomains lead to a similar circulant structure in the so-called coset\ncorrelation matrix. This circulant structure allows for a strong compression\nand a simple least-squares reconstruction method. The latter is possible under\nthe full column rank condition of the system matrix, which can be achieved by\ndesigning the spatial or temporal sampling patterns based on a circular sparse\nruler. We analyze the statistical performance of the compressively\nreconstructed periodogram including bias and variance. We further consider the\ncase when the bins are so small that the received spectra at two frequencies or\nangles, with a spacing between them larger than the size of the bin, can still\nbe correlated. In this case, the resulting coset correlation matrix is\ngenerally not circulant and thus a special approach is required.\n",
        "pdf_link": "http://arxiv.org/pdf/1407.4017v2"
    },
    {
        "title": "Time-Symmetric Physics: A Radical Approach to the Decoherence Problem",
        "authors": [
            "Paul J. Werbos"
        ],
        "category": "cs.OH",
        "published_year": "2014",
        "summary": "  The most powerful form of quantum learning system possible would somehow\nlearn the parameters W of a quantum system f(X, W), for f representing the\nlargest, most powerful set of possible input-output relations. This paper\naddresses the issue of how to enlarge the set represented by f, by using a new\nformulation of time-symmetric physics to model analog quantum computers based\non spin and by exploring possible sources of backwards-time free energy so as\nto address problems of decoherence and dissipation.\n",
        "pdf_link": "http://arxiv.org/pdf/1501.00027v1"
    },
    {
        "title": "Analyzing In-Game Movements of Soccer Players at Scale",
        "authors": [
            "Laszlo Gyarmati",
            "Mohamed Hefeeda"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  It is challenging to get access to datasets related to the physical\nperformance of soccer players. The teams consider such information highly\nconfidential, especially if it covers in-game performance.Hence, most of the\nanalysis and evaluation of the players' performance do not contain much\ninformation on the physical aspect of the game, creating a blindspot in\nperformance analysis. We propose a novel method to solve this issue by deriving\nmovement characteristics of soccer players. We use event-based datasets from\ndata provider companies covering 50+ soccer leagues allowing us to analyze the\nmovement profiles of potentially tens of thousands of players without any major\ninvestment. Our methodology does not require expensive, dedicated player\ntracking system deployed in the stadium. We also compute the similarity of the\nplayers based on their movement characteristics and as such identify potential\ncandidates who may be able to replace a given player. Finally, we quantify the\nuniqueness and consistency of players in terms of their in-game movements. Our\nstudy is the first of its kind that focuses on the movements of soccer players\nat scale, while it derives novel, actionable insights for the soccer industry\nfrom event-based datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1603.05583v1"
    },
    {
        "title": "Towards a characterization of the uncertainty curve for graphs",
        "authors": [
            "Bastien Pasdeloup",
            "Vincent Gripon",
            "Grgoire Mercier",
            "Dominique Pastor"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  Signal processing on graphs is a recent research domain that aims at\ngeneralizing classical tools in signal processing, in order to analyze signals\nevolving on complex domains. Such domains are represented by graphs, for which\none can compute a particular matrix, called the normalized Laplacian. It was\nshown that the eigenvalues of this Laplacian correspond to the frequencies of\nthe Fourier domain in classical signal processing. Therefore, the frequency\ndomain is not the same for every support graph. A consequence of this is that\nthere is no non-trivial generalization of Heisenberg's uncertainty principle,\nthat states that a signal cannot be fully localized both in the time domain and\nin the frequency domain. A way to generalize this principle, introduced by\nAgaskar and Lu, consists in determining a curve that represents a lower bound\non the compromise between precision in the graph domain and precision in the\nspectral domain. The aim of this paper is to propose a characterization of the\nsignals achieving this curve, for a larger class of graphs than the one studied\nby Agaskar and Lu.\n",
        "pdf_link": "http://arxiv.org/pdf/1605.00451v1"
    },
    {
        "title": "Smart Asset Management for Electric Utilities: Big Data and Future",
        "authors": [
            "Swasti R. Khuntia",
            "Jose L. Rueda",
            "Mart A. M. M. van der Meijden"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  This paper discusses about future challenges in terms of big data and new\ntechnologies. Utilities have been collecting data in large amounts but they are\nhardly utilized because they are huge in amount and also there is uncertainty\nassociated with it. Condition monitoring of assets collects large amounts of\ndata during daily operations. The question arises \"How to extract information\nfrom large chunk of data?\" The concept of \"rich data and poor information\" is\nbeing challenged by big data analytics with advent of machine learning\ntechniques. Along with technological advancements like Internet of Things\n(IoT), big data analytics will play an important role for electric utilities.\nIn this paper, challenges are answered by pathways and guidelines to make the\ncurrent asset management practices smarter for the future.\n",
        "pdf_link": "http://arxiv.org/pdf/1706.09711v2"
    },
    {
        "title": "The system of cloud oriented learning tools as an element of educational\n  and scientific environment of high school",
        "authors": [
            "Andrii M. Striuk",
            "Maryna V. Rassovytska"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The aim of this research is to design and implementation of cloud based\nlearning environment for separate division of the university. The analysis of\nexisting approaches to the construction of cloud based learning environments,\nthe formation of requirements cloud based learning tools, the selection on the\nbasis of these requirements, cloud ICT training and pilot their use for\nbuilding cloud based learning environment for separate division of the\nuniversity with the use of open source software and resources its own IT\ninfrastructure of the institution. Results of the study is planned to\ngeneralize to develop recommendations for the design of cloud based environment\nof high school.\n",
        "pdf_link": "http://arxiv.org/pdf/1808.02081v1"
    },
    {
        "title": "ACTT: Automotive CAN Tokenization and Translation",
        "authors": [
            "Miki E. Verma",
            "Robert A. Bridges",
            "Samuel C. Hollifield"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  Modern vehicles contain scores of Electrical Control Units (ECUs) that\nbroadcast messages over a Controller Area Network (CAN). Vehicle manufacturers\nrely on security through obscurity by concealing their unique mapping of CAN\nmessages to vehicle functions which differs for each make, model, year, and\neven trim. This poses a major obstacle for after-market modifications notably\nperformance tuning and in-vehicle network security measures. We present ACTT:\nAutomotive CAN Tokenization and Translation, a novel, vehicle-agnostic,\nalgorithm that leverages available diagnostic information to parse CAN data\ninto meaningful messages, simultaneously cutting binary messages into tokens,\nand learning the translation to map these contiguous bits to the value of the\nvehicle function communicated.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.07897v1"
    },
    {
        "title": "Design paradigms of intelligent control systems on a chip",
        "authors": [
            "K. M. Deliparaschos",
            "S. G. Tzafestas"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This paper focuses on the Field Programmable Gate Array (FPGA) design and\nimplementation of intelligent control system applications on a chip,\nspecifically fuzzy logic and genetic algorithm processing units. Initially, an\noverview of the FPGA technology is presented, followed by design methodologies,\ndevelopment tools and the use of hardware description languages (HDL). Two FPGA\ndesign examples with the use of Hardware Description Languages (HDLs) of\nparameterized fuzzy logic controller cores are discussed. Thereinafter, a\nSystem-on-a-Chip (SoC) designed by the authors in previous work and realized on\nFPGA featuring a Digital Fuzzy Logic Controller (DFLC) and a soft processor\ncore for the path tracking problem of mobile robots is discussed. Finally a\nGenetic Algorithm implementation (previously published by the authors) in FPGA\nchip for the Traveling Salesman Problem (TSP) is also discussed.\n",
        "pdf_link": "http://arxiv.org/pdf/1811.08426v1"
    },
    {
        "title": "Towards Approximate Mobile Computing",
        "authors": [
            "Veljko Pejovic"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Mobile computing is one of the main drivers of innovation, yet the future\ngrowth of mobile computing capabilities remains critically threatened by\nhardware constraints, such as the already extremely dense transistor packing\nand limited battery capacity. The breakdown of Dennard scaling and stagnating\nenergy storage improvements further amplify these threats. However, the\ncomputational burden we put on our mobile devices is not always justified. In a\nmyriad of situations the result of a computation is further manipulated,\ninterpreted, and finally acted upon. This allows for the computation to be\nrelaxed, so that the result is calculated with \"good enough\", not perfect\naccuracy. For example, results of a Web search may be perfectly acceptable even\nif the order of the last few listed items is shuffled, as an end user decides\nwhich of the available links to follow. Similarly, the quality of a\nvoice-over-IP call may be acceptable, despite being imperfect, as long as the\ntwo involved parties can clearly understand each other. This novel way of\nthinking about computation is termed Approximate Computing (AC) and promises to\nreduce resource usage, while ensuring that satisfactory performance is\ndelivered to end-users. AC is already experimented with on various levels of\ndesktop computer architecture, from the hardware level where incorrect adders\nhave been designed to sacrifice result correctness for reduced energy\nconsumption, to compiler-level optimisations that omit certain lines of code to\nspeed up video encoding. AC is yet to be attempted on mobile devices and in\nthis article we examine the potential benefits of mobile AC and present an\noverview of AC techniques applicable in the mobile domain.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.08972v1"
    },
    {
        "title": "SysMART Outdoor Services: A System of Connected and Smart Supermarkets",
        "authors": [
            "Yazan Mohamad",
            "Majd Makdessi",
            "Omar Raad",
            "Issam Damaj"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Smart cities are today's modern trend. Many high-tech industrial firms are\nexploring different approaches to implement smart cities. Various projects aim\nat internet-of-things and smart solutions. Current implementations are mostly\nlocalized to a specific building or area; however, the growth is crossing space\nand geographic location limits. Shopping is a central activity that is frequent\nand typically a time-consuming task. SysMART is system of connected and smart\nsupermarkets. SysMART enables a plausible shopping experience for customers.\nThe aim of SysMART is to provide an advanced lifestyle with its ease of use\nfunctionality. SysMART outdoor services support distant parking availability,\ntraffic status, and remote inventory checks for supermarkets in a chain.\nSysMART implementation relies on cutting edge technologies that support rapid\nprototyping and precision data acquisition, such as, National Instrument\ndevices. The selected development environment is LabView with its world-class\ninterfacing libraries. The paper comprises a detailed system description,\ndevelopment strategy, interface design, software engineering, and a thorough\nanalysis and evaluation.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.12407v1"
    },
    {
        "title": "A Self-Healing Hardware Architecture for Safety-Critical Digital\n  Embedded Devices",
        "authors": [
            "Shawkat Sabah Khairullah"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Digital Embedded Devices of next-generation safety-critical industrial\nautomation systems require high levels of survivability and resilience against\nthe hardware and software failure. One of the concepts for achieving this\nrequirement is the design of resilient and survivable digital embedded systems.\nIn the last two decades, development of self-healing digital systems based on\nmolecular and cellular biology have received attention for the design of robust\ndigital systems. However, many of these approaches have not been architected\nfrom the outset with safety in mind, nor have they been targeted for the\napplications of automation community where a significant need exists. This\npaper presents a new self-healing hardware architecture, inspired from the way\nnature responds, defends and heals: the stem cells in the immune system of\nliving organisms, the life cycle of the living cell, and the pathway from\nDeoxyribonucleic acid (DNA) to protein. The proposed architecture is\nintegrating cellular-based biological concepts, traditional fault tolerance\ntechniques, and operational schematics for the international standard IEC\n61131-3 to facilitate adoption in the automation industry and safety-critical\napplications. To date, two industrial applications have been mapped on the\nproposed architecture, which are capable of tolerating a significant number of\nfaults that can stem from harsh environmental changes and external disturbances\nand we believe the nexus of its concepts can positively impact the next\ngeneration of critical systems in the automation industry\n",
        "pdf_link": "http://arxiv.org/pdf/1910.00064v1"
    },
    {
        "title": "Detection of fraudulent users in P2P financial market",
        "authors": [
            "Hao Wang"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Financial fraud detection is one of the core technological assets of Fintech\ncompanies. It saves tens of millions of money fro m Chinese Fintech companies\nsince the bad loan rate is more than 10%. HC Financial Service Group is the 3rd\nlargest company in the Chinese P2P financial market. In this paper we\nillustrate how we tackle the fraud detection problem at HC Financial. We\nutilize two powerful workhorses in the machine learning field - random forest\nand gradient boosting decision tree to detect fraudulent users . We demonstrate\nthat by carefully select features and tune model parameters , we could\neffectively filter out fraudulent users in the P2P market.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.02010v1"
    },
    {
        "title": "The Open Porous Media Flow Reservoir Simulator",
        "authors": [
            "Atgeirr Fl Rasmussen",
            "Tor Harald Sandve",
            "Kai Bao",
            "Andreas Lauser",
            "Joakim Hove",
            "Brd Skaflestad",
            "Robert Klfkorn",
            "Markus Blatt",
            "Alf Birger Rustad",
            "Ove Svareid",
            "Knut-Andreas Lie",
            "Andreas Thune"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The Open Porous Media (OPM) initiative is a community effort that encourages\nopen innovation and reproducible research for simulation of porous media\nprocesses. OPM coordinates collaborative software development, maintains and\ndistributes open-source software and open data sets, and seeks to ensure that\nthese are available under a free license in a long-term perspective.\n  In this paper, we present OPM Flow, which is a reservoir simulator developed\nfor industrial use, as well as some of the individual components used to make\nOPM Flow. The descriptions apply to the 2019.10 release of OPM.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.06059v1"
    },
    {
        "title": "GeoSES -- um ndice Socioeconmico para Estudos de Sade no Brasil",
        "authors": [
            "Ligia Vizeu Barrozo",
            "Michel Fornaciali",
            "Carmen Diva Saldiva de Andr",
            "Guilherme Augusto Zimeo Morais",
            "Giselle Mansur",
            "William Cabral-Miranda",
            "Joo Ricardo Sato",
            "Edson Amaro Jnior"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Objective: to define an index that summarizes the main dimensions of the\nsocioeconomic context for research purposes, evaluation and monitoring health\ninequalities. Methods: the index was created from the 2010 Brazilian\nDemographic Census, whose variables selection was guided by theoretical\nreferences for health studies, including seven socioeconomic dimensions:\neducation, mobility, poverty, wealth, income, segregation and deprivation of\nresources and services. The index was developed using principal component\nanalysis, and was evaluated for its construct, content and applicability\ncomponents. Results: GeoSES-BR dimensions showed good association with HDI-M\n(above 0.85). The model with the poverty dimension best explained the relative\nrisk of avoidable cause mortality in Brazil. In the intraurban scale, the model\nwith GeoSES-IM was the one that best explained the relative risk of mortality\nfrom circulatory system diseases. Conclusion: GeoSES showed significant\nexplanatory potential in the studied scales.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.06155v1"
    },
    {
        "title": "Predicting Memory Compiler Performance Outputs using Feed-Forward Neural\n  Networks",
        "authors": [
            "Felix Last",
            "Max Haeberlein",
            "Ulf Schlichtmann"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Typical semiconductor chips include thousands of mostly small memories. As\nmemories contribute an estimated 25% to 40% to the overall power, performance,\nand area (PPA) of a chip, memories must be designed carefully to meet the\nsystem's requirements. Memory arrays are highly uniform and can be described by\napproximately 10 parameters depending mostly on the complexity of the\nperiphery. Thus, to improve PPA utilization, memories are typically generated\nby memory compilers. A key task in the design flow of a chip is to find optimal\nmemory compiler parametrizations which on the one hand fulfill system\nrequirements while on the other hand optimize PPA. Although most compiler\nvendors also provide optimizers for this task, these are often slow or\ninaccurate. To enable efficient optimization in spite of long compiler run\ntimes, we propose training fully connected feed-forward neural networks to\npredict PPA outputs given a memory compiler parametrization. Using an\nexhaustive search-based optimizer framework which obtains neural network\npredictions, PPA-optimal parametrizations are found within seconds after chip\ndesigners have specified their requirements. Average model prediction errors of\nless than 3%, a decision reliability of over 99% and productive usage of the\noptimizer for successful, large volume chip design projects illustrate the\neffectiveness of the approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.03269v1"
    },
    {
        "title": "Toward a Wearable RFID System for Real-Time Activity Recognition Using\n  Radio Patterns",
        "authors": [
            "Liang Wang",
            "Tao Gu",
            "Xianping Tao",
            "Jian Lu"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Elderly care is one of the many applications supported by real-time activity\nrecognition systems. Traditional approaches use cameras, body sensor networks,\nor radio patterns from various sources for activity recognition. However, these\napproaches are limited due to ease-of-use, coverage, or privacy preserving\nissues. In this paper, we present a novel wearable Radio Frequency\nIdentification (RFID) system aims at providing an easy-to-use solution with\nhigh detection coverage. Our system uses passive tags which are\nmaintenance-free and can be embedded into the clothes to reduce the wearing and\nmaintenance efforts. A small RFID reader is also worn on the user's body to\nextend the detection coverage as the user moves. We exploit RFID radio patterns\nand extract both spatial and temporal features to characterize various\nactivities. We also address the issues of false negative of tag readings and\ntag/antenna calibration, and design a fast online recognition system. Antenna\nand tag selection is done automatically to explore the minimum number of\ndevices required to achieve target accuracy. We develop a prototype system\nwhich consists of a wearable RFID system and a smartphone to demonstrate the\nworking principles, and conduct experimental studies with four subjects over\ntwo weeks. The results show that our system achieves a high recognition\naccuracy of 93.6 percent with a latency of 5 seconds. Additionally, we show\nthat the system only requires two antennas and four tagged body parts to\nachieve a high recognition accuracy of 85 percent.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.07719v1"
    },
    {
        "title": "Modeling and solving a vehicle-sharing problem considering multiple\n  alternative modes of transport",
        "authors": [
            "Miriam Enzi",
            "Sophie N. Parragh",
            "David Pisinger"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Motivated by the change in mobility patterns, we present a scheduling\napproach for a vehicle-sharing problem, considering several alternative modes\nof transport, from a company viewpoint with centralized planning. We consider\nvehicle-sharing in a company having one or more depots and a fixed number of\nusers, i.e. employees. The users have appointments with a fixed location and\nfixed start and end times. A vehicle must be used for a full trip of a user\nfrom depot to depot. We aim at assigning vehicles to user trips so as to\nmaximize savings compared to other modes of transport. We first consider that\nonly one type of vehicle is used, and second that multiple vehicle types can be\nused. For the first case, we show that the vehicle-sharing problem can be\nformulated as a minimum-cost flow problem. Secondly, if multiple types of\nvehicles are available the problem can be formulated as a multi-commodity flow\nproblem. These formulations make the problem applicable in daily operations due\nto efficient solution methods. We provide a comprehensive computational study\nfor both cases on instances based on demographic, spatial, and economic data of\nVienna. We show that our formulations for this problem solve these instances in\na few seconds, which makes them usable in an online booking system. In the\nanalysis we discuss different potential settings. We study the optimal\ncomposition of a shared fleet, restricted sets of modes of transport, and\nvariations of the objective function.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.08207v2"
    },
    {
        "title": "Reconfigurable Computing Applied to Latency Reduction for the Tactile\n  Internet",
        "authors": [
            "Jos C. V. S. Junior",
            "Matheus F. Torquato",
            "Toktam Mahmoodi",
            "Mischa Dohler",
            "Marcelo A. C. Fernandes"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Tactile internet applications allow robotic devices to be remotely controlled\nover a communication medium with an unnoticeable time delay. In a bilateral\ncommunication, the acceptable round trip latency is usually in the order of 1ms\nup to 10ms depending on the application requirements. It is estimated that 70%\nof the total latency is generated by the communication network, and the\nremaining 30% is produced by master and slave devices. Thus, this paper aims to\npropose a strategy to reduce 30% of the total latency that is produced by such\ndevices. The strategy is to apply reconfigurable computation using FPGAs to\nminimize the execution time of device-associated algorithms. With this in mind,\nthis work presents a hardware reference model for modules that implement\nnonlinear positioning and force calculations as well as a tactile system formed\nby two robotic manipulators. In addition to presenting the implementation\ndetails, simulations and experimental tests are performed in order to validate\nthe proposed model. Results associated with the FPGA sampling rate, throughput,\nlatency, and post-synthesis occupancy area are analyzed.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.12463v1"
    },
    {
        "title": "Quantum Approximation for Wireless Scheduling",
        "authors": [
            "Jaeho Choi",
            "Seunghyeok Oh",
            "Joongheon Kim"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  This paper proposes a quantum approximate optimization algorithm (QAOA)\nmethod for wireless scheduling problems. The QAOA is one of the promising\nhybrid quantum-classical algorithms for many applications and it provides\nhighly accurate optimization solutions in NP-hard problems. QAOA maps the given\nproblems into Hilbert spaces, and then it generates Hamiltonian for the given\nobjectives and constraints. Then, QAOA finds proper parameters from classical\noptimization approaches in order to optimize the expectation value of generated\nHamiltonian. Based on the parameters, the optimal solution to the given problem\ncan be obtained from the optimum of the expectation value of Hamiltonian.\nInspired by QAOA, a quantum approximate optimization for scheduling (QAOS)\nalgorithm is proposed. First of all, this paper formulates a wireless\nscheduling problem using maximum weight independent set (MWIS). Then, for the\ngiven MWIS, the proposed QAOS designs the Hamiltonian of the problem. After\nthat, the iterative QAOS sequence solves the wireless scheduling problem. This\npaper verifies the novelty of the proposed QAOS via simulations implemented by\nCirq and TensorFlow-Quantum.\n",
        "pdf_link": "http://arxiv.org/pdf/2004.11229v2"
    },
    {
        "title": "Privacy vs National Security",
        "authors": [
            "Tajdar Jawaid"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  There are growing concerns and anxiety about privacy among the general public\nespecially after the revelations of former NSA contractor and whistleblowers\nlike Edward Snowden and others. While privacy is the fundamental concept of\nbeing human, the growing tug-of-war between an individuals privacy and freedom\nvs national security has renewed the concerns about where the fine balance\nshould lie between the two. For the first time in history the technological\nadvancement has made the mass data gathering, analysis, and storage a\nfinancially and technologically feasible option for the governments and private\nbusinesses. This has led to the growing interest of governments and security\nagencies around the globe to develop sophisticated algorithms using the power\nof Big-Data, Machine-Learning and Artificial Intelligence. The technology has\nenabled governments and private businesses to collect and store thousands of\ndata points on every individual, which has put an individuals privacy under\nconstant threat. This article analyses the individual's privacy concepts and\nits perceived link with national security. The article will also discuss the\nvarious aspects of privacy and national-security, arguments of both sides and\nwhere a boundary should be drawn between privacy and national security.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.12633v1"
    },
    {
        "title": "Comparison Analysis of Tree Based and Ensembled Regression Algorithms\n  for Traffic Accident Severity Prediction",
        "authors": [
            "Muhammad Umer",
            "Saima Sadiq",
            "Abid Ishaq",
            "Saleem Ullah",
            "Najia Saher",
            "Hamza Ahmad Madni"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Rapid increase of traffic volume on urban roads over time has changed the\ntraffic scenario globally. It has also increased the ratio of road accidents\nthat can be severe and fatal in the worst case. To improve traffic safety and\nits management on urban roads, there is a need for prediction of severity level\nof accidents. Various machine learning models are being used for accident\nprediction. In this study, tree based ensemble models (Random Forest, AdaBoost,\nExtra Tree, and Gradient Boosting) and ensemble of two statistical models\n(Logistic Regression Stochastic Gradient Descent) as voting classifiers are\ncompared for prediction of road accident severity. Significant features that\nare strongly correlated with the accident severity are identified by Random\nForest. Analysis proved Random Forest as the best performing model with highest\nclassification results with 0.974 accuracy, 0.954 precision, 0.930 recall and\n0.942 F-score using 20 most significant features as compared to other\ntechniques classification of road accidents severity.\n",
        "pdf_link": "http://arxiv.org/pdf/2010.14921v1"
    },
    {
        "title": "Impacts of the Space Technology Evolution in the V\\&V of Embedded\n  Software-Intensive Systems",
        "authors": [
            "Carlos Leandro Gomes Batista",
            "Tania Basso",
            "Ftima Mattiello-Francisco",
            "Regina Moraes"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  CubeSat-based nanosatellites are composed of COTS components and rely on its\nstructure and standardized interfaces. A challenge in the nanosatellites\ncontext is to adapt the V\\&V (Verification and Validation) process to answer to\nthe increase importance of the embedded software, to reduce the artefacts to be\ndelivered aiming at cutting cost and time and still complying with\ninternational standards. This work presents an analysis of the strategy adopted\nin a real nanosatellite for the development of the OBDH software embedded in\nNanosatC-BR2 mission. The goal is to discuss the impact that the\nstandardization of the structure and interfaces of the CubeSat impose on the\nV\\&V process of the SiS and to highlight the challenges of ``New Space Age``\nfor the use of existing V\\&V techniques and methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.14914v1"
    },
    {
        "title": "SEH: Size Estimate Hedging for Single-Server Queues",
        "authors": [
            "Maryam Akbari-Moghaddam",
            "Douglas G. Down"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  For a single server system, Shortest Remaining Processing Time (SRPT) is an\noptimal size-based policy. In this paper, we discuss scheduling a single-server\nsystem when exact information about the jobs' processing times is not\navailable. When the SRPT policy uses estimated processing times, the\nunderestimation of large jobs can significantly degrade performance. We propose\na simple heuristic, Size Estimate Hedging (SEH), that only uses estimated\nprocessing times for scheduling decisions. A job's priority is increased\ndynamically according to an SRPT rule until it is determined that it is\nunderestimated, at which time the priority is frozen. Numerical results suggest\nthat SEH has desirable performance for estimation error variance that is\nconsistent with what is seen in practice.\n",
        "pdf_link": "http://arxiv.org/pdf/2101.00007v5"
    },
    {
        "title": "A Composable Glitch-Aware Delay Model",
        "authors": [
            "Jrgen Maier",
            "Daniel hlinger",
            "Ulrich Schmid",
            "Matthias Fgger",
            "Thomas Nowak"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  We introduce the Composable Involution Delay Model (CIDM) for fast and\naccurate digital simulation. It is based on the Involution Delay Model (IDM)\n[F\\\"ugger et al., IEEE TCAD 2020], which has been shown to be the only existing\ncandidate for faithful glitch propagation known so far. In its present form,\nhowever, it has shortcomings that limit its practical applicability and\nutility. First, IDM delay predictions are conceptually based on discretizing\nthe analog signal waveforms using specific matching input and output\ndiscretization threshold voltages. Unfortunately, they are difficult to\ndetermine and typically different for interconnected gates. Second,\nmetastability and high-frequency oscillations in a real circuit could be\ninvisible in the IDM signal predictions. Our CIDM reduces the characterization\neffort by allowing independent discretization thresholds, improves\ncomposability and increases the modeling power by exposing canceled pulse\ntrains at the gate interconnect. We formally show that, despite these\nimprovements, the CIDM still retains the IDM's faithfulness, which is a\nconsequence of the mathematical properties of involution delay functions.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.10966v1"
    },
    {
        "title": "Optimal Seat Allocation Under Social Distancing Constraints",
        "authors": [
            "Michael Barry",
            "Claudio Gambella",
            "Fabio Lorenzi",
            "John Sheehan",
            "Joern Ploennigs"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  The Covid-19 pandemic introduces new challenges and constraints for return to\nwork business planning. We describe a space allocation problem that\nincorporates social distancing constraints while optimising the number of\navailable safe workspaces in a return to work scenario. We propose and\ndemonstrate a graph based approach that solves the optimisation problem via\nmodelling as a bipartite graph of disconnected components over a graph of\nconstraints. We compare results obtained with a constrained random walk and a\nlinear programming approach.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.05017v1"
    },
    {
        "title": "Business Suitability Principles for Workflow Modelling",
        "authors": [
            "Alistair P. Barros",
            "Arthur H. M. ter Hofstede",
            "Henderik A. Proper",
            "Peter N. Creasy"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  By incorporating aspects of coordination and collaboration, workflow\nimplementations of information systems require a sound conceptualisation of\n\\EM{business processing} semantics. Traditionally, the success of conceptual\nmodelling techniques has depended largely on the adequacy of conceptualisation,\nexpressive power, comprehensibility and formal foundation. An equally important\nrequirement, particularly with the increased conceptualisation of business\naspects, is \\EM{business suitability}. In this paper, the focus is on the\nbusiness suitability of workflow modelling for a commonly encountered class of\n(operational) business processing, e.g. those of insurance claims, bank loans\nand land conveyancing. A general assessment is first conducted on some\n\\EM{integrated} techniques characterising well-known paradigms - structured\nprocess modelling, object-oriented modelling, behavioural process modelling and\nbusiness-oriented modelling. Through this, an insight into business suitability\nwithin the broader perspective of technique adequacy, is gained. A specific\nbusiness suitability diagnosis then follows using a particular characterisation\nof business processing, i.e.\\ one where the intuitive semantics and\ninter-relationship of business services and business processes are nuanced. As\na result, five business suitability principles are elicited. These are proposed\nfor a more detailed understanding and (synthetic) development of workflow\nmodelling techniques. Accordingly, further insight into workflow specification\nlanguages and workflow globalisation in open distributed architectures may also\nbe gained.\n",
        "pdf_link": "http://arxiv.org/pdf/2105.12654v1"
    },
    {
        "title": "Low cost cloud based remote microscopy for biological sciences",
        "authors": [
            "Pierre V Baudin",
            "Victoria T Ly",
            "Pattawong Pansodtee",
            "Erik A Jung",
            "Robert Currie",
            "Ryan Hoffman",
            "Helen Rankin Willsey",
            "Alex A Pollen",
            "Tomasz J Nowakowski",
            "David Haussler",
            "Mohammed Andres Mostajo-Radji",
            "Sofie Salama",
            "Mircea Teodorescu"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  A low cost remote imaging platform for biological applications was developed.\nThe \"Picroscope\" is a device that allows the user to perform longitudinal\nimaging studies on multi-well cell culture plates. Here we present the network\narchitecture and software used to facilitate communication between modules\nwithin the device as well as external cloud services. A web based console was\ncreated to control the device and view experiment results. Post processing\ntools were developed to analyze captured data in the cloud. The result is a\nplatform for controlling biological experiments from outside the lab.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.07419v1"
    },
    {
        "title": "EnergySaver Software Manual",
        "authors": [
            "Davi Guimares da Silva",
            "Marla Teresinha Barbosa Geller",
            "Dalton Felipe Silva Varo",
            "Joo Bentes",
            "Mauro Srgio dos Santos Moura",
            "Yasmin Braga Teixeira",
            "Clayton Andr Maia dos Santos",
            "Anderson Alvarenga de Moura Meneses"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Energy efficiency is a topic that has attracted the attention of researchers\nin recent years, in order to seek sustainability solutions for energy\nproduction and reduction of its costs, aiming to provide a balance between\ndevelopment and protection of natural resources. Thus, we proposed the\nEnergySaver software that has as its objective the monitoring of electric\nenergy consumption, from data capture to consumption forecast for the following\nmonth. To create Energy Saver, we used Open Source technologies applied to the\nInternet of Things (IoT), embedded systems, and Long Short-Term Memory Neural\nNetworks (LSTM). However, in order to have harmony between the current\nresearchers and those who may manipulate this software in the future, it is\nessential to create a Software Manual, where all the details of its\nimplementation are described in detail. Therefore, this article describes all\nthe steps for the implementation of the system, from the methodological scheme\nof the system, its modeling with UML, to the modules that compose it, becoming\na Manual for its use.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.06664v1"
    },
    {
        "title": "Gain and Pain of a Reliable Delay Model",
        "authors": [
            "Jrgen Maier"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  State-of-the-art digital circuit design tools almost exclusively rely on pure\nand inertial delay for timing simulations. While these provide reasonable\nestimations at very low execution time in the average case, their ability to\ncover complex signal traces is limited. Research has provided the dynamic\nInvolution Delay Model (IDM) as a promising alternative, which was shown (i) to\ndepict reality more closely and recently (ii) to be compatible with modern\nsimulation suites. In this paper we complement these encouraging results by\nexperimentally exploring the behavioral coverage for more advanced circuits. In\ndetail we apply the IDM to three simple circuits (a combinatorial loop, an SR\nlatch and an adder), interpret the delivered results and evaluate the overhead\nin realistic settings. Comparisons to digital (inertial delay) and analog\n(SPICE) simulations reveal, that the IDM delivers very fine-grained results,\nwhich match analog simulations very closely. Moreover, severe shortcomings of\ninertial delay become apparent in our simulations, as it fails to depict a\nrange of malicious behaviors. Overall the Involution Delay Model hence\nrepresents a viable upgrade to the available delay models in modern digital\ntiming simulation tools.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.06814v2"
    },
    {
        "title": "On the optimal layout of a dining room in the era of COVID-19 using\n  mathematical optimization",
        "authors": [
            "Claudio Contardo",
            "Luciano Costa"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  We consider the problem of maximizing the number of people that a dining room\ncan accommodate provided that the chairs belonging to different tables are\nsocially distant. We introduce an optimization model that incorporates several\ncharacteristics of the problem, namely: the type and size of surface of the\ndining room, the shapes and sizes of the tables, the positions of the chairs,\nthe sitting sense of the customers, and the possibility of adding space\nseparators to increase the capacity. We propose a simple, yet general,\nset-packing formulation for the problem. We investigate the efficiency of space\nseparators and the impact of considering the sitting sense of customers in the\nroom capacity. We also perform an algorithmic analysis of the model, and assess\nits scalability to the problem size, the presence of (or lack thereof) room\nseparators, and the consideration of the sitting sense of customers. We also\npropose two constructive heuristics capable of coping with large problem\ninstances otherwise intractable for the optimization model.\n",
        "pdf_link": "http://arxiv.org/pdf/2108.04233v2"
    },
    {
        "title": "The Turing machine of a harmonic oscillator: from the code to the\n  dynamic system",
        "authors": [
            "Francesco Sisini",
            "Valentina Sisini"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  In this work we consider a dynamic system consisting of a damped harmonic\noscillator and we formalize a Turing Machine whose definition in terms of\nstates, alphabet and transition rules, can be considered equivalent to that of\nthe oscillator. We prove that the Turing Machine of a FOR loop corresponds to\nthat of the oscillator and we ask ourselves if it is possible to obtain the\ndynamic system of the harmonic oscillator as a physical realization of the FOR\nloop. We discuss the relationship between the results found and the science of\nCan and Can't. We discuss the possibility of an evolution of computer science\nalso towards non-computerized specialized machines whose operating principle is\ndesigned as an automatic process starting from a source code instead of as a\nwork of human ingenuity. The approach to the implementation of algorithms in\ndynamic systems instead of universal computers can be particularly interesting\nfor the field of both diagnostic and implantable medical devices.\n",
        "pdf_link": "http://arxiv.org/pdf/2110.06119v1"
    },
    {
        "title": "A Simple Hybrid Model for Accurate Delay Modeling of a Multi-Input Gate",
        "authors": [
            "Arman Ferdowsi",
            "Jrgen Maier",
            "Daniel hlinger",
            "Ulrich Schmid"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Faithfully representing small gate delay variations caused by input\nswitchings on different inputs in close temporal proximity is a very\nchallenging task for digital delay models. In this paper, we use the example of\na 2-input NOR gate to show that a simple hybrid model leads to a surprisingly\naccurate digital delay model. Our model utilizes simple first-order ordinary\ndifferential equations (ODEs) in all modes, resulting from considering\ntransistors as ideal switches in a simple RC model of the gate. By analytically\nsolving the resulting ODEs, we derive expressions for the gate delays, as well\nas formulas that facilitate model parametrization. It turns out that our model\nalmost faithfully captures the Charlie effect, except in just one specific\nsituation. In addition, we experimentally compare our model's predictions both\nto SPICE simulations, using some 15 nm technology, and to some existing delay\nmodels. Our results show a significant improvement of the achievable modeling\naccuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/2111.11182v1"
    },
    {
        "title": "Smart Support for Mission Success",
        "authors": [
            "Juliette Mattioli",
            "Pierre-Olivier Robic"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Today's battlefield environment is complex, dynamic and uncertain, and\nrequires efficient support to ensure mission success. This relies on a proper\nsupport strategy to provide supported equipment able to fulfill the mission. In\nthe context of defense where both systems and organization are complex, having\na holistic approach is challenging by nature, forces and support agencies need\nto rely on an efficient decision support system. Logistics, readiness and\nsustainability are critical factors for asset management, which can benefit\nfrom AI to reach \"Smart In Service\" level relying especially on predictive and\nprescriptive approaches and on effective management of operational re-sources.\nSmart Support capacities can be then monitored by appropriate metrics and\nimproved by multi-criteria decision support and knowledge management system.\nDepending on the operational context in terms of information and the objective,\ndifferent AI paradigms (data-driven AI, knowledge-based AI) are suitable even a\ncombination through hybrid AI.\n",
        "pdf_link": "http://arxiv.org/pdf/2112.04957v1"
    },
    {
        "title": "A Brief Analysis of the Apollo Guidance Computer",
        "authors": [
            "Charles Averill"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  The AGC was designed with the sole purpose of providing navigational guidance\nand spacecraft control during the Apollo program throughout the 1960s and early\n1970s. The AGC sported 72kb of ROM, 4kb of RAM, and a whopping 14,245 FLOPS,\nroughly 30 million times fewer than the computer this report is being written\non. These limitations are what make the AGC so interesting, as its programmers\nhad to ration each individual word of memory due to the bulk of memory\ntechnology of the time. Despite these limitations (or perhaps due to them), the\nAGC was highly optimized, and arguably the most advanced computer of its time,\nas its computational power was only matched in the late 1970s by computers like\nthe Apple II. It is safe to say that the AGC had no intended market, and was\nexplicitly designed to enhance control of the Apollo Command Module and Apollo\nLunar Module. The AGC was not entirely internal to NASA, however, and was\ndesigned in MIT's Instrumentation Laboratory, and manufactured by Raytheon, a\nweapons and defense contractor.\n",
        "pdf_link": "http://arxiv.org/pdf/2201.08230v1"
    },
    {
        "title": "Defining a synthetic data generator for realistic electric vehicle\n  charging sessions",
        "authors": [
            "Manu Lahariya",
            "Dries Benoit",
            "Chris Develder"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Electric vehicle (EV) charging stations have become prominent in electricity\ngrids in the past years. Analysis of EV charging sessions is useful for\nflexibility analysis, load balancing, offering incentives to customers, etc.\nYet, the limited availability of such EV sessions data hinders further\ndevelopment in these fields. Addressing this need for publicly available and\nrealistic data, we develop a synthetic data generator (SDG) for EV charging\nsessions. Our SDG assumes the EV inter-arrival time to follow an exponential\ndistribution. Departure times are modeled by defining a conditional probability\ndensity function (pdf) for connection times. This pdf for connection time and\nrequired energy is fitted by Gaussian mixture models. Since we train our SDG\nusing a large real-world dataset, its output is realistic.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.01129v1"
    },
    {
        "title": "Building AI Innovation Labs together with Companies",
        "authors": [
            "Jens Heidrich",
            "Andreas Jedlitschka",
            "Adam Trendowicz",
            "Anna Maria Vollmer"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  In the future, most companies will be confronted with the topic of Artificial\nIntelligence (AI) and will have to decide on their strategy in this regards.\nCurrently, a lot of companies are thinking about whether and how AI and the\nusage of data will impact their business model and what potential use cases\ncould look like. One of the biggest challenges lies in coming up with\ninnovative solution ideas with a clear business value. This requires business\ncompetencies on the one hand and technical competencies in AI and data\nanalytics on the other hand. In this article, we present the concept of AI\ninnovation labs and demonstrate a comprehensive framework, from coming up with\nthe right ideas to incrementally implementing and evaluating them regarding\ntheir business value and their feasibility based on a company's capabilities.\nThe concept is the result of nine years of working on data-driven innovations\nwith companies from various domains. Furthermore, we share some lessons learned\nfrom its practical applications. Even though a lot of technical publications\ncan be found in the literature regarding the development of AI models and many\nconsultancy companies provide corresponding services for building AI\ninnovations, we found very few publications sharing details about what an\nend-to-end framework could look like.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.08465v1"
    },
    {
        "title": "Generic Lithography Modeling with Dual-band Optics-Inspired Neural\n  Networks",
        "authors": [
            "Haoyu Yang",
            "Zongyi Li",
            "Kumara Sastry",
            "Saumyadip Mukhopadhyay",
            "Mark Kilgard",
            "Anima Anandkumar",
            "Brucek Khailany",
            "Vivek Singh",
            "Haoxing Ren"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Lithography simulation is a critical step in VLSI design and optimization for\nmanufacturability. Existing solutions for highly accurate lithography\nsimulation with rigorous models are computationally expensive and slow, even\nwhen equipped with various approximation techniques. Recently, machine learning\nhas provided alternative solutions for lithography simulation tasks such as\ncoarse-grained edge placement error regression and complete contour prediction.\nHowever, the impact of these learning-based methods has been limited due to\nrestrictive usage scenarios or low simulation accuracy. To tackle these\nconcerns, we introduce an dual-band optics-inspired neural network design that\nconsiders the optical physics underlying lithography. To the best of our\nknowledge, our approach yields the first published via/metal layer contour\nsimulation at 1nm^2/pixel resolution with any tile size. Compared to previous\nmachine learning based solutions, we demonstrate that our framework can be\ntrained much faster and offers a significant improvement on efficiency and\nimage quality with 20X smaller model size. We also achieve 85X simulation\nspeedup over traditional lithography simulator with 1% accuracy loss.\n",
        "pdf_link": "http://arxiv.org/pdf/2203.08616v1"
    },
    {
        "title": "Optimal Layered Defense For Site Protection",
        "authors": [
            "Tsvetan Asamov",
            "Emre Yamangil",
            "Endre Boros",
            "Paul Kantor",
            "Fred Roberts"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  We present a model for layered security with applications to the protection\nof sites such as stadiums or large gathering places. We formulate the problem\nas one of maximizing the capture of illegal contraband. The objective function\nis indefinite and only limited information can be gained when the problem is\nsolved by standard convex optimization methods. In order to solve the model, we\ndevelop a dynamic programming approach, and study its convergence properties.\nAdditionally, we formulate a version of the problem aimed at addressing\nintelligent adversaries who can adjust their direction of attack as they\nobserve changes in the site security. Furthermore, we also develop a method for\nthe solution of the latter model. Finally, we perform computational experiments\nto demonstrate the use of our methods.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.08961v1"
    },
    {
        "title": "Device for measuring the plant physiology and electrophysiology",
        "authors": [
            "Serge Kernbach"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  This paper briefly describes the device - the phytosensor - for measuring\nphysiological and electrophysiological parameters of plants. This system is\ndeveloped as a bio-physiological sensor in precise agriculture, as a tool in\nplant research and environmental biology, and for plant enthusiasts in smart\nhome or entertainment applications. The phytosentor measures main physiological\nparameters such as the leaf transpiration rate, sap flow, tissue conductivity\nand frequency response, biopotentials (action potentials and variation\npotentials), and can conduct electrochemical impedance spectroscopy with\norganic tissues. Soil moisture and temperature, air quality (CO2, NO2, O3 and\nother sensors on I2C bus), and general environmental parameters (light,\ntemperature, humidity, air pressure, electromagnetic and magnetic fields) are\nalso recorded in real time. In addition to phytosensing, the device can also\nperform phytoactuation, i.e. execute electrical or light stimulation of plants,\ncontrol irrigation and lighting modes, conduct fully autonomous experiments\nwith complex feedback-based and adaptive scenarios in robotic or biohybrid\nsystems. This article represents the revised and extended version of original\npaper and includes some descriptions and images from the FloraRobotica and\nBioHybrids projects.\n",
        "pdf_link": "http://arxiv.org/pdf/2206.10459v1"
    },
    {
        "title": "SAP Signavio Academic Models: A Large Process Model Dataset",
        "authors": [
            "Diana Sola",
            "Christian Warmuth",
            "Bernhard Schfer",
            "Peyman Badakhshan",
            "Jana-Rebecca Rehse",
            "Timotheus Kampik"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  In this paper, we introduce the SAP Signavio Academic Models (SAP-SAM)\ndataset, a collection of hundreds of thousands of business models, mainly\nprocess models in BPMN notation. The model collection is a subset of the models\nthat were created over the course of roughly a decade on academic.signavio.com,\na free-of-charge software-as-a-service platform that researchers, teachers, and\nstudents can use to create business (process) models. We provide a preliminary\nanalysis of the model collection, as well as recommendations on how to work\nwith it. In addition, we discuss potential use cases and limitations of the\nmodel collection from academic and industry perspectives.\n",
        "pdf_link": "http://arxiv.org/pdf/2208.12223v1"
    },
    {
        "title": "Alternate Timelines for TidalCycles",
        "authors": [
            "Alex McLean"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  The TidalCycles (or Tidal for short) live coding environment has been\ndeveloped since around 2009, via several rewrites of its core representation.\nRather than having fixed goals, this development has been guided by use,\nmotivated by the open aim to make music. This development process can be seen\nas a long-form improvisation, with insights into the nature of Tidal gained\nthrough the process of writing it, feeding back to guide the next steps of\ndevelopment.\n  This brings the worrying thought that key insights will have been missed\nalong this development journey, that would otherwise have lead to very\ndifferent software. Indeed participants at beginners' workshops that I have\nlead or co-lead have often asked questions without good answers, because they\nmade deficiencies or missing features in the software clear. It is well known\nthat a beginner's mind is able to see much that an expert has become blind to.\nRunning workshops are an excellent way to find new development ideas, but the\npresent paper explores a different technique - the rewrite.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.04289v1"
    },
    {
        "title": "Functional Component Descriptions for Electrical Circuits based on\n  Semantic Technology Reasoning",
        "authors": [
            "Johannes Bayer",
            "Mina Karami Zadeh",
            "Markus Schrder",
            "Andreas Dengel"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Circuit diagrams have been used in electrical engineering for decades to\ndescribe the wiring of devices and facilities. They depict electrical\ncomponents in a symbolic and graph-based manner. While the circuit design is\nusually performed electronically, there are still legacy paper-based diagrams\nthat require digitization in order to be used in CAE systems. Generally,\nknowledge on specific circuits may be lost between engineering projects, making\nit hard for domain novices to understand a given circuit design. The\ngraph-based nature of these documents can be exploited by semantic\ntechnology-based reasoning in order to generate human-understandable\ndescriptions of their functional principles. More precisely, each electrical\ncomponent (e.g. a diode) of a circuit may be assigned a high-level function\nlabel which describes its purpose within the device (e.g. flyback diode for\nreverse voltage protection). In this paper, forward chaining rules are used for\nsuch a generation. The described approach is applicable for both CAE-based\ncircuits as well as raw circuits yielded by an image understanding pipeline.\nThe viability of the approach is demonstrated by application to an existing set\nof circuits.\n",
        "pdf_link": "http://arxiv.org/pdf/2209.05533v1"
    },
    {
        "title": "The Executable Digital Twin: merging the digital and the physics worlds",
        "authors": [
            "Herman Van der Auweraer",
            "Dirk Hartmann"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  While the digital twin has become an intrinsic part of the product creation\nprocess, its true power lies in the connectivity of the digital representation\nwith its physical counterpart. Data acquired on the physical asset can\nvalidate, update and enrich the digital twin. The knowledge contained in the\ndigital representation brings value to the physical asset itself. When a\ndedicated encapsulation is extracted from the digital twin to model a specific\nset of behaviors in a specific context, delivering a stand-alone executable\nrepresentation, such instantiated and self-contained model is referred to as an\nExecutable Digital Twin. In this contribution, key building blocks such as\nmodel order reduction, real-time models, state estimation and co-simulation are\nreviewed, and a number of characteristic use cases are presented. These include\nvirtual sensing, hybrid testing and hardware-in-the loop, model-based control\nand model-based diagnostics.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.17402v2"
    },
    {
        "title": "QMKPy: A Python Testbed for the Quadratic Multiple Knapsack Problem",
        "authors": [
            "Karl-Ludwig Besser",
            "Eduard A. Jorswieck"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  QMKPy provides a Python framework for modeling and solving the quadratic\nmultiple knapsack problem (QMKP). It is primarily aimed at researchers who\ndevelop new solution algorithms for the QMKP. QMKPy therefore mostly functions\nas a testbed to quickly implement novel algorithms and compare their results\nwith existing ones. However, the package also already includes implementations\nof established algorithms for those who only need to solve a QMKP as part of\ntheir research.\n",
        "pdf_link": "http://arxiv.org/pdf/2211.17222v1"
    },
    {
        "title": "Sharing Linkable Learning Objects with the use of Metadata and a\n  Taxonomy Assistant for Categorization",
        "authors": [
            "Valentina Franzoni",
            "Sergio Tasso",
            "Simonetta Pallottelli",
            "Damiano Perri"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  In this work, a re-design of the Moodledata module functionalities is\npresented to share learning objects between e-learning content platforms, e.g.,\nMoodle and G-Lorep, in a linkable object format. The e-learning courses content\nof the Drupal-based Content Management System G-Lorep for academic learning is\nexchanged designing an object incorporating metadata to support the reuse and\nthe classification in its context. In such an Artificial Intelligence\nenvironment, the exchange of Linkable Learning Objects can be used for dialogue\nbetween Learning Systems to obtain information, especially with the use of\nsemantic or structural similarity measures to enhance the existent Taxonomy\nAssistant for advanced automated classification.\n",
        "pdf_link": "http://arxiv.org/pdf/2212.05947v1"
    },
    {
        "title": "Modelling Maritime SAR Effective Sweep Widths for Helicopters in VDM",
        "authors": [
            "Alexander Sulaiman",
            "Ken Pierce"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Search and Rescue (SAR) is searching for and providing help to people in\ndanger. In the UK, SAR teams are typically charities with limited resources,\nand SAR missions are time critical. Search managers need to objectively decide\nwhich search assets (e.g. helicopter vs drone) would be better. A key metric in\nthe SAR community is effective sweep width (W), which provides a single measure\nfor a search asset's ability to detect a specific object in specific\nenvironmental conditions. Tables of W for different search assets are provided\nin various manuals, such as the International Aeronautical and Maritime SAR\n(IAMSAR) Manual. However, these tables take years of expensive testing and\nexperience to produce, and no such tables exist for drones. This paper uses the\nVienna Development Method (VDM) to build an initial model of W for a known case\n(helicopters at sea) with a view to predicting W tables for drones. The model\ncomputes W for various search object sizes, helicopter altitude and visibility.\nThe results for the model are quite different from the published tables, which\nshows that the abstraction level is not yet correct, however it produced useful\ninsights and directions for the next steps.\n",
        "pdf_link": "http://arxiv.org/pdf/2304.00983v1"
    },
    {
        "title": "Toward Platform-based Building Design",
        "authors": [
            "Yu-Wen Lin",
            "Tsz Ling Elaine Tang",
            "Stefano Schiavon",
            "Costas J. Spanos"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  The electronic design industry has undergone a significant transformation,\ntransitioning from traditional hand-drawn designs to modern automated design\nprocesses. While Computer-Aided Design (CAD) tools emerged alongside the\nelectronic industry, the current building design process has little to no\nautomation. There is a need for a unified platform to address the complexity of\nbuilding design and provide a more systematic approach. Platform-based design\n(PBD), originally developed in the electronic industry, enables efficient\ndesign processes by promoting the reuse of hardware and software systems. It\nalso facilitates design space exploration while optimizing performance. This\npaper proposes a modular approach that divides the building into various\ndisciplines and introduces a design flow using the PBD framework to streamline\nthe design process. We also present a case study that demonstrates the use of\nthe PBD framework in the Heating, Ventilation, and Air Conditioning (HVAC)\nsystems design.\n",
        "pdf_link": "http://arxiv.org/pdf/2305.10949v1"
    },
    {
        "title": "An Interdisciplinary Survey on Origin-destination Flows Modeling: Theory\n  and Techniques",
        "authors": [
            "Can Rong",
            "Jingtao Ding",
            "Yong Li"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Origin-destination (OD) flow modeling is an extensively researched subject\nacross multiple disciplines, such as the investigation of travel demand in\ntransportation and spatial interaction modeling in geography. However,\nresearchers from different fields tend to employ their own unique research\nparadigms and lack interdisciplinary communication, preventing the\ncross-fertilization of knowledge and the development of novel solutions to\nchallenges. This article presents a systematic interdisciplinary survey that\ncomprehensively and holistically scrutinizes OD flows from utilizing\nfundamental theory to studying the mechanism of population mobility and solving\npractical problems with engineering techniques, such as computational models.\nSpecifically, regional economics, urban geography, and sociophysics are adept\nat employing theoretical research methods to explore the underlying mechanisms\nof OD flows. They have developed three influential theoretical models: the\ngravity model, the intervening opportunities model, and the radiation model.\nThese models specifically focus on examining the fundamental influences of\ndistance, opportunities, and population on OD flows, respectively. In the\nmeantime, fields such as transportation, urban planning, and computer science\nprimarily focus on addressing four practical problems: OD prediction, OD\nconstruction, OD estimation, and OD forecasting. Advanced computational models,\nsuch as deep learning models, have gradually been introduced to address these\nproblems more effectively. Finally, based on the existing research, this survey\nsummarizes current challenges and outlines future directions for this topic.\nThrough this survey, we aim to break down the barriers between disciplines in\nOD flow-related research, fostering interdisciplinary perspectives and modes of\nthinking.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.10048v4"
    },
    {
        "title": "Cyber Framework for Steering and Measurements Collection Over\n  Instrument-Computing Ecosystems",
        "authors": [
            "Anees Al-Najjar",
            "Nageswara S. V. Rao",
            "Ramanan Sankaran",
            "Helia Zandi",
            "Debangshu Mukherjee",
            "Maxim Ziatdinov",
            "Craig Bridges"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  We propose a framework to develop cyber solutions to support the remote\nsteering of science instruments and measurements collection over\ninstrument-computing ecosystems. It is based on provisioning separate data and\ncontrol connections at the network level, and developing software modules\nconsisting of Python wrappers for instrument commands and Pyro server-client\ncodes that make them available across the ecosystem network. We demonstrate\nautomated measurement transfers and remote steering operations in a microscopy\nuse case for materials research over an ecosystem of Nion microscopes and\ncomputing platforms connected over site networks. The proposed framework is\ncurrently under further refinement and being adopted to science workflows with\nautomated remote experiments steering for autonomous chemistry laboratories and\nsmart energy grid simulations.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.06883v1"
    },
    {
        "title": "Wordification: A New Way of Teaching English Spelling Patterns",
        "authors": [
            "Lexington Whalen",
            "Nathan Bickel",
            "Shash Comandur",
            "Dalton Craven",
            "Stanley Dubinsky",
            "Homayoun Valafar"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Literacy, or the ability to read and write, is a crucial indicator of success\nin life and greater society. It is estimated that 85% of people in juvenile\ndelinquent systems cannot adequately read or write, that more than half of\nthose with substance abuse issues have complications in reading or writing and\nthat two-thirds of those who do not complete high school lack proper literacy\nskills. Furthermore, young children who do not possess reading skills matching\ngrade level by the fourth grade are approximately 80% likely to not catch up at\nall. Many may believe that in a developed country such as the United States,\nliteracy fails to be an issue; however, this is a dangerous misunderstanding.\nGlobally an estimated 1.19 trillion dollars are lost every year due to issues\nin literacy; in the USA, the loss is an estimated 300 billion. To put it in\nmore shocking terms, one in five American adults still fail to comprehend basic\nsentences. Making matters worse, the only tools available now to correct a lack\nof reading and writing ability are found in expensive tutoring or other\nprograms that oftentimes fail to be able to reach the required audience. In\nthis paper, our team puts forward a new way of teaching English spelling and\nword recognitions to grade school students in the United States: Wordification.\nWordification is a web application designed to teach English literacy using\nprinciples of linguistics applied to the orthographic and phonological\nproperties of words in a manner not fully utilized previously in any\ncomputer-based teaching application.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.12981v2"
    },
    {
        "title": "Morphological Computing as Logic Underlying Cognition in Human, Animal,\n  and Intelligent Machine",
        "authors": [
            "Gordana Dodig-Crnkovic"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  This work examines the interconnections between logic, epistemology, and\nsciences within the Naturalist tradition. It presents a scheme that connects\nlogic, mathematics, physics, chemistry, biology, and cognition, emphasizing\nscale-invariant, self-organizing dynamics across organizational tiers of\nnature. The inherent logic of agency exists in natural processes at various\nlevels, under information exchanges. It applies to humans, animals, and\nartifactual agents. The common human-centric, natural language-based logic is\nan example of complex logic evolved by living organisms that already appears in\nthe simplest form at the level of basal cognition of unicellular organisms.\nThus, cognitive logic stems from the evolution of physical, chemical, and\nbiological logic. In a computing nature framework with a self-organizing\nagency, innovative computational frameworks grounded in\nmorphological/physical/natural computation can be used to explain the genesis\nof human-centered logic through the steps of naturalized logical processes at\nlower levels of organization. The Extended Evolutionary Synthesis of living\nagents is essential for understanding the emergence of human-level logic and\nthe relationship between logic and information processing/computational\nepistemology. We conclude that more research is needed to elucidate the details\nof the mechanisms linking natural phenomena with the logic of agency in nature.\n",
        "pdf_link": "http://arxiv.org/pdf/2309.13979v1"
    },
    {
        "title": "Solving the multiplication problem of a large language model system\n  using a graph-based method",
        "authors": [
            "Turker Tuncer",
            "Sengul Dogan",
            "Mehmet Baygin",
            "Prabal Datta Barua",
            "Abdul Hafeez-Baig",
            "Ru-San Tan",
            "Subrata Chakraborty",
            "U. Rajendra Acharya"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  The generative pre-trained transformer (GPT)-based chatbot software ChatGPT\npossesses excellent natural language processing capabilities but is inadequate\nfor solving arithmetic problems, especially multiplication. Its GPT structure\nuses a computational graph for multiplication, which has limited accuracy\nbeyond simple multiplication operations. We developed a graph-based\nmultiplication algorithm that emulated human-like numerical operations by\nincorporating a 10k operator, where k represents the maximum power to base 10\nof the larger of two input numbers. Our proposed algorithm attained 100%\naccuracy for 1,000,000 large number multiplication tasks, effectively solving\nthe multiplication challenge of GPT-based and other large language models. Our\nwork highlights the importance of blending simple human insights into the\ndesign of artificial intelligence algorithms. Keywords: Graph-based\nmultiplication; ChatGPT; Multiplication problem\n",
        "pdf_link": "http://arxiv.org/pdf/2310.13016v1"
    },
    {
        "title": "Rock Climbing Route Generation and Grading as Computational Creativity",
        "authors": [
            "Jesse Roberts"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  In this paper, we bridge work in rock climbing route generation and grading\ninto the computational creativity community. We provide the necessary\nbackground to situate that literature and demonstrate the domain's intellectual\nmerit in the computational creativity community. We provide a guiding set of\ndesiderata for future work in this area. We propose an approach to\ncomputational route grading. Finally, we identify important gaps in the\nliterature and consider how they may be filled. This paper thus also serves as\na pilot study, planting a flag for our ongoing research in this domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2311.02211v1"
    },
    {
        "title": "Foundations of Work-Systems Modeling",
        "authors": [
            "Henderik Alex Proper"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  In 2006, the course \"Modeling of Organizations\" is taught for the third time.\nThis third time will be the second time we will use the new lecture notes \"Work\nSystems Modelling\" from the DA VINCI series. These lecture notes, however, will\nbe evolved further hand-in-hand with the actual process of lecturing. In the\nacademic year 2005/2006, a second incarnation of these lecture notes will be\ncreated, where the aim is to deliver these lecture notes in three increments.\nAn important step that will be taken in this academic year is the integration\nof the ICIS Work Systems Modelling lecture notes with the NICI course on\nOrganisational Dynamics. The first results of this integration will start to\nappear in the second and third trimester.\n",
        "pdf_link": "http://arxiv.org/pdf/2401.16221v1"
    },
    {
        "title": "Is 3-(F)WL Enough to Distinguish All 3D Graphs?",
        "authors": [
            "Wanghan Xu"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The problem of graph isomorphism is an important but challenging problem in\nthe field of graph analysis, for example: analyzing the similarity of two\nchemical molecules, or studying the expressive ability of graph neural\nnetworks. WL test is a method to judge whether two graphs are isomorphic, but\nit cannot distinguish all non-isomorphic graphs. As an improvement of WL, k-WL\nhas stronger isomorphism discrimination ability, and as k increases, its\ndiscrimination ability is strictly increasing. However, whether the isomorphic\ndiscrimination power of k-WL is strictly increasing for more complex 3D graphs,\nor whether there exists k that can discriminate all 3D graphs, remains\nunexplored. This paper attempts to explore this problem from the perspective of\ngraph generation.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.08429v1"
    },
    {
        "title": "Constraint Propagation on GPU: A Case Study for the Bin Packing\n  Constraint",
        "authors": [
            "Fabio Tardivo",
            "Laurent Michel",
            "Enrico Pontelli"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The Bin Packing Problem is one of the most important problems in discrete\noptimization, as it captures the requirements of many real-world problems.\nBecause of its importance, it has been approached with the main theoretical and\npractical tools. Resolution approaches based on Linear Programming are the most\neffective, while Constraint Programming proves valuable when the Bin Packing\nProblem is a component of a larger problem. This work focuses on the Bin\nPacking constraint and explores how GPUs can be used to enhance its propagation\nalgorithm. Two approaches are motivated and discussed, one based on knapsack\nreasoning and one using alternative lower bounds. The implementations are\nevaluated in comparison with state-of-the-art approaches on different\nbenchmarks from the literature. The results indicate that the GPU-accelerated\nlower bounds offers a desirable alternative to tackle large instances.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.14821v1"
    },
    {
        "title": "Crowdsense Roadside Parking Spaces with Dynamic Gap Reduction Algorithm",
        "authors": [
            "Wenjun Zheng",
            "Zhan Shi",
            "Qianyu Ou",
            "Ruizhi Liao"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  In the context of smart city development, mobile sensing emerges as a\ncost-effective alternative to fixed sensing for on-street parking detection.\nHowever, its practicality is often challenged by the inherent accuracy\nlimitations arising from detection intervals. This paper introduces a novel\nDynamic Gap Reduction Algorithm (DGRA), which is a crowdsensing-based approach\naimed at addressing this question through parking detection data collected by\nsensors on moving vehicles. The algorithm's efficacy is validated through real\ndrive tests and simulations. We also present a Driver-Side and Traffic-Based\nModel (DSTBM), which incorporates drivers' parking decisions and traffic\nconditions to evaluate DGRA's performance. Results highlight DGRA's significant\npotential in reducing the mobile sensing accuracy gap, marking a step forward\nin efficient urban parking management.\n",
        "pdf_link": "http://arxiv.org/pdf/2408.14475v1"
    },
    {
        "title": "SPICE-PIDE: A Methodology for Design and Optimization of Integrated\n  Circuits",
        "authors": [
            "Jehan Taraporewalla",
            "Arun KP",
            "Sugata Ghosh",
            "Abhishek Agarwal",
            "Bijaydoot Basak",
            "Dipankar Saha"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  In application-specific designs, owing to the trade-off between power\nconsumption and speed, optimization of various circuit parameters has become a\nchallenging task. Several of the performance metrics, viz. energy efficiency,\ngain, performance, and noise immunity, are interrelated and difficult to tune.\nSuch efforts may result in a great deal of manual iterations which in turn\nincrease the computational overhead. Thus, it is important to develop a\nmethodology that not only explores large design space but also reduces the\ncomputational time. In this work, we investigate the viability of using a SPICE\nand Python IDE (PIDE) interface to optimize integrated circuits. The SPICE\nsimulations are carried out using 22 nm technology node with a nominal supply\nvoltage of 0.8 V. The SPICE-PIDE optimizer, as delineated in this work, is able\nto provide the best solution sets considering various performance metrics and\ndesign complexities for 5 transistor level converters.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.05323v1"
    },
    {
        "title": "Assisted morbidity coding: the SISCO.web use case for identifying the\n  main diagnosis in Hospital Discharge Records",
        "authors": [
            "Elena Cardillo",
            "Lucilla Frattura"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Coding morbidity data using international standard diagnostic classifications\nis increasingly important and still challenging. Clinical coders and physicians\nassign codes to patient episodes based on their interpretation of case notes or\nelectronic patient records. Therefore, accurate coding relies on the legibility\nof case notes and the coders' understanding of medical terminology. During the\nlast ten years, many studies have shown poor reproducibility of clinical\ncoding, even recently, with the application of Artificial Intelligence-based\nmodels. Given this context, the paper aims to present the SISCO.web approach\ndesigned to support physicians in filling in Hospital Discharge Records with\nproper diagnoses and procedures codes using the International Classification of\nDiseases (9th and 10th), and, above all, in identifying the main pathological\ncondition. The web service leverages NLP algorithms, specific coding rules, as\nwell as ad hoc decision trees to identify the main condition, showing promising\nresults in providing accurate ICD coding suggestions.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.09651v1"
    },
    {
        "title": "Motif Caller: Sequence Reconstruction for Motif-Based DNA Storage",
        "authors": [
            "Parv Agarwal",
            "Thomas Heinis"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  DNA data storage is rapidly gaining traction as a long-term data archival\nsolution, primarily due to its exceptional durability. Retrieving stored data\nrelies on DNA sequencing, which involves a process called basecalling -- a\ntypically costly and slow task that uses machine learning to map raw sequencing\nsignals back to individual DNA bases (which are then translated into digital\nbits to recover the data). Current models for basecalling have been optimized\nfor reading individual bases. However, with the advent of novel DNA synthesis\nmethods tailored for data storage, there is significant potential for\noptimizing the reading process. In this paper, we focus on Motif-based DNA\nsynthesis, where sequences are constructed from motifs -- groups of bases --\nrather than individual bases. To enable efficient reading of data stored in DNA\nusing Motif-based DNA synthesis, we designed Motif Caller, a machine learning\nmodel built to detect entire motifs within a DNA sequence, rather than\nindividual bases. Motifs can also be detected from individually identified\nbases using a basecaller and then searching for motifs, however, such an\napproach is unnecessarily complex and slow. Building a machine learning model\nthat directly identifies motifs allows to avoid the additional step of\nsearching for motifs. It also makes use of the greater amount of features per\nmotif, thus enabling finding the motifs with higher accuracy. Motif Caller\nsignificantly enhances the efficiency and accuracy of data retrieval in DNA\nstorage based on Motif-Based DNA synthesis.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.16074v1"
    },
    {
        "title": "The Expresso Microarray Experiment Management System: The Functional\n  Genomics of Stress Responses in Loblolly Pine",
        "authors": [
            "Lenwood S. Heath",
            "Naren Ramakrishnan",
            "Ronald R. Sederoff",
            "Ross W. Whetten",
            "Boris I. Chevone",
            "Craig A. Struble",
            "Vincent Y. Jouenne",
            "Dawei Chen",
            "Leonel van Zyl",
            "Ruth G. Alscher"
        ],
        "category": "cs.OH",
        "published_year": "2001",
        "summary": "  Conception, design, and implementation of cDNA microarray experiments present\na variety of bioinformatics challenges for biologists and computational\nscientists. The multiple stages of data acquisition and analysis have motivated\nthe design of Expresso, a system for microarray experiment management. Salient\naspects of Expresso include support for clone replication and randomized\nplacement; automatic gridding, extraction of expression data from each spot,\nand quality monitoring; flexible methods of combining data from individual\nspots into information about clones and functional categories; and the use of\ninductive logic programming for higher-level data analysis and mining. The\ndevelopment of Expresso is occurring in parallel with several generations of\nmicroarray experiments aimed at elucidating genomic responses to drought stress\nin loblolly pine seedlings. The current experimental design incorporates 384\npine cDNAs replicated and randomly placed in two specific microarray layouts.\nWe describe the design of Expresso as well as results of analysis with Expresso\nthat suggest the importance of molecular chaperones and membrane transport\nproteins in mechanisms conferring successful adaptation to long-term drought\nstress.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0110047v1"
    },
    {
        "title": "A multipurpose Hopf deformation of the Algebra of Feynman-like Diagrams",
        "authors": [
            "Grard Henry Edmond Duchamp",
            "Allan I. Solomon",
            "Pawel Blasiak",
            "Karol A. Penson",
            "Andrzej Horzela"
        ],
        "category": "cs.OH",
        "published_year": "2006",
        "summary": "  We construct a three parameter deformation of the Hopf algebra\n$\\mathbf{LDIAG}$. This new algebra is a true Hopf deformation which reduces to\n$\\mathbf{LDIAG}$ on one hand and to $\\mathbf{MQSym}$ on the other, relating\n$\\mathbf{LDIAG}$ to other Hopf algebras of interest in contemporary physics.\nFurther, its product law reproduces that of the algebra of polyzeta functions.\n",
        "pdf_link": "http://arxiv.org/pdf/cs/0609107v2"
    },
    {
        "title": "Diversity-Integration Trade-offs in MIMO Detection",
        "authors": [
            "Antonio De Maio",
            "Marco Lops",
            "Luca Venturino"
        ],
        "category": "cs.OH",
        "published_year": "2008",
        "summary": "  In this work, a MIMO detection problem is considered. At first, we derive the\nGeneralized Likelihood Ratio Test (GLRT) for arbitrary transmitted signals and\narbitrary time-correlation of the disturbance. Then, we investigate design\ncriteria for the transmitted waveforms in both power-unlimited and\npower-limited systems and we study the interplay among the rank of the\noptimized code matrix, the number of transmit diversity paths and the amount of\nenergy integrated along each path. The results show that increasing the rank of\nthe code matrix allows generating a larger number of diversity paths at the\nprice of reducing the average signal-to-clutter level along each path.\n",
        "pdf_link": "http://arxiv.org/pdf/0805.0740v1"
    },
    {
        "title": "Performance Evaluation of SCM-WDM System Using Different Linecoding",
        "authors": [
            "Md. Shamim Reza",
            "Md. Maruf Hossain",
            "Adnan Ahmed Chowdhury",
            "S. M. Shamim Reza",
            "Md. Moshiur Rahman"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  This paper investigates the theoretical performance analysis for a subcarrier\nmultiplexed (SCM) wavelength division multiplexing (WDM) optical transmission\nsystem in presence of optical beat interference (OBI) which occurs during the\nphoto detection process. We have presented a comparison for improving the\nperformance of SCM-WDM system in presence of OBI. Non-return-to zero (NRZ),\nManchester and Miller code (MC) line coding are used for performance\ninvestigation of SCM-WDM system. A suitable signal bandwidth is selected and\n200 KHz is considered as channel bandwidth. Power spectrum of signal and cross\ncomponent for those line coding are analyzed. Comparison results are evaluated\nin terms of signal to OBI ratio for the three linecoding schemes which is\ncalled signal to interference ratio (SIR). It is found that there is a\nsignificant increase in the SIR by employing Miller code compared to NRZ and\nManchester for the same data rate. For example, for a number of subcarriers of\n10, the achievable SIR is about -24 dB for Miller coded system compared to -46\ndB for NRZ coded system and -49 dB for Manchester coded system. The results are\nfound to be satisfactorily agreed with the expected results.\n",
        "pdf_link": "http://arxiv.org/pdf/1004.4830v1"
    },
    {
        "title": "Parallel QR decomposition in LTE-A systems",
        "authors": [
            "Sebastien Aubert",
            "Manar Mohaisen",
            "Fabienne Nouvel",
            "KyungHi Chang"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  The QR Decomposition (QRD) of communication channel matrices is a fundamental\nprerequisite to several detection schemes in Multiple-Input Multiple-Output\n(MIMO) communication systems. Herein, the main feature of the QRD is to\ntransform the non-causal system into a causal system, where consequently\nefficient detection algorithms based on the Successive Interference\nCancellation (SIC) or Sphere Decoder (SD) become possible. Also, QRD can be\nused as a light but efficient antenna selection scheme. In this paper, we\naddress the study of the QRD methods and compare their efficiency in terms of\ncomputational complexity and error rate performance. Moreover, a particular\nattention is paid to the parallelism of the QRD algorithms since it reduces the\nlatency of the matrix factorization.\n",
        "pdf_link": "http://arxiv.org/pdf/1005.4895v1"
    },
    {
        "title": "MIMO Detection Algorithms for High Data Rate Wireless Transmission",
        "authors": [
            "Nirmalendu Bikas Sinha",
            "R. Bera",
            "M. Mitra"
        ],
        "category": "cs.OH",
        "published_year": "2010",
        "summary": "  Motivated by MIMO broad-band fading channel model, in this section a\ncomparative study is presented regarding various uncoded adaptive and\nnon-adaptive MIMO detection algorithms with respect to BER/PER performance, and\nhardware complexity. All the simulations are conducted within MIMO-OFDM\nframework and with a packet structure similar to that of IEEE 802.11a/g\nstandard. As the comparison results show, the RLS algorithm appears to be an\naffordable solution for wideband MIMO system targeting at Giga-bit wireless\ntransmission. So MIMO can overcome huge processing power required for MIMO\ndetection by using optimizing channel coding and MIMO detection.\n",
        "pdf_link": "http://arxiv.org/pdf/1006.3222v1"
    },
    {
        "title": "Transient Stability Assessment of Smart Power System using Complex\n  Networks Framework",
        "authors": [
            "A. B. M. Nasiruzzaman",
            "H. R. Pota"
        ],
        "category": "cs.OH",
        "published_year": "2011",
        "summary": "  In this paper, a new methodology for stability assessment of a smart power\nsystem is proposed. The key to this assessment is an index called betweenness\nindex which is based on ideas from complex network theory. The proposed\nbetweenness index is an improvement of previous works since it considers the\nactual real power flow through the transmission lines along the network.\nFurthermore, this work initiates a new area for complex system research to\nassess the stability of the power system.\n",
        "pdf_link": "http://arxiv.org/pdf/1103.3339v1"
    },
    {
        "title": "A tour about Isaac Newton's life",
        "authors": [
            "A. C. Sparavigna",
            "R. Marazzato"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  Here we propose a tour about the life of Isaac Newton, using a georeferenced\nmethod, based on the free satellite maps. Our tour is modelled on the time-line\nof the great scientist's life, as an ancient \"itinerarium\" was modelled on the\nRoman roads, providing a listing of places and intervening distances, sometimes\nwith short description or symbols concerning the places. KML language and\nGoogle Earth, with its Street View and 3D images are powerful tools to create\nthis virtual tour.\n",
        "pdf_link": "http://arxiv.org/pdf/1203.4966v1"
    },
    {
        "title": "A Multi-State Power Model for Adequacy Assessment of Distributed\n  Generation via Universal Generating Function",
        "authors": [
            "Yan-Fu Li",
            "Enrico Zio"
        ],
        "category": "cs.OH",
        "published_year": "2012",
        "summary": "  The current and future developments of electric power systems are pushing the\nboundaries of reliability assessment to consider distribution networks with\nrenewable generators. Given the stochastic features of these elements, most\nmodeling approaches rely on Monte Carlo simulation. The computational costs\nassociated to the simulation approach force to treating mostly small-sized\nsystems, i.e. with a limited number of lumped components of a given renewable\ntechnology (e.g. wind or solar, etc.) whose behavior is described by a binary\nstate, working or failed. In this paper, we propose an analytical multi-state\nmodeling approach for the reliability assessment of distributed generation\n(DG). The approach allows looking to a number of diverse energy generation\ntechnologies distributed on the system. Multiple states are used to describe\nthe randomness in the generation units, due to the stochastic nature of the\ngeneration sources and of the mechanical degradation/failure behavior of the\ngeneration systems. The universal generating function (UGF) technique is used\nfor the individual component multi-state modeling. A multiplication-type\ncomposition operator is introduced to combine the UGFs for the mechanical\ndegradation and renewable generation source states into the UGF of the\nrenewable generator power output. The overall multi-state DG system UGF is then\nconstructed and classical reliability indices (e.g. loss of load expectation\n(LOLE), expected energy not supplied (EENS)) are computed from the DG system\ngeneration and load UGFs. An application of the model is shown on a DG system\nadapted from the IEEE 34 nodes distribution test feeder.\n",
        "pdf_link": "http://arxiv.org/pdf/1206.6808v1"
    },
    {
        "title": "Demodulation of Sparse PPM Signals with Low Samples Using Trained RIP\n  Matrix",
        "authors": [
            "Seyed Hossein Hosseini",
            "Mahrokh G. Shayesteh",
            "Mehdi Chehel Amirani"
        ],
        "category": "cs.OH",
        "published_year": "2013",
        "summary": "  Compressed sensing (CS) theory considers the restricted isometry property\n(RIP) as a sufficient condition for measurement matrix which guarantees the\nrecovery of any sparse signal from its compressed measurements. The RIP\ncondition also preserves enough information for classification of sparse\nsymbols, even with fewer measurements. In this work, we utilize RIP bound as\nthe cost function for training a simple neural network in order to exploit the\nnear optimal measurements or equivalently near optimal features for\nclassification of a known set of sparse symbols. As an example, we consider\ndemodulation of pulse position modulation (PPM) signals. The results indicate\nthat the proposed method has much better performance than the random\nmeasurements and requires less samples than the optimum matched filter\ndemodulator, at the expense of some performance loss. Further, the proposed\napproach does not need equalizer for multipath channels in contrast to the\nconventional receiver.\n",
        "pdf_link": "http://arxiv.org/pdf/1309.5854v1"
    },
    {
        "title": "Photoplethysmography-Based Heart Rate Monitoring in Physical Activities\n  via Joint Sparse Spectrum Reconstruction",
        "authors": [
            "Zhilin Zhang"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Goal: A new method for heart rate monitoring using photoplethysmography (PPG)\nduring physical activities is proposed. Methods: It jointly estimates spectra\nof PPG signals and simultaneous acceleration signals, utilizing the multiple\nmeasurement vector model in sparse signal recovery. Due to a common sparsity\nconstraint on spectral coefficients, the method can easily identify and remove\nspectral peaks of motion artifact (MA) in PPG spectra. Thus, it does not need\nany extra signal processing modular to remove MA as in some other algorithms.\nFurthermore, seeking spectral peaks associated with heart rate is simplified.\nResults: Experimental results on 12 PPG datasets sampled at 25 Hz and recorded\nduring subjects' fast running showed that it had high performance. The average\nabsolute estimation error was 1.28 beat per minute and the standard deviation\nwas 2.61 beat per minute. Conclusion and Significance: These results show that\nthe method has great potential to be used for PPG-based heart rate monitoring\nin wearable devices for fitness tracking and health monitoring.\n",
        "pdf_link": "http://arxiv.org/pdf/1503.00688v2"
    },
    {
        "title": "Coherent 100G Nonlinear Compensation with Single-Step Digital\n  Backpropagation",
        "authors": [
            "Marco Secondini",
            "Simon Rommel",
            "Francesco Fresi",
            "Enrico Forestieri",
            "Gianluca Meloni",
            "Luca Pot"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Enhanced-SSFM digital backpropagation (DBP) is experimentally demonstrated\nand compared to conventional DBP. A 112 Gb/s PM-QPSK signal is transmitted over\na 3200 km dispersion-unmanaged link. The intradyne coherent receiver includes\nsingle-step digital backpropagation based on the enhanced-SSFM algorithm. In\ncomparison, conventional DBP requires twenty steps to achieve the same\nperformance. An analysis of the computational complexity and structure of the\ntwo algorithms reveals that the overall complexity and power consumption of DBP\nare reduced by a factor of 16 with respect to a conventional implementation,\nwhile the computation time is reduced by a factor of 20. As a result, the\nproposed algorithm enables a practical and effective implementation of DBP in\nreal-time optical receivers, with only a moderate increase of the computational\ncomplexity, power consumption, and latency with respect to a simple\nfeed-forward equalizer for dispersion compensation.\n",
        "pdf_link": "http://arxiv.org/pdf/1507.00921v1"
    },
    {
        "title": "Missing Spectrum-Data Recovery in Cognitive Radio Networks Using\n  Piecewise Constant Nonnegative Matrix Factorization",
        "authors": [
            "Alireza Zaeemzadeh",
            "Mohsen Joneidi",
            "Behzad Shahrasbi",
            "Nazanin Rahnavard"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  In this paper, we propose a missing spectrum data recovery technique for\ncognitive radio (CR) networks using Nonnegative Matrix Factorization (NMF). It\nis shown that the spectrum measurements collected from secondary users (SUs)\ncan be factorized as product of a channel gain matrix times an activation\nmatrix. Then, an NMF method with piecewise constant activation coefficients is\nintroduced to analyze the measurements and estimate the missing spectrum data.\nThe proposed optimization problem is solved by a Majorization-Minimization\ntechnique. The numerical simulation verifies that the proposed technique is\nable to accurately estimate the missing spectrum data in the presence of noise\nand fading.\n",
        "pdf_link": "http://arxiv.org/pdf/1508.07269v1"
    },
    {
        "title": "Fast inference of ill-posed problems within a convex space",
        "authors": [
            "Jorge Fernandez-de-Cossio-Diaz",
            "Roberto Mulet"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  In multiple scientific and technological applications we face the problem of\nhaving low dimensional data to be justified by a linear model defined in a high\ndimensional parameter space. The difference in dimensionality makes the problem\nill-defined: the model is consistent with the data for many values of its\nparameters. The objective is to find the probability distribution of parameter\nvalues consistent with the data, a problem that can be cast as the exploration\nof a high dimensional convex polytope. In this work we introduce a novel\nalgorithm to solve this problem efficiently. It provides results that are\nstatistically indistinguishable from currently used numerical techniques while\nits running time scales linearly with the system size. We show that the\nalgorithm performs robustly in many abstract and practical applications. As\nworking examples we simulate the effects of restricting reaction fluxes on the\nspace of feasible phenotypes of a {\\em genome} scale E. Coli metabolic network\nand infer the traffic flow between origin and destination nodes in a real\ncommunication network.\n",
        "pdf_link": "http://arxiv.org/pdf/1602.08412v1"
    },
    {
        "title": "Axodraw Version 2",
        "authors": [
            "John C. Collins",
            "J. A. M. Vermaseren"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  We present version two of the Latex graphical style file Axodraw. It has a\nnumber of new drawing primitives and many extra options, and it can now work\nwith \\program{pdflatex} to directly produce output in PDF file format (but with\nthe aid of an auxiliary program).\n",
        "pdf_link": "http://arxiv.org/pdf/1606.01177v1"
    },
    {
        "title": "Design and Implementation of a Novel Compatible Encoding Scheme in the\n  Time Domain for Image Sensor Communication",
        "authors": [
            "Trang Nguyen",
            "Mohammad Arif Hossain",
            "Yeong Min Jang"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  This paper presents a modulation scheme in the time domain based on\nOn-Off-Keying and proposes various compatible supports for different types of\nimage sensors. The content of this article is a sub-proposal to the IEEE\n802.15.7r1 Task Group (TG7r1) aimed at Optical Wireless Communication (OWC)\nusing an image sensor as the receiver. The compatibility support is\nindispensable for Image Sensor Communications (ISC) because the rolling shutter\nimage sensors currently available have different frame rates, shutter speeds,\nsampling rates, and resolutions. However, focusing on unidirectional\ncommunications (i.e., data broadcasting, beacons), an asynchronous\ncommunication prototype is also discussed in the paper. Due to the physical\nlimitations associated with typical image sensors (including low and varying\nframe rates, long exposures, and low shutter speeds), the link speed\nperformance is critically considered. Based on the practical measurement of\ncamera response to modulated light, an operating frequency range is suggested\nalong with the similar system architecture, decoding procedure, and algorithms.\nA significant feature of our novel data frame structure is that it can support\nboth typical frame rate cameras (in the oversampling mode) as well as very low\nframe rate cameras (in the error detection mode for a camera whose frame rate\nis lower than the transmission packet rate). A high frame rate camera, i.e., no\nless than 20 fps, is supported in an oversampling mode in which a majority\nvoting scheme for decoding data is applied. A low frame rate camera, i.e., when\nthe frame rate drops to less than 20 fps at some certain time, is supported by\nan error detection mode in which any missing data sub-packet is detected in\ndecoding and later corrected by external code. Numerical results and valuable\nanalysis are also included to indicate the capability of the proposed schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/1606.05666v1"
    },
    {
        "title": "Phase Noise Influence in Optical OFDM Systems employing RF Pilot Tone\n  for Phase Noise Cancellation",
        "authors": [
            "Gunnar Jacobsen",
            "Leonid G. Kazovsky",
            "Tianhua Xu",
            "Sergei Popov",
            "Jie Li",
            "Yimo Zhang",
            "Ari T. Friberg"
        ],
        "category": "cs.OH",
        "published_year": "2016",
        "summary": "  For coherent and direct-detection Orthogonal Frequency Division Multiplexed\n(OFDM) systems employing radio frequency (RF) pilot tone phase noise\ncancellation the influence of laser phase noise is evaluated. Novel analytical\nresults for the common phase error and for the (modulation dependent) inter\ncarrier interference are evaluated based upon Gaussian statistics for the laser\nphase noise. In the evaluation it is accounted for that the laser phase noise\nis filtered in the correlation signal detection. Numerical results are\npresented for OFDM systems with 4 and 16 PSK modulation, 200 OFDM bins and baud\nrate of 1 GS/s. It is found that about 225 km transmission is feasible for the\ncoherent 4PSK-OFDM system over normal (G.652) fiber.\n",
        "pdf_link": "http://arxiv.org/pdf/1607.08791v1"
    },
    {
        "title": "Quantum Mechanical Approach to Modelling Reliability of Sensor Reports",
        "authors": [
            "Zichang He",
            "Wen Jiang"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Dempster-Shafer evidence theory is wildly applied in multi-sensor data\nfusion. However, lots of uncertainty and interference exist in practical\nsituation, especially in the battle field. It is still an open issue to model\nthe reliability of sensor reports. Many methods are proposed based on the\nrelationship among collected data. In this letter, we proposed a quantum\nmechanical approach to evaluate the reliability of sensor reports, which is\nbased on the properties of a sensor itself. The proposed method is used to\nmodify the combining of evidences.\n",
        "pdf_link": "http://arxiv.org/pdf/1705.01013v1"
    },
    {
        "title": "DeepPicar: A Low-cost Deep Neural Network-based Autonomous Car",
        "authors": [
            "Michael G. Bechtel",
            "Elise McEllhiney",
            "Minje Kim",
            "Heechul Yun"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  We present DeepPicar, a low-cost deep neural network based autonomous car\nplatform. DeepPicar is a small scale replication of a real self-driving car\ncalled DAVE-2 by NVIDIA. DAVE-2 uses a deep convolutional neural network (CNN),\nwhich takes images from a front-facing camera as input and produces car\nsteering angles as output. DeepPicar uses the same network architecture---9\nlayers, 27 million connections and 250K parameters---and can drive itself in\nreal-time using a web camera and a Raspberry Pi 3 quad-core platform. Using\nDeepPicar, we analyze the Pi 3's computing capabilities to support end-to-end\ndeep learning based real-time control of autonomous vehicles. We also\nsystematically compare other contemporary embedded computing platforms using\nthe DeepPicar's CNN-based real-time control workload. We find that all tested\nplatforms, including the Pi 3, are capable of supporting the CNN-based\nreal-time control, from 20 Hz up to 100 Hz, depending on hardware platform.\nHowever, we find that shared resource contention remains an important issue\nthat must be considered in applying CNN models on shared memory based embedded\ncomputing platforms; we observe up to 11.6X execution time increase in the CNN\nbased control loop due to shared resource contention. To protect the CNN\nworkload, we also evaluate state-of-the-art cache partitioning and memory\nbandwidth throttling techniques on the Pi 3. We find that cache partitioning is\nineffective, while memory bandwidth throttling is an effective solution.\n",
        "pdf_link": "http://arxiv.org/pdf/1712.08644v4"
    },
    {
        "title": "TikZ-FeynHand: Basic User Guide",
        "authors": [
            "Max Dohse"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  This is a userguide for the LaTex package Tikz-FeynHand at\nhttps://ctan.org/pkg/tikz-feynhand which let's you draw Feynman diagrams using\nTikZ. It contains many examples and a 5-minute introduction to TikZ.\n  The package is a low-end modification of the package TikZ-Feynman at\nhttps://ctan.org/pkg/tikz-feynman, one of whose principal advantages is the\nautomatic generation of diagrams, for which it needs LuaTex. FeynHand only\nprovides the manual mode and hence runs in LaTex without any reference to\nLuaTex.\n  In addition it provides some NEW STYLES for vertices and propagators,\nalternative SHORTER KEYWORDS in addition to TikZ-Feynman's longer ones, some\nshortcut commands for QUICKLY CUSTOMIZING the diagrams' look, and the new\nfeature to put one propagator \"ON TOP\" of another.\n",
        "pdf_link": "http://arxiv.org/pdf/1802.00689v1"
    },
    {
        "title": "Energy Efficiency and Emission Testing for Connected and Automated\n  Vehicles Using Real-World Driving Data",
        "authors": [
            "Yan Chang",
            "Weiqing Yang",
            "Ding Zhao"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  By using the onboard sensing and external connectivity technology, connected\nand automated vehicles (CAV) could lead to improved energy efficiency, better\nrouting, and lower traffic congestion. With the rapid development of the\ntechnology and adaptation of CAV, it is more critical to develop the universal\nevaluation method and the testing standard which could evaluate the impacts on\nenergy consumption and environmental pollution of CAV fairly, especially under\nthe various traffic conditions. In this paper, we proposed a new method and\nframework to evaluate the energy efficiency and emission of the vehicle based\non the unsupervised learning methods. Both the real-world driving data of the\nevaluated vehicle and the large naturalistic driving dataset are used to\nperform the driving primitive analysis and coupling. Then the linear weighted\nestimation method could be used to calculate the testing result of the\nevaluated vehicle. The results show that this method can successfully identify\nthe typical driving primitives. The couples of the driving primitives from the\nevaluated vehicle and the typical driving primitives from the large real-world\ndriving dataset coincide with each other very well. This new method could\nenhance the standard development of the energy efficiency and emission testing\nof CAV and other off-cycle credits.\n",
        "pdf_link": "http://arxiv.org/pdf/1805.07643v2"
    },
    {
        "title": "Research on the pixel-based and object-oriented methods of urban feature\n  extraction with GF-2 remote-sensing images",
        "authors": [
            "Dong-dong Zhang",
            "Lei Zhang",
            "Vladimir Zaborovsky",
            "Feng Xie",
            "Yan-wen Wu",
            "Ting-ting Lu"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  During the rapid urbanization construction of China, acquisition of urban\ngeographic information and timely data updating are important and fundamental\ntasks for the refined management of cities. With the development of domestic\nremote sensing technology, the application of Gaofen-2 (GF-2) high-resolution\nremote sensing images can greatly improve the accuracy of information\nextraction. This paper introduces an approach using object-oriented\nclassification methods for urban feature extraction based on GF-2 satellite\ndata. A combination of spectral, spatial attributes and membership functions\nwas employed for mapping the urban features of Qinhuai District, Nanjing. The\ndata preprocessing is carried out by ENVI software, and the subsequent data is\nexported into the eCognition software for object-oriented classification and\nextraction of urban feature information. Finally, the obtained raster image\nclassification results are vectorized using the ARCGIS software, and the vector\ngraphics are stored in the library, which can be used for further analysis and\nmodeling. Accuracy assessment was performed using ground truth data acquired by\nvisual interpretation and from other reliable secondary data sources. Compared\nwith the result of pixel-based supervised (neural net) classification, the\ndeveloped object-oriented method can significantly improve extraction accuracy,\nand after manual interpretation, an overall accuracy of 95.44% can be achieved,\nwith a Kappa coefficient of 0.9405, which objectively confirmed the superiority\nof the object-oriented method and the feasibility of the utilization of GF-2\nsatellite data.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.03412v1"
    },
    {
        "title": "Trial of an AI: Empowering people to explore law and science challenges",
        "authors": [
            "Gaudron Arthur"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Artificial Intelligence represents many things: a new market to conquer or a\nquality label for tech companies, a threat for traditional industries, a menace\nfor democracy, or a blessing for our busy everyday life. The press abounds in\nexamples illustrating these aspects, but one should draw not hasty and\npremature conclusions. The first successes in AI have been a surprise for\nsociety at large-including researchers in the field. Today, after the initial\nstupefaction, we have examples of the system reactions: traditional companies\nare heavily investing in AI, social platforms are monitored during elections,\ndata collection is more and more regulated, etc. The resilience of an\norganization (i.e. its capacity to resist to a shock) relies deeply on the\nperception of its environment. Future problems have to be anticipated, while\nunforeseen events occurring have to be quickly identified in order to be\nmitigated as fast as possible. The author states that this clear perception\nstarts with a common definition of AI in terms of capacities and limits. AI\npractitioners should make notions and concepts accessible to the general public\nand the impacted fields (e.g. industries, law, education). It is a truism that\nonly law experts would have the potential to estimate IA impacts on judicial\nsystem. However, questions remain on how to connect different kind of expertise\nand what is the appropriate level of detail required for the knowledge\nexchanges. And the same consideration is true for dissemination towards\nsociety. Ultimately, society will live with decisions made by the \"experts\". It\nsounds wise to involve society in the decision process rather than risking to\npay consequences later. Therefore, society also needs the key concepts to\nunderstand AI impact on their life. This was the purpose of the trial of an IA\nthat took place in October 2018 at the Court of Appeal of Paris: gathering\nexperts from various fields to expose challenges in law and science towards a\ngeneral public.\n",
        "pdf_link": "http://arxiv.org/pdf/1903.09518v1"
    },
    {
        "title": "Towards Leveraging End-of-Life Tools as an Asset: Value Co-Creation\n  based on Deep Learning in the Machining Industry",
        "authors": [
            "Jannis Walk",
            "Niklas Khl",
            "Jonathan Schfer"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Sustainability is the key concept in the management of products that reached\ntheir end-of-life. We propose that end-of-life products have -- besides their\nvalue as recyclable assets -- additional value for producer and consumer. We\nargue this is especially true for the machining industry, where we illustrate\nan automatic characterization of worn cutting tools to foster value co-creation\nbetween tool manufacturer and tool user (customer) in the future. In the work\nat hand, we present a deep-learning-based computer vision system for the\nautomatic classification of worn tools regarding flank wear and chipping. The\nresulting Matthews Correlation Coefficient of 0.878 and 0.644 confirms the\nfeasibility of our system based on the VGG-16 network and Gradient Boosting.\nBased on these first results we derive a research agenda which addresses the\nneed for a more holistic tool characterization by semantic segmentation and\nassesses the perceived business impact and usability by different user groups.\n",
        "pdf_link": "http://arxiv.org/pdf/2008.01053v1"
    },
    {
        "title": "Z-checker: A Framework for Assessing Lossy Compression of Scientific\n  Data",
        "authors": [
            "Dingwen Tao",
            "Sheng Di",
            "Hanqi Guo",
            "Zizhong Chen",
            "Franck Cappello"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Because of vast volume of data being produced by today's scientific\nsimulations and experiments, lossy data compressor allowing user-controlled\nloss of accuracy during the compression is a relevant solution for\nsignificantly reducing the data size. However, lossy compressor developers and\nusers are missing a tool to explore the features of scientific datasets and\nunderstand the data alteration after compression in a systematic and reliable\nway. To address this gap, we have designed and implemented a generic framework\ncalled Z-checker. On the one hand, Z-checker combines a battery of data\nanalysis components for data compression. On the other hand, Z-checker is\nimplemented as an open-source community tool to which users and developers can\ncontribute and add new analysis components based on their additional analysis\ndemands. In this paper, we present a survey of existing lossy compressors. Then\nwe describe the design framework of Z-checker, in which we integrated\nevaluation metrics proposed in prior work as well as other analysis tools.\nSpecifically, for lossy compressor developers, Z-checker can be used to\ncharacterize critical properties of any dataset to improve compression\nstrategies. For lossy compression users, Z-checker can detect the compression\nquality, provide various global distortion analysis comparing the original data\nwith the decompressed data and statistical analysis of the compression error.\nZ-checker can perform the analysis with either coarse granularity or fine\ngranularity, such that the users and developers can select the best-fit,\nadaptive compressors for different parts of the dataset. Z-checker features a\nvisualization interface displaying all analysis results in addition to some\nbasic views of the datasets such as time series. To the best of our knowledge,\nZ-checker is the first tool designed to assess lossy compression\ncomprehensively for scientific datasets.\n",
        "pdf_link": "http://arxiv.org/pdf/1707.09320v2"
    },
    {
        "title": "The Separator, a Two-Phase Oil and Water Gravity CPS Separator Testbed",
        "authors": [
            "Michael Breza",
            "Laksh Bhatia",
            "Ivana Tomic",
            "Anqi Fu",
            "Waqas Ikram",
            "Valentinos Kongezos",
            "Julie A. McCann"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Industrial Control Systems (ICS) are evolving with advances in new\ntechnology. The addition of wireless sensors and actuators and new control\ntechniques means that engineering practices from communication systems are\nbeing integrated into those used for control systems. The two are engineered in\nvery different ways. Neither engineering approach is capable of accounting for\nthe subtle interactions and interdependence that occur when the two are\ncombined. This paper describes our first steps to bridge this gap, and push the\nboundaries of both computer communication system and control system design. We\npresent The Separator testbed, a Cyber-Physical testbed enabling our search for\na suitable way to engineer systems that combine both computer networks and\ncontrol systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2002.00945v1"
    },
    {
        "title": "Limitations of PLL simulation: hidden oscillations in MatLab and SPICE",
        "authors": [
            "G. Bianchi",
            "N. V. Kuznetsov",
            "G. A. Leonov",
            "M. V. Yuldashev",
            "R. V. Yuldashev"
        ],
        "category": "cs.OH",
        "published_year": "2015",
        "summary": "  Nonlinear analysis of the phase-locked loop (PLL) based circuits is a\nchallenging task, thus in modern engineering literature simplified mathematical\nmodels and simulation are widely used for their study. In this work the\nlimitations of numerical approach is discussed and it is shown that, e.g.\nhidden oscillations may not be found by simulation. Corresponding examples in\nSPICE and MatLab, which may lead to wrong conclusions concerning the\noperability of PLL-based circuits, are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/1506.02484v2"
    },
    {
        "title": "A software framework for pipelined arithmetic algorithms in field\n  programmable gate arrays",
        "authors": [
            "J. B. Kim",
            "E. Won"
        ],
        "category": "cs.OH",
        "published_year": "2017",
        "summary": "  Pipelined algorithms implemented in field programmable gate arrays are being\nextensively used for hardware triggers in the modern experimental high energy\nphysics field and the complexity of such algorithms are increases rapidly. For\ndevelopment of such hardware triggers, algorithms are developed in\n$\\texttt{C++}$, ported to hardware description language for synthesizing\nfirmware, and then ported back to $\\texttt{C++}$ for simulating the firmware\nresponse down to the single bit level. We present a $\\texttt{C++}$ software\nframework which automatically simulates and generates hardware description\nlanguage code for pipelined arithmetic algorithms.\n",
        "pdf_link": "http://arxiv.org/pdf/1710.09235v3"
    },
    {
        "title": "Research on Artificial Intelligence Ethics Based on the Evolution of\n  Population Knowledge Base",
        "authors": [
            "Feng Liu",
            "Yong Shi"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The unclear development direction of human society is a deep reason for that\nit is difficult to form a uniform ethical standard for human society and\nartificial intelligence. Since the 21st century, the latest advances in the\nInternet, brain science and artificial intelligence have brought new\ninspiration to the research on the development direction of human society.\nThrough the study of the Internet brain model, AI IQ evaluation, and the\nevolution of the brain, this paper proposes that the evolution of population\nknowledge base is the key for judging the development direction of human\nsociety, thereby discussing the standards and norms for the construction of\nartificial intelligence ethics.\n",
        "pdf_link": "http://arxiv.org/pdf/1806.10095v3"
    },
    {
        "title": "Galaxy Learning -- A Position Paper",
        "authors": [
            "Chao Wu",
            "Jun Xiao",
            "Gang Huang",
            "Fei Wu"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The recent rapid development of artificial intelligence (AI, mainly driven by\nmachine learning research, especially deep learning) has achieved phenomenal\nsuccess in various applications. However, to further apply AI technologies in\nreal-world context, several significant issues regarding the AI ecosystem\nshould be addressed. We identify the main issues as data privacy, ownership,\nand exchange, which are difficult to be solved with the current centralized\nparadigm of machine learning training methodology. As a result, we propose a\nnovel model training paradigm based on blockchain, named Galaxy Learning, which\naims to train a model with distributed data and to reserve the data ownership\nfor their owners. In this new paradigm, encrypted models are moved around\ninstead, and are federated once trained. Model training, as well as the\ncommunication, is achieved with blockchain and its smart contracts. Pricing of\ntraining data is determined by its contribution, and therefore it is not about\nthe exchange of data ownership. In this position paper, we describe the\nmotivation, paradigm, design, and challenges as well as opportunities of Galaxy\nLearning.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.00753v1"
    },
    {
        "title": "Image-based reconstruction for the impact problems by using DPNNs",
        "authors": [
            "Yu Li",
            "Hu Wang",
            "Wenquan Shuai",
            "Honghao Zhang",
            "Yong Peng"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  With the improvement of the pattern recognition and feature extraction of\nDeep Neural Networks (DPNNs), image-based design and optimization have been\nwidely used in multidisciplinary researches. Recently, a Reconstructive Neural\nNetwork (ReConNN) has been proposed to obtain an image-based model from an\nanalysis-based model [1, 2], and a steady-state heat transfer of a heat sink\nhas been successfully reconstructed. Commonly, this method is suitable to\nhandle stable-state problems. However, it has difficulties handling nonlinear\ntransient impact problems, due to the bottlenecks of the Deep Neural Network\n(DPNN). For example, nonlinear transient problems make it difficult for the\nGenerative Adversarial Network (GAN) to generate various reasonable images.\nTherefore, in this study, an improved ReConNN method is proposed to address the\nmentioned weaknesses. Time-dependent ordered images can be generated.\nFurthermore, the improved method is successfully applied in impact simulation\ncase and engineering experiment. Through the experiments, comparisons and\nanalyses, the improved method is demonstrated to outperform the former one in\nterms of its accuracy, efficiency and costs.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.03229v3"
    },
    {
        "title": "Governance by Glass-Box: Implementing Transparent Moral Bounds for AI\n  Behaviour",
        "authors": [
            "Andrea Aler Tubella",
            "Andreas Theodorou",
            "Virginia Dignum",
            "Frank Dignum"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Artificial Intelligence (AI) applications are being used to predict and\nassess behaviour in multiple domains, such as criminal justice and consumer\nfinance, which directly affect human well-being. However, if AI is to improve\npeople's lives, then people must be able to trust AI, which means being able to\nunderstand what the system is doing and why. Even though transparency is often\nseen as the requirement in this case, realistically it might not always be\npossible or desirable, whereas the need to ensure that the system operates\nwithin set moral bounds remains. In this paper, we present an approach to\nevaluate the moral bounds of an AI system based on the monitoring of its inputs\nand outputs. We place a \"glass box\" around the system by mapping moral values\ninto explicit verifiable norms that constrain inputs and outputs, in such a way\nthat if these remain within the box we can guarantee that the system adheres to\nthe value. The focus on inputs and outputs allows for the verification and\ncomparison of vastly different intelligent systems; from deep neural networks\nto agent-based systems. The explicit transformation of abstract moral values\ninto concrete norms brings great benefits in terms of explainability;\nstakeholders know exactly how the system is interpreting and employing relevant\nabstract moral human values and calibrate their trust accordingly. Moreover, by\noperating at a higher level we can check the compliance of the system with\ndifferent interpretations of the same value. These advantages will have an\nimpact on the well-being of AI systems users at large, building their trust and\nproviding them with concrete knowledge on how systems adhere to moral values.\n",
        "pdf_link": "http://arxiv.org/pdf/1905.04994v2"
    },
    {
        "title": "Non-linearity identification for construction workers'\n  personality-safety behaviour predictive relationship using neural network and\n  linear regression modelling",
        "authors": [
            "Yifan Gao",
            "Vicente A. Gonzalez",
            "Tak Wing Yiu",
            "Guillermo Cabrera-Guerrerod"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The prediction of workers' safety behaviour can help identify vulnerable\nworkers who intend to undertake unsafe behaviours and be useful in the design\nof management practices to minimise the occurrence of accidents. The latest\nliterature has evidenced that there is within-population diversity that leads\npeople's intended safety behaviours in the workplace, which are found to vary\namong individuals as a function of their personality traits. In this study, an\ninnovative forecasting model, which employs neural network algorithms, is\ndeveloped to numerically simulate the predictive relationship between\nconstruction workers' personality traits and their intended safety behaviour.\nThe data-driven nature of neural network enabled a reliable estimate of the\nrelationship, which allowed this research to find that a nonlinear effect\nexists in the relationship. This research has practical implications. The\nneural network developed is shown to have highly satisfactory prediction\naccuracy and is thereby potentially useful for assisting project\ndecision-makers to assess how prone workers are to carry out unsafe behaviours\nin the workplace.\n",
        "pdf_link": "http://arxiv.org/pdf/1912.05944v3"
    },
    {
        "title": "Efficient Programmable Random Variate Generation Accelerator from Sensor\n  Noise",
        "authors": [
            "James Timothy Meech",
            "Phillip Stanley-Marbell"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  We introduce a method for non-uniform random number generation based on\nsampling a physical process in a controlled environment. We demonstrate one\nproof-of-concept implementation of the method that reduces the error of Monte\nCarlo integration of a univariate Gaussian by 1068 times while doubling the\nspeed of the Monte Carlo simulation. We show that the supply voltage and\ntemperature of the physical process must be controlled to prevent the mean and\nstandard deviation of the random number generator from drifting.\n",
        "pdf_link": "http://arxiv.org/pdf/2001.05400v2"
    },
    {
        "title": "High Performance Interference Suppression in Multi-User Massive MIMO\n  Detector",
        "authors": [
            "Andrey Ivanov",
            "Alexander Osinsky",
            "Dmitry Lakontsev",
            "Dmitry Yarotsky"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  In this paper, we propose a new nonlinear detector with improved interference\nsuppression in Multi-User Multiple Input, Multiple Output (MU-MIMO) system. The\nproposed detector is a combination of the following parts: QR decomposition\n(QRD), low complexity users sorting before QRD, sorting-reduced (SR) K-best\nmethod and minimum mean square error (MMSE) pre-processing. Our method\noutperforms a linear interference rejection combining (IRC, i.e. MMSE\nnaturally) method significantly in both strong interference and additive white\nnoise scenarios with both ideal and real channel estimations. This result has\nwide application importance for scenarios with strong interference, i.e. when\nco-located users utilize the internet in stadium, highway, shopping center,\netc. Simulation results are presented for the non-line of sight 3D-UMa model of\n5G QuaDRiGa 2.0 channel for 16 highly correlated single-antenna users with\nQAM16 modulation in 64 antennas of Massive MIMO system. The performance was\ncompared with MMSE and other detection approaches.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.03466v1"
    },
    {
        "title": "Dyslexia and Dysgraphia prediction: A new machine learning approach",
        "authors": [
            "Gilles Richard",
            "Mathieu Serrurier"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Learning disabilities like dysgraphia, dyslexia, dyspraxia, etc. interfere\nwith academic achievements but have also long terms consequences beyond the\nacademic time. It is widely admitted that between 5% to 10% of the world\npopulation is subject to this kind of disabilities. For assessing such\ndisabilities in early childhood, children have to solve a battery of tests.\nHuman experts score these tests, and decide whether the children require\nspecific education strategy on the basis of their marks. The assessment can be\nlengthy, costly and emotionally painful. In this paper, we investigate how\nArtificial Intelligence can help in automating this assessment. Gathering a\ndataset of handwritten text pictures and audio recordings, both from standard\nchildren and from dyslexic and/or dysgraphic children, we apply machine\nlearning techniques for classification in order to analyze the differences\nbetween dyslexic/dysgraphic and standard readers/writers and to build a model.\nThe model is trained on simple features obtained by analysing the pictures and\nthe audio files. Our preliminary implementation shows relatively high\nperformances on the dataset we have used. This suggests the possibility to\nscreen dyslexia and dysgraphia via non-invasive methods in an accurate way as\nsoon as enough data are available.\n",
        "pdf_link": "http://arxiv.org/pdf/2005.06401v1"
    },
    {
        "title": "A System for the Generation of Synthetic Wide Area Aerial Surveillance\n  Imagery",
        "authors": [
            "Elias J Griffith",
            "Chinmaya Mishra",
            "Jason F. Ralph",
            "Simon Maskell"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  The development, benchmarking and validation of aerial Persistent\nSurveillance (PS) algorithms requires access to specialist Wide Area Aerial\nSurveillance (WAAS) datasets. Such datasets are difficult to obtain and are\noften extremely large both in spatial resolution and temporal duration. This\npaper outlines an approach to the simulation of complex urban environments and\ndemonstrates the viability of using this approach for the generation of\nsimulated sensor data, corresponding to the use of wide area imaging systems\nfor surveillance and reconnaissance applications. This provides a\ncost-effective method to generate datasets for vehicle tracking algorithms and\nanomaly detection methods. The system fuses the Simulation of Urban Mobility\n(SUMO) traffic simulator with a MATLAB controller and an image generator to\ncreate scenes containing uninterrupted door-to-door journeys across large areas\nof the urban environment. This `pattern-of-life' approach provides\nthree-dimensional visual information with natural movement and traffic flows.\nThis can then be used to provide simulated sensor measurements (e.g. visual\nband and infrared video imagery) and automatic access to ground-truth data for\nthe evaluation of multi-target tracking systems.\n",
        "pdf_link": "http://arxiv.org/pdf/1803.04856v1"
    },
    {
        "title": "Appliance Event Detection -- A Multivariate, Supervised Classification\n  Approach",
        "authors": [
            "Matthias Kahl",
            "Thomas Kriechbaumer",
            "Daniel Jorde",
            "Anwar Ul Haq",
            "Hans-Arno Jacobsen"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Non-intrusive load monitoring (NILM) is a modern and still expanding\ntechnique, helping to understand fundamental energy consumption patterns and\nappliance characteristics. Appliance event detection is an elementary step in\nthe NILM pipeline. Unfortunately, several types of appliances (e.g., switching\nmode power supply (SMPS) or multi-state) are known to challenge\nstate-of-the-art event detection systems due to their noisy consumption\nprofiles. Classical rule-based event detection system become infeasible and\ncomplex for these appliances. By stepping away from distinct event definitions,\nwe can learn from a consumer-configured event model to differentiate between\nrelevant and irrelevant event transients.\n  We introduce a boosting oriented adaptive training, that uses false positives\nfrom the initial training area to reduce the number of false positives on the\ntest area substantially. The results show a false positive decrease by more\nthan a factor of eight on a dataset that has a strong focus on SMPS-driven\nappliances. To obtain a stable event detection system, we applied several\nexperiments on different parameters to measure its performance. These\nexperiments include the evaluation of six event features from the spectral and\ntime domain, different types of feature space normalization to eliminate\nundesired feature weighting, the conventional and adaptive training, and two\ncommon classifiers with its optimal parameter settings. The evaluations are\nperformed on two publicly available energy datasets with high sampling rates:\nBLUED and BLOND-50.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.11580v1"
    },
    {
        "title": "Smart Laptop Bag with Machine Learning for Activity Recognition",
        "authors": [
            "Dwij Sukeshkumar Sheth",
            "Shantanu Singh",
            "Prakhar S Mathur",
            "Vydeki D"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  In todays world of smart living, the smart laptop bag, presented in this\npaper, provides a better solution to keep track of our precious possessions and\nmonitoring them in real time. As the world moves towards a much tech-savvy\ndirection, the novel laptop bag discussed here facilitates the user to perform\nlocation tracking, ambiance monitoring, user-state monitoring etc. in one\ndevice. The innovative design uses cloud computing and machine learning\nalgorithms to monitor the health of the user and many parameters of the bag.\nThe emergency alert system in this bag could be trained to send appropriate\nnotifications to emergency contacts of the user, in case of abnormal health\nconditions or theft of the bag. The experimental smart laptop bag uses deep\nneural network, which was trained and tested over the various parameters from\nthe bag and produces above 95% accurate results.\n",
        "pdf_link": "http://arxiv.org/pdf/1904.11882v1"
    },
    {
        "title": "Value-Added Chemical Discovery Using Reinforcement Learning",
        "authors": [
            "Peihong Jiang",
            "Hieu Doan",
            "Sandeep Madireddy",
            "Rajeev Surendran Assary",
            "Prasanna Balaprakash"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Computer-assisted synthesis planning aims to help chemists find better\nreaction pathways faster. Finding viable and short pathways from sugar\nmolecules to value-added chemicals can be modeled as a retrosynthesis planning\nproblem with a catalyst allowed. This is a crucial step in efficient biomass\nconversion. The traditional computational chemistry approach to identifying\npossible reaction pathways involves computing the reaction energies of hundreds\nof intermediates, which is a critical bottleneck in silico reaction discovery.\nDeep reinforcement learning has shown in other domains that a well-trained\nagent with little or no prior human knowledge can surpass human performance.\nWhile some effort has been made to adapt machine learning techniques to the\nretrosynthesis planning problem, value-added chemical discovery presents unique\nchallenges. Specifically, the reaction can occur in several different sites in\na molecule, a subtle case that has never been treated in previous works. With a\nmore versatile formulation of the problem as a Markov decision process, we\naddress the problem using deep reinforcement learning techniques and present\npromising preliminary results.\n",
        "pdf_link": "http://arxiv.org/pdf/1911.07630v1"
    },
    {
        "title": "6-Layer Model for a Structured Description and Categorization of Urban\n  Traffic and Environment",
        "authors": [
            "Maike Scholtes",
            "Lukas Westhofen",
            "Lara Ruth Turner",
            "Katrin Lotto",
            "Michael Schuldes",
            "Hendrik Weber",
            "Nicolas Wagener",
            "Christian Neurohr",
            "Martin Bollmann",
            "Franziska Krtke",
            "Johannes Hiller",
            "Michael Hoss",
            "Julian Bock",
            "Lutz Eckstein"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Verification and validation of automated driving functions impose large\nchallenges. Currently, scenario-based approaches are investigated in research\nand industry, aiming at a reduction of testing efforts by specifying safety\nrelevant scenarios. To define those scenarios and operate in a complex\nreal-world design domain, a structured description of the environment is\nneeded. Within the PEGASUS research project, the 6-Layer Model (6LM) was\nintroduced for the description of highway scenarios. This paper refines the 6LM\nand extends it to urban traffic and environment. As defined in PEGASUS, the 6LM\nprovides the possibility to categorize the environment and, therefore,\nfunctions as a structured basis for subsequent scenario description. The model\nenables a structured description and categorization of the general environment,\nwithout incorporating any knowledge or anticipating any functions of actors.\nBeyond that, there is a variety of other applications of the 6LM, which are\nelaborated in this paper. The 6LM includes a description of the road network\nand traffic guidance objects, roadside structures, temporary modifications of\nthe former, dynamic objects, environmental conditions and digital information.\nThe work at hand specifies each layer by categorizing its items. Guidelines are\nformulated and explanatory examples are given to standardize the application of\nthe model for an objective environment description. In contrast to previous\npublications, the model and its design are described in far more detail.\nFinally, the holistic description of the 6LM presented includes remarks on\npossible future work when expanding the concept to machine perception aspects.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.06319v2"
    },
    {
        "title": "Calibrating Path Choices and Train Capacities for Urban Rail Transit\n  Simulation Models Using Smart Card and Train Movement Data",
        "authors": [
            "Baichuan Mo",
            "Zhenliang Ma",
            "Haris N. Koutsopoulos",
            "Jinhua Zhao"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Transit network simulation models are often used for performance and\nretrospective analysis of urban rail systems, taking advantage of the\navailability of extensive automated fare collection (AFC) and automated vehicle\nlocation (AVL) data. Important inputs to such models, in addition to\norigin-destination flows, include passenger path choices and train capacity.\nTrain capacity, which has often been overlooked in the literature, is an\nimportant input that exhibits a lot of variabilities. The paper proposes a\nsimulation-based optimization (SBO) framework to simultaneously calibrate path\nchoices and train capacity for urban rail systems using AFC and AVL data. The\ncalibration is formulated as an optimization problem with a black-box objective\nfunction. Seven algorithms from four branches of SBO solving methods are\nevaluated. The algorithms are evaluated using an experimental design that\nincludes five scenarios, representing different degrees of path choice\nrandomness and crowding sensitivity. Data from the Hong Kong Mass Transit\nRailway (MTR) system is used as a case study. The data is used to generate\nsynthetic observations used as \"ground truth\". The results show that the\nresponse surface methods (particularly Constrained Optimization using Response\nSurfaces) have consistently good performance under all scenarios. The proposed\napproach drives large-scale simulation applications for monitoring and\nplanning.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.07731v3"
    },
    {
        "title": "Observement as Universal Measurement",
        "authors": [
            "David G. Green",
            "Kerri Morgan",
            "Marc Cheong"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Measurement theory is the cornerstone of science, but no equivalent theory\nunderpins the huge volumes of non-numerical data now being generated. In this\nstudy, we show that replacing numbers with alternative mathematical models,\nsuch as strings and graphs, generalises traditional measurement to provide\nrigorous, formal systems (`observement') for recording and interpreting\nnon-numerical data. Moreover, we show that these representations are already\nwidely used and identify general classes of interpretive methodologies implicit\nin representations based on character strings and graphs (networks). This\nimplies that a generalised concept of measurement has the potential to reveal\nnew insights as well as deep connections between different fields of research.\n",
        "pdf_link": "http://arxiv.org/pdf/2012.12095v1"
    },
    {
        "title": "Using I4.0 digital twins in agriculture",
        "authors": [
            "Rodrigo Falco",
            "Raghad Matar",
            "Bernd Rauch"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Agriculture is a huge domain where an enormous landscape of systems interact\nto support agricultural processes, which are becoming increasingly digital.\nFrom the perspective of agricultural service providers, a prominent challenge\nis interoperability. In the Fraunhofer lighthouse project Cognitive Agriculture\n(COGNAC), we investigated how the usage of Industry 4.0 digital twins (I4.0\nDTs) can help overcome this challenge. This paper contributes architecture\ndrivers and a solution concept using I4.0 DTs in the agricultural domain.\nFurthermore, we discuss the opportunities and limitations offered by I4.0 DTs\nfor the agricultural domain.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.09682v1"
    },
    {
        "title": "Lost in Algorithms",
        "authors": [
            "Andrew N. Sloss"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Algorithms are becoming more capable, and with that comes hic sunt dracones\n(here be dragons). The term symbolizes areas beyond our known maps. We use this\nterm since we are stepping into an exciting, potentially dangerous, and unknown\narea with algorithms. Our curiosity to understand the natural world drives our\nsearch for new methods. For this reason, it is crucial to explore this subject.\n  The project's objective is to overlay the information obtained, in\nconjunction with the state of hardware today, to see if we can determine the\nlikely directions for future algorithms'. Even though we slightly cover\nnon-classical computing in this paper, our primary focus is on classical\ncomputing (i.e., digital computers). It is worth noting that non-classical\nquantum computing requires classical computers to operate; they are not\nmutually exclusive.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.10333v1"
    },
    {
        "title": "A Framework for Operational Volume Generation for Urban Air Mobility\n  Strategic Deconfliction",
        "authors": [
            "Ellis Lee Thompson",
            "Yan Xu",
            "Peng Wei"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Strategic pre-flight functions focus on the planning and deconfliction of\nroutes for aircraft systems. The urban air mobility concept calls for higher\nlevels of autonomy with onboard and en route functions but also strategic and\npre-flight systems. Existing endeavours into strategic pre-flight functions\nfocus on improving the route generation and strategic deconfliction of these\nroutes. Introduced with the urban air mobility concept is the premise of\noperational volumes. These 4D regions of airspace, describe the intended\noperational region for an aircraft for finite time. Chaining these together\nforms a contract of finite operational volumes over a given route. It is no\nlonger enough to only deconflict routes within the airspace, but to now\nconsider these 4D operational volumes. To provide an effective all-in-one\napproach, we propose a novel framework for generating routes and accompanying\ncontracts of operational volumes, along with deconfliction focused around 4D\noperational volumes. Experimental results show efficiency of operational volume\ngeneration utilising reachability analysis and demonstrate sufficient success\nin deconfliction of operational volumes.\n",
        "pdf_link": "http://arxiv.org/pdf/2301.12961v8"
    },
    {
        "title": "RoboCup Junior in the Hunter Region: Driving the Future of Robotic STEM\n  Education",
        "authors": [
            "Aaron S. W. Wong",
            "Ryan Jeffery",
            "Peter Turner",
            "Scott Sleap",
            "Stephan K. Chalup"
        ],
        "category": "cs.OH",
        "published_year": "2018",
        "summary": "  RoboCup Junior is a project-oriented educational initiative that sponsors\nregional, national and international robotic events for young students in\nprimary and secondary school. It leads children to the fundamentals of teamwork\nand complex problem solving through step-by-step logical thinking using\ncomputers and robots. The Faculty of Engineering and Built Environment at the\nUniversity of Newcastle in Australia has hosted and organized the Hunter\nregional tournament since 2012. This paper presents an analysis of data\ncollected from RoboCup Junior in the Hunter Region, New South Wales, Australia,\nfor a period of six years 2012-2017 inclusive. Our study evaluates the\neffectiveness of the competition in terms of geographical spread, participation\nnumbers, and gender balance. We also present a case study about current\nuniversity students who have previously participated in RoboCup Junior.\n",
        "pdf_link": "http://arxiv.org/pdf/1901.03229v1"
    },
    {
        "title": "Using AI for Economic Upliftment of Handicraft Industry",
        "authors": [
            "Nitya Raviprakash",
            "Sonam Damani",
            "Ankush Chatterjee",
            "Meghana Joshi",
            "Puneet Agrawal"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The handicraft industry is a strong pillar of Indian economy which provides\nlarge-scale employment opportunities to artisans in rural and underprivileged\ncommunities. However, in this era of globalization, diverse modern designs have\nrendered traditional designs old and monotonous, causing an alarming decline of\nhandicraft sales. For this age-old industry to survive the global competition,\nit is imperative to integrate contemporary designs with Indian handicrafts. In\nthis paper, we use novel AI techniques to generate contemporary designs for two\npopular Indian handicrafts - Ikat and Block Print. These techniques were\nsuccessfully employed by communities across India to manufacture and sell\nproducts with greater appeal and revenue. The designs are evaluated to be\nsignificantly more likeable and marketable than the current designs used by\nartisans.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.02014v1"
    },
    {
        "title": "Earthquake Prediction With Artificial Neural Network Method: The\n  Application Of West Anatolian Fault In Turkey",
        "authors": [
            "Handan Cam",
            "Osman Duman"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  A method that exactly knows the earthquakes beforehand and can generalize\nthem cannot still been developed. However, earthquakes are tried to be\npredicted through numerous methods. One of these methods, artificial neural\nnetworks give appropriate outputs to different patterns by learning the\nrelationship between the determined inputs and outputs. In this study, a\nfeedforward back propagation artificial neural network that is connected to\nGutenberg-Richter relationship and that bases on b value used in earthquake\npredictions was developed. The artificial neural network was trained employing\nearthquake data belonging to four different regions which have intensive\nseismic activity in the west of Turkey. After the training process, the\nearthquake data belonging to later dates of the same regions were used for\ntesting and the performance of the network was put forward. When the prediction\nresults of the developed network are examined, the prediction results that the\nnetwork predicts that an earthquake is not going to occur are quite high in all\nregions. Furthermore, the earthquake prediction results that the network\npredicts that an earthquake is going to occur are different to some extent for\nthe studied regions.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.02209v1"
    },
    {
        "title": "Emergency Management Systems and Algorithms: a Comprehensive Survey",
        "authors": [
            "Huibo Bi",
            "Erol Gelenbe"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Owing to the increasing frequency and destruction of natural and manmade\ndisasters to modern highly-populated societies, emergency management, which\nprovides solutions to prevent or address disasters, have drawn considerable\nresearch over the last few decades and become a multidisciplinary area. Because\nof its open and inclusive nature, new technologies always tend to influence,\nchange or even revolutionise this research area. Hence, it is imperative to\nconsolidate the state-of-the-art studies and knowledge to meet the research\nneeds and identify the future research directions. The paper presents a\ncomprehensive and systemic review of the existing research in the field of\nemergency management from both the system design aspect and algorithm\nengineering aspect. We begin with the history and evolution of the emergency\nmanagement research. Then the two main research topics of this area, \"emergency\nnavigation\" and \"emergency search and rescue planning\", are introduced and\ndiscussed. Finally, we suggest the emerging challenges and opportunities from\nsystem optimisation, evacuee behaviour modelling and optimisation, computing\npatterns, data analysis, energy and cyber security aspects.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04136v1"
    },
    {
        "title": "EU H2020 Gauss project. Geo-Fencing Software System",
        "authors": [
            "Hao Xu"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  The Geofencing system is the key to operate the Unmanned Aerial Vehicle (UAV)\nwithin the safe and appropriate zone to avoid public concerns and other privacy\nissues. The system is designed to keep the UAV away from geofenced obstacles\nusing the onboard GNSS and IMU location. The Geofencing system is part of the\nH2020 GAUSS project and facilities other subsystems, for instance, to support\nthe command and control link, which is the security measure to secure the UAV\nfrom hijacking and signal spoofing. The regulatory authorities expressed the\nconcern of having UAVs flying in the no-fly zone and causing troubles from\noffending private privacy to hazards at airport airspace. Hence the geofence\nsystem shall provide guidance message, which enables the UAV to evacuate from\nno-fly-zone, based on real-time updated location. This thesis aims to first\nillustrate the generation of geofence and then apply the geofence system on UAV\noperation. This application enables UAV to fly in the designated area without\nhuman intervention. The project is built with JAVA using GIS-enabled Database\nManagement System and Open Soured Map data powered by OpenStreetMap and OS map.\nThis method has been tested by simulations which had results of high accuracy.\n",
        "pdf_link": "http://arxiv.org/pdf/1907.04154v1"
    },
    {
        "title": "Authentication Modeling with Five Generic Processes",
        "authors": [
            "Sabah Al-Fedaghi",
            "MennatAllah Bayoumi"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Conceptual modeling is an essential tool in many fields of study, including\nsecurity specification in information technology systems. As a model, it\nrestricts access to resources and identifies possible threats to the system. We\nclaim that current modeling languages (e.g., Unified Modeling Language,\nBusiness Process Model and Notation) lack the notion of genericity, which\nrefers to a limited set of elementary processes. This paper proposes five\ngeneric processes for modeling the structural behavior of a system: creating,\nreleasing, transferring, receiving, and processing. The paper demonstrates\nthese processes within the context of public key infrastructure, biometric, and\nmultifactor authentication. The results indicate that the proposed generic\nprocesses are sufficient to represent these authentication schemes.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.01597v1"
    },
    {
        "title": "A Method of EV Detour-to-Recharge Behavior Modeling and Charging Station\n  Deployment",
        "authors": [
            "Tianshu Ouyang",
            "Jiahong Cai",
            "Yuxuan Gao",
            "Xinyan He",
            "Huimiao Chen",
            "Kexin Hang"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Electric vehicles (EVs) are increasingly used in transportation. Worldwide\nuse of EVs, for their limited battery capacity, calls for effective planning of\nEVs charging stations to enhance the efficiency of using EVs. This paper\nprovides a methodology of describing EV detouring behavior for recharging, and\nbased on this, we adopt the extra driving length caused by detouring and the\nlength of uncompleted route as the indicators of evaluating an EV charging\nstation deployment plan. In this way, we can simulate EV behavior based on\ntravel data (demand). Then, a genetic algorithm (GA) based EV charging station\nsitting optimization method is developed to obtain an effective plan. A\ndetailed case study based on a 100-node 203-branch transportation network\nwithin a 30 km * 30 km region is included to test the effectiveness of our\nmethod. Insights from our method may be applicable for charging station\nplanning in various transportation networks.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.02138v4"
    },
    {
        "title": "Data-driven charging strategies for grid-beneficial, customer-oriented\n  and battery-preserving electric mobility",
        "authors": [
            "Karl Schwenk",
            "Tim Harr",
            "Ren Gromann",
            "Riccardo Remo Appino",
            "Veit Hagenmeyer",
            "Ralf Mikut"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Electric Vehicle (EV) penetration and renewable energies enables synergies\nbetween energy supply, vehicle users, and the mobility sector. However, also\nnew issues arise for car manufacturers: During charging and discharging of EV\nbatteries a degradation (battery aging) occurs that correlates with a value\ndepreciation of the entire EV. As EV users' satisfaction depends on reliable\nand value-stable products, car manufacturers offer charging assistants for\nsimplified and sustainable EV usage by considering individual customer needs\nand battery aging. Hitherto models to quantify battery aging have limited\npracticability due to a complex execution. Data-driven methods hold feasible\nalternatives for SOH estimation. However, the existing approaches barely use\nuser-related data. By means of a linear and a neural network regression model,\nwe first estimate the energy consumption for driving considering individual\ndriving styles and environmental conditions. In following work, the consumption\nmodel trained on data from batteries without degradation can be used to\nestimate the energy consumption for EVs with aged batteries. A discrepancy\nbetween the estimation and the real consumption indicates a battery aging\ncaused by increased internal losses. We then target to evaluate the influence\nof charging strategies on battery degradation.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.07503v1"
    },
    {
        "title": "Benchmark Dataset for Timetable Optimization of Bus Routes in the City\n  of New Delhi",
        "authors": [
            "Anubhav Jain",
            "Avdesh Kumar",
            "Saumya Balodi",
            "Pravesh Biyani"
        ],
        "category": "cs.OH",
        "published_year": "2019",
        "summary": "  Public transport is one of the major forms of transportation in the world.\nThis makes it vital to ensure that public transport is efficient. This research\npresents a novel real-time GPS bus transit data for over 500 routes of buses\noperating in New Delhi. The data can be used for modeling various timetable\noptimization tasks as well as in other domains such as traffic management,\ntravel time estimation, etc. The paper also presents an approach to reduce the\nwaiting time of Delhi buses by analyzing the traffic behavior and proposing a\ntimetable. This algorithm serves as a benchmark for the dataset. The algorithm\nuses a constrained clustering algorithm for classification of trips. It further\nanalyses the data statistically to provide a timetable which is efficient in\nlearning the inter- and intra-month variations.\n",
        "pdf_link": "http://arxiv.org/pdf/1910.08903v1"
    },
    {
        "title": "TiLA: Twin-in-the-Loop Architecture for Cyber-Physical Production\n  Systems",
        "authors": [
            "Heejong Park",
            "Arvind Easwaran",
            "Sidharta Andalam"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Digital twin is a virtual replica of a real-world object that lives\nsimultaneously with its physical counterpart. Since its first introduction in\n2003 by Grieves, digital twin has gained momentum in a wide range of\napplications such as industrial manufacturing, automotive and artificial\nintelligence. However, many digital-twin-related approaches, found in\nindustries as well as literature, mainly focus on modelling individual physical\nthings with high-fidelity methods with limited scalability. In this paper, we\nintroduce a digital-twin architecture called TiLA (Twin-in-the-Loop\nArchitecture). TiLA employs heterogeneous models and online data to create a\ndigital twin, which follows a Globally Asynchronous Locally Synchronous (GALS)\nmodel of computation. It facilitates the creation of a scalable digital twin\nwith different levels of modelling abstraction as well as giving GALS formalism\nfor execution strategy. Furthermore, TiLA provides facilities to develop\napplications around the twin as well as an interface to synchronise the twin\nwith the physical system through an industrial communication protocol. A\ndigital twin for a manufacturing line has been developed as a case study using\nTiLA. It demonstrates the use of digital twin models together with online data\nfor monitoring and analysing failures in the physical system.\n",
        "pdf_link": "http://arxiv.org/pdf/2003.09370v1"
    },
    {
        "title": "SAXSDOG: open software for real-time azimuthal integration of 2D\n  scattering images",
        "authors": [
            "Max Burian",
            "Christian Meisenbichler",
            "Denys Naumenko",
            "Heinz Amenitsch"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  In-situ small- and wide-angle scattering experiments at synchrotrons often\nresult in massive amounts of data within seconds only. Especially during such\nbeamtimes, processing of the acquired data online, so without mentionable\ndelay, is key to obtain feedback on failure or success of the experiment. We\nthus developed SAXSDOG, a python based environment for real-time azimuthal\nintegration of large-area scattering-images. The software is primarily designed\nfor dedicated data-pipelines: once a scattering image is transferred from the\ndetector onto the storage-unit, it is automatically integrated and\npre-evaluated using integral parameters within milliseconds. The control and\nconfiguration of the underlying server-based processes is done via a graphical\nuser interface SAXSLEASH, which visualizes the resulting 1D data together with\nintegral classifiers in real time. SAXSDOG further includes a portable\n'take-home' version for users that runs on standalone computers, enabling its\nuse in labs or at the preferred workspace.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.02022v1"
    },
    {
        "title": "A Deep Learning-Based FPGA Function Block Detection Method with\n  Bitstream to Image Transformation",
        "authors": [
            "Minzhen Chen",
            "Peng Liu"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  In the context of various application scenarios and/or for the sake of\nstrengthening field-programmable gate array (FPGA) security, the system\nfunctions of an FPGA design need to be analyzed, which can be achieved by\nsystematically partitioning the FPGA's bitstream into manageable functional\nblocks and detecting their functionalities thereafter. In this paper, we\npropose a novel deep learning-based FPGA function block detection method with\nthree major steps. In specific, we first analyze the format of the bitstream to\nobtain the mapping relationship between the configuration bits and configurable\nlogic blocks because of the discontinuity of the configuration bits in the\nbitstream for one element. In order to reap the maturity of object detection\ntechniques based on deep learning, our next step is to convert an FPGA\nbitstream to an image, following the proposed transformation method that takes\naccount of both the adjacency nature of the programmable logic and the high\ndegree of redundancy of configuration information. Once the image is obtained,\na deep learning-based object detection algorithm is applied to this transformed\nimage, and the objects detected can be reflected back to determine the function\nblocks of the original FPGA design. The deep neural network used for function\nblock detection is trained and validated with a specially crafted\nbitstream/image dataset. Experiments have confirmed high detection accuracy of\nthe proposed function detection method, showing a 98.11% of mean Average\nPrecision (IoU=0.5) for 10 function blocks within a YOLOv3 detector implemented\non Xilinx Zynq-7000 SoCs and Zynq UltraScale+ MPSoCs.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.11434v3"
    },
    {
        "title": "Automatic Parking in Smart Cities",
        "authors": [
            "Arezou Abyaneh",
            "Vanessa Fakhoury",
            "Nizar Zorba"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  The objective behind this project is to maximize the efficiency of land\nspace, to decrease the driver stress and frustration, along with a considerable\nreduction in air pollution. Our contribution is in the form of an automatic\nparking system that is controlled by cellular phones. The structure is a\nhexagon shape that uses conveyor belts, to transport the vehicles from the\nentrance into the parking spaces over an elevating platform. The entrance gate\nincludes length-measuring sensors to determine whether the approaching vehicle\nis eligible to enter. Our system is controlled through a microcontroller, and\nusing cellular communications to connect to the customer. The project can be\napplied to different locations and is capable of capacity extensions.\n",
        "pdf_link": "http://arxiv.org/pdf/2007.13491v1"
    },
    {
        "title": "AI Chiller: An Open IoT Cloud Based Machine Learning Framework for the\n  Energy Saving of Building HVAC System via Big Data Analytics on the Fusion of\n  BMS and Environmental Data",
        "authors": [
            "Yong Yu"
        ],
        "category": "cs.OH",
        "published_year": "2020",
        "summary": "  Energy saving and carbon emission reduction in buildings is one of the key\nmeasures in combating climate change. Heating, Ventilation, and Air\nConditioning (HVAC) system account for the majority of the energy consumption\nin the built environment, and among which, the chiller plant constitutes the\ntop portion. The optimization of chiller system power consumption had been\nextensively studied in the mechanical engineering and building service domains.\nMany works employ physical models from the domain knowledge. With the advance\nof big data and AI, the adoption of machine learning into the optimization\nproblems becomes popular. Although many research works and projects turn to\nthis direction for energy saving, the application into the optimization problem\nremains a challenging task. This work is targeted to outline a framework for\nsuch problems on how the energy saving should be benchmarked, if holistic or\nindividually modeling should be used, how the optimization is to be conducted,\nwhy data pattern augmentation at the initial deployment is a must, why the\ngradually increasing changes strategy must be used. Results of analysis on\nhistorical data and empirical experiment on live data are presented.\n",
        "pdf_link": "http://arxiv.org/pdf/2011.01047v1"
    },
    {
        "title": "FBCNet: A Multi-view Convolutional Neural Network for Brain-Computer\n  Interface",
        "authors": [
            "Ravikiran Mane",
            "Effie Chew",
            "Karen Chua",
            "Kai Keng Ang",
            "Neethu Robinson",
            "A. P. Vinod",
            "Seong-Whan Lee",
            "Cuntai Guan"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Lack of adequate training samples and noisy high-dimensional features are key\nchallenges faced by Motor Imagery (MI) decoding algorithms for\nelectroencephalogram (EEG) based Brain-Computer Interface (BCI). To address\nthese challenges, inspired from neuro-physiological signatures of MI, this\npaper proposes a novel Filter-Bank Convolutional Network (FBCNet) for MI\nclassification. FBCNet employs a multi-view data representation followed by\nspatial filtering to extract spectro-spatially discriminative features. This\nmultistage approach enables efficient training of the network even when limited\ntraining data is available. More significantly, in FBCNet, we propose a novel\nVariance layer that effectively aggregates the EEG time-domain information.\nWith this design, we compare FBCNet with state-of-the-art (SOTA) BCI algorithm\non four MI datasets: The BCI competition IV dataset 2a (BCIC-IV-2a), the\nOpenBMI dataset, and two large datasets from chronic stroke patients. The\nresults show that, by achieving 76.20% 4-class classification accuracy, FBCNet\nsets a new SOTA for BCIC-IV-2a dataset. On the other three datasets, FBCNet\nyields up to 8% higher binary classification accuracies. Additionally, using\nexplainable AI techniques we present one of the first reports about the\ndifferences in discriminative EEG features between healthy subjects and stroke\npatients. Also, the FBCNet source code is available at\nhttps://github.com/ravikiran-mane/FBCNet.\n",
        "pdf_link": "http://arxiv.org/pdf/2104.01233v1"
    },
    {
        "title": "Three-body problem -- from Newton to supercomputer plus machine learning",
        "authors": [
            "Shijun Liao",
            "Xiaoming Li",
            "Yu Yang"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  The famous three-body problem can be traced back to Newton in 1687, but quite\nfew families of periodic orbits were found in 300 years thereafter. In this\npaper, we propose an effective approach and roadmap to numerically gain planar\nperiodic orbits of three-body systems with arbitrary masses by means of machine\nlearning based on an artificial neural network (ANN) model. Given any a known\nperiodic orbit as a starting point, this approach can provide more and more\nperiodic orbits (of the same family name) with variable masses, while the mass\ndomain having periodic orbits becomes larger and larger, and the ANN model\nbecomes wiser and wiser. Finally we have an ANN model trained by means of all\nobtained periodic orbits of the same family, which provides a convenient way to\ngive accurate enough predictions of periodic orbits with arbitrary masses for\nphysicists and astronomers. It suggests that the high-performance computer and\nartificial intelligence (including machine learning) should be the key to gain\nperiodic orbits of the famous three-body problem.\n",
        "pdf_link": "http://arxiv.org/pdf/2106.11010v2"
    },
    {
        "title": "Digital Twin As A Cost Reduction Method",
        "authors": [
            "Suleyman Yukcu",
            "Omer Aydin"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  Many fields have been affected by the introduction of concepts such as\nsensors, industry 4.0, internet of things, machine learning and artificial\nintelligence in recent years. As a result of the interaction of cyber physical\nsystems with these concepts, digital twin model has emerged. The concept of\ndigital twin has been used in many areas with its emergence. The use of this\nmodel has made significant gains, especially in decision making processes. The\ngains in decision making processes contribute to every field and cause changes\nin terms of cost. In this study, the historical development of the concept of\ndigital twin has been mentioned and general information about the usage areas\nof digital twin has been given. In the light of this information, the cost\neffect of the digital twin model, therefore its appearance from the cost\naccounting window and its use as a cost reduction method were evaluated. This\nstudy was carried out in order to shed light on the studies with the\ninsufficient resources in the Turkish literature and the cost accounting\nperspective.\n",
        "pdf_link": "http://arxiv.org/pdf/2107.14109v1"
    },
    {
        "title": "A Computable Piece of Uncomputable Art whose Expansion May Explain the\n  Universe in Software Space",
        "authors": [
            "Hector Zenil"
        ],
        "category": "cs.OH",
        "published_year": "2021",
        "summary": "  At the intersection of what I call uncomputable art and computational\nepistemology, a form of experimental philosophy, we find an exciting and\npromising area of science related to causation with an alternative, possibly\nbest possible, solution to the challenge of the inverse problem. That is the\nproblem of finding the possible causes, mechanistic origins, first principles,\nand generative models of a piece of data from a physical phenomenon. Here we\nexplain how generating and exploring software space following the framework of\nAlgorithmic Information Dynamics, it is possible to find small models and learn\nto navigate a sci-fi-looking space that can advance the field of scientific\ndiscovery with complementary tools to offer an opportunity to advance science\nitself.\n",
        "pdf_link": "http://arxiv.org/pdf/2109.08523v1"
    },
    {
        "title": "Quantum Fault Trees",
        "authors": [
            "Gabriel San Martin Silva",
            "Tarannom Parhizkar",
            "Enrique Lopez Droguett"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Fault tree analysis is a technique widely used in risk and reliability\nanalysis of complex engineering systems given its deductive nature and\nrelatively simple interpretation. In a fault tree, events are usually\nrepresented by a binary variable that indicates whether an event occurs or not,\ntraditionally associated with the values 1 and 0, respectively. Different\nevents are linked together using logical gates, modelling the dependencies that\na subsystem or system may have over its basic components. In this study,\nquantum computing is leveraged to propose a novel approach to encode a\ntraditional fault tree into a quantum algorithm. This quantum fault tree method\nuses quantum bits to represent basic events, effectively encoding the original\nfault tree into a quantum circuit. The execution of the resulting quantum\ncircuit represents a full simulation of the fault tree, and multiple executions\ncan be utilized to compute the failure probability of the whole system. The\nproposed approach is tested on a case study portraying a dynamic positioning\nsystem. Results verify that the quantum-based proposed approach is able to\neffectively obtain the dynamic positioning failure probability through\nsimulation, opening promising opportunities for future investigations in the\narea.\n",
        "pdf_link": "http://arxiv.org/pdf/2204.10877v1"
    },
    {
        "title": "Road Network Variation Based on HD Map Analysis for the Simulative\n  Safety Assurance of Automated Vehicles",
        "authors": [
            "Daniel Becker",
            "Christian Geller",
            "Lutz Eckstein"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  The validation and verification of automated driving functions (ADFs) is a\nchallenging task on the journey of making those functions available to the\npublic beyond the current research context. Simulation is a valuable building\nblock for scenario-based testing that can help to model traffic situations that\nare relevant for ADFs. In addition to the surrounding traffic and environment\nof the ADF under test, the logical description and automated generation of\nconcrete road networks have an important role. We aim to reduce efforts for\nmanual map generation and to improve the automated testing process during\ndevelopment.\n  Hence, this paper proposes a method to analyze real road networks and extract\nrelevant parameters for the variation of synthetic simulation maps that\ncorrespond to real-world properties. Consequently, characteristics for\ninner-city junctions are selected from Here HD map. Then, parameter\ndistributions are determined, analyzed and used to generate variations of road\nnetworks in the OpenDRIVE standard. The presented methodology enables efficient\nroad network modeling which can be used for large scale simulations. The\ndeveloped road network generation tool is publicly available on GitHub.\n",
        "pdf_link": "http://arxiv.org/pdf/2210.00853v1"
    },
    {
        "title": "HERMES: qualification of High pErformance pRogrammable Microprocessor\n  and dEvelopment of Software ecosystem",
        "authors": [
            "Nadia Ibellaatti",
            "Edouard Lepape",
            "Alp Kilic",
            "Kaya Akyel",
            "Kassem Chouayakh",
            "Fabrizio Ferrandi",
            "Claudio Barone",
            "Serena Curzel",
            "Michele Fiorito",
            "Giovanni Gozzi",
            "Miguel Masmano",
            "Ana Risquez Navarro",
            "Manuel Muoz",
            "Vicente Nicolau Gallego",
            "Patricia Lopez Cueva",
            "Jean-noel Letrillard",
            "Franck Wartel"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  European efforts to boost competitiveness in the sector of space services\npromote the research and development of advanced software and hardware\nsolutions. The EU-funded HERMES project contributes to the effort by qualifying\nradiation-hardened, high-performance programmable microprocessors, and by\ndeveloping a software ecosystem that facilitates the deployment of complex\napplications on such platforms. The main objectives of the project include\nreaching a technology readiness level of 6 (i.e., validated and demonstrated in\nrelevant environment) for the rad-hard NG-ULTRA FPGA with its ceramic hermetic\npackage CGA 1752, developed within projects of the European Space Agency,\nFrench National Centre for Space Studies and the European Union. An equally\nimportant share of the project is dedicated to the development and validation\nof tools that support multicore software programming and FPGA acceleration,\nincluding Bambu for High-Level Synthesis and the XtratuM hypervisor with a\nlevel one boot loader for virtualization.\n",
        "pdf_link": "http://arxiv.org/pdf/2302.06427v1"
    },
    {
        "title": "Real-Time Adaptive Abstraction and Approximation Using Validity Frames\n  -- an Experience Report",
        "authors": [
            "Raheleh Biglari",
            "Joachim Denil"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Designing a Cyber-Physical System (CPS), including modeling the control\ncomponents and services, is a challenging task. Using models and simulations\nduring run-time is crucial for successfully implementing advanced control and\nprediction components. The complexity of designing an effective CPS system\nincreases due to real-time constraints. Generating accurate predictions and\nmaking decisions using detailed models in various contexts is %can be\ncomputationally demanding and complex to manage within the available\ncomputational resources. Employing approximated models and switching to the\nmost suited model adaptively at run-time is an effective technique. But an\napproximated model is most probable not valid in all the different contexts the\nsystem will be in. This experience report uses the Validity Frame concept to\nenable %this adaptation at run-time. In each environment, some influencing\nfactors are outside the model's control, but these properties influence the\nmodel's behavior. By defining Validity Frames, based on specific contexts and\nrelated models, we present a possible perspective to address the issue of\nselecting the more appropriate model in various contexts. Furthermore, we\ndiscuss the insights and lessons obtained and determine future challenges.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.07144v2"
    },
    {
        "title": "Digital Twins for Trust Building in Autonomous Drones through Dynamic\n  Safety Evaluation",
        "authors": [
            "Danish Iqbal",
            "Barbora Buhnova",
            "Emilia Cioroaica"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  The adoption process of innovative software-intensive technologies leverages\ncomplex trust concerns in different forms and shapes. Perceived safety plays a\nfundamental role in technology adoption, being especially crucial in the case\nof those innovative software-driven technologies characterized by a high degree\nof dynamism and unpredictability, like collaborating autonomous systems. These\nsystems need to synchronize their maneuvers in order to collaboratively engage\nin reactions to unpredictable incoming hazardous situations. That is however\nonly possible in the presence of mutual trust.\n  In this paper, we propose an approach for machine-to-machine dynamic trust\nassessment for collaborating autonomous systems that supports trust-building\nbased on the concept of dynamic safety assurance within the collaborative\nprocess among the software-intensive autonomous systems. In our approach, we\nleverage the concept of digital twins which are abstract models fed with\nreal-time data used in the run-time dynamic exchange of information. The\ninformation exchange is performed through the execution of specialized models\nthat embed the necessary safety properties. More particularly, we examine the\npossible role of the Digital Twins in machine-to-machine trust building and\npresent their design in supporting dynamic trust assessment of autonomous\ndrones. Ultimately, we present a proof of concept of direct and indirect trust\nassessment by employing the Digital Twin in a use case involving two autonomous\ncollaborating drones.\n",
        "pdf_link": "http://arxiv.org/pdf/2303.12805v1"
    },
    {
        "title": "Classification of Sequential Circuits as Causal Functions",
        "authors": [
            "Shunji Nishimura"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  In sequential circuits, the current output may depend on both past and\ncurrent inputs. However, certain kinds of sequential circuits do not refer to\nall of the past inputs to generate the current output; they only refer to a\nsubset of past inputs. This paper investigates which subset of past inputs a\nsequential circuit refers to, and proposes a new classification of sequential\ncircuits based on this criterion. The conventional classification of sequential\ncircuits distinguishes between synchronous and asynchronous circuits. In\ncontrast, the new classification consolidates synchronous circuits and multiple\nclock domain circuits into the same category.\n",
        "pdf_link": "http://arxiv.org/pdf/2306.17583v1"
    },
    {
        "title": "Towards a unified language in experimental designs propagated by a\n  software framework",
        "authors": [
            "Emi Tanaka"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  Experiments require human decisions in the design process, which in turn are\nreformulated and summarized as inputs into a system (computational or\notherwise) to generate the experimental design. I leverage this system to\npromote a language of experimental designs by proposing a novel computational\nframework, called \"the grammar of experimental designs\", to specify\nexperimental designs based on an object-oriented programming system that\ndeclaratively encapsulates the experimental structure. The framework aims to\nengage human cognition by building experimental designs with modular functions\nthat modify a targeted singular element of the experimental design object. The\nsyntax and semantics of the framework are built upon consideration from\nmultiple perspectives. While the core framework is language-agnostic, the\nframework is implemented in the `edibble` R-package. A range of examples is\nshown to demonstrate the utility of the framework.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.11593v2"
    },
    {
        "title": "Development of an Autonomous Reverse Engineering Capability for\n  Controller Area Network Messages to Support Autonomous Control Retrofits",
        "authors": [
            "Kevin Setterstrom",
            "Jeremy Straub"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  As the autonomous vehicle industry continues to grow, various companies are\nexploring the use of aftermarket kits to retrofit existing vehicles with\nsemi-autonomous capabilities. However, differences in implementation of the\ncontroller area network (CAN) used by each vehicle manufacturer poses a\nsignificant challenge to achieving large-scale implementation of retrofits. To\naddress this challenge, this research proposes a method for reverse engineering\nthe CAN channels associated with a vehicle's accelerator and brake pedals,\nwithout any prior knowledge of the vehicle. By simultaneously recording\ninertial measurement unit (IMU) and CAN data during vehicle operation, the\nproposed algorithms can identify the CAN channels that correspond to each\ncontrol. During testing of six vehicles from three manufacturers, the proposed\nmethod was shown to successfully identify the CAN channels for the accelerator\npedal and brake pedal for each vehicle tested. These promising results\ndemonstrate the potential for using this approach for developing aftermarket\nautonomous vehicle kits - potentially with additional research to facilitate\nreal-time use. Notably, the proposed system has the potential to maintain its\neffectiveness despite changes in vehicle CAN standards, and it could\npotentially be adapted to function with any vehicle communications medium.\n",
        "pdf_link": "http://arxiv.org/pdf/2307.11781v1"
    },
    {
        "title": "Compression Performance Analysis of Different File Formats",
        "authors": [
            "Han Yang",
            "Guangjun Qin",
            "Yongqing Hu"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  In data storage and transmission, file compression is a common technique for\nreducing the volume of data, reducing data storage space and transmission time\nand bandwidth. However, there are significant differences in the compression\nperformance of different types of file formats, and the benefits vary. In this\npaper, 22 file formats with approximately 178GB of data were collected and the\nZlib algorithm was used for compression experiments to compare performance in\norder to investigate the compression gains of different file types. The\nexperimental results show that some file types are poorly compressed, with\nalmost constant file size and long compression time, resulting in lower gains;\nsome other file types are significantly reduced in file size and compression\ntime after compression, which can effectively reduce the data volume. Based on\nthe above experimental results, this paper will then selectively reduce the\ndata volume by compression in data storage and transmission for the file types\nin order to obtain the maximum compression yield.\n",
        "pdf_link": "http://arxiv.org/pdf/2308.12275v1"
    },
    {
        "title": "Metacognitive threshold: a computational account",
        "authors": [
            "Brendan Conway-Smith",
            "Robert L. West"
        ],
        "category": "cs.OH",
        "published_year": "2023",
        "summary": "  This paper will explore ways of computationally accounting for the\nmetacognitive threshold -- the minimum amount of stimulus needed for a mental\nstate to be perceived -- and discuss potential cognitive mechanisms by which\nthis threshold can be influenced through metacognitive training and meditation.\n",
        "pdf_link": "http://arxiv.org/pdf/2310.13005v1"
    },
    {
        "title": "ModZoo: A Large-Scale Study of Modded Android Apps and their Markets",
        "authors": [
            "Luis A. Saavedra",
            "Hridoy S. Dutta",
            "Alastair R. Beresford",
            "Alice Hutchings"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  We present the results of the first large-scale study into Android markets\nthat offer modified or modded apps: apps whose features and functionality have\nbeen altered by a third-party. We analyse over 146k (thousand) apps obtained\nfrom 13 of the most popular modded app markets. Around 90% of apps we collect\nare altered in some way when compared to the official counterparts on Google\nPlay. Modifications include games cheats, such as infinite coins or lives;\nmainstream apps with premium features provided for free; and apps with modified\nadvertising identifiers or excluded ads. We find the original app developers\nlose significant potential revenue due to: the provision of paid for apps for\nfree (around 5% of the apps across all markets); the free availability of\npremium features that require payment in the official app; and modified\nadvertising identifiers. While some modded apps have all trackers and ads\nremoved (3%), in general, the installation of these apps is significantly more\nrisky for the user than the official version: modded apps are ten times more\nlikely to be marked as malicious and often request additional permissions.\n",
        "pdf_link": "http://arxiv.org/pdf/2402.19180v2"
    },
    {
        "title": "Trainable Least Squares to Reduce PAPR in OFDM-based Hybrid Beamforming\n  Systems",
        "authors": [
            "Andrey Ivanov",
            "Alexander Osinsky",
            "Roman Bychkov",
            "Vladimir Kalinin",
            "Dmitry Lakontsev"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  In this paper, we propose a trainable least squares (LS) approach for\nreducing the peak-to-average power ratio (PAPR) of orthogonal frequency\ndivision multiplexing (OFDM) signals in a hybrid beamforming (HBF) system.\nCompared to digital beamforming (DBF), in HBF technology the number of antennas\nexceeds the number of digital ports. Therefore, PAPR reduction capabilities are\nrestricted by both a limited bandwidth and the reduced size of digital space.\nThe problem is to meet both conditions. Moreover, the major HBF advantage is a\nreduced system complexity, thus the complexity of the PAPR reduction algorithm\nis expected to be low. To justify the performance of the proposed trainable LS,\nwe provide a performance bound achieved by convex optimization using the CVX\nMatlab package. Moreover, the complexity of the proposed algorithm can be\ncomparable to the minimal complexity of the digital ``twin'' calculation in\nHBF. The abovementioned features prove the feasibility of the trained LS for\nPAPR reduction in fully-connected HBF.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02160v1"
    },
    {
        "title": "Virtual Sectorization to Enable Hybrid Beamforming in mm-Wave mMIMO",
        "authors": [
            "Roman Bychkov",
            "Andrey Dergachev",
            "Alexander Osinsky",
            "Vladimir Lyashev",
            "Andrey Ivanov"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Hybrid beamforming (HBF) is a key technology to enable mm-wave Massive\nmultiple-input multiple-output (mMIMO) receivers for future-generation wireless\ncommunications. It combines beamforming in both analog (via phase shifters) and\ndigital domains, resulting in low power consumption and high spectral\nefficiency. In practice, the problem of joint beamforming in multi-user\nscenarios is still open because an analog beam can't cover all users\nsimultaneously. In this paper, we propose a hierarchical approach to divide\nusers into clusters. Each cluster consists of users inside a virtual sector\nproduced by the analog beamforming of an HBF-based mMIMO receiver. Thus, inside\neach sector, a lower-cost digital beamforming serves a limited number of users\nwithin the same cluster. Simulations with realistic non-line-of-sight scenarios\ngenerated by the QuaDRiGa 2.0 demonstrate that our methods outperform standard\nFFT-based alternatives and almost achieve SVD-based beamspace performance\nbound.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02161v1"
    },
    {
        "title": "LoS Sensing-based Channel Estimation in UAV-Assisted OFDM Systems",
        "authors": [
            "Chaojin Qing",
            "Zhiying Liu",
            "Wenquan Hu",
            "Yinjie Zhang",
            "Xi Cai",
            "Pengfei Du"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  In unmanned aerial vehicle (UAV)-assisted orthogonal frequency division\nmultiplexing (OFDM) systems, the potential advantage of the line-of-sight (LoS)\npath, characterized by its high probability of existence, has not been fully\nharnessed, thereby impeding the improvement of channel estimation (CE)\naccuracy. Inspired by the ideas of integrated sensing and communication (ISAC),\nthis letter develops a LoS sensing method aimed at detecting the presence of\nLoS path. Leveraging the prior information obtained from LoS path detection,\nthe detection thresholds for resolvable paths are proposed for LoS and Non-LoS\n(NLoS) scenarios, respectively. By employing these specifically designed\ndetection thresholds, denoising processing is applied to classical least square\n(LS) CE, thereby improving the CE accuracy. Simulation results validate the\neffectiveness of the proposed method in enhancing CE accuracy and demonstrate\nits robustness against parameter variations.\n",
        "pdf_link": "http://arxiv.org/pdf/2404.02162v1"
    },
    {
        "title": "Stream State-tying for Sign Language Recognition",
        "authors": [
            "Jiyong Ma",
            "Wen Gao",
            "Chunli Wang"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  In this paper, a novel approach to sign language recognition based on state\ntying in each of data streams is presented. In this framework, it is assumed\nthat hand gesture signal is represented in terms of six synchronous data\nstreams, i.e., the left/right hand position, left/right hand orientation and\nleft/right handshape. This approach offers a very accurate representation of\nthe sign space and keeps the number of parameters reasonably small in favor of\na fast decoding. Experiments were carried out for 5177 Chinese signs. The real\ntime isolated recognition rate is 94.8%. For continuous sign recognition, the\nword correct rate is 91.4%. Keywords: Sign language recognition; Automatic sign\nlanguage translation; Hand gesture recognition; Hidden Markov models;\nState-tying; Multimodal user interface; Virtual reality; Man-machine systems.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.10975v1"
    },
    {
        "title": "Predicting Star Scientists in the Field of Artificial Intelligence: A\n  Machine Learning Approach",
        "authors": [
            "Koosha Shirouyeh",
            "Andrea Schiffauerova",
            "Ashkan Ebadi"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  Star scientists are highly influential researchers who have made significant\ncontributions to their field, gained widespread recognition, and often\nattracted substantial research funding. They are critical for the advancement\nof science and innovation, and they have a significant influence on the\ntransfer of knowledge and technology to industry. Identifying potential star\nscientists before their performance becomes outstanding is important for\nrecruitment, collaboration, networking, or research funding decisions. Using\nmachine learning techniques, this study proposes a model to predict star\nscientists in the field of artificial intelligence while highlighting features\nrelated to their success. Our results confirm that rising stars follow\ndifferent patterns compared to their non-rising stars counterparts in almost\nall the early-career features. We also found that certain features such as\ngender and ethnic diversity play important roles in scientific collaboration\nand that they can significantly impact an author's career development and\nsuccess. The most important features in predicting star scientists in the field\nof artificial intelligence were the number of articles, group discipline\ndiversity, and weighted degree centrality. The proposed approach offers\nvaluable insights for researchers, practitioners, and funding agencies\ninterested in identifying and supporting talented researchers.\n",
        "pdf_link": "http://arxiv.org/pdf/2407.14559v1"
    },
    {
        "title": "RESISTO Project: Safeguarding the Power Grid from Meteorological\n  Phenomena",
        "authors": [
            "Jacob Rodrguez-Rivero",
            "David Lpez-Garca",
            "Fermn Segovia",
            "Javier Ramrez",
            "Juan Manuel Grriz",
            "Ral Serrano",
            "David Prez",
            "Ivn Maza",
            "Anbal Ollero",
            "Pol Paradell Sol",
            "Albert Gili Selga",
            "Jos Luis Domnguez-Garca",
            "A. Romero",
            "A. Berro",
            "Roco Domnguez",
            "Inmaculada Prieto"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  The RESISTO project, a pioneer innovation initiative in Europe, endeavors to\nenhance the resilience of electrical networks against extreme weather events\nand associated risks. Emphasizing intelligence and flexibility within\ndistribution networks, RESISTO aims to address climatic and physical incidents\ncomprehensively, fostering resilience across planning, response, recovery, and\nadaptation phases. Leveraging advanced technologies including AI, IoT sensors,\nand aerial robots, RESISTO integrates prediction, detection, and mitigation\nstrategies to optimize network operation. This article summarizes the main\ntechnical aspects of the proposed solutions to meet the aforementioned\nobjectives, including the development of a climate risk detection platform, an\nIoT-based monitoring and anomaly detection network, and a fleet of intelligent\naerial robots. Each contributing to the project's overarching objectives of\nenhancing network resilience and operational efficiency.\n",
        "pdf_link": "http://arxiv.org/pdf/2410.19799v1"
    },
    {
        "title": "SprayCraft: Graph-Based Route Optimization for Variable Rate Precision\n  Spraying",
        "authors": [
            "Kiran K. Kethineni",
            "Saraju P. Mohanty",
            "Elias Kougianos",
            "Sanjukta Bhowmick",
            "Laavanya Rachakonda"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  To efficiently manage plant diseases, Agriculture Cyber-Physical Systems\n(A-CPS) have been developed to detect and localize disease infestations by\nintegrating the Internet of Agro-Things (IoAT). By the nature of plant and\npathogen interactions, the spread of a disease appears as a focus with density\nof infected plants and intensity of infection diminishing outwards. This\ngradient of infection needs variable rate and precision pesticide spraying to\nefficiently utilize resources and effectively handle the diseases. This\narticle, SprayCraft presents a graph based method for disease management A-CPS\nto identify disease hotspots and compute near optimal path for a spraying drone\nto perform variable rate precision spraying. It uses graph to represent the\ndiseased locations and their spatial relation, Message Passing is performed\nover the graph to compute the probability of a location to be a disease\nhotspot. These probabilities also serve as disease intensity measures and are\nused for variable rate spraying at each location. Whereas, the graph is\nutilized to compute tour path by considering it as Traveling Salesman Problem\n(TSP) for precision spraying by the drone. Proposed method has been validated\non synthetic data of locations of diseased locations in a farmland.\n",
        "pdf_link": "http://arxiv.org/pdf/2412.12176v1"
    },
    {
        "title": "A QUBO Formulation for the Generalized Takuzu/LinkedIn Tango Game",
        "authors": [
            "Alejandro Mata Ali",
            "Edgar Mencia"
        ],
        "category": "cs.OH",
        "published_year": "2024",
        "summary": "  In this paper we present a QUBO formulation for the Takuzu game (or Binairo),\nfor the most recent LinkedIn game, Tango, and for its generalizations. We\noptimize the number of variables needed to solve the combinatorial problem,\nmaking it suitable to be solved by quantum devices with fewer resources.\n",
        "pdf_link": "http://arxiv.org/pdf/2501.00002v1"
    },
    {
        "title": "Innovations in the field of on-board scheduling technologies",
        "authors": [
            "Temenuzhka Avramova",
            "Riccardo Maderna",
            "Alessandro Benetton",
            "Christian Cardenio"
        ],
        "category": "cs.OH",
        "published_year": "2022",
        "summary": "  Space missions are characterized by long distances, difficult or unavailable\ncommunication and high operating costs. Moreover, complexity has been\nconstantly increasing in recent years. For this reason, improving the autonomy\nof space operators is an attractive goal to increase the mission reward with\nlower costs. This paper proposes an onboard scheduler, that integrates inside\nan onboard software framework for mission autonomy. Given a set of activities,\nit is responsible for determining the starting time of each activity according\nto their priority, order constraints, and resource consumption. The presented\nscheduler is based on linear integer programming and relies on the use of a\nbranch-and-cut solver. The technology has been tested on an Earth Observation\nscenario, comparing its performance against the state-of-the-art scheduling\ntechnology.\n",
        "pdf_link": "http://arxiv.org/pdf/2205.06792v1"
    }
]